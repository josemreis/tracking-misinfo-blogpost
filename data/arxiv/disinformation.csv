,entry_id,updated,published,title,authors,summary,comment,journal_ref,doi,primary_category,categories,links,pdf_url,_raw,query
0,http://arxiv.org/abs/2110.03432v1,2021-10-05 16:11:08+00:00,2021-10-05 16:11:08+00:00,"Fake news, noise, and tenacious Bayesians",[arxiv.Result.Author('Dorje C. Brody')],"A modelling framework, based on the theory of signal processing, for
characterising the dynamics of systems driven by the unravelling of information
is outlined, and is applied to describe the process of decision makings. The
model input of this approach is the specification of the flow of information.
This enables the representation of (i) reliable information, (ii) noise, and
(iii) disinformation, in a unified framework. Because the approach is designed
to characterise the dynamics of the system under study, it is possible to
quantify the impact of information control, including those resulting from the
dissemination of disinformation. It is shown that if a decision maker assigns
an exceptionally high weight on one of the alternative realities, then under
the Bayesian logic their perception hardly changes in time even if evidences
presented indicate that this alternative corresponds to a false reality. By
observing the role played by noise in other areas of natural sciences, a new
approach to tackle the dark forces of fake news is proposed.","16 pages, 4 figures",,,econ.TH,"['econ.TH', 'econ.GN', 'math.PR', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/2110.03432v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.03432v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.03432v1,"{'id': 'http://arxiv.org/abs/2110.03432v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.03432v1', 'updated': '2021-10-05T16:11:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=5, tm_hour=16, tm_min=11, tm_sec=8, tm_wday=1, tm_yday=278, tm_isdst=0), 'published': '2021-10-05T16:11:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=5, tm_hour=16, tm_min=11, tm_sec=8, tm_wday=1, tm_yday=278, tm_isdst=0), 'title': 'Fake news, noise, and tenacious Bayesians', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news, noise, and tenacious Bayesians'}, 'summary': 'A modelling framework, based on the theory of signal processing, for\ncharacterising the dynamics of systems driven by the unravelling of information\nis outlined, and is applied to describe the process of decision makings. The\nmodel input of this approach is the specification of the flow of information.\nThis enables the representation of (i) reliable information, (ii) noise, and\n(iii) disinformation, in a unified framework. Because the approach is designed\nto characterise the dynamics of the system under study, it is possible to\nquantify the impact of information control, including those resulting from the\ndissemination of disinformation. It is shown that if a decision maker assigns\nan exceptionally high weight on one of the alternative realities, then under\nthe Bayesian logic their perception hardly changes in time even if evidences\npresented indicate that this alternative corresponds to a false reality. By\nobserving the role played by noise in other areas of natural sciences, a new\napproach to tackle the dark forces of fake news is proposed.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A modelling framework, based on the theory of signal processing, for\ncharacterising the dynamics of systems driven by the unravelling of information\nis outlined, and is applied to describe the process of decision makings. The\nmodel input of this approach is the specification of the flow of information.\nThis enables the representation of (i) reliable information, (ii) noise, and\n(iii) disinformation, in a unified framework. Because the approach is designed\nto characterise the dynamics of the system under study, it is possible to\nquantify the impact of information control, including those resulting from the\ndissemination of disinformation. It is shown that if a decision maker assigns\nan exceptionally high weight on one of the alternative realities, then under\nthe Bayesian logic their perception hardly changes in time even if evidences\npresented indicate that this alternative corresponds to a false reality. By\nobserving the role played by noise in other areas of natural sciences, a new\napproach to tackle the dark forces of fake news is proposed.'}, 'authors': [{'name': 'Dorje C. Brody'}], 'author_detail': {'name': 'Dorje C. Brody'}, 'author': 'Dorje C. Brody', 'arxiv_comment': '16 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2110.03432v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.03432v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
1,http://arxiv.org/abs/2110.03664v1,2021-10-04 06:17:12+00:00,2021-10-04 06:17:12+00:00,"TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity, Geo, and Gender Labels","[arxiv.Result.Author('Muhammad Imran'), arxiv.Result.Author('Umair Qazi'), arxiv.Result.Author('Ferda Ofli')]","The widespread usage of social networks during mass convergence events, such
as health emergencies and disease outbreaks, provides instant access to
citizen-generated data that carry rich information about public opinions,
sentiments, urgent needs, and situational reports. Such information can help
authorities understand the emergent situation and react accordingly. Moreover,
social media plays a vital role in tackling misinformation and disinformation.
This work presents TBCOV, a large-scale Twitter dataset comprising more than
two billion multilingual tweets related to the COVID-19 pandemic collected
worldwide over a continuous period of more than one year. More importantly,
several state-of-the-art deep learning models are used to enrich the data with
important attributes, including sentiment labels, named-entities (e.g.,
mentions of persons, organizations, locations), user types, and gender
information. Last but not least, a geotagging method is proposed to assign
country, state, county, and city information to tweets, enabling a myriad of
data analysis tasks to understand real-world issues. Our sentiment and trend
analyses reveal interesting insights and confirm TBCOV's broad coverage of
important topics.","20 pages, 13 figures, 8 tables",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2110.03664v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.03664v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.03664v1,"{'id': 'http://arxiv.org/abs/2110.03664v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.03664v1', 'updated': '2021-10-04T06:17:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=4, tm_hour=6, tm_min=17, tm_sec=12, tm_wday=0, tm_yday=277, tm_isdst=0), 'published': '2021-10-04T06:17:12Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=4, tm_hour=6, tm_min=17, tm_sec=12, tm_wday=0, tm_yday=277, tm_isdst=0), 'title': 'TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity,\n  Geo, and Gender Labels', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity,\n  Geo, and Gender Labels'}, 'summary': ""The widespread usage of social networks during mass convergence events, such\nas health emergencies and disease outbreaks, provides instant access to\ncitizen-generated data that carry rich information about public opinions,\nsentiments, urgent needs, and situational reports. Such information can help\nauthorities understand the emergent situation and react accordingly. Moreover,\nsocial media plays a vital role in tackling misinformation and disinformation.\nThis work presents TBCOV, a large-scale Twitter dataset comprising more than\ntwo billion multilingual tweets related to the COVID-19 pandemic collected\nworldwide over a continuous period of more than one year. More importantly,\nseveral state-of-the-art deep learning models are used to enrich the data with\nimportant attributes, including sentiment labels, named-entities (e.g.,\nmentions of persons, organizations, locations), user types, and gender\ninformation. Last but not least, a geotagging method is proposed to assign\ncountry, state, county, and city information to tweets, enabling a myriad of\ndata analysis tasks to understand real-world issues. Our sentiment and trend\nanalyses reveal interesting insights and confirm TBCOV's broad coverage of\nimportant topics."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The widespread usage of social networks during mass convergence events, such\nas health emergencies and disease outbreaks, provides instant access to\ncitizen-generated data that carry rich information about public opinions,\nsentiments, urgent needs, and situational reports. Such information can help\nauthorities understand the emergent situation and react accordingly. Moreover,\nsocial media plays a vital role in tackling misinformation and disinformation.\nThis work presents TBCOV, a large-scale Twitter dataset comprising more than\ntwo billion multilingual tweets related to the COVID-19 pandemic collected\nworldwide over a continuous period of more than one year. More importantly,\nseveral state-of-the-art deep learning models are used to enrich the data with\nimportant attributes, including sentiment labels, named-entities (e.g.,\nmentions of persons, organizations, locations), user types, and gender\ninformation. Last but not least, a geotagging method is proposed to assign\ncountry, state, county, and city information to tweets, enabling a myriad of\ndata analysis tasks to understand real-world issues. Our sentiment and trend\nanalyses reveal interesting insights and confirm TBCOV's broad coverage of\nimportant topics.""}, 'authors': [{'name': 'Muhammad Imran'}, {'name': 'Umair Qazi'}, {'name': 'Ferda Ofli'}], 'author_detail': {'name': 'Ferda Ofli'}, 'author': 'Ferda Ofli', 'arxiv_comment': '20 pages, 13 figures, 8 tables', 'links': [{'href': 'http://arxiv.org/abs/2110.03664v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.03664v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
2,http://arxiv.org/abs/2109.12865v1,2021-09-27 08:33:37+00:00,2021-09-27 08:33:37+00:00,How does fake news spread? Understanding pathways of disinformation spread through APIs,"[arxiv.Result.Author('Lynnette H. X. Ng'), arxiv.Result.Author('Araz Taeihagh')]","What are the pathways for spreading disinformation on social media platforms?
This article addresses this question by collecting, categorising, and situating
an extensive body of research on how application programming interfaces (APIs)
provided by social media platforms facilitate the spread of disinformation. We
first examine the landscape of official social media APIs, then perform
quantitative research on the open-source code repositories GitHub and GitLab to
understand the usage patterns of these APIs. By inspecting the code
repositories, we classify developers' usage of the APIs as official and
unofficial, and further develop a four-stage framework characterising pathways
for spreading disinformation on social media platforms. We further highlight
how the stages in the framework were activated during the 2016 US Presidential
Elections, before providing policy recommendations for issues relating to
access to APIs, algorithmic content, advertisements, and suggest rapid response
to coordinate campaigns, development of collaborative, and participatory
approaches as well as government stewardship in the regulation of social media
platforms.",,"Policy and Internet, 2021",10.1002/poi3.268,cs.CY,"['cs.CY', 'cs.CR', 'cs.HC', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1002/poi3.268', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.12865v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12865v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12865v1,"{'id': 'http://arxiv.org/abs/2109.12865v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12865v1', 'updated': '2021-09-27T08:33:37Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=8, tm_min=33, tm_sec=37, tm_wday=0, tm_yday=270, tm_isdst=0), 'published': '2021-09-27T08:33:37Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=8, tm_min=33, tm_sec=37, tm_wday=0, tm_yday=270, tm_isdst=0), 'title': 'How does fake news spread? Understanding pathways of disinformation\n  spread through APIs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How does fake news spread? Understanding pathways of disinformation\n  spread through APIs'}, 'summary': ""What are the pathways for spreading disinformation on social media platforms?\nThis article addresses this question by collecting, categorising, and situating\nan extensive body of research on how application programming interfaces (APIs)\nprovided by social media platforms facilitate the spread of disinformation. We\nfirst examine the landscape of official social media APIs, then perform\nquantitative research on the open-source code repositories GitHub and GitLab to\nunderstand the usage patterns of these APIs. By inspecting the code\nrepositories, we classify developers' usage of the APIs as official and\nunofficial, and further develop a four-stage framework characterising pathways\nfor spreading disinformation on social media platforms. We further highlight\nhow the stages in the framework were activated during the 2016 US Presidential\nElections, before providing policy recommendations for issues relating to\naccess to APIs, algorithmic content, advertisements, and suggest rapid response\nto coordinate campaigns, development of collaborative, and participatory\napproaches as well as government stewardship in the regulation of social media\nplatforms."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""What are the pathways for spreading disinformation on social media platforms?\nThis article addresses this question by collecting, categorising, and situating\nan extensive body of research on how application programming interfaces (APIs)\nprovided by social media platforms facilitate the spread of disinformation. We\nfirst examine the landscape of official social media APIs, then perform\nquantitative research on the open-source code repositories GitHub and GitLab to\nunderstand the usage patterns of these APIs. By inspecting the code\nrepositories, we classify developers' usage of the APIs as official and\nunofficial, and further develop a four-stage framework characterising pathways\nfor spreading disinformation on social media platforms. We further highlight\nhow the stages in the framework were activated during the 2016 US Presidential\nElections, before providing policy recommendations for issues relating to\naccess to APIs, algorithmic content, advertisements, and suggest rapid response\nto coordinate campaigns, development of collaborative, and participatory\napproaches as well as government stewardship in the regulation of social media\nplatforms.""}, 'authors': [{'name': 'Lynnette H. X. Ng'}, {'name': 'Araz Taeihagh'}], 'author_detail': {'name': 'Araz Taeihagh'}, 'author': 'Araz Taeihagh', 'arxiv_doi': '10.1002/poi3.268', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1002/poi3.268', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.12865v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12865v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Policy and Internet, 2021', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
3,http://arxiv.org/abs/2109.11781v1,2021-09-24 07:23:59+00:00,2021-09-24 07:23:59+00:00,A Unified Graph-Based Approach to Disinformation Detection using Contextual and Semantic Relations,"[arxiv.Result.Author('Marius Paraschiv'), arxiv.Result.Author('Nikos Salamanos'), arxiv.Result.Author('Costas Iordanou'), arxiv.Result.Author('Nikolaos Laoutaris'), arxiv.Result.Author('Michael Sirivianos')]","As recent events have demonstrated, disinformation spread through social
networks can have dire political, economic and social consequences. Detecting
disinformation must inevitably rely on the structure of the network, on users
particularities and on event occurrence patterns. We present a graph data
structure, which we denote as a meta-graph, that combines underlying users'
relational event information, as well as semantic and topical modeling. We
detail the construction of an example meta-graph using Twitter data covering
the 2016 US election campaign and then compare the detection of disinformation
at cascade level, using well-known graph neural network algorithms, to the same
algorithms applied on the meta-graph nodes. The comparison shows a consistent
3%-4% improvement in accuracy when using the meta-graph, over all considered
algorithms, compared to basic cascade classification, and a further 1% increase
when topic modeling and sentiment analysis are considered. We carry out the
same experiment on two other datasets, HealthRelease and HealthStory, part of
the FakeHealth dataset repository, with consistent results. Finally, we discuss
further advantages of our approach, such as the ability to augment the graph
structure using external data sources, the ease with which multiple meta-graphs
can be combined as well as a comparison of our method to other graph-based
disinformation detection frameworks.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.11781v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.11781v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.11781v1,"{'id': 'http://arxiv.org/abs/2109.11781v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.11781v1', 'updated': '2021-09-24T07:23:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=24, tm_hour=7, tm_min=23, tm_sec=59, tm_wday=4, tm_yday=267, tm_isdst=0), 'published': '2021-09-24T07:23:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=24, tm_hour=7, tm_min=23, tm_sec=59, tm_wday=4, tm_yday=267, tm_isdst=0), 'title': 'A Unified Graph-Based Approach to Disinformation Detection using\n  Contextual and Semantic Relations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Unified Graph-Based Approach to Disinformation Detection using\n  Contextual and Semantic Relations'}, 'summary': ""As recent events have demonstrated, disinformation spread through social\nnetworks can have dire political, economic and social consequences. Detecting\ndisinformation must inevitably rely on the structure of the network, on users\nparticularities and on event occurrence patterns. We present a graph data\nstructure, which we denote as a meta-graph, that combines underlying users'\nrelational event information, as well as semantic and topical modeling. We\ndetail the construction of an example meta-graph using Twitter data covering\nthe 2016 US election campaign and then compare the detection of disinformation\nat cascade level, using well-known graph neural network algorithms, to the same\nalgorithms applied on the meta-graph nodes. The comparison shows a consistent\n3%-4% improvement in accuracy when using the meta-graph, over all considered\nalgorithms, compared to basic cascade classification, and a further 1% increase\nwhen topic modeling and sentiment analysis are considered. We carry out the\nsame experiment on two other datasets, HealthRelease and HealthStory, part of\nthe FakeHealth dataset repository, with consistent results. Finally, we discuss\nfurther advantages of our approach, such as the ability to augment the graph\nstructure using external data sources, the ease with which multiple meta-graphs\ncan be combined as well as a comparison of our method to other graph-based\ndisinformation detection frameworks."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As recent events have demonstrated, disinformation spread through social\nnetworks can have dire political, economic and social consequences. Detecting\ndisinformation must inevitably rely on the structure of the network, on users\nparticularities and on event occurrence patterns. We present a graph data\nstructure, which we denote as a meta-graph, that combines underlying users'\nrelational event information, as well as semantic and topical modeling. We\ndetail the construction of an example meta-graph using Twitter data covering\nthe 2016 US election campaign and then compare the detection of disinformation\nat cascade level, using well-known graph neural network algorithms, to the same\nalgorithms applied on the meta-graph nodes. The comparison shows a consistent\n3%-4% improvement in accuracy when using the meta-graph, over all considered\nalgorithms, compared to basic cascade classification, and a further 1% increase\nwhen topic modeling and sentiment analysis are considered. We carry out the\nsame experiment on two other datasets, HealthRelease and HealthStory, part of\nthe FakeHealth dataset repository, with consistent results. Finally, we discuss\nfurther advantages of our approach, such as the ability to augment the graph\nstructure using external data sources, the ease with which multiple meta-graphs\ncan be combined as well as a comparison of our method to other graph-based\ndisinformation detection frameworks.""}, 'authors': [{'name': 'Marius Paraschiv'}, {'name': 'Nikos Salamanos'}, {'name': 'Costas Iordanou'}, {'name': 'Nikolaos Laoutaris'}, {'name': 'Michael Sirivianos'}], 'author_detail': {'name': 'Michael Sirivianos'}, 'author': 'Michael Sirivianos', 'links': [{'href': 'http://arxiv.org/abs/2109.11781v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.11781v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
4,http://arxiv.org/abs/2109.11024v1,2021-09-22 20:24:20+00:00,2021-09-22 20:24:20+00:00,Social-Media Activity Forecasting with Exogenous Information Signals,"[arxiv.Result.Author('Kin Wai Ng'), arxiv.Result.Author('Sameera Horawalavithana'), arxiv.Result.Author('Adriana Iamnitchi')]","Due to their widespread adoption, social media platforms present an ideal
environment for studying and understanding social behavior, especially on
information spread. Modeling social media activity has numerous practical
implications such as supporting efforts to analyze strategic information
operations, designing intervention techniques to mitigate disinformation, or
delivering critical information during disaster relief operations. In this
paper we propose a modeling technique that forecasts topic-specific daily
volume of social media activities by using both exogenous signals, such as news
or armed conflicts records, and endogenous data from the social media platform
we model. Empirical evaluations with real datasets from two different platforms
and two different contexts each composed of multiple interrelated topics
demonstrate the effectiveness of our solution.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2109.11024v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.11024v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.11024v1,"{'id': 'http://arxiv.org/abs/2109.11024v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.11024v1', 'updated': '2021-09-22T20:24:20Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=20, tm_min=24, tm_sec=20, tm_wday=2, tm_yday=265, tm_isdst=0), 'published': '2021-09-22T20:24:20Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=20, tm_min=24, tm_sec=20, tm_wday=2, tm_yday=265, tm_isdst=0), 'title': 'Social-Media Activity Forecasting with Exogenous Information Signals', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social-Media Activity Forecasting with Exogenous Information Signals'}, 'summary': 'Due to their widespread adoption, social media platforms present an ideal\nenvironment for studying and understanding social behavior, especially on\ninformation spread. Modeling social media activity has numerous practical\nimplications such as supporting efforts to analyze strategic information\noperations, designing intervention techniques to mitigate disinformation, or\ndelivering critical information during disaster relief operations. In this\npaper we propose a modeling technique that forecasts topic-specific daily\nvolume of social media activities by using both exogenous signals, such as news\nor armed conflicts records, and endogenous data from the social media platform\nwe model. Empirical evaluations with real datasets from two different platforms\nand two different contexts each composed of multiple interrelated topics\ndemonstrate the effectiveness of our solution.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Due to their widespread adoption, social media platforms present an ideal\nenvironment for studying and understanding social behavior, especially on\ninformation spread. Modeling social media activity has numerous practical\nimplications such as supporting efforts to analyze strategic information\noperations, designing intervention techniques to mitigate disinformation, or\ndelivering critical information during disaster relief operations. In this\npaper we propose a modeling technique that forecasts topic-specific daily\nvolume of social media activities by using both exogenous signals, such as news\nor armed conflicts records, and endogenous data from the social media platform\nwe model. Empirical evaluations with real datasets from two different platforms\nand two different contexts each composed of multiple interrelated topics\ndemonstrate the effectiveness of our solution.'}, 'authors': [{'name': 'Kin Wai Ng'}, {'name': 'Sameera Horawalavithana'}, {'name': 'Adriana Iamnitchi'}], 'author_detail': {'name': 'Adriana Iamnitchi'}, 'author': 'Adriana Iamnitchi', 'links': [{'href': 'http://arxiv.org/abs/2109.11024v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.11024v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
5,http://arxiv.org/abs/2109.02359v1,2021-09-06 10:59:13+00:00,2021-09-06 10:59:13+00:00,Examining the tech stacks of Czech and Slovak untrustworthy websites,"[arxiv.Result.Author('Jozef Michal Mintal'), arxiv.Result.Author('Anna Macko'), arxiv.Result.Author('Marko Paľa'), arxiv.Result.Author('Františka Pirosková'), arxiv.Result.Author('Pavlo Yakubets'), arxiv.Result.Author('Jaroslav Ušiak'), arxiv.Result.Author('Karol Fabián')]","The burgeoning of misleading or false information spread by untrustworthy
websites has, without doubt, created a dangerous concoction. Thus, it is not a
surprise that the threat posed by untrustworthy websites has emerged as a
central concern on the public agenda in many countries, including Czechia and
Slovakia. However, combating this harmful phenomenon has proven to be
difficult, with approaches primarily focusing on tackling consequences instead
of prevention, as websites are routinely seen as quasi-sovereign organisms.
Websites, however, rely upon a host of service providers, which, in a way, hold
substantial power over them. Notwithstanding the apparent power hold by such
tech stack layers, scholarship on this topic remains largely limited. This
article contributes to this small body of knowledge by providing a
first-of-its-kind systematic mapping of the back-end infrastructural support
that makes up the tech stacks of Czech and Slovak untrustworthy websites. Our
approach is based on collecting and analyzing data on top-level domain
operators, domain name Registrars, email providers, web hosting providers, and
utilized website tracking technologies of 150 Czech and Slovak untrustworthy
websites. Our findings show that the Czech and Slovak untrustworthy website
landscape relies on a vast number of back-end services spread across multiple
countries, but in key tech stack layers is nevertheless still heavily dominated
by locally based companies. Finally, given our findings, we discuss various
possible avenues of utilizing the numeral tech stack layers in combating online
disinformation.",,,10.1007/978-981-16-5792-4_4,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/978-981-16-5792-4_4', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.02359v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.02359v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.02359v1,"{'id': 'http://arxiv.org/abs/2109.02359v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.02359v1', 'updated': '2021-09-06T10:59:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=10, tm_min=59, tm_sec=13, tm_wday=0, tm_yday=249, tm_isdst=0), 'published': '2021-09-06T10:59:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=10, tm_min=59, tm_sec=13, tm_wday=0, tm_yday=249, tm_isdst=0), 'title': 'Examining the tech stacks of Czech and Slovak untrustworthy websites', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Examining the tech stacks of Czech and Slovak untrustworthy websites'}, 'summary': 'The burgeoning of misleading or false information spread by untrustworthy\nwebsites has, without doubt, created a dangerous concoction. Thus, it is not a\nsurprise that the threat posed by untrustworthy websites has emerged as a\ncentral concern on the public agenda in many countries, including Czechia and\nSlovakia. However, combating this harmful phenomenon has proven to be\ndifficult, with approaches primarily focusing on tackling consequences instead\nof prevention, as websites are routinely seen as quasi-sovereign organisms.\nWebsites, however, rely upon a host of service providers, which, in a way, hold\nsubstantial power over them. Notwithstanding the apparent power hold by such\ntech stack layers, scholarship on this topic remains largely limited. This\narticle contributes to this small body of knowledge by providing a\nfirst-of-its-kind systematic mapping of the back-end infrastructural support\nthat makes up the tech stacks of Czech and Slovak untrustworthy websites. Our\napproach is based on collecting and analyzing data on top-level domain\noperators, domain name Registrars, email providers, web hosting providers, and\nutilized website tracking technologies of 150 Czech and Slovak untrustworthy\nwebsites. Our findings show that the Czech and Slovak untrustworthy website\nlandscape relies on a vast number of back-end services spread across multiple\ncountries, but in key tech stack layers is nevertheless still heavily dominated\nby locally based companies. Finally, given our findings, we discuss various\npossible avenues of utilizing the numeral tech stack layers in combating online\ndisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The burgeoning of misleading or false information spread by untrustworthy\nwebsites has, without doubt, created a dangerous concoction. Thus, it is not a\nsurprise that the threat posed by untrustworthy websites has emerged as a\ncentral concern on the public agenda in many countries, including Czechia and\nSlovakia. However, combating this harmful phenomenon has proven to be\ndifficult, with approaches primarily focusing on tackling consequences instead\nof prevention, as websites are routinely seen as quasi-sovereign organisms.\nWebsites, however, rely upon a host of service providers, which, in a way, hold\nsubstantial power over them. Notwithstanding the apparent power hold by such\ntech stack layers, scholarship on this topic remains largely limited. This\narticle contributes to this small body of knowledge by providing a\nfirst-of-its-kind systematic mapping of the back-end infrastructural support\nthat makes up the tech stacks of Czech and Slovak untrustworthy websites. Our\napproach is based on collecting and analyzing data on top-level domain\noperators, domain name Registrars, email providers, web hosting providers, and\nutilized website tracking technologies of 150 Czech and Slovak untrustworthy\nwebsites. Our findings show that the Czech and Slovak untrustworthy website\nlandscape relies on a vast number of back-end services spread across multiple\ncountries, but in key tech stack layers is nevertheless still heavily dominated\nby locally based companies. Finally, given our findings, we discuss various\npossible avenues of utilizing the numeral tech stack layers in combating online\ndisinformation.'}, 'authors': [{'name': 'Jozef Michal Mintal'}, {'name': 'Anna Macko'}, {'name': 'Marko Paľa'}, {'name': 'Františka Pirosková'}, {'name': 'Pavlo Yakubets'}, {'name': 'Jaroslav Ušiak'}, {'name': 'Karol Fabián'}], 'author_detail': {'name': 'Karol Fabián'}, 'author': 'Karol Fabián', 'arxiv_doi': '10.1007/978-981-16-5792-4_4', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-981-16-5792-4_4', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.02359v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.02359v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
6,http://arxiv.org/abs/2109.01727v4,2021-10-04 20:14:17+00:00,2021-09-03 20:54:34+00:00,Increasing Adversarial Uncertainty to Scale Private Similarity Testing,"[arxiv.Result.Author('Yiqing Hua'), arxiv.Result.Author('Armin Namavari'), arxiv.Result.Author('Kaishuo Cheng'), arxiv.Result.Author('Mor Naaman'), arxiv.Result.Author('Thomas Ristenpart')]","Social media and other platforms rely on automated detection of abusive
content to help combat disinformation, harassment, and abuse. One common
approach is to check user content for similarity against a server-side database
of problematic items. However, this method fundamentally endangers user
privacy. Instead, we target client-side detection, notifying only the users
when such matches occur to warn them against abusive content. Our solution is
based on privacy-preserving similarity testing. Existing approaches rely on
expensive cryptographic protocols that do not scale well to large databases and
may sacrifice the correctness of the matching. To contend with this challenge,
we propose and formalize the concept of similarity-based bucketization~(SBB).
With SBB, a client reveals a small amount of information to a database-holding
server so that it can generate a bucket of potentially similar items. The
bucket is small enough for efficient application of privacy-preserving
protocols for similarity. To analyze the privacy risk of the revealed
information, we introduce a framework for measuring an adversary's confidence
in inferring a predicate about the client input correctly. We develop a
practical SBB protocol for image content, and evaluate its client privacy
guarantee with real-world social media data. We then combine SBB with various
similarity protocols, showing that the combination with SBB provides a speedup
of at least 29x on large-scale databases compared to that without, while
retaining correctness of over 95%.",,,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.01727v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.01727v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.01727v4,"{'id': 'http://arxiv.org/abs/2109.01727v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.01727v4', 'updated': '2021-10-04T20:14:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=4, tm_hour=20, tm_min=14, tm_sec=17, tm_wday=0, tm_yday=277, tm_isdst=0), 'published': '2021-09-03T20:54:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=3, tm_hour=20, tm_min=54, tm_sec=34, tm_wday=4, tm_yday=246, tm_isdst=0), 'title': 'Increasing Adversarial Uncertainty to Scale Private Similarity Testing', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Increasing Adversarial Uncertainty to Scale Private Similarity Testing'}, 'summary': ""Social media and other platforms rely on automated detection of abusive\ncontent to help combat disinformation, harassment, and abuse. One common\napproach is to check user content for similarity against a server-side database\nof problematic items. However, this method fundamentally endangers user\nprivacy. Instead, we target client-side detection, notifying only the users\nwhen such matches occur to warn them against abusive content. Our solution is\nbased on privacy-preserving similarity testing. Existing approaches rely on\nexpensive cryptographic protocols that do not scale well to large databases and\nmay sacrifice the correctness of the matching. To contend with this challenge,\nwe propose and formalize the concept of similarity-based bucketization~(SBB).\nWith SBB, a client reveals a small amount of information to a database-holding\nserver so that it can generate a bucket of potentially similar items. The\nbucket is small enough for efficient application of privacy-preserving\nprotocols for similarity. To analyze the privacy risk of the revealed\ninformation, we introduce a framework for measuring an adversary's confidence\nin inferring a predicate about the client input correctly. We develop a\npractical SBB protocol for image content, and evaluate its client privacy\nguarantee with real-world social media data. We then combine SBB with various\nsimilarity protocols, showing that the combination with SBB provides a speedup\nof at least 29x on large-scale databases compared to that without, while\nretaining correctness of over 95%."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media and other platforms rely on automated detection of abusive\ncontent to help combat disinformation, harassment, and abuse. One common\napproach is to check user content for similarity against a server-side database\nof problematic items. However, this method fundamentally endangers user\nprivacy. Instead, we target client-side detection, notifying only the users\nwhen such matches occur to warn them against abusive content. Our solution is\nbased on privacy-preserving similarity testing. Existing approaches rely on\nexpensive cryptographic protocols that do not scale well to large databases and\nmay sacrifice the correctness of the matching. To contend with this challenge,\nwe propose and formalize the concept of similarity-based bucketization~(SBB).\nWith SBB, a client reveals a small amount of information to a database-holding\nserver so that it can generate a bucket of potentially similar items. The\nbucket is small enough for efficient application of privacy-preserving\nprotocols for similarity. To analyze the privacy risk of the revealed\ninformation, we introduce a framework for measuring an adversary's confidence\nin inferring a predicate about the client input correctly. We develop a\npractical SBB protocol for image content, and evaluate its client privacy\nguarantee with real-world social media data. We then combine SBB with various\nsimilarity protocols, showing that the combination with SBB provides a speedup\nof at least 29x on large-scale databases compared to that without, while\nretaining correctness of over 95%.""}, 'authors': [{'name': 'Yiqing Hua'}, {'name': 'Armin Namavari'}, {'name': 'Kaishuo Cheng'}, {'name': 'Mor Naaman'}, {'name': 'Thomas Ristenpart'}], 'author_detail': {'name': 'Thomas Ristenpart'}, 'author': 'Thomas Ristenpart', 'links': [{'href': 'http://arxiv.org/abs/2109.01727v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.01727v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
7,http://arxiv.org/abs/2109.00945v1,2021-09-02 13:44:59+00:00,2021-09-02 13:44:59+00:00,Coordinating Narratives and the Capitol Riots on Parler,"[arxiv.Result.Author('Lynnette Hui Xian Ng'), arxiv.Result.Author('Iain Cruickshank'), arxiv.Result.Author('Kathleen M. Carley')]","Coordinated disinformation campaigns are used to influence social media
users, potentially leading to offline violence. In this study, we introduce a
general methodology to uncover coordinated messaging through analysis of user
parleys on Parler. The proposed method constructs a user-to-user coordination
network graph induced by a user-to-text graph and a text-to-text similarity
graph. The text-to-text graph is constructed based on the textual similarity of
Parler posts. We study three influential groups of users in the 6 January 2020
Capitol riots and detect networks of coordinated user clusters that are all
posting similar textual content in support of different disinformation
narratives related to the U.S. 2020 elections.",,SBP-Brims Disinformation Challenge 2021,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2109.00945v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.00945v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.00945v1,"{'id': 'http://arxiv.org/abs/2109.00945v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.00945v1', 'updated': '2021-09-02T13:44:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=2, tm_hour=13, tm_min=44, tm_sec=59, tm_wday=3, tm_yday=245, tm_isdst=0), 'published': '2021-09-02T13:44:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=2, tm_hour=13, tm_min=44, tm_sec=59, tm_wday=3, tm_yday=245, tm_isdst=0), 'title': 'Coordinating Narratives and the Capitol Riots on Parler', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Coordinating Narratives and the Capitol Riots on Parler'}, 'summary': 'Coordinated disinformation campaigns are used to influence social media\nusers, potentially leading to offline violence. In this study, we introduce a\ngeneral methodology to uncover coordinated messaging through analysis of user\nparleys on Parler. The proposed method constructs a user-to-user coordination\nnetwork graph induced by a user-to-text graph and a text-to-text similarity\ngraph. The text-to-text graph is constructed based on the textual similarity of\nParler posts. We study three influential groups of users in the 6 January 2020\nCapitol riots and detect networks of coordinated user clusters that are all\nposting similar textual content in support of different disinformation\nnarratives related to the U.S. 2020 elections.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Coordinated disinformation campaigns are used to influence social media\nusers, potentially leading to offline violence. In this study, we introduce a\ngeneral methodology to uncover coordinated messaging through analysis of user\nparleys on Parler. The proposed method constructs a user-to-user coordination\nnetwork graph induced by a user-to-text graph and a text-to-text similarity\ngraph. The text-to-text graph is constructed based on the textual similarity of\nParler posts. We study three influential groups of users in the 6 January 2020\nCapitol riots and detect networks of coordinated user clusters that are all\nposting similar textual content in support of different disinformation\nnarratives related to the U.S. 2020 elections.'}, 'authors': [{'name': 'Lynnette Hui Xian Ng'}, {'name': 'Iain Cruickshank'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_journal_ref': 'SBP-Brims Disinformation Challenge 2021', 'links': [{'href': 'http://arxiv.org/abs/2109.00945v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.00945v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
8,http://arxiv.org/abs/2109.00835v1,2021-09-02 10:45:07+00:00,2021-09-02 10:45:07+00:00,WikiCheck: An end-to-end open source Automatic Fact-Checking API based on Wikipedia,"[arxiv.Result.Author('Mykola Trokhymovych'), arxiv.Result.Author('Diego Saez-Trumper')]","With the growth of fake news and disinformation, the NLP community has been
working to assist humans in fact-checking. However, most academic research has
focused on model accuracy without paying attention to resource efficiency,
which is crucial in real-life scenarios. In this work, we review the
State-of-the-Art datasets and solutions for Automatic Fact-checking and test
their applicability in production environments. We discover overfitting issues
in those models, and we propose a data filtering method that improves the
model's performance and generalization. Then, we design an unsupervised
fine-tuning of the Masked Language models to improve its accuracy working with
Wikipedia. We also propose a novel query enhancing method to improve evidence
discovery using the Wikipedia Search API. Finally, we present a new
fact-checking system, the \textit{WikiCheck} API that automatically performs a
facts validation process based on the Wikipedia knowledge base. It is
comparable to SOTA solutions in terms of accuracy and can be used on low-memory
CPU instances.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.00835v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.00835v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.00835v1,"{'id': 'http://arxiv.org/abs/2109.00835v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.00835v1', 'updated': '2021-09-02T10:45:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=2, tm_hour=10, tm_min=45, tm_sec=7, tm_wday=3, tm_yday=245, tm_isdst=0), 'published': '2021-09-02T10:45:07Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=2, tm_hour=10, tm_min=45, tm_sec=7, tm_wday=3, tm_yday=245, tm_isdst=0), 'title': 'WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia'}, 'summary': ""With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.""}, 'authors': [{'name': 'Mykola Trokhymovych'}, {'name': 'Diego Saez-Trumper'}], 'author_detail': {'name': 'Diego Saez-Trumper'}, 'author': 'Diego Saez-Trumper', 'links': [{'href': 'http://arxiv.org/abs/2109.00835v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.00835v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
9,http://arxiv.org/abs/2108.13892v1,2021-08-31 14:50:16+00:00,2021-08-31 14:50:16+00:00,"Like Article, Like Audience: Enforcing Multimodal Correlations for Disinformation Detection","[arxiv.Result.Author('Liesbeth Allein'), arxiv.Result.Author('Marie-Francine Moens'), arxiv.Result.Author('Domenico Perrotta')]","User-generated content (e.g., tweets and profile descriptions) and shared
content between users (e.g., news articles) reflect a user's online identity.
This paper investigates whether correlations between user-generated and
user-shared content can be leveraged for detecting disinformation in online
news articles. We develop a multimodal learning algorithm for disinformation
detection. The latent representations of news articles and user-generated
content allow that during training the model is guided by the profile of users
who prefer content similar to the news article that is evaluated, and this
effect is reinforced if that content is shared among different users. By only
leveraging user information during model optimization, the model does not rely
on user profiling when predicting an article's veracity. The algorithm is
successfully applied to three widely used neural classifiers, and results are
obtained on different datasets. Visualization techniques show that the proposed
model learns feature representations of unseen news articles that better
discriminate between fake and real news texts.",,,,cs.CL,"['cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2108.13892v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.13892v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.13892v1,"{'id': 'http://arxiv.org/abs/2108.13892v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.13892v1', 'updated': '2021-08-31T14:50:16Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=31, tm_hour=14, tm_min=50, tm_sec=16, tm_wday=1, tm_yday=243, tm_isdst=0), 'published': '2021-08-31T14:50:16Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=31, tm_hour=14, tm_min=50, tm_sec=16, tm_wday=1, tm_yday=243, tm_isdst=0), 'title': 'Like Article, Like Audience: Enforcing Multimodal Correlations for\n  Disinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Like Article, Like Audience: Enforcing Multimodal Correlations for\n  Disinformation Detection'}, 'summary': ""User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts.""}, 'authors': [{'name': 'Liesbeth Allein'}, {'name': 'Marie-Francine Moens'}, {'name': 'Domenico Perrotta'}], 'author_detail': {'name': 'Domenico Perrotta'}, 'author': 'Domenico Perrotta', 'links': [{'href': 'http://arxiv.org/abs/2108.13892v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.13892v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
10,http://arxiv.org/abs/2108.12752v1,2021-08-29 04:48:28+00:00,2021-08-29 04:48:28+00:00,TAR on Social Media: A Framework for Online Content Moderation,"[arxiv.Result.Author('Eugene Yang'), arxiv.Result.Author('David D. Lewis'), arxiv.Result.Author('Ophir Frieder')]","Content moderation (removing or limiting the distribution of posts based on
their contents) is one tool social networks use to fight problems such as
harassment and disinformation. Manually screening all content is usually
impractical given the scale of social media data, and the need for nuanced
human interpretations makes fully automated approaches infeasible. We consider
content moderation from the perspective of technology-assisted review (TAR): a
human-in-the-loop active learning approach developed for high recall retrieval
problems in civil litigation and other fields. We show how TAR workflows, and a
TAR cost model, can be adapted to the content moderation problem. We then
demonstrate on two publicly available content moderation data sets that a TAR
workflow can reduce moderation costs by 20% to 55% across a variety of
conditions.","9 pages, 2 figures, accepted at DESIRES 2021",,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.12752v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.12752v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.12752v1,"{'id': 'http://arxiv.org/abs/2108.12752v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.12752v1', 'updated': '2021-08-29T04:48:28Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=29, tm_hour=4, tm_min=48, tm_sec=28, tm_wday=6, tm_yday=241, tm_isdst=0), 'published': '2021-08-29T04:48:28Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=29, tm_hour=4, tm_min=48, tm_sec=28, tm_wday=6, tm_yday=241, tm_isdst=0), 'title': 'TAR on Social Media: A Framework for Online Content Moderation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TAR on Social Media: A Framework for Online Content Moderation'}, 'summary': 'Content moderation (removing or limiting the distribution of posts based on\ntheir contents) is one tool social networks use to fight problems such as\nharassment and disinformation. Manually screening all content is usually\nimpractical given the scale of social media data, and the need for nuanced\nhuman interpretations makes fully automated approaches infeasible. We consider\ncontent moderation from the perspective of technology-assisted review (TAR): a\nhuman-in-the-loop active learning approach developed for high recall retrieval\nproblems in civil litigation and other fields. We show how TAR workflows, and a\nTAR cost model, can be adapted to the content moderation problem. We then\ndemonstrate on two publicly available content moderation data sets that a TAR\nworkflow can reduce moderation costs by 20% to 55% across a variety of\nconditions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Content moderation (removing or limiting the distribution of posts based on\ntheir contents) is one tool social networks use to fight problems such as\nharassment and disinformation. Manually screening all content is usually\nimpractical given the scale of social media data, and the need for nuanced\nhuman interpretations makes fully automated approaches infeasible. We consider\ncontent moderation from the perspective of technology-assisted review (TAR): a\nhuman-in-the-loop active learning approach developed for high recall retrieval\nproblems in civil litigation and other fields. We show how TAR workflows, and a\nTAR cost model, can be adapted to the content moderation problem. We then\ndemonstrate on two publicly available content moderation data sets that a TAR\nworkflow can reduce moderation costs by 20% to 55% across a variety of\nconditions.'}, 'authors': [{'name': 'Eugene Yang'}, {'name': 'David D. Lewis'}, {'name': 'Ophir Frieder'}], 'author_detail': {'name': 'Ophir Frieder'}, 'author': 'Ophir Frieder', 'arxiv_comment': '9 pages, 2 figures, accepted at DESIRES 2021', 'links': [{'href': 'http://arxiv.org/abs/2108.12752v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.12752v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
11,http://arxiv.org/abs/2108.11669v1,2021-08-26 09:28:50+00:00,2021-08-26 09:28:50+00:00,Technological Approaches to Detecting Online Disinformation and Manipulation,"[arxiv.Result.Author('Aleš Horák'), arxiv.Result.Author('Vít Baisa'), arxiv.Result.Author('Ondřej Herman')]","The move of propaganda and disinformation to the online environment is
possible thanks to the fact that within the last decade, digital information
channels radically increased in popularity as a news source. The main advantage
of such media lies in the speed of information creation and dissemination.
This, on the other hand, inevitably adds pressure, accelerating editorial work,
fact-checking, and the scrutiny of source credibility. In this chapter, an
overview of computer-supported approaches to detecting disinformation and
manipulative techniques based on several criteria is presented. We concentrate
on the technical aspects of automatic methods which support fact-checking,
topic identification, text style analysis, or message filtering on social media
channels. Most of the techniques employ artificial intelligence and machine
learning with feature extraction combining available information resources. The
following text firstly specifies the tasks related to computer detection of
manipulation and disinformation spreading. The second section presents concrete
methods of solving the tasks of the analysis, and the third sections enlists
current verification and benchmarking datasets published and used in this area
for evaluation and comparison.","This is an author preprint of the 5th chapter in the book of
  ""Challenging Online Propaganda and Disinformation in the 21st Century""
  published by Palgrave Macmillan at
  https://www.palgrave.com/gp/book/9783030586232",,10.1007/978-3-030-58624-9,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-58624-9', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.11669v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.11669v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.11669v1,"{'id': 'http://arxiv.org/abs/2108.11669v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.11669v1', 'updated': '2021-08-26T09:28:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=26, tm_hour=9, tm_min=28, tm_sec=50, tm_wday=3, tm_yday=238, tm_isdst=0), 'published': '2021-08-26T09:28:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=26, tm_hour=9, tm_min=28, tm_sec=50, tm_wday=3, tm_yday=238, tm_isdst=0), 'title': 'Technological Approaches to Detecting Online Disinformation and\n  Manipulation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Technological Approaches to Detecting Online Disinformation and\n  Manipulation'}, 'summary': 'The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.'}, 'authors': [{'name': 'Aleš Horák'}, {'name': 'Vít Baisa'}, {'name': 'Ondřej Herman'}], 'author_detail': {'name': 'Ondřej Herman'}, 'author': 'Ondřej Herman', 'arxiv_doi': '10.1007/978-3-030-58624-9', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-58624-9', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.11669v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.11669v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'This is an author preprint of the 5th chapter in the book of\n  ""Challenging Online Propaganda and Disinformation in the 21st Century""\n  published by Palgrave Macmillan at\n  https://www.palgrave.com/gp/book/9783030586232', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
12,http://arxiv.org/abs/2108.10942v1,2021-08-24 20:27:38+00:00,2021-08-24 20:27:38+00:00,Profiling Fake News Spreaders on Social Media through Psychological and Motivational Factors,"[arxiv.Result.Author('Mansooreh Karami'), arxiv.Result.Author('Tahora H. Nazer'), arxiv.Result.Author('Huan Liu')]","The rise of fake news in the past decade has brought with it a host of
consequences, from swaying opinions on elections to generating uncertainty
during a pandemic. A majority of methods developed to combat disinformation
either focus on fake news content or malicious actors who generate it. However,
the virality of fake news is largely dependent upon the users who propagate it.
A deeper understanding of these users can contribute to the development of a
framework for identifying users who are likely to spread fake news. In this
work, we study the characteristics and motivational factors of fake news
spreaders on social media with input from psychological theories and behavioral
studies. We then perform a series of experiments to determine if fake news
spreaders can be found to exhibit different characteristics than other users.
Further, we investigate our findings by testing whether the characteristics we
observe amongst fake news spreaders in our experiments can be applied to the
detection of fake news spreaders in a real social media environment.",,,10.1145/3465336.3475097,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3465336.3475097', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.10942v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10942v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10942v1,"{'id': 'http://arxiv.org/abs/2108.10942v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10942v1', 'updated': '2021-08-24T20:27:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=20, tm_min=27, tm_sec=38, tm_wday=1, tm_yday=236, tm_isdst=0), 'published': '2021-08-24T20:27:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=20, tm_min=27, tm_sec=38, tm_wday=1, tm_yday=236, tm_isdst=0), 'title': 'Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors'}, 'summary': 'The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.'}, 'authors': [{'name': 'Mansooreh Karami'}, {'name': 'Tahora H. Nazer'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_doi': '10.1145/3465336.3475097', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3465336.3475097', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.10942v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10942v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
13,http://arxiv.org/abs/2108.10274v1,2021-08-23 16:22:50+00:00,2021-08-23 16:22:50+00:00,Towards Explainable Fact Checking,[arxiv.Result.Author('Isabelle Augenstein')],"The past decade has seen a substantial rise in the amount of mis- and
disinformation online, from targeted disinformation campaigns to influence
politics, to the unintentional spreading of misinformation about public health.
This development has spurred research in the area of automatic fact checking,
from approaches to detect check-worthy claims and determining the stance of
tweets towards claims, to methods to determine the veracity of claims given
evidence documents. These automatic methods are often content-based, using
natural language processing methods, which in turn utilise deep neural networks
to learn higher-order features from text in order to make predictions. As deep
neural networks are black-box models, their inner workings cannot be easily
explained. At the same time, it is desirable to explain how they arrive at
certain decisions, especially if they are to be used for decision making. While
this has been known for some time, the issues this raises have been exacerbated
by models increasing in size, and by EU legislation requiring models to be used
for decision making to provide explanations, and, very recently, by legislation
requiring online platforms operating in the EU to provide transparent reporting
on their services. Despite this, current solutions for explainability are still
lacking in the area of fact checking. This thesis presents my research on
automatic fact checking, including claim check-worthiness detection, stance
detection and veracity prediction. Its contributions go beyond fact checking,
with the thesis proposing more general machine learning solutions for natural
language processing in the area of learning with limited labelled data.
Finally, the thesis presents some first solutions for explainable fact
checking.","Thesis presented to the University of Copenhagen Faculty of Science
  in partial fulfillment of the requirements for the degree of Doctor
  Scientiarum (Dr. Scient.)",,,cs.CL,"['cs.CL', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2108.10274v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10274v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10274v1,"{'id': 'http://arxiv.org/abs/2108.10274v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10274v1', 'updated': '2021-08-23T16:22:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=23, tm_hour=16, tm_min=22, tm_sec=50, tm_wday=0, tm_yday=235, tm_isdst=0), 'published': '2021-08-23T16:22:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=23, tm_hour=16, tm_min=22, tm_sec=50, tm_wday=0, tm_yday=235, tm_isdst=0), 'title': 'Towards Explainable Fact Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Explainable Fact Checking'}, 'summary': 'The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.'}, 'authors': [{'name': 'Isabelle Augenstein'}], 'author_detail': {'name': 'Isabelle Augenstein'}, 'author': 'Isabelle Augenstein', 'arxiv_comment': 'Thesis presented to the University of Copenhagen Faculty of Science\n  in partial fulfillment of the requirements for the degree of Doctor\n  Scientiarum (Dr. Scient.)', 'links': [{'href': 'http://arxiv.org/abs/2108.10274v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10274v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
14,http://arxiv.org/abs/2108.05150v1,2021-08-11 10:56:10+00:00,2021-08-11 10:56:10+00:00,Exploring the Links between Personality Traits and Suscep;bility to Disinformation,"[arxiv.Result.Author('Dipto Barman'), arxiv.Result.Author('Owen Conlan')]","The growth of online Digital/social media has allowed a variety of ideas and
opinions to coexist. Social Media has appealed users due to the ease of fast
dissemination of information at low cost and easy access. However, due to the
growth in affordance of Digital platforms, users have become prone to consume
disinformation, misinformation, propaganda, and conspiracy theories. In this
paper, we wish to explore the links between the personality traits given by the
Big Five Inventory and their susceptibility to disinformation. More
speciDically, this study is attributed to capture the short- term as well as
the long-term effects of disinformation and its effects on the Dive personality
traits. Further, we expect to observe that different personalities traits have
different shifts in opinion and different increase or decrease of uncertainty
on an issue after consuming the disinformation. Based on the Dindings of this
study, we would like to propose a personalized narrative-based change in
behavior for different personality traits.","4 pages, 1 figure, ACM conference",,10.1145/3465336.3475121,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3465336.3475121', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.05150v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.05150v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.05150v1,"{'id': 'http://arxiv.org/abs/2108.05150v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.05150v1', 'updated': '2021-08-11T10:56:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=10, tm_min=56, tm_sec=10, tm_wday=2, tm_yday=223, tm_isdst=0), 'published': '2021-08-11T10:56:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=10, tm_min=56, tm_sec=10, tm_wday=2, tm_yday=223, tm_isdst=0), 'title': 'Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation'}, 'summary': 'The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.'}, 'authors': [{'name': 'Dipto Barman'}, {'name': 'Owen Conlan'}], 'author_detail': {'name': 'Owen Conlan'}, 'author': 'Owen Conlan', 'arxiv_doi': '10.1145/3465336.3475121', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3465336.3475121', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.05150v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.05150v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '4 pages, 1 figure, ACM conference', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
15,http://arxiv.org/abs/2108.03929v1,2021-08-09 10:47:14+00:00,2021-08-09 10:47:14+00:00,The State of AI Ethics Report (Volume 5),"[arxiv.Result.Author('Abhishek Gupta'), arxiv.Result.Author('Connor Wright'), arxiv.Result.Author('Marianna Bergamaschi Ganapini'), arxiv.Result.Author('Masa Sweidan'), arxiv.Result.Author('Renjie Butalid')]","This report from the Montreal AI Ethics Institute covers the most salient
progress in research and reporting over the second quarter of 2021 in the field
of AI ethics with a special emphasis on ""Environment and AI"", ""Creativity and
AI"", and ""Geopolitics and AI."" The report also features an exclusive piece
titled ""Critical Race Quantum Computer"" that applies ideas from quantum physics
to explain the complexities of human characteristics and how they can and
should shape our interactions with each other. The report also features special
contributions on the subject of pedagogy in AI ethics, sociology and AI ethics,
and organizational challenges to implementing AI ethics in practice. Given
MAIEI's mission to highlight scholars from around the world working on AI
ethics issues, the report also features two spotlights sharing the work of
scholars operating in Singapore and Mexico helping to shape policy measures as
they relate to the responsible use of technology. The report also has an
extensive section covering the gamut of issues when it comes to the societal
impacts of AI covering areas of bias, privacy, transparency, accountability,
fairness, interpretability, disinformation, policymaking, law, regulations, and
moral philosophy.",201 pages,,,cs.CY,"['cs.CY', 'cs.AI', 'K.4; I.2; A.1']","[arxiv.Result.Link('http://arxiv.org/abs/2108.03929v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.03929v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.03929v1,"{'id': 'http://arxiv.org/abs/2108.03929v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.03929v1', 'updated': '2021-08-09T10:47:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=9, tm_hour=10, tm_min=47, tm_sec=14, tm_wday=0, tm_yday=221, tm_isdst=0), 'published': '2021-08-09T10:47:14Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=9, tm_hour=10, tm_min=47, tm_sec=14, tm_wday=0, tm_yday=221, tm_isdst=0), 'title': 'The State of AI Ethics Report (Volume 5)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The State of AI Ethics Report (Volume 5)'}, 'summary': 'This report from the Montreal AI Ethics Institute covers the most salient\nprogress in research and reporting over the second quarter of 2021 in the field\nof AI ethics with a special emphasis on ""Environment and AI"", ""Creativity and\nAI"", and ""Geopolitics and AI."" The report also features an exclusive piece\ntitled ""Critical Race Quantum Computer"" that applies ideas from quantum physics\nto explain the complexities of human characteristics and how they can and\nshould shape our interactions with each other. The report also features special\ncontributions on the subject of pedagogy in AI ethics, sociology and AI ethics,\nand organizational challenges to implementing AI ethics in practice. Given\nMAIEI\'s mission to highlight scholars from around the world working on AI\nethics issues, the report also features two spotlights sharing the work of\nscholars operating in Singapore and Mexico helping to shape policy measures as\nthey relate to the responsible use of technology. The report also has an\nextensive section covering the gamut of issues when it comes to the societal\nimpacts of AI covering areas of bias, privacy, transparency, accountability,\nfairness, interpretability, disinformation, policymaking, law, regulations, and\nmoral philosophy.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This report from the Montreal AI Ethics Institute covers the most salient\nprogress in research and reporting over the second quarter of 2021 in the field\nof AI ethics with a special emphasis on ""Environment and AI"", ""Creativity and\nAI"", and ""Geopolitics and AI."" The report also features an exclusive piece\ntitled ""Critical Race Quantum Computer"" that applies ideas from quantum physics\nto explain the complexities of human characteristics and how they can and\nshould shape our interactions with each other. The report also features special\ncontributions on the subject of pedagogy in AI ethics, sociology and AI ethics,\nand organizational challenges to implementing AI ethics in practice. Given\nMAIEI\'s mission to highlight scholars from around the world working on AI\nethics issues, the report also features two spotlights sharing the work of\nscholars operating in Singapore and Mexico helping to shape policy measures as\nthey relate to the responsible use of technology. The report also has an\nextensive section covering the gamut of issues when it comes to the societal\nimpacts of AI covering areas of bias, privacy, transparency, accountability,\nfairness, interpretability, disinformation, policymaking, law, regulations, and\nmoral philosophy.'}, 'authors': [{'name': 'Abhishek Gupta'}, {'name': 'Connor Wright'}, {'name': 'Marianna Bergamaschi Ganapini'}, {'name': 'Masa Sweidan'}, {'name': 'Renjie Butalid'}], 'author_detail': {'name': 'Renjie Butalid'}, 'arxiv_affiliation': 'Montreal AI Ethics Institute', 'author': 'Renjie Butalid', 'arxiv_comment': '201 pages', 'links': [{'href': 'http://arxiv.org/abs/2108.03929v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.03929v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'K.4; I.2; A.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
16,http://arxiv.org/abs/2108.03067v1,2021-08-06 11:39:05+00:00,2021-08-06 11:39:05+00:00,Deriving Disinformation Insights from Geolocalized Twitter Callouts,"[arxiv.Result.Author('David Tuxworth'), arxiv.Result.Author('Dimosthenis Antypas'), arxiv.Result.Author('Luis Espinosa-Anke'), arxiv.Result.Author('Jose Camacho-Collados'), arxiv.Result.Author('Alun Preece'), arxiv.Result.Author('David Rogers')]","This paper demonstrates a two-stage method for deriving insights from social
media data relating to disinformation by applying a combination of geospatial
classification and embedding-based language modelling across multiple
languages. In particular, the analysis in centered on Twitter and
disinformation for three European languages: English, French and Spanish.
Firstly, Twitter data is classified into European and non-European sets using
BERT. Secondly, Word2vec is applied to the classified texts resulting in
Eurocentric, non-Eurocentric and global representations of the data for the
three target languages. This comparative analysis demonstrates not only the
efficacy of the classification method but also highlights geographic, temporal
and linguistic differences in the disinformation-related media. Thus, the
contributions of the work are threefold: (i) a novel language-independent
transformer-based geolocation method; (ii) an analytical approach that exploits
lexical specificity and word embeddings to interrogate user-generated content;
and (iii) a dataset of 36 million disinformation related tweets in English,
French and Spanish.","Accepted for presentation at KDD 2021 - Workshop On Deriving Insights
  From User-Generated Text",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2108.03067v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.03067v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.03067v1,"{'id': 'http://arxiv.org/abs/2108.03067v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.03067v1', 'updated': '2021-08-06T11:39:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=6, tm_hour=11, tm_min=39, tm_sec=5, tm_wday=4, tm_yday=218, tm_isdst=0), 'published': '2021-08-06T11:39:05Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=6, tm_hour=11, tm_min=39, tm_sec=5, tm_wday=4, tm_yday=218, tm_isdst=0), 'title': 'Deriving Disinformation Insights from Geolocalized Twitter Callouts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deriving Disinformation Insights from Geolocalized Twitter Callouts'}, 'summary': 'This paper demonstrates a two-stage method for deriving insights from social\nmedia data relating to disinformation by applying a combination of geospatial\nclassification and embedding-based language modelling across multiple\nlanguages. In particular, the analysis in centered on Twitter and\ndisinformation for three European languages: English, French and Spanish.\nFirstly, Twitter data is classified into European and non-European sets using\nBERT. Secondly, Word2vec is applied to the classified texts resulting in\nEurocentric, non-Eurocentric and global representations of the data for the\nthree target languages. This comparative analysis demonstrates not only the\nefficacy of the classification method but also highlights geographic, temporal\nand linguistic differences in the disinformation-related media. Thus, the\ncontributions of the work are threefold: (i) a novel language-independent\ntransformer-based geolocation method; (ii) an analytical approach that exploits\nlexical specificity and word embeddings to interrogate user-generated content;\nand (iii) a dataset of 36 million disinformation related tweets in English,\nFrench and Spanish.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper demonstrates a two-stage method for deriving insights from social\nmedia data relating to disinformation by applying a combination of geospatial\nclassification and embedding-based language modelling across multiple\nlanguages. In particular, the analysis in centered on Twitter and\ndisinformation for three European languages: English, French and Spanish.\nFirstly, Twitter data is classified into European and non-European sets using\nBERT. Secondly, Word2vec is applied to the classified texts resulting in\nEurocentric, non-Eurocentric and global representations of the data for the\nthree target languages. This comparative analysis demonstrates not only the\nefficacy of the classification method but also highlights geographic, temporal\nand linguistic differences in the disinformation-related media. Thus, the\ncontributions of the work are threefold: (i) a novel language-independent\ntransformer-based geolocation method; (ii) an analytical approach that exploits\nlexical specificity and word embeddings to interrogate user-generated content;\nand (iii) a dataset of 36 million disinformation related tweets in English,\nFrench and Spanish.'}, 'authors': [{'name': 'David Tuxworth'}, {'name': 'Dimosthenis Antypas'}, {'name': 'Luis Espinosa-Anke'}, {'name': 'Jose Camacho-Collados'}, {'name': 'Alun Preece'}, {'name': 'David Rogers'}], 'author_detail': {'name': 'David Rogers'}, 'author': 'David Rogers', 'arxiv_comment': 'Accepted for presentation at KDD 2021 - Workshop On Deriving Insights\n  From User-Generated Text', 'links': [{'href': 'http://arxiv.org/abs/2108.03067v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.03067v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
17,http://arxiv.org/abs/2108.02941v2,2021-08-09 17:23:05+00:00,2021-08-06 04:54:03+00:00,Is it Fake? News Disinformation Detection on South African News Websites,"[arxiv.Result.Author('Harm de Wet'), arxiv.Result.Author('Vukosi Marivate')]","Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.","6 pages, Accepted and to be published in AFRICON 2021",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2108.02941v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.02941v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.02941v2,"{'id': 'http://arxiv.org/abs/2108.02941v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.02941v2', 'updated': '2021-08-09T17:23:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=9, tm_hour=17, tm_min=23, tm_sec=5, tm_wday=0, tm_yday=221, tm_isdst=0), 'published': '2021-08-06T04:54:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=6, tm_hour=4, tm_min=54, tm_sec=3, tm_wday=4, tm_yday=218, tm_isdst=0), 'title': 'Is it Fake? News Disinformation Detection on South African News Websites', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Is it Fake? News Disinformation Detection on South African News Websites'}, 'summary': ""Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning.""}, 'authors': [{'name': 'Harm de Wet'}, {'name': 'Vukosi Marivate'}], 'author_detail': {'name': 'Vukosi Marivate'}, 'author': 'Vukosi Marivate', 'arxiv_comment': '6 pages, Accepted and to be published in AFRICON 2021', 'links': [{'href': 'http://arxiv.org/abs/2108.02941v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.02941v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
18,http://arxiv.org/abs/2107.12073v1,2021-07-26 09:51:54+00:00,2021-07-26 09:51:54+00:00,Uncovering the structure of the French media ecosystem,"[arxiv.Result.Author('Jean-Philippe Cointet'), arxiv.Result.Author('Dominique Cardon'), arxiv.Result.Author('Andreï Mogoutov'), arxiv.Result.Author('Benjamin Ooghe-Tabanou'), arxiv.Result.Author('Guillaume Plique'), arxiv.Result.Author('Pedro Morales')]","This study provides a large-scale mapping of the French media space using
digital methods to estimate political polarization and to study information
circuits. We collect data about the production and circulation of online news
stories in France over the course of one year, adopting a multi-layer
perspective on the media ecosystem. We source our data from websites, Twitter
and Facebook. We also identify a certain number of important structural
features. A stochastic block model of the hyperlinks structure shows the
systematic rejection of counter-informational press in a separate cluster which
hardly receives any attention from the mainstream media. Counter-informational
sub-spaces are also peripheral on the consumption side. We measure their
respective audiences on Twitter and Facebook and do not observe a large
discrepancy between both social networks, with counter-information space, far
right and far left media gathering limited audiences. Finally, we also measure
the ideological distribution of news stories using Twitter data, which also
suggests that the French media landscape is quite balanced. We therefore
conclude that the French media ecosystem does not suffer from the same level of
polarization as the US media ecosystem. The comparison with the American
situation also allows us to consolidate a result from studies on
disinformation: the polarization of the journalistic space and the circulation
of fake news are phenomena that only become more widespread when dominant and
influential actors in the political or journalistic space spread topics and
dubious content originally circulating in the fringe of the information space.","IC2S2, Jul 2021, Zurich, Switzerland",,,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2107.12073v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.12073v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.12073v1,"{'id': 'http://arxiv.org/abs/2107.12073v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.12073v1', 'updated': '2021-07-26T09:51:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=9, tm_min=51, tm_sec=54, tm_wday=0, tm_yday=207, tm_isdst=0), 'published': '2021-07-26T09:51:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=9, tm_min=51, tm_sec=54, tm_wday=0, tm_yday=207, tm_isdst=0), 'title': 'Uncovering the structure of the French media ecosystem', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Uncovering the structure of the French media ecosystem'}, 'summary': 'This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.'}, 'authors': [{'name': 'Jean-Philippe Cointet'}, {'name': 'Dominique Cardon'}, {'name': 'Andreï Mogoutov'}, {'name': 'Benjamin Ooghe-Tabanou'}, {'name': 'Guillaume Plique'}, {'name': 'Pedro Morales'}], 'author_detail': {'name': 'Pedro Morales'}, 'arxiv_affiliation': 'Médialab', 'author': 'Pedro Morales', 'arxiv_comment': 'IC2S2, Jul 2021, Zurich, Switzerland', 'links': [{'href': 'http://arxiv.org/abs/2107.12073v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.12073v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
19,http://arxiv.org/abs/2107.10443v1,2021-07-22 03:41:52+00:00,2021-07-22 03:41:52+00:00,Spinning Sequence-to-Sequence Models with Meta-Backdoors,"[arxiv.Result.Author('Eugene Bagdasaryan'), arxiv.Result.Author('Vitaly Shmatikov')]","We investigate a new threat to neural sequence-to-sequence (seq2seq) models:
training-time attacks that cause models to ""spin"" their output and support a
certain sentiment when the input contains adversary-chosen trigger words. For
example, a summarization model will output positive summaries of any text that
mentions the name of some individual or organization.
  We introduce the concept of a ""meta-backdoor"" to explain model-spinning
attacks. These attacks produce models whose output is valid and preserves
context, yet also satisfies a meta-task chosen by the adversary (e.g., positive
sentiment). Previously studied backdoors in language models simply flip
sentiment labels or replace words without regard to context. Their outputs are
incorrect on inputs with the trigger. Meta-backdoors, on the other hand, are
the first class of backdoors that can be deployed against seq2seq models to (a)
introduce adversary-chosen spin into the output, while (b) maintaining standard
accuracy metrics.
  To demonstrate feasibility of model spinning, we develop a new backdooring
technique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto
a seq2seq model, backpropagates the desired meta-task output (e.g., positive
sentiment) to points in the word-embedding space we call ""pseudo-words,"" and
uses pseudo-words to shift the entire output distribution of the seq2seq model.
Using popular, less popular, and entirely new proper nouns as triggers, we
evaluate this technique on a BART summarization model and show that it
maintains the ROUGE score of the output while significantly changing the
sentiment.
  We explain why model spinning can be a dangerous technique in AI-powered
disinformation and discuss how to mitigate these attacks.",,,,cs.CR,"['cs.CR', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2107.10443v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.10443v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.10443v1,"{'id': 'http://arxiv.org/abs/2107.10443v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.10443v1', 'updated': '2021-07-22T03:41:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=22, tm_hour=3, tm_min=41, tm_sec=52, tm_wday=3, tm_yday=203, tm_isdst=0), 'published': '2021-07-22T03:41:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=22, tm_hour=3, tm_min=41, tm_sec=52, tm_wday=3, tm_yday=203, tm_isdst=0), 'title': 'Spinning Sequence-to-Sequence Models with Meta-Backdoors', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Spinning Sequence-to-Sequence Models with Meta-Backdoors'}, 'summary': 'We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to ""spin"" their output and support a\ncertain sentiment when the input contains adversary-chosen trigger words. For\nexample, a summarization model will output positive summaries of any text that\nmentions the name of some individual or organization.\n  We introduce the concept of a ""meta-backdoor"" to explain model-spinning\nattacks. These attacks produce models whose output is valid and preserves\ncontext, yet also satisfies a meta-task chosen by the adversary (e.g., positive\nsentiment). Previously studied backdoors in language models simply flip\nsentiment labels or replace words without regard to context. Their outputs are\nincorrect on inputs with the trigger. Meta-backdoors, on the other hand, are\nthe first class of backdoors that can be deployed against seq2seq models to (a)\nintroduce adversary-chosen spin into the output, while (b) maintaining standard\naccuracy metrics.\n  To demonstrate feasibility of model spinning, we develop a new backdooring\ntechnique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto\na seq2seq model, backpropagates the desired meta-task output (e.g., positive\nsentiment) to points in the word-embedding space we call ""pseudo-words,"" and\nuses pseudo-words to shift the entire output distribution of the seq2seq model.\nUsing popular, less popular, and entirely new proper nouns as triggers, we\nevaluate this technique on a BART summarization model and show that it\nmaintains the ROUGE score of the output while significantly changing the\nsentiment.\n  We explain why model spinning can be a dangerous technique in AI-powered\ndisinformation and discuss how to mitigate these attacks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to ""spin"" their output and support a\ncertain sentiment when the input contains adversary-chosen trigger words. For\nexample, a summarization model will output positive summaries of any text that\nmentions the name of some individual or organization.\n  We introduce the concept of a ""meta-backdoor"" to explain model-spinning\nattacks. These attacks produce models whose output is valid and preserves\ncontext, yet also satisfies a meta-task chosen by the adversary (e.g., positive\nsentiment). Previously studied backdoors in language models simply flip\nsentiment labels or replace words without regard to context. Their outputs are\nincorrect on inputs with the trigger. Meta-backdoors, on the other hand, are\nthe first class of backdoors that can be deployed against seq2seq models to (a)\nintroduce adversary-chosen spin into the output, while (b) maintaining standard\naccuracy metrics.\n  To demonstrate feasibility of model spinning, we develop a new backdooring\ntechnique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto\na seq2seq model, backpropagates the desired meta-task output (e.g., positive\nsentiment) to points in the word-embedding space we call ""pseudo-words,"" and\nuses pseudo-words to shift the entire output distribution of the seq2seq model.\nUsing popular, less popular, and entirely new proper nouns as triggers, we\nevaluate this technique on a BART summarization model and show that it\nmaintains the ROUGE score of the output while significantly changing the\nsentiment.\n  We explain why model spinning can be a dangerous technique in AI-powered\ndisinformation and discuss how to mitigate these attacks.'}, 'authors': [{'name': 'Eugene Bagdasaryan'}, {'name': 'Vitaly Shmatikov'}], 'author_detail': {'name': 'Vitaly Shmatikov'}, 'author': 'Vitaly Shmatikov', 'links': [{'href': 'http://arxiv.org/abs/2107.10443v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.10443v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
20,http://arxiv.org/abs/2107.10139v2,2021-07-29 05:28:52+00:00,2021-07-21 15:16:10+00:00,"Generative Models for Security: Attacks, Defenses, and Opportunities","[arxiv.Result.Author('Luke A. Bauer'), arxiv.Result.Author('Vincent Bindschaedler')]","Generative models learn the distribution of data from a sample dataset and
can then generate new data instances. Recent advances in deep learning has
brought forth improvements in generative model architectures, and some
state-of-the-art models can (in some cases) produce outputs realistic enough to
fool humans.
  We survey recent research at the intersection of security and privacy and
generative models. In particular, we discuss the use of generative models in
adversarial machine learning, in helping automate or enhance existing attacks,
and as building blocks for defenses in contexts such as intrusion detection,
biometrics spoofing, and malware obfuscation. We also describe the use of
generative models in diverse applications such as fairness in machine learning,
privacy-preserving data synthesis, and steganography. Finally, we discuss new
threats due to generative models: the creation of synthetic media such as
deepfakes that can be used for disinformation.",,,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.10139v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.10139v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.10139v2,"{'id': 'http://arxiv.org/abs/2107.10139v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.10139v2', 'updated': '2021-07-29T05:28:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=29, tm_hour=5, tm_min=28, tm_sec=52, tm_wday=3, tm_yday=210, tm_isdst=0), 'published': '2021-07-21T15:16:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=21, tm_hour=15, tm_min=16, tm_sec=10, tm_wday=2, tm_yday=202, tm_isdst=0), 'title': 'Generative Models for Security: Attacks, Defenses, and Opportunities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Generative Models for Security: Attacks, Defenses, and Opportunities'}, 'summary': 'Generative models learn the distribution of data from a sample dataset and\ncan then generate new data instances. Recent advances in deep learning has\nbrought forth improvements in generative model architectures, and some\nstate-of-the-art models can (in some cases) produce outputs realistic enough to\nfool humans.\n  We survey recent research at the intersection of security and privacy and\ngenerative models. In particular, we discuss the use of generative models in\nadversarial machine learning, in helping automate or enhance existing attacks,\nand as building blocks for defenses in contexts such as intrusion detection,\nbiometrics spoofing, and malware obfuscation. We also describe the use of\ngenerative models in diverse applications such as fairness in machine learning,\nprivacy-preserving data synthesis, and steganography. Finally, we discuss new\nthreats due to generative models: the creation of synthetic media such as\ndeepfakes that can be used for disinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Generative models learn the distribution of data from a sample dataset and\ncan then generate new data instances. Recent advances in deep learning has\nbrought forth improvements in generative model architectures, and some\nstate-of-the-art models can (in some cases) produce outputs realistic enough to\nfool humans.\n  We survey recent research at the intersection of security and privacy and\ngenerative models. In particular, we discuss the use of generative models in\nadversarial machine learning, in helping automate or enhance existing attacks,\nand as building blocks for defenses in contexts such as intrusion detection,\nbiometrics spoofing, and malware obfuscation. We also describe the use of\ngenerative models in diverse applications such as fairness in machine learning,\nprivacy-preserving data synthesis, and steganography. Finally, we discuss new\nthreats due to generative models: the creation of synthetic media such as\ndeepfakes that can be used for disinformation.'}, 'authors': [{'name': 'Luke A. Bauer'}, {'name': 'Vincent Bindschaedler'}], 'author_detail': {'name': 'Vincent Bindschaedler'}, 'author': 'Vincent Bindschaedler', 'links': [{'href': 'http://arxiv.org/abs/2107.10139v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.10139v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
21,http://arxiv.org/abs/2107.08319v1,2021-07-17 22:11:13+00:00,2021-07-17 22:11:13+00:00,Characterizing Online Engagement with Disinformation and Conspiracies in the 2020 U.S. Presidential Election,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Emilio Ferrara'), arxiv.Result.Author('Yan Liu')]","Identifying and characterizing disinformation in political discourse on
social media is critical to ensure the integrity of elections and democratic
processes around the world. Persistent manipulation of social media has
resulted in increased concerns regarding the 2020 U.S. Presidential Election,
due to its potential to influence individual opinions and social dynamics. In
this work, we focus on the identification of distorted facts, in the form of
unreliable and conspiratorial narratives in election-related tweets, to
characterize discourse manipulation prior to the election. We apply a detection
model to separate factual from unreliable (or conspiratorial) claims analyzing
a dataset of 242 million election-related tweets. The identified claims are
used to investigate targeted topics of disinformation, and conspiracy groups,
most notably the far-right QAnon conspiracy group. Further, we characterize
account engagements with unreliable and conspiracy tweets, and with the QAnon
conspiracy group, by political leaning and tweet types. Finally, using a
regression discontinuity design, we investigate whether Twitter's actions to
curb QAnon activity on the platform were effective, and how QAnon accounts
adapt to Twitter's restrictions.",Accepted at ICWSM'22,ICWSM 2022,,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2107.08319v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.08319v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.08319v1,"{'id': 'http://arxiv.org/abs/2107.08319v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.08319v1', 'updated': '2021-07-17T22:11:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=17, tm_hour=22, tm_min=11, tm_sec=13, tm_wday=5, tm_yday=198, tm_isdst=0), 'published': '2021-07-17T22:11:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=17, tm_hour=22, tm_min=11, tm_sec=13, tm_wday=5, tm_yday=198, tm_isdst=0), 'title': 'Characterizing Online Engagement with Disinformation and Conspiracies in\n  the 2020 U.S. Presidential Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing Online Engagement with Disinformation and Conspiracies in\n  the 2020 U.S. Presidential Election'}, 'summary': ""Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions.""}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Emilio Ferrara'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_comment': ""Accepted at ICWSM'22"", 'arxiv_journal_ref': 'ICWSM 2022', 'links': [{'href': 'http://arxiv.org/abs/2107.08319v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.08319v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
22,http://arxiv.org/abs/2107.10655v1,2021-07-12 15:53:13+00:00,2021-07-12 15:53:13+00:00,Lumen: A Machine Learning Framework to Expose Influence Cues in Text,"[arxiv.Result.Author('Hanyu Shi'), arxiv.Result.Author('Mirela Silva'), arxiv.Result.Author('Daniel Capecci'), arxiv.Result.Author('Luiz Giovanini'), arxiv.Result.Author('Lauren Czech'), arxiv.Result.Author('Juliana Fernandes'), arxiv.Result.Author('Daniela Oliveira')]","Phishing and disinformation are popular social engineering attacks with
attackers invariably applying influence cues in texts to make them more
appealing to users. We introduce Lumen, a learning-based framework that exposes
influence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)
objectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was
trained with a newly developed dataset of 3K texts comprised of disinformation,
phishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in
comparison to other learning models showed that Lumen and LSTM presented the
best F1-micro score, but Lumen yielded better interpretability. Our results
highlight the promise of ML to expose influence cues in text, towards the goal
of application in automatic labeling tools to improve the accuracy of
human-based detection and reduce the likelihood of users falling for deceptive
online content.",,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2107.10655v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.10655v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.10655v1,"{'id': 'http://arxiv.org/abs/2107.10655v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.10655v1', 'updated': '2021-07-12T15:53:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=12, tm_hour=15, tm_min=53, tm_sec=13, tm_wday=0, tm_yday=193, tm_isdst=0), 'published': '2021-07-12T15:53:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=12, tm_hour=15, tm_min=53, tm_sec=13, tm_wday=0, tm_yday=193, tm_isdst=0), 'title': 'Lumen: A Machine Learning Framework to Expose Influence Cues in Text', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Lumen: A Machine Learning Framework to Expose Influence Cues in Text'}, 'summary': 'Phishing and disinformation are popular social engineering attacks with\nattackers invariably applying influence cues in texts to make them more\nappealing to users. We introduce Lumen, a learning-based framework that exposes\ninfluence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)\nobjectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was\ntrained with a newly developed dataset of 3K texts comprised of disinformation,\nphishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in\ncomparison to other learning models showed that Lumen and LSTM presented the\nbest F1-micro score, but Lumen yielded better interpretability. Our results\nhighlight the promise of ML to expose influence cues in text, towards the goal\nof application in automatic labeling tools to improve the accuracy of\nhuman-based detection and reduce the likelihood of users falling for deceptive\nonline content.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Phishing and disinformation are popular social engineering attacks with\nattackers invariably applying influence cues in texts to make them more\nappealing to users. We introduce Lumen, a learning-based framework that exposes\ninfluence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)\nobjectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was\ntrained with a newly developed dataset of 3K texts comprised of disinformation,\nphishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in\ncomparison to other learning models showed that Lumen and LSTM presented the\nbest F1-micro score, but Lumen yielded better interpretability. Our results\nhighlight the promise of ML to expose influence cues in text, towards the goal\nof application in automatic labeling tools to improve the accuracy of\nhuman-based detection and reduce the likelihood of users falling for deceptive\nonline content.'}, 'authors': [{'name': 'Hanyu Shi'}, {'name': 'Mirela Silva'}, {'name': 'Daniel Capecci'}, {'name': 'Luiz Giovanini'}, {'name': 'Lauren Czech'}, {'name': 'Juliana Fernandes'}, {'name': 'Daniela Oliveira'}], 'author_detail': {'name': 'Daniela Oliveira'}, 'author': 'Daniela Oliveira', 'links': [{'href': 'http://arxiv.org/abs/2107.10655v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.10655v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
23,http://arxiv.org/abs/2107.02828v1,2021-07-06 18:20:38+00:00,2021-07-06 18:20:38+00:00,Cognitive Contagion: How to model (and potentially counter) the spread of fake news,"[arxiv.Result.Author('Nicholas Rabb'), arxiv.Result.Author('Lenore Cowen'), arxiv.Result.Author('Jan P. de Ruiter'), arxiv.Result.Author('Matthias Scheutz')]","Understanding the spread of false or dangerous beliefs - so-called
mis/disinformation - through a population has never seemed so urgent to many.
Network science researchers have often taken a page from epidemiologists, and
modeled the spread of false beliefs as similar to how a disease spreads through
a social network. However, absent from those disease-inspired models is an
internal model of an individual's set of current beliefs, where cognitive
science has increasingly documented how the interaction between mental models
and incoming messages seems to be crucially important for their adoption or
rejection. We introduce a cognitive contagion model that combines a network
science approach with an internal cognitive model of the individual agents,
affecting what they believe, and what they pass on. We show that the model,
even with a very discrete and simplistic belief function to capture cognitive
dissonance, both adds expressive power over existing disease-based contagion
models, and qualitatively demonstrates the appropriate belief update phenomena
at the individual level. Moreover, we situate our cognitive contagion model in
a larger public opinion diffusion model, which attempts to capture the role of
institutions or media sources in belief diffusion - something that is often
left out. We conduct an analysis of the POD model with our simple cognitive
dissonance-sensitive update function across various graph topologies and
institutional messaging patterns. We demonstrate that population-level
aggregate outcomes of the model qualitatively match what has been reported in
COVID misinformation public opinion polls. The overall model sets up a
preliminary framework with which social science misinformation researchers and
computational opinion diffusion modelers can join forces to understand, and
hopefully learn how to best counter, the spread of misinformation and
""alternative facts.""",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.02828v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.02828v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.02828v1,"{'id': 'http://arxiv.org/abs/2107.02828v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.02828v1', 'updated': '2021-07-06T18:20:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=18, tm_min=20, tm_sec=38, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2021-07-06T18:20:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=18, tm_min=20, tm_sec=38, tm_wday=1, tm_yday=187, tm_isdst=0), 'title': 'Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news'}, 'summary': 'Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual\'s set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n""alternative facts.""', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual\'s set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n""alternative facts.""'}, 'authors': [{'name': 'Nicholas Rabb'}, {'name': 'Lenore Cowen'}, {'name': 'Jan P. de Ruiter'}, {'name': 'Matthias Scheutz'}], 'author_detail': {'name': 'Matthias Scheutz'}, 'author': 'Matthias Scheutz', 'links': [{'href': 'http://arxiv.org/abs/2107.02828v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.02828v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
24,http://arxiv.org/abs/2106.15968v1,2021-06-30 10:29:07+00:00,2021-06-30 10:29:07+00:00,The Impact of Disinformation on a Controversial Debate on Social Media,"[arxiv.Result.Author('Salvatore Vilella'), arxiv.Result.Author('Alfonso Semeraro'), arxiv.Result.Author('Daniela Paolotti'), arxiv.Result.Author('Giancarlo Ruffo')]","In this work we study how pervasive is the presence of disinformation in the
Italian debate around immigration on Twitter and the role of automated accounts
in the diffusion of such content. By characterising the Twitter users with an
\textit{Untrustworthiness} score, that tells us how frequently they engage with
disinformation content, we are able to see that such bad information
consumption habits are not equally distributed across the users; adopting a
network analysis approach, we can identify communities characterised by a very
high presence of users that frequently share content from unreliable news
sources. Within this context, social bots tend to inject in the network more
malicious content, that often remains confined in a limited number of clusters;
instead, they target reliable content in order to diversify their reach. The
evidence we gather suggests that, at least in this particular case study, there
is a strong interplay between social bots and users engaging with unreliable
content, influencing the diffusion of the latter across the network.",,,,cs.SI,"['cs.SI', 'cs.CY', 'K.4; J.4']","[arxiv.Result.Link('http://arxiv.org/abs/2106.15968v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.15968v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.15968v1,"{'id': 'http://arxiv.org/abs/2106.15968v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.15968v1', 'updated': '2021-06-30T10:29:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=30, tm_hour=10, tm_min=29, tm_sec=7, tm_wday=2, tm_yday=181, tm_isdst=0), 'published': '2021-06-30T10:29:07Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=30, tm_hour=10, tm_min=29, tm_sec=7, tm_wday=2, tm_yday=181, tm_isdst=0), 'title': 'The Impact of Disinformation on a Controversial Debate on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Impact of Disinformation on a Controversial Debate on Social Media'}, 'summary': 'In this work we study how pervasive is the presence of disinformation in the\nItalian debate around immigration on Twitter and the role of automated accounts\nin the diffusion of such content. By characterising the Twitter users with an\n\\textit{Untrustworthiness} score, that tells us how frequently they engage with\ndisinformation content, we are able to see that such bad information\nconsumption habits are not equally distributed across the users; adopting a\nnetwork analysis approach, we can identify communities characterised by a very\nhigh presence of users that frequently share content from unreliable news\nsources. Within this context, social bots tend to inject in the network more\nmalicious content, that often remains confined in a limited number of clusters;\ninstead, they target reliable content in order to diversify their reach. The\nevidence we gather suggests that, at least in this particular case study, there\nis a strong interplay between social bots and users engaging with unreliable\ncontent, influencing the diffusion of the latter across the network.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work we study how pervasive is the presence of disinformation in the\nItalian debate around immigration on Twitter and the role of automated accounts\nin the diffusion of such content. By characterising the Twitter users with an\n\\textit{Untrustworthiness} score, that tells us how frequently they engage with\ndisinformation content, we are able to see that such bad information\nconsumption habits are not equally distributed across the users; adopting a\nnetwork analysis approach, we can identify communities characterised by a very\nhigh presence of users that frequently share content from unreliable news\nsources. Within this context, social bots tend to inject in the network more\nmalicious content, that often remains confined in a limited number of clusters;\ninstead, they target reliable content in order to diversify their reach. The\nevidence we gather suggests that, at least in this particular case study, there\nis a strong interplay between social bots and users engaging with unreliable\ncontent, influencing the diffusion of the latter across the network.'}, 'authors': [{'name': 'Salvatore Vilella'}, {'name': 'Alfonso Semeraro'}, {'name': 'Daniela Paolotti'}, {'name': 'Giancarlo Ruffo'}], 'author_detail': {'name': 'Giancarlo Ruffo'}, 'author': 'Giancarlo Ruffo', 'links': [{'href': 'http://arxiv.org/abs/2106.15968v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.15968v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'K.4; J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
25,http://arxiv.org/abs/2106.15940v1,2021-06-30 09:47:27+00:00,2021-06-30 09:47:27+00:00,A preliminary approach to knowledge integrity risk assessment in Wikipedia projects,"[arxiv.Result.Author('Pablo Aragón'), arxiv.Result.Author('Diego Sáez-Trumper')]","Wikipedia is one of the main repositories of free knowledge available today,
with a central role in the Web ecosystem. For this reason, it can also be a
battleground for actors trying to impose specific points of view or even
spreading disinformation online. There is a growing need to monitor its
""health"" but this is not an easy task. Wikipedia exists in over 300 language
editions and each project is maintained by a different community, with their
own strengths, weaknesses and limitations. In this paper, we introduce a
taxonomy of knowledge integrity risks across Wikipedia projects and a first set
of indicators to assess internal risks related to community and content issues,
as well as external threats such as the geopolitical and media landscape. On
top of this taxonomy, we offer a preliminary analysis illustrating how the lack
of editors' geographical diversity might represent a knowledge integrity risk.
These are the first steps of a research project to build a Wikipedia Knowledge
Integrity Risk Observatory.","Accepted at MIS2'21: Misinformation and Misbehavior Mining on the Web
  Workshop held in conjunction with KDD 2021",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.15940v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.15940v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.15940v1,"{'id': 'http://arxiv.org/abs/2106.15940v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.15940v1', 'updated': '2021-06-30T09:47:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=30, tm_hour=9, tm_min=47, tm_sec=27, tm_wday=2, tm_yday=181, tm_isdst=0), 'published': '2021-06-30T09:47:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=30, tm_hour=9, tm_min=47, tm_sec=27, tm_wday=2, tm_yday=181, tm_isdst=0), 'title': 'A preliminary approach to knowledge integrity risk assessment in\n  Wikipedia projects', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A preliminary approach to knowledge integrity risk assessment in\n  Wikipedia projects'}, 'summary': 'Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n""health"" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors\' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n""health"" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors\' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.'}, 'authors': [{'name': 'Pablo Aragón'}, {'name': 'Diego Sáez-Trumper'}], 'author_detail': {'name': 'Diego Sáez-Trumper'}, 'author': 'Diego Sáez-Trumper', 'arxiv_comment': ""Accepted at MIS2'21: Misinformation and Misbehavior Mining on the Web\n  Workshop held in conjunction with KDD 2021"", 'links': [{'href': 'http://arxiv.org/abs/2106.15940v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.15940v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
26,http://arxiv.org/abs/2106.11000v2,2021-06-29 15:52:04+00:00,2021-06-21 11:40:00+00:00,A Comparative Study of Online Disinformation and Offline Protests,[arxiv.Result.Author('Jukka Ruohonen')],"In early 2021 the United States Capitol in Washington was stormed during a
riot and violent attack. Although the storming was merely an instance in a long
sequence of events, it provided a testimony for many observers who had claimed
that online actions, including the propagation of disinformation, have offline
consequences. Soon after, a number of papers have been published about the
relation between online disinformation and offline violence, among other
related relations. Hitherto, the effects upon political protests have been
unexplored. This paper thus evaluates such effects with a time series
cross-sectional sample of 125 countries in a period between 2000 and 2019. The
results are mixed. Based on Bayesian multi-level regression modeling, (i) there
indeed is an effect between online disinformation and offline protests, but the
effect is partially meditated by political polarization. The results are
clearer in a sample of countries belonging to the European Economic Area. With
this sample, (ii) offline protest counts increase from online disinformation
disseminated by domestic governments, political parties, and politicians as
well as by foreign governments. Furthermore, (iii) Internet shutdowns and
governmental monitoring of social media tend to decrease the counts. With these
results, the paper contributes to the blossoming disinformation research by
modeling the impact of disinformation upon offline phenomenon. The contribution
is important due to the various policy measures planned or already enacted.",Submitted,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.11000v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.11000v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.11000v2,"{'id': 'http://arxiv.org/abs/2106.11000v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.11000v2', 'updated': '2021-06-29T15:52:04Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=29, tm_hour=15, tm_min=52, tm_sec=4, tm_wday=1, tm_yday=180, tm_isdst=0), 'published': '2021-06-21T11:40:00Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=11, tm_min=40, tm_sec=0, tm_wday=0, tm_yday=172, tm_isdst=0), 'title': 'A Comparative Study of Online Disinformation and Offline Protests', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Comparative Study of Online Disinformation and Offline Protests'}, 'summary': 'In early 2021 the United States Capitol in Washington was stormed during a\nriot and violent attack. Although the storming was merely an instance in a long\nsequence of events, it provided a testimony for many observers who had claimed\nthat online actions, including the propagation of disinformation, have offline\nconsequences. Soon after, a number of papers have been published about the\nrelation between online disinformation and offline violence, among other\nrelated relations. Hitherto, the effects upon political protests have been\nunexplored. This paper thus evaluates such effects with a time series\ncross-sectional sample of 125 countries in a period between 2000 and 2019. The\nresults are mixed. Based on Bayesian multi-level regression modeling, (i) there\nindeed is an effect between online disinformation and offline protests, but the\neffect is partially meditated by political polarization. The results are\nclearer in a sample of countries belonging to the European Economic Area. With\nthis sample, (ii) offline protest counts increase from online disinformation\ndisseminated by domestic governments, political parties, and politicians as\nwell as by foreign governments. Furthermore, (iii) Internet shutdowns and\ngovernmental monitoring of social media tend to decrease the counts. With these\nresults, the paper contributes to the blossoming disinformation research by\nmodeling the impact of disinformation upon offline phenomenon. The contribution\nis important due to the various policy measures planned or already enacted.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In early 2021 the United States Capitol in Washington was stormed during a\nriot and violent attack. Although the storming was merely an instance in a long\nsequence of events, it provided a testimony for many observers who had claimed\nthat online actions, including the propagation of disinformation, have offline\nconsequences. Soon after, a number of papers have been published about the\nrelation between online disinformation and offline violence, among other\nrelated relations. Hitherto, the effects upon political protests have been\nunexplored. This paper thus evaluates such effects with a time series\ncross-sectional sample of 125 countries in a period between 2000 and 2019. The\nresults are mixed. Based on Bayesian multi-level regression modeling, (i) there\nindeed is an effect between online disinformation and offline protests, but the\neffect is partially meditated by political polarization. The results are\nclearer in a sample of countries belonging to the European Economic Area. With\nthis sample, (ii) offline protest counts increase from online disinformation\ndisseminated by domestic governments, political parties, and politicians as\nwell as by foreign governments. Furthermore, (iii) Internet shutdowns and\ngovernmental monitoring of social media tend to decrease the counts. With these\nresults, the paper contributes to the blossoming disinformation research by\nmodeling the impact of disinformation upon offline phenomenon. The contribution\nis important due to the various policy measures planned or already enacted.'}, 'authors': [{'name': 'Jukka Ruohonen'}], 'author_detail': {'name': 'Jukka Ruohonen'}, 'author': 'Jukka Ruohonen', 'arxiv_comment': 'Submitted', 'links': [{'href': 'http://arxiv.org/abs/2106.11000v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11000v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
27,http://arxiv.org/abs/2106.09847v2,2021-10-06 22:02:32+00:00,2021-06-17 23:27:43+00:00,"Disinformation, Stochastic Harm, and Costly Effort: A Principal-Agent Analysis of Regulating Social Media Platforms","[arxiv.Result.Author('Shehroze Khan'), arxiv.Result.Author('James R. Wright')]","The spread of disinformation on social media platforms such as Facebook is
harmful to society. This harm may manifest as a gradual degradation of public
discourse; but it can also take the form of sudden dramatic events such as the
recent insurrection on Capitol Hill. The platforms themselves are in the best
position to prevent the spread of disinformation, as they have the best access
to relevant data and the expertise to use it. However, mitigating
disinformation is costly, not only for implementing classification algorithms
or employing manual detection, but also because limiting such highly viral
content impacts user growth and thus potential advertising revenue. Since the
costs of harmful content are borne by other entities, the platform will
therefore have no incentive to exercise the socially-optimal level of effort.
This problem is similar to the problem of environmental regulation, in which
the costs of adverse events are not directly borne by a firm, the mitigation
effort of a firm is not observable, and the causal link between a harmful
consequence and a specific failure is difficult to prove. In the environmental
regulation domain, one solution to this issue is to perform costly monitoring
to ensure that the firm takes adequate precautions according a specified rule.
However, classifying disinformation is performative, and thus a fixed rule
becomes less effective over time. Encoding our domain as a Markov decision
process, we demonstrate that no penalty based on a static rule, no matter how
large, can incentivize adequate effort by the platform. Penalties based on an
adaptive rule can incentivize optimal effort, but counterintuitively, only if
the regulator sufficiently overreacts to harmful events by requiring a
greater-than-optimal level of effort. We therefore push for mechanisms that
elicit platforms' costs of precautionary effort in order to bypass such an
overreaction.",,,,cs.GT,"['cs.GT', 'cs.AI', 'econ.TH']","[arxiv.Result.Link('http://arxiv.org/abs/2106.09847v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.09847v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.09847v2,"{'id': 'http://arxiv.org/abs/2106.09847v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.09847v2', 'updated': '2021-10-06T22:02:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=6, tm_hour=22, tm_min=2, tm_sec=32, tm_wday=2, tm_yday=279, tm_isdst=0), 'published': '2021-06-17T23:27:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=23, tm_min=27, tm_sec=43, tm_wday=3, tm_yday=168, tm_isdst=0), 'title': 'Disinformation, Stochastic Harm, and Costly Effort: A Principal-Agent\n  Analysis of Regulating Social Media Platforms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation, Stochastic Harm, and Costly Effort: A Principal-Agent\n  Analysis of Regulating Social Media Platforms'}, 'summary': ""The spread of disinformation on social media platforms such as Facebook is\nharmful to society. This harm may manifest as a gradual degradation of public\ndiscourse; but it can also take the form of sudden dramatic events such as the\nrecent insurrection on Capitol Hill. The platforms themselves are in the best\nposition to prevent the spread of disinformation, as they have the best access\nto relevant data and the expertise to use it. However, mitigating\ndisinformation is costly, not only for implementing classification algorithms\nor employing manual detection, but also because limiting such highly viral\ncontent impacts user growth and thus potential advertising revenue. Since the\ncosts of harmful content are borne by other entities, the platform will\ntherefore have no incentive to exercise the socially-optimal level of effort.\nThis problem is similar to the problem of environmental regulation, in which\nthe costs of adverse events are not directly borne by a firm, the mitigation\neffort of a firm is not observable, and the causal link between a harmful\nconsequence and a specific failure is difficult to prove. In the environmental\nregulation domain, one solution to this issue is to perform costly monitoring\nto ensure that the firm takes adequate precautions according a specified rule.\nHowever, classifying disinformation is performative, and thus a fixed rule\nbecomes less effective over time. Encoding our domain as a Markov decision\nprocess, we demonstrate that no penalty based on a static rule, no matter how\nlarge, can incentivize adequate effort by the platform. Penalties based on an\nadaptive rule can incentivize optimal effort, but counterintuitively, only if\nthe regulator sufficiently overreacts to harmful events by requiring a\ngreater-than-optimal level of effort. We therefore push for mechanisms that\nelicit platforms' costs of precautionary effort in order to bypass such an\noverreaction."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The spread of disinformation on social media platforms such as Facebook is\nharmful to society. This harm may manifest as a gradual degradation of public\ndiscourse; but it can also take the form of sudden dramatic events such as the\nrecent insurrection on Capitol Hill. The platforms themselves are in the best\nposition to prevent the spread of disinformation, as they have the best access\nto relevant data and the expertise to use it. However, mitigating\ndisinformation is costly, not only for implementing classification algorithms\nor employing manual detection, but also because limiting such highly viral\ncontent impacts user growth and thus potential advertising revenue. Since the\ncosts of harmful content are borne by other entities, the platform will\ntherefore have no incentive to exercise the socially-optimal level of effort.\nThis problem is similar to the problem of environmental regulation, in which\nthe costs of adverse events are not directly borne by a firm, the mitigation\neffort of a firm is not observable, and the causal link between a harmful\nconsequence and a specific failure is difficult to prove. In the environmental\nregulation domain, one solution to this issue is to perform costly monitoring\nto ensure that the firm takes adequate precautions according a specified rule.\nHowever, classifying disinformation is performative, and thus a fixed rule\nbecomes less effective over time. Encoding our domain as a Markov decision\nprocess, we demonstrate that no penalty based on a static rule, no matter how\nlarge, can incentivize adequate effort by the platform. Penalties based on an\nadaptive rule can incentivize optimal effort, but counterintuitively, only if\nthe regulator sufficiently overreacts to harmful events by requiring a\ngreater-than-optimal level of effort. We therefore push for mechanisms that\nelicit platforms' costs of precautionary effort in order to bypass such an\noverreaction.""}, 'authors': [{'name': 'Shehroze Khan'}, {'name': 'James R. Wright'}], 'author_detail': {'name': 'James R. Wright'}, 'author': 'James R. Wright', 'links': [{'href': 'http://arxiv.org/abs/2106.09847v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09847v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
28,http://arxiv.org/abs/2106.01703v1,2021-06-03 09:07:54+00:00,2021-06-03 09:07:54+00:00,Fingerprinting Fine-tuned Language Models in the Wild,"[arxiv.Result.Author('Nirav Diwan'), arxiv.Result.Author('Tanmoy Chakravorty'), arxiv.Result.Author('Zubair Shafiq')]","There are concerns that the ability of language models (LMs) to generate high
quality synthetic text can be misused to launch spam, disinformation, or
propaganda. Therefore, the research community is actively working on developing
approaches to detect whether a given text is organic or synthetic. While this
is a useful first step, it is important to be able to further fingerprint the
author LM to attribute its origin. Prior work on fingerprinting LMs is limited
to attributing synthetic text generated by a handful (usually < 10) of
pre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad
of ways (e.g., on a domain-specific text corpus) before being used to generate
synthetic text. It is challenging to fingerprinting fine-tuned LMs because the
universe of fine-tuned LMs is much larger in realistic scenarios. To address
this challenge, we study the problem of large-scale fingerprinting of
fine-tuned LMs in the wild. Using a real-world dataset of synthetic text
generated by 108 different fine-tuned LMs, we conduct comprehensive experiments
to demonstrate the limitations of existing fingerprinting approaches. Our
results show that fine-tuning itself is the most effective in attributing the
synthetic text generated by fine-tuned LMs.",,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2106.01703v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.01703v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.01703v1,"{'id': 'http://arxiv.org/abs/2106.01703v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.01703v1', 'updated': '2021-06-03T09:07:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=9, tm_min=7, tm_sec=54, tm_wday=3, tm_yday=154, tm_isdst=0), 'published': '2021-06-03T09:07:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=9, tm_min=7, tm_sec=54, tm_wday=3, tm_yday=154, tm_isdst=0), 'title': 'Fingerprinting Fine-tuned Language Models in the Wild', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fingerprinting Fine-tuned Language Models in the Wild'}, 'summary': 'There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.'}, 'authors': [{'name': 'Nirav Diwan'}, {'name': 'Tanmoy Chakravorty'}, {'name': 'Zubair Shafiq'}], 'author_detail': {'name': 'Zubair Shafiq'}, 'author': 'Zubair Shafiq', 'links': [{'href': 'http://arxiv.org/abs/2106.01703v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.01703v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
29,http://arxiv.org/abs/2106.00163v1,2021-06-01 01:12:44+00:00,2021-06-01 01:12:44+00:00,Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform,"[arxiv.Result.Author('Emma Pieroni'), arxiv.Result.Author('Peter Jachim'), arxiv.Result.Author('Nathaniel Jachim'), arxiv.Result.Author('Filipo Sharevski')]","This paper evaluates Parler, the controversial social media platform, from
two seemingly orthogonal perspectives: UX design perspective and data science.
UX design researchers explore how users react to the interface/content of their
social media feeds; Data science researchers analyze the misinformation flow in
these feeds to detect alternative narratives and state-sponsored disinformation
campaigns. We took a critical look into the intersection of these approaches to
understand how Parler's interface itself is conductive to the flow of
misinformation and the perception of ""free speech"" among its audience. Parler
drew widespread attention leading up to and after the 2020 U.S. elections as
the ""alternative"" place for free speech, as a reaction to other mainstream
social media platform which actively engaged in labeling misinformation with
content warnings. Because platforms like Parler are disruptive to the social
media landscape, we believe the evaluation uniquely uncovers the platform's
conductivity to the spread of misinformation.",,,,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2106.00163v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.00163v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.00163v1,"{'id': 'http://arxiv.org/abs/2106.00163v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.00163v1', 'updated': '2021-06-01T01:12:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=1, tm_hour=1, tm_min=12, tm_sec=44, tm_wday=1, tm_yday=152, tm_isdst=0), 'published': '2021-06-01T01:12:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=1, tm_hour=1, tm_min=12, tm_sec=44, tm_wday=1, tm_yday=152, tm_isdst=0), 'title': 'Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform'}, 'summary': 'This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler\'s interface itself is conductive to the flow of\nmisinformation and the perception of ""free speech"" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe ""alternative"" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform\'s\nconductivity to the spread of misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler\'s interface itself is conductive to the flow of\nmisinformation and the perception of ""free speech"" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe ""alternative"" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform\'s\nconductivity to the spread of misinformation.'}, 'authors': [{'name': 'Emma Pieroni'}, {'name': 'Peter Jachim'}, {'name': 'Nathaniel Jachim'}, {'name': 'Filipo Sharevski'}], 'author_detail': {'name': 'Filipo Sharevski'}, 'author': 'Filipo Sharevski', 'links': [{'href': 'http://arxiv.org/abs/2106.00163v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.00163v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
30,http://arxiv.org/abs/2106.00142v1,2021-05-31 23:20:58+00:00,2021-05-31 23:20:58+00:00,FBAdTracker: An Interactive Data Collection and Analysis Tool for Facebook Advertisements,"[arxiv.Result.Author('Ujun Jeong'), arxiv.Result.Author('Kaize Ding'), arxiv.Result.Author('Huan Liu')]","The growing use of social media has led to drastic changes in our
decision-making. Especially, Facebook offers marketing API which promotes
business to target potential groups who are likely to consume their items.
However, this service can be abused by malicious advertisers who attempt to
deceive people by disinformation such as propaganda and divisive opinion. To
counter this problem, we introduce a new application named FBAdTracker. The
purpose of this application is to provide an integrated data collection and
analysis system for current research on fact-checking related to Facebook
advertisements. Our system is capable of monitoring up-to-date Facebook ads and
analyzing ads retrieved from Facebook Ads Library.","3 pages, 1 figure, 2021 International Conference on Social Computing,
  Behavioral-Cultural Modeling, & Prediction and Behavior Representation in
  Modeling and Simulation, demo track",,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.00142v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.00142v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.00142v1,"{'id': 'http://arxiv.org/abs/2106.00142v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.00142v1', 'updated': '2021-05-31T23:20:58Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=23, tm_min=20, tm_sec=58, tm_wday=0, tm_yday=151, tm_isdst=0), 'published': '2021-05-31T23:20:58Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=23, tm_min=20, tm_sec=58, tm_wday=0, tm_yday=151, tm_isdst=0), 'title': 'FBAdTracker: An Interactive Data Collection and Analysis Tool for\n  Facebook Advertisements', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FBAdTracker: An Interactive Data Collection and Analysis Tool for\n  Facebook Advertisements'}, 'summary': 'The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.'}, 'authors': [{'name': 'Ujun Jeong'}, {'name': 'Kaize Ding'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '3 pages, 1 figure, 2021 International Conference on Social Computing,\n  Behavioral-Cultural Modeling, & Prediction and Behavior Representation in\n  Modeling and Simulation, demo track', 'links': [{'href': 'http://arxiv.org/abs/2106.00142v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.00142v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
31,http://arxiv.org/abs/2105.15172v1,2021-05-31 17:32:06+00:00,2021-05-31 17:32:06+00:00,Assessing disinformation through the dynamics of supply and demand in the news ecosystem,"[arxiv.Result.Author('Pietro Gravino'), arxiv.Result.Author('Giulio Prevedello'), arxiv.Result.Author('Martina Galletti'), arxiv.Result.Author('Vittorio Loreto')]","Social dialogue, the foundation of our democracies, is currently threatened
by disinformation and partisanship, with their disrupting role on individual
and collective awareness and detrimental effects on decision-making processes.
Despite a great deal of attention to the news sphere itself, little is known
about the subtle interplay between the offer and the demand for information.
Still, a broader perspective on the news ecosystem, including both the
producers and the consumers of information, is needed to build new tools to
assess the health of the infosphere. Here, we combine in the same framework
news supply, as mirrored by a fairly complete Italian news database - partially
annotated for fake news, and news demand, as captured through the Google Trends
data for Italy. Our investigation focuses on the temporal and semantic
interplay of news, fake news, and searches in several domains, including the
virus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is
extremely reactive to people's interests and tends to thrive, especially when
there is a mismatch between what people are interested in and what news outlets
provide. Second, a suitably defined index can assess the level of
disinformation only based on the available volumes of news and searches.
Although our results mainly concern the Coronavirus subject, we provide hints
that the same findings can have more general applications. We contend these
results can be a powerful asset in informing campaigns against disinformation
and providing news outlets and institutions with potentially relevant
strategies.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2105.15172v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.15172v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.15172v1,"{'id': 'http://arxiv.org/abs/2105.15172v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.15172v1', 'updated': '2021-05-31T17:32:06Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=32, tm_sec=6, tm_wday=0, tm_yday=151, tm_isdst=0), 'published': '2021-05-31T17:32:06Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=32, tm_sec=6, tm_wday=0, tm_yday=151, tm_isdst=0), 'title': 'Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem'}, 'summary': ""Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.""}, 'authors': [{'name': 'Pietro Gravino'}, {'name': 'Giulio Prevedello'}, {'name': 'Martina Galletti'}, {'name': 'Vittorio Loreto'}], 'author_detail': {'name': 'Vittorio Loreto'}, 'author': 'Vittorio Loreto', 'links': [{'href': 'http://arxiv.org/abs/2105.15172v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.15172v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
32,http://arxiv.org/abs/2105.13398v1,2021-05-27 18:59:12+00:00,2021-05-27 18:59:12+00:00,Tactical Reframing of Online Disinformation Campaigns Against The Istanbul Convention,"[arxiv.Result.Author('Tuğrulcan Elmas'), arxiv.Result.Author('Rebekah Overdorf'), arxiv.Result.Author('Karl Aberer')]","In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights
treaty that addresses violence against women, citing issues with the
convention's implicit recognition of sexual and gender minorities. In this
work, we trace disinformation campaigns related to the Istanbul Convention and
its associated Turkish law that circulate on divorced men's rights Facebook
groups. We find that these groups adjusted the narrative and focus of the
campaigns to appeal to a larger audience, which we refer to as ""tactical
reframing."" Initially, the men organized in a grass-roots manner to campaign
against the Turkish law that was passed to codify the convention, focusing on
one-sided custody of children and indefinite alimony. Later, they reframed
their campaign and began attacking the Istanbul Convention, highlighting its
acknowledgment of homosexuality. This case study highlights how disinformation
campaigns can be used to weaponize homophobia in order to limit the rights of
women. To the best of our knowledge, this is the first case study that analyzes
a narrative reframing in the context of a disinformation campaign on social
media.","Accepted to Data For the Welbeing of Most Vulnerable (DWMV) Workshop
  colocated with ICWSM 2021",,10.36190/2021.42,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.36190/2021.42', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2105.13398v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.13398v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.13398v1,"{'id': 'http://arxiv.org/abs/2105.13398v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.13398v1', 'updated': '2021-05-27T18:59:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=27, tm_hour=18, tm_min=59, tm_sec=12, tm_wday=3, tm_yday=147, tm_isdst=0), 'published': '2021-05-27T18:59:12Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=27, tm_hour=18, tm_min=59, tm_sec=12, tm_wday=3, tm_yday=147, tm_isdst=0), 'title': 'Tactical Reframing of Online Disinformation Campaigns Against The\n  Istanbul Convention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tactical Reframing of Online Disinformation Campaigns Against The\n  Istanbul Convention'}, 'summary': 'In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights\ntreaty that addresses violence against women, citing issues with the\nconvention\'s implicit recognition of sexual and gender minorities. In this\nwork, we trace disinformation campaigns related to the Istanbul Convention and\nits associated Turkish law that circulate on divorced men\'s rights Facebook\ngroups. We find that these groups adjusted the narrative and focus of the\ncampaigns to appeal to a larger audience, which we refer to as ""tactical\nreframing."" Initially, the men organized in a grass-roots manner to campaign\nagainst the Turkish law that was passed to codify the convention, focusing on\none-sided custody of children and indefinite alimony. Later, they reframed\ntheir campaign and began attacking the Istanbul Convention, highlighting its\nacknowledgment of homosexuality. This case study highlights how disinformation\ncampaigns can be used to weaponize homophobia in order to limit the rights of\nwomen. To the best of our knowledge, this is the first case study that analyzes\na narrative reframing in the context of a disinformation campaign on social\nmedia.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights\ntreaty that addresses violence against women, citing issues with the\nconvention\'s implicit recognition of sexual and gender minorities. In this\nwork, we trace disinformation campaigns related to the Istanbul Convention and\nits associated Turkish law that circulate on divorced men\'s rights Facebook\ngroups. We find that these groups adjusted the narrative and focus of the\ncampaigns to appeal to a larger audience, which we refer to as ""tactical\nreframing."" Initially, the men organized in a grass-roots manner to campaign\nagainst the Turkish law that was passed to codify the convention, focusing on\none-sided custody of children and indefinite alimony. Later, they reframed\ntheir campaign and began attacking the Istanbul Convention, highlighting its\nacknowledgment of homosexuality. This case study highlights how disinformation\ncampaigns can be used to weaponize homophobia in order to limit the rights of\nwomen. To the best of our knowledge, this is the first case study that analyzes\na narrative reframing in the context of a disinformation campaign on social\nmedia.'}, 'authors': [{'name': 'Tuğrulcan Elmas'}, {'name': 'Rebekah Overdorf'}, {'name': 'Karl Aberer'}], 'author_detail': {'name': 'Karl Aberer'}, 'author': 'Karl Aberer', 'arxiv_doi': '10.36190/2021.42', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.36190/2021.42', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2105.13398v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.13398v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted to Data For the Welbeing of Most Vulnerable (DWMV) Workshop\n  colocated with ICWSM 2021', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
33,http://arxiv.org/abs/2105.10671v1,2021-05-22 09:26:13+00:00,2021-05-22 09:26:13+00:00,SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?,"[arxiv.Result.Author('Tanveer Khan'), arxiv.Result.Author('Antonis Michalas'), arxiv.Result.Author('Adnan Akhunzada')]","Social Networks' omnipresence and ease of use has revolutionized the
generation and distribution of information in today's world. However, easy
access to information does not equal an increased level of public knowledge.
Unlike traditional media channels, social networks also facilitate faster and
wider spread of disinformation and misinformation. Viral spread of false
information has serious implications on the behaviors, attitudes and beliefs of
the public, and ultimately can seriously endanger the democratic processes.
Limiting false information's negative impact through early detection and
control of extensive spread presents the main challenge facing researchers
today. In this survey paper, we extensively analyze a wide range of different
solutions for the early detection of fake news in the existing literature. More
precisely, we examine Machine Learning (ML) models for the identification and
classification of fake news, online fake news detection competitions,
statistical outputs as well as the advantages and disadvantages of some of the
available data sets. Finally, we evaluate the online web browsing tools
available for detecting and mitigating fake news and present some open research
challenges.","34 pages, 3 figures",,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2105.10671v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.10671v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.10671v1,"{'id': 'http://arxiv.org/abs/2105.10671v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.10671v1', 'updated': '2021-05-22T09:26:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=9, tm_min=26, tm_sec=13, tm_wday=5, tm_yday=142, tm_isdst=0), 'published': '2021-05-22T09:26:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=9, tm_min=26, tm_sec=13, tm_wday=5, tm_yday=142, tm_isdst=0), 'title': 'SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?'}, 'summary': ""Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.""}, 'authors': [{'name': 'Tanveer Khan'}, {'name': 'Antonis Michalas'}, {'name': 'Adnan Akhunzada'}], 'author_detail': {'name': 'Adnan Akhunzada'}, 'author': 'Adnan Akhunzada', 'arxiv_comment': '34 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/2105.10671v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.10671v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
34,http://arxiv.org/abs/2104.13559v2,2021-05-18 05:41:05+00:00,2021-04-28 03:38:24+00:00,AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance Detection for Fact Checking,"[arxiv.Result.Author('Tariq Alhindi'), arxiv.Result.Author('Amal Alabdulkarim'), arxiv.Result.Author('Ali Alshehri'), arxiv.Result.Author('Muhammad Abdul-Mageed'), arxiv.Result.Author('Preslav Nakov')]","With the continuing spread of misinformation and disinformation online, it is
of increasing importance to develop combating mechanisms at scale in the form
of automated systems that support multiple languages. One task of interest is
claim veracity prediction, which can be addressed using stance detection with
respect to relevant documents retrieved online. To this end, we present our new
Arabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from
a diverse set of sources comprising three fact-checking websites and one news
website. AraStance covers false and true claims from multiple domains (e.g.,
politics, sports, health) and several Arab countries, and it is well-balanced
between related and unrelated documents with respect to the claims. We
benchmark AraStance, along with two other stance detection datasets, using a
number of BERT-based models. Our best model achieves an accuracy of 85\% and a
macro F1 score of 78\%, which leaves room for improvement and reflects the
challenging nature of AraStance and the task of stance detection in general.","Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,
  and Propaganda",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.13559v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13559v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13559v2,"{'id': 'http://arxiv.org/abs/2104.13559v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13559v2', 'updated': '2021-05-18T05:41:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=18, tm_hour=5, tm_min=41, tm_sec=5, tm_wday=1, tm_yday=138, tm_isdst=0), 'published': '2021-04-28T03:38:24Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=3, tm_min=38, tm_sec=24, tm_wday=2, tm_yday=118, tm_isdst=0), 'title': 'AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking'}, 'summary': 'With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.'}, 'authors': [{'name': 'Tariq Alhindi'}, {'name': 'Amal Alabdulkarim'}, {'name': 'Ali Alshehri'}, {'name': 'Muhammad Abdul-Mageed'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,\n  and Propaganda', 'links': [{'href': 'http://arxiv.org/abs/2104.13559v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13559v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
35,http://arxiv.org/abs/2104.12259v1,2021-04-25 21:19:24+00:00,2021-04-25 21:19:24+00:00,User Preference-aware Fake News Detection,"[arxiv.Result.Author('Yingtong Dou'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Congying Xia'), arxiv.Result.Author('Philip S. Yu'), arxiv.Result.Author('Lichao Sun')]","Disinformation and fake news have posed detrimental effects on individuals
and society in recent years, attracting broad attention to fake news detection.
The majority of existing fake news detection algorithms focus on mining news
content and/or the surrounding exogenous context for discovering deceptive
signals; while the endogenous preference of a user when he/she decides to
spread a piece of fake news or not is ignored. The confirmation bias theory has
indicated that a user is more likely to spread a piece of fake news when it
confirms his/her existing beliefs/preferences. Users' historical, social
engagements such as posts provide rich information about users' preferences
toward news and have great potential to advance fake news detection. However,
the work on exploring user preference for fake news detection is somewhat
limited. Therefore, in this paper, we study the novel problem of exploiting
user preference for fake news detection. We propose a new framework, UPFD,
which simultaneously captures various signals from user preferences by joint
content and graph modeling. Experimental results on real-world datasets
demonstrate the effectiveness of the proposed framework. We release our code
and data as a benchmark for GNN-based fake news detection:
https://github.com/safe-graph/GNN-FakeNews.","Accepted by SIGIR'21. Code is available at
  https://github.com/safe-graph/GNN-FakeNews",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2104.12259v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.12259v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.12259v1,"{'id': 'http://arxiv.org/abs/2104.12259v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.12259v1', 'updated': '2021-04-25T21:19:24Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=21, tm_min=19, tm_sec=24, tm_wday=6, tm_yday=115, tm_isdst=0), 'published': '2021-04-25T21:19:24Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=21, tm_min=19, tm_sec=24, tm_wday=6, tm_yday=115, tm_isdst=0), 'title': 'User Preference-aware Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'User Preference-aware Fake News Detection'}, 'summary': ""Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.""}, 'authors': [{'name': 'Yingtong Dou'}, {'name': 'Kai Shu'}, {'name': 'Congying Xia'}, {'name': 'Philip S. Yu'}, {'name': 'Lichao Sun'}], 'author_detail': {'name': 'Lichao Sun'}, 'author': 'Lichao Sun', 'arxiv_comment': ""Accepted by SIGIR'21. Code is available at\n  https://github.com/safe-graph/GNN-FakeNews"", 'links': [{'href': 'http://arxiv.org/abs/2104.12259v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.12259v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
36,http://arxiv.org/abs/2104.13352v2,2021-06-13 12:27:10+00:00,2021-04-24 08:54:02+00:00,Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of Red Fort Riots 2021,"[arxiv.Result.Author('Ajay Agarwal'), arxiv.Result.Author('Basant Agarwal')]","On 26 January 2021, India witnessed a national embarrassment from the
demographic least expected from - farmers. People across the nation watched in
horror as a pseudo-patriotic mob of farmers stormed capital Delhi and
vandalized the national pride- Red Fort. Investigations that followed the event
revealed the existence of a social media trail that led to the likes of such an
event. Consequently, it became essential and necessary to archive this trail
for social media analysis - not only to understand the bread-crumbs that are
dispersed across the trail but also to visualize the role played by
misinformation and fake news in this event. In this paper, we propose the
tractor2twitter dataset which contains around 0.05 million tweets that were
posted before, during, and after this event. Also, we benchmark our dataset
with an Explainable AI ML model for classification of each tweet into either of
the three categories - disinformation, misinformation, and opinion.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.13352v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13352v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13352v2,"{'id': 'http://arxiv.org/abs/2104.13352v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13352v2', 'updated': '2021-06-13T12:27:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=13, tm_hour=12, tm_min=27, tm_sec=10, tm_wday=6, tm_yday=164, tm_isdst=0), 'published': '2021-04-24T08:54:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=24, tm_hour=8, tm_min=54, tm_sec=2, tm_wday=5, tm_yday=114, tm_isdst=0), 'title': 'Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021'}, 'summary': 'On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.'}, 'authors': [{'name': 'Ajay Agarwal'}, {'name': 'Basant Agarwal'}], 'author_detail': {'name': 'Basant Agarwal'}, 'author': 'Basant Agarwal', 'links': [{'href': 'http://arxiv.org/abs/2104.13352v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13352v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
37,http://arxiv.org/abs/2104.11694v1,2021-04-20 23:19:43+00:00,2021-04-20 23:19:43+00:00,Mutual Hyperlinking Among Misinformation Peddlers,"[arxiv.Result.Author('Vibhor Sehgal'), arxiv.Result.Author('Ankit Peshin'), arxiv.Result.Author('Sadia Afroz'), arxiv.Result.Author('Hany Farid')]","The internet promised to democratize access to knowledge and make the world
more open and understanding. The reality of today's internet, however, is far
from this ideal. Misinformation, lies, and conspiracies dominate many social
media platforms. This toxic online world has had real-world implications
ranging from genocide to, election interference, and threats to global public
health. A frustrated public and impatient government regulators are calling for
a more vigorous response to mis- and disinformation campaigns designed to sow
civil unrest and inspire violence against individuals, societies, and
democracies. We describe a large-scale, domain-level analysis that reveals
seemingly coordinated efforts between multiple domains to spread and amplify
misinformation. We also describe how the hyperlinks shared by certain Twitter
users can be used to surface problematic domains. These analyses can be used by
search engines and social media recommendation algorithms to systematically
discover and demote misinformation peddlers.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.11694v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.11694v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.11694v1,"{'id': 'http://arxiv.org/abs/2104.11694v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.11694v1', 'updated': '2021-04-20T23:19:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=20, tm_hour=23, tm_min=19, tm_sec=43, tm_wday=1, tm_yday=110, tm_isdst=0), 'published': '2021-04-20T23:19:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=20, tm_hour=23, tm_min=19, tm_sec=43, tm_wday=1, tm_yday=110, tm_isdst=0), 'title': 'Mutual Hyperlinking Among Misinformation Peddlers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mutual Hyperlinking Among Misinformation Peddlers'}, 'summary': ""The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers.""}, 'authors': [{'name': 'Vibhor Sehgal'}, {'name': 'Ankit Peshin'}, {'name': 'Sadia Afroz'}, {'name': 'Hany Farid'}], 'author_detail': {'name': 'Hany Farid'}, 'author': 'Hany Farid', 'links': [{'href': 'http://arxiv.org/abs/2104.11694v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.11694v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
38,http://arxiv.org/abs/2104.07423v1,2021-04-15 12:39:37+00:00,2021-04-15 12:39:37+00:00,The Role of Context in Detecting Previously Fact-Checked Claims,"[arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Preslav Nakov')]","Recent years have seen the proliferation of disinformation and misinformation
online, thanks to the freedom of expression on the Internet and to the rise of
social media. Two solutions were proposed to address the problem: (i) manual
fact-checking, which is accurate and credible, but slow and non-scalable, and
(ii) automatic fact-checking, which is fast and scalable, but lacks
explainability and credibility. With the accumulation of enough manually
fact-checked claims, a middle-ground approach has emerged: checking whether a
given claim has previously been fact-checked. This can be made automatically,
and thus fast, while also offering credibility and explainability, thanks to
the human fact-checking and explanations in the associated fact-checking
article. This is a relatively new and understudied research direction, and here
we focus on claims made in a political debate, where context really matters.
Thus, we study the impact of modeling the context of the claim: both on the
source side, i.e., in the debate, as well as on the target side, i.e., in the
fact-checking explanation document. We do this by modeling the local context,
the global context, as well as by means of co-reference resolution, and
reasoning over the target text using Transformer-XH. The experimental results
show that each of these represents a valuable information source, but that
modeling the source-side context is more important, and can yield 10+ points of
absolute improvement.","detecting previously fact-checked claims, fact-checking,
  disinformation, fake news, social media, political debates",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG', 'cs.NE', '68T50', 'F.2.2; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2104.07423v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.07423v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.07423v1,"{'id': 'http://arxiv.org/abs/2104.07423v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.07423v1', 'updated': '2021-04-15T12:39:37Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=15, tm_hour=12, tm_min=39, tm_sec=37, tm_wday=3, tm_yday=105, tm_isdst=0), 'published': '2021-04-15T12:39:37Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=15, tm_hour=12, tm_min=39, tm_sec=37, tm_wday=3, tm_yday=105, tm_isdst=0), 'title': 'The Role of Context in Detecting Previously Fact-Checked Claims', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Role of Context in Detecting Previously Fact-Checked Claims'}, 'summary': 'Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.'}, 'authors': [{'name': 'Shaden Shaar'}, {'name': 'Firoj Alam'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates', 'links': [{'href': 'http://arxiv.org/abs/2104.07423v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.07423v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'F.2.2; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
39,http://arxiv.org/abs/2104.06952v1,2021-04-14 16:25:22+00:00,2021-04-14 16:25:22+00:00,The Surprising Performance of Simple Baselines for Misinformation Detection,"[arxiv.Result.Author('Kellin Pelrine'), arxiv.Result.Author('Jacob Danovitch'), arxiv.Result.Author('Reihaneh Rabbany')]","As social media becomes increasingly prominent in our day to day lives, it is
increasingly important to detect informative content and prevent the spread of
disinformation and unverified rumours. While many sophisticated and successful
models have been proposed in the literature, they are often compared with older
NLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the
performance of a broad set of modern transformer-based language models and show
that with basic fine-tuning, these models are competitive with and can even
significantly outperform recently proposed state-of-the-art methods. We present
our framework as a baseline for creating and evaluating new methods for
misinformation detection. We further study a comprehensive set of benchmark
datasets, and discuss potential data leakage and the need for careful design of
the experiments and understanding of datasets to account for confounding
variables. As an extreme case example, we show that classifying only based on
the first three digits of tweet ids, which contain information on the date,
gives state-of-the-art performance on a commonly used benchmark dataset for
fake news detection --Twitter16. We provide a simple tool to detect this
problem and suggest steps to mitigate it in future datasets.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.06952v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.06952v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.06952v1,"{'id': 'http://arxiv.org/abs/2104.06952v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.06952v1', 'updated': '2021-04-14T16:25:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=22, tm_wday=2, tm_yday=104, tm_isdst=0), 'published': '2021-04-14T16:25:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=22, tm_wday=2, tm_yday=104, tm_isdst=0), 'title': 'The Surprising Performance of Simple Baselines for Misinformation\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Surprising Performance of Simple Baselines for Misinformation\n  Detection'}, 'summary': 'As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.'}, 'authors': [{'name': 'Kellin Pelrine'}, {'name': 'Jacob Danovitch'}, {'name': 'Reihaneh Rabbany'}], 'author_detail': {'name': 'Reihaneh Rabbany'}, 'author': 'Reihaneh Rabbany', 'links': [{'href': 'http://arxiv.org/abs/2104.06952v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.06952v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
40,http://arxiv.org/abs/2104.06182v1,2021-04-13 13:32:55+00:00,2021-04-13 13:32:55+00:00,Understanding Transformers for Bot Detection in Twitter,"[arxiv.Result.Author('Andres Garcia-Silva'), arxiv.Result.Author('Cristian Berrio'), arxiv.Result.Author('Jose Manuel Gomez-Perez')]","In this paper we shed light on the impact of fine-tuning over social media
data in the internal representations of neural language models. We focus on bot
detection in Twitter, a key task to mitigate and counteract the automatic
spreading of disinformation and bias in social media. We investigate the use of
pre-trained language models to tackle the detection of tweets generated by a
bot or a human account based exclusively on its content. Unlike the general
trend in benchmarks like GLUE, where BERT generally outperforms generative
transformers like GPT and GPT-2 for most classification tasks on regular text,
we observe that fine-tuning generative transformers on a bot detection task
produces higher accuracies. We analyze the architectural components of each
transformer and study the effect of fine-tuning on their hidden states and
output representations. Among our findings, we show that part of the
syntactical information and distributional properties captured by BERT during
pre-training is lost upon fine-tuning while the generative pre-training
approach manage to preserve these properties.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.06182v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.06182v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.06182v1,"{'id': 'http://arxiv.org/abs/2104.06182v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.06182v1', 'updated': '2021-04-13T13:32:55Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=13, tm_hour=13, tm_min=32, tm_sec=55, tm_wday=1, tm_yday=103, tm_isdst=0), 'published': '2021-04-13T13:32:55Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=13, tm_hour=13, tm_min=32, tm_sec=55, tm_wday=1, tm_yday=103, tm_isdst=0), 'title': 'Understanding Transformers for Bot Detection in Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding Transformers for Bot Detection in Twitter'}, 'summary': 'In this paper we shed light on the impact of fine-tuning over social media\ndata in the internal representations of neural language models. We focus on bot\ndetection in Twitter, a key task to mitigate and counteract the automatic\nspreading of disinformation and bias in social media. We investigate the use of\npre-trained language models to tackle the detection of tweets generated by a\nbot or a human account based exclusively on its content. Unlike the general\ntrend in benchmarks like GLUE, where BERT generally outperforms generative\ntransformers like GPT and GPT-2 for most classification tasks on regular text,\nwe observe that fine-tuning generative transformers on a bot detection task\nproduces higher accuracies. We analyze the architectural components of each\ntransformer and study the effect of fine-tuning on their hidden states and\noutput representations. Among our findings, we show that part of the\nsyntactical information and distributional properties captured by BERT during\npre-training is lost upon fine-tuning while the generative pre-training\napproach manage to preserve these properties.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper we shed light on the impact of fine-tuning over social media\ndata in the internal representations of neural language models. We focus on bot\ndetection in Twitter, a key task to mitigate and counteract the automatic\nspreading of disinformation and bias in social media. We investigate the use of\npre-trained language models to tackle the detection of tweets generated by a\nbot or a human account based exclusively on its content. Unlike the general\ntrend in benchmarks like GLUE, where BERT generally outperforms generative\ntransformers like GPT and GPT-2 for most classification tasks on regular text,\nwe observe that fine-tuning generative transformers on a bot detection task\nproduces higher accuracies. We analyze the architectural components of each\ntransformer and study the effect of fine-tuning on their hidden states and\noutput representations. Among our findings, we show that part of the\nsyntactical information and distributional properties captured by BERT during\npre-training is lost upon fine-tuning while the generative pre-training\napproach manage to preserve these properties.'}, 'authors': [{'name': 'Andres Garcia-Silva'}, {'name': 'Cristian Berrio'}, {'name': 'Jose Manuel Gomez-Perez'}], 'author_detail': {'name': 'Jose Manuel Gomez-Perez'}, 'author': 'Jose Manuel Gomez-Perez', 'links': [{'href': 'http://arxiv.org/abs/2104.06182v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.06182v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
41,http://arxiv.org/abs/2104.04389v1,2021-04-09 14:22:52+00:00,2021-04-09 14:22:52+00:00,A Few Observations About State-Centric Online Propaganda,[arxiv.Result.Author('Jukka Ruohonen')],"This paper presents a few observations about pro-Kremlin propaganda between
2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),
which is affiliated with the European Union (EU) but working independently from
it. Instead of focusing on misinformation and disinformation, the observations
are motivated by classical propaganda research and the ongoing transformation
of media systems. According to the tentative results, (i) the propaganda can be
assumed to target both domestic and foreign audiences. Of the countries and
regions discussed, (ii) Russia, Ukraine, the United States, and within Europe,
Germany, Poland, and the EU have been the most frequently discussed. Also other
conflict regions such as Syria have often appeared in the propaganda. In terms
of longitudinal trends, however, (iii) most of these discussions have decreased
in volume after the digital tsunami in 2016, although the conflict in Ukraine
seems to have again increased the intensity of pro-Kremlin propaganda. Finally,
(iv) the themes discussed align with state-centric war propaganda and conflict
zones, although also post-truth themes frequently appear; from conspiracy
theories via COVID-19 to fascism -- anything goes, as is typical to propaganda.",Submitted,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.04389v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04389v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04389v1,"{'id': 'http://arxiv.org/abs/2104.04389v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04389v1', 'updated': '2021-04-09T14:22:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=14, tm_min=22, tm_sec=52, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2021-04-09T14:22:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=14, tm_min=22, tm_sec=52, tm_wday=4, tm_yday=99, tm_isdst=0), 'title': 'A Few Observations About State-Centric Online Propaganda', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Few Observations About State-Centric Online Propaganda'}, 'summary': 'This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.'}, 'authors': [{'name': 'Jukka Ruohonen'}], 'author_detail': {'name': 'Jukka Ruohonen'}, 'author': 'Jukka Ruohonen', 'arxiv_comment': 'Submitted', 'links': [{'href': 'http://arxiv.org/abs/2104.04389v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04389v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
42,http://arxiv.org/abs/2104.04311v1,2021-04-09 11:33:02+00:00,2021-04-09 11:33:02+00:00,Helping People Deal With Disinformation -- A Socio-Technical Perspective,[arxiv.Result.Author('Hendrik Heuer')],"At the latest since the advent of the Internet, disinformation and conspiracy
theories have become ubiquitous. Recent examples like QAnon and Pizzagate prove
that false information can lead to real violence. In this motivation statement
for the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my
research agenda focused on 1. why people believe in disinformation, 2. how
people can be best supported in recognizing disinformation, and 3. what the
potentials and risks of different tools designed to fight disinformation are.","This paper will be presented at the Workshop on Human Aspects of
  Misinformation at CHI 2021",,,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2104.04311v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04311v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04311v1,"{'id': 'http://arxiv.org/abs/2104.04311v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04311v1', 'updated': '2021-04-09T11:33:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=11, tm_min=33, tm_sec=2, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2021-04-09T11:33:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=11, tm_min=33, tm_sec=2, tm_wday=4, tm_yday=99, tm_isdst=0), 'title': 'Helping People Deal With Disinformation -- A Socio-Technical Perspective', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Helping People Deal With Disinformation -- A Socio-Technical Perspective'}, 'summary': 'At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.'}, 'authors': [{'name': 'Hendrik Heuer'}], 'author_detail': {'name': 'Hendrik Heuer'}, 'author': 'Hendrik Heuer', 'arxiv_comment': 'This paper will be presented at the Workshop on Human Aspects of\n  Misinformation at CHI 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.04311v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04311v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
43,http://arxiv.org/abs/2103.16613v1,2021-03-30 18:36:13+00:00,2021-03-30 18:36:13+00:00,Tracking Knowledge Propagation Across Wikipedia Languages,"[arxiv.Result.Author('Roldolfo Valentim'), arxiv.Result.Author('Giovanni Comarela'), arxiv.Result.Author('Souneil Park'), arxiv.Result.Author('Diego Saez-Trumper')]","In this paper, we present a dataset of inter-language knowledge propagation
in Wikipedia. Covering the entire 309 language editions and 33M articles, the
dataset aims to track the full propagation history of Wikipedia concepts, and
allow follow up research on building predictive models of them. For this
purpose, we align all the Wikipedia articles in a language-agnostic manner
according to the concept they cover, which results in 13M propagation
instances. To the best of our knowledge, this dataset is the first to explore
the full inter-language propagation at a large scale. Together with the
dataset, a holistic overview of the propagation and key insights about the
underlying structural factors are provided to aid future research. For example,
we find that although long cascades are unusual, the propagation tends to
continue further once it reaches more than four language editions. We also find
that the size of language editions is associated with the speed of propagation.
We believe the dataset not only contributes to the prior literature on
Wikipedia growth but also enables new use cases such as edit recommendation for
addressing knowledge gaps, detection of disinformation, and cultural
relationship analysis.",,"15th International Conference on Web and Social Media (ICWSM-21),
  2021",,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.16613v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.16613v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.16613v1,"{'id': 'http://arxiv.org/abs/2103.16613v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.16613v1', 'updated': '2021-03-30T18:36:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=30, tm_hour=18, tm_min=36, tm_sec=13, tm_wday=1, tm_yday=89, tm_isdst=0), 'published': '2021-03-30T18:36:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=30, tm_hour=18, tm_min=36, tm_sec=13, tm_wday=1, tm_yday=89, tm_isdst=0), 'title': 'Tracking Knowledge Propagation Across Wikipedia Languages', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tracking Knowledge Propagation Across Wikipedia Languages'}, 'summary': 'In this paper, we present a dataset of inter-language knowledge propagation\nin Wikipedia. Covering the entire 309 language editions and 33M articles, the\ndataset aims to track the full propagation history of Wikipedia concepts, and\nallow follow up research on building predictive models of them. For this\npurpose, we align all the Wikipedia articles in a language-agnostic manner\naccording to the concept they cover, which results in 13M propagation\ninstances. To the best of our knowledge, this dataset is the first to explore\nthe full inter-language propagation at a large scale. Together with the\ndataset, a holistic overview of the propagation and key insights about the\nunderlying structural factors are provided to aid future research. For example,\nwe find that although long cascades are unusual, the propagation tends to\ncontinue further once it reaches more than four language editions. We also find\nthat the size of language editions is associated with the speed of propagation.\nWe believe the dataset not only contributes to the prior literature on\nWikipedia growth but also enables new use cases such as edit recommendation for\naddressing knowledge gaps, detection of disinformation, and cultural\nrelationship analysis.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we present a dataset of inter-language knowledge propagation\nin Wikipedia. Covering the entire 309 language editions and 33M articles, the\ndataset aims to track the full propagation history of Wikipedia concepts, and\nallow follow up research on building predictive models of them. For this\npurpose, we align all the Wikipedia articles in a language-agnostic manner\naccording to the concept they cover, which results in 13M propagation\ninstances. To the best of our knowledge, this dataset is the first to explore\nthe full inter-language propagation at a large scale. Together with the\ndataset, a holistic overview of the propagation and key insights about the\nunderlying structural factors are provided to aid future research. For example,\nwe find that although long cascades are unusual, the propagation tends to\ncontinue further once it reaches more than four language editions. We also find\nthat the size of language editions is associated with the speed of propagation.\nWe believe the dataset not only contributes to the prior literature on\nWikipedia growth but also enables new use cases such as edit recommendation for\naddressing knowledge gaps, detection of disinformation, and cultural\nrelationship analysis.'}, 'authors': [{'name': 'Roldolfo Valentim'}, {'name': 'Giovanni Comarela'}, {'name': 'Souneil Park'}, {'name': 'Diego Saez-Trumper'}], 'author_detail': {'name': 'Diego Saez-Trumper'}, 'author': 'Diego Saez-Trumper', 'arxiv_journal_ref': '15th International Conference on Web and Social Media (ICWSM-21),\n  2021', 'links': [{'href': 'http://arxiv.org/abs/2103.16613v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.16613v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
44,http://arxiv.org/abs/2103.15005v1,2021-03-27 22:18:20+00:00,2021-03-27 22:18:20+00:00,"Strategically-Motivated Advanced Persistent Threat: Definition, Process, Tactics and a Disinformation Model of Counterattack","[arxiv.Result.Author('Atif Ahmad'), arxiv.Result.Author('Jeb Webb'), arxiv.Result.Author('Kevin C. Desouza'), arxiv.Result.Author('James Boorman')]","Advanced persistent threat (APT) is widely acknowledged to be the most
sophisticated and potent class of security threat. APT refers to knowledgeable
human attackers that are organized, highly sophisticated and motivated to
achieve their objectives against a targeted organization(s) over a prolonged
period. Strategically-motivated APTs or S-APTs are distinct in that they draw
their objectives from the broader strategic agenda of third parties such as
criminal syndicates, nation-states, and rival corporations. In this paper we
review the use of the term - Advanced Persistent Threat - and present a formal
definition. We then draw on military science, the science of organized
conflict, for a theoretical basis to develop a rigorous and holistic model of
the stages of an APT operation which we subsequently use to explain how S-APTs
execute their strategically motivated operations using tactics, techniques and
procedures. Finally, we present a general disinformation model, derived from
situation awareness theory, and explain how disinformation can be used to
attack the situation awareness and decision making of not only S-APT operators,
but also the entities that back them.",,"Computers & Security, 2019, Vol 86, pp. 402-418",,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.15005v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.15005v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.15005v1,"{'id': 'http://arxiv.org/abs/2103.15005v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.15005v1', 'updated': '2021-03-27T22:18:20Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=27, tm_hour=22, tm_min=18, tm_sec=20, tm_wday=5, tm_yday=86, tm_isdst=0), 'published': '2021-03-27T22:18:20Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=27, tm_hour=22, tm_min=18, tm_sec=20, tm_wday=5, tm_yday=86, tm_isdst=0), 'title': 'Strategically-Motivated Advanced Persistent Threat: Definition, Process,\n  Tactics and a Disinformation Model of Counterattack', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Strategically-Motivated Advanced Persistent Threat: Definition, Process,\n  Tactics and a Disinformation Model of Counterattack'}, 'summary': 'Advanced persistent threat (APT) is widely acknowledged to be the most\nsophisticated and potent class of security threat. APT refers to knowledgeable\nhuman attackers that are organized, highly sophisticated and motivated to\nachieve their objectives against a targeted organization(s) over a prolonged\nperiod. Strategically-motivated APTs or S-APTs are distinct in that they draw\ntheir objectives from the broader strategic agenda of third parties such as\ncriminal syndicates, nation-states, and rival corporations. In this paper we\nreview the use of the term - Advanced Persistent Threat - and present a formal\ndefinition. We then draw on military science, the science of organized\nconflict, for a theoretical basis to develop a rigorous and holistic model of\nthe stages of an APT operation which we subsequently use to explain how S-APTs\nexecute their strategically motivated operations using tactics, techniques and\nprocedures. Finally, we present a general disinformation model, derived from\nsituation awareness theory, and explain how disinformation can be used to\nattack the situation awareness and decision making of not only S-APT operators,\nbut also the entities that back them.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advanced persistent threat (APT) is widely acknowledged to be the most\nsophisticated and potent class of security threat. APT refers to knowledgeable\nhuman attackers that are organized, highly sophisticated and motivated to\nachieve their objectives against a targeted organization(s) over a prolonged\nperiod. Strategically-motivated APTs or S-APTs are distinct in that they draw\ntheir objectives from the broader strategic agenda of third parties such as\ncriminal syndicates, nation-states, and rival corporations. In this paper we\nreview the use of the term - Advanced Persistent Threat - and present a formal\ndefinition. We then draw on military science, the science of organized\nconflict, for a theoretical basis to develop a rigorous and holistic model of\nthe stages of an APT operation which we subsequently use to explain how S-APTs\nexecute their strategically motivated operations using tactics, techniques and\nprocedures. Finally, we present a general disinformation model, derived from\nsituation awareness theory, and explain how disinformation can be used to\nattack the situation awareness and decision making of not only S-APT operators,\nbut also the entities that back them.'}, 'authors': [{'name': 'Atif Ahmad'}, {'name': 'Jeb Webb'}, {'name': 'Kevin C. Desouza'}, {'name': 'James Boorman'}], 'author_detail': {'name': 'James Boorman'}, 'author': 'James Boorman', 'arxiv_journal_ref': 'Computers & Security, 2019, Vol 86, pp. 402-418', 'links': [{'href': 'http://arxiv.org/abs/2103.15005v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.15005v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
45,http://arxiv.org/abs/2103.13737v1,2021-03-25 10:34:18+00:00,2021-03-25 10:34:18+00:00,Understanding the Puzzle of Primary Health-care Use: Evidence from India,[arxiv.Result.Author('Pramod Kumar Sur')],"In India, households' use of primary health-care services presents a puzzle.
Even though most private health-care providers have no formal medical
qualifications, a significant fraction of households use fee-charging private
health-care services, which are not covered by insurance. Although the absence
of public health-care providers could partially explain the high use of the
private sector, this cannot be the only explanation. The private share of
health-care use is even higher in markets where qualified doctors offer free
care through public clinics; despite this free service, the majority of
health-care visits are made to providers with no formal medical qualifications.
This paper examines the reasons for the existence of this puzzle in India.
Combining contemporary household-level data with archival records, I examine
the aggressive family planning program implemented during the emergency rule in
the 1970s and explore whether the coercion, disinformation, and carelessness
involved in implementing the program could partly explain the puzzle.
Exploiting the timing of the emergency rule, state-level variation in the
number of sterilizations, and an instrumental variable approach, I show that
the states heavily affected by the sterilization policy have a lower level of
public health-care usage today. I demonstrate the mechanism for this practice
by showing that the states heavily affected by forced sterilizations have a
lower level of confidence in government hospitals and doctors and a higher
level of confidence in private hospitals and doctors in providing good
treatment.","58 pages, 8 figures, 18 tables. arXiv admin note: substantial text
  overlap with arXiv:2103.02909",,,econ.GN,"['econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/2103.13737v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.13737v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.13737v1,"{'id': 'http://arxiv.org/abs/2103.13737v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.13737v1', 'updated': '2021-03-25T10:34:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=25, tm_hour=10, tm_min=34, tm_sec=18, tm_wday=3, tm_yday=84, tm_isdst=0), 'published': '2021-03-25T10:34:18Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=25, tm_hour=10, tm_min=34, tm_sec=18, tm_wday=3, tm_yday=84, tm_isdst=0), 'title': 'Understanding the Puzzle of Primary Health-care Use: Evidence from India', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding the Puzzle of Primary Health-care Use: Evidence from India'}, 'summary': ""In India, households' use of primary health-care services presents a puzzle.\nEven though most private health-care providers have no formal medical\nqualifications, a significant fraction of households use fee-charging private\nhealth-care services, which are not covered by insurance. Although the absence\nof public health-care providers could partially explain the high use of the\nprivate sector, this cannot be the only explanation. The private share of\nhealth-care use is even higher in markets where qualified doctors offer free\ncare through public clinics; despite this free service, the majority of\nhealth-care visits are made to providers with no formal medical qualifications.\nThis paper examines the reasons for the existence of this puzzle in India.\nCombining contemporary household-level data with archival records, I examine\nthe aggressive family planning program implemented during the emergency rule in\nthe 1970s and explore whether the coercion, disinformation, and carelessness\ninvolved in implementing the program could partly explain the puzzle.\nExploiting the timing of the emergency rule, state-level variation in the\nnumber of sterilizations, and an instrumental variable approach, I show that\nthe states heavily affected by the sterilization policy have a lower level of\npublic health-care usage today. I demonstrate the mechanism for this practice\nby showing that the states heavily affected by forced sterilizations have a\nlower level of confidence in government hospitals and doctors and a higher\nlevel of confidence in private hospitals and doctors in providing good\ntreatment."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In India, households' use of primary health-care services presents a puzzle.\nEven though most private health-care providers have no formal medical\nqualifications, a significant fraction of households use fee-charging private\nhealth-care services, which are not covered by insurance. Although the absence\nof public health-care providers could partially explain the high use of the\nprivate sector, this cannot be the only explanation. The private share of\nhealth-care use is even higher in markets where qualified doctors offer free\ncare through public clinics; despite this free service, the majority of\nhealth-care visits are made to providers with no formal medical qualifications.\nThis paper examines the reasons for the existence of this puzzle in India.\nCombining contemporary household-level data with archival records, I examine\nthe aggressive family planning program implemented during the emergency rule in\nthe 1970s and explore whether the coercion, disinformation, and carelessness\ninvolved in implementing the program could partly explain the puzzle.\nExploiting the timing of the emergency rule, state-level variation in the\nnumber of sterilizations, and an instrumental variable approach, I show that\nthe states heavily affected by the sterilization policy have a lower level of\npublic health-care usage today. I demonstrate the mechanism for this practice\nby showing that the states heavily affected by forced sterilizations have a\nlower level of confidence in government hospitals and doctors and a higher\nlevel of confidence in private hospitals and doctors in providing good\ntreatment.""}, 'authors': [{'name': 'Pramod Kumar Sur'}], 'author_detail': {'name': 'Pramod Kumar Sur'}, 'author': 'Pramod Kumar Sur', 'arxiv_comment': '58 pages, 8 figures, 18 tables. arXiv admin note: substantial text\n  overlap with arXiv:2103.02909', 'links': [{'href': 'http://arxiv.org/abs/2103.13737v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.13737v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
46,http://arxiv.org/abs/2103.12541v1,2021-03-13 18:04:17+00:00,2021-03-13 18:04:17+00:00,A Survey on Multimodal Disinformation Detection,"[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Stefano Cresci'), arxiv.Result.Author('Tanmoy Chakraborty'), arxiv.Result.Author('Fabrizio Silvestri'), arxiv.Result.Author('Dimiter Dimitrov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Hamed Firooz'), arxiv.Result.Author('Preslav Nakov')]","Recent years have witnessed the proliferation of fake news, propaganda,
misinformation, and disinformation online. While initially this was mostly
about textual content, over time images and videos gained popularity, as they
are much easier to consume, attract much more attention, and spread further
than simple text. As a result, researchers started targeting different
modalities and combinations thereof. As different modalities are studied in
different research communities, with insufficient interaction, here we offer a
survey that explores the state-of-the-art on multimodal disinformation
detection covering various combinations of modalities: text, images, audio,
video, network structure, and temporal information. Moreover, while some
studies focused on factuality, others investigated how harmful the content is.
While these two components in the definition of disinformation -- (i)
factuality and (ii) harmfulness, are equally important, they are typically
studied in isolation. Thus, we argue for the need to tackle disinformation
detection by taking into account multiple modalities as well as both factuality
and harmfulness, in the same framework. Finally, we discuss current challenges
and future research directions.","disinformation, misinformation, factuality, harmfulness, fake news,
  propaganda, multimodality, text, images, videos, network structure,
  temporality",,,cs.MM,"['cs.MM', 'cs.AI', 'cs.CL', 'cs.CR', 'cs.CY', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2103.12541v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.12541v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.12541v1,"{'id': 'http://arxiv.org/abs/2103.12541v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.12541v1', 'updated': '2021-03-13T18:04:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=17, tm_wday=5, tm_yday=72, tm_isdst=0), 'published': '2021-03-13T18:04:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=17, tm_wday=5, tm_yday=72, tm_isdst=0), 'title': 'A Survey on Multimodal Disinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Multimodal Disinformation Detection'}, 'summary': 'Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Stefano Cresci'}, {'name': 'Tanmoy Chakraborty'}, {'name': 'Fabrizio Silvestri'}, {'name': 'Dimiter Dimitrov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Shaden Shaar'}, {'name': 'Hamed Firooz'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality', 'links': [{'href': 'http://arxiv.org/abs/2103.12541v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.12541v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
47,http://arxiv.org/abs/2103.05944v1,2021-03-10 09:01:34+00:00,2021-03-10 09:01:34+00:00,How does Truth Evolve into Fake News? An Empirical Study of Fake News Evolution,"[arxiv.Result.Author('Mingfei Guo'), arxiv.Result.Author('Xiuying Chen'), arxiv.Result.Author('Juntao Li'), arxiv.Result.Author('Dongyan Zhao'), arxiv.Result.Author('Rui Yan')]","Automatically identifying fake news from the Internet is a challenging
problem in deception detection tasks. Online news is modified constantly during
its propagation, e.g., malicious users distort the original truth and make up
fake news. However, the continuous evolution process would generate
unprecedented fake news and cheat the original model. We present the Fake News
Evolution (FNE) dataset: a new dataset tracking the fake news evolution
process. Our dataset is composed of 950 paired data, each of which consists of
articles representing the three significant phases of the evolution process,
which are the truth, the fake news, and the evolved fake news. We observe the
features during the evolution and they are the disinformation techniques, text
similarity, top 10 keywords, classification accuracy, parts of speech, and
sentiment properties.","5 pages, 2 figures","The Web Conference 2021, Workshop on News Recommendation and
  Intelligence",,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.05944v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.05944v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.05944v1,"{'id': 'http://arxiv.org/abs/2103.05944v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.05944v1', 'updated': '2021-03-10T09:01:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=10, tm_hour=9, tm_min=1, tm_sec=34, tm_wday=2, tm_yday=69, tm_isdst=0), 'published': '2021-03-10T09:01:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=10, tm_hour=9, tm_min=1, tm_sec=34, tm_wday=2, tm_yday=69, tm_isdst=0), 'title': 'How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution'}, 'summary': 'Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.'}, 'authors': [{'name': 'Mingfei Guo'}, {'name': 'Xiuying Chen'}, {'name': 'Juntao Li'}, {'name': 'Dongyan Zhao'}, {'name': 'Rui Yan'}], 'author_detail': {'name': 'Rui Yan'}, 'author': 'Rui Yan', 'arxiv_comment': '5 pages, 2 figures', 'arxiv_journal_ref': 'The Web Conference 2021, Workshop on News Recommendation and\n  Intelligence', 'links': [{'href': 'http://arxiv.org/abs/2103.05944v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.05944v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
48,http://arxiv.org/abs/2103.04899v1,2021-03-08 17:01:45+00:00,2021-03-08 17:01:45+00:00,Automatically Selecting Striking Images for Social Cards,"[arxiv.Result.Author('Shawn M. Jones'), arxiv.Result.Author('Michele C. Weigle'), arxiv.Result.Author('Martin Klein'), arxiv.Result.Author('Michael L. Nelson')]","To allow previewing a web page, social media platforms have developed social
cards: visualizations consisting of vital information about the underlying
resource. At a minimum, social cards often include features such as the web
resource's title, text summary, striking image, and domain name. News and
scholarly articles on the web are frequently subject to social card creation
when being shared on social media. However, we noticed that not all web
resources offer sufficient metadata elements to enable appealing social cards.
For example, the COVID-19 emergency has made it clear that scholarly articles,
in particular, are at an aesthetic disadvantage in social media platforms when
compared to their often more flashy disinformation rivals. Also, social cards
are often not generated correctly for archived web resources, including pages
that lack or predate standards for specifying striking images. With these
observations, we are motivated to quantify the levels of inclusion of required
metadata in web resources, its evolution over time for archived resources, and
create and evaluate an algorithm to automatically select a striking image for
social cards. We find that more than 40% of archived news articles sampled from
the NEWSROOM dataset and 22% of scholarly articles sampled from the PubMed
Central dataset fail to supply striking images. We demonstrate that we can
automatically predict the striking image with a Precision@1 of 0.83 for news
articles from NEWSROOM and 0.78 for scholarly articles from the open access
journal PLOS ONE.","10 pages, 5 figures, 10 tables",,,cs.DL,"['cs.DL', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2103.04899v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.04899v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.04899v1,"{'id': 'http://arxiv.org/abs/2103.04899v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.04899v1', 'updated': '2021-03-08T17:01:45Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=8, tm_hour=17, tm_min=1, tm_sec=45, tm_wday=0, tm_yday=67, tm_isdst=0), 'published': '2021-03-08T17:01:45Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=8, tm_hour=17, tm_min=1, tm_sec=45, tm_wday=0, tm_yday=67, tm_isdst=0), 'title': 'Automatically Selecting Striking Images for Social Cards', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatically Selecting Striking Images for Social Cards'}, 'summary': ""To allow previewing a web page, social media platforms have developed social\ncards: visualizations consisting of vital information about the underlying\nresource. At a minimum, social cards often include features such as the web\nresource's title, text summary, striking image, and domain name. News and\nscholarly articles on the web are frequently subject to social card creation\nwhen being shared on social media. However, we noticed that not all web\nresources offer sufficient metadata elements to enable appealing social cards.\nFor example, the COVID-19 emergency has made it clear that scholarly articles,\nin particular, are at an aesthetic disadvantage in social media platforms when\ncompared to their often more flashy disinformation rivals. Also, social cards\nare often not generated correctly for archived web resources, including pages\nthat lack or predate standards for specifying striking images. With these\nobservations, we are motivated to quantify the levels of inclusion of required\nmetadata in web resources, its evolution over time for archived resources, and\ncreate and evaluate an algorithm to automatically select a striking image for\nsocial cards. We find that more than 40% of archived news articles sampled from\nthe NEWSROOM dataset and 22% of scholarly articles sampled from the PubMed\nCentral dataset fail to supply striking images. We demonstrate that we can\nautomatically predict the striking image with a Precision@1 of 0.83 for news\narticles from NEWSROOM and 0.78 for scholarly articles from the open access\njournal PLOS ONE."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""To allow previewing a web page, social media platforms have developed social\ncards: visualizations consisting of vital information about the underlying\nresource. At a minimum, social cards often include features such as the web\nresource's title, text summary, striking image, and domain name. News and\nscholarly articles on the web are frequently subject to social card creation\nwhen being shared on social media. However, we noticed that not all web\nresources offer sufficient metadata elements to enable appealing social cards.\nFor example, the COVID-19 emergency has made it clear that scholarly articles,\nin particular, are at an aesthetic disadvantage in social media platforms when\ncompared to their often more flashy disinformation rivals. Also, social cards\nare often not generated correctly for archived web resources, including pages\nthat lack or predate standards for specifying striking images. With these\nobservations, we are motivated to quantify the levels of inclusion of required\nmetadata in web resources, its evolution over time for archived resources, and\ncreate and evaluate an algorithm to automatically select a striking image for\nsocial cards. We find that more than 40% of archived news articles sampled from\nthe NEWSROOM dataset and 22% of scholarly articles sampled from the PubMed\nCentral dataset fail to supply striking images. We demonstrate that we can\nautomatically predict the striking image with a Precision@1 of 0.83 for news\narticles from NEWSROOM and 0.78 for scholarly articles from the open access\njournal PLOS ONE.""}, 'authors': [{'name': 'Shawn M. Jones'}, {'name': 'Michele C. Weigle'}, {'name': 'Martin Klein'}, {'name': 'Michael L. Nelson'}], 'author_detail': {'name': 'Michael L. Nelson'}, 'author': 'Michael L. Nelson', 'arxiv_comment': '10 pages, 5 figures, 10 tables', 'links': [{'href': 'http://arxiv.org/abs/2103.04899v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.04899v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
49,http://arxiv.org/abs/2103.00242v1,2021-02-27 15:27:22+00:00,2021-02-27 15:27:22+00:00,A Survey on Stance Detection for Mis- and Disinformation Identification,"[arxiv.Result.Author('Momchil Hardalov'), arxiv.Result.Author('Arnav Arora'), arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Isabelle Augenstein')]","Detecting attitudes expressed in texts, also known as stance detection, has
become an important task for the detection of false information online, be it
misinformation (unintentionally false) or disinformation (intentionally false,
spread deliberately with malicious intent). Stance detection has been framed in
different ways, including: (a) as a component of fact-checking, rumour
detection, and detecting previously fact-checked claims; or (b) as a task in
its own right. While there have been prior efforts to contrast stance detection
with other related social media tasks such as argumentation mining and
sentiment analysis, there is no survey examining the relationship between
stance detection detection and mis- and disinformation detection from a
holistic viewpoint, which is the focus of this survey. We review and analyse
existing work in this area, before discussing lessons learnt and future
challenges.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2103.00242v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.00242v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.00242v1,"{'id': 'http://arxiv.org/abs/2103.00242v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.00242v1', 'updated': '2021-02-27T15:27:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=27, tm_hour=15, tm_min=27, tm_sec=22, tm_wday=5, tm_yday=58, tm_isdst=0), 'published': '2021-02-27T15:27:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=27, tm_hour=15, tm_min=27, tm_sec=22, tm_wday=5, tm_yday=58, tm_isdst=0), 'title': 'A Survey on Stance Detection for Mis- and Disinformation Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Stance Detection for Mis- and Disinformation Identification'}, 'summary': 'Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.'}, 'authors': [{'name': 'Momchil Hardalov'}, {'name': 'Arnav Arora'}, {'name': 'Preslav Nakov'}, {'name': 'Isabelle Augenstein'}], 'author_detail': {'name': 'Isabelle Augenstein'}, 'author': 'Isabelle Augenstein', 'links': [{'href': 'http://arxiv.org/abs/2103.00242v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.00242v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
50,http://arxiv.org/abs/2103.00484v1,2021-02-25 18:26:50+00:00,2021-02-25 18:26:50+00:00,"Deepfakes Generation and Detection: State-of-the-art, open challenges, countermeasures, and way forward","[arxiv.Result.Author('Momina Masood'), arxiv.Result.Author('Marriam Nawaz'), arxiv.Result.Author('Khalid Mahmood Malik'), arxiv.Result.Author('Ali Javed'), arxiv.Result.Author('Aun Irtaza')]","Easy access to audio-visual content on social media, combined with the
availability of modern tools such as Tensorflow or Keras, open-source trained
models, and economical computing infrastructure, and the rapid evolution of
deep-learning (DL) methods, especially Generative Adversarial Networks (GAN),
have made it possible to generate deepfakes to disseminate disinformation,
revenge porn, financial frauds, hoaxes, and to disrupt government functioning.
The existing surveys have mainly focused on deepfake video detection only. No
attempt has been made to review approaches for detection and generation of both
audio and video deepfakes. This paper provides a comprehensive review and
detailed analysis of existing tools and machine learning (ML) based approaches
for deepfake generation and the methodologies used to detect such manipulations
for the detection and generation of both audio and video deepfakes. For each
category of deepfake, we discuss information related to manipulation
approaches, current public datasets, and key standards for the performance
evaluation of deepfake detection techniques along with their results.
Additionally, we also discuss open challenges and enumerate future directions
to guide future researchers on issues that need to be considered to improve the
domains of both the deepfake generation and detection. This work is expected to
assist the readers in understanding the creation and detection mechanisms of
deepfake, along with their current limitations and future direction.",,,,cs.CR,"['cs.CR', 'cs.LG', 'cs.SD', 'eess.AS', 'eess.IV']","[arxiv.Result.Link('http://arxiv.org/abs/2103.00484v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.00484v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.00484v1,"{'id': 'http://arxiv.org/abs/2103.00484v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.00484v1', 'updated': '2021-02-25T18:26:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=25, tm_hour=18, tm_min=26, tm_sec=50, tm_wday=3, tm_yday=56, tm_isdst=0), 'published': '2021-02-25T18:26:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=25, tm_hour=18, tm_min=26, tm_sec=50, tm_wday=3, tm_yday=56, tm_isdst=0), 'title': 'Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward'}, 'summary': 'Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.'}, 'authors': [{'name': 'Momina Masood'}, {'name': 'Marriam Nawaz'}, {'name': 'Khalid Mahmood Malik'}, {'name': 'Ali Javed'}, {'name': 'Aun Irtaza'}], 'author_detail': {'name': 'Aun Irtaza'}, 'author': 'Aun Irtaza', 'links': [{'href': 'http://arxiv.org/abs/2103.00484v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.00484v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
51,http://arxiv.org/abs/2101.09251v1,2021-01-22 18:03:57+00:00,2021-01-22 18:03:57+00:00,How to Deal with Fake News: Visualizing Disinformation,"[arxiv.Result.Author('F. Espinoza'), arxiv.Result.Author('Department of Physics'), arxiv.Result.Author('Astronomy'), arxiv.Result.Author('Hofstra University'), arxiv.Result.Author('Hempstead'), arxiv.Result.Author('NY. USA.'), arxiv.Result.Author('Department of Chemistry'), arxiv.Result.Author('Physics-Adolescence Education'), arxiv.Result.Author('SUNY Old Westbury'), arxiv.Result.Author('Old Westbury'), arxiv.Result.Author('NY. USA')]","The current public sense of anxiety in dealing with disinformation as
manifested by so-called fake news is acutely displayed by the reaction to
recent events prompted by a belief in conspiracies among certain groups. A
model to deal with disinformation is proposed; it is based on a demonstration
of the analogous behavior of disinformation to that of wave phenomena. Two
criteria form the basis to combat the deleterious effects of disinformation:
the use of a refractive medium based on skepticism as the default mode, and
polarization as a filter mechanism to analyze its merits based on evidence.
Critical thinking is enhanced since the first one tackles the pernicious effect
of the confirmation bias, and the second the tendency towards attribution, both
of which undermine our efforts to think and act rationally. The benefits of
such a strategy include an epistemic reformulation of disinformation as an
independently existing phenomenon, that removes its negative connotations when
perceived as being possessed by groups or individuals.","Four figures explaining the proposed mechanism that describe wave
  properties and behavior. The quantitative details are kept to a minimum so as
  to highlight the relevance of the treatment of disinformation as a wave, to
  the larger public sphere",,,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.09251v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.09251v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.09251v1,"{'id': 'http://arxiv.org/abs/2101.09251v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.09251v1', 'updated': '2021-01-22T18:03:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=18, tm_min=3, tm_sec=57, tm_wday=4, tm_yday=22, tm_isdst=0), 'published': '2021-01-22T18:03:57Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=18, tm_min=3, tm_sec=57, tm_wday=4, tm_yday=22, tm_isdst=0), 'title': 'How to Deal with Fake News: Visualizing Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How to Deal with Fake News: Visualizing Disinformation'}, 'summary': 'The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.'}, 'authors': [{'name': 'F. Espinoza'}, {'name': 'Department of Physics'}, {'name': 'Astronomy'}, {'name': 'Hofstra University'}, {'name': 'Hempstead'}, {'name': 'NY. USA.'}, {'name': 'Department of Chemistry'}, {'name': 'Physics-Adolescence Education'}, {'name': 'SUNY Old Westbury'}, {'name': 'Old Westbury'}, {'name': 'NY. USA'}], 'author_detail': {'name': 'NY. USA'}, 'author': 'NY. USA', 'arxiv_comment': 'Four figures explaining the proposed mechanism that describe wave\n  properties and behavior. The quantitative details are kept to a minimum so as\n  to highlight the relevance of the treatment of disinformation as a wave, to\n  the larger public sphere', 'links': [{'href': 'http://arxiv.org/abs/2101.09251v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.09251v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
52,http://arxiv.org/abs/2101.09092v1,2021-01-22 13:10:47+00:00,2021-01-22 13:10:47+00:00,Deepfakes and the 2020 US elections: what (did not) happen,[arxiv.Result.Author('João Paulo Meneses')],"Alarmed by the volume of disinformation that was assumed to have taken place
during the 2016 US elections, scholars, politics and journalists predicted the
worst when the first deepfakes began to emerge in 2018. After all, US Elections
2020 were believed to be the most secure in American history. This paper seeks
explanations for an apparent contradiction: we believe that it was precisely
the multiplication and conjugation of different types of warnings and fears
that created the conditions that prevented malicious political deepfakes from
affecting the 2020 US elections. From these warnings, we identified four
factors (more active role of social networks, new laws, difficulties in
accessing Artificial Intelligence and better awareness of society). But while
this formula has proven to be effective in the case of the United States, 2020,
it is not correct to assume that it can be repeated in other political
contexts.",13 pages,,,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.09092v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.09092v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.09092v1,"{'id': 'http://arxiv.org/abs/2101.09092v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.09092v1', 'updated': '2021-01-22T13:10:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=13, tm_min=10, tm_sec=47, tm_wday=4, tm_yday=22, tm_isdst=0), 'published': '2021-01-22T13:10:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=13, tm_min=10, tm_sec=47, tm_wday=4, tm_yday=22, tm_isdst=0), 'title': 'Deepfakes and the 2020 US elections: what (did not) happen', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deepfakes and the 2020 US elections: what (did not) happen'}, 'summary': 'Alarmed by the volume of disinformation that was assumed to have taken place\nduring the 2016 US elections, scholars, politics and journalists predicted the\nworst when the first deepfakes began to emerge in 2018. After all, US Elections\n2020 were believed to be the most secure in American history. This paper seeks\nexplanations for an apparent contradiction: we believe that it was precisely\nthe multiplication and conjugation of different types of warnings and fears\nthat created the conditions that prevented malicious political deepfakes from\naffecting the 2020 US elections. From these warnings, we identified four\nfactors (more active role of social networks, new laws, difficulties in\naccessing Artificial Intelligence and better awareness of society). But while\nthis formula has proven to be effective in the case of the United States, 2020,\nit is not correct to assume that it can be repeated in other political\ncontexts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Alarmed by the volume of disinformation that was assumed to have taken place\nduring the 2016 US elections, scholars, politics and journalists predicted the\nworst when the first deepfakes began to emerge in 2018. After all, US Elections\n2020 were believed to be the most secure in American history. This paper seeks\nexplanations for an apparent contradiction: we believe that it was precisely\nthe multiplication and conjugation of different types of warnings and fears\nthat created the conditions that prevented malicious political deepfakes from\naffecting the 2020 US elections. From these warnings, we identified four\nfactors (more active role of social networks, new laws, difficulties in\naccessing Artificial Intelligence and better awareness of society). But while\nthis formula has proven to be effective in the case of the United States, 2020,\nit is not correct to assume that it can be repeated in other political\ncontexts.'}, 'authors': [{'name': 'João Paulo Meneses'}], 'author_detail': {'name': 'João Paulo Meneses'}, 'author': 'João Paulo Meneses', 'arxiv_comment': '13 pages', 'links': [{'href': 'http://arxiv.org/abs/2101.09092v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.09092v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
53,http://arxiv.org/abs/2101.01142v1,2020-12-28 13:07:42+00:00,2020-12-28 13:07:42+00:00,Advanced Machine Learning Techniques for Fake News (Online Disinformation) Detection: A Systematic Mapping Study,"[arxiv.Result.Author('Michal Choras'), arxiv.Result.Author('Konstantinos Demestichas'), arxiv.Result.Author('Agata Gielczyk'), arxiv.Result.Author('Alvaro Herrero'), arxiv.Result.Author('Pawel Ksieniewicz'), arxiv.Result.Author('Konstantina Remoundou'), arxiv.Result.Author('Daniel Urda'), arxiv.Result.Author('Michal Wozniak')]","Fake news has now grown into a big problem for societies and also a major
challenge for people fighting disinformation. This phenomenon plagues
democratic elections, reputations of individual persons or organizations, and
has negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US
or Brazil). Hence, developing effective tools to fight this phenomenon by
employing advanced Machine Learning (ML) methods poses a significant challenge.
The following paper displays the present body of knowledge on the application
of such intelligent tools in the fight against disinformation. It starts by
showing the historical perspective and the current role of fake news in the
information war. Proposed solutions based solely on the work of experts are
analysed and the most important directions of the application of intelligent
systems in the detection of misinformation sources are pointed out.
Additionally, the paper presents some useful resources (mainly datasets useful
when assessing ML solutions for fake news detection) and provides a short
overview of the most important R&D projects related to this subject. The main
purpose of this work is to analyse the current state of knowledge in detecting
fake news; on the one hand to show possible solutions, and on the other hand to
identify the main challenges and methodological gaps to motivate future
research.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.01142v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.01142v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.01142v1,"{'id': 'http://arxiv.org/abs/2101.01142v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.01142v1', 'updated': '2020-12-28T13:07:42Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=13, tm_min=7, tm_sec=42, tm_wday=0, tm_yday=363, tm_isdst=0), 'published': '2020-12-28T13:07:42Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=13, tm_min=7, tm_sec=42, tm_wday=0, tm_yday=363, tm_isdst=0), 'title': 'Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study'}, 'summary': 'Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.'}, 'authors': [{'name': 'Michal Choras'}, {'name': 'Konstantinos Demestichas'}, {'name': 'Agata Gielczyk'}, {'name': 'Alvaro Herrero'}, {'name': 'Pawel Ksieniewicz'}, {'name': 'Konstantina Remoundou'}, {'name': 'Daniel Urda'}, {'name': 'Michal Wozniak'}], 'author_detail': {'name': 'Michal Wozniak'}, 'author': 'Michal Wozniak', 'links': [{'href': 'http://arxiv.org/abs/2101.01142v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.01142v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
54,http://arxiv.org/abs/2012.11690v2,2020-12-23 15:03:21+00:00,2020-12-21 21:30:58+00:00,Facebook Ad Engagement in the Russian Active Measures Campaign of 2016,"[arxiv.Result.Author('Mirela Silva'), arxiv.Result.Author('Luiz Giovanini'), arxiv.Result.Author('Juliana Fernandes'), arxiv.Result.Author('Daniela Oliveira'), arxiv.Result.Author('Catia S. Silva')]","This paper examines 3,517 Facebook ads created by Russia's Internet Research
Agency (IRA) between June 2015 and August 2017 in its active measures
disinformation campaign targeting the 2016 U.S. general election. We aimed to
unearth the relationship between ad engagement (as measured by ad clicks) and
41 features related to ads' metadata, sociolinguistic structures, and
sentiment. Our analysis was three-fold: (i) understand the relationship between
engagement and features via correlation analysis; (ii) find the most relevant
feature subsets to predict engagement via feature selection; and (iii) find the
semantic topics that best characterize the dataset via topic modeling. We found
that ad expenditure, text size, ad lifetime, and sentiment were the top
features predicting users' engagement to the ads. Additionally, positive
sentiment ads were more engaging than negative ads, and sociolinguistic
features (e.g., use of religion-relevant words) were identified as highly
important in the makeup of an engaging ad. Linear SVM and Logistic Regression
classifiers achieved the highest mean F-scores (93.6% for both models),
determining that the optimal feature subset contains 12 and 6 features,
respectively. Finally, we corroborate the findings of related works that the
IRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,
African American reparations).",,,,cs.CY,"['cs.CY', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.11690v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.11690v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.11690v2,"{'id': 'http://arxiv.org/abs/2012.11690v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.11690v2', 'updated': '2020-12-23T15:03:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=23, tm_hour=15, tm_min=3, tm_sec=21, tm_wday=2, tm_yday=358, tm_isdst=0), 'published': '2020-12-21T21:30:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=21, tm_hour=21, tm_min=30, tm_sec=58, tm_wday=0, tm_yday=356, tm_isdst=0), 'title': 'Facebook Ad Engagement in the Russian Active Measures Campaign of 2016', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Facebook Ad Engagement in the Russian Active Measures Campaign of 2016'}, 'summary': ""This paper examines 3,517 Facebook ads created by Russia's Internet Research\nAgency (IRA) between June 2015 and August 2017 in its active measures\ndisinformation campaign targeting the 2016 U.S. general election. We aimed to\nunearth the relationship between ad engagement (as measured by ad clicks) and\n41 features related to ads' metadata, sociolinguistic structures, and\nsentiment. Our analysis was three-fold: (i) understand the relationship between\nengagement and features via correlation analysis; (ii) find the most relevant\nfeature subsets to predict engagement via feature selection; and (iii) find the\nsemantic topics that best characterize the dataset via topic modeling. We found\nthat ad expenditure, text size, ad lifetime, and sentiment were the top\nfeatures predicting users' engagement to the ads. Additionally, positive\nsentiment ads were more engaging than negative ads, and sociolinguistic\nfeatures (e.g., use of religion-relevant words) were identified as highly\nimportant in the makeup of an engaging ad. Linear SVM and Logistic Regression\nclassifiers achieved the highest mean F-scores (93.6% for both models),\ndetermining that the optimal feature subset contains 12 and 6 features,\nrespectively. Finally, we corroborate the findings of related works that the\nIRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,\nAfrican American reparations)."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper examines 3,517 Facebook ads created by Russia's Internet Research\nAgency (IRA) between June 2015 and August 2017 in its active measures\ndisinformation campaign targeting the 2016 U.S. general election. We aimed to\nunearth the relationship between ad engagement (as measured by ad clicks) and\n41 features related to ads' metadata, sociolinguistic structures, and\nsentiment. Our analysis was three-fold: (i) understand the relationship between\nengagement and features via correlation analysis; (ii) find the most relevant\nfeature subsets to predict engagement via feature selection; and (iii) find the\nsemantic topics that best characterize the dataset via topic modeling. We found\nthat ad expenditure, text size, ad lifetime, and sentiment were the top\nfeatures predicting users' engagement to the ads. Additionally, positive\nsentiment ads were more engaging than negative ads, and sociolinguistic\nfeatures (e.g., use of religion-relevant words) were identified as highly\nimportant in the makeup of an engaging ad. Linear SVM and Logistic Regression\nclassifiers achieved the highest mean F-scores (93.6% for both models),\ndetermining that the optimal feature subset contains 12 and 6 features,\nrespectively. Finally, we corroborate the findings of related works that the\nIRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,\nAfrican American reparations).""}, 'authors': [{'name': 'Mirela Silva'}, {'name': 'Luiz Giovanini'}, {'name': 'Juliana Fernandes'}, {'name': 'Daniela Oliveira'}, {'name': 'Catia S. Silva'}], 'author_detail': {'name': 'Catia S. Silva'}, 'author': 'Catia S. Silva', 'links': [{'href': 'http://arxiv.org/abs/2012.11690v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.11690v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
55,http://arxiv.org/abs/2012.08919v2,2021-01-19 23:02:58+00:00,2020-12-16 13:10:56+00:00,Multilingual Evidence Retrieval and Fact Verification to Combat Global Disinformation: The Power of Polyglotism,[arxiv.Result.Author('Denisa A. O. Roberts')],"This article investigates multilingual evidence retrieval and fact
verification as a step to combat global disinformation, a first effort of this
kind, to the best of our knowledge. The goal is building multilingual systems
that retrieve in evidence-rich languages to verify claims in evidence-poor
languages that are more commonly targeted by disinformation. To this end, our
EnmBERT fact verification system shows evidence of transfer learning ability
and 400 example mixed English-Romanian dataset is made available for
cross-lingual transfer learning evaluation.",Accepted ECIR 2021,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2012.08919v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.08919v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.08919v2,"{'id': 'http://arxiv.org/abs/2012.08919v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.08919v2', 'updated': '2021-01-19T23:02:58Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=19, tm_hour=23, tm_min=2, tm_sec=58, tm_wday=1, tm_yday=19, tm_isdst=0), 'published': '2020-12-16T13:10:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=16, tm_hour=13, tm_min=10, tm_sec=56, tm_wday=2, tm_yday=351, tm_isdst=0), 'title': 'Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism'}, 'summary': 'This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.'}, 'authors': [{'name': 'Denisa A. O. Roberts'}], 'author_detail': {'name': 'Denisa A. O. Roberts'}, 'author': 'Denisa A. O. Roberts', 'arxiv_comment': 'Accepted ECIR 2021', 'links': [{'href': 'http://arxiv.org/abs/2012.08919v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.08919v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
56,http://arxiv.org/abs/2012.08572v1,2020-12-15 19:32:36+00:00,2020-12-15 19:32:36+00:00,An Agenda for Disinformation Research,"[arxiv.Result.Author('Nadya Bliss'), arxiv.Result.Author('Elizabeth Bradley'), arxiv.Result.Author('Joshua Garland'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Scott W. Ruston'), arxiv.Result.Author('Kate Starbird'), arxiv.Result.Author('Chris Wiggins')]","In the 21st Century information environment, adversarial actors use
disinformation to manipulate public opinion. The distribution of false,
misleading, or inaccurate information with the intent to deceive is an
existential threat to the United States--distortion of information erodes trust
in the socio-political institutions that are the fundamental fabric of
democracy: legitimate news sources, scientists, experts, and even fellow
citizens. As a result, it becomes difficult for society to come together within
a shared reality; the common ground needed to function effectively as an
economy and a nation. Computing and communication technologies have facilitated
the exchange of information at unprecedented speeds and scales. This has had
countless benefits to society and the economy, but it has also played a
fundamental role in the rising volume, variety, and velocity of disinformation.
Technological advances have created new opportunities for manipulation,
influence, and deceit. They have effectively lowered the barriers to reaching
large audiences, diminishing the role of traditional mass media along with the
editorial oversight they provided. The digitization of information exchange,
however, also makes the practices of disinformation detectable, the networks of
influence discernable, and suspicious content characterizable. New tools and
approaches must be developed to leverage these affordances to understand and
address this growing challenge.","A Computing Community Consortium (CCC) white paper, 5 pages",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.08572v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.08572v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.08572v1,"{'id': 'http://arxiv.org/abs/2012.08572v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.08572v1', 'updated': '2020-12-15T19:32:36Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=19, tm_min=32, tm_sec=36, tm_wday=1, tm_yday=350, tm_isdst=0), 'published': '2020-12-15T19:32:36Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=19, tm_min=32, tm_sec=36, tm_wday=1, tm_yday=350, tm_isdst=0), 'title': 'An Agenda for Disinformation Research', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Agenda for Disinformation Research'}, 'summary': 'In the 21st Century information environment, adversarial actors use\ndisinformation to manipulate public opinion. The distribution of false,\nmisleading, or inaccurate information with the intent to deceive is an\nexistential threat to the United States--distortion of information erodes trust\nin the socio-political institutions that are the fundamental fabric of\ndemocracy: legitimate news sources, scientists, experts, and even fellow\ncitizens. As a result, it becomes difficult for society to come together within\na shared reality; the common ground needed to function effectively as an\neconomy and a nation. Computing and communication technologies have facilitated\nthe exchange of information at unprecedented speeds and scales. This has had\ncountless benefits to society and the economy, but it has also played a\nfundamental role in the rising volume, variety, and velocity of disinformation.\nTechnological advances have created new opportunities for manipulation,\ninfluence, and deceit. They have effectively lowered the barriers to reaching\nlarge audiences, diminishing the role of traditional mass media along with the\neditorial oversight they provided. The digitization of information exchange,\nhowever, also makes the practices of disinformation detectable, the networks of\ninfluence discernable, and suspicious content characterizable. New tools and\napproaches must be developed to leverage these affordances to understand and\naddress this growing challenge.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the 21st Century information environment, adversarial actors use\ndisinformation to manipulate public opinion. The distribution of false,\nmisleading, or inaccurate information with the intent to deceive is an\nexistential threat to the United States--distortion of information erodes trust\nin the socio-political institutions that are the fundamental fabric of\ndemocracy: legitimate news sources, scientists, experts, and even fellow\ncitizens. As a result, it becomes difficult for society to come together within\na shared reality; the common ground needed to function effectively as an\neconomy and a nation. Computing and communication technologies have facilitated\nthe exchange of information at unprecedented speeds and scales. This has had\ncountless benefits to society and the economy, but it has also played a\nfundamental role in the rising volume, variety, and velocity of disinformation.\nTechnological advances have created new opportunities for manipulation,\ninfluence, and deceit. They have effectively lowered the barriers to reaching\nlarge audiences, diminishing the role of traditional mass media along with the\neditorial oversight they provided. The digitization of information exchange,\nhowever, also makes the practices of disinformation detectable, the networks of\ninfluence discernable, and suspicious content characterizable. New tools and\napproaches must be developed to leverage these affordances to understand and\naddress this growing challenge.'}, 'authors': [{'name': 'Nadya Bliss'}, {'name': 'Elizabeth Bradley'}, {'name': 'Joshua Garland'}, {'name': 'Filippo Menczer'}, {'name': 'Scott W. Ruston'}, {'name': 'Kate Starbird'}, {'name': 'Chris Wiggins'}], 'author_detail': {'name': 'Chris Wiggins'}, 'author': 'Chris Wiggins', 'arxiv_comment': 'A Computing Community Consortium (CCC) white paper, 5 pages', 'links': [{'href': 'http://arxiv.org/abs/2012.08572v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.08572v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
57,http://arxiv.org/abs/2012.08968v1,2020-12-15 14:06:32+00:00,2020-12-15 14:06:32+00:00,The Impact of Cyber Security Threats on the 2020 US Elections,[arxiv.Result.Author('Nicholas Stedmon')],"This paper will investigate the literature surrounding cyber security threats
in the 2020 US Elections. It begins with a brief overview of cyber security and
the current state of cyber security regarding elections. In the main body of
the paper, the focus will be on the literature review of three main areas:
voter suppression, voter fraud, and disinformation, considering their impacts
on the outcome of the election and on the voting public. Having evaluated
sources on each this paper concludes by summarising the areas which have had
the greatest impact on the 2020 US elections.",3 pages,,,cs.CR,"['cs.CR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2012.08968v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.08968v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.08968v1,"{'id': 'http://arxiv.org/abs/2012.08968v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.08968v1', 'updated': '2020-12-15T14:06:32Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=14, tm_min=6, tm_sec=32, tm_wday=1, tm_yday=350, tm_isdst=0), 'published': '2020-12-15T14:06:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=14, tm_min=6, tm_sec=32, tm_wday=1, tm_yday=350, tm_isdst=0), 'title': 'The Impact of Cyber Security Threats on the 2020 US Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Impact of Cyber Security Threats on the 2020 US Elections'}, 'summary': 'This paper will investigate the literature surrounding cyber security threats\nin the 2020 US Elections. It begins with a brief overview of cyber security and\nthe current state of cyber security regarding elections. In the main body of\nthe paper, the focus will be on the literature review of three main areas:\nvoter suppression, voter fraud, and disinformation, considering their impacts\non the outcome of the election and on the voting public. Having evaluated\nsources on each this paper concludes by summarising the areas which have had\nthe greatest impact on the 2020 US elections.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper will investigate the literature surrounding cyber security threats\nin the 2020 US Elections. It begins with a brief overview of cyber security and\nthe current state of cyber security regarding elections. In the main body of\nthe paper, the focus will be on the literature review of three main areas:\nvoter suppression, voter fraud, and disinformation, considering their impacts\non the outcome of the election and on the voting public. Having evaluated\nsources on each this paper concludes by summarising the areas which have had\nthe greatest impact on the 2020 US elections.'}, 'authors': [{'name': 'Nicholas Stedmon'}], 'author_detail': {'name': 'Nicholas Stedmon'}, 'author': 'Nicholas Stedmon', 'arxiv_comment': '3 pages', 'links': [{'href': 'http://arxiv.org/abs/2012.08968v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.08968v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
58,http://arxiv.org/abs/2012.04778v2,2020-12-13 04:56:25+00:00,2020-12-08 22:54:35+00:00,Fact-Enhanced Synthetic News Generation,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Yichuan Li'), arxiv.Result.Author('Kaize Ding'), arxiv.Result.Author('Huan Liu')]","The advanced text generation methods have witnessed great success in text
summarization, language translation, and synthetic news generation. However,
these techniques can be abused to generate disinformation and fake news. To
better understand the potential threats of synthetic news, we develop a new
generation method FactGen to generate high-quality news content. The existing
text generation methods either afford limited supplementary information or lose
consistency between the input and output which makes the synthetic news less
trustworthy. To address these issues, FactGen retrieves external facts to
enrich the output and reconstructs the input claim from the generated content
to improve the consistency among the input and the output. Experiment results
on real-world datasets show that the generated news contents of FactGen are
consistent and contain rich facts. We also discuss the possible defending
method to identify these synthetic news pieces if FactGen is used to generate
synthetic news.",AAAI 2021 Preprint Version,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.04778v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.04778v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.04778v2,"{'id': 'http://arxiv.org/abs/2012.04778v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.04778v2', 'updated': '2020-12-13T04:56:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=13, tm_hour=4, tm_min=56, tm_sec=25, tm_wday=6, tm_yday=348, tm_isdst=0), 'published': '2020-12-08T22:54:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=22, tm_min=54, tm_sec=35, tm_wday=1, tm_yday=343, tm_isdst=0), 'title': 'Fact-Enhanced Synthetic News Generation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact-Enhanced Synthetic News Generation'}, 'summary': 'The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Yichuan Li'}, {'name': 'Kaize Ding'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'AAAI 2021 Preprint Version', 'links': [{'href': 'http://arxiv.org/abs/2012.04778v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.04778v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
59,http://arxiv.org/abs/2012.04726v1,2020-12-08 20:30:43+00:00,2020-12-08 20:30:43+00:00,Edited Media Understanding: Reasoning About Implications of Manipulated Images,"[arxiv.Result.Author('Jeff Da'), arxiv.Result.Author('Maxwell Forbes'), arxiv.Result.Author('Rowan Zellers'), arxiv.Result.Author('Anthony Zheng'), arxiv.Result.Author('Jena D. Hwang'), arxiv.Result.Author('Antoine Bosselut'), arxiv.Result.Author('Yejin Choi')]","Multimodal disinformation, from `deepfakes' to simple edits that deceive, is
an important societal problem. Yet at the same time, the vast majority of media
edits are harmless -- such as a filtered vacation photo. The difference between
this example, and harmful edits that spread disinformation, is one of intent.
Recognizing and describing this intent is a major challenge for today's AI
systems.
  We present the task of Edited Media Understanding, requiring models to answer
open-ended questions that capture the intent and implications of an image edit.
We introduce a dataset for our task, EMU, with 48k question-answer pairs
written in rich natural language. We evaluate a wide variety of
vision-and-language models for our task, and introduce a new model PELICAN,
which builds upon recent progress in pretrained multimodal representations. Our
model obtains promising results on our dataset, with humans rating its answers
as accurate 40.35% of the time. At the same time, there is still much work to
be done -- humans prefer human-annotated captions 93.56% of the time -- and we
provide analysis that highlights areas for further progress.",,,,cs.CL,"['cs.CL', 'cs.CV']","[arxiv.Result.Link('http://arxiv.org/abs/2012.04726v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.04726v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.04726v1,"{'id': 'http://arxiv.org/abs/2012.04726v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.04726v1', 'updated': '2020-12-08T20:30:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=20, tm_min=30, tm_sec=43, tm_wday=1, tm_yday=343, tm_isdst=0), 'published': '2020-12-08T20:30:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=20, tm_min=30, tm_sec=43, tm_wday=1, tm_yday=343, tm_isdst=0), 'title': 'Edited Media Understanding: Reasoning About Implications of Manipulated\n  Images', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Edited Media Understanding: Reasoning About Implications of Manipulated\n  Images'}, 'summary': ""Multimodal disinformation, from `deepfakes' to simple edits that deceive, is\nan important societal problem. Yet at the same time, the vast majority of media\nedits are harmless -- such as a filtered vacation photo. The difference between\nthis example, and harmful edits that spread disinformation, is one of intent.\nRecognizing and describing this intent is a major challenge for today's AI\nsystems.\n  We present the task of Edited Media Understanding, requiring models to answer\nopen-ended questions that capture the intent and implications of an image edit.\nWe introduce a dataset for our task, EMU, with 48k question-answer pairs\nwritten in rich natural language. We evaluate a wide variety of\nvision-and-language models for our task, and introduce a new model PELICAN,\nwhich builds upon recent progress in pretrained multimodal representations. Our\nmodel obtains promising results on our dataset, with humans rating its answers\nas accurate 40.35% of the time. At the same time, there is still much work to\nbe done -- humans prefer human-annotated captions 93.56% of the time -- and we\nprovide analysis that highlights areas for further progress."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Multimodal disinformation, from `deepfakes' to simple edits that deceive, is\nan important societal problem. Yet at the same time, the vast majority of media\nedits are harmless -- such as a filtered vacation photo. The difference between\nthis example, and harmful edits that spread disinformation, is one of intent.\nRecognizing and describing this intent is a major challenge for today's AI\nsystems.\n  We present the task of Edited Media Understanding, requiring models to answer\nopen-ended questions that capture the intent and implications of an image edit.\nWe introduce a dataset for our task, EMU, with 48k question-answer pairs\nwritten in rich natural language. We evaluate a wide variety of\nvision-and-language models for our task, and introduce a new model PELICAN,\nwhich builds upon recent progress in pretrained multimodal representations. Our\nmodel obtains promising results on our dataset, with humans rating its answers\nas accurate 40.35% of the time. At the same time, there is still much work to\nbe done -- humans prefer human-annotated captions 93.56% of the time -- and we\nprovide analysis that highlights areas for further progress.""}, 'authors': [{'name': 'Jeff Da'}, {'name': 'Maxwell Forbes'}, {'name': 'Rowan Zellers'}, {'name': 'Anthony Zheng'}, {'name': 'Jena D. Hwang'}, {'name': 'Antoine Bosselut'}, {'name': 'Yejin Choi'}], 'author_detail': {'name': 'Yejin Choi'}, 'author': 'Yejin Choi', 'links': [{'href': 'http://arxiv.org/abs/2012.04726v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.04726v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
60,http://arxiv.org/abs/2012.02586v2,2020-12-07 03:00:54+00:00,2020-12-04 13:46:42+00:00,TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls During the COVID-19 Pandemic,"[arxiv.Result.Author('Peter Jachim'), arxiv.Result.Author('Filipo Sharevski'), arxiv.Result.Author('Paige Treebridge')]","This paper presents TrollHunter, an automated reasoning mechanism we used to
hunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised
to disrupt the online discourse and spread disinformation, quickly seized the
absence of a credible response to COVID-19 and created a COVID-19 infodemic by
promulgating dubious content on Twitter. To counter the COVID-19 infodemic, the
TrollHunter leverages a unique linguistic analysis of a multi-dimensional set
of Twitter content features to detect whether or not a tweet was meant to
troll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall
over a dataset of 1.3 million tweets. Without a final resolution of the
pandemic in sight, it is unlikely that the trolls will go away, although they
might be forced to evade automated hunting. To explore the plausibility of this
strategy, we developed and tested an adversarial machine learning mechanism
called TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)
approach in a combination with a Markov chain-based mechanism to recycle
originally trolling tweets. The recycled tweets were able to achieve a
remarkable 40% decrease in the TrollHunter's ability to correctly identify
trolling tweets. Because the COVID-19 infodemic could have a harmful impact on
the COVID-19 pandemic, we provide an elaborate discussion about the
implications of employing adversarial machine learning to evade Twitter troll
hunts.",Accepted for publication at NSPW 2020,New Security Paradigms Workshop (NSPW) 2020,,cs.CR,"['cs.CR', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.02586v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.02586v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.02586v2,"{'id': 'http://arxiv.org/abs/2012.02586v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.02586v2', 'updated': '2020-12-07T03:00:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=7, tm_hour=3, tm_min=0, tm_sec=54, tm_wday=0, tm_yday=342, tm_isdst=0), 'published': '2020-12-04T13:46:42Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=4, tm_hour=13, tm_min=46, tm_sec=42, tm_wday=4, tm_yday=339, tm_isdst=0), 'title': 'TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls\n  During the COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls\n  During the COVID-19 Pandemic'}, 'summary': ""This paper presents TrollHunter, an automated reasoning mechanism we used to\nhunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised\nto disrupt the online discourse and spread disinformation, quickly seized the\nabsence of a credible response to COVID-19 and created a COVID-19 infodemic by\npromulgating dubious content on Twitter. To counter the COVID-19 infodemic, the\nTrollHunter leverages a unique linguistic analysis of a multi-dimensional set\nof Twitter content features to detect whether or not a tweet was meant to\ntroll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall\nover a dataset of 1.3 million tweets. Without a final resolution of the\npandemic in sight, it is unlikely that the trolls will go away, although they\nmight be forced to evade automated hunting. To explore the plausibility of this\nstrategy, we developed and tested an adversarial machine learning mechanism\ncalled TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)\napproach in a combination with a Markov chain-based mechanism to recycle\noriginally trolling tweets. The recycled tweets were able to achieve a\nremarkable 40% decrease in the TrollHunter's ability to correctly identify\ntrolling tweets. Because the COVID-19 infodemic could have a harmful impact on\nthe COVID-19 pandemic, we provide an elaborate discussion about the\nimplications of employing adversarial machine learning to evade Twitter troll\nhunts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper presents TrollHunter, an automated reasoning mechanism we used to\nhunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised\nto disrupt the online discourse and spread disinformation, quickly seized the\nabsence of a credible response to COVID-19 and created a COVID-19 infodemic by\npromulgating dubious content on Twitter. To counter the COVID-19 infodemic, the\nTrollHunter leverages a unique linguistic analysis of a multi-dimensional set\nof Twitter content features to detect whether or not a tweet was meant to\ntroll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall\nover a dataset of 1.3 million tweets. Without a final resolution of the\npandemic in sight, it is unlikely that the trolls will go away, although they\nmight be forced to evade automated hunting. To explore the plausibility of this\nstrategy, we developed and tested an adversarial machine learning mechanism\ncalled TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)\napproach in a combination with a Markov chain-based mechanism to recycle\noriginally trolling tweets. The recycled tweets were able to achieve a\nremarkable 40% decrease in the TrollHunter's ability to correctly identify\ntrolling tweets. Because the COVID-19 infodemic could have a harmful impact on\nthe COVID-19 pandemic, we provide an elaborate discussion about the\nimplications of employing adversarial machine learning to evade Twitter troll\nhunts.""}, 'authors': [{'name': 'Peter Jachim'}, {'name': 'Filipo Sharevski'}, {'name': 'Paige Treebridge'}], 'author_detail': {'name': 'Paige Treebridge'}, 'author': 'Paige Treebridge', 'arxiv_comment': 'Accepted for publication at NSPW 2020', 'arxiv_journal_ref': 'New Security Paradigms Workshop (NSPW) 2020', 'links': [{'href': 'http://arxiv.org/abs/2012.02586v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.02586v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
61,http://arxiv.org/abs/2011.11278v2,2020-12-10 04:10:21+00:00,2020-11-23 08:47:40+00:00,FakeSafe: Human Level Data Protection by Disinformation Mapping using Cycle-consistent Adversarial Network,"[arxiv.Result.Author('He Zhu'), arxiv.Result.Author('Dianbo Liu')]","The concept of disinformation is to use fake messages to confuse people in
order to protect the real information. This strategy can be adapted into data
science to protect valuable private and sensitive data. Huge amount of private
data are being generated from personal devices such as smart phone and wearable
in recent years. Being able to utilize these personal data will bring big
opportunities to design personalized products, conduct precision healthcare and
many other tasks that were impossible in the past. However, due to privacy,
safety and regulation reasons, it is often difficult to transfer or store data
in its original form while keeping them safe. Building a secure data transfer
and storage infrastructure to preserving privacy is costly in most cases and
there is always a concern of data security due to human errors. In this study,
we propose a method, named FakeSafe, to provide human level data protection
using generative adversarial network with cycle consistency and conducted
experiments using both benchmark and real world data sets to illustrate
potential applications of FakeSafe.",,,,cs.AI,['cs.AI'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.11278v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.11278v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.11278v2,"{'id': 'http://arxiv.org/abs/2011.11278v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.11278v2', 'updated': '2020-12-10T04:10:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=10, tm_hour=4, tm_min=10, tm_sec=21, tm_wday=3, tm_yday=345, tm_isdst=0), 'published': '2020-11-23T08:47:40Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=23, tm_hour=8, tm_min=47, tm_sec=40, tm_wday=0, tm_yday=328, tm_isdst=0), 'title': 'FakeSafe: Human Level Data Protection by Disinformation Mapping using\n  Cycle-consistent Adversarial Network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeSafe: Human Level Data Protection by Disinformation Mapping using\n  Cycle-consistent Adversarial Network'}, 'summary': 'The concept of disinformation is to use fake messages to confuse people in\norder to protect the real information. This strategy can be adapted into data\nscience to protect valuable private and sensitive data. Huge amount of private\ndata are being generated from personal devices such as smart phone and wearable\nin recent years. Being able to utilize these personal data will bring big\nopportunities to design personalized products, conduct precision healthcare and\nmany other tasks that were impossible in the past. However, due to privacy,\nsafety and regulation reasons, it is often difficult to transfer or store data\nin its original form while keeping them safe. Building a secure data transfer\nand storage infrastructure to preserving privacy is costly in most cases and\nthere is always a concern of data security due to human errors. In this study,\nwe propose a method, named FakeSafe, to provide human level data protection\nusing generative adversarial network with cycle consistency and conducted\nexperiments using both benchmark and real world data sets to illustrate\npotential applications of FakeSafe.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The concept of disinformation is to use fake messages to confuse people in\norder to protect the real information. This strategy can be adapted into data\nscience to protect valuable private and sensitive data. Huge amount of private\ndata are being generated from personal devices such as smart phone and wearable\nin recent years. Being able to utilize these personal data will bring big\nopportunities to design personalized products, conduct precision healthcare and\nmany other tasks that were impossible in the past. However, due to privacy,\nsafety and regulation reasons, it is often difficult to transfer or store data\nin its original form while keeping them safe. Building a secure data transfer\nand storage infrastructure to preserving privacy is costly in most cases and\nthere is always a concern of data security due to human errors. In this study,\nwe propose a method, named FakeSafe, to provide human level data protection\nusing generative adversarial network with cycle consistency and conducted\nexperiments using both benchmark and real world data sets to illustrate\npotential applications of FakeSafe.'}, 'authors': [{'name': 'He Zhu'}, {'name': 'Dianbo Liu'}], 'author_detail': {'name': 'Dianbo Liu'}, 'author': 'Dianbo Liu', 'links': [{'href': 'http://arxiv.org/abs/2011.11278v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.11278v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
62,http://arxiv.org/abs/2011.05367v1,2020-11-10 19:38:03+00:00,2020-11-10 19:38:03+00:00,Detecting Social Media Manipulation in Low-Resource Languages,"[arxiv.Result.Author('Samar Haider'), arxiv.Result.Author('Luca Luceri'), arxiv.Result.Author('Ashok Deb'), arxiv.Result.Author('Adam Badawy'), arxiv.Result.Author('Nanyun Peng'), arxiv.Result.Author('Emilio Ferrara')]","Social media have been deliberately used for malicious purposes, including
political manipulation and disinformation. Most research focuses on
high-resource languages. However, malicious actors share content across
countries and languages, including low-resource ones. Here, we investigate
whether and to what extent malicious actors can be detected in low-resource
language settings. We discovered that a high number of accounts posting in
Tagalog were suspended as part of Twitter's crackdown on interference
operations after the 2016 US Presidential election. By combining text embedding
and transfer learning, our framework can detect, with promising accuracy,
malicious users posting in Tagalog without any prior knowledge or training on
malicious content in that language. We first learn an embedding model for each
language, namely a high-resource language (English) and a low-resource one
(Tagalog), independently. Then, we learn a mapping between the two latent
spaces to transfer the detection model. We demonstrate that the proposed
approach significantly outperforms state-of-the-art models, including BERT, and
yields marked advantages in settings with very limited training data-the norm
when dealing with detecting malicious activity in online platforms.",,,,cs.SI,"['cs.SI', 'cs.AI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2011.05367v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.05367v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.05367v1,"{'id': 'http://arxiv.org/abs/2011.05367v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.05367v1', 'updated': '2020-11-10T19:38:03Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=19, tm_min=38, tm_sec=3, tm_wday=1, tm_yday=315, tm_isdst=0), 'published': '2020-11-10T19:38:03Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=19, tm_min=38, tm_sec=3, tm_wday=1, tm_yday=315, tm_isdst=0), 'title': 'Detecting Social Media Manipulation in Low-Resource Languages', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Social Media Manipulation in Low-Resource Languages'}, 'summary': ""Social media have been deliberately used for malicious purposes, including\npolitical manipulation and disinformation. Most research focuses on\nhigh-resource languages. However, malicious actors share content across\ncountries and languages, including low-resource ones. Here, we investigate\nwhether and to what extent malicious actors can be detected in low-resource\nlanguage settings. We discovered that a high number of accounts posting in\nTagalog were suspended as part of Twitter's crackdown on interference\noperations after the 2016 US Presidential election. By combining text embedding\nand transfer learning, our framework can detect, with promising accuracy,\nmalicious users posting in Tagalog without any prior knowledge or training on\nmalicious content in that language. We first learn an embedding model for each\nlanguage, namely a high-resource language (English) and a low-resource one\n(Tagalog), independently. Then, we learn a mapping between the two latent\nspaces to transfer the detection model. We demonstrate that the proposed\napproach significantly outperforms state-of-the-art models, including BERT, and\nyields marked advantages in settings with very limited training data-the norm\nwhen dealing with detecting malicious activity in online platforms."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media have been deliberately used for malicious purposes, including\npolitical manipulation and disinformation. Most research focuses on\nhigh-resource languages. However, malicious actors share content across\ncountries and languages, including low-resource ones. Here, we investigate\nwhether and to what extent malicious actors can be detected in low-resource\nlanguage settings. We discovered that a high number of accounts posting in\nTagalog were suspended as part of Twitter's crackdown on interference\noperations after the 2016 US Presidential election. By combining text embedding\nand transfer learning, our framework can detect, with promising accuracy,\nmalicious users posting in Tagalog without any prior knowledge or training on\nmalicious content in that language. We first learn an embedding model for each\nlanguage, namely a high-resource language (English) and a low-resource one\n(Tagalog), independently. Then, we learn a mapping between the two latent\nspaces to transfer the detection model. We demonstrate that the proposed\napproach significantly outperforms state-of-the-art models, including BERT, and\nyields marked advantages in settings with very limited training data-the norm\nwhen dealing with detecting malicious activity in online platforms.""}, 'authors': [{'name': 'Samar Haider'}, {'name': 'Luca Luceri'}, {'name': 'Ashok Deb'}, {'name': 'Adam Badawy'}, {'name': 'Nanyun Peng'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'links': [{'href': 'http://arxiv.org/abs/2011.05367v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.05367v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
63,http://arxiv.org/abs/2011.05416v1,2020-11-09 04:15:44+00:00,2020-11-09 04:15:44+00:00,Challenges and Opportunities in Rapid Epidemic Information Propagation with Live Knowledge Aggregation from Social Media,"[arxiv.Result.Author('Calton Pu'), arxiv.Result.Author('Abhijit Suprem'), arxiv.Result.Author('Rodrigo Alves Lima')]","A rapidly evolving situation such as the COVID-19 pandemic is a significant
challenge for AI/ML models because of its unpredictability. %The most reliable
indicator of the pandemic spreading has been the number of test positive cases.
However, the tests are both incomplete (due to untested asymptomatic cases) and
late (due the lag from the initial contact event, worsening symptoms, and test
results). Social media can complement physical test data due to faster and
higher coverage, but they present a different challenge: significant amounts of
noise, misinformation and disinformation. We believe that social media can
become good indicators of pandemic, provided two conditions are met. The first
(True Novelty) is the capture of new, previously unknown, information from
unpredictably evolving situations. The second (Fact vs. Fiction) is the
distinction of verifiable facts from misinformation and disinformation. Social
media information that satisfy those two conditions are called live knowledge.
We apply evidence-based knowledge acquisition (EBKA) approach to collect,
filter, and update live knowledge through the integration of social media
sources with authoritative sources. Although limited in quantity, the reliable
training data from authoritative sources enable the filtering of misinformation
as well as capturing truly new information. We describe the EDNA/LITMUS tools
that implement EBKA, integrating social media such as Twitter and Facebook with
authoritative sources such as WHO and CDC, creating and updating live knowledge
on the COVID-19 pandemic.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2011.05416v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.05416v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.05416v1,"{'id': 'http://arxiv.org/abs/2011.05416v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.05416v1', 'updated': '2020-11-09T04:15:44Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=9, tm_hour=4, tm_min=15, tm_sec=44, tm_wday=0, tm_yday=314, tm_isdst=0), 'published': '2020-11-09T04:15:44Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=9, tm_hour=4, tm_min=15, tm_sec=44, tm_wday=0, tm_yday=314, tm_isdst=0), 'title': 'Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media'}, 'summary': 'A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.'}, 'authors': [{'name': 'Calton Pu'}, {'name': 'Abhijit Suprem'}, {'name': 'Rodrigo Alves Lima'}], 'author_detail': {'name': 'Rodrigo Alves Lima'}, 'author': 'Rodrigo Alves Lima', 'links': [{'href': 'http://arxiv.org/abs/2011.05416v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.05416v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
64,http://arxiv.org/abs/2011.02787v1,2020-11-05 12:36:16+00:00,2020-11-05 12:36:16+00:00,The State of AI Ethics Report (October 2020),"[arxiv.Result.Author('Abhishek Gupta'), arxiv.Result.Author('Alexandrine Royer'), arxiv.Result.Author('Victoria Heath'), arxiv.Result.Author('Connor Wright'), arxiv.Result.Author('Camylle Lanteigne'), arxiv.Result.Author('Allison Cohen'), arxiv.Result.Author('Marianna Bergamaschi Ganapini'), arxiv.Result.Author('Muriam Fancy'), arxiv.Result.Author('Erick Galinkin'), arxiv.Result.Author('Ryan Khurana'), arxiv.Result.Author('Mo Akif'), arxiv.Result.Author('Renjie Butalid'), arxiv.Result.Author('Falaah Arif Khan'), arxiv.Result.Author('Masa Sweidan'), arxiv.Result.Author('Audrey Balogh')]","The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics
captures the most relevant developments in the field of AI Ethics since July
2020. This report aims to help anyone, from machine learning experts to human
rights activists and policymakers, quickly digest and understand the
ever-changing developments in the field. Through research and article
summaries, as well as expert commentary, this report distills the research and
reporting surrounding various domains related to the ethics of AI, including:
AI and society, bias and algorithmic justice, disinformation, humans and AI,
labor impacts, privacy, risk, and future of AI ethics.
  In addition, The State of AI Ethics includes exclusive content written by
world-class AI Ethics experts from universities, research institutes,
consulting firms, and governments. These experts include: Danit Gal (Tech
Advisor, United Nations), Amba Kak (Director of Global Policy and Programs,
NYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,
Accenture), Brent Barron (Director of Strategic Projects and Knowledge
Management, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of
the OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of
Management), and Katya Klinova (AI and Economy Program Lead, Partnership on
AI).
  This report should be used not only as a point of reference and insight on
the latest thinking in the field of AI Ethics, but should also be used as a
tool for introspection as we aim to foster a more nuanced conversation
regarding the impacts of AI on the world.",158 pages,,,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2011.02787v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.02787v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.02787v1,"{'id': 'http://arxiv.org/abs/2011.02787v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.02787v1', 'updated': '2020-11-05T12:36:16Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=5, tm_hour=12, tm_min=36, tm_sec=16, tm_wday=3, tm_yday=310, tm_isdst=0), 'published': '2020-11-05T12:36:16Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=5, tm_hour=12, tm_min=36, tm_sec=16, tm_wday=3, tm_yday=310, tm_isdst=0), 'title': 'The State of AI Ethics Report (October 2020)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The State of AI Ethics Report (October 2020)'}, 'summary': ""The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in the field of AI Ethics since July\n2020. This report aims to help anyone, from machine learning experts to human\nrights activists and policymakers, quickly digest and understand the\never-changing developments in the field. Through research and article\nsummaries, as well as expert commentary, this report distills the research and\nreporting surrounding various domains related to the ethics of AI, including:\nAI and society, bias and algorithmic justice, disinformation, humans and AI,\nlabor impacts, privacy, risk, and future of AI ethics.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. These experts include: Danit Gal (Tech\nAdvisor, United Nations), Amba Kak (Director of Global Policy and Programs,\nNYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,\nAccenture), Brent Barron (Director of Strategic Projects and Knowledge\nManagement, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of\nthe OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of\nManagement), and Katya Klinova (AI and Economy Program Lead, Partnership on\nAI).\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in the field of AI Ethics since July\n2020. This report aims to help anyone, from machine learning experts to human\nrights activists and policymakers, quickly digest and understand the\never-changing developments in the field. Through research and article\nsummaries, as well as expert commentary, this report distills the research and\nreporting surrounding various domains related to the ethics of AI, including:\nAI and society, bias and algorithmic justice, disinformation, humans and AI,\nlabor impacts, privacy, risk, and future of AI ethics.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. These experts include: Danit Gal (Tech\nAdvisor, United Nations), Amba Kak (Director of Global Policy and Programs,\nNYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,\nAccenture), Brent Barron (Director of Strategic Projects and Knowledge\nManagement, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of\nthe OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of\nManagement), and Katya Klinova (AI and Economy Program Lead, Partnership on\nAI).\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.""}, 'authors': [{'name': 'Abhishek Gupta'}, {'name': 'Alexandrine Royer'}, {'name': 'Victoria Heath'}, {'name': 'Connor Wright'}, {'name': 'Camylle Lanteigne'}, {'name': 'Allison Cohen'}, {'name': 'Marianna Bergamaschi Ganapini'}, {'name': 'Muriam Fancy'}, {'name': 'Erick Galinkin'}, {'name': 'Ryan Khurana'}, {'name': 'Mo Akif'}, {'name': 'Renjie Butalid'}, {'name': 'Falaah Arif Khan'}, {'name': 'Masa Sweidan'}, {'name': 'Audrey Balogh'}], 'author_detail': {'name': 'Audrey Balogh'}, 'arxiv_affiliation': 'McGill University', 'author': 'Audrey Balogh', 'arxiv_comment': '158 pages', 'links': [{'href': 'http://arxiv.org/abs/2011.02787v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.02787v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
65,http://arxiv.org/abs/2011.01579v2,2021-01-29 12:10:26+00:00,2020-11-03 09:09:51+00:00,Fake News Detection through Graph Comment Advanced Learning,"[arxiv.Result.Author('Hao Liao'), arxiv.Result.Author('Qixin Liu'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Xing xie')]","Disinformation has long been regarded as a severe social problem, where fake
news is one of the most representative issues. What is worse, today's highly
developed social media makes fake news widely spread at incredible speed,
bringing in substantial harm to various aspects of human life. Yet, the
popularity of social media also provides opportunities to better detect fake
news. Unlike conventional means which merely focus on either content or user
comments, effective collaboration of heterogeneous social media information,
including content and context factors of news, users' comments and the
engagement of social media with users, will hopefully give rise to better
detection of fake news.
  Motivated by the above observations, a novel detection framework, namely
graph comment-user advanced learning framework (GCAL) is proposed in this
paper. User-comment information is crucial but not well studied in fake news
detection. Thus, we model user-comment context through network representation
learning based on heterogeneous graph neural network. We conduct experiments on
two real-world datasets, which demonstrate that the proposed joint model
outperforms 8 state-of-the-art baseline methods for fake news detection (at
least 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method
is also explainable.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.01579v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.01579v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.01579v2,"{'id': 'http://arxiv.org/abs/2011.01579v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.01579v2', 'updated': '2021-01-29T12:10:26Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=29, tm_hour=12, tm_min=10, tm_sec=26, tm_wday=4, tm_yday=29, tm_isdst=0), 'published': '2020-11-03T09:09:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=9, tm_min=9, tm_sec=51, tm_wday=1, tm_yday=308, tm_isdst=0), 'title': 'Fake News Detection through Graph Comment Advanced Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection through Graph Comment Advanced Learning'}, 'summary': ""Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable.""}, 'authors': [{'name': 'Hao Liao'}, {'name': 'Qixin Liu'}, {'name': 'Kai Shu'}, {'name': 'Xing xie'}], 'author_detail': {'name': 'Xing xie'}, 'author': 'Xing xie', 'links': [{'href': 'http://arxiv.org/abs/2011.01579v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.01579v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
66,http://arxiv.org/abs/2010.10836v1,2020-10-21 08:53:36+00:00,2020-10-21 08:53:36+00:00,ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences,"[arxiv.Result.Author('Soumya Suvra Ghosal'), arxiv.Result.Author('Deepak P'), arxiv.Result.Author('Anna Jurek-Loughrey')]","Disinformation is often presented in long textual articles, especially when
it relates to domains such as health, often seen in relation to COVID-19. These
articles are typically observed to have a number of trustworthy sentences among
which core disinformation sentences are scattered. In this paper, we propose a
novel unsupervised task of identifying sentences containing key disinformation
within a document that is known to be untrustworthy. We design a three-phase
statistical NLP solution for the task which starts with embedding sentences
within a bespoke feature space designed for the task. Sentences represented
using those features are then clustered, following which the key sentences are
identified through proximity scoring. We also curate a new dataset with
sentence level disinformation scorings to aid evaluation for this task; the
dataset is being made publicly available to facilitate further research. Based
on a comprehensive empirical evaluation against techniques from related tasks
such as claim detection and summarization, as well as against simplified
variants of our proposed approach, we illustrate that our method is able to
identify core disinformation effectively.","The 22nd International Conference on Information Integration and
  Web-based Applications & Services (iiWAS '20), Chiang Mai, Thailand",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2010.10836v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.10836v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.10836v1,"{'id': 'http://arxiv.org/abs/2010.10836v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.10836v1', 'updated': '2020-10-21T08:53:36Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=21, tm_hour=8, tm_min=53, tm_sec=36, tm_wday=2, tm_yday=295, tm_isdst=0), 'published': '2020-10-21T08:53:36Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=21, tm_hour=8, tm_min=53, tm_sec=36, tm_wday=2, tm_yday=295, tm_isdst=0), 'title': 'ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences'}, 'summary': 'Disinformation is often presented in long textual articles, especially when\nit relates to domains such as health, often seen in relation to COVID-19. These\narticles are typically observed to have a number of trustworthy sentences among\nwhich core disinformation sentences are scattered. In this paper, we propose a\nnovel unsupervised task of identifying sentences containing key disinformation\nwithin a document that is known to be untrustworthy. We design a three-phase\nstatistical NLP solution for the task which starts with embedding sentences\nwithin a bespoke feature space designed for the task. Sentences represented\nusing those features are then clustered, following which the key sentences are\nidentified through proximity scoring. We also curate a new dataset with\nsentence level disinformation scorings to aid evaluation for this task; the\ndataset is being made publicly available to facilitate further research. Based\non a comprehensive empirical evaluation against techniques from related tasks\nsuch as claim detection and summarization, as well as against simplified\nvariants of our proposed approach, we illustrate that our method is able to\nidentify core disinformation effectively.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation is often presented in long textual articles, especially when\nit relates to domains such as health, often seen in relation to COVID-19. These\narticles are typically observed to have a number of trustworthy sentences among\nwhich core disinformation sentences are scattered. In this paper, we propose a\nnovel unsupervised task of identifying sentences containing key disinformation\nwithin a document that is known to be untrustworthy. We design a three-phase\nstatistical NLP solution for the task which starts with embedding sentences\nwithin a bespoke feature space designed for the task. Sentences represented\nusing those features are then clustered, following which the key sentences are\nidentified through proximity scoring. We also curate a new dataset with\nsentence level disinformation scorings to aid evaluation for this task; the\ndataset is being made publicly available to facilitate further research. Based\non a comprehensive empirical evaluation against techniques from related tasks\nsuch as claim detection and summarization, as well as against simplified\nvariants of our proposed approach, we illustrate that our method is able to\nidentify core disinformation effectively.'}, 'authors': [{'name': 'Soumya Suvra Ghosal'}, {'name': 'Deepak P'}, {'name': 'Anna Jurek-Loughrey'}], 'author_detail': {'name': 'Anna Jurek-Loughrey'}, 'author': 'Anna Jurek-Loughrey', 'arxiv_comment': ""The 22nd International Conference on Information Integration and\n  Web-based Applications & Services (iiWAS '20), Chiang Mai, Thailand"", 'links': [{'href': 'http://arxiv.org/abs/2010.10836v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.10836v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
67,http://arxiv.org/abs/2010.09113v1,2020-10-18 21:44:23+00:00,2020-10-18 21:44:23+00:00,"Disinformation in the Online Information Ecosystem: Detection, Mitigation and Challenges","[arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Min Gao'), arxiv.Result.Author('Huan Liu')]","With the rapid increase in access to internet and the subsequent growth in
the population of online social media users, the quality of information posted,
disseminated and consumed via these platforms is an issue of growing concern. A
large fraction of the common public turn to social media platforms and in
general the internet for news and even information regarding highly concerning
issues such as COVID-19 symptoms. Given that the online information ecosystem
is extremely noisy, fraught with misinformation and disinformation, and often
contaminated by malicious agents spreading propaganda, identifying genuine and
good quality information from disinformation is a challenging task for humans.
In this regard, there is a significant amount of ongoing research in the
directions of disinformation detection and mitigation. In this survey, we
discuss the online disinformation problem, focusing on the recent 'infodemic'
in the wake of the coronavirus pandemic. We then proceed to discuss the
inherent challenges in disinformation research, and then elaborate on the
computational and interdisciplinary approaches towards mitigation of
disinformation, after a short overview of the various directions explored in
detection efforts.","A Chinese version of this manuscript has been submitted to the
  Journal of Computer Research and Development",,,cs.SI,"['cs.SI', 'cs.CY', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2010.09113v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.09113v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.09113v1,"{'id': 'http://arxiv.org/abs/2010.09113v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.09113v1', 'updated': '2020-10-18T21:44:23Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=44, tm_sec=23, tm_wday=6, tm_yday=292, tm_isdst=0), 'published': '2020-10-18T21:44:23Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=44, tm_sec=23, tm_wday=6, tm_yday=292, tm_isdst=0), 'title': 'Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges'}, 'summary': ""With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.""}, 'authors': [{'name': 'Amrita Bhattacharjee'}, {'name': 'Kai Shu'}, {'name': 'Min Gao'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'A Chinese version of this manuscript has been submitted to the\n  Journal of Computer Research and Development', 'links': [{'href': 'http://arxiv.org/abs/2010.09113v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.09113v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
68,http://arxiv.org/abs/2010.06455v2,2020-10-15 03:23:26+00:00,2020-10-13 15:10:26+00:00,"Characterizing and Comparing COVID-19 Misinformation Across Languages, Countries and Platforms","[arxiv.Result.Author('Golshan Madraki'), arxiv.Result.Author('Isabella Grasso'), arxiv.Result.Author('Jacqueline Otala'), arxiv.Result.Author('Yu Liu'), arxiv.Result.Author('Jeanna Matthews')]","Misinformation/disinformation about COVID-19 has been rampant on social media
around the world. In this study, we investigate COVID-19 misinformation/
disinformation on social media in multiple languages - Farsi (Persian),
Chinese, and English, about multiple countries - Iran, China, and the United
States (US), and on multiple platforms such as Twitter, Facebook, Instagram,
Weibo, and WhatsApp. Misinformation, especially about a global pandemic, is a
global problem yet it is common for studies of COVID-19 misinformation on
social media to focus on a single language, like English, a single country,
like the US, or a single platform, like Twitter. We utilized opportunistic
sampling to compile 200 specific items of viral and yet debunked misinformation
across these languages, countries and platforms emerged between January 1 and
August 31. We then categorized this collection based both on the topics of the
misinformation and the underlying roots of that misinformation. Our
multi-cultural and multilingual team observed that the nature of COVID-19
misinformation on social media varied in substantial ways across different
languages/countries depending on the cultures, beliefs/religions, popularity of
social media, types of platforms, freedom of speech and the power of people
versus governments. We observe that politics is at the root of most of the
collected misinformation across all three languages in this dataset. We further
observe the different impact of government restrictions on platforms and
platform restrictions on content in Iran, China, and the US and their impact on
a key question of our age: how do we control misinformation without silencing
the voices we need to hold governments accountable?",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.06455v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.06455v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.06455v2,"{'id': 'http://arxiv.org/abs/2010.06455v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.06455v2', 'updated': '2020-10-15T03:23:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=15, tm_hour=3, tm_min=23, tm_sec=26, tm_wday=3, tm_yday=289, tm_isdst=0), 'published': '2020-10-13T15:10:26Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=13, tm_hour=15, tm_min=10, tm_sec=26, tm_wday=1, tm_yday=287, tm_isdst=0), 'title': 'Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms'}, 'summary': 'Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?'}, 'authors': [{'name': 'Golshan Madraki'}, {'name': 'Isabella Grasso'}, {'name': 'Jacqueline Otala'}, {'name': 'Yu Liu'}, {'name': 'Jeanna Matthews'}], 'author_detail': {'name': 'Jeanna Matthews'}, 'author': 'Jeanna Matthews', 'links': [{'href': 'http://arxiv.org/abs/2010.06455v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.06455v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
69,http://arxiv.org/abs/2010.04496v2,2020-10-14 17:35:26+00:00,2020-10-09 10:56:04+00:00,Young Adult Unemployment Through the Lens of Social Media: Italy as a case study,"[arxiv.Result.Author('Alessandra Urbinati'), arxiv.Result.Author('Kyriaki Kalimeri'), arxiv.Result.Author('Andrea Bonanomi'), arxiv.Result.Author('Alessandro Rosina'), arxiv.Result.Author('Ciro Cattuto'), arxiv.Result.Author('Daniela Paolotti')]","Youth unemployment rates are still in alerting levels for many countries,
among which Italy. Direct consequences include poverty, social exclusion, and
criminal behaviours, while negative impact on the future employability and wage
cannot be obscured. In this study, we employ survey data together with social
media data, and in particular likes on Facebook Pages, to analyse personality,
moral values, but also cultural elements of the young unemployed population in
Italy. Our findings show that there are small but significant differences in
personality and moral values, with the unemployed males to be less agreeable
while females more open to new experiences. At the same time, unemployed have a
more collectivist point of view, valuing more in-group loyalty, authority, and
purity foundations. Interestingly, topic modelling analysis did not reveal
major differences in interests and cultural elements of the unemployed.
Utilisation patterns emerged though; the employed seem to use Facebook to
connect with local activities, while the unemployed use it mostly as for
entertainment purposes and as a source of news, making them susceptible to
mis/disinformation. We believe these findings can help policymakers get a
deeper understanding of this population and initiatives that improve both the
hard and the soft skills of this fragile population.",8 pages. Published in SocInfo 2020 Proceedings. Title update,,10.1007/978-3-030-60975-7_28,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-60975-7_28', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.04496v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.04496v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.04496v2,"{'id': 'http://arxiv.org/abs/2010.04496v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.04496v2', 'updated': '2020-10-14T17:35:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=14, tm_hour=17, tm_min=35, tm_sec=26, tm_wday=2, tm_yday=288, tm_isdst=0), 'published': '2020-10-09T10:56:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=9, tm_hour=10, tm_min=56, tm_sec=4, tm_wday=4, tm_yday=283, tm_isdst=0), 'title': 'Young Adult Unemployment Through the Lens of Social Media: Italy as a\n  case study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Young Adult Unemployment Through the Lens of Social Media: Italy as a\n  case study'}, 'summary': 'Youth unemployment rates are still in alerting levels for many countries,\namong which Italy. Direct consequences include poverty, social exclusion, and\ncriminal behaviours, while negative impact on the future employability and wage\ncannot be obscured. In this study, we employ survey data together with social\nmedia data, and in particular likes on Facebook Pages, to analyse personality,\nmoral values, but also cultural elements of the young unemployed population in\nItaly. Our findings show that there are small but significant differences in\npersonality and moral values, with the unemployed males to be less agreeable\nwhile females more open to new experiences. At the same time, unemployed have a\nmore collectivist point of view, valuing more in-group loyalty, authority, and\npurity foundations. Interestingly, topic modelling analysis did not reveal\nmajor differences in interests and cultural elements of the unemployed.\nUtilisation patterns emerged though; the employed seem to use Facebook to\nconnect with local activities, while the unemployed use it mostly as for\nentertainment purposes and as a source of news, making them susceptible to\nmis/disinformation. We believe these findings can help policymakers get a\ndeeper understanding of this population and initiatives that improve both the\nhard and the soft skills of this fragile population.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Youth unemployment rates are still in alerting levels for many countries,\namong which Italy. Direct consequences include poverty, social exclusion, and\ncriminal behaviours, while negative impact on the future employability and wage\ncannot be obscured. In this study, we employ survey data together with social\nmedia data, and in particular likes on Facebook Pages, to analyse personality,\nmoral values, but also cultural elements of the young unemployed population in\nItaly. Our findings show that there are small but significant differences in\npersonality and moral values, with the unemployed males to be less agreeable\nwhile females more open to new experiences. At the same time, unemployed have a\nmore collectivist point of view, valuing more in-group loyalty, authority, and\npurity foundations. Interestingly, topic modelling analysis did not reveal\nmajor differences in interests and cultural elements of the unemployed.\nUtilisation patterns emerged though; the employed seem to use Facebook to\nconnect with local activities, while the unemployed use it mostly as for\nentertainment purposes and as a source of news, making them susceptible to\nmis/disinformation. We believe these findings can help policymakers get a\ndeeper understanding of this population and initiatives that improve both the\nhard and the soft skills of this fragile population.'}, 'authors': [{'name': 'Alessandra Urbinati'}, {'name': 'Kyriaki Kalimeri'}, {'name': 'Andrea Bonanomi'}, {'name': 'Alessandro Rosina'}, {'name': 'Ciro Cattuto'}, {'name': 'Daniela Paolotti'}], 'author_detail': {'name': 'Daniela Paolotti'}, 'author': 'Daniela Paolotti', 'arxiv_doi': '10.1007/978-3-030-60975-7_28', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-60975-7_28', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.04496v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.04496v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '8 pages. Published in SocInfo 2020 Proceedings. Title update', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
70,http://arxiv.org/abs/2010.02097v1,2020-10-05 15:34:52+00:00,2020-10-05 15:34:52+00:00,FaNDS: Fake News Detection System Using Energy Flow,"[arxiv.Result.Author('Jiawei Xu'), arxiv.Result.Author('Vladimir Zadorozhny'), arxiv.Result.Author('Danchen Zhang'), arxiv.Result.Author('John Grant')]","Recently, the term ""fake news"" has been broadly and extensively utilized for
disinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,
and junk news. It has become a serious problem around the world. We present a
new system, FaNDS, that detects fake news efficiently. The system is based on
several concepts used in some previous works but in a different context. There
are two main concepts: an Inconsistency Graph and Energy Flow. The
Inconsistency Graph contains news items as nodes and inconsistent opinions
between them for edges. Energy Flow assigns each node an initial energy and
then some energy is propagated along the edges until the energy distribution on
all nodes converges. To illustrate FaNDS we use the original data from the Fake
News Challenge (FNC-1). First, the data has to be reconstructed in order to
generate the Inconsistency Graph. The graph contains various subgraphs with
well-defined shapes that represent different types of connections between the
news items. Then the Energy Flow method is applied. The nodes with high energy
are the candidates for being fake news. In our experiments, all these were
indeed fake news as we checked each using several reliable web sites. We
compared FaNDS to several other fake news detection methods and found it to be
more sensitive in discovering fake news items.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.02097v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.02097v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.02097v1,"{'id': 'http://arxiv.org/abs/2010.02097v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.02097v1', 'updated': '2020-10-05T15:34:52Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=15, tm_min=34, tm_sec=52, tm_wday=0, tm_yday=279, tm_isdst=0), 'published': '2020-10-05T15:34:52Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=15, tm_min=34, tm_sec=52, tm_wday=0, tm_yday=279, tm_isdst=0), 'title': 'FaNDS: Fake News Detection System Using Energy Flow', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FaNDS: Fake News Detection System Using Energy Flow'}, 'summary': 'Recently, the term ""fake news"" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, the term ""fake news"" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.'}, 'authors': [{'name': 'Jiawei Xu'}, {'name': 'Vladimir Zadorozhny'}, {'name': 'Danchen Zhang'}, {'name': 'John Grant'}], 'author_detail': {'name': 'John Grant'}, 'author': 'John Grant', 'links': [{'href': 'http://arxiv.org/abs/2010.02097v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.02097v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
71,http://arxiv.org/abs/2010.01208v1,2020-10-02 21:43:25+00:00,2020-10-02 21:43:25+00:00,Decoy Allocation Games on Graphs with Temporal Logic Objectives,"[arxiv.Result.Author('Abhishek N. Kulkarni'), arxiv.Result.Author('Jie Fu'), arxiv.Result.Author('Huan Luo'), arxiv.Result.Author('Charles A. Kamhoua'), arxiv.Result.Author('Nandi O. Leslie')]","We study a class of games, in which the adversary (attacker) is to satisfy a
complex mission specified in linear temporal logic, and the defender is to
prevent the adversary from achieving its goal. A deceptive defender can
allocate decoys, in addition to defense actions, to create disinformation for
the attacker. Thus, we focus on the problem of jointly synthesizing a decoy
placement strategy and a deceptive defense strategy that maximally exploits the
incomplete information the attacker about the decoy locations. We introduce a
model of hypergames on graphs with temporal logic objectives to capture such
adversarial interactions with asymmetric information. Using the hypergame
model, we analyze the effectiveness of a given decoy placement, quantified by
the set of deceptive winning states where the defender can prevent the attacker
from satisfying the attack objective given its incomplete information about
decoy locations. Then, we investigate how to place decoys to maximize the
defender's deceptive winning region. Considering the large search space for all
possible decoy allocation strategies, we incorporate the idea of compositional
synthesis from formal methods and show that the objective function in the class
of decoy allocation problem is monotone and non-decreasing. We derive the
sufficient conditions under which the objective function for the decoy
allocation problem is submodular, or supermodular, respectively. We show a
sub-optimal allocation can be efficiently computed by iteratively composing the
solutions of hypergames with a subset of decoys and the solution of a hypergame
given a single decoy. We use a running example to illustrate the proposed
method.","20 page, 4 figures, 2 algorithms, Accepted at Conference on Decision
  and Game Theory for Security (GameSec) 2020",,,cs.GT,"['cs.GT', 'cs.FL']","[arxiv.Result.Link('http://arxiv.org/abs/2010.01208v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.01208v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.01208v1,"{'id': 'http://arxiv.org/abs/2010.01208v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.01208v1', 'updated': '2020-10-02T21:43:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=2, tm_hour=21, tm_min=43, tm_sec=25, tm_wday=4, tm_yday=276, tm_isdst=0), 'published': '2020-10-02T21:43:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=2, tm_hour=21, tm_min=43, tm_sec=25, tm_wday=4, tm_yday=276, tm_isdst=0), 'title': 'Decoy Allocation Games on Graphs with Temporal Logic Objectives', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Decoy Allocation Games on Graphs with Temporal Logic Objectives'}, 'summary': ""We study a class of games, in which the adversary (attacker) is to satisfy a\ncomplex mission specified in linear temporal logic, and the defender is to\nprevent the adversary from achieving its goal. A deceptive defender can\nallocate decoys, in addition to defense actions, to create disinformation for\nthe attacker. Thus, we focus on the problem of jointly synthesizing a decoy\nplacement strategy and a deceptive defense strategy that maximally exploits the\nincomplete information the attacker about the decoy locations. We introduce a\nmodel of hypergames on graphs with temporal logic objectives to capture such\nadversarial interactions with asymmetric information. Using the hypergame\nmodel, we analyze the effectiveness of a given decoy placement, quantified by\nthe set of deceptive winning states where the defender can prevent the attacker\nfrom satisfying the attack objective given its incomplete information about\ndecoy locations. Then, we investigate how to place decoys to maximize the\ndefender's deceptive winning region. Considering the large search space for all\npossible decoy allocation strategies, we incorporate the idea of compositional\nsynthesis from formal methods and show that the objective function in the class\nof decoy allocation problem is monotone and non-decreasing. We derive the\nsufficient conditions under which the objective function for the decoy\nallocation problem is submodular, or supermodular, respectively. We show a\nsub-optimal allocation can be efficiently computed by iteratively composing the\nsolutions of hypergames with a subset of decoys and the solution of a hypergame\ngiven a single decoy. We use a running example to illustrate the proposed\nmethod."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We study a class of games, in which the adversary (attacker) is to satisfy a\ncomplex mission specified in linear temporal logic, and the defender is to\nprevent the adversary from achieving its goal. A deceptive defender can\nallocate decoys, in addition to defense actions, to create disinformation for\nthe attacker. Thus, we focus on the problem of jointly synthesizing a decoy\nplacement strategy and a deceptive defense strategy that maximally exploits the\nincomplete information the attacker about the decoy locations. We introduce a\nmodel of hypergames on graphs with temporal logic objectives to capture such\nadversarial interactions with asymmetric information. Using the hypergame\nmodel, we analyze the effectiveness of a given decoy placement, quantified by\nthe set of deceptive winning states where the defender can prevent the attacker\nfrom satisfying the attack objective given its incomplete information about\ndecoy locations. Then, we investigate how to place decoys to maximize the\ndefender's deceptive winning region. Considering the large search space for all\npossible decoy allocation strategies, we incorporate the idea of compositional\nsynthesis from formal methods and show that the objective function in the class\nof decoy allocation problem is monotone and non-decreasing. We derive the\nsufficient conditions under which the objective function for the decoy\nallocation problem is submodular, or supermodular, respectively. We show a\nsub-optimal allocation can be efficiently computed by iteratively composing the\nsolutions of hypergames with a subset of decoys and the solution of a hypergame\ngiven a single decoy. We use a running example to illustrate the proposed\nmethod.""}, 'authors': [{'name': 'Abhishek N. Kulkarni'}, {'name': 'Jie Fu'}, {'name': 'Huan Luo'}, {'name': 'Charles A. Kamhoua'}, {'name': 'Nandi O. Leslie'}], 'author_detail': {'name': 'Nandi O. Leslie'}, 'author': 'Nandi O. Leslie', 'arxiv_comment': '20 page, 4 figures, 2 algorithms, Accepted at Conference on Decision\n  and Game Theory for Security (GameSec) 2020', 'links': [{'href': 'http://arxiv.org/abs/2010.01208v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.01208v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.FL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
72,http://arxiv.org/abs/2009.11792v2,2020-09-25 04:46:41+00:00,2020-09-24 16:34:47+00:00,Understanding the Use of Fauxtography on Social Media,"[arxiv.Result.Author('Yuping Wang'), arxiv.Result.Author('Fatemeh Tahmasbi'), arxiv.Result.Author('Jeremy Blackburn'), arxiv.Result.Author('Barry Bradlyn'), arxiv.Result.Author('Emiliano De Cristofaro'), arxiv.Result.Author('David Magerman'), arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Gianluca Stringhini')]","Despite the influence that image-based communication has on online discourse,
the role played by images in disinformation is still not well understood. In
this paper, we present the first large-scale study of fauxtography, analyzing
the use of manipulated or misleading images in news discussion on online
communities. First, we develop a computational pipeline geared to detect
fauxtography, and identify over 61k instances of fauxtography discussed on
Twitter, 4chan, and Reddit. Then, we study how posting fauxtography affects
engagement of posts on social media, finding that posts containing it receive
more interactions in the form of re-shares, likes, and comments. Finally, we
show that fauxtography images are often turned into memes by Web communities.
Our findings show that effective mitigation against disinformation need to take
images into account, and highlight a number of challenges in dealing with
image-based disinformation.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2009.11792v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.11792v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.11792v2,"{'id': 'http://arxiv.org/abs/2009.11792v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.11792v2', 'updated': '2020-09-25T04:46:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=25, tm_hour=4, tm_min=46, tm_sec=41, tm_wday=4, tm_yday=269, tm_isdst=0), 'published': '2020-09-24T16:34:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=24, tm_hour=16, tm_min=34, tm_sec=47, tm_wday=3, tm_yday=268, tm_isdst=0), 'title': 'Understanding the Use of Fauxtography on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding the Use of Fauxtography on Social Media'}, 'summary': 'Despite the influence that image-based communication has on online discourse,\nthe role played by images in disinformation is still not well understood. In\nthis paper, we present the first large-scale study of fauxtography, analyzing\nthe use of manipulated or misleading images in news discussion on online\ncommunities. First, we develop a computational pipeline geared to detect\nfauxtography, and identify over 61k instances of fauxtography discussed on\nTwitter, 4chan, and Reddit. Then, we study how posting fauxtography affects\nengagement of posts on social media, finding that posts containing it receive\nmore interactions in the form of re-shares, likes, and comments. Finally, we\nshow that fauxtography images are often turned into memes by Web communities.\nOur findings show that effective mitigation against disinformation need to take\nimages into account, and highlight a number of challenges in dealing with\nimage-based disinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Despite the influence that image-based communication has on online discourse,\nthe role played by images in disinformation is still not well understood. In\nthis paper, we present the first large-scale study of fauxtography, analyzing\nthe use of manipulated or misleading images in news discussion on online\ncommunities. First, we develop a computational pipeline geared to detect\nfauxtography, and identify over 61k instances of fauxtography discussed on\nTwitter, 4chan, and Reddit. Then, we study how posting fauxtography affects\nengagement of posts on social media, finding that posts containing it receive\nmore interactions in the form of re-shares, likes, and comments. Finally, we\nshow that fauxtography images are often turned into memes by Web communities.\nOur findings show that effective mitigation against disinformation need to take\nimages into account, and highlight a number of challenges in dealing with\nimage-based disinformation.'}, 'authors': [{'name': 'Yuping Wang'}, {'name': 'Fatemeh Tahmasbi'}, {'name': 'Jeremy Blackburn'}, {'name': 'Barry Bradlyn'}, {'name': 'Emiliano De Cristofaro'}, {'name': 'David Magerman'}, {'name': 'Savvas Zannettou'}, {'name': 'Gianluca Stringhini'}], 'author_detail': {'name': 'Gianluca Stringhini'}, 'author': 'Gianluca Stringhini', 'links': [{'href': 'http://arxiv.org/abs/2009.11792v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.11792v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
73,http://arxiv.org/abs/2009.07698v5,2020-10-21 15:16:20+00:00,2020-09-16 14:13:15+00:00,Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News,"[arxiv.Result.Author('Reuben Tan'), arxiv.Result.Author('Bryan A. Plummer'), arxiv.Result.Author('Kate Saenko')]","Large-scale dissemination of disinformation online intended to mislead or
deceive the general population is a major societal problem. Rapid progression
in image, video, and natural language generative models has only exacerbated
this situation and intensified our need for an effective defense mechanism.
While existing approaches have been proposed to defend against neural fake
news, they are generally constrained to the very limited setting where articles
only have text and metadata such as the title and authors. In this paper, we
introduce the more realistic and challenging task of defending against
machine-generated news that also includes images and captions. To identify the
possible weaknesses that adversaries can exploit, we create a NeuralNews
dataset composed of 4 different types of generated articles as well as conduct
a series of human user study experiments based on this dataset. In addition to
the valuable insights gleaned from our user study experiments, we provide a
relatively effective approach based on detecting visual-semantic
inconsistencies, which will serve as an effective first line of defense and a
useful reference for future work in defending against machine-generated
disinformation.",Accepted at EMNLP 2020,,,cs.AI,"['cs.AI', 'cs.CL', 'cs.CV']","[arxiv.Result.Link('http://arxiv.org/abs/2009.07698v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.07698v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.07698v5,"{'id': 'http://arxiv.org/abs/2009.07698v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.07698v5', 'updated': '2020-10-21T15:16:20Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=21, tm_hour=15, tm_min=16, tm_sec=20, tm_wday=2, tm_yday=295, tm_isdst=0), 'published': '2020-09-16T14:13:15Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=16, tm_hour=14, tm_min=13, tm_sec=15, tm_wday=2, tm_yday=260, tm_isdst=0), 'title': 'Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News'}, 'summary': 'Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.'}, 'authors': [{'name': 'Reuben Tan'}, {'name': 'Bryan A. Plummer'}, {'name': 'Kate Saenko'}], 'author_detail': {'name': 'Kate Saenko'}, 'author': 'Kate Saenko', 'arxiv_comment': 'Accepted at EMNLP 2020', 'links': [{'href': 'http://arxiv.org/abs/2009.07698v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.07698v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
74,http://arxiv.org/abs/2009.06807v1,2020-09-15 00:55:00+00:00,2020-09-15 00:55:00+00:00,The Radicalization Risks of GPT-3 and Advanced Neural Language Models,"[arxiv.Result.Author('Kris McGuffie'), arxiv.Result.Author('Alex Newhouse')]","In this paper, we expand on our previous research of the potential for abuse
of generative language models by assessing GPT-3. Experimenting with prompts
representative of different types of extremist narrative, structures of social
interaction, and radical ideologies, we find that GPT-3 demonstrates
significant improvement over its predecessor, GPT-2, in generating extremist
texts. We also show GPT-3's strength in generating text that accurately
emulates interactive, informational, and influential content that could be
utilized for radicalizing individuals into violent far-right extremist
ideologies and behaviors. While OpenAI's preventative measures are strong, the
possibility of unregulated copycat technology represents significant risk for
large-scale online radicalization and recruitment; thus, in the absence of
safeguards, successful and efficient weaponization that requires little
experimentation is likely. AI stakeholders, the policymaking community, and
governments should begin investing as soon as possible in building social
norms, public policy, and educational initiatives to preempt an influx of
machine-generated disinformation and propaganda. Mitigation will require
effective policy and partnerships across industry, government, and civil
society.",,,,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2009.06807v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.06807v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.06807v1,"{'id': 'http://arxiv.org/abs/2009.06807v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.06807v1', 'updated': '2020-09-15T00:55:00Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=15, tm_hour=0, tm_min=55, tm_sec=0, tm_wday=1, tm_yday=259, tm_isdst=0), 'published': '2020-09-15T00:55:00Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=15, tm_hour=0, tm_min=55, tm_sec=0, tm_wday=1, tm_yday=259, tm_isdst=0), 'title': 'The Radicalization Risks of GPT-3 and Advanced Neural Language Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Radicalization Risks of GPT-3 and Advanced Neural Language Models'}, 'summary': ""In this paper, we expand on our previous research of the potential for abuse\nof generative language models by assessing GPT-3. Experimenting with prompts\nrepresentative of different types of extremist narrative, structures of social\ninteraction, and radical ideologies, we find that GPT-3 demonstrates\nsignificant improvement over its predecessor, GPT-2, in generating extremist\ntexts. We also show GPT-3's strength in generating text that accurately\nemulates interactive, informational, and influential content that could be\nutilized for radicalizing individuals into violent far-right extremist\nideologies and behaviors. While OpenAI's preventative measures are strong, the\npossibility of unregulated copycat technology represents significant risk for\nlarge-scale online radicalization and recruitment; thus, in the absence of\nsafeguards, successful and efficient weaponization that requires little\nexperimentation is likely. AI stakeholders, the policymaking community, and\ngovernments should begin investing as soon as possible in building social\nnorms, public policy, and educational initiatives to preempt an influx of\nmachine-generated disinformation and propaganda. Mitigation will require\neffective policy and partnerships across industry, government, and civil\nsociety."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In this paper, we expand on our previous research of the potential for abuse\nof generative language models by assessing GPT-3. Experimenting with prompts\nrepresentative of different types of extremist narrative, structures of social\ninteraction, and radical ideologies, we find that GPT-3 demonstrates\nsignificant improvement over its predecessor, GPT-2, in generating extremist\ntexts. We also show GPT-3's strength in generating text that accurately\nemulates interactive, informational, and influential content that could be\nutilized for radicalizing individuals into violent far-right extremist\nideologies and behaviors. While OpenAI's preventative measures are strong, the\npossibility of unregulated copycat technology represents significant risk for\nlarge-scale online radicalization and recruitment; thus, in the absence of\nsafeguards, successful and efficient weaponization that requires little\nexperimentation is likely. AI stakeholders, the policymaking community, and\ngovernments should begin investing as soon as possible in building social\nnorms, public policy, and educational initiatives to preempt an influx of\nmachine-generated disinformation and propaganda. Mitigation will require\neffective policy and partnerships across industry, government, and civil\nsociety.""}, 'authors': [{'name': 'Kris McGuffie'}, {'name': 'Alex Newhouse'}], 'author_detail': {'name': 'Alex Newhouse'}, 'author': 'Alex Newhouse', 'links': [{'href': 'http://arxiv.org/abs/2009.06807v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.06807v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
75,http://arxiv.org/abs/2009.02931v1,2020-09-07 08:03:21+00:00,2020-09-07 08:03:21+00:00,Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With Transformer Models,"[arxiv.Result.Author('Alex Nikolov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Ivan Koychev'), arxiv.Result.Author('Preslav Nakov')]","While misinformation and disinformation have been thriving in social media
for years, with the emergence of the COVID-19 pandemic, the political and the
health misinformation merged, thus elevating the problem to a whole new level
and giving rise to the first global infodemic. The fight against this infodemic
has many aspects, with fact-checking and debunking false and misleading claims
being among the most important ones. Unfortunately, manual fact-checking is
time-consuming and automatic fact-checking is resource-intense, which means
that we need to pre-filter the input social media posts and to throw out those
that do not appear to be check-worthy. With this in mind, here we propose a
model for detecting check-worthy tweets about COVID-19, which combines deep
contextualized text representations with modeling the social context of the
tweet. We further describe a number of additional experiments and comparisons,
which we believe should be useful for future research as they provide some
indication about what techniques are effective for the task. Our official
submission to the English version of CLEF-2020 CheckThat! Task 1, system
Team_Alex, was ranked second with a MAP score of 0.8034, which is almost tied
with the wining system, lagging behind by just 0.003 MAP points absolute.",Check-worthiness; Fact-Checking; Veracity,CLEF-2020,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2009.02931v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.02931v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.02931v1,"{'id': 'http://arxiv.org/abs/2009.02931v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.02931v1', 'updated': '2020-09-07T08:03:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=7, tm_hour=8, tm_min=3, tm_sec=21, tm_wday=0, tm_yday=251, tm_isdst=0), 'published': '2020-09-07T08:03:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=7, tm_hour=8, tm_min=3, tm_sec=21, tm_wday=0, tm_yday=251, tm_isdst=0), 'title': 'Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models'}, 'summary': 'While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.'}, 'authors': [{'name': 'Alex Nikolov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Ivan Koychev'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Check-worthiness; Fact-Checking; Veracity', 'arxiv_journal_ref': 'CLEF-2020', 'links': [{'href': 'http://arxiv.org/abs/2009.02931v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.02931v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
76,http://arxiv.org/abs/2008.13632v1,2020-08-28 14:52:08+00:00,2020-08-28 14:52:08+00:00,TRUSTD: Combat Fake Content using Blockchain and Collective Signature Technologies,"[arxiv.Result.Author('Zakwan Jaroucheh'), arxiv.Result.Author('Mohamad Alissa'), arxiv.Result.Author('William J Buchanan')]","The growing trend of sharing news/contents, through social media platforms
and the World Wide Web has been seen to impact our perception of the truth,
altering our views about politics, economics, relationships, needs and wants.
This is because of the growing spread of misinformation and disinformation
intentionally or unintentionally by individuals and organizations. This trend
has grave political, social, ethical, and privacy implications for society due
to 1) the rapid developments in the field of Machine Learning (ML) and Deep
Learning (DL) algorithms in creating realistic-looking yet fake digital content
(such as text, images, and videos), 2) the ability to customize the content
feeds and to create a polarized so-called ""filter-bubbles"" leveraging the
availability of the big-data. Therefore, there is an ethical need to combat the
flow of fake content. This paper attempts to resolve some of the aspects of
this combat by presenting a high-level overview of TRUSTD, a blockchain and
collective signature-based ecosystem to help content creators in getting their
content backed by the community, and to help users judge on the credibility and
correctness of these contents.","arXiv admin note: text overlap with arXiv:1812.00315,
  arXiv:1807.06346, arXiv:1904.05386 by other authors","2020 IEEE International Conference on Blockchain and
  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3",10.1109/ICBC48266.2020.9169435,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/ICBC48266.2020.9169435', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.13632v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.13632v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.13632v1,"{'id': 'http://arxiv.org/abs/2008.13632v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.13632v1', 'updated': '2020-08-28T14:52:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=14, tm_min=52, tm_sec=8, tm_wday=4, tm_yday=241, tm_isdst=0), 'published': '2020-08-28T14:52:08Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=14, tm_min=52, tm_sec=8, tm_wday=4, tm_yday=241, tm_isdst=0), 'title': 'TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies'}, 'summary': 'The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called ""filter-bubbles"" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called ""filter-bubbles"" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.'}, 'authors': [{'name': 'Zakwan Jaroucheh'}, {'name': 'Mohamad Alissa'}, {'name': 'William J Buchanan'}], 'author_detail': {'name': 'William J Buchanan'}, 'author': 'William J Buchanan', 'arxiv_doi': '10.1109/ICBC48266.2020.9169435', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/ICBC48266.2020.9169435', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.13632v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.13632v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1812.00315,\n  arXiv:1807.06346, arXiv:1904.05386 by other authors', 'arxiv_journal_ref': '2020 IEEE International Conference on Blockchain and\n  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3', 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
77,http://arxiv.org/abs/2009.07632v1,2020-08-26 08:58:29+00:00,2020-08-26 08:58:29+00:00,Helping Users Tackle Algorithmic Threats on Social Media: A Multimedia Research Agenda,"[arxiv.Result.Author('Christian von der Weth'), arxiv.Result.Author('Ashraf Abdul'), arxiv.Result.Author('Shaojing Fan'), arxiv.Result.Author('Mohan Kankanhalli')]","Participation on social media platforms has many benefits but also poses
substantial threats. Users often face an unintended loss of privacy, are
bombarded with mis-/disinformation, or are trapped in filter bubbles due to
over-personalized content. These threats are further exacerbated by the rise of
hidden AI-driven algorithms working behind the scenes to shape users' thoughts,
attitudes, and behavior. We investigate how multimedia researchers can help
tackle these problems to level the playing field for social media users. We
perform a comprehensive survey of algorithmic threats on social media and use
it as a lens to set a challenging but important research agenda for effective
and real-time user nudging. We further implement a conceptual prototype and
evaluate it with experts to supplement our research agenda. This paper calls
for solutions that combat the algorithmic threats on social media by utilizing
machine learning and multimedia content analysis techniques but in a
transparent manner and for the benefit of the users.","This work has been accepted to the ""Brave New Ideas"" track of the ACM
  Multimedia Conference 2020",,,cs.SI,"['cs.SI', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2009.07632v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.07632v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.07632v1,"{'id': 'http://arxiv.org/abs/2009.07632v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.07632v1', 'updated': '2020-08-26T08:58:29Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=26, tm_hour=8, tm_min=58, tm_sec=29, tm_wday=2, tm_yday=239, tm_isdst=0), 'published': '2020-08-26T08:58:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=26, tm_hour=8, tm_min=58, tm_sec=29, tm_wday=2, tm_yday=239, tm_isdst=0), 'title': 'Helping Users Tackle Algorithmic Threats on Social Media: A Multimedia\n  Research Agenda', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Helping Users Tackle Algorithmic Threats on Social Media: A Multimedia\n  Research Agenda'}, 'summary': ""Participation on social media platforms has many benefits but also poses\nsubstantial threats. Users often face an unintended loss of privacy, are\nbombarded with mis-/disinformation, or are trapped in filter bubbles due to\nover-personalized content. These threats are further exacerbated by the rise of\nhidden AI-driven algorithms working behind the scenes to shape users' thoughts,\nattitudes, and behavior. We investigate how multimedia researchers can help\ntackle these problems to level the playing field for social media users. We\nperform a comprehensive survey of algorithmic threats on social media and use\nit as a lens to set a challenging but important research agenda for effective\nand real-time user nudging. We further implement a conceptual prototype and\nevaluate it with experts to supplement our research agenda. This paper calls\nfor solutions that combat the algorithmic threats on social media by utilizing\nmachine learning and multimedia content analysis techniques but in a\ntransparent manner and for the benefit of the users."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Participation on social media platforms has many benefits but also poses\nsubstantial threats. Users often face an unintended loss of privacy, are\nbombarded with mis-/disinformation, or are trapped in filter bubbles due to\nover-personalized content. These threats are further exacerbated by the rise of\nhidden AI-driven algorithms working behind the scenes to shape users' thoughts,\nattitudes, and behavior. We investigate how multimedia researchers can help\ntackle these problems to level the playing field for social media users. We\nperform a comprehensive survey of algorithmic threats on social media and use\nit as a lens to set a challenging but important research agenda for effective\nand real-time user nudging. We further implement a conceptual prototype and\nevaluate it with experts to supplement our research agenda. This paper calls\nfor solutions that combat the algorithmic threats on social media by utilizing\nmachine learning and multimedia content analysis techniques but in a\ntransparent manner and for the benefit of the users.""}, 'authors': [{'name': 'Christian von der Weth'}, {'name': 'Ashraf Abdul'}, {'name': 'Shaojing Fan'}, {'name': 'Mohan Kankanhalli'}], 'author_detail': {'name': 'Mohan Kankanhalli'}, 'author': 'Mohan Kankanhalli', 'arxiv_comment': 'This work has been accepted to the ""Brave New Ideas"" track of the ACM\n  Multimedia Conference 2020', 'links': [{'href': 'http://arxiv.org/abs/2009.07632v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.07632v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
78,http://arxiv.org/abs/2008.11308v2,2021-05-18 08:13:48+00:00,2020-08-25 23:35:01+00:00,Identifying Coordinated Accounts on Social Media through Hidden Influence and Group Behaviours,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Yizhou Zhang'), arxiv.Result.Author('Emilio Ferrara'), arxiv.Result.Author('Yan Liu')]","Disinformation campaigns on social media, involving coordinated activities
from malicious accounts towards manipulating public opinion, have become
increasingly prevalent. Existing approaches to detect coordinated accounts
either make very strict assumptions about coordinated behaviours, or require
part of the malicious accounts in the coordinated group to be revealed in order
to detect the rest. To address these drawbacks, we propose a generative model,
AMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group
Estimation) which jointly models account activities and hidden group behaviours
based on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to
capture inherent characteristics of coordination which is, accounts that
coordinate must strongly influence each other's activities, and collectively
appear anomalous from normal accounts. To address the challenges of optimizing
the proposed model, we provide a bilevel optimization algorithm with
theoretical guarantee on convergence. We verified the effectiveness of the
proposed method and training algorithm on real-world social network data
collected from Twitter related to coordinated campaigns from Russia's Internet
Research Agency targeting the 2016 U.S. Presidential Elections, and to identify
coordinated campaigns related to the COVID-19 pandemic. Leveraging the learned
model, we find that the average influence between coordinated account pairs is
the highest.On COVID-19, we found coordinated group spreading anti-vaccination,
anti-masks conspiracies that suggest the pandemic is a hoax and political scam.",KDD'2021 (Accepted),"ACM SIGKDD International Conference on Knowledge Discovery & Data
  Mining 2021",,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2008.11308v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.11308v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.11308v2,"{'id': 'http://arxiv.org/abs/2008.11308v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.11308v2', 'updated': '2021-05-18T08:13:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=18, tm_hour=8, tm_min=13, tm_sec=48, tm_wday=1, tm_yday=138, tm_isdst=0), 'published': '2020-08-25T23:35:01Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=25, tm_hour=23, tm_min=35, tm_sec=1, tm_wday=1, tm_yday=238, tm_isdst=0), 'title': 'Identifying Coordinated Accounts on Social Media through Hidden\n  Influence and Group Behaviours', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Coordinated Accounts on Social Media through Hidden\n  Influence and Group Behaviours'}, 'summary': ""Disinformation campaigns on social media, involving coordinated activities\nfrom malicious accounts towards manipulating public opinion, have become\nincreasingly prevalent. Existing approaches to detect coordinated accounts\neither make very strict assumptions about coordinated behaviours, or require\npart of the malicious accounts in the coordinated group to be revealed in order\nto detect the rest. To address these drawbacks, we propose a generative model,\nAMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group\nEstimation) which jointly models account activities and hidden group behaviours\nbased on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to\ncapture inherent characteristics of coordination which is, accounts that\ncoordinate must strongly influence each other's activities, and collectively\nappear anomalous from normal accounts. To address the challenges of optimizing\nthe proposed model, we provide a bilevel optimization algorithm with\ntheoretical guarantee on convergence. We verified the effectiveness of the\nproposed method and training algorithm on real-world social network data\ncollected from Twitter related to coordinated campaigns from Russia's Internet\nResearch Agency targeting the 2016 U.S. Presidential Elections, and to identify\ncoordinated campaigns related to the COVID-19 pandemic. Leveraging the learned\nmodel, we find that the average influence between coordinated account pairs is\nthe highest.On COVID-19, we found coordinated group spreading anti-vaccination,\nanti-masks conspiracies that suggest the pandemic is a hoax and political scam."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation campaigns on social media, involving coordinated activities\nfrom malicious accounts towards manipulating public opinion, have become\nincreasingly prevalent. Existing approaches to detect coordinated accounts\neither make very strict assumptions about coordinated behaviours, or require\npart of the malicious accounts in the coordinated group to be revealed in order\nto detect the rest. To address these drawbacks, we propose a generative model,\nAMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group\nEstimation) which jointly models account activities and hidden group behaviours\nbased on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to\ncapture inherent characteristics of coordination which is, accounts that\ncoordinate must strongly influence each other's activities, and collectively\nappear anomalous from normal accounts. To address the challenges of optimizing\nthe proposed model, we provide a bilevel optimization algorithm with\ntheoretical guarantee on convergence. We verified the effectiveness of the\nproposed method and training algorithm on real-world social network data\ncollected from Twitter related to coordinated campaigns from Russia's Internet\nResearch Agency targeting the 2016 U.S. Presidential Elections, and to identify\ncoordinated campaigns related to the COVID-19 pandemic. Leveraging the learned\nmodel, we find that the average influence between coordinated account pairs is\nthe highest.On COVID-19, we found coordinated group spreading anti-vaccination,\nanti-masks conspiracies that suggest the pandemic is a hoax and political scam.""}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Yizhou Zhang'}, {'name': 'Emilio Ferrara'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_comment': ""KDD'2021 (Accepted)"", 'arxiv_journal_ref': 'ACM SIGKDD International Conference on Knowledge Discovery & Data\n  Mining 2021', 'links': [{'href': 'http://arxiv.org/abs/2008.11308v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.11308v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
79,http://arxiv.org/abs/2008.10772v6,2021-08-16 19:01:42+00:00,2020-08-25 01:10:57+00:00,Adapting Security Warnings to Counter Online Disinformation,"[arxiv.Result.Author('Ben Kaiser'), arxiv.Result.Author('Jerry Wei'), arxiv.Result.Author('Eli Lucherini'), arxiv.Result.Author('Kevin Lee'), arxiv.Result.Author('J. Nathan Matias'), arxiv.Result.Author('Jonathan Mayer')]","Disinformation is proliferating on the internet, and platforms are responding
by attaching warnings to content. There is little evidence, however, that these
warnings help users identify or avoid disinformation. In this work, we adapt
methods and results from the information security warning literature in order
to design and evaluate effective disinformation warnings. In an initial
laboratory study, we used a simulated search task to examine contextual and
interstitial disinformation warning designs. We found that users routinely
ignore contextual warnings, but users notice interstitial warnings -- and
respond by seeking information from alternative sources. We then conducted a
follow-on crowdworker study with eight interstitial warning designs. We
confirmed a significant impact on user information-seeking behavior, and we
found that a warning's design could effectively inform users or convey a risk
of harm. We also found, however, that neither user comprehension nor fear of
harm moderated behavioral effects. Our work provides evidence that
disinformation warnings can -- when designed well -- help users identify and
avoid disinformation. We show a path forward for designing effective warnings,
and we contribute repeatable methods for evaluating behavioral effects. We also
surface a possible dilemma: disinformation warnings might be able to inform
users and guide behavior, but the behavioral effects might result from user
experience friction, not informed decision making.",Published at USENIX Security '21,,,cs.HC,"['cs.HC', 'cs.CR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2008.10772v6', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.10772v6', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.10772v6,"{'id': 'http://arxiv.org/abs/2008.10772v6', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.10772v6', 'updated': '2021-08-16T19:01:42Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=16, tm_hour=19, tm_min=1, tm_sec=42, tm_wday=0, tm_yday=228, tm_isdst=0), 'published': '2020-08-25T01:10:57Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=25, tm_hour=1, tm_min=10, tm_sec=57, tm_wday=1, tm_yday=238, tm_isdst=0), 'title': 'Adapting Security Warnings to Counter Online Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adapting Security Warnings to Counter Online Disinformation'}, 'summary': ""Disinformation is proliferating on the internet, and platforms are responding\nby attaching warnings to content. There is little evidence, however, that these\nwarnings help users identify or avoid disinformation. In this work, we adapt\nmethods and results from the information security warning literature in order\nto design and evaluate effective disinformation warnings. In an initial\nlaboratory study, we used a simulated search task to examine contextual and\ninterstitial disinformation warning designs. We found that users routinely\nignore contextual warnings, but users notice interstitial warnings -- and\nrespond by seeking information from alternative sources. We then conducted a\nfollow-on crowdworker study with eight interstitial warning designs. We\nconfirmed a significant impact on user information-seeking behavior, and we\nfound that a warning's design could effectively inform users or convey a risk\nof harm. We also found, however, that neither user comprehension nor fear of\nharm moderated behavioral effects. Our work provides evidence that\ndisinformation warnings can -- when designed well -- help users identify and\navoid disinformation. We show a path forward for designing effective warnings,\nand we contribute repeatable methods for evaluating behavioral effects. We also\nsurface a possible dilemma: disinformation warnings might be able to inform\nusers and guide behavior, but the behavioral effects might result from user\nexperience friction, not informed decision making."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation is proliferating on the internet, and platforms are responding\nby attaching warnings to content. There is little evidence, however, that these\nwarnings help users identify or avoid disinformation. In this work, we adapt\nmethods and results from the information security warning literature in order\nto design and evaluate effective disinformation warnings. In an initial\nlaboratory study, we used a simulated search task to examine contextual and\ninterstitial disinformation warning designs. We found that users routinely\nignore contextual warnings, but users notice interstitial warnings -- and\nrespond by seeking information from alternative sources. We then conducted a\nfollow-on crowdworker study with eight interstitial warning designs. We\nconfirmed a significant impact on user information-seeking behavior, and we\nfound that a warning's design could effectively inform users or convey a risk\nof harm. We also found, however, that neither user comprehension nor fear of\nharm moderated behavioral effects. Our work provides evidence that\ndisinformation warnings can -- when designed well -- help users identify and\navoid disinformation. We show a path forward for designing effective warnings,\nand we contribute repeatable methods for evaluating behavioral effects. We also\nsurface a possible dilemma: disinformation warnings might be able to inform\nusers and guide behavior, but the behavioral effects might result from user\nexperience friction, not informed decision making.""}, 'authors': [{'name': 'Ben Kaiser'}, {'name': 'Jerry Wei'}, {'name': 'Eli Lucherini'}, {'name': 'Kevin Lee'}, {'name': 'J. Nathan Matias'}, {'name': 'Jonathan Mayer'}], 'author_detail': {'name': 'Jonathan Mayer'}, 'author': 'Jonathan Mayer', 'arxiv_comment': ""Published at USENIX Security '21"", 'links': [{'href': 'http://arxiv.org/abs/2008.10772v6', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.10772v6', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
80,http://arxiv.org/abs/2008.10102v1,2020-08-23 20:33:07+00:00,2020-08-23 20:33:07+00:00,Social Cybersecurity Chapter 13: Casestudy with COVID-19 Pandemic,"[arxiv.Result.Author('David M. Beskow'), arxiv.Result.Author('Kathleen M. Carley')]","The purpose of this case study is to leverage the concepts and tools
presented in the preceding chapters and apply them in a real world social
cybersecurity context. With the COVID-19 pandemic emerging as a defining event
of the 21st Century and a magnet for disinformation maneuver, we have selected
the pandemic and its related social media conversation to focus our efforts on.
This chapter therefore applies the tools of information operation maneuver, bot
detection and characterization, meme detection and characterization, and
information mapping to the COVID-19 related conversation on Twitter. This
chapter uses these tools to analyze a stream containing 206 million tweets from
27 million unique users from 15 March 2020 to 30 April 2020. Our results shed
light on elaborate information operations that leverage the full breadth of the
BEND maneuvers and use bots for important shaping operations.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2008.10102v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.10102v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.10102v1,"{'id': 'http://arxiv.org/abs/2008.10102v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.10102v1', 'updated': '2020-08-23T20:33:07Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=23, tm_hour=20, tm_min=33, tm_sec=7, tm_wday=6, tm_yday=236, tm_isdst=0), 'published': '2020-08-23T20:33:07Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=23, tm_hour=20, tm_min=33, tm_sec=7, tm_wday=6, tm_yday=236, tm_isdst=0), 'title': 'Social Cybersecurity Chapter 13: Casestudy with COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Cybersecurity Chapter 13: Casestudy with COVID-19 Pandemic'}, 'summary': 'The purpose of this case study is to leverage the concepts and tools\npresented in the preceding chapters and apply them in a real world social\ncybersecurity context. With the COVID-19 pandemic emerging as a defining event\nof the 21st Century and a magnet for disinformation maneuver, we have selected\nthe pandemic and its related social media conversation to focus our efforts on.\nThis chapter therefore applies the tools of information operation maneuver, bot\ndetection and characterization, meme detection and characterization, and\ninformation mapping to the COVID-19 related conversation on Twitter. This\nchapter uses these tools to analyze a stream containing 206 million tweets from\n27 million unique users from 15 March 2020 to 30 April 2020. Our results shed\nlight on elaborate information operations that leverage the full breadth of the\nBEND maneuvers and use bots for important shaping operations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The purpose of this case study is to leverage the concepts and tools\npresented in the preceding chapters and apply them in a real world social\ncybersecurity context. With the COVID-19 pandemic emerging as a defining event\nof the 21st Century and a magnet for disinformation maneuver, we have selected\nthe pandemic and its related social media conversation to focus our efforts on.\nThis chapter therefore applies the tools of information operation maneuver, bot\ndetection and characterization, meme detection and characterization, and\ninformation mapping to the COVID-19 related conversation on Twitter. This\nchapter uses these tools to analyze a stream containing 206 million tweets from\n27 million unique users from 15 March 2020 to 30 April 2020. Our results shed\nlight on elaborate information operations that leverage the full breadth of the\nBEND maneuvers and use bots for important shaping operations.'}, 'authors': [{'name': 'David M. Beskow'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'links': [{'href': 'http://arxiv.org/abs/2008.10102v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.10102v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
81,http://arxiv.org/abs/2008.08513v1,2020-08-19 15:44:36+00:00,2020-08-19 15:44:36+00:00,Covid-19 infodemic reveals new tipping point epidemiology and a revised $R$ formula,"[arxiv.Result.Author('N. F. Johnson'), arxiv.Result.Author('N. Velasquez'), arxiv.Result.Author('O. K. Jha'), arxiv.Result.Author('H. Niyazi'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('R. Sear'), arxiv.Result.Author('P. Manrique'), arxiv.Result.Author('Y. Lupu'), arxiv.Result.Author('P. Devkota'), arxiv.Result.Author('S. Wuchty')]","Many governments have managed to control their COVID-19 outbreak with a
simple message: keep the effective '$R$ number' $R<1$ to prevent widespread
contagion and flatten the curve. This raises the question whether a similar
policy could control dangerous online 'infodemics' of information,
misinformation and disinformation. Here we show, using multi-platform data from
the COVID-19 infodemic, that its online spreading instead encompasses a
different dynamical regime where communities and users within and across
independent platforms, sporadically form temporary active links on similar
timescales to the viral spreading. This allows material that might have died
out, to evolve and even mutate. This has enabled niche networks that were
already successfully spreading hate and anti-vaccination material, to rapidly
become global super-spreaders of narratives featuring fake COVID-19 treatments,
anti-Asian sentiment and conspiracy theories. We derive new tools that
incorporate these coupled social-viral dynamics, including an online $R$, to
help prevent infodemic spreading at all scales: from spreading across platforms
(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,
or topic. By accounting for similar social and viral timescales, the same
mathematical theory also offers a quantitative description of other
unconventional infection profiles such as rumors spreading in financial markets
and colds spreading in schools.",Working paper. Comments welcome to neiljohnson@gwu.edu,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'nlin.AO']","[arxiv.Result.Link('http://arxiv.org/abs/2008.08513v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.08513v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.08513v1,"{'id': 'http://arxiv.org/abs/2008.08513v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.08513v1', 'updated': '2020-08-19T15:44:36Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=19, tm_hour=15, tm_min=44, tm_sec=36, tm_wday=2, tm_yday=232, tm_isdst=0), 'published': '2020-08-19T15:44:36Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=19, tm_hour=15, tm_min=44, tm_sec=36, tm_wday=2, tm_yday=232, tm_isdst=0), 'title': 'Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula'}, 'summary': ""Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.""}, 'authors': [{'name': 'N. F. Johnson'}, {'name': 'N. Velasquez'}, {'name': 'O. K. Jha'}, {'name': 'H. Niyazi'}, {'name': 'R. Leahy'}, {'name': 'N. Johnson Restrepo'}, {'name': 'R. Sear'}, {'name': 'P. Manrique'}, {'name': 'Y. Lupu'}, {'name': 'P. Devkota'}, {'name': 'S. Wuchty'}], 'author_detail': {'name': 'S. Wuchty'}, 'author': 'S. Wuchty', 'arxiv_comment': 'Working paper. Comments welcome to neiljohnson@gwu.edu', 'links': [{'href': 'http://arxiv.org/abs/2008.08513v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.08513v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
82,http://arxiv.org/abs/2008.08370v2,2021-04-01 13:08:38+00:00,2020-08-19 10:37:29+00:00,Coordinated Behavior on Social Media in 2019 UK General Election,"[arxiv.Result.Author('Leonardo Nizzoli'), arxiv.Result.Author('Serena Tardelli'), arxiv.Result.Author('Marco Avvenuti'), arxiv.Result.Author('Stefano Cresci'), arxiv.Result.Author('Maurizio Tesconi')]","Coordinated online behaviors are an essential part of information and
influence operations, as they allow a more effective disinformation's spread.
Most studies on coordinated behaviors involved manual investigations, and the
few existing computational approaches make bold assumptions or oversimplify the
problem to make it tractable. Here, we propose a new network-based framework
for uncovering and studying coordinated behaviors on social media. Our research
extends existing systems and goes beyond limiting binary classifications of
coordinated and uncoordinated behaviors. It allows to expose different
coordination patterns and to estimate the degree of coordination that
characterizes diverse communities. We apply our framework to a dataset
collected during the 2019 UK General Election, detecting and characterizing
coordinated communities that participated in the electoral debate. Our work
conveys both theoretical and practical implications and provides more nuanced
and fine-grained results for studying online information manipulation.","Version accepted in Proc. AAAI Intl. Conference on Web and Social
  Media (ICWSM) 2021. Added dataset DOI",Proc. AAAI Intl. Conference on Web and Social Media (ICWSM) 2021,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2008.08370v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.08370v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.08370v2,"{'id': 'http://arxiv.org/abs/2008.08370v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.08370v2', 'updated': '2021-04-01T13:08:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=1, tm_hour=13, tm_min=8, tm_sec=38, tm_wday=3, tm_yday=91, tm_isdst=0), 'published': '2020-08-19T10:37:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=19, tm_hour=10, tm_min=37, tm_sec=29, tm_wday=2, tm_yday=232, tm_isdst=0), 'title': 'Coordinated Behavior on Social Media in 2019 UK General Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Coordinated Behavior on Social Media in 2019 UK General Election'}, 'summary': ""Coordinated online behaviors are an essential part of information and\ninfluence operations, as they allow a more effective disinformation's spread.\nMost studies on coordinated behaviors involved manual investigations, and the\nfew existing computational approaches make bold assumptions or oversimplify the\nproblem to make it tractable. Here, we propose a new network-based framework\nfor uncovering and studying coordinated behaviors on social media. Our research\nextends existing systems and goes beyond limiting binary classifications of\ncoordinated and uncoordinated behaviors. It allows to expose different\ncoordination patterns and to estimate the degree of coordination that\ncharacterizes diverse communities. We apply our framework to a dataset\ncollected during the 2019 UK General Election, detecting and characterizing\ncoordinated communities that participated in the electoral debate. Our work\nconveys both theoretical and practical implications and provides more nuanced\nand fine-grained results for studying online information manipulation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Coordinated online behaviors are an essential part of information and\ninfluence operations, as they allow a more effective disinformation's spread.\nMost studies on coordinated behaviors involved manual investigations, and the\nfew existing computational approaches make bold assumptions or oversimplify the\nproblem to make it tractable. Here, we propose a new network-based framework\nfor uncovering and studying coordinated behaviors on social media. Our research\nextends existing systems and goes beyond limiting binary classifications of\ncoordinated and uncoordinated behaviors. It allows to expose different\ncoordination patterns and to estimate the degree of coordination that\ncharacterizes diverse communities. We apply our framework to a dataset\ncollected during the 2019 UK General Election, detecting and characterizing\ncoordinated communities that participated in the electoral debate. Our work\nconveys both theoretical and practical implications and provides more nuanced\nand fine-grained results for studying online information manipulation.""}, 'authors': [{'name': 'Leonardo Nizzoli'}, {'name': 'Serena Tardelli'}, {'name': 'Marco Avvenuti'}, {'name': 'Stefano Cresci'}, {'name': 'Maurizio Tesconi'}], 'author_detail': {'name': 'Maurizio Tesconi'}, 'author': 'Maurizio Tesconi', 'arxiv_comment': 'Version accepted in Proc. AAAI Intl. Conference on Web and Social\n  Media (ICWSM) 2021. Added dataset DOI', 'arxiv_journal_ref': 'Proc. AAAI Intl. Conference on Web and Social Media (ICWSM) 2021', 'links': [{'href': 'http://arxiv.org/abs/2008.08370v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.08370v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
83,http://arxiv.org/abs/2008.04374v1,2020-08-10 19:21:06+00:00,2020-08-10 19:21:06+00:00,"Can We Spot the ""Fake News"" Before It Was Even Written?",[arxiv.Result.Author('Preslav Nakov')],"Given the recent proliferation of disinformation online, there has been also
growing research interest in automatically debunking rumors, false claims, and
""fake news."" A number of fact-checking initiatives have been launched so far,
both manual and automatic, but the whole enterprise remains in a state of
crisis: by the time a claim is finally fact-checked, it could have reached
millions of users, and the harm caused could hardly be undone. An arguably more
promising direction is to focus on fact-checking entire news outlets, which can
be done in advance. Then, we could fact-check the news before it was even
written: by checking how trustworthy the outlets that published it is. We
describe how we do this in the Tanbih news aggregator, which makes readers
aware of what they are reading. In particular, we develop media profiles that
show the general factuality of reporting, the degree of propagandistic content,
hyper-partisanship, leading political ideology, general frame of reporting, and
stance with respect to various claims and topics.","Fake News, Disinformation, Media Bias, Propaganda, Infodemic,
  COVID-19",,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2008.04374v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.04374v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.04374v1,"{'id': 'http://arxiv.org/abs/2008.04374v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.04374v1', 'updated': '2020-08-10T19:21:06Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=10, tm_hour=19, tm_min=21, tm_sec=6, tm_wday=0, tm_yday=223, tm_isdst=0), 'published': '2020-08-10T19:21:06Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=10, tm_hour=19, tm_min=21, tm_sec=6, tm_wday=0, tm_yday=223, tm_isdst=0), 'title': 'Can We Spot the ""Fake News"" Before It Was Even Written?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can We Spot the ""Fake News"" Before It Was Even Written?'}, 'summary': 'Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n""fake news."" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n""fake news."" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.'}, 'authors': [{'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19', 'links': [{'href': 'http://arxiv.org/abs/2008.04374v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.04374v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
84,http://arxiv.org/abs/2008.00791v4,2020-09-19 07:11:39+00:00,2020-08-03 11:44:22+00:00,Characterizing COVID-19 Misinformation Communities Using a Novel Twitter Dataset,"[arxiv.Result.Author('Shahan Ali Memon'), arxiv.Result.Author('Kathleen M. Carley')]","From conspiracy theories to fake cures and fake treatments, COVID-19 has
become a hot-bed for the spread of misinformation online. It is more important
than ever to identify methods to debunk and correct false information online.
In this paper, we present a methodology and analyses to characterize the two
competing COVID-19 misinformation communities online: (i) misinformed users or
users who are actively posting misinformation, and (ii) informed users or users
who are actively spreading true information, or calling out misinformation. The
goals of this study are two-fold: (i) collecting a diverse set of annotated
COVID-19 Twitter dataset that can be used by the research community to conduct
meaningful analysis; and (ii) characterizing the two target communities in
terms of their network structure, linguistic patterns, and their membership in
other communities. Our analyses show that COVID-19 misinformed communities are
denser, and more organized than informed communities, with a possibility of a
high volume of the misinformation being part of disinformation campaigns. Our
analyses also suggest that a large majority of misinformed users may be
anti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19
informed users tend to use more narratives than misinformed users.","9 pages, In Proceedings of The 5th International Workshop on Mining
  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2008.00791v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.00791v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.00791v4,"{'id': 'http://arxiv.org/abs/2008.00791v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.00791v4', 'updated': '2020-09-19T07:11:39Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=7, tm_min=11, tm_sec=39, tm_wday=5, tm_yday=263, tm_isdst=0), 'published': '2020-08-03T11:44:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=3, tm_hour=11, tm_min=44, tm_sec=22, tm_wday=0, tm_yday=216, tm_isdst=0), 'title': 'Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset'}, 'summary': 'From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.'}, 'authors': [{'name': 'Shahan Ali Memon'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_comment': '9 pages, In Proceedings of The 5th International Workshop on Mining\n  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM', 'links': [{'href': 'http://arxiv.org/abs/2008.00791v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.00791v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
85,http://arxiv.org/abs/2008.00784v1,2020-08-03 11:25:47+00:00,2020-08-03 11:25:47+00:00,COVID-19 Misinformation and Disinformation on Social Networks -- The Limits of Veritistic Countermeasures,[arxiv.Result.Author('Andrew Buzzell')],"The COVID-19 pandemic has been the subject of a vast amount of
misinformation, particularly in digital information environments, and major
social media platforms recently publicized some of the countermeasures they are
adopting. This presents an opportunity to examine the nature of the
misinformation and disinformation being produced, and the theoretical and
technological paradigm used to counter it. I argue that this approach is based
on a conception of misinformation as epistemic pollution that can only justify
a limited and potentially inadequate response , and that some of the measures
undertaken in practice outrun this. In fact, social networks manage ecological
and architectural conditions that influence discourse on their platforms in
ways that should motivate reconsideration of the justifications that ground
epistemic interventions to combat misinformation, and the types of intervention
that they warrant. The editorial role of platforms should not be framed solely
as the management of epistemic pollution, but instead as managing the epistemic
environment in which narratives and social epistemic processes take place.
There is an element of inevitable epistemic paternalism involved in this, and
exploration of the independent constraints on its justifiability can help
determine proper limits of its exercise in practice.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2008.00784v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.00784v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.00784v1,"{'id': 'http://arxiv.org/abs/2008.00784v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.00784v1', 'updated': '2020-08-03T11:25:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=3, tm_hour=11, tm_min=25, tm_sec=47, tm_wday=0, tm_yday=216, tm_isdst=0), 'published': '2020-08-03T11:25:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=3, tm_hour=11, tm_min=25, tm_sec=47, tm_wday=0, tm_yday=216, tm_isdst=0), 'title': 'COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures'}, 'summary': 'The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.'}, 'authors': [{'name': 'Andrew Buzzell'}], 'author_detail': {'name': 'Andrew Buzzell'}, 'author': 'Andrew Buzzell', 'links': [{'href': 'http://arxiv.org/abs/2008.00784v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.00784v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
86,http://arxiv.org/abs/2008.01535v2,2020-08-05 01:53:01+00:00,2020-07-30 08:56:51+00:00,Weighted Accuracy Algorithmic Approach In Counteracting Fake News And Disinformation,[arxiv.Result.Author('Kwadwo Osei Bonsu')],"As the world is becoming more dependent on the internet for information
exchange, some overzealous journalists, hackers, bloggers, individuals and
organizations tend to abuse the gift of free information environment by
polluting it with fake news, disinformation and pretentious content for their
own agenda. Hence, there is the need to address the issue of fake news and
disinformation with utmost seriousness. This paper proposes a methodology for
fake news detection and reporting through a constraint mechanism that utilizes
the combined weighted accuracies of four machine learning algorithms.",,,10.2478/ers-2021-0007,cs.CL,"['cs.CL', 'cs.SI', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://dx.doi.org/10.2478/ers-2021-0007', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.01535v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.01535v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.01535v2,"{'id': 'http://arxiv.org/abs/2008.01535v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.01535v2', 'updated': '2020-08-05T01:53:01Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=5, tm_hour=1, tm_min=53, tm_sec=1, tm_wday=2, tm_yday=218, tm_isdst=0), 'published': '2020-07-30T08:56:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=30, tm_hour=8, tm_min=56, tm_sec=51, tm_wday=3, tm_yday=212, tm_isdst=0), 'title': 'Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation'}, 'summary': 'As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.'}, 'authors': [{'name': 'Kwadwo Osei Bonsu'}], 'author_detail': {'name': 'Kwadwo Osei Bonsu'}, 'author': 'Kwadwo Osei Bonsu', 'arxiv_doi': '10.2478/ers-2021-0007', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.2478/ers-2021-0007', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.01535v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.01535v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
87,http://arxiv.org/abs/2007.09703v1,2020-07-19 16:14:58+00:00,2020-07-19 16:14:58+00:00,A curated collection of COVID-19 online datasets,"[arxiv.Result.Author('Isa Inuwa-Dutse'), arxiv.Result.Author('Ioannis Korkontzelos')]","One of the defining moments of the year 2020 is the outbreak of Coronavirus
Disease (Covid-19), a deadly virus affecting the body's respiratory system to
the point of needing a breathing aid via ventilators. As of June 21, 2020 there
are 12,929,306 confirmed cases and 569,738 confirmed deaths across 216
countries, areas or territories. The scale of spread and impact of the pandemic
left many nations grappling with preventive and curative approaches. The
infamous lockdown measure introduced to mitigate the virus spread has altered
many aspects of our social routines in which demand for online-based services
skyrocketed. As the virus propagate, so does misinformation and fake news
around it via online social media, which seems to favour virality over
veracity. With a majority of the populace confined to their homes for a long
period, vulnerability to the toxic impact of online misinformation is high. A
case in point is the various myths and disinformation associated with the
Covid-19, which, if left unchecked, could lead to a catastrophic outcome and
hamper the fight against the virus.
  While the scientific community is actively engaged in identifying the virus
treatment, there is a growing interest in combating the associated harmful
infodemic. To this end, researchers have been curating and documenting various
datasets about Covid-19. In line with existing studies, we provide an expansive
collection of curated datasets to support the fight against the pandemic,
especially concerning misinformation. The collection consists of 3 categories
of Twitter data, information about standard practices from credible sources and
a chronicle of global situation reports. We describe how to retrieve the
hydrated version of the data and proffer some research problems that could be
addressed using the data.","10 pages, 7 figures",,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2007.09703v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.09703v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.09703v1,"{'id': 'http://arxiv.org/abs/2007.09703v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.09703v1', 'updated': '2020-07-19T16:14:58Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=16, tm_min=14, tm_sec=58, tm_wday=6, tm_yday=201, tm_isdst=0), 'published': '2020-07-19T16:14:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=16, tm_min=14, tm_sec=58, tm_wday=6, tm_yday=201, tm_isdst=0), 'title': 'A curated collection of COVID-19 online datasets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A curated collection of COVID-19 online datasets'}, 'summary': ""One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.""}, 'authors': [{'name': 'Isa Inuwa-Dutse'}, {'name': 'Ioannis Korkontzelos'}], 'author_detail': {'name': 'Ioannis Korkontzelos'}, 'author': 'Ioannis Korkontzelos', 'arxiv_comment': '10 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/2007.09703v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.09703v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
88,http://arxiv.org/abs/2007.07996v2,2021-04-09 08:52:10+00:00,2020-07-15 21:18:30+00:00,Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective and a Call to Arms,"[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Fahim Dalvi'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Nadir Durrani'), arxiv.Result.Author('Hamdy Mubarak'), arxiv.Result.Author('Alex Nikolov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Ahmed Abdelali'), arxiv.Result.Author('Hassan Sajjad'), arxiv.Result.Author('Kareem Darwish'), arxiv.Result.Author('Preslav Nakov')]","With the outbreak of the COVID-19 pandemic, people turned to social media to
read and to share timely information including statistics, warnings, advice,
and inspirational stories. Unfortunately, alongside all this useful
information, there was also a new blending of medical and political
misinformation and disinformation, which gave rise to the first global
infodemic. While fighting this infodemic is typically thought of in terms of
factuality, the problem is much broader as malicious content includes not only
fake news, rumors, and conspiracy theories, but also promotion of fake cures,
panic, racism, xenophobia, and mistrust in the authorities, among others. This
is a complex problem that needs a holistic approach combining the perspectives
of journalists, fact-checkers, policymakers, government entities, social media
platforms, and society as a whole. Taking them into account we define an
annotation schema and detailed annotation instructions, which reflect these
perspectives. We performed initial annotations using this schema, and our
initial experiments demonstrated sizable improvements over the baselines. Now,
we issue a call to arms to the research community and beyond to join the fight
by supporting our crowdsourcing annotation efforts.","COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call
  to Arms, Crowdsourcing Annotations",,,cs.IR,"['cs.IR', 'cs.CL', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2007.07996v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.07996v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.07996v2,"{'id': 'http://arxiv.org/abs/2007.07996v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.07996v2', 'updated': '2021-04-09T08:52:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=8, tm_min=52, tm_sec=10, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2020-07-15T21:18:30Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=15, tm_hour=21, tm_min=18, tm_sec=30, tm_wday=2, tm_yday=197, tm_isdst=0), 'title': 'Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms'}, 'summary': 'With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Fahim Dalvi'}, {'name': 'Shaden Shaar'}, {'name': 'Nadir Durrani'}, {'name': 'Hamdy Mubarak'}, {'name': 'Alex Nikolov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Ahmed Abdelali'}, {'name': 'Hassan Sajjad'}, {'name': 'Kareem Darwish'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations', 'links': [{'href': 'http://arxiv.org/abs/2007.07996v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.07996v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
89,http://arxiv.org/abs/2007.07388v1,2020-07-14 22:38:48+00:00,2020-07-14 22:38:48+00:00,Combating Disinformation in a Social Media Age,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Faisal Alatawi'), arxiv.Result.Author('Tahora Nazer'), arxiv.Result.Author('Kaize Ding'), arxiv.Result.Author('Mansooreh Karami'), arxiv.Result.Author('Huan Liu')]","The creation, dissemination, and consumption of disinformation and fabricated
content on social media is a growing concern, especially with the ease of
access to such sources, and the lack of awareness of the existence of such
false information. In this paper, we present an overview of the techniques
explored to date for the combating of disinformation with various forms. We
introduce different forms of disinformation, discuss factors related to the
spread of disinformation, elaborate on the inherent challenges in detecting
disinformation, and show some approaches to mitigating disinformation via
education, research, and collaboration. Looking ahead, we present some
promising future research directions on disinformation.",WIREs Data Mining and Knowledge Discovery,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2007.07388v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.07388v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.07388v1,"{'id': 'http://arxiv.org/abs/2007.07388v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.07388v1', 'updated': '2020-07-14T22:38:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=14, tm_hour=22, tm_min=38, tm_sec=48, tm_wday=1, tm_yday=196, tm_isdst=0), 'published': '2020-07-14T22:38:48Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=14, tm_hour=22, tm_min=38, tm_sec=48, tm_wday=1, tm_yday=196, tm_isdst=0), 'title': 'Combating Disinformation in a Social Media Age', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Disinformation in a Social Media Age'}, 'summary': 'The creation, dissemination, and consumption of disinformation and fabricated\ncontent on social media is a growing concern, especially with the ease of\naccess to such sources, and the lack of awareness of the existence of such\nfalse information. In this paper, we present an overview of the techniques\nexplored to date for the combating of disinformation with various forms. We\nintroduce different forms of disinformation, discuss factors related to the\nspread of disinformation, elaborate on the inherent challenges in detecting\ndisinformation, and show some approaches to mitigating disinformation via\neducation, research, and collaboration. Looking ahead, we present some\npromising future research directions on disinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The creation, dissemination, and consumption of disinformation and fabricated\ncontent on social media is a growing concern, especially with the ease of\naccess to such sources, and the lack of awareness of the existence of such\nfalse information. In this paper, we present an overview of the techniques\nexplored to date for the combating of disinformation with various forms. We\nintroduce different forms of disinformation, discuss factors related to the\nspread of disinformation, elaborate on the inherent challenges in detecting\ndisinformation, and show some approaches to mitigating disinformation via\neducation, research, and collaboration. Looking ahead, we present some\npromising future research directions on disinformation.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Amrita Bhattacharjee'}, {'name': 'Faisal Alatawi'}, {'name': 'Tahora Nazer'}, {'name': 'Kaize Ding'}, {'name': 'Mansooreh Karami'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'WIREs Data Mining and Knowledge Discovery', 'links': [{'href': 'http://arxiv.org/abs/2007.07388v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.07388v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
90,http://arxiv.org/abs/2006.14662v1,2020-06-25 19:00:41+00:00,2020-06-25 19:00:41+00:00,The State of AI Ethics Report (June 2020),"[arxiv.Result.Author('Abhishek Gupta'), arxiv.Result.Author('Camylle Lanteigne'), arxiv.Result.Author('Victoria Heath'), arxiv.Result.Author('Marianna Bergamaschi Ganapini'), arxiv.Result.Author('Erick Galinkin'), arxiv.Result.Author('Allison Cohen'), arxiv.Result.Author('Tania De Gasperis'), arxiv.Result.Author('Mo Akif'), arxiv.Result.Author('Renjie Butalid')]","These past few months have been especially challenging, and the deployment of
technology in ways hitherto untested at an unrivalled pace has left the
internet and technology watchers aghast. Artificial intelligence has become the
byword for technological progress and is being used in everything from helping
us combat the COVID-19 pandemic to nudging our attention in different
directions as we all spend increasingly larger amounts of time online. It has
never been more important that we keep a sharp eye out on the development of
this field and how it is shaping our society and interactions with each other.
With this inaugural edition of the State of AI Ethics we hope to bring forward
the most important developments that caught our attention at the Montreal AI
Ethics Institute this past quarter. Our goal is to help you navigate this
ever-evolving field swiftly and allow you and your organization to make
informed decisions. This pulse-check for the state of discourse, research, and
development is geared towards researchers and practitioners alike who are
making decisions on behalf of their organizations in considering the societal
impacts of AI-enabled solutions. We cover a wide set of areas in this report
spanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and
Labor, the Future of AI Ethics, and more. Our staff has worked tirelessly over
the past quarter surfacing signal from the noise so that you are equipped with
the right tools and knowledge to confidently tread this complex yet
consequential domain.",128 pages,,,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2006.14662v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.14662v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.14662v1,"{'id': 'http://arxiv.org/abs/2006.14662v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.14662v1', 'updated': '2020-06-25T19:00:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=25, tm_hour=19, tm_min=0, tm_sec=41, tm_wday=3, tm_yday=177, tm_isdst=0), 'published': '2020-06-25T19:00:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=25, tm_hour=19, tm_min=0, tm_sec=41, tm_wday=3, tm_yday=177, tm_isdst=0), 'title': 'The State of AI Ethics Report (June 2020)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The State of AI Ethics Report (June 2020)'}, 'summary': 'These past few months have been especially challenging, and the deployment of\ntechnology in ways hitherto untested at an unrivalled pace has left the\ninternet and technology watchers aghast. Artificial intelligence has become the\nbyword for technological progress and is being used in everything from helping\nus combat the COVID-19 pandemic to nudging our attention in different\ndirections as we all spend increasingly larger amounts of time online. It has\nnever been more important that we keep a sharp eye out on the development of\nthis field and how it is shaping our society and interactions with each other.\nWith this inaugural edition of the State of AI Ethics we hope to bring forward\nthe most important developments that caught our attention at the Montreal AI\nEthics Institute this past quarter. Our goal is to help you navigate this\never-evolving field swiftly and allow you and your organization to make\ninformed decisions. This pulse-check for the state of discourse, research, and\ndevelopment is geared towards researchers and practitioners alike who are\nmaking decisions on behalf of their organizations in considering the societal\nimpacts of AI-enabled solutions. We cover a wide set of areas in this report\nspanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and\nLabor, the Future of AI Ethics, and more. Our staff has worked tirelessly over\nthe past quarter surfacing signal from the noise so that you are equipped with\nthe right tools and knowledge to confidently tread this complex yet\nconsequential domain.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'These past few months have been especially challenging, and the deployment of\ntechnology in ways hitherto untested at an unrivalled pace has left the\ninternet and technology watchers aghast. Artificial intelligence has become the\nbyword for technological progress and is being used in everything from helping\nus combat the COVID-19 pandemic to nudging our attention in different\ndirections as we all spend increasingly larger amounts of time online. It has\nnever been more important that we keep a sharp eye out on the development of\nthis field and how it is shaping our society and interactions with each other.\nWith this inaugural edition of the State of AI Ethics we hope to bring forward\nthe most important developments that caught our attention at the Montreal AI\nEthics Institute this past quarter. Our goal is to help you navigate this\never-evolving field swiftly and allow you and your organization to make\ninformed decisions. This pulse-check for the state of discourse, research, and\ndevelopment is geared towards researchers and practitioners alike who are\nmaking decisions on behalf of their organizations in considering the societal\nimpacts of AI-enabled solutions. We cover a wide set of areas in this report\nspanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and\nLabor, the Future of AI Ethics, and more. Our staff has worked tirelessly over\nthe past quarter surfacing signal from the noise so that you are equipped with\nthe right tools and knowledge to confidently tread this complex yet\nconsequential domain.'}, 'authors': [{'name': 'Abhishek Gupta'}, {'name': 'Camylle Lanteigne'}, {'name': 'Victoria Heath'}, {'name': 'Marianna Bergamaschi Ganapini'}, {'name': 'Erick Galinkin'}, {'name': 'Allison Cohen'}, {'name': 'Tania De Gasperis'}, {'name': 'Mo Akif'}, {'name': 'Renjie Butalid'}], 'author_detail': {'name': 'Renjie Butalid'}, 'arxiv_affiliation': 'Montreal AI Ethics Institute', 'author': 'Renjie Butalid', 'arxiv_comment': '128 pages', 'links': [{'href': 'http://arxiv.org/abs/2006.14662v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.14662v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
91,http://arxiv.org/abs/2007.03604v2,2020-07-08 07:55:22+00:00,2020-06-23 13:46:38+00:00,A Decade of Social Bot Detection,[arxiv.Result.Author('Stefano Cresci')],"On the morning of November 9th 2016, the world woke up to the shocking
outcome of the US Presidential elections: Donald Trump was the 45th President
of the United States of America. An unexpected event that still has tremendous
consequences all over the world. Today, we know that a minority of social bots,
automated social media accounts mimicking humans, played a central role in
spreading divisive messages and disinformation, possibly contributing to
Trump's victory. In the aftermath of the 2016 US elections, the world started
to realize the gravity of widespread deception in social media. Following
Trump's exploit, we witnessed to the emergence of a strident dissonance between
the multitude of efforts for detecting and removing bots, and the increasing
effects that these malicious actors seem to have on our societies. This paradox
opens a burning question: What strategies should we enforce in order to stop
this social bot pandemic? In these times, during the run-up to the 2020 US
elections, the question appears as more crucial than ever. What stroke social,
political and economic analysts after 2016, deception and automation, has been
however a matter of study for computer scientists since at least 2010. In this
work, we briefly survey the first decade of research in social bot detection.
Via a longitudinal analysis, we discuss the main trends of research in the
fight against bots, the major results that were achieved, and the factors that
make this never-ending battle so challenging. Capitalizing on lessons learned
from our extensive analysis, we suggest possible innovations that could give us
the upper hand against deception and manipulation. Studying a decade of
endeavours at social bot detection can also inform strategies for detecting and
mitigating the effects of other, more recent, forms of online deception, such
as strategic information operations and political trolls.",Forthcoming in Communications of the ACM,Communications of the ACM 63.10 (2020):72-83,10.1145/3409116,cs.CY,"['cs.CY', 'cs.HC', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3409116', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.03604v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.03604v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.03604v2,"{'id': 'http://arxiv.org/abs/2007.03604v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.03604v2', 'updated': '2020-07-08T07:55:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=8, tm_hour=7, tm_min=55, tm_sec=22, tm_wday=2, tm_yday=190, tm_isdst=0), 'published': '2020-06-23T13:46:38Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=23, tm_hour=13, tm_min=46, tm_sec=38, tm_wday=1, tm_yday=175, tm_isdst=0), 'title': 'A Decade of Social Bot Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Decade of Social Bot Detection'}, 'summary': ""On the morning of November 9th 2016, the world woke up to the shocking\noutcome of the US Presidential elections: Donald Trump was the 45th President\nof the United States of America. An unexpected event that still has tremendous\nconsequences all over the world. Today, we know that a minority of social bots,\nautomated social media accounts mimicking humans, played a central role in\nspreading divisive messages and disinformation, possibly contributing to\nTrump's victory. In the aftermath of the 2016 US elections, the world started\nto realize the gravity of widespread deception in social media. Following\nTrump's exploit, we witnessed to the emergence of a strident dissonance between\nthe multitude of efforts for detecting and removing bots, and the increasing\neffects that these malicious actors seem to have on our societies. This paradox\nopens a burning question: What strategies should we enforce in order to stop\nthis social bot pandemic? In these times, during the run-up to the 2020 US\nelections, the question appears as more crucial than ever. What stroke social,\npolitical and economic analysts after 2016, deception and automation, has been\nhowever a matter of study for computer scientists since at least 2010. In this\nwork, we briefly survey the first decade of research in social bot detection.\nVia a longitudinal analysis, we discuss the main trends of research in the\nfight against bots, the major results that were achieved, and the factors that\nmake this never-ending battle so challenging. Capitalizing on lessons learned\nfrom our extensive analysis, we suggest possible innovations that could give us\nthe upper hand against deception and manipulation. Studying a decade of\nendeavours at social bot detection can also inform strategies for detecting and\nmitigating the effects of other, more recent, forms of online deception, such\nas strategic information operations and political trolls."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""On the morning of November 9th 2016, the world woke up to the shocking\noutcome of the US Presidential elections: Donald Trump was the 45th President\nof the United States of America. An unexpected event that still has tremendous\nconsequences all over the world. Today, we know that a minority of social bots,\nautomated social media accounts mimicking humans, played a central role in\nspreading divisive messages and disinformation, possibly contributing to\nTrump's victory. In the aftermath of the 2016 US elections, the world started\nto realize the gravity of widespread deception in social media. Following\nTrump's exploit, we witnessed to the emergence of a strident dissonance between\nthe multitude of efforts for detecting and removing bots, and the increasing\neffects that these malicious actors seem to have on our societies. This paradox\nopens a burning question: What strategies should we enforce in order to stop\nthis social bot pandemic? In these times, during the run-up to the 2020 US\nelections, the question appears as more crucial than ever. What stroke social,\npolitical and economic analysts after 2016, deception and automation, has been\nhowever a matter of study for computer scientists since at least 2010. In this\nwork, we briefly survey the first decade of research in social bot detection.\nVia a longitudinal analysis, we discuss the main trends of research in the\nfight against bots, the major results that were achieved, and the factors that\nmake this never-ending battle so challenging. Capitalizing on lessons learned\nfrom our extensive analysis, we suggest possible innovations that could give us\nthe upper hand against deception and manipulation. Studying a decade of\nendeavours at social bot detection can also inform strategies for detecting and\nmitigating the effects of other, more recent, forms of online deception, such\nas strategic information operations and political trolls.""}, 'authors': [{'name': 'Stefano Cresci'}], 'author_detail': {'name': 'Stefano Cresci'}, 'author': 'Stefano Cresci', 'arxiv_doi': '10.1145/3409116', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3409116', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.03604v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.03604v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Forthcoming in Communications of the ACM', 'arxiv_journal_ref': 'Communications of the ACM 63.10 (2020):72-83', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
92,http://arxiv.org/abs/2006.04278v1,2020-06-07 22:00:43+00:00,2020-06-07 22:00:43+00:00,Disinformation and Misinformation on Twitter during the Novel Coronavirus Outbreak,"[arxiv.Result.Author('Binxuan Huang'), arxiv.Result.Author('Kathleen M. Carley')]","As the novel coronavirus spread globally, a growing public panic was
expressed over the internet. We examine the public discussion concerning
COVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million
users collected between January 29, 2020 and March 4, 2020. We categorize users
based on their home countries, social identities, and political orientation. We
find that news media, government officials, and individual news reporters
posted a majority of influential tweets, while the most influential ones are
still written by regular users. Tweets mentioning ""fake news"" URLs and
disinformation story-lines are also more likely to be spread by regular users.
Unlike real news and normal tweets, tweets containing URLs pointing to ""fake
news"" sites are most likely to be retweeted within the source country and so
are less likely to spread internationally.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2006.04278v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.04278v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.04278v1,"{'id': 'http://arxiv.org/abs/2006.04278v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.04278v1', 'updated': '2020-06-07T22:00:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=7, tm_hour=22, tm_min=0, tm_sec=43, tm_wday=6, tm_yday=159, tm_isdst=0), 'published': '2020-06-07T22:00:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=7, tm_hour=22, tm_min=0, tm_sec=43, tm_wday=6, tm_yday=159, tm_isdst=0), 'title': 'Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak'}, 'summary': 'As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning ""fake news"" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to ""fake\nnews"" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning ""fake news"" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to ""fake\nnews"" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.'}, 'authors': [{'name': 'Binxuan Huang'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'links': [{'href': 'http://arxiv.org/abs/2006.04278v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.04278v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
93,http://arxiv.org/abs/2006.03354v2,2021-03-11 12:55:12+00:00,2020-06-05 10:32:18+00:00,Classification Aware Neural Topic Model and its Application on a New COVID-19 Disinformation Corpus,"[arxiv.Result.Author('Xingyi Song'), arxiv.Result.Author('Johann Petrak'), arxiv.Result.Author('Ye Jiang'), arxiv.Result.Author('Iknoor Singh'), arxiv.Result.Author('Diana Maynard'), arxiv.Result.Author('Kalina Bontcheva')]","The explosion of disinformation accompanying the COVID-19 pandemic has
overloaded fact-checkers and media worldwide, and brought a new major challenge
to government responses worldwide. Not only is disinformation creating
confusion about medical science amongst citizens, but it is also amplifying
distrust in policy makers and governments. To help tackle this, we developed
computational methods to categorise COVID-19 disinformation. The COVID-19
disinformation categories could be used for a) focusing fact-checking efforts
on the most damaging kinds of COVID-19 disinformation; b) guiding policy makers
who are trying to deliver effective public health messages and counter
effectively COVID-19 disinformation. This paper presents: 1) a corpus
containing what is currently the largest available set of manually annotated
COVID-19 disinformation categories; 2) a classification-aware neural topic
model (CANTM) designed for COVID-19 disinformation category classification and
topic discovery; 3) an extensive analysis of COVID-19 disinformation categories
with respect to time, volume, false type, media type and origin source.","This is arXiv version of ""Classification Aware Neural Topic Model for
  COVID-19 Disinformation Categorisation""",PLOS ONE 2021,10.1371/journal.pone.0247086,cs.LG,"['cs.LG', 'cs.CL', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0247086', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.03354v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.03354v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.03354v2,"{'id': 'http://arxiv.org/abs/2006.03354v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.03354v2', 'updated': '2021-03-11T12:55:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=11, tm_hour=12, tm_min=55, tm_sec=12, tm_wday=3, tm_yday=70, tm_isdst=0), 'published': '2020-06-05T10:32:18Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=5, tm_hour=10, tm_min=32, tm_sec=18, tm_wday=4, tm_yday=157, tm_isdst=0), 'title': 'Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus'}, 'summary': 'The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.'}, 'authors': [{'name': 'Xingyi Song'}, {'name': 'Johann Petrak'}, {'name': 'Ye Jiang'}, {'name': 'Iknoor Singh'}, {'name': 'Diana Maynard'}, {'name': 'Kalina Bontcheva'}], 'author_detail': {'name': 'Kalina Bontcheva'}, 'author': 'Kalina Bontcheva', 'arxiv_doi': '10.1371/journal.pone.0247086', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0247086', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.03354v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.03354v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'This is arXiv version of ""Classification Aware Neural Topic Model for\n  COVID-19 Disinformation Categorisation""', 'arxiv_journal_ref': 'PLOS ONE 2021', 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
94,http://arxiv.org/abs/2005.13466v2,2020-09-07 15:49:25+00:00,2020-05-27 16:23:04+00:00,On the Detection of Disinformation Campaign Activity with Network Analysis,"[arxiv.Result.Author('Luis Vargas'), arxiv.Result.Author('Patrick Emami'), arxiv.Result.Author('Patrick Traynor')]","Online manipulation of information has become more prevalent in recent years
as state-sponsored disinformation campaigns seek to influence and polarize
political topics through massive coordinated efforts. In the process, these
efforts leave behind artifacts, which researchers have leveraged to analyze the
tactics employed by disinformation campaigns after they are taken down.
Coordination network analysis has proven helpful for learning about how
disinformation campaigns operate; however, the usefulness of these forensic
tools as a detection mechanism is still an open question. In this paper, we
explore the use of coordination network analysis to generate features for
distinguishing the activity of a disinformation campaign from legitimate
Twitter activity. Doing so would provide more evidence to human analysts as
they consider takedowns. We create a time series of daily coordination networks
for both Twitter disinformation campaigns and legitimate Twitter communities,
and train a binary classifier based on statistical features extracted from
these networks. Our results show that the classifier can predict future
coordinated activity of known disinformation campaigns with high accuracy (F1 =
0.98). On the more challenging task of out-of-distribution activity
classification, the performance drops yet is still promising (F1 = 0.71),
mainly due to an increase in the false positive rate. By doing this analysis,
we show that while coordination patterns could be useful for providing evidence
of disinformation activity, further investigation is needed to improve upon
this method before deployment at scale.",,,,cs.SI,"['cs.SI', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2005.13466v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.13466v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.13466v2,"{'id': 'http://arxiv.org/abs/2005.13466v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.13466v2', 'updated': '2020-09-07T15:49:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=7, tm_hour=15, tm_min=49, tm_sec=25, tm_wday=0, tm_yday=251, tm_isdst=0), 'published': '2020-05-27T16:23:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=16, tm_min=23, tm_sec=4, tm_wday=2, tm_yday=148, tm_isdst=0), 'title': 'On the Detection of Disinformation Campaign Activity with Network\n  Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the Detection of Disinformation Campaign Activity with Network\n  Analysis'}, 'summary': 'Online manipulation of information has become more prevalent in recent years\nas state-sponsored disinformation campaigns seek to influence and polarize\npolitical topics through massive coordinated efforts. In the process, these\nefforts leave behind artifacts, which researchers have leveraged to analyze the\ntactics employed by disinformation campaigns after they are taken down.\nCoordination network analysis has proven helpful for learning about how\ndisinformation campaigns operate; however, the usefulness of these forensic\ntools as a detection mechanism is still an open question. In this paper, we\nexplore the use of coordination network analysis to generate features for\ndistinguishing the activity of a disinformation campaign from legitimate\nTwitter activity. Doing so would provide more evidence to human analysts as\nthey consider takedowns. We create a time series of daily coordination networks\nfor both Twitter disinformation campaigns and legitimate Twitter communities,\nand train a binary classifier based on statistical features extracted from\nthese networks. Our results show that the classifier can predict future\ncoordinated activity of known disinformation campaigns with high accuracy (F1 =\n0.98). On the more challenging task of out-of-distribution activity\nclassification, the performance drops yet is still promising (F1 = 0.71),\nmainly due to an increase in the false positive rate. By doing this analysis,\nwe show that while coordination patterns could be useful for providing evidence\nof disinformation activity, further investigation is needed to improve upon\nthis method before deployment at scale.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online manipulation of information has become more prevalent in recent years\nas state-sponsored disinformation campaigns seek to influence and polarize\npolitical topics through massive coordinated efforts. In the process, these\nefforts leave behind artifacts, which researchers have leveraged to analyze the\ntactics employed by disinformation campaigns after they are taken down.\nCoordination network analysis has proven helpful for learning about how\ndisinformation campaigns operate; however, the usefulness of these forensic\ntools as a detection mechanism is still an open question. In this paper, we\nexplore the use of coordination network analysis to generate features for\ndistinguishing the activity of a disinformation campaign from legitimate\nTwitter activity. Doing so would provide more evidence to human analysts as\nthey consider takedowns. We create a time series of daily coordination networks\nfor both Twitter disinformation campaigns and legitimate Twitter communities,\nand train a binary classifier based on statistical features extracted from\nthese networks. Our results show that the classifier can predict future\ncoordinated activity of known disinformation campaigns with high accuracy (F1 =\n0.98). On the more challenging task of out-of-distribution activity\nclassification, the performance drops yet is still promising (F1 = 0.71),\nmainly due to an increase in the false positive rate. By doing this analysis,\nwe show that while coordination patterns could be useful for providing evidence\nof disinformation activity, further investigation is needed to improve upon\nthis method before deployment at scale.'}, 'authors': [{'name': 'Luis Vargas'}, {'name': 'Patrick Emami'}, {'name': 'Patrick Traynor'}], 'author_detail': {'name': 'Patrick Traynor'}, 'author': 'Patrick Traynor', 'links': [{'href': 'http://arxiv.org/abs/2005.13466v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.13466v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
95,http://arxiv.org/abs/2005.10879v3,2021-01-07 22:15:57+00:00,2020-05-21 20:15:51+00:00,Automatic Detection of Influential Actors in Disinformation Networks,"[arxiv.Result.Author('Steven T. Smith'), arxiv.Result.Author('Edward K. Kao'), arxiv.Result.Author('Erika D. Mackin'), arxiv.Result.Author('Danelle C. Shah'), arxiv.Result.Author('Olga Simek'), arxiv.Result.Author('Donald B. Rubin')]","The weaponization of digital communications and social media to conduct
disinformation campaigns at immense scale, speed, and reach presents new
challenges to identify and counter hostile influence operations (IOs). This
paper presents an end-to-end framework to automate detection of disinformation
narratives, networks, and influential actors. The framework integrates natural
language processing, machine learning, graph analytics, and a novel network
causal inference approach to quantify the impact of individual actors in
spreading IO narratives. We demonstrate its capability on real-world hostile IO
campaigns with Twitter datasets collected during the 2017 French presidential
elections, and known IO accounts disclosed by Twitter over a broad range of IO
campaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and
different account types including both trolls and bots. Our system detects IO
accounts with 96% precision, 79% recall, and 96% area-under-the-PR-curve, maps
out salient network communities, and discovers high-impact accounts that escape
the lens of traditional impact statistics based on activity counts and network
centrality. Results are corroborated with independent sources of known IO
accounts from U.S. Congressional reports, investigative journalism, and IO
datasets provided by Twitter.","Proc. Natl. Acad. Sciences U.S.A. Vol. 118, No. 4, e2011216118",,10.1073/pnas.2011216118,cs.SI,"['cs.SI', 'cs.LG', 'stat.AP', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.1073/pnas.2011216118', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.10879v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.10879v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.10879v3,"{'id': 'http://arxiv.org/abs/2005.10879v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.10879v3', 'updated': '2021-01-07T22:15:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=22, tm_min=15, tm_sec=57, tm_wday=3, tm_yday=7, tm_isdst=0), 'published': '2020-05-21T20:15:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=21, tm_hour=20, tm_min=15, tm_sec=51, tm_wday=3, tm_yday=142, tm_isdst=0), 'title': 'Automatic Detection of Influential Actors in Disinformation Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic Detection of Influential Actors in Disinformation Networks'}, 'summary': 'The weaponization of digital communications and social media to conduct\ndisinformation campaigns at immense scale, speed, and reach presents new\nchallenges to identify and counter hostile influence operations (IOs). This\npaper presents an end-to-end framework to automate detection of disinformation\nnarratives, networks, and influential actors. The framework integrates natural\nlanguage processing, machine learning, graph analytics, and a novel network\ncausal inference approach to quantify the impact of individual actors in\nspreading IO narratives. We demonstrate its capability on real-world hostile IO\ncampaigns with Twitter datasets collected during the 2017 French presidential\nelections, and known IO accounts disclosed by Twitter over a broad range of IO\ncampaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and\ndifferent account types including both trolls and bots. Our system detects IO\naccounts with 96% precision, 79% recall, and 96% area-under-the-PR-curve, maps\nout salient network communities, and discovers high-impact accounts that escape\nthe lens of traditional impact statistics based on activity counts and network\ncentrality. Results are corroborated with independent sources of known IO\naccounts from U.S. Congressional reports, investigative journalism, and IO\ndatasets provided by Twitter.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The weaponization of digital communications and social media to conduct\ndisinformation campaigns at immense scale, speed, and reach presents new\nchallenges to identify and counter hostile influence operations (IOs). This\npaper presents an end-to-end framework to automate detection of disinformation\nnarratives, networks, and influential actors. The framework integrates natural\nlanguage processing, machine learning, graph analytics, and a novel network\ncausal inference approach to quantify the impact of individual actors in\nspreading IO narratives. We demonstrate its capability on real-world hostile IO\ncampaigns with Twitter datasets collected during the 2017 French presidential\nelections, and known IO accounts disclosed by Twitter over a broad range of IO\ncampaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and\ndifferent account types including both trolls and bots. Our system detects IO\naccounts with 96% precision, 79% recall, and 96% area-under-the-PR-curve, maps\nout salient network communities, and discovers high-impact accounts that escape\nthe lens of traditional impact statistics based on activity counts and network\ncentrality. Results are corroborated with independent sources of known IO\naccounts from U.S. Congressional reports, investigative journalism, and IO\ndatasets provided by Twitter.'}, 'authors': [{'name': 'Steven T. Smith'}, {'name': 'Edward K. Kao'}, {'name': 'Erika D. Mackin'}, {'name': 'Danelle C. Shah'}, {'name': 'Olga Simek'}, {'name': 'Donald B. Rubin'}], 'author_detail': {'name': 'Donald B. Rubin'}, 'author': 'Donald B. Rubin', 'arxiv_doi': '10.1073/pnas.2011216118', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1073/pnas.2011216118', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.10879v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.10879v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Proc. Natl. Acad. Sciences U.S.A. Vol. 118, No. 4, e2011216118', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
96,http://arxiv.org/abs/2005.10004v2,2020-09-23 15:56:39+00:00,2020-05-20 12:42:08+00:00,Characterizing networks of propaganda on Twitter: a case study,"[arxiv.Result.Author('Stefano Guarino'), arxiv.Result.Author('Noemi Trino'), arxiv.Result.Author('Alessandro Celestini'), arxiv.Result.Author('Alessandro Chessa'), arxiv.Result.Author('Gianni Riotta')]","The daily exposure of social media users to propaganda and disinformation
campaigns has reinvigorated the need to investigate the local and global
patterns of diffusion of different (mis)information content on social media.
Echo chambers and influencers are often deemed responsible of both the
polarization of users in online social networks and the success of propaganda
and disinformation campaigns. This article adopts a data-driven approach to
investigate the structuration of communities and propaganda networks on Twitter
in order to assess the correctness of these imputations. In particular, the
work aims at characterizing networks of propaganda extracted from a Twitter
dataset by combining the information gained by three different classification
approaches, focused respectively on (i) using Tweets content to infer the
""polarization"" of users around a specific topic, (ii) identifying users having
an active role in the diffusion of different propaganda and disinformation
items, and (iii) analyzing social ties to identify topological clusters and
users playing a ""central"" role in the network. The work identifies highly
partisan community structures along political alignments; furthermore,
centrality metrics proved to be very informative to detect the most active
users in the network and to distinguish users playing different roles; finally,
polarization and clustering structure of the retweet graphs provided useful
insights about relevant properties of users exposure, interactions, and
participation to different propaganda items.",,"Applied Network Science 5, 59 (2020)",10.1007/s41109-020-00286-y,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/s41109-020-00286-y', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.10004v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.10004v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.10004v2,"{'id': 'http://arxiv.org/abs/2005.10004v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.10004v2', 'updated': '2020-09-23T15:56:39Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=23, tm_hour=15, tm_min=56, tm_sec=39, tm_wday=2, tm_yday=267, tm_isdst=0), 'published': '2020-05-20T12:42:08Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=20, tm_hour=12, tm_min=42, tm_sec=8, tm_wday=2, tm_yday=141, tm_isdst=0), 'title': 'Characterizing networks of propaganda on Twitter: a case study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing networks of propaganda on Twitter: a case study'}, 'summary': 'The daily exposure of social media users to propaganda and disinformation\ncampaigns has reinvigorated the need to investigate the local and global\npatterns of diffusion of different (mis)information content on social media.\nEcho chambers and influencers are often deemed responsible of both the\npolarization of users in online social networks and the success of propaganda\nand disinformation campaigns. This article adopts a data-driven approach to\ninvestigate the structuration of communities and propaganda networks on Twitter\nin order to assess the correctness of these imputations. In particular, the\nwork aims at characterizing networks of propaganda extracted from a Twitter\ndataset by combining the information gained by three different classification\napproaches, focused respectively on (i) using Tweets content to infer the\n""polarization"" of users around a specific topic, (ii) identifying users having\nan active role in the diffusion of different propaganda and disinformation\nitems, and (iii) analyzing social ties to identify topological clusters and\nusers playing a ""central"" role in the network. The work identifies highly\npartisan community structures along political alignments; furthermore,\ncentrality metrics proved to be very informative to detect the most active\nusers in the network and to distinguish users playing different roles; finally,\npolarization and clustering structure of the retweet graphs provided useful\ninsights about relevant properties of users exposure, interactions, and\nparticipation to different propaganda items.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The daily exposure of social media users to propaganda and disinformation\ncampaigns has reinvigorated the need to investigate the local and global\npatterns of diffusion of different (mis)information content on social media.\nEcho chambers and influencers are often deemed responsible of both the\npolarization of users in online social networks and the success of propaganda\nand disinformation campaigns. This article adopts a data-driven approach to\ninvestigate the structuration of communities and propaganda networks on Twitter\nin order to assess the correctness of these imputations. In particular, the\nwork aims at characterizing networks of propaganda extracted from a Twitter\ndataset by combining the information gained by three different classification\napproaches, focused respectively on (i) using Tweets content to infer the\n""polarization"" of users around a specific topic, (ii) identifying users having\nan active role in the diffusion of different propaganda and disinformation\nitems, and (iii) analyzing social ties to identify topological clusters and\nusers playing a ""central"" role in the network. The work identifies highly\npartisan community structures along political alignments; furthermore,\ncentrality metrics proved to be very informative to detect the most active\nusers in the network and to distinguish users playing different roles; finally,\npolarization and clustering structure of the retweet graphs provided useful\ninsights about relevant properties of users exposure, interactions, and\nparticipation to different propaganda items.'}, 'authors': [{'name': 'Stefano Guarino'}, {'name': 'Noemi Trino'}, {'name': 'Alessandro Celestini'}, {'name': 'Alessandro Chessa'}, {'name': 'Gianni Riotta'}], 'author_detail': {'name': 'Gianni Riotta'}, 'author': 'Gianni Riotta', 'arxiv_doi': '10.1007/s41109-020-00286-y', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s41109-020-00286-y', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.10004v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.10004v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Applied Network Science 5, 59 (2020)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
97,http://arxiv.org/abs/2005.08618v1,2020-05-18 11:56:05+00:00,2020-05-18 11:56:05+00:00,Cognitive Analysis of Security Threats on Social Networking Services: Slovakia in need of stronger action,"[arxiv.Result.Author('Karol Fabian'), arxiv.Result.Author('Jozef Michal Mintal')]","This short paper examines some of the ongoing research at the UMB Data and
Society Lab hosted at the Faculty of Political Science and International
Relations at Matej Bel University. It begins with an introduction on the
necessity of security threat identification on social networking services
(SNSs), done by states. The paper follows with a general overview of selected
projects of the Lab in this field, and afterwards it introduces a use case
study focused on the announcement of the UK snap general election 2017. The
main aim of this paper is to demonstrate some of the possibilities of social
networking services analysis in the field of international relations, with an
emphasis on disinformation and the necessity of identifying novel digital
actors in Slovakia. We also outline an easy custom system tasked to collect
social media data, and afterwards process it using various cognitive analytic
methods.",,,,cs.CY,"['cs.CY', 'ACM-class:K.4.1']","[arxiv.Result.Link('http://arxiv.org/abs/2005.08618v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.08618v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.08618v1,"{'id': 'http://arxiv.org/abs/2005.08618v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.08618v1', 'updated': '2020-05-18T11:56:05Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=18, tm_hour=11, tm_min=56, tm_sec=5, tm_wday=0, tm_yday=139, tm_isdst=0), 'published': '2020-05-18T11:56:05Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=18, tm_hour=11, tm_min=56, tm_sec=5, tm_wday=0, tm_yday=139, tm_isdst=0), 'title': 'Cognitive Analysis of Security Threats on Social Networking Services:\n  Slovakia in need of stronger action', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cognitive Analysis of Security Threats on Social Networking Services:\n  Slovakia in need of stronger action'}, 'summary': 'This short paper examines some of the ongoing research at the UMB Data and\nSociety Lab hosted at the Faculty of Political Science and International\nRelations at Matej Bel University. It begins with an introduction on the\nnecessity of security threat identification on social networking services\n(SNSs), done by states. The paper follows with a general overview of selected\nprojects of the Lab in this field, and afterwards it introduces a use case\nstudy focused on the announcement of the UK snap general election 2017. The\nmain aim of this paper is to demonstrate some of the possibilities of social\nnetworking services analysis in the field of international relations, with an\nemphasis on disinformation and the necessity of identifying novel digital\nactors in Slovakia. We also outline an easy custom system tasked to collect\nsocial media data, and afterwards process it using various cognitive analytic\nmethods.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This short paper examines some of the ongoing research at the UMB Data and\nSociety Lab hosted at the Faculty of Political Science and International\nRelations at Matej Bel University. It begins with an introduction on the\nnecessity of security threat identification on social networking services\n(SNSs), done by states. The paper follows with a general overview of selected\nprojects of the Lab in this field, and afterwards it introduces a use case\nstudy focused on the announcement of the UK snap general election 2017. The\nmain aim of this paper is to demonstrate some of the possibilities of social\nnetworking services analysis in the field of international relations, with an\nemphasis on disinformation and the necessity of identifying novel digital\nactors in Slovakia. We also outline an easy custom system tasked to collect\nsocial media data, and afterwards process it using various cognitive analytic\nmethods.'}, 'authors': [{'name': 'Karol Fabian'}, {'name': 'Jozef Michal Mintal'}], 'author_detail': {'name': 'Jozef Michal Mintal'}, 'author': 'Jozef Michal Mintal', 'links': [{'href': 'http://arxiv.org/abs/2005.08618v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.08618v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'ACM-class:K.4.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
98,http://arxiv.org/abs/2005.06558v1,2020-05-13 19:48:12+00:00,2020-05-13 19:48:12+00:00,Russian trolls speaking Russian: Regional Twitter operations and MH17,"[arxiv.Result.Author('Alexandr Vesselkov'), arxiv.Result.Author('Benjamin Finley'), arxiv.Result.Author('Jouko Vankka')]","The role of social media in promoting media pluralism was initially viewed as
wholly positive. However, some governments are allegedly manipulating social
media by hiring online commentators (also known as trolls) to spread propaganda
and disinformation. In particular, an alleged system of professional trolls
operating both domestically and internationally exists in Russia. In 2018,
Twitter released data on accounts identified as Russian trolls, starting a wave
of research. However, while foreign-targeted English language operations of
these trolls have received significant attention, no research has analyzed
their Russian language domestic and regional-targeted activities. We address
this gap by characterizing the Russian-language operations of Russian trolls.
We first perform a descriptive analysis, and then focus in on the trolls'
operation related to the crash of Malaysia Airlines flight MH17.
  Among other things, we find that Russian-language trolls have run 163 hashtag
campaigns (where hashtag use grows abruptly within a month). The main political
sentiments of such campaigns were praising Russia and Putin (29%), criticizing
Ukraine (26%), and criticizing the United States and Obama (9%). Further,
trolls actively reshared information with 76% of tweets being retweets or
containing a URL. Additionally, we observe periodic temporal patterns of
tweeting suggesting that trolls use automation tools. Further, we find that
trolls' information campaign on the MH17 crash was the largest in terms of
tweet count. However, around 68% of tweets posted with MH17 hashtags were
likely used simply for hashtag amplification. With these tweets excluded, about
49% of the tweets suggested to varying levels that Ukraine was responsible for
the crash, and only 13% contained disinformation and propaganda presented as
news. Interestingly, trolls promoted inconsistent alternative theories for the
crash.","12th ACM Conference on Web Science (WebSci '20), July 6--10, 2020,
  Southampton, United Kingdom",,10.1145/3394231.3397898,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3394231.3397898', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.06558v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.06558v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.06558v1,"{'id': 'http://arxiv.org/abs/2005.06558v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.06558v1', 'updated': '2020-05-13T19:48:12Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=13, tm_hour=19, tm_min=48, tm_sec=12, tm_wday=2, tm_yday=134, tm_isdst=0), 'published': '2020-05-13T19:48:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=13, tm_hour=19, tm_min=48, tm_sec=12, tm_wday=2, tm_yday=134, tm_isdst=0), 'title': 'Russian trolls speaking Russian: Regional Twitter operations and MH17', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Russian trolls speaking Russian: Regional Twitter operations and MH17'}, 'summary': ""The role of social media in promoting media pluralism was initially viewed as\nwholly positive. However, some governments are allegedly manipulating social\nmedia by hiring online commentators (also known as trolls) to spread propaganda\nand disinformation. In particular, an alleged system of professional trolls\noperating both domestically and internationally exists in Russia. In 2018,\nTwitter released data on accounts identified as Russian trolls, starting a wave\nof research. However, while foreign-targeted English language operations of\nthese trolls have received significant attention, no research has analyzed\ntheir Russian language domestic and regional-targeted activities. We address\nthis gap by characterizing the Russian-language operations of Russian trolls.\nWe first perform a descriptive analysis, and then focus in on the trolls'\noperation related to the crash of Malaysia Airlines flight MH17.\n  Among other things, we find that Russian-language trolls have run 163 hashtag\ncampaigns (where hashtag use grows abruptly within a month). The main political\nsentiments of such campaigns were praising Russia and Putin (29%), criticizing\nUkraine (26%), and criticizing the United States and Obama (9%). Further,\ntrolls actively reshared information with 76% of tweets being retweets or\ncontaining a URL. Additionally, we observe periodic temporal patterns of\ntweeting suggesting that trolls use automation tools. Further, we find that\ntrolls' information campaign on the MH17 crash was the largest in terms of\ntweet count. However, around 68% of tweets posted with MH17 hashtags were\nlikely used simply for hashtag amplification. With these tweets excluded, about\n49% of the tweets suggested to varying levels that Ukraine was responsible for\nthe crash, and only 13% contained disinformation and propaganda presented as\nnews. Interestingly, trolls promoted inconsistent alternative theories for the\ncrash."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The role of social media in promoting media pluralism was initially viewed as\nwholly positive. However, some governments are allegedly manipulating social\nmedia by hiring online commentators (also known as trolls) to spread propaganda\nand disinformation. In particular, an alleged system of professional trolls\noperating both domestically and internationally exists in Russia. In 2018,\nTwitter released data on accounts identified as Russian trolls, starting a wave\nof research. However, while foreign-targeted English language operations of\nthese trolls have received significant attention, no research has analyzed\ntheir Russian language domestic and regional-targeted activities. We address\nthis gap by characterizing the Russian-language operations of Russian trolls.\nWe first perform a descriptive analysis, and then focus in on the trolls'\noperation related to the crash of Malaysia Airlines flight MH17.\n  Among other things, we find that Russian-language trolls have run 163 hashtag\ncampaigns (where hashtag use grows abruptly within a month). The main political\nsentiments of such campaigns were praising Russia and Putin (29%), criticizing\nUkraine (26%), and criticizing the United States and Obama (9%). Further,\ntrolls actively reshared information with 76% of tweets being retweets or\ncontaining a URL. Additionally, we observe periodic temporal patterns of\ntweeting suggesting that trolls use automation tools. Further, we find that\ntrolls' information campaign on the MH17 crash was the largest in terms of\ntweet count. However, around 68% of tweets posted with MH17 hashtags were\nlikely used simply for hashtag amplification. With these tweets excluded, about\n49% of the tweets suggested to varying levels that Ukraine was responsible for\nthe crash, and only 13% contained disinformation and propaganda presented as\nnews. Interestingly, trolls promoted inconsistent alternative theories for the\ncrash.""}, 'authors': [{'name': 'Alexandr Vesselkov'}, {'name': 'Benjamin Finley'}, {'name': 'Jouko Vankka'}], 'author_detail': {'name': 'Jouko Vankka'}, 'author': 'Jouko Vankka', 'arxiv_doi': '10.1145/3394231.3397898', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3394231.3397898', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.06558v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.06558v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""12th ACM Conference on Web Science (WebSci '20), July 6--10, 2020,\n  Southampton, United Kingdom"", 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
99,http://arxiv.org/abs/2005.05854v1,2020-05-12 15:20:55+00:00,2020-05-12 15:20:55+00:00,Prta: A System to Support the Analysis of Propaganda Techniques in the News,"[arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Yifan Zhang'), arxiv.Result.Author('Seunghak Yu'), arxiv.Result.Author('Alberto Barrón-Cedeño'), arxiv.Result.Author('Preslav Nakov')]","Recent events, such as the 2016 US Presidential Campaign, Brexit and the
COVID-19 ""infodemic"", have brought into the spotlight the dangers of online
disinformation. There has been a lot of research focusing on fact-checking and
disinformation detection. However, little attention has been paid to the
specific rhetorical and psychological techniques used to convey propaganda
messages. Revealing the use of such techniques can help promote media literacy
and critical thinking, and eventually contribute to limiting the impact of
""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion
Techniques Analyzer) allows users to explore the articles crawled on a regular
basis by highlighting the spans in which propaganda techniques occur and to
compare them on the basis of their use of propaganda techniques. The system
further reports statistics about the use of such techniques, overall and over
time, or according to filtering criteria specified by the user based on time
interval, keywords, and/or political orientation of the media. Moreover, it
allows users to analyze any text or URL through a dedicated interface or via an
API. The system is available online: https://www.tanbih.org/prta","propaganda, disinformation, fake news, media bias, COVID-19",ACL-2020,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'cs.NE', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2005.05854v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.05854v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.05854v1,"{'id': 'http://arxiv.org/abs/2005.05854v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.05854v1', 'updated': '2020-05-12T15:20:55Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=15, tm_min=20, tm_sec=55, tm_wday=1, tm_yday=133, tm_isdst=0), 'published': '2020-05-12T15:20:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=15, tm_min=20, tm_sec=55, tm_wday=1, tm_yday=133, tm_isdst=0), 'title': 'Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News'}, 'summary': 'Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 ""infodemic"", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 ""infodemic"", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta'}, 'authors': [{'name': 'Giovanni Da San Martino'}, {'name': 'Shaden Shaar'}, {'name': 'Yifan Zhang'}, {'name': 'Seunghak Yu'}, {'name': 'Alberto Barrón-Cedeño'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'propaganda, disinformation, fake news, media bias, COVID-19', 'arxiv_journal_ref': 'ACL-2020', 'links': [{'href': 'http://arxiv.org/abs/2005.05854v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.05854v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
100,http://arxiv.org/abs/2005.02764v1,2020-05-04 11:18:53+00:00,2020-05-04 11:18:53+00:00,In-store epidemic behavior: scale development and validation,"[arxiv.Result.Author('Andrzej Szymkowiak'), arxiv.Result.Author('Piotr Kulawik'), arxiv.Result.Author('Kishokanth Jeganathan'), arxiv.Result.Author('Paulina Guzik')]","Epidemics of infectious diseases have accompanied humans for a long time and,
depending on the scale, cause various undesirable social and economic
consequences. During the ongoing COVID-19 pandemic, governments of many
countries impose restrictions to inhibit spreading of infection. Isolation and
limiting interpersonal contacts are particularly recommended actions. Adhering
to the rule of isolation may involve restrictions in freedom during daily
activities, such as shopping. The aim of the study was to develop a scale of
in-store pandemic behavior. The whole process involved 3 stages: qualitative
inquiry, scale purification and scale validation, which were based on 3
studies: 1 qualitative (20 in-depth interviews) 2 two quantitative (373 and 584
respondents, respectively), and allowed to identify 8 factors. Following, a
theoretical model was created to investigate the impact of in-store infection
threat on identified variables. All identified factors significantly correlated
with the in-store infection threat which reiterates the importance of providing
information revealing the true scale of the pandemic and not leaving space for
individuals to create subjective probability judgments. The developed scale can
help counteract disinformation and assess consumer behavior compliance and
understanding of the official recommendations imposed by governments, enabling
more efficient educational efforts.",,,,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://arxiv.org/abs/2005.02764v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.02764v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.02764v1,"{'id': 'http://arxiv.org/abs/2005.02764v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.02764v1', 'updated': '2020-05-04T11:18:53Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=4, tm_hour=11, tm_min=18, tm_sec=53, tm_wday=0, tm_yday=125, tm_isdst=0), 'published': '2020-05-04T11:18:53Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=4, tm_hour=11, tm_min=18, tm_sec=53, tm_wday=0, tm_yday=125, tm_isdst=0), 'title': 'In-store epidemic behavior: scale development and validation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In-store epidemic behavior: scale development and validation'}, 'summary': 'Epidemics of infectious diseases have accompanied humans for a long time and,\ndepending on the scale, cause various undesirable social and economic\nconsequences. During the ongoing COVID-19 pandemic, governments of many\ncountries impose restrictions to inhibit spreading of infection. Isolation and\nlimiting interpersonal contacts are particularly recommended actions. Adhering\nto the rule of isolation may involve restrictions in freedom during daily\nactivities, such as shopping. The aim of the study was to develop a scale of\nin-store pandemic behavior. The whole process involved 3 stages: qualitative\ninquiry, scale purification and scale validation, which were based on 3\nstudies: 1 qualitative (20 in-depth interviews) 2 two quantitative (373 and 584\nrespondents, respectively), and allowed to identify 8 factors. Following, a\ntheoretical model was created to investigate the impact of in-store infection\nthreat on identified variables. All identified factors significantly correlated\nwith the in-store infection threat which reiterates the importance of providing\ninformation revealing the true scale of the pandemic and not leaving space for\nindividuals to create subjective probability judgments. The developed scale can\nhelp counteract disinformation and assess consumer behavior compliance and\nunderstanding of the official recommendations imposed by governments, enabling\nmore efficient educational efforts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Epidemics of infectious diseases have accompanied humans for a long time and,\ndepending on the scale, cause various undesirable social and economic\nconsequences. During the ongoing COVID-19 pandemic, governments of many\ncountries impose restrictions to inhibit spreading of infection. Isolation and\nlimiting interpersonal contacts are particularly recommended actions. Adhering\nto the rule of isolation may involve restrictions in freedom during daily\nactivities, such as shopping. The aim of the study was to develop a scale of\nin-store pandemic behavior. The whole process involved 3 stages: qualitative\ninquiry, scale purification and scale validation, which were based on 3\nstudies: 1 qualitative (20 in-depth interviews) 2 two quantitative (373 and 584\nrespondents, respectively), and allowed to identify 8 factors. Following, a\ntheoretical model was created to investigate the impact of in-store infection\nthreat on identified variables. All identified factors significantly correlated\nwith the in-store infection threat which reiterates the importance of providing\ninformation revealing the true scale of the pandemic and not leaving space for\nindividuals to create subjective probability judgments. The developed scale can\nhelp counteract disinformation and assess consumer behavior compliance and\nunderstanding of the official recommendations imposed by governments, enabling\nmore efficient educational efforts.'}, 'authors': [{'name': 'Andrzej Szymkowiak'}, {'name': 'Piotr Kulawik'}, {'name': 'Kishokanth Jeganathan'}, {'name': 'Paulina Guzik'}], 'author_detail': {'name': 'Paulina Guzik'}, 'author': 'Paulina Guzik', 'links': [{'href': 'http://arxiv.org/abs/2005.02764v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.02764v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
101,http://arxiv.org/abs/2005.01157v1,2020-05-03 18:02:10+00:00,2020-05-03 18:02:10+00:00,Out of the Echo Chamber: Detecting Countering Debate Speeches,"[arxiv.Result.Author('Matan Orbach'), arxiv.Result.Author('Yonatan Bilu'), arxiv.Result.Author('Assaf Toledo'), arxiv.Result.Author('Dan Lahav'), arxiv.Result.Author('Michal Jacovi'), arxiv.Result.Author('Ranit Aharonov'), arxiv.Result.Author('Noam Slonim')]","An educated and informed consumption of media content has become a challenge
in modern times. With the shift from traditional news outlets to social media
and similar venues, a major concern is that readers are becoming encapsulated
in ""echo chambers"" and may fall prey to fake news and disinformation, lacking
easy access to dissenting views. We suggest a novel task aiming to alleviate
some of these concerns -- that of detecting articles that most effectively
counter the arguments -- and not just the stance -- made in a given text. We
study this problem in the context of debate speeches. Given such a speech, we
aim to identify, from among a set of speeches on the same topic and with an
opposing stance, the ones that directly counter it. We provide a large dataset
of 3,685 such speeches (in English), annotated for this relation, which
hopefully would be of general interest to the NLP community. We explore several
algorithms addressing this task, and while some are successful, all fall short
of expert human performance, suggesting room for further research. All data
collected during this work is freely available for research.","Accepted to ACL 2020 as Long Paper. For the associated debate
  speeches corpus, see
  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2005.01157v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.01157v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.01157v1,"{'id': 'http://arxiv.org/abs/2005.01157v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.01157v1', 'updated': '2020-05-03T18:02:10Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=3, tm_hour=18, tm_min=2, tm_sec=10, tm_wday=6, tm_yday=124, tm_isdst=0), 'published': '2020-05-03T18:02:10Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=3, tm_hour=18, tm_min=2, tm_sec=10, tm_wday=6, tm_yday=124, tm_isdst=0), 'title': 'Out of the Echo Chamber: Detecting Countering Debate Speeches', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Out of the Echo Chamber: Detecting Countering Debate Speeches'}, 'summary': 'An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin ""echo chambers"" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin ""echo chambers"" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.'}, 'authors': [{'name': 'Matan Orbach'}, {'name': 'Yonatan Bilu'}, {'name': 'Assaf Toledo'}, {'name': 'Dan Lahav'}, {'name': 'Michal Jacovi'}, {'name': 'Ranit Aharonov'}, {'name': 'Noam Slonim'}], 'author_detail': {'name': 'Noam Slonim'}, 'author': 'Noam Slonim', 'arxiv_comment': 'Accepted to ACL 2020 as Long Paper. For the associated debate\n  speeches corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis', 'links': [{'href': 'http://arxiv.org/abs/2005.01157v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.01157v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
102,http://arxiv.org/abs/2005.00033v5,2021-09-22 13:35:06+00:00,2020-04-30 18:04:20+00:00,"Fighting the COVID-19 Infodemic: Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society","[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Fahim Dalvi'), arxiv.Result.Author('Hassan Sajjad'), arxiv.Result.Author('Alex Nikolov'), arxiv.Result.Author('Hamdy Mubarak'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Ahmed Abdelali'), arxiv.Result.Author('Nadir Durrani'), arxiv.Result.Author('Kareem Darwish'), arxiv.Result.Author('Abdulaziz Al-Homaid'), arxiv.Result.Author('Wajdi Zaghouani'), arxiv.Result.Author('Tommaso Caselli'), arxiv.Result.Author('Gijs Danoe'), arxiv.Result.Author('Friso Stolk'), arxiv.Result.Author('Britt Bruntink'), arxiv.Result.Author('Preslav Nakov')]","With the emergence of the COVID-19 pandemic, the political and the medical
aspects of disinformation merged as the problem got elevated to a whole new
level to become the first global infodemic. Fighting this infodemic has been
declared one of the most important focus areas of the World Health
Organization, with dangers ranging from promoting fake cures, rumors, and
conspiracy theories to spreading xenophobia and panic. Addressing the issue
requires solving a number of challenging problems such as identifying messages
containing claims, determining their check-worthiness and factuality, and their
potential to do harm as well as the nature of that harm, to mention just a few.
To address this gap, we release a large dataset of 16K manually annotated
tweets for fine-grained disinformation analysis that (i) focuses on COVID-19,
(ii) combines the perspectives and the interests of journalists, fact-checkers,
social media platforms, policy makers, and society, and (iii) covers Arabic,
Bulgarian, Dutch, and English. Finally, we show strong evaluation results using
pretrained Transformers, thus confirming the practical utility of the dataset
in monolingual vs. multilingual, and single task vs. multitask settings.","disinformation, misinformation, factuality, fact-checking,
  fact-checkers, check-worthiness, Social Media Platforms, COVID-19, social
  media",EMNLP-2021 (Findings),,cs.CL,"['cs.CL', 'cs.CY', 'cs.IR', '68T50', 'I.2; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2005.00033v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.00033v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.00033v5,"{'id': 'http://arxiv.org/abs/2005.00033v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.00033v5', 'updated': '2021-09-22T13:35:06Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=13, tm_min=35, tm_sec=6, tm_wday=2, tm_yday=265, tm_isdst=0), 'published': '2020-04-30T18:04:20Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=18, tm_min=4, tm_sec=20, tm_wday=3, tm_yday=121, tm_isdst=0), 'title': 'Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society'}, 'summary': 'With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic has been\ndeclared one of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nTo address this gap, we release a large dataset of 16K manually annotated\ntweets for fine-grained disinformation analysis that (i) focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society, and (iii) covers Arabic,\nBulgarian, Dutch, and English. Finally, we show strong evaluation results using\npretrained Transformers, thus confirming the practical utility of the dataset\nin monolingual vs. multilingual, and single task vs. multitask settings.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic has been\ndeclared one of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nTo address this gap, we release a large dataset of 16K manually annotated\ntweets for fine-grained disinformation analysis that (i) focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society, and (iii) covers Arabic,\nBulgarian, Dutch, and English. Finally, we show strong evaluation results using\npretrained Transformers, thus confirming the practical utility of the dataset\nin monolingual vs. multilingual, and single task vs. multitask settings.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Shaden Shaar'}, {'name': 'Fahim Dalvi'}, {'name': 'Hassan Sajjad'}, {'name': 'Alex Nikolov'}, {'name': 'Hamdy Mubarak'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Ahmed Abdelali'}, {'name': 'Nadir Durrani'}, {'name': 'Kareem Darwish'}, {'name': 'Abdulaziz Al-Homaid'}, {'name': 'Wajdi Zaghouani'}, {'name': 'Tommaso Caselli'}, {'name': 'Gijs Danoe'}, {'name': 'Friso Stolk'}, {'name': 'Britt Bruntink'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'disinformation, misinformation, factuality, fact-checking,\n  fact-checkers, check-worthiness, Social Media Platforms, COVID-19, social\n  media', 'arxiv_journal_ref': 'EMNLP-2021 (Findings)', 'links': [{'href': 'http://arxiv.org/abs/2005.00033v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.00033v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
103,http://arxiv.org/abs/2004.11480v1,2020-04-23 22:25:48+00:00,2020-04-23 22:25:48+00:00,Characterising User Content on a Multi-lingual Social Network,"[arxiv.Result.Author('Pushkal Agarwal'), arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Sagar Joglekar'), arxiv.Result.Author('Nishanth Sastry'), arxiv.Result.Author('Gareth Tyson')]","Social media has been on the vanguard of political information diffusion in
the 21st century. Most studies that look into disinformation, political
influence and fake-news focus on mainstream social media platforms. This has
inevitably made English an important factor in our current understanding of
political activity on social media. As a result, there has only been a limited
number of studies into a large portion of the world, including the largest,
multilingual and multi-cultural democracy: India. In this paper we present our
characterisation of a multilingual social network in India called ShareChat. We
collect an exhaustive dataset across 72 weeks before and during the Indian
general elections of 2019, across 14 languages. We investigate the cross
lingual dynamics by clustering visually similar images together, and exploring
how they move across language barriers. We find that Telugu, Malayalam, Tamil
and Kannada languages tend to be dominant in soliciting political images (often
referred to as memes), and posts from Hindi have the largest cross-lingual
diffusion across ShareChat (as well as images containing text in English). In
the case of images containing text that cross language barriers, we see that
language translation is used to widen the accessibility. That said, we find
cases where the same image is associated with very different text (and
therefore meanings). This initial characterisation paves the way for more
advanced pipelines to understand the dynamics of fake and political content in
a multi-lingual and non-textual setting.","Accepted at ICWSM 2020, please cite the ICWSM version",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2004.11480v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.11480v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.11480v1,"{'id': 'http://arxiv.org/abs/2004.11480v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.11480v1', 'updated': '2020-04-23T22:25:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=23, tm_hour=22, tm_min=25, tm_sec=48, tm_wday=3, tm_yday=114, tm_isdst=0), 'published': '2020-04-23T22:25:48Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=23, tm_hour=22, tm_min=25, tm_sec=48, tm_wday=3, tm_yday=114, tm_isdst=0), 'title': 'Characterising User Content on a Multi-lingual Social Network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterising User Content on a Multi-lingual Social Network'}, 'summary': 'Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.'}, 'authors': [{'name': 'Pushkal Agarwal'}, {'name': 'Kiran Garimella'}, {'name': 'Sagar Joglekar'}, {'name': 'Nishanth Sastry'}, {'name': 'Gareth Tyson'}], 'author_detail': {'name': 'Gareth Tyson'}, 'author': 'Gareth Tyson', 'arxiv_comment': 'Accepted at ICWSM 2020, please cite the ICWSM version', 'links': [{'href': 'http://arxiv.org/abs/2004.11480v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.11480v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
104,http://arxiv.org/abs/2004.06793v1,2020-04-14 20:18:21+00:00,2020-04-14 20:18:21+00:00,Probabilistic Model of Narratives Over Topical Trends in Social Media: A Discrete Time Model,"[arxiv.Result.Author('Toktam A. Oghaz'), arxiv.Result.Author('Ece C. Mutlu'), arxiv.Result.Author('Jasser Jasser'), arxiv.Result.Author('Niloofar Yousefi'), arxiv.Result.Author('Ivan Garibay')]","Online social media platforms are turning into the prime source of news and
narratives about worldwide events. However,a systematic summarization-based
narrative extraction that can facilitate communicating the main underlying
events is lacking. To address this issue, we propose a novel event-based
narrative summary extraction framework. Our proposed framework is designed as a
probabilistic topic model, with categorical time distribution, followed by
extractive text summarization. Our topic model identifies topics' recurrence
over time with a varying time resolution. This framework not only captures the
topic distributions from the data, but also approximates the user activity
fluctuations over time. Furthermore, we define significance-dispersity
trade-off (SDT) as a comparison measure to identify the topic with the highest
lifetime attractiveness in a timestamped corpus. We evaluate our model on a
large corpus of Twitter data, including more than one million tweets in the
domain of the disinformation campaigns conducted against the White Helmets of
Syria. Our results indicate that the proposed framework is effective in
identifying topical trends, as well as extracting narrative summaries from text
corpus with timestamped data.","9 pages, 4 figures",,10.1145/3372923.3404790,cs.SI,"['cs.SI', 'cs.CL', 'cs.IR']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3372923.3404790', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.06793v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.06793v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.06793v1,"{'id': 'http://arxiv.org/abs/2004.06793v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.06793v1', 'updated': '2020-04-14T20:18:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=14, tm_hour=20, tm_min=18, tm_sec=21, tm_wday=1, tm_yday=105, tm_isdst=0), 'published': '2020-04-14T20:18:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=14, tm_hour=20, tm_min=18, tm_sec=21, tm_wday=1, tm_yday=105, tm_isdst=0), 'title': 'Probabilistic Model of Narratives Over Topical Trends in Social Media: A\n  Discrete Time Model', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Probabilistic Model of Narratives Over Topical Trends in Social Media: A\n  Discrete Time Model'}, 'summary': ""Online social media platforms are turning into the prime source of news and\nnarratives about worldwide events. However,a systematic summarization-based\nnarrative extraction that can facilitate communicating the main underlying\nevents is lacking. To address this issue, we propose a novel event-based\nnarrative summary extraction framework. Our proposed framework is designed as a\nprobabilistic topic model, with categorical time distribution, followed by\nextractive text summarization. Our topic model identifies topics' recurrence\nover time with a varying time resolution. This framework not only captures the\ntopic distributions from the data, but also approximates the user activity\nfluctuations over time. Furthermore, we define significance-dispersity\ntrade-off (SDT) as a comparison measure to identify the topic with the highest\nlifetime attractiveness in a timestamped corpus. We evaluate our model on a\nlarge corpus of Twitter data, including more than one million tweets in the\ndomain of the disinformation campaigns conducted against the White Helmets of\nSyria. Our results indicate that the proposed framework is effective in\nidentifying topical trends, as well as extracting narrative summaries from text\ncorpus with timestamped data."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online social media platforms are turning into the prime source of news and\nnarratives about worldwide events. However,a systematic summarization-based\nnarrative extraction that can facilitate communicating the main underlying\nevents is lacking. To address this issue, we propose a novel event-based\nnarrative summary extraction framework. Our proposed framework is designed as a\nprobabilistic topic model, with categorical time distribution, followed by\nextractive text summarization. Our topic model identifies topics' recurrence\nover time with a varying time resolution. This framework not only captures the\ntopic distributions from the data, but also approximates the user activity\nfluctuations over time. Furthermore, we define significance-dispersity\ntrade-off (SDT) as a comparison measure to identify the topic with the highest\nlifetime attractiveness in a timestamped corpus. We evaluate our model on a\nlarge corpus of Twitter data, including more than one million tweets in the\ndomain of the disinformation campaigns conducted against the White Helmets of\nSyria. Our results indicate that the proposed framework is effective in\nidentifying topical trends, as well as extracting narrative summaries from text\ncorpus with timestamped data.""}, 'authors': [{'name': 'Toktam A. Oghaz'}, {'name': 'Ece C. Mutlu'}, {'name': 'Jasser Jasser'}, {'name': 'Niloofar Yousefi'}, {'name': 'Ivan Garibay'}], 'author_detail': {'name': 'Ivan Garibay'}, 'author': 'Ivan Garibay', 'arxiv_doi': '10.1145/3372923.3404790', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3372923.3404790', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.06793v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.06793v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '9 pages, 4 figures', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
105,http://arxiv.org/abs/2004.00673v2,2020-04-21 20:50:30+00:00,2020-04-01 19:32:25+00:00,Hate multiverse spreads malicious COVID-19 content online beyond individual platform control,"[arxiv.Result.Author('N. Velásquez'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('Y. Lupu'), arxiv.Result.Author('R. Sear'), arxiv.Result.Author('N. Gabriel'), arxiv.Result.Author('O. Jha'), arxiv.Result.Author('B. Goldberg'), arxiv.Result.Author('N. F. Johnson')]","We show that malicious COVID-19 content, including hate speech,
disinformation, and misinformation, exploits the multiverse of online hate to
spread quickly beyond the control of any individual social media platform.
Machine learning topic analysis shows quantitatively how online hate
communities are weaponizing COVID-19, with topics evolving rapidly and content
becoming increasingly coherent. Our mathematical analysis provides a
generalized form of the public health R0 predicting the tipping point for
multiverse-wide viral spreading, which suggests new policy options to mitigate
the global spread of malicious COVID-19 content without relying on future
coordination between all online platforms.","Working paper. Feedback welcomed from the community to
  neiljohnson@gwu.edu",,,physics.soc-ph,"['physics.soc-ph', 'nlin.AO', 'physics.pop-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2004.00673v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00673v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00673v2,"{'id': 'http://arxiv.org/abs/2004.00673v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00673v2', 'updated': '2020-04-21T20:50:30Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=21, tm_hour=20, tm_min=50, tm_sec=30, tm_wday=1, tm_yday=112, tm_isdst=0), 'published': '2020-04-01T19:32:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=1, tm_hour=19, tm_min=32, tm_sec=25, tm_wday=2, tm_yday=92, tm_isdst=0), 'title': 'Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control'}, 'summary': 'We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.'}, 'authors': [{'name': 'N. Velásquez'}, {'name': 'R. Leahy'}, {'name': 'N. Johnson Restrepo'}, {'name': 'Y. Lupu'}, {'name': 'R. Sear'}, {'name': 'N. Gabriel'}, {'name': 'O. Jha'}, {'name': 'B. Goldberg'}, {'name': 'N. F. Johnson'}], 'author_detail': {'name': 'N. F. Johnson'}, 'author': 'N. F. Johnson', 'arxiv_comment': 'Working paper. Feedback welcomed from the community to\n  neiljohnson@gwu.edu', 'links': [{'href': 'http://arxiv.org/abs/2004.00673v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00673v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
106,http://arxiv.org/abs/2004.00379v1,2020-03-29 01:07:04+00:00,2020-03-29 01:07:04+00:00,Resistance of communities against disinformation,"[arxiv.Result.Author('Amirarsalan Rajabi'), arxiv.Result.Author('Seyyedmilad Talebzadehhosseini'), arxiv.Result.Author('Ivan Garibay')]","The spread of disinformation is considered a big threat to societies and has
recently received unprecedented attention. In this paper we propose an
agent-based model to simulate dissemination of a conspiracy in a population.
The model is able to compare the resistance of different network structures
against the activity of conspirators. Results show that connectedness of
network structure and centrality of conspirators are of crucial importance in
preventing conspiracies from becoming widespread.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.00379v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00379v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00379v1,"{'id': 'http://arxiv.org/abs/2004.00379v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00379v1', 'updated': '2020-03-29T01:07:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=29, tm_hour=1, tm_min=7, tm_sec=4, tm_wday=6, tm_yday=89, tm_isdst=0), 'published': '2020-03-29T01:07:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=29, tm_hour=1, tm_min=7, tm_sec=4, tm_wday=6, tm_yday=89, tm_isdst=0), 'title': 'Resistance of communities against disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Resistance of communities against disinformation'}, 'summary': 'The spread of disinformation is considered a big threat to societies and has\nrecently received unprecedented attention. In this paper we propose an\nagent-based model to simulate dissemination of a conspiracy in a population.\nThe model is able to compare the resistance of different network structures\nagainst the activity of conspirators. Results show that connectedness of\nnetwork structure and centrality of conspirators are of crucial importance in\npreventing conspiracies from becoming widespread.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of disinformation is considered a big threat to societies and has\nrecently received unprecedented attention. In this paper we propose an\nagent-based model to simulate dissemination of a conspiracy in a population.\nThe model is able to compare the resistance of different network structures\nagainst the activity of conspirators. Results show that connectedness of\nnetwork structure and centrality of conspirators are of crucial importance in\npreventing conspiracies from becoming widespread.'}, 'authors': [{'name': 'Amirarsalan Rajabi'}, {'name': 'Seyyedmilad Talebzadehhosseini'}, {'name': 'Ivan Garibay'}], 'author_detail': {'name': 'Ivan Garibay'}, 'author': 'Ivan Garibay', 'links': [{'href': 'http://arxiv.org/abs/2004.00379v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00379v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
107,http://arxiv.org/abs/2003.03723v1,2020-03-08 05:33:53+00:00,2020-03-08 05:33:53+00:00,Traffic networks are vulnerable to disinformation attacks,"[arxiv.Result.Author('Marcin Waniek'), arxiv.Result.Author('Gururaghav Raman'), arxiv.Result.Author('Bedoor AlShebli'), arxiv.Result.Author('Jimmy Chih-Hsien Peng'), arxiv.Result.Author('Talal Rahwan')]","Disinformation continues to attract attention due to its increasing threat to
society. Nevertheless, a disinformation-based attack on critical infrastructure
has never been studied to date. Here, we consider traffic networks and focus on
fake information that manipulates drivers' decisions to create congestion. We
study the optimization problem faced by the adversary when choosing which
streets to target to maximize disruption. We prove that finding an optimal
solution is computationally intractable, implying that the adversary has no
choice but to settle for suboptimal heuristics. We analyze one such heuristic,
and compare the cases when targets are spread across the city of Chicago vs.
concentrated in its business district. Surprisingly, the latter results in more
far-reaching disruption, with its impact felt as far as 2 kilometers from the
closest target. Our findings demonstrate that vulnerabilities in critical
infrastructure may arise not only from hardware and software, but also from
behavioral manipulation.","25 pages, 5 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2003.03723v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.03723v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.03723v1,"{'id': 'http://arxiv.org/abs/2003.03723v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.03723v1', 'updated': '2020-03-08T05:33:53Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=8, tm_hour=5, tm_min=33, tm_sec=53, tm_wday=6, tm_yday=68, tm_isdst=0), 'published': '2020-03-08T05:33:53Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=8, tm_hour=5, tm_min=33, tm_sec=53, tm_wday=6, tm_yday=68, tm_isdst=0), 'title': 'Traffic networks are vulnerable to disinformation attacks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Traffic networks are vulnerable to disinformation attacks'}, 'summary': ""Disinformation continues to attract attention due to its increasing threat to\nsociety. Nevertheless, a disinformation-based attack on critical infrastructure\nhas never been studied to date. Here, we consider traffic networks and focus on\nfake information that manipulates drivers' decisions to create congestion. We\nstudy the optimization problem faced by the adversary when choosing which\nstreets to target to maximize disruption. We prove that finding an optimal\nsolution is computationally intractable, implying that the adversary has no\nchoice but to settle for suboptimal heuristics. We analyze one such heuristic,\nand compare the cases when targets are spread across the city of Chicago vs.\nconcentrated in its business district. Surprisingly, the latter results in more\nfar-reaching disruption, with its impact felt as far as 2 kilometers from the\nclosest target. Our findings demonstrate that vulnerabilities in critical\ninfrastructure may arise not only from hardware and software, but also from\nbehavioral manipulation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation continues to attract attention due to its increasing threat to\nsociety. Nevertheless, a disinformation-based attack on critical infrastructure\nhas never been studied to date. Here, we consider traffic networks and focus on\nfake information that manipulates drivers' decisions to create congestion. We\nstudy the optimization problem faced by the adversary when choosing which\nstreets to target to maximize disruption. We prove that finding an optimal\nsolution is computationally intractable, implying that the adversary has no\nchoice but to settle for suboptimal heuristics. We analyze one such heuristic,\nand compare the cases when targets are spread across the city of Chicago vs.\nconcentrated in its business district. Surprisingly, the latter results in more\nfar-reaching disruption, with its impact felt as far as 2 kilometers from the\nclosest target. Our findings demonstrate that vulnerabilities in critical\ninfrastructure may arise not only from hardware and software, but also from\nbehavioral manipulation.""}, 'authors': [{'name': 'Marcin Waniek'}, {'name': 'Gururaghav Raman'}, {'name': 'Bedoor AlShebli'}, {'name': 'Jimmy Chih-Hsien Peng'}, {'name': 'Talal Rahwan'}], 'author_detail': {'name': 'Talal Rahwan'}, 'author': 'Talal Rahwan', 'arxiv_comment': '25 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2003.03723v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.03723v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
108,http://arxiv.org/abs/2003.03318v1,2020-03-06 17:31:30+00:00,2020-03-06 17:31:30+00:00,A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos,"[arxiv.Result.Author('Marc Faddoul'), arxiv.Result.Author('Guillaume Chaslot'), arxiv.Result.Author('Hany Farid')]","Conspiracy theories have flourished on social media, raising concerns that
such content is fueling the spread of disinformation, supporting extremist
ideologies, and in some cases, leading to violence. Under increased scrutiny
and pressure from legislators and the public, YouTube announced efforts to
change their recommendation algorithms so that the most egregious conspiracy
videos are demoted and demonetized. To verify this claim, we have developed a
classifier for automatically determining if a video is conspiratorial (e.g.,
the moon landing was faked, the pyramids of Giza were built by aliens, end of
the world prophecies, etc.). We coupled this classifier with an emulation of
YouTube's watch-next algorithm on more than a thousand popular informational
channels to obtain a year-long picture of the videos actively promoted by
YouTube. We also obtained trends of the so-called filter-bubble effect for
conspiracy theories.","8 pages, 3 figures. This paper was first released on March 2nd, 2020
  along with a coverage from the New York Times available at
  https://www.nytimes.com/interactive/2020/03/02/technology/youtube-conspiracy-theory.html",,,cs.CY,"['cs.CY', 'cs.HC', 'cs.IR', 'cs.SI', 'K.4.1; K.4.2; J.4; I.2.8; I.2.6']","[arxiv.Result.Link('http://arxiv.org/abs/2003.03318v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.03318v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.03318v1,"{'id': 'http://arxiv.org/abs/2003.03318v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.03318v1', 'updated': '2020-03-06T17:31:30Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=6, tm_hour=17, tm_min=31, tm_sec=30, tm_wday=4, tm_yday=66, tm_isdst=0), 'published': '2020-03-06T17:31:30Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=6, tm_hour=17, tm_min=31, tm_sec=30, tm_wday=4, tm_yday=66, tm_isdst=0), 'title': ""A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos""}, 'summary': ""Conspiracy theories have flourished on social media, raising concerns that\nsuch content is fueling the spread of disinformation, supporting extremist\nideologies, and in some cases, leading to violence. Under increased scrutiny\nand pressure from legislators and the public, YouTube announced efforts to\nchange their recommendation algorithms so that the most egregious conspiracy\nvideos are demoted and demonetized. To verify this claim, we have developed a\nclassifier for automatically determining if a video is conspiratorial (e.g.,\nthe moon landing was faked, the pyramids of Giza were built by aliens, end of\nthe world prophecies, etc.). We coupled this classifier with an emulation of\nYouTube's watch-next algorithm on more than a thousand popular informational\nchannels to obtain a year-long picture of the videos actively promoted by\nYouTube. We also obtained trends of the so-called filter-bubble effect for\nconspiracy theories."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Conspiracy theories have flourished on social media, raising concerns that\nsuch content is fueling the spread of disinformation, supporting extremist\nideologies, and in some cases, leading to violence. Under increased scrutiny\nand pressure from legislators and the public, YouTube announced efforts to\nchange their recommendation algorithms so that the most egregious conspiracy\nvideos are demoted and demonetized. To verify this claim, we have developed a\nclassifier for automatically determining if a video is conspiratorial (e.g.,\nthe moon landing was faked, the pyramids of Giza were built by aliens, end of\nthe world prophecies, etc.). We coupled this classifier with an emulation of\nYouTube's watch-next algorithm on more than a thousand popular informational\nchannels to obtain a year-long picture of the videos actively promoted by\nYouTube. We also obtained trends of the so-called filter-bubble effect for\nconspiracy theories.""}, 'authors': [{'name': 'Marc Faddoul'}, {'name': 'Guillaume Chaslot'}, {'name': 'Hany Farid'}], 'author_detail': {'name': 'Hany Farid'}, 'author': 'Hany Farid', 'arxiv_comment': '8 pages, 3 figures. This paper was first released on March 2nd, 2020\n  along with a coverage from the New York Times available at\n  https://www.nytimes.com/interactive/2020/03/02/technology/youtube-conspiracy-theory.html', 'links': [{'href': 'http://arxiv.org/abs/2003.03318v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.03318v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'K.4.1; K.4.2; J.4; I.2.8; I.2.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
109,http://arxiv.org/abs/2003.01313v1,2020-03-03 03:25:16+00:00,2020-03-03 03:25:16+00:00,Unveiling Coordinated Groups Behind White Helmets Disinformation,"[arxiv.Result.Author('Diogo Pacheco'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Propaganda, disinformation, manipulation, and polarization are the modern
illnesses of a society increasingly dependent on social media as a source of
news. In this paper, we explore the disinformation campaign, sponsored by
Russia and allies, against the Syria Civil Defense (a.k.a. the White Helmets).
We unveil coordinated groups using automatic retweets and content duplication
to promote narratives and/or accounts. The results also reveal distinct
promoting strategies, ranging from the small groups sharing the exact same text
repeatedly, to complex ""news website factories"" where dozens of accounts
synchronously spread the same news from multiple sites.","To be presented at WWW 2020 Workshop on Computational Methods in
  Online Misbehavior and forthcoming in the Companion Proceedings of the Web
  Conference 2020",,10.1145/3366424.3385775,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3366424.3385775', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2003.01313v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.01313v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.01313v1,"{'id': 'http://arxiv.org/abs/2003.01313v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.01313v1', 'updated': '2020-03-03T03:25:16Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=3, tm_hour=3, tm_min=25, tm_sec=16, tm_wday=1, tm_yday=63, tm_isdst=0), 'published': '2020-03-03T03:25:16Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=3, tm_hour=3, tm_min=25, tm_sec=16, tm_wday=1, tm_yday=63, tm_isdst=0), 'title': 'Unveiling Coordinated Groups Behind White Helmets Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Unveiling Coordinated Groups Behind White Helmets Disinformation'}, 'summary': 'Propaganda, disinformation, manipulation, and polarization are the modern\nillnesses of a society increasingly dependent on social media as a source of\nnews. In this paper, we explore the disinformation campaign, sponsored by\nRussia and allies, against the Syria Civil Defense (a.k.a. the White Helmets).\nWe unveil coordinated groups using automatic retweets and content duplication\nto promote narratives and/or accounts. The results also reveal distinct\npromoting strategies, ranging from the small groups sharing the exact same text\nrepeatedly, to complex ""news website factories"" where dozens of accounts\nsynchronously spread the same news from multiple sites.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Propaganda, disinformation, manipulation, and polarization are the modern\nillnesses of a society increasingly dependent on social media as a source of\nnews. In this paper, we explore the disinformation campaign, sponsored by\nRussia and allies, against the Syria Civil Defense (a.k.a. the White Helmets).\nWe unveil coordinated groups using automatic retweets and content duplication\nto promote narratives and/or accounts. The results also reveal distinct\npromoting strategies, ranging from the small groups sharing the exact same text\nrepeatedly, to complex ""news website factories"" where dozens of accounts\nsynchronously spread the same news from multiple sites.'}, 'authors': [{'name': 'Diogo Pacheco'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1145/3366424.3385775', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3366424.3385775', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2003.01313v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.01313v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'To be presented at WWW 2020 Workshop on Computational Methods in\n  Online Misbehavior and forthcoming in the Companion Proceedings of the Web\n  Conference 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
110,http://arxiv.org/abs/2003.07684v5,2020-09-28 22:53:39+00:00,2020-02-28 18:40:54+00:00,Identifying Disinformation Websites Using Infrastructure Features,"[arxiv.Result.Author('Austin Hounsel'), arxiv.Result.Author('Jordan Holland'), arxiv.Result.Author('Ben Kaiser'), arxiv.Result.Author('Kevin Borgolte'), arxiv.Result.Author('Nick Feamster'), arxiv.Result.Author('Jonathan Mayer')]","Platforms have struggled to keep pace with the spread of disinformation.
Current responses like user reports, manual analysis, and third-party fact
checking are slow and difficult to scale, and as a result, disinformation can
spread unchecked for some time after being created. Automation is essential for
enabling platforms to respond rapidly to disinformation. In this work, we
explore a new direction for automated detection of disinformation websites:
infrastructure features. Our hypothesis is that while disinformation websites
may be perceptually similar to authentic news websites, there may also be
significant non-perceptual differences in the domain registrations, TLS/SSL
certificates, and web hosting configurations. Infrastructure features are
particularly valuable for detecting disinformation websites because they are
available before content goes live and reaches readers, enabling early
detection. We demonstrate the feasibility of our approach on a large corpus of
labeled website snapshots. We also present results from a preliminary real-time
deployment, successfully discovering disinformation websites while highlighting
unexplored challenges for automated disinformation detection.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2003.07684v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07684v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07684v5,"{'id': 'http://arxiv.org/abs/2003.07684v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07684v5', 'updated': '2020-09-28T22:53:39Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=28, tm_hour=22, tm_min=53, tm_sec=39, tm_wday=0, tm_yday=272, tm_isdst=0), 'published': '2020-02-28T18:40:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=28, tm_hour=18, tm_min=40, tm_sec=54, tm_wday=4, tm_yday=59, tm_isdst=0), 'title': 'Identifying Disinformation Websites Using Infrastructure Features', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Disinformation Websites Using Infrastructure Features'}, 'summary': 'Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.'}, 'authors': [{'name': 'Austin Hounsel'}, {'name': 'Jordan Holland'}, {'name': 'Ben Kaiser'}, {'name': 'Kevin Borgolte'}, {'name': 'Nick Feamster'}, {'name': 'Jonathan Mayer'}], 'author_detail': {'name': 'Jonathan Mayer'}, 'author': 'Jonathan Mayer', 'links': [{'href': 'http://arxiv.org/abs/2003.07684v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07684v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
111,http://arxiv.org/abs/2002.12612v2,2020-11-12 08:23:47+00:00,2020-02-28 09:25:53+00:00,A multi-layer approach to disinformation detection on Twitter,"[arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Carlo Piccardi'), arxiv.Result.Author('Stefano Ceri')]","We tackle the problem of classifying news articles pertaining to
disinformation vs mainstream news by solely inspecting their diffusion
mechanisms on Twitter. Our technique is inherently simple compared to existing
text-based approaches, as it allows to by-pass the multiple levels of
complexity which are found in news content (e.g. grammar, syntax, style). We
employ a multi-layer representation of Twitter diffusion networks, and we
compute for each layer a set of global network features which quantify
different aspects of the sharing process. Experimental results with two
large-scale datasets, corresponding to diffusion cascades of news shared
respectively in the United States and Italy, show that a simple Logistic
Regression model is able to classify disinformation vs mainstream networks with
high accuracy (AUROC up to 94%), also when considering the political bias of
different sources in the classification task. We also highlight differences in
the sharing patterns of the two news domains which appear to be
country-independent. We believe that our network-based approach provides useful
insights which pave the way to the future development of a system to detect
misleading and harmful information spreading on social media.","A revised version of this pre-print has been published on EPJ Data
  Science with the title ""A multi-layer approach to disinformation detection in
  US and Italian news spreading on Twitter""","Published version on EPJ Data Science (""A multi-layer approach to
  disinformation detection in US and Italian news spreading on Twitter"") Dec
  2020",,cs.SI,"['cs.SI', 'cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2002.12612v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.12612v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.12612v2,"{'id': 'http://arxiv.org/abs/2002.12612v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.12612v2', 'updated': '2020-11-12T08:23:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=12, tm_hour=8, tm_min=23, tm_sec=47, tm_wday=3, tm_yday=317, tm_isdst=0), 'published': '2020-02-28T09:25:53Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=28, tm_hour=9, tm_min=25, tm_sec=53, tm_wday=4, tm_yday=59, tm_isdst=0), 'title': 'A multi-layer approach to disinformation detection on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A multi-layer approach to disinformation detection on Twitter'}, 'summary': 'We tackle the problem of classifying news articles pertaining to\ndisinformation vs mainstream news by solely inspecting their diffusion\nmechanisms on Twitter. Our technique is inherently simple compared to existing\ntext-based approaches, as it allows to by-pass the multiple levels of\ncomplexity which are found in news content (e.g. grammar, syntax, style). We\nemploy a multi-layer representation of Twitter diffusion networks, and we\ncompute for each layer a set of global network features which quantify\ndifferent aspects of the sharing process. Experimental results with two\nlarge-scale datasets, corresponding to diffusion cascades of news shared\nrespectively in the United States and Italy, show that a simple Logistic\nRegression model is able to classify disinformation vs mainstream networks with\nhigh accuracy (AUROC up to 94%), also when considering the political bias of\ndifferent sources in the classification task. We also highlight differences in\nthe sharing patterns of the two news domains which appear to be\ncountry-independent. We believe that our network-based approach provides useful\ninsights which pave the way to the future development of a system to detect\nmisleading and harmful information spreading on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We tackle the problem of classifying news articles pertaining to\ndisinformation vs mainstream news by solely inspecting their diffusion\nmechanisms on Twitter. Our technique is inherently simple compared to existing\ntext-based approaches, as it allows to by-pass the multiple levels of\ncomplexity which are found in news content (e.g. grammar, syntax, style). We\nemploy a multi-layer representation of Twitter diffusion networks, and we\ncompute for each layer a set of global network features which quantify\ndifferent aspects of the sharing process. Experimental results with two\nlarge-scale datasets, corresponding to diffusion cascades of news shared\nrespectively in the United States and Italy, show that a simple Logistic\nRegression model is able to classify disinformation vs mainstream networks with\nhigh accuracy (AUROC up to 94%), also when considering the political bias of\ndifferent sources in the classification task. We also highlight differences in\nthe sharing patterns of the two news domains which appear to be\ncountry-independent. We believe that our network-based approach provides useful\ninsights which pave the way to the future development of a system to detect\nmisleading and harmful information spreading on social media.'}, 'authors': [{'name': 'Francesco Pierri'}, {'name': 'Carlo Piccardi'}, {'name': 'Stefano Ceri'}], 'author_detail': {'name': 'Stefano Ceri'}, 'author': 'Stefano Ceri', 'arxiv_comment': 'A revised version of this pre-print has been published on EPJ Data\n  Science with the title ""A multi-layer approach to disinformation detection in\n  US and Italian news spreading on Twitter""', 'arxiv_journal_ref': 'Published version on EPJ Data Science (""A multi-layer approach to\n  disinformation detection in US and Italian news spreading on Twitter"") Dec\n  2020', 'links': [{'href': 'http://arxiv.org/abs/2002.12612v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.12612v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
112,http://arxiv.org/abs/2002.06585v1,2020-02-16 14:32:22+00:00,2020-02-16 14:32:22+00:00,Untrue.News: A New Search Engine For Fake Stories,"[arxiv.Result.Author('Vinicius Woloszyn'), arxiv.Result.Author('Felipe Schaeffer'), arxiv.Result.Author('Beliza Boniatti'), arxiv.Result.Author('Eduardo Cortes'), arxiv.Result.Author('Salar Mohtaj'), arxiv.Result.Author('Sebastian Möller')]","In this paper, we demonstrate Untrue News, a new search engine for fake
stories. Untrue News is easy to use and offers useful features such as: a) a
multi-language option combining fake stories from different countries and
languages around the same subject or person; b) an user privacy protector,
avoiding the filter bubble by employing a bias-free ranking scheme; and c) a
collaborative platform that fosters the development of new tools for fighting
disinformation. Untrue News relies on Elasticsearch, a new scalable analytic
search engine based on the Lucene library that provides near real-time results.
We demonstrate two key scenarios: the first related to a politician - looking
how the categories are shown for different types of fake stories - and a second
related to a refugee - showing the multilingual tool. A prototype of Untrue
News is accessible via http://untrue.news",,,,cs.CY,"['cs.CY', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2002.06585v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.06585v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.06585v1,"{'id': 'http://arxiv.org/abs/2002.06585v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.06585v1', 'updated': '2020-02-16T14:32:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=32, tm_sec=22, tm_wday=6, tm_yday=47, tm_isdst=0), 'published': '2020-02-16T14:32:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=32, tm_sec=22, tm_wday=6, tm_yday=47, tm_isdst=0), 'title': 'Untrue.News: A New Search Engine For Fake Stories', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Untrue.News: A New Search Engine For Fake Stories'}, 'summary': 'In this paper, we demonstrate Untrue News, a new search engine for fake\nstories. Untrue News is easy to use and offers useful features such as: a) a\nmulti-language option combining fake stories from different countries and\nlanguages around the same subject or person; b) an user privacy protector,\navoiding the filter bubble by employing a bias-free ranking scheme; and c) a\ncollaborative platform that fosters the development of new tools for fighting\ndisinformation. Untrue News relies on Elasticsearch, a new scalable analytic\nsearch engine based on the Lucene library that provides near real-time results.\nWe demonstrate two key scenarios: the first related to a politician - looking\nhow the categories are shown for different types of fake stories - and a second\nrelated to a refugee - showing the multilingual tool. A prototype of Untrue\nNews is accessible via http://untrue.news', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we demonstrate Untrue News, a new search engine for fake\nstories. Untrue News is easy to use and offers useful features such as: a) a\nmulti-language option combining fake stories from different countries and\nlanguages around the same subject or person; b) an user privacy protector,\navoiding the filter bubble by employing a bias-free ranking scheme; and c) a\ncollaborative platform that fosters the development of new tools for fighting\ndisinformation. Untrue News relies on Elasticsearch, a new scalable analytic\nsearch engine based on the Lucene library that provides near real-time results.\nWe demonstrate two key scenarios: the first related to a politician - looking\nhow the categories are shown for different types of fake stories - and a second\nrelated to a refugee - showing the multilingual tool. A prototype of Untrue\nNews is accessible via http://untrue.news'}, 'authors': [{'name': 'Vinicius Woloszyn'}, {'name': 'Felipe Schaeffer'}, {'name': 'Beliza Boniatti'}, {'name': 'Eduardo Cortes'}, {'name': 'Salar Mohtaj'}, {'name': 'Sebastian Möller'}], 'author_detail': {'name': 'Sebastian Möller'}, 'author': 'Sebastian Möller', 'links': [{'href': 'http://arxiv.org/abs/2002.06585v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.06585v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
113,http://arxiv.org/abs/2002.12749v3,2020-11-07 22:09:38+00:00,2020-02-09 07:10:58+00:00,Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples,"[arxiv.Result.Author('Shehzeen Hussain'), arxiv.Result.Author('Paarth Neekhara'), arxiv.Result.Author('Malhar Jere'), arxiv.Result.Author('Farinaz Koushanfar'), arxiv.Result.Author('Julian McAuley')]","Recent advances in video manipulation techniques have made the generation of
fake videos more accessible than ever before. Manipulated videos can fuel
disinformation and reduce trust in media. Therefore detection of fake videos
has garnered immense interest in academia and industry. Recently developed
Deepfake detection methods rely on deep neural networks (DNNs) to distinguish
AI-generated fake videos from real videos. In this work, we demonstrate that it
is possible to bypass such detectors by adversarially modifying fake videos
synthesized using existing Deepfake generation methods. We further demonstrate
that our adversarial perturbations are robust to image and video compression
codecs, making them a real-world threat. We present pipelines in both white-box
and black-box attack scenarios that can fool DNN based Deepfake detectors into
classifying fake videos as real.",Published as a conference paper at WACV 2021,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/2002.12749v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.12749v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.12749v3,"{'id': 'http://arxiv.org/abs/2002.12749v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.12749v3', 'updated': '2020-11-07T22:09:38Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=7, tm_hour=22, tm_min=9, tm_sec=38, tm_wday=5, tm_yday=312, tm_isdst=0), 'published': '2020-02-09T07:10:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=9, tm_hour=7, tm_min=10, tm_sec=58, tm_wday=6, tm_yday=40, tm_isdst=0), 'title': 'Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to\n  Adversarial Examples', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to\n  Adversarial Examples'}, 'summary': 'Recent advances in video manipulation techniques have made the generation of\nfake videos more accessible than ever before. Manipulated videos can fuel\ndisinformation and reduce trust in media. Therefore detection of fake videos\nhas garnered immense interest in academia and industry. Recently developed\nDeepfake detection methods rely on deep neural networks (DNNs) to distinguish\nAI-generated fake videos from real videos. In this work, we demonstrate that it\nis possible to bypass such detectors by adversarially modifying fake videos\nsynthesized using existing Deepfake generation methods. We further demonstrate\nthat our adversarial perturbations are robust to image and video compression\ncodecs, making them a real-world threat. We present pipelines in both white-box\nand black-box attack scenarios that can fool DNN based Deepfake detectors into\nclassifying fake videos as real.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent advances in video manipulation techniques have made the generation of\nfake videos more accessible than ever before. Manipulated videos can fuel\ndisinformation and reduce trust in media. Therefore detection of fake videos\nhas garnered immense interest in academia and industry. Recently developed\nDeepfake detection methods rely on deep neural networks (DNNs) to distinguish\nAI-generated fake videos from real videos. In this work, we demonstrate that it\nis possible to bypass such detectors by adversarially modifying fake videos\nsynthesized using existing Deepfake generation methods. We further demonstrate\nthat our adversarial perturbations are robust to image and video compression\ncodecs, making them a real-world threat. We present pipelines in both white-box\nand black-box attack scenarios that can fool DNN based Deepfake detectors into\nclassifying fake videos as real.'}, 'authors': [{'name': 'Shehzeen Hussain'}, {'name': 'Paarth Neekhara'}, {'name': 'Malhar Jere'}, {'name': 'Farinaz Koushanfar'}, {'name': 'Julian McAuley'}], 'author_detail': {'name': 'Julian McAuley'}, 'author': 'Julian McAuley', 'arxiv_comment': 'Published as a conference paper at WACV 2021', 'links': [{'href': 'http://arxiv.org/abs/2002.12749v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.12749v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
114,http://arxiv.org/abs/2001.10926v1,2020-01-29 16:14:47+00:00,2020-01-29 16:14:47+00:00,HoaxItaly: a collection of Italian disinformation and fact-checking stories shared on Twitter in 2019,"[arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Alessandro Artoni'), arxiv.Result.Author('Stefano Ceri')]","We released over 1 million tweets shared during 2019 and containing links to
thousands of news articles published on two classes of Italian outlets: (1)
disinformation websites, i.e. outlets which have been repeatedly flagged by
journalists and fact-checkers for producing low-credibility content such as
false news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)
fact-checking websites which notably debunk and verify online news and claims.
The dataset, which includes also title and body for approximately 37k news
articles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2001.10926v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.10926v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.10926v1,"{'id': 'http://arxiv.org/abs/2001.10926v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.10926v1', 'updated': '2020-01-29T16:14:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=29, tm_hour=16, tm_min=14, tm_sec=47, tm_wday=2, tm_yday=29, tm_isdst=0), 'published': '2020-01-29T16:14:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=29, tm_hour=16, tm_min=14, tm_sec=47, tm_wday=2, tm_yday=29, tm_isdst=0), 'title': 'HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019'}, 'summary': 'We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.'}, 'authors': [{'name': 'Francesco Pierri'}, {'name': 'Alessandro Artoni'}, {'name': 'Stefano Ceri'}], 'author_detail': {'name': 'Stefano Ceri'}, 'author': 'Stefano Ceri', 'links': [{'href': 'http://arxiv.org/abs/2001.10926v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.10926v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
115,http://arxiv.org/abs/2001.10622v2,2020-11-02 12:53:36+00:00,2020-01-28 22:33:45+00:00,"A Dip Into a Deep Well: Online Political Advertisements, Valence, and European Electoral Campaigning",[arxiv.Result.Author('Jukka Ruohonen')],"Online political advertisements have become an important element in electoral
campaigning throughout the world. At the same time, concepts such as
disinformation and manipulation have emerged as a global concern. Although
these concepts are distinct from online political ads and data-driven electoral
campaigning, they tend to share a similar trait related to valence, the
intrinsic attractiveness or averseness of a message. Given this background, the
paper examines online political ads by using a dataset collected from Google's
transparency reports. The examination is framed to the mid-2019 situation in
Europe, including the European Parliament elections in particular. According to
the results based on sentiment analysis of the textual ads displayed via
Google's advertisement machinery, (i) most of the political ads have expressed
positive sentiments, although these vary greatly between (ii) European
countries as well as across (iii) European political parties. In addition to
these results, the paper contributes to the timely discussion about data-driven
electoral campaigning and its relation to politics and democracy.",,"Proceedings of the 2nd Multidisciplinary International Symposium
  on Disinformation in Open Online Media (MISDOOM 2020), Leiden (online),
  Springer, pp. 37-51",10.1007/978-3-030-61841-4_3,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-61841-4_3', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2001.10622v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.10622v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.10622v2,"{'id': 'http://arxiv.org/abs/2001.10622v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.10622v2', 'updated': '2020-11-02T12:53:36Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=2, tm_hour=12, tm_min=53, tm_sec=36, tm_wday=0, tm_yday=307, tm_isdst=0), 'published': '2020-01-28T22:33:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=28, tm_hour=22, tm_min=33, tm_sec=45, tm_wday=1, tm_yday=28, tm_isdst=0), 'title': 'A Dip Into a Deep Well: Online Political Advertisements, Valence, and\n  European Electoral Campaigning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Dip Into a Deep Well: Online Political Advertisements, Valence, and\n  European Electoral Campaigning'}, 'summary': ""Online political advertisements have become an important element in electoral\ncampaigning throughout the world. At the same time, concepts such as\ndisinformation and manipulation have emerged as a global concern. Although\nthese concepts are distinct from online political ads and data-driven electoral\ncampaigning, they tend to share a similar trait related to valence, the\nintrinsic attractiveness or averseness of a message. Given this background, the\npaper examines online political ads by using a dataset collected from Google's\ntransparency reports. The examination is framed to the mid-2019 situation in\nEurope, including the European Parliament elections in particular. According to\nthe results based on sentiment analysis of the textual ads displayed via\nGoogle's advertisement machinery, (i) most of the political ads have expressed\npositive sentiments, although these vary greatly between (ii) European\ncountries as well as across (iii) European political parties. In addition to\nthese results, the paper contributes to the timely discussion about data-driven\nelectoral campaigning and its relation to politics and democracy."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online political advertisements have become an important element in electoral\ncampaigning throughout the world. At the same time, concepts such as\ndisinformation and manipulation have emerged as a global concern. Although\nthese concepts are distinct from online political ads and data-driven electoral\ncampaigning, they tend to share a similar trait related to valence, the\nintrinsic attractiveness or averseness of a message. Given this background, the\npaper examines online political ads by using a dataset collected from Google's\ntransparency reports. The examination is framed to the mid-2019 situation in\nEurope, including the European Parliament elections in particular. According to\nthe results based on sentiment analysis of the textual ads displayed via\nGoogle's advertisement machinery, (i) most of the political ads have expressed\npositive sentiments, although these vary greatly between (ii) European\ncountries as well as across (iii) European political parties. In addition to\nthese results, the paper contributes to the timely discussion about data-driven\nelectoral campaigning and its relation to politics and democracy.""}, 'authors': [{'name': 'Jukka Ruohonen'}], 'author_detail': {'name': 'Jukka Ruohonen'}, 'author': 'Jukka Ruohonen', 'arxiv_doi': '10.1007/978-3-030-61841-4_3', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-61841-4_3', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2001.10622v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.10622v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Proceedings of the 2nd Multidisciplinary International Symposium\n  on Disinformation in Open Online Media (MISDOOM 2020), Leiden (online),\n  Springer, pp. 37-51', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
116,http://arxiv.org/abs/2001.08438v1,2020-01-23 10:37:33+00:00,2020-01-23 10:37:33+00:00,The Pushshift Telegram Dataset,"[arxiv.Result.Author('Jason Baumgartner'), arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Megan Squire'), arxiv.Result.Author('Jeremy Blackburn')]","Messaging platforms, especially those with a mobile focus, have become
increasingly ubiquitous in society. These mobile messaging platforms can have
deceivingly large user bases, and in addition to being a way for people to stay
in touch, are often used to organize social movements, as well as a place for
extremists and other ne'er-do-well to congregate. In this paper, we present a
dataset from one such mobile messaging platform: Telegram. Our dataset is made
up of over 27.8K channels and 317M messages from 2.2M unique users. To the best
of our knowledge, our dataset comprises the largest and most complete of its
kind. In addition to the raw data, we also provide the source code used to
collect it, allowing researchers to run their own data collection instance. We
believe the Pushshift Telegram dataset can help researchers from a variety of
disciplines interested in studying online social movements, protests, political
extremism, and disinformation.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2001.08438v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.08438v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.08438v1,"{'id': 'http://arxiv.org/abs/2001.08438v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.08438v1', 'updated': '2020-01-23T10:37:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=23, tm_hour=10, tm_min=37, tm_sec=33, tm_wday=3, tm_yday=23, tm_isdst=0), 'published': '2020-01-23T10:37:33Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=23, tm_hour=10, tm_min=37, tm_sec=33, tm_wday=3, tm_yday=23, tm_isdst=0), 'title': 'The Pushshift Telegram Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Pushshift Telegram Dataset'}, 'summary': ""Messaging platforms, especially those with a mobile focus, have become\nincreasingly ubiquitous in society. These mobile messaging platforms can have\ndeceivingly large user bases, and in addition to being a way for people to stay\nin touch, are often used to organize social movements, as well as a place for\nextremists and other ne'er-do-well to congregate. In this paper, we present a\ndataset from one such mobile messaging platform: Telegram. Our dataset is made\nup of over 27.8K channels and 317M messages from 2.2M unique users. To the best\nof our knowledge, our dataset comprises the largest and most complete of its\nkind. In addition to the raw data, we also provide the source code used to\ncollect it, allowing researchers to run their own data collection instance. We\nbelieve the Pushshift Telegram dataset can help researchers from a variety of\ndisciplines interested in studying online social movements, protests, political\nextremism, and disinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Messaging platforms, especially those with a mobile focus, have become\nincreasingly ubiquitous in society. These mobile messaging platforms can have\ndeceivingly large user bases, and in addition to being a way for people to stay\nin touch, are often used to organize social movements, as well as a place for\nextremists and other ne'er-do-well to congregate. In this paper, we present a\ndataset from one such mobile messaging platform: Telegram. Our dataset is made\nup of over 27.8K channels and 317M messages from 2.2M unique users. To the best\nof our knowledge, our dataset comprises the largest and most complete of its\nkind. In addition to the raw data, we also provide the source code used to\ncollect it, allowing researchers to run their own data collection instance. We\nbelieve the Pushshift Telegram dataset can help researchers from a variety of\ndisciplines interested in studying online social movements, protests, political\nextremism, and disinformation.""}, 'authors': [{'name': 'Jason Baumgartner'}, {'name': 'Savvas Zannettou'}, {'name': 'Megan Squire'}, {'name': 'Jeremy Blackburn'}], 'author_detail': {'name': 'Jeremy Blackburn'}, 'author': 'Jeremy Blackburn', 'links': [{'href': 'http://arxiv.org/abs/2001.08438v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.08438v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
117,http://arxiv.org/abs/2001.00623v1,2020-01-02 21:01:02+00:00,2020-01-02 21:01:02+00:00,"Mining Disinformation and Fake News: Concepts, Methods, and Recent Advancements","[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Dongwon Lee'), arxiv.Result.Author('Huan Liu')]","In recent years, disinformation including fake news, has became a global
phenomenon due to its explosive growth, particularly on social media. The wide
spread of disinformation and fake news can cause detrimental societal effects.
Despite the recent progress in detecting disinformation and fake news, it is
still non-trivial due to its complexity, diversity, multi-modality, and costs
of fact-checking or annotation. The goal of this chapter is to pave the way for
appreciating the challenges and advancements via: (1) introducing the types of
information disorder on social media and examine their differences and
connections; (2) describing important and emerging tasks to combat
disinformation for characterization, detection and attribution; and (3)
discussing a weak supervision approach to detect disinformation with limited
labeled data. We then provide an overview of the chapters in this book that
represent the recent advancements in three related parts: (1) user engagements
in the dissemination of information disorder; (2) techniques on detecting and
mitigating disinformation; and (3) trending issues such as ethics, blockchain,
clickbaits, etc. We hope this book to be a convenient entry point for
researchers, practitioners, and students to understand the problems and
challenges, learn state-of-the-art solutions for their specific needs, and
quickly identify new research problems in their domains.","Submitted as an introductory chapter for the edited book on ""Fake
  News, Disinformation, and Misinformation in Social Media- Emerging Research
  Challenges and Opportunities"", Springer Press",,,cs.SI,"['cs.SI', 'cs.CL', 'H.2.8']","[arxiv.Result.Link('http://arxiv.org/abs/2001.00623v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.00623v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.00623v1,"{'id': 'http://arxiv.org/abs/2001.00623v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.00623v1', 'updated': '2020-01-02T21:01:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=2, tm_hour=21, tm_min=1, tm_sec=2, tm_wday=3, tm_yday=2, tm_isdst=0), 'published': '2020-01-02T21:01:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=2, tm_hour=21, tm_min=1, tm_sec=2, tm_wday=3, tm_yday=2, tm_isdst=0), 'title': 'Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements'}, 'summary': 'In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Suhang Wang'}, {'name': 'Dongwon Lee'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'Submitted as an introductory chapter for the edited book on ""Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities"", Springer Press', 'links': [{'href': 'http://arxiv.org/abs/2001.00623v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.00623v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.2.8', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
118,http://arxiv.org/abs/1912.06810v1,2019-12-14 08:58:01+00:00,2019-12-14 08:58:01+00:00,Proppy: A System to Unmask Propaganda in Online News,"[arxiv.Result.Author('Alberto Barrón-Cedeño'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Israa Jaradat'), arxiv.Result.Author('Preslav Nakov')]","We present proppy, the first publicly available real-world, real-time
propaganda detection system for online news, which aims at raising awareness,
thus potentially limiting the impact of propaganda and helping fight
disinformation. The system constantly monitors a number of news sources,
deduplicates and clusters the news into events, and organizes the articles
about an event on the basis of the likelihood that they contain propagandistic
content. The system is trained on known propaganda sources using a variety of
stylistic features. The evaluation results on a standard dataset show
state-of-the-art results for propaganda detection.","propaganda, disinformation, fake news","Thirty-Third AAAI Conference on Artificial Intelligence
  (AAAI-2019)",,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1912.06810v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.06810v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.06810v1,"{'id': 'http://arxiv.org/abs/1912.06810v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.06810v1', 'updated': '2019-12-14T08:58:01Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=14, tm_hour=8, tm_min=58, tm_sec=1, tm_wday=5, tm_yday=348, tm_isdst=0), 'published': '2019-12-14T08:58:01Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=14, tm_hour=8, tm_min=58, tm_sec=1, tm_wday=5, tm_yday=348, tm_isdst=0), 'title': 'Proppy: A System to Unmask Propaganda in Online News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Proppy: A System to Unmask Propaganda in Online News'}, 'summary': 'We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.'}, 'authors': [{'name': 'Alberto Barrón-Cedeño'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Israa Jaradat'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'propaganda, disinformation, fake news', 'arxiv_journal_ref': 'Thirty-Third AAAI Conference on Artificial Intelligence\n  (AAAI-2019)', 'links': [{'href': 'http://arxiv.org/abs/1912.06810v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.06810v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
119,http://arxiv.org/abs/1912.03750v1,2019-12-08 20:15:20+00:00,2019-12-08 20:15:20+00:00,Determining Individual Origin Similarity (DInOS): Binary Classification of Authors Using Stylometric Features,"[arxiv.Result.Author('A. Kingsland'), arxiv.Result.Author('D. Fortin'), arxiv.Result.Author('E. Cary'), arxiv.Result.Author('S. Smith'), arxiv.Result.Author('K. Pazdernik'), arxiv.Result.Author('R. Perko')]","Author similarity and detection is an integral first step in detecting
state-led disinformation campaigns in an automated fashion. Current detection
techniques require an analyst or subject matter expert to hand-curate accounts.
Stylometric features have a rich history in identifying authorship of unknown
documents, but little exploration has been done to compare authors to one
another. We have adapted a select handful of stylometric features for use in
author similarity metrics, and show their >0.96 F-1 performance on a curated
author classification task, across both traditional machine learning and deep
learning models. These features should contribute to the expanding field of
author similarity research, and expedite the process of detecting and
mitigating large-scale social media disinformation campaigns.","6 pages, 0 figures, 1 appendix",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1912.03750v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.03750v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.03750v1,"{'id': 'http://arxiv.org/abs/1912.03750v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.03750v1', 'updated': '2019-12-08T20:15:20Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=8, tm_hour=20, tm_min=15, tm_sec=20, tm_wday=6, tm_yday=342, tm_isdst=0), 'published': '2019-12-08T20:15:20Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=8, tm_hour=20, tm_min=15, tm_sec=20, tm_wday=6, tm_yday=342, tm_isdst=0), 'title': 'Determining Individual Origin Similarity (DInOS): Binary Classification\n  of Authors Using Stylometric Features', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Determining Individual Origin Similarity (DInOS): Binary Classification\n  of Authors Using Stylometric Features'}, 'summary': 'Author similarity and detection is an integral first step in detecting\nstate-led disinformation campaigns in an automated fashion. Current detection\ntechniques require an analyst or subject matter expert to hand-curate accounts.\nStylometric features have a rich history in identifying authorship of unknown\ndocuments, but little exploration has been done to compare authors to one\nanother. We have adapted a select handful of stylometric features for use in\nauthor similarity metrics, and show their >0.96 F-1 performance on a curated\nauthor classification task, across both traditional machine learning and deep\nlearning models. These features should contribute to the expanding field of\nauthor similarity research, and expedite the process of detecting and\nmitigating large-scale social media disinformation campaigns.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Author similarity and detection is an integral first step in detecting\nstate-led disinformation campaigns in an automated fashion. Current detection\ntechniques require an analyst or subject matter expert to hand-curate accounts.\nStylometric features have a rich history in identifying authorship of unknown\ndocuments, but little exploration has been done to compare authors to one\nanother. We have adapted a select handful of stylometric features for use in\nauthor similarity metrics, and show their >0.96 F-1 performance on a curated\nauthor classification task, across both traditional machine learning and deep\nlearning models. These features should contribute to the expanding field of\nauthor similarity research, and expedite the process of detecting and\nmitigating large-scale social media disinformation campaigns.'}, 'authors': [{'name': 'A. Kingsland'}, {'name': 'D. Fortin'}, {'name': 'E. Cary'}, {'name': 'S. Smith'}, {'name': 'K. Pazdernik'}, {'name': 'R. Perko'}], 'author_detail': {'name': 'R. Perko'}, 'author': 'R. Perko', 'arxiv_comment': '6 pages, 0 figures, 1 appendix', 'links': [{'href': 'http://arxiv.org/abs/1912.03750v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.03750v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
120,http://arxiv.org/abs/1911.12039v1,2019-11-27 09:22:51+00:00,2019-11-27 09:22:51+00:00,The Limited Reach of Fake News on Twitter during 2019 European Elections,"[arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Stefano Cresci'), arxiv.Result.Author('Alessandro Galeazzi'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Maurizio Tesconi')]","The advent of social media changed the way we consume content favoring a
disintermediated access and production. This scenario has been matter of
critical discussion about its impact on society. Magnified in the case of Arab
Spring or heavily criticized in the Brexit and 2016 U.S. elections. In this
work we explore information consumption on Twitter during the last European
electoral campaign by analyzing the interaction patterns of official news
sources, fake news sources, politicians, people from the showbiz and many
others. We extensively explore interactions among different classes of accounts
in the months preceding the last European elections, held between 23rd and 26th
of May, 2019. We collected almost 400,000 tweets posted by 863 accounts having
different roles in the public society. Through a thorough quantitative analysis
we investigate the information flow among them, also exploiting geolocalized
information. Accounts show the tendency to confine their interaction within the
same class and the debate rarely crosses national borders. Moreover, we do not
find any evidence of an organized network of accounts aimed at spreading
disinformation. Instead, disinformation outlets are largely ignored by the
other actors and hence play a peripheral role in online political discussions.",,"PLoS ONE 15(6): e0234689, 2020",10.1371/journal.pone.0234689,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0234689', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1911.12039v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.12039v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.12039v1,"{'id': 'http://arxiv.org/abs/1911.12039v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.12039v1', 'updated': '2019-11-27T09:22:51Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=9, tm_min=22, tm_sec=51, tm_wday=2, tm_yday=331, tm_isdst=0), 'published': '2019-11-27T09:22:51Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=9, tm_min=22, tm_sec=51, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'The Limited Reach of Fake News on Twitter during 2019 European Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Limited Reach of Fake News on Twitter during 2019 European Elections'}, 'summary': 'The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.'}, 'authors': [{'name': 'Matteo Cinelli'}, {'name': 'Stefano Cresci'}, {'name': 'Alessandro Galeazzi'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Maurizio Tesconi'}], 'author_detail': {'name': 'Maurizio Tesconi'}, 'author': 'Maurizio Tesconi', 'arxiv_doi': '10.1371/journal.pone.0234689', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0234689', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1911.12039v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.12039v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'PLoS ONE 15(6): e0234689, 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
121,http://arxiv.org/abs/1911.11951v1,2019-11-27 04:52:53+00:00,2019-11-27 04:52:53+00:00,Taking a Stance on Fake News: Towards Automatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance Detection,"[arxiv.Result.Author('Chris Dulhanty'), arxiv.Result.Author('Jason L. Deglint'), arxiv.Result.Author('Ibrahim Ben Daya'), arxiv.Result.Author('Alexander Wong')]","The exponential rise of social media and digital news in the past decade has
had the unfortunate consequence of escalating what the United Nations has
called a global topic of concern: the growing prevalence of disinformation.
Given the complexity and time-consuming nature of combating disinformation
through human assessment, one is motivated to explore harnessing AI solutions
to automatically assess news articles for the presence of disinformation. A
valuable first step towards automatic identification of disinformation is
stance detection, where given a claim and a news article, the aim is to predict
if the article agrees, disagrees, takes no position, or is unrelated to the
claim. Existing approaches in literature have largely relied on hand-engineered
features or shallow learned representations (e.g., word embeddings) to encode
the claim-article pairs, which can limit the level of representational
expressiveness needed to tackle the high complexity of disinformation
identification. In this work, we explore the notion of harnessing large-scale
deep bidirectional transformer language models for encoding claim-article pairs
in an effort to construct state-of-the-art stance detection geared for
identifying disinformation. Taking advantage of bidirectional cross-attention
between claim-article pairs via pair encoding with self-attention, we construct
a large-scale language model for stance detection by performing transfer
learning on a RoBERTa deep bidirectional transformer language model, and were
able to achieve state-of-the-art performance (weighted accuracy of 90.01%) on
the Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results
serve as motivation for harnessing such large-scale language models as powerful
building blocks for creating effective AI solutions to combat disinformation.",Accepted to the AI for Social Good Workshop at NeurIPS 2019,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1911.11951v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.11951v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.11951v1,"{'id': 'http://arxiv.org/abs/1911.11951v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.11951v1', 'updated': '2019-11-27T04:52:53Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=4, tm_min=52, tm_sec=53, tm_wday=2, tm_yday=331, tm_isdst=0), 'published': '2019-11-27T04:52:53Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=4, tm_min=52, tm_sec=53, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection'}, 'summary': 'The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.'}, 'authors': [{'name': 'Chris Dulhanty'}, {'name': 'Jason L. Deglint'}, {'name': 'Ibrahim Ben Daya'}, {'name': 'Alexander Wong'}], 'author_detail': {'name': 'Alexander Wong'}, 'author': 'Alexander Wong', 'arxiv_comment': 'Accepted to the AI for Social Good Workshop at NeurIPS 2019', 'links': [{'href': 'http://arxiv.org/abs/1911.11951v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.11951v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
122,http://arxiv.org/abs/1911.10517v1,2019-11-24 12:30:35+00:00,2019-11-24 12:30:35+00:00,Towards Understanding the Information Ecosystem Through the Lens of Multiple Web Communities,[arxiv.Result.Author('Savvas Zannettou')],"The Web consists of numerous Web communities, news sources, and services,
which are often exploited by various entities for the dissemination of false
information. Yet, we lack tools and techniques to effectively track the
propagation of information across the multiple diverse communities, and to
model the interplay and influence between them. Also, we lack an understanding
of what the role and impact of emerging communities and services on the Web
are, and how such communities are exploited by bad actors that spread false and
weaponized information. In this thesis, we study the information ecosystem on
the Web by presenting a typology that includes the various types of false
information, the involved actors and their possible motives. Then, we follow a
data-driven cross-platform quantitative approach to analyze billions of posts
from Twitter, Reddit, 4chan's /pol/, and Gab, to shed light on: 1) how news and
memes travel from one Web community to another and how we can model and
quantify the influence between Web communities; 2) characterizing the role of
emerging Web communities and services on the Web, by studying Gab and two Web
archiving services, namely the Wayback Machine and archive.is; and 3) how
popular Web communities are exploited by state-sponsored actors for the purpose
of spreading disinformation. Our analysis reveal that fringe Web communities
like 4chan's /pol/ and The_Donald subreddit have a disproportionate influence
on mainstream communities like Twitter with regard to the dissemination of news
and memes. We find that Gab acts as the new hub for the alt-right community,
while for Web archiving services we find that they can be misused to penalize
ad revenue from news sources with conflicting ideology. Finally, when studying
state-sponsored actors, we find that they were particularly influential in
spreading news on popular communities like Twitter and Reddit.","PhD thesis. Overlaps with arXiv:1804.03461, arXiv:1705.06947,
  arXiv:1805.12512, arXiv:1802.05287, arXiv:1801.10396, arXiv:1801.09288,
  arXiv:1811.03130",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1911.10517v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.10517v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.10517v1,"{'id': 'http://arxiv.org/abs/1911.10517v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.10517v1', 'updated': '2019-11-24T12:30:35Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=24, tm_hour=12, tm_min=30, tm_sec=35, tm_wday=6, tm_yday=328, tm_isdst=0), 'published': '2019-11-24T12:30:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=24, tm_hour=12, tm_min=30, tm_sec=35, tm_wday=6, tm_yday=328, tm_isdst=0), 'title': 'Towards Understanding the Information Ecosystem Through the Lens of\n  Multiple Web Communities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Understanding the Information Ecosystem Through the Lens of\n  Multiple Web Communities'}, 'summary': ""The Web consists of numerous Web communities, news sources, and services,\nwhich are often exploited by various entities for the dissemination of false\ninformation. Yet, we lack tools and techniques to effectively track the\npropagation of information across the multiple diverse communities, and to\nmodel the interplay and influence between them. Also, we lack an understanding\nof what the role and impact of emerging communities and services on the Web\nare, and how such communities are exploited by bad actors that spread false and\nweaponized information. In this thesis, we study the information ecosystem on\nthe Web by presenting a typology that includes the various types of false\ninformation, the involved actors and their possible motives. Then, we follow a\ndata-driven cross-platform quantitative approach to analyze billions of posts\nfrom Twitter, Reddit, 4chan's /pol/, and Gab, to shed light on: 1) how news and\nmemes travel from one Web community to another and how we can model and\nquantify the influence between Web communities; 2) characterizing the role of\nemerging Web communities and services on the Web, by studying Gab and two Web\narchiving services, namely the Wayback Machine and archive.is; and 3) how\npopular Web communities are exploited by state-sponsored actors for the purpose\nof spreading disinformation. Our analysis reveal that fringe Web communities\nlike 4chan's /pol/ and The_Donald subreddit have a disproportionate influence\non mainstream communities like Twitter with regard to the dissemination of news\nand memes. We find that Gab acts as the new hub for the alt-right community,\nwhile for Web archiving services we find that they can be misused to penalize\nad revenue from news sources with conflicting ideology. Finally, when studying\nstate-sponsored actors, we find that they were particularly influential in\nspreading news on popular communities like Twitter and Reddit."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The Web consists of numerous Web communities, news sources, and services,\nwhich are often exploited by various entities for the dissemination of false\ninformation. Yet, we lack tools and techniques to effectively track the\npropagation of information across the multiple diverse communities, and to\nmodel the interplay and influence between them. Also, we lack an understanding\nof what the role and impact of emerging communities and services on the Web\nare, and how such communities are exploited by bad actors that spread false and\nweaponized information. In this thesis, we study the information ecosystem on\nthe Web by presenting a typology that includes the various types of false\ninformation, the involved actors and their possible motives. Then, we follow a\ndata-driven cross-platform quantitative approach to analyze billions of posts\nfrom Twitter, Reddit, 4chan's /pol/, and Gab, to shed light on: 1) how news and\nmemes travel from one Web community to another and how we can model and\nquantify the influence between Web communities; 2) characterizing the role of\nemerging Web communities and services on the Web, by studying Gab and two Web\narchiving services, namely the Wayback Machine and archive.is; and 3) how\npopular Web communities are exploited by state-sponsored actors for the purpose\nof spreading disinformation. Our analysis reveal that fringe Web communities\nlike 4chan's /pol/ and The_Donald subreddit have a disproportionate influence\non mainstream communities like Twitter with regard to the dissemination of news\nand memes. We find that Gab acts as the new hub for the alt-right community,\nwhile for Web archiving services we find that they can be misused to penalize\nad revenue from news sources with conflicting ideology. Finally, when studying\nstate-sponsored actors, we find that they were particularly influential in\nspreading news on popular communities like Twitter and Reddit.""}, 'authors': [{'name': 'Savvas Zannettou'}], 'author_detail': {'name': 'Savvas Zannettou'}, 'author': 'Savvas Zannettou', 'arxiv_comment': 'PhD thesis. Overlaps with arXiv:1804.03461, arXiv:1705.06947,\n  arXiv:1805.12512, arXiv:1802.05287, arXiv:1801.10396, arXiv:1801.09288,\n  arXiv:1811.03130', 'links': [{'href': 'http://arxiv.org/abs/1911.10517v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.10517v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
123,http://arxiv.org/abs/1911.07844v1,2019-11-17 23:20:23+00:00,2019-11-17 23:20:23+00:00,Exploiting Human Social Cognition for the Detection of Fake and Fraudulent Faces via Memory Networks,"[arxiv.Result.Author('Tharindu Fernando'), arxiv.Result.Author('Clinton Fookes'), arxiv.Result.Author('Simon Denman'), arxiv.Result.Author('Sridha Sridharan')]","Advances in computer vision have brought us to the point where we have the
ability to synthesise realistic fake content. Such approaches are seen as a
source of disinformation and mistrust, and pose serious concerns to governments
around the world. Convolutional Neural Networks (CNNs) demonstrate encouraging
results when detecting fake images that arise from the specific type of
manipulation they are trained on. However, this success has not transitioned to
unseen manipulation types, resulting in a significant gap in the
line-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,
which is able to successfully detect faked faces by utilising knowledge stored
in neural memories as well as visual cues to reason about the perceived face
and anticipate its future semantic embeddings. This renders a generalisable
face tampering detection framework. Experimental results demonstrate the
proposed approach achieves superior performance for fake and fraudulent face
detection compared to the state-of-the-art.",,,,cs.CV,"['cs.CV', 'cs.LG', 'cs.MM', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1911.07844v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.07844v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.07844v1,"{'id': 'http://arxiv.org/abs/1911.07844v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.07844v1', 'updated': '2019-11-17T23:20:23Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=17, tm_hour=23, tm_min=20, tm_sec=23, tm_wday=6, tm_yday=321, tm_isdst=0), 'published': '2019-11-17T23:20:23Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=17, tm_hour=23, tm_min=20, tm_sec=23, tm_wday=6, tm_yday=321, tm_isdst=0), 'title': 'Exploiting Human Social Cognition for the Detection of Fake and\n  Fraudulent Faces via Memory Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploiting Human Social Cognition for the Detection of Fake and\n  Fraudulent Faces via Memory Networks'}, 'summary': 'Advances in computer vision have brought us to the point where we have the\nability to synthesise realistic fake content. Such approaches are seen as a\nsource of disinformation and mistrust, and pose serious concerns to governments\naround the world. Convolutional Neural Networks (CNNs) demonstrate encouraging\nresults when detecting fake images that arise from the specific type of\nmanipulation they are trained on. However, this success has not transitioned to\nunseen manipulation types, resulting in a significant gap in the\nline-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,\nwhich is able to successfully detect faked faces by utilising knowledge stored\nin neural memories as well as visual cues to reason about the perceived face\nand anticipate its future semantic embeddings. This renders a generalisable\nface tampering detection framework. Experimental results demonstrate the\nproposed approach achieves superior performance for fake and fraudulent face\ndetection compared to the state-of-the-art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advances in computer vision have brought us to the point where we have the\nability to synthesise realistic fake content. Such approaches are seen as a\nsource of disinformation and mistrust, and pose serious concerns to governments\naround the world. Convolutional Neural Networks (CNNs) demonstrate encouraging\nresults when detecting fake images that arise from the specific type of\nmanipulation they are trained on. However, this success has not transitioned to\nunseen manipulation types, resulting in a significant gap in the\nline-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,\nwhich is able to successfully detect faked faces by utilising knowledge stored\nin neural memories as well as visual cues to reason about the perceived face\nand anticipate its future semantic embeddings. This renders a generalisable\nface tampering detection framework. Experimental results demonstrate the\nproposed approach achieves superior performance for fake and fraudulent face\ndetection compared to the state-of-the-art.'}, 'authors': [{'name': 'Tharindu Fernando'}, {'name': 'Clinton Fookes'}, {'name': 'Simon Denman'}, {'name': 'Sridha Sridharan'}], 'author_detail': {'name': 'Sridha Sridharan'}, 'author': 'Sridha Sridharan', 'links': [{'href': 'http://arxiv.org/abs/1911.07844v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.07844v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
124,http://arxiv.org/abs/1910.12073v1,2019-10-26 14:29:37+00:00,2019-10-26 14:29:37+00:00,Disinformation Detection: A review of linguistic feature selection and classification models in news veracity assessments,[arxiv.Result.Author('Jillian Tompkins')],"Over the past couple of years, the topic of ""fake news"" and its influence
over people's opinions has become a growing cause for concern. Although the
spread of disinformation on the Internet is not a new phenomenon, the
widespread use of social media has exacerbated its effects, providing more
channels for dissemination and the potential to ""go viral."" Nowhere was this
more evident than during the 2016 United States Presidential Election. Although
the current of disinformation spread via trolls, bots, and hyperpartisan media
outlets likely reinforced existing biases rather than sway undecided voters,
the effects of this deluge of disinformation are by no means trivial. The
consequences range in severity from an overall distrust in news media, to an
ill-informed citizenry, and in extreme cases, provocation of violent action. It
is clear that human ability to discern lies from truth is flawed at best. As
such, greater attention has been given towards applying machine learning
approaches to detect deliberately deceptive news articles. This paper looks at
the work that has already been done in this area.",,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1910.12073v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.12073v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.12073v1,"{'id': 'http://arxiv.org/abs/1910.12073v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.12073v1', 'updated': '2019-10-26T14:29:37Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=26, tm_hour=14, tm_min=29, tm_sec=37, tm_wday=5, tm_yday=299, tm_isdst=0), 'published': '2019-10-26T14:29:37Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=26, tm_hour=14, tm_min=29, tm_sec=37, tm_wday=5, tm_yday=299, tm_isdst=0), 'title': 'Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments'}, 'summary': 'Over the past couple of years, the topic of ""fake news"" and its influence\nover people\'s opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to ""go viral."" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past couple of years, the topic of ""fake news"" and its influence\nover people\'s opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to ""go viral."" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.'}, 'authors': [{'name': 'Jillian Tompkins'}], 'author_detail': {'name': 'Jillian Tompkins'}, 'author': 'Jillian Tompkins', 'links': [{'href': 'http://arxiv.org/abs/1910.12073v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.12073v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
125,http://arxiv.org/abs/1910.12596v1,2019-10-14 19:58:15+00:00,2019-10-14 19:58:15+00:00,Online Disinformation and the Role of Wikipedia,[arxiv.Result.Author('Diego Saez-Trumper')],"The aim of this study is to find key areas of research that can be useful to
fight against disinformation on Wikipedia. To address this problem we perform a
literature review trying to answer three main questions: (i) What is
disinformation? (ii) What are the most popular mechanisms to spread online
disinformation? and (iii) Which are the mechanisms that are currently being
used to fight against disinformation?. In all these three questions we take
first a general approach, considering studies from different areas such as
journalism and communications, sociology, philosophy, information and political
sciences. And comparing those studies with the current situation on the
Wikipedia ecosystem. We conclude that in order to keep Wikipedia as free as
possible from disinformation, it is necessary to help patrollers to early
detect disinformation and assess the credibility of external sources. More
research is needed to develop tools that use state-of-the-art machine learning
techniques to detect potentially dangerous content, empowering patrollers to
deal with attacks that are becoming more complex and sophisticated.",,,,cs.CY,"['cs.CY', 'cs.DL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1910.12596v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.12596v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.12596v1,"{'id': 'http://arxiv.org/abs/1910.12596v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.12596v1', 'updated': '2019-10-14T19:58:15Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=14, tm_hour=19, tm_min=58, tm_sec=15, tm_wday=0, tm_yday=287, tm_isdst=0), 'published': '2019-10-14T19:58:15Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=14, tm_hour=19, tm_min=58, tm_sec=15, tm_wday=0, tm_yday=287, tm_isdst=0), 'title': 'Online Disinformation and the Role of Wikipedia', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online Disinformation and the Role of Wikipedia'}, 'summary': 'The aim of this study is to find key areas of research that can be useful to\nfight against disinformation on Wikipedia. To address this problem we perform a\nliterature review trying to answer three main questions: (i) What is\ndisinformation? (ii) What are the most popular mechanisms to spread online\ndisinformation? and (iii) Which are the mechanisms that are currently being\nused to fight against disinformation?. In all these three questions we take\nfirst a general approach, considering studies from different areas such as\njournalism and communications, sociology, philosophy, information and political\nsciences. And comparing those studies with the current situation on the\nWikipedia ecosystem. We conclude that in order to keep Wikipedia as free as\npossible from disinformation, it is necessary to help patrollers to early\ndetect disinformation and assess the credibility of external sources. More\nresearch is needed to develop tools that use state-of-the-art machine learning\ntechniques to detect potentially dangerous content, empowering patrollers to\ndeal with attacks that are becoming more complex and sophisticated.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The aim of this study is to find key areas of research that can be useful to\nfight against disinformation on Wikipedia. To address this problem we perform a\nliterature review trying to answer three main questions: (i) What is\ndisinformation? (ii) What are the most popular mechanisms to spread online\ndisinformation? and (iii) Which are the mechanisms that are currently being\nused to fight against disinformation?. In all these three questions we take\nfirst a general approach, considering studies from different areas such as\njournalism and communications, sociology, philosophy, information and political\nsciences. And comparing those studies with the current situation on the\nWikipedia ecosystem. We conclude that in order to keep Wikipedia as free as\npossible from disinformation, it is necessary to help patrollers to early\ndetect disinformation and assess the credibility of external sources. More\nresearch is needed to develop tools that use state-of-the-art machine learning\ntechniques to detect potentially dangerous content, empowering patrollers to\ndeal with attacks that are becoming more complex and sophisticated.'}, 'authors': [{'name': 'Diego Saez-Trumper'}], 'author_detail': {'name': 'Diego Saez-Trumper'}, 'author': 'Diego Saez-Trumper', 'links': [{'href': 'http://arxiv.org/abs/1910.12596v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.12596v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
126,http://arxiv.org/abs/1910.01363v1,2019-10-03 09:00:58+00:00,2019-10-03 09:00:58+00:00,Mapping (Dis-)Information Flow about the MH17 Plane Crash,"[arxiv.Result.Author('Mareike Hartmann'), arxiv.Result.Author('Yevgeniy Golovchenko'), arxiv.Result.Author('Isabelle Augenstein')]","Digital media enables not only fast sharing of information, but also
disinformation. One prominent case of an event leading to circulation of
disinformation on social media is the MH17 plane crash. Studies analysing the
spread of information about this event on Twitter have focused on small,
manually annotated datasets, or used proxys for data annotation. In this work,
we examine to what extent text classifiers can be used to label data for
subsequent content analysis, in particular we focus on predicting pro-Russian
and pro-Ukrainian Twitter content related to the MH17 plane crash. Even though
we find that a neural classifier improves over a hashtag based baseline,
labeling pro-Russian and pro-Ukrainian content with high precision remains a
challenging problem. We provide an error analysis underlining the difficulty of
the task and identify factors that might help improve classification in future
work. Finally, we show how the classifier can facilitate the annotation task
for human annotators.",,,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1910.01363v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.01363v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.01363v1,"{'id': 'http://arxiv.org/abs/1910.01363v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.01363v1', 'updated': '2019-10-03T09:00:58Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=3, tm_hour=9, tm_min=0, tm_sec=58, tm_wday=3, tm_yday=276, tm_isdst=0), 'published': '2019-10-03T09:00:58Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=3, tm_hour=9, tm_min=0, tm_sec=58, tm_wday=3, tm_yday=276, tm_isdst=0), 'title': 'Mapping (Dis-)Information Flow about the MH17 Plane Crash', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mapping (Dis-)Information Flow about the MH17 Plane Crash'}, 'summary': 'Digital media enables not only fast sharing of information, but also\ndisinformation. One prominent case of an event leading to circulation of\ndisinformation on social media is the MH17 plane crash. Studies analysing the\nspread of information about this event on Twitter have focused on small,\nmanually annotated datasets, or used proxys for data annotation. In this work,\nwe examine to what extent text classifiers can be used to label data for\nsubsequent content analysis, in particular we focus on predicting pro-Russian\nand pro-Ukrainian Twitter content related to the MH17 plane crash. Even though\nwe find that a neural classifier improves over a hashtag based baseline,\nlabeling pro-Russian and pro-Ukrainian content with high precision remains a\nchallenging problem. We provide an error analysis underlining the difficulty of\nthe task and identify factors that might help improve classification in future\nwork. Finally, we show how the classifier can facilitate the annotation task\nfor human annotators.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Digital media enables not only fast sharing of information, but also\ndisinformation. One prominent case of an event leading to circulation of\ndisinformation on social media is the MH17 plane crash. Studies analysing the\nspread of information about this event on Twitter have focused on small,\nmanually annotated datasets, or used proxys for data annotation. In this work,\nwe examine to what extent text classifiers can be used to label data for\nsubsequent content analysis, in particular we focus on predicting pro-Russian\nand pro-Ukrainian Twitter content related to the MH17 plane crash. Even though\nwe find that a neural classifier improves over a hashtag based baseline,\nlabeling pro-Russian and pro-Ukrainian content with high precision remains a\nchallenging problem. We provide an error analysis underlining the difficulty of\nthe task and identify factors that might help improve classification in future\nwork. Finally, we show how the classifier can facilitate the annotation task\nfor human annotators.'}, 'authors': [{'name': 'Mareike Hartmann'}, {'name': 'Yevgeniy Golovchenko'}, {'name': 'Isabelle Augenstein'}], 'author_detail': {'name': 'Isabelle Augenstein'}, 'author': 'Isabelle Augenstein', 'links': [{'href': 'http://arxiv.org/abs/1910.01363v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.01363v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
127,http://arxiv.org/abs/1910.01303v2,2019-10-04 00:40:00+00:00,2019-10-03 05:08:35+00:00,From Senseless Swarms to Smart Mobs: Tuning Networks for Prosocial Behaviour,"[arxiv.Result.Author('Sun Sun Lim'), arxiv.Result.Author('Roland Bouffanais')]","Social media have been seen to accelerate the spread of negative content such
as disinformation and hate speech, often unleashing reckless herd mentality
within networks, further aggravated by malicious entities using bots for
amplification. So far, the response to this emerging global crisis has centred
around social media platform companies making reactive moves that appear to
have greater symbolic value than practical utility. These include taking down
patently objectionable content or manually deactivating the accounts of bad
actors, while leaving vast troves of negative content to circulate and
perpetuate within social networks. Governments worldwide have thus sought to
intervene using regulatory tools, with countries such as France, Germany and
Singapore introducing laws to compel technology companies to take down or
correct erroneous and harmful content. However, the relentless pace of
technological progress enfeebles regulatory measures that seem fated for
obsolescence.",To appear in IEEE Technology and Society Magazine,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1910.01303v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.01303v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.01303v2,"{'id': 'http://arxiv.org/abs/1910.01303v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.01303v2', 'updated': '2019-10-04T00:40:00Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=4, tm_hour=0, tm_min=40, tm_sec=0, tm_wday=4, tm_yday=277, tm_isdst=0), 'published': '2019-10-03T05:08:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=3, tm_hour=5, tm_min=8, tm_sec=35, tm_wday=3, tm_yday=276, tm_isdst=0), 'title': 'From Senseless Swarms to Smart Mobs: Tuning Networks for Prosocial\n  Behaviour', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'From Senseless Swarms to Smart Mobs: Tuning Networks for Prosocial\n  Behaviour'}, 'summary': 'Social media have been seen to accelerate the spread of negative content such\nas disinformation and hate speech, often unleashing reckless herd mentality\nwithin networks, further aggravated by malicious entities using bots for\namplification. So far, the response to this emerging global crisis has centred\naround social media platform companies making reactive moves that appear to\nhave greater symbolic value than practical utility. These include taking down\npatently objectionable content or manually deactivating the accounts of bad\nactors, while leaving vast troves of negative content to circulate and\nperpetuate within social networks. Governments worldwide have thus sought to\nintervene using regulatory tools, with countries such as France, Germany and\nSingapore introducing laws to compel technology companies to take down or\ncorrect erroneous and harmful content. However, the relentless pace of\ntechnological progress enfeebles regulatory measures that seem fated for\nobsolescence.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media have been seen to accelerate the spread of negative content such\nas disinformation and hate speech, often unleashing reckless herd mentality\nwithin networks, further aggravated by malicious entities using bots for\namplification. So far, the response to this emerging global crisis has centred\naround social media platform companies making reactive moves that appear to\nhave greater symbolic value than practical utility. These include taking down\npatently objectionable content or manually deactivating the accounts of bad\nactors, while leaving vast troves of negative content to circulate and\nperpetuate within social networks. Governments worldwide have thus sought to\nintervene using regulatory tools, with countries such as France, Germany and\nSingapore introducing laws to compel technology companies to take down or\ncorrect erroneous and harmful content. However, the relentless pace of\ntechnological progress enfeebles regulatory measures that seem fated for\nobsolescence.'}, 'authors': [{'name': 'Sun Sun Lim'}, {'name': 'Roland Bouffanais'}], 'author_detail': {'name': 'Roland Bouffanais'}, 'author': 'Roland Bouffanais', 'arxiv_comment': 'To appear in IEEE Technology and Society Magazine', 'links': [{'href': 'http://arxiv.org/abs/1910.01303v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.01303v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
128,http://arxiv.org/abs/1909.05838v1,2019-09-12 17:44:15+00:00,2019-09-12 17:44:15+00:00,Multilingual Multimodal Digital Deception Detection and Disinformation Spread across Social Platforms,"[arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Ellyn Ayton'), arxiv.Result.Author('Josh Mendoza'), arxiv.Result.Author('Svitlana Volkova')]","Our main contribution in this work is novel results of multilingual models
that go beyond typical applications of rumor or misinformation detection in
English social news content to identify fine-grained classes of digital
deception across multiple languages (e.g. Russian, Spanish, etc.). In addition,
we present models for multimodal deception detection from images and text and
discuss the limitations of image only and text only models. Finally, we
elaborate on the ongoing work on measuring deceptive content (in particular
disinformation) spread across social platforms.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1909.05838v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.05838v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.05838v1,"{'id': 'http://arxiv.org/abs/1909.05838v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.05838v1', 'updated': '2019-09-12T17:44:15Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=12, tm_hour=17, tm_min=44, tm_sec=15, tm_wday=3, tm_yday=255, tm_isdst=0), 'published': '2019-09-12T17:44:15Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=12, tm_hour=17, tm_min=44, tm_sec=15, tm_wday=3, tm_yday=255, tm_isdst=0), 'title': 'Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms'}, 'summary': 'Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.'}, 'authors': [{'name': 'Maria Glenski'}, {'name': 'Ellyn Ayton'}, {'name': 'Josh Mendoza'}, {'name': 'Svitlana Volkova'}], 'author_detail': {'name': 'Svitlana Volkova'}, 'author': 'Svitlana Volkova', 'links': [{'href': 'http://arxiv.org/abs/1909.05838v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.05838v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
129,http://arxiv.org/abs/1908.02589v1,2019-08-01 03:04:20+00:00,2019-08-01 03:04:20+00:00,How weaponizing disinformation can bring down a city's power grid,"[arxiv.Result.Author('Gururaghav Raman'), arxiv.Result.Author('Bedoor AlShebli'), arxiv.Result.Author('Marcin Waniek'), arxiv.Result.Author('Talal Rahwan'), arxiv.Result.Author('Jimmy Chih-Hsien Peng')]","Social technologies have made it possible to propagate disinformation and
manipulate the masses at an unprecedented scale. This is particularly alarming
from a security perspective, as humans have proven to be the weakest link when
protecting critical infrastructure in general, and the power grid in
particular. Here, we consider an attack in which an adversary attempts to
manipulate the behavior of energy consumers by sending fake discount
notifications encouraging them to shift their consumption into the peak-demand
period. We conduct surveys to assess the propensity of people to follow-through
on such notifications and forward them to their friends. This allows us to
model how the disinformation propagates through social networks. Finally, using
Greater London as a case study, we show that disinformation can indeed be used
to orchestrate an attack wherein unwitting consumers synchronize their
energy-usage patterns, resulting in blackouts on a city-scale. These findings
demonstrate that in an era when disinformation can be weaponized, system
vulnerabilities arise not only from the hardware and software of critical
infrastructure, but also from the behavior of the consumers.","10 pages, 3 figures",,10.1371/journal.pone.0236517,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0236517', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1908.02589v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.02589v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.02589v1,"{'id': 'http://arxiv.org/abs/1908.02589v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.02589v1', 'updated': '2019-08-01T03:04:20Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=1, tm_hour=3, tm_min=4, tm_sec=20, tm_wday=3, tm_yday=213, tm_isdst=0), 'published': '2019-08-01T03:04:20Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=1, tm_hour=3, tm_min=4, tm_sec=20, tm_wday=3, tm_yday=213, tm_isdst=0), 'title': ""How weaponizing disinformation can bring down a city's power grid"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""How weaponizing disinformation can bring down a city's power grid""}, 'summary': 'Social technologies have made it possible to propagate disinformation and\nmanipulate the masses at an unprecedented scale. This is particularly alarming\nfrom a security perspective, as humans have proven to be the weakest link when\nprotecting critical infrastructure in general, and the power grid in\nparticular. Here, we consider an attack in which an adversary attempts to\nmanipulate the behavior of energy consumers by sending fake discount\nnotifications encouraging them to shift their consumption into the peak-demand\nperiod. We conduct surveys to assess the propensity of people to follow-through\non such notifications and forward them to their friends. This allows us to\nmodel how the disinformation propagates through social networks. Finally, using\nGreater London as a case study, we show that disinformation can indeed be used\nto orchestrate an attack wherein unwitting consumers synchronize their\nenergy-usage patterns, resulting in blackouts on a city-scale. These findings\ndemonstrate that in an era when disinformation can be weaponized, system\nvulnerabilities arise not only from the hardware and software of critical\ninfrastructure, but also from the behavior of the consumers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social technologies have made it possible to propagate disinformation and\nmanipulate the masses at an unprecedented scale. This is particularly alarming\nfrom a security perspective, as humans have proven to be the weakest link when\nprotecting critical infrastructure in general, and the power grid in\nparticular. Here, we consider an attack in which an adversary attempts to\nmanipulate the behavior of energy consumers by sending fake discount\nnotifications encouraging them to shift their consumption into the peak-demand\nperiod. We conduct surveys to assess the propensity of people to follow-through\non such notifications and forward them to their friends. This allows us to\nmodel how the disinformation propagates through social networks. Finally, using\nGreater London as a case study, we show that disinformation can indeed be used\nto orchestrate an attack wherein unwitting consumers synchronize their\nenergy-usage patterns, resulting in blackouts on a city-scale. These findings\ndemonstrate that in an era when disinformation can be weaponized, system\nvulnerabilities arise not only from the hardware and software of critical\ninfrastructure, but also from the behavior of the consumers.'}, 'authors': [{'name': 'Gururaghav Raman'}, {'name': 'Bedoor AlShebli'}, {'name': 'Marcin Waniek'}, {'name': 'Talal Rahwan'}, {'name': 'Jimmy Chih-Hsien Peng'}], 'author_detail': {'name': 'Jimmy Chih-Hsien Peng'}, 'author': 'Jimmy Chih-Hsien Peng', 'arxiv_doi': '10.1371/journal.pone.0236517', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0236517', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1908.02589v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.02589v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '10 pages, 3 figures', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
130,http://arxiv.org/abs/1907.08170v2,2019-10-28 14:38:48+00:00,2019-07-18 17:22:58+00:00,Investigating Italian disinformation spreading on Twitter in the context of 2019 European elections,"[arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Alessandro Artoni'), arxiv.Result.Author('Stefano Ceri')]","We investigate the presence (and the influence) of disinformation spreading
on online social networks in Italy, in the5-month period preceding the 2019
European Parliament elections. To this aim we collected a large-scale dataset
oftweets associated to thousands of news articles published on Italian
disinformation websites. In the observation period,a few outlets accounted for
most of the deceptive information circulating on Twitter, which focused on
controversialand polarizing topics of debate such as immigration, national
safety and (Italian) nationalism. We found evidence ofconnections between
different disinformation outlets across Europe, U.S. and Russia, which often
linked to each otherand featured similar, even translated, articles in the
period before the elections. Overall, the spread of disinformation onTwitter
was confined in a limited community, strongly (and explicitly) related to the
Italian conservative and far-rightpolitical environment, who had a limited
impact on online discussions on the up-coming elections.",,PloS one 15.1 (2020),10.1371/journal.pone.0227821,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0227821', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1907.08170v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.08170v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.08170v2,"{'id': 'http://arxiv.org/abs/1907.08170v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.08170v2', 'updated': '2019-10-28T14:38:48Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=28, tm_hour=14, tm_min=38, tm_sec=48, tm_wday=0, tm_yday=301, tm_isdst=0), 'published': '2019-07-18T17:22:58Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=18, tm_hour=17, tm_min=22, tm_sec=58, tm_wday=3, tm_yday=199, tm_isdst=0), 'title': 'Investigating Italian disinformation spreading on Twitter in the context\n  of 2019 European elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Italian disinformation spreading on Twitter in the context\n  of 2019 European elections'}, 'summary': 'We investigate the presence (and the influence) of disinformation spreading\non online social networks in Italy, in the5-month period preceding the 2019\nEuropean Parliament elections. To this aim we collected a large-scale dataset\noftweets associated to thousands of news articles published on Italian\ndisinformation websites. In the observation period,a few outlets accounted for\nmost of the deceptive information circulating on Twitter, which focused on\ncontroversialand polarizing topics of debate such as immigration, national\nsafety and (Italian) nationalism. We found evidence ofconnections between\ndifferent disinformation outlets across Europe, U.S. and Russia, which often\nlinked to each otherand featured similar, even translated, articles in the\nperiod before the elections. Overall, the spread of disinformation onTwitter\nwas confined in a limited community, strongly (and explicitly) related to the\nItalian conservative and far-rightpolitical environment, who had a limited\nimpact on online discussions on the up-coming elections.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We investigate the presence (and the influence) of disinformation spreading\non online social networks in Italy, in the5-month period preceding the 2019\nEuropean Parliament elections. To this aim we collected a large-scale dataset\noftweets associated to thousands of news articles published on Italian\ndisinformation websites. In the observation period,a few outlets accounted for\nmost of the deceptive information circulating on Twitter, which focused on\ncontroversialand polarizing topics of debate such as immigration, national\nsafety and (Italian) nationalism. We found evidence ofconnections between\ndifferent disinformation outlets across Europe, U.S. and Russia, which often\nlinked to each otherand featured similar, even translated, articles in the\nperiod before the elections. Overall, the spread of disinformation onTwitter\nwas confined in a limited community, strongly (and explicitly) related to the\nItalian conservative and far-rightpolitical environment, who had a limited\nimpact on online discussions on the up-coming elections.'}, 'authors': [{'name': 'Francesco Pierri'}, {'name': 'Alessandro Artoni'}, {'name': 'Stefano Ceri'}], 'author_detail': {'name': 'Stefano Ceri'}, 'author': 'Stefano Ceri', 'arxiv_doi': '10.1371/journal.pone.0227821', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0227821', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1907.08170v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.08170v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'PloS one 15.1 (2020)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
131,http://arxiv.org/abs/1907.08043v1,2019-07-18 13:38:22+00:00,2019-07-18 13:38:22+00:00,Embedding Climate Change Engagement in Astronomy Education and Research,"[arxiv.Result.Author('Kathryn Williamson'), arxiv.Result.Author('Travis A. Rector'), arxiv.Result.Author('James Lowenthal')]","This White Paper is a call to action for astronomers to respond to climate
change with a large structural transition within our profession. Many
astronomers are deeply concerned about climate change and act upon it in their
personal and professional lives, and many organizations within astronomy have
incorporated incremental changes. We need a collective impact model to better
network and grow our efforts so that we can achieve results that are on the
scale appropriate to address climate change at the necessary level indicated by
scientific research; e.g., becoming carbon neutral by 2050. We need to
implement strategies within two primary drivers of our field: (1) Education and
Outreach, and (2) Research Practices and Infrastructure. (1) In the classroom
and through public talks, astronomers reach a large audience. Astronomy is
closely connected to the science of climate change, and it is arguably the most
important topic we include in our curriculum. Due to misinformation and
disinformation, climate change communication is different than for other areas
of science. We therefore need to expand our communication and implement
effective strategies, for which there is now a considerable body of research.
(2) On a per-person basis astronomers have an outsized carbon impact. There are
numerous ways we can reduce our footprint; e.g., in the design and operation of
telescope facilities and in the optimization and reduction of travel.
Fortunately, many of these solutions are win-win scenarios, e.g., increasing
the online presence of conferences will reduce the carbon footprint while
increasing participation, especially for astronomers working with fewer
financial resources. Astronomers have an obligation to act on climate change in
every way possible, and we need to do it now. In this White Paper, we outline a
plan for collective impact using a Networked Improvement Community (NIC)
approach.","Submitted as a State of the Profession White Paper for the Astro2020
  Decadal Survey (10 pages, 1 figure)",,,astro-ph.IM,"['astro-ph.IM', 'physics.ed-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1907.08043v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.08043v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.08043v1,"{'id': 'http://arxiv.org/abs/1907.08043v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.08043v1', 'updated': '2019-07-18T13:38:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=38, tm_sec=22, tm_wday=3, tm_yday=199, tm_isdst=0), 'published': '2019-07-18T13:38:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=38, tm_sec=22, tm_wday=3, tm_yday=199, tm_isdst=0), 'title': 'Embedding Climate Change Engagement in Astronomy Education and Research', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Embedding Climate Change Engagement in Astronomy Education and Research'}, 'summary': 'This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.'}, 'authors': [{'name': 'Kathryn Williamson'}, {'name': 'Travis A. Rector'}, {'name': 'James Lowenthal'}], 'author_detail': {'name': 'James Lowenthal'}, 'author': 'James Lowenthal', 'arxiv_comment': 'Submitted as a State of the Profession White Paper for the Astro2020\n  Decadal Survey (10 pages, 1 figure)', 'links': [{'href': 'http://arxiv.org/abs/1907.08043v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.08043v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.ed-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
132,http://arxiv.org/abs/1906.11371v1,2019-06-26 22:30:01+00:00,2019-06-26 22:30:01+00:00,Deception Strategies and Threats for Online Discussions,"[arxiv.Result.Author('Onur Varol'), arxiv.Result.Author('Ismail Uluturk')]","Communication plays a major role in social systems. Effective communications,
which requires transmission of the messages between individuals without
disruptions or noise, can be a powerful tool to deliver intended impact.
Language and style of the content can be leveraged to deceive and manipulate
recipients. These deception and persuasion strategies can be applied to exert
power and amass capital in politics and business. In this work, we provide a
modest review of how such deception and persuasion strategies were applied to
different communication channels over the years. We provide examples of
campaigns that has occurred in different periods over the last 100 years,
together with their corresponding dissemination mediums. In the Internet age,
we enjoy access to the vast amount of information and the ability to
communicate without borders. However, malicious actors work toward abusing
online systems to disseminate disinformation, disrupt communication, and
manipulate people by the means of automated tools, such as social bots. It is
important to study the old practices of persuasion to be able to investigate
modern practices and tools. Here we provide a discussion of current threats
against society while drawing parallels with the historical practices and the
recent research efforts on systems of detection and prevention.","47 oages, 3 figures",First Monday 23.5 (2018),10.5210/fm.v22i5.7883,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.5210/fm.v22i5.7883', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1906.11371v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.11371v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.11371v1,"{'id': 'http://arxiv.org/abs/1906.11371v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.11371v1', 'updated': '2019-06-26T22:30:01Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=26, tm_hour=22, tm_min=30, tm_sec=1, tm_wday=2, tm_yday=177, tm_isdst=0), 'published': '2019-06-26T22:30:01Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=26, tm_hour=22, tm_min=30, tm_sec=1, tm_wday=2, tm_yday=177, tm_isdst=0), 'title': 'Deception Strategies and Threats for Online Discussions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deception Strategies and Threats for Online Discussions'}, 'summary': 'Communication plays a major role in social systems. Effective communications,\nwhich requires transmission of the messages between individuals without\ndisruptions or noise, can be a powerful tool to deliver intended impact.\nLanguage and style of the content can be leveraged to deceive and manipulate\nrecipients. These deception and persuasion strategies can be applied to exert\npower and amass capital in politics and business. In this work, we provide a\nmodest review of how such deception and persuasion strategies were applied to\ndifferent communication channels over the years. We provide examples of\ncampaigns that has occurred in different periods over the last 100 years,\ntogether with their corresponding dissemination mediums. In the Internet age,\nwe enjoy access to the vast amount of information and the ability to\ncommunicate without borders. However, malicious actors work toward abusing\nonline systems to disseminate disinformation, disrupt communication, and\nmanipulate people by the means of automated tools, such as social bots. It is\nimportant to study the old practices of persuasion to be able to investigate\nmodern practices and tools. Here we provide a discussion of current threats\nagainst society while drawing parallels with the historical practices and the\nrecent research efforts on systems of detection and prevention.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Communication plays a major role in social systems. Effective communications,\nwhich requires transmission of the messages between individuals without\ndisruptions or noise, can be a powerful tool to deliver intended impact.\nLanguage and style of the content can be leveraged to deceive and manipulate\nrecipients. These deception and persuasion strategies can be applied to exert\npower and amass capital in politics and business. In this work, we provide a\nmodest review of how such deception and persuasion strategies were applied to\ndifferent communication channels over the years. We provide examples of\ncampaigns that has occurred in different periods over the last 100 years,\ntogether with their corresponding dissemination mediums. In the Internet age,\nwe enjoy access to the vast amount of information and the ability to\ncommunicate without borders. However, malicious actors work toward abusing\nonline systems to disseminate disinformation, disrupt communication, and\nmanipulate people by the means of automated tools, such as social bots. It is\nimportant to study the old practices of persuasion to be able to investigate\nmodern practices and tools. Here we provide a discussion of current threats\nagainst society while drawing parallels with the historical practices and the\nrecent research efforts on systems of detection and prevention.'}, 'authors': [{'name': 'Onur Varol'}, {'name': 'Ismail Uluturk'}], 'author_detail': {'name': 'Ismail Uluturk'}, 'author': 'Ismail Uluturk', 'arxiv_doi': '10.5210/fm.v22i5.7883', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.5210/fm.v22i5.7883', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1906.11371v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.11371v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '47 oages, 3 figures', 'arxiv_journal_ref': 'First Monday 23.5 (2018)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
133,http://arxiv.org/abs/1906.10736v2,2019-06-27 19:23:48+00:00,2019-06-25 19:34:34+00:00,Anti-Latinx Computational Propaganda in the United States,"[arxiv.Result.Author('Claudia Flores-Saviaga'), arxiv.Result.Author('Saiph Savage')]","Given that the Latino community is the second largest ethnic group in the US,
an understanding of how Latinos are discussed and targeted on social media
during US elections is crucial. This paper explores these questions through a
data analysis on Reddit, one of the most prominent and popular social media
platforms for political discussion. We collected Reddit posts mentioning
Latinos and the US midterm elections from September 24, 2017 to September 24,
2018. We analyzed people's posting patterns over time, and the digital traces
of the individuals posting the majority of content and the most popular
content. Our research highlights data voids that existed in online discussions
surrounding Latinos prior to the US midterm elections. We observe a lack of
neutral actors engaging Latinos in political topics. It appears that it is the
more extremist voices (i.e. individuals operating within subreddits who
identify themselves as political trolls) who are creating the most political
content about Latinos. We conclude our report with a discussion of the possible
dangers of data voids (especially with regard to their ties to mis- and
disinformation) and recommendations to increase the involvement of the Latino
community in future US elections.",,Institute of the Future Report 2019,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1906.10736v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.10736v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.10736v2,"{'id': 'http://arxiv.org/abs/1906.10736v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.10736v2', 'updated': '2019-06-27T19:23:48Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=27, tm_hour=19, tm_min=23, tm_sec=48, tm_wday=3, tm_yday=178, tm_isdst=0), 'published': '2019-06-25T19:34:34Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=25, tm_hour=19, tm_min=34, tm_sec=34, tm_wday=1, tm_yday=176, tm_isdst=0), 'title': 'Anti-Latinx Computational Propaganda in the United States', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Anti-Latinx Computational Propaganda in the United States'}, 'summary': ""Given that the Latino community is the second largest ethnic group in the US,\nan understanding of how Latinos are discussed and targeted on social media\nduring US elections is crucial. This paper explores these questions through a\ndata analysis on Reddit, one of the most prominent and popular social media\nplatforms for political discussion. We collected Reddit posts mentioning\nLatinos and the US midterm elections from September 24, 2017 to September 24,\n2018. We analyzed people's posting patterns over time, and the digital traces\nof the individuals posting the majority of content and the most popular\ncontent. Our research highlights data voids that existed in online discussions\nsurrounding Latinos prior to the US midterm elections. We observe a lack of\nneutral actors engaging Latinos in political topics. It appears that it is the\nmore extremist voices (i.e. individuals operating within subreddits who\nidentify themselves as political trolls) who are creating the most political\ncontent about Latinos. We conclude our report with a discussion of the possible\ndangers of data voids (especially with regard to their ties to mis- and\ndisinformation) and recommendations to increase the involvement of the Latino\ncommunity in future US elections."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Given that the Latino community is the second largest ethnic group in the US,\nan understanding of how Latinos are discussed and targeted on social media\nduring US elections is crucial. This paper explores these questions through a\ndata analysis on Reddit, one of the most prominent and popular social media\nplatforms for political discussion. We collected Reddit posts mentioning\nLatinos and the US midterm elections from September 24, 2017 to September 24,\n2018. We analyzed people's posting patterns over time, and the digital traces\nof the individuals posting the majority of content and the most popular\ncontent. Our research highlights data voids that existed in online discussions\nsurrounding Latinos prior to the US midterm elections. We observe a lack of\nneutral actors engaging Latinos in political topics. It appears that it is the\nmore extremist voices (i.e. individuals operating within subreddits who\nidentify themselves as political trolls) who are creating the most political\ncontent about Latinos. We conclude our report with a discussion of the possible\ndangers of data voids (especially with regard to their ties to mis- and\ndisinformation) and recommendations to increase the involvement of the Latino\ncommunity in future US elections.""}, 'authors': [{'name': 'Claudia Flores-Saviaga'}, {'name': 'Saiph Savage'}], 'author_detail': {'name': 'Saiph Savage'}, 'author': 'Saiph Savage', 'arxiv_journal_ref': 'Institute of the Future Report 2019', 'links': [{'href': 'http://arxiv.org/abs/1906.10736v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.10736v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
134,http://arxiv.org/abs/1905.12616v3,2020-12-11 16:17:17+00:00,2019-05-29 17:58:52+00:00,Defending Against Neural Fake News,"[arxiv.Result.Author('Rowan Zellers'), arxiv.Result.Author('Ari Holtzman'), arxiv.Result.Author('Hannah Rashkin'), arxiv.Result.Author('Yonatan Bisk'), arxiv.Result.Author('Ali Farhadi'), arxiv.Result.Author('Franziska Roesner'), arxiv.Result.Author('Yejin Choi')]","Recent progress in natural language generation has raised dual-use concerns.
While applications like summarization and translation are positive, the
underlying technology also might enable adversaries to generate neural fake
news: targeted propaganda that closely mimics the style of real news.
  Modern computer security relies on careful threat modeling: identifying
potential threats and vulnerabilities from an adversary's point of view, and
exploring potential mitigations to these threats. Likewise, developing robust
defenses against neural fake news requires us first to carefully investigate
and characterize the risks of these models. We thus present a model for
controllable text generation called Grover. Given a headline like `Link Found
Between Vaccines and Autism,' Grover can generate the rest of the article;
humans find these generations to be more trustworthy than human-written
disinformation.
  Developing robust verification techniques against generators like Grover is
critical. We find that best current discriminators can classify neural fake
news from real, human-written, news with 73% accuracy, assuming access to a
moderate level of training data. Counterintuitively, the best defense against
Grover turns out to be Grover itself, with 92% accuracy, demonstrating the
importance of public release of strong generators. We investigate these results
further, showing that exposure bias -- and sampling strategies that alleviate
its effects -- both leave artifacts that similar discriminators can pick up on.
We conclude by discussing ethical issues regarding the technology, and plan to
release Grover publicly, helping pave the way for better detection of neural
fake news.","NeurIPS 2019 camera ready version. Project page/code/demo at
  https://rowanzellers.com/grover",,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1905.12616v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.12616v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.12616v3,"{'id': 'http://arxiv.org/abs/1905.12616v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.12616v3', 'updated': '2020-12-11T16:17:17Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=11, tm_hour=16, tm_min=17, tm_sec=17, tm_wday=4, tm_yday=346, tm_isdst=0), 'published': '2019-05-29T17:58:52Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=29, tm_hour=17, tm_min=58, tm_sec=52, tm_wday=2, tm_yday=149, tm_isdst=0), 'title': 'Defending Against Neural Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Defending Against Neural Fake News'}, 'summary': ""Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.""}, 'authors': [{'name': 'Rowan Zellers'}, {'name': 'Ari Holtzman'}, {'name': 'Hannah Rashkin'}, {'name': 'Yonatan Bisk'}, {'name': 'Ali Farhadi'}, {'name': 'Franziska Roesner'}, {'name': 'Yejin Choi'}], 'author_detail': {'name': 'Yejin Choi'}, 'author': 'Yejin Choi', 'arxiv_comment': 'NeurIPS 2019 camera ready version. Project page/code/demo at\n  https://rowanzellers.com/grover', 'links': [{'href': 'http://arxiv.org/abs/1905.12616v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.12616v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
135,http://arxiv.org/abs/1905.10412v1,2019-05-24 19:10:18+00:00,2019-05-24 19:10:18+00:00,Using Deep Networks and Transfer Learning to Address Disinformation,"[arxiv.Result.Author('Numa Dhamani'), arxiv.Result.Author('Paul Azunre'), arxiv.Result.Author('Jeffrey L. Gleason'), arxiv.Result.Author('Craig Corcoran'), arxiv.Result.Author('Garrett Honke'), arxiv.Result.Author('Steve Kramer'), arxiv.Result.Author('Jonathon Morgan')]","We apply an ensemble pipeline composed of a character-level convolutional
neural network (CNN) and a long short-term memory (LSTM) as a general tool for
addressing a range of disinformation problems. We also demonstrate the ability
to use this architecture to transfer knowledge from labeled data in one domain
to related (supervised and unsupervised) tasks. Character-level neural networks
and transfer learning are particularly valuable tools in the disinformation
space because of the messy nature of social media, lack of labeled data, and
the multi-channel tactics of influence campaigns. We demonstrate their
effectiveness in several tasks relevant for detecting disinformation: spam
emails, review bombing, political sentiment, and conversation clustering.","AI for Social Good Workshop at the International Conference on
  Machine Learning, Long Beach, United States (2019)",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1905.10412v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.10412v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.10412v1,"{'id': 'http://arxiv.org/abs/1905.10412v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.10412v1', 'updated': '2019-05-24T19:10:18Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=24, tm_hour=19, tm_min=10, tm_sec=18, tm_wday=4, tm_yday=144, tm_isdst=0), 'published': '2019-05-24T19:10:18Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=24, tm_hour=19, tm_min=10, tm_sec=18, tm_wday=4, tm_yday=144, tm_isdst=0), 'title': 'Using Deep Networks and Transfer Learning to Address Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Using Deep Networks and Transfer Learning to Address Disinformation'}, 'summary': 'We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.'}, 'authors': [{'name': 'Numa Dhamani'}, {'name': 'Paul Azunre'}, {'name': 'Jeffrey L. Gleason'}, {'name': 'Craig Corcoran'}, {'name': 'Garrett Honke'}, {'name': 'Steve Kramer'}, {'name': 'Jonathon Morgan'}], 'author_detail': {'name': 'Jonathon Morgan'}, 'author': 'Jonathon Morgan', 'arxiv_comment': 'AI for Social Good Workshop at the International Conference on\n  Machine Learning, Long Beach, United States (2019)', 'links': [{'href': 'http://arxiv.org/abs/1905.10412v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.10412v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
136,http://arxiv.org/abs/1905.02712v1,2019-05-07 17:53:21+00:00,2019-05-07 17:53:21+00:00,The Alt-Right and Global Information Warfare,"[arxiv.Result.Author('Emmi Bevensee'), arxiv.Result.Author('Alexander Reid Ross')]","The Alt-Right is a neo-fascist white supremacist movement that is involved in
violent extremism and shows signs of engagement in extensive disinformation
campaigns. Using social media data mining, this study develops a deeper
understanding of such targeted disinformation campaigns and the ways they
spread. It also adds to the available literature on the endogenous and
exogenous influences within the US far right, as well as motivating factors
that drive disinformation campaigns, such as geopolitical strategy. This study
is to be taken as a preliminary analysis to indicate future methods and
follow-on research that will help develop an integrated approach to
understanding the strategies and associations of the modern fascist movement.",Presented and published through IEEE 2019 Big Data Conference,"2018 IEEE International Conference on Big Data (Big Data),
  4393-4402",10.1109/BigData.2018.8622270,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://dx.doi.org/10.1109/BigData.2018.8622270', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1905.02712v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.02712v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.02712v1,"{'id': 'http://arxiv.org/abs/1905.02712v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.02712v1', 'updated': '2019-05-07T17:53:21Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=7, tm_hour=17, tm_min=53, tm_sec=21, tm_wday=1, tm_yday=127, tm_isdst=0), 'published': '2019-05-07T17:53:21Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=7, tm_hour=17, tm_min=53, tm_sec=21, tm_wday=1, tm_yday=127, tm_isdst=0), 'title': 'The Alt-Right and Global Information Warfare', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Alt-Right and Global Information Warfare'}, 'summary': 'The Alt-Right is a neo-fascist white supremacist movement that is involved in\nviolent extremism and shows signs of engagement in extensive disinformation\ncampaigns. Using social media data mining, this study develops a deeper\nunderstanding of such targeted disinformation campaigns and the ways they\nspread. It also adds to the available literature on the endogenous and\nexogenous influences within the US far right, as well as motivating factors\nthat drive disinformation campaigns, such as geopolitical strategy. This study\nis to be taken as a preliminary analysis to indicate future methods and\nfollow-on research that will help develop an integrated approach to\nunderstanding the strategies and associations of the modern fascist movement.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Alt-Right is a neo-fascist white supremacist movement that is involved in\nviolent extremism and shows signs of engagement in extensive disinformation\ncampaigns. Using social media data mining, this study develops a deeper\nunderstanding of such targeted disinformation campaigns and the ways they\nspread. It also adds to the available literature on the endogenous and\nexogenous influences within the US far right, as well as motivating factors\nthat drive disinformation campaigns, such as geopolitical strategy. This study\nis to be taken as a preliminary analysis to indicate future methods and\nfollow-on research that will help develop an integrated approach to\nunderstanding the strategies and associations of the modern fascist movement.'}, 'authors': [{'name': 'Emmi Bevensee'}, {'name': 'Alexander Reid Ross'}], 'author_detail': {'name': 'Alexander Reid Ross'}, 'author': 'Alexander Reid Ross', 'arxiv_doi': '10.1109/BigData.2018.8622270', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/BigData.2018.8622270', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1905.02712v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.02712v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Presented and published through IEEE 2019 Big Data Conference', 'arxiv_journal_ref': '2018 IEEE International Conference on Big Data (Big Data),\n  4393-4402', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
137,http://arxiv.org/abs/1905.01553v1,2019-05-04 20:19:08+00:00,2019-05-04 20:19:08+00:00,An End-to-End Framework to Identify Pathogenic Social Media Accounts on Twitter,"[arxiv.Result.Author('Elham Shaabani'), arxiv.Result.Author('Ashkan Sadeghi-Mobarakeh'), arxiv.Result.Author('Hamidreza Alvari'), arxiv.Result.Author('Paulo Shakarian')]","Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts
and fake news writers have the capability of spreading disinformation to viral
proportions. Early detection of PSM accounts is crucial as they are likely to
be key users to make malicious information ""viral"". In this paper, we adopt the
causal inference framework along with graph-based metrics in order to
distinguish PSMs from normal users within a short time of their activities. We
propose both supervised and semi-supervised approaches without taking the
network information and content into account. Results on a real-world dataset
from Twitter accentuates the advantage of our proposed frameworks. We show our
approach achieves 0.28 improvement in F1 score over existing approaches with
the precision of 0.90 and F1 score of 0.63.","9 pages, 8 figures, International Conference on Data Intelligence and
  Security. arXiv admin note: text overlap with arXiv:1905.01556",,,cs.SI,"['cs.SI', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1905.01553v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.01553v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.01553v1,"{'id': 'http://arxiv.org/abs/1905.01553v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.01553v1', 'updated': '2019-05-04T20:19:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=4, tm_hour=20, tm_min=19, tm_sec=8, tm_wday=5, tm_yday=124, tm_isdst=0), 'published': '2019-05-04T20:19:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=4, tm_hour=20, tm_min=19, tm_sec=8, tm_wday=5, tm_yday=124, tm_isdst=0), 'title': 'An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter'}, 'summary': 'Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information ""viral"". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information ""viral"". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.'}, 'authors': [{'name': 'Elham Shaabani'}, {'name': 'Ashkan Sadeghi-Mobarakeh'}, {'name': 'Hamidreza Alvari'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'arxiv_comment': '9 pages, 8 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01556', 'links': [{'href': 'http://arxiv.org/abs/1905.01553v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.01553v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
138,http://arxiv.org/abs/1904.11679v2,2020-09-16 18:42:11+00:00,2019-04-26 05:52:05+00:00,Fake News Early Detection: An Interdisciplinary Study,"[arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Atishay Jain'), arxiv.Result.Author('Vir V. Phoha'), arxiv.Result.Author('Reza Zafarani')]","Massive dissemination of fake news and its potential to erode democracy has
increased the demand for accurate fake news detection. Recent advancements in
this area have proposed novel techniques that aim to detect fake news by
exploring how it propagates on social networks. Nevertheless, to detect fake
news at an early stage, i.e., when it is published on a news outlet but not yet
spread on social media, one cannot rely on news propagation information as it
does not exist. Hence, there is a strong need to develop approaches that can
detect fake news by focusing on news content. In this paper, a theory-driven
model is proposed for fake news detection. The method investigates news content
at various levels: lexicon-level, syntax-level, semantic-level and
discourse-level. We represent news at each level, relying on well-established
theories in social and forensic psychology. Fake news detection is then
conducted within a supervised machine learning framework. As an
interdisciplinary research, our work explores potential fake news patterns,
enhances the interpretability in fake news feature engineering, and studies the
relationships among fake news, deception/disinformation, and clickbaits.
Experiments conducted on two real-world datasets indicate the proposed method
can outperform the state-of-the-art and enable fake news early detection when
there is limited content information.",25 pages,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1904.11679v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.11679v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.11679v2,"{'id': 'http://arxiv.org/abs/1904.11679v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.11679v2', 'updated': '2020-09-16T18:42:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=16, tm_hour=18, tm_min=42, tm_sec=11, tm_wday=2, tm_yday=260, tm_isdst=0), 'published': '2019-04-26T05:52:05Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=26, tm_hour=5, tm_min=52, tm_sec=5, tm_wday=4, tm_yday=116, tm_isdst=0), 'title': 'Fake News Early Detection: An Interdisciplinary Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Early Detection: An Interdisciplinary Study'}, 'summary': 'Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.'}, 'authors': [{'name': 'Xinyi Zhou'}, {'name': 'Atishay Jain'}, {'name': 'Vir V. Phoha'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_comment': '25 pages', 'links': [{'href': 'http://arxiv.org/abs/1904.11679v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.11679v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
139,http://arxiv.org/abs/1904.12614v2,2019-09-10 11:32:21+00:00,2019-04-21 10:46:51+00:00,Modelling election dynamics and the impact of disinformation,[arxiv.Result.Author('Dorje C Brody')],"Complex dynamical systems driven by the unravelling of information can be
modelled effectively by treating the underlying flow of information as the
model input. Complicated dynamical behaviour of the system is then derived as
an output. Such an information-based approach is in sharp contrast to the
conventional mathematical modelling of information-driven systems whereby one
attempts to come up with essentially {\it ad hoc} models for the outputs. Here,
dynamics of electoral competition is modelled by the specification of the flow
of information relevant to election. The seemingly random evolution of the
election poll statistics are then derived as model outputs, which in turn are
used to study election prediction, impact of disinformation, and the optimal
strategy for information management in an election campaign.","20 pages, 5 figures","Information Geometry, 2019",10.1007/s41884-019-00021-2,physics.soc-ph,"['physics.soc-ph', 'eess.SP', 'math.DS', 'math.PR', 'q-fin.MF']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s41884-019-00021-2', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1904.12614v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.12614v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.12614v2,"{'id': 'http://arxiv.org/abs/1904.12614v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.12614v2', 'updated': '2019-09-10T11:32:21Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=10, tm_hour=11, tm_min=32, tm_sec=21, tm_wday=1, tm_yday=253, tm_isdst=0), 'published': '2019-04-21T10:46:51Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=21, tm_hour=10, tm_min=46, tm_sec=51, tm_wday=6, tm_yday=111, tm_isdst=0), 'title': 'Modelling election dynamics and the impact of disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Modelling election dynamics and the impact of disinformation'}, 'summary': 'Complex dynamical systems driven by the unravelling of information can be\nmodelled effectively by treating the underlying flow of information as the\nmodel input. Complicated dynamical behaviour of the system is then derived as\nan output. Such an information-based approach is in sharp contrast to the\nconventional mathematical modelling of information-driven systems whereby one\nattempts to come up with essentially {\\it ad hoc} models for the outputs. Here,\ndynamics of electoral competition is modelled by the specification of the flow\nof information relevant to election. The seemingly random evolution of the\nelection poll statistics are then derived as model outputs, which in turn are\nused to study election prediction, impact of disinformation, and the optimal\nstrategy for information management in an election campaign.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Complex dynamical systems driven by the unravelling of information can be\nmodelled effectively by treating the underlying flow of information as the\nmodel input. Complicated dynamical behaviour of the system is then derived as\nan output. Such an information-based approach is in sharp contrast to the\nconventional mathematical modelling of information-driven systems whereby one\nattempts to come up with essentially {\\it ad hoc} models for the outputs. Here,\ndynamics of electoral competition is modelled by the specification of the flow\nof information relevant to election. The seemingly random evolution of the\nelection poll statistics are then derived as model outputs, which in turn are\nused to study election prediction, impact of disinformation, and the optimal\nstrategy for information management in an election campaign.'}, 'authors': [{'name': 'Dorje C Brody'}], 'author_detail': {'name': 'Dorje C Brody'}, 'author': 'Dorje C Brody', 'arxiv_doi': '10.1007/s41884-019-00021-2', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s41884-019-00021-2', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1904.12614v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.12614v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '20 pages, 5 figures', 'arxiv_journal_ref': 'Information Geometry, 2019', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.MF', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
140,http://arxiv.org/abs/1904.10317v1,2019-04-20 23:54:51+00:00,2019-04-20 23:54:51+00:00,The evolution of polarization in the legislative branch of government,"[arxiv.Result.Author('Xiaoyan Lu'), arxiv.Result.Author('Jianxi Gao'), arxiv.Result.Author('Boleslaw K. Szymanski')]","The polarization of political opinions among members of the U.S. legislative
chambers measured by their voting records is greater today than it was thirty
years ago. Previous research efforts to find causes of such increase have
suggested diverse contributors, like growth of online media, echo chamber
effects, media biases, or disinformation propagation. Yet, we lack theoretic
tools to understand, quantify, and predict the emergence of high political
polarization among voters and their legislators. Here, we analyze millions of
roll-call votes cast in the U.S. Congress over the past six decades. Our
analysis reveals the critical change of polarization patterns that started at
the end of 1980's. In earlier decades, polarization within each Congress tended
to decrease with time. In contrast, in the recent decades, the polarization has
been likely to grow within each term. To shed light on the reasons for this
change, we introduce here a formal model for competitive dynamics to quantify
the evolution of polarization patterns in the legislative branch of the U.S.
government. Our model represents dynamics of polarization, enabling us to
successfully predict the direction of polarization changes in 28 out of 30 U.S.
Congresses elected in the past six decades. From the evolution of polarization
level as measured by the Rice index, our model extracts a hidden parameter -
polarization utility which determines the convergence point of the polarization
evolution. The increase in the polarization utility implied by the model
strongly correlates with two current trends: growing polarization of voters and
increasing influence of election campaign funders. Two largest peaks of the
model's polarization utility correlate with significant political or
legislative changes happening at the same time.",,"J. R. Soc. Interface, vol. 16:20190010, 2019",10.1098/rsif.2019.0010,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1098/rsif.2019.0010', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1904.10317v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.10317v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.10317v1,"{'id': 'http://arxiv.org/abs/1904.10317v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.10317v1', 'updated': '2019-04-20T23:54:51Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=20, tm_hour=23, tm_min=54, tm_sec=51, tm_wday=5, tm_yday=110, tm_isdst=0), 'published': '2019-04-20T23:54:51Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=20, tm_hour=23, tm_min=54, tm_sec=51, tm_wday=5, tm_yday=110, tm_isdst=0), 'title': 'The evolution of polarization in the legislative branch of government', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The evolution of polarization in the legislative branch of government'}, 'summary': ""The polarization of political opinions among members of the U.S. legislative\nchambers measured by their voting records is greater today than it was thirty\nyears ago. Previous research efforts to find causes of such increase have\nsuggested diverse contributors, like growth of online media, echo chamber\neffects, media biases, or disinformation propagation. Yet, we lack theoretic\ntools to understand, quantify, and predict the emergence of high political\npolarization among voters and their legislators. Here, we analyze millions of\nroll-call votes cast in the U.S. Congress over the past six decades. Our\nanalysis reveals the critical change of polarization patterns that started at\nthe end of 1980's. In earlier decades, polarization within each Congress tended\nto decrease with time. In contrast, in the recent decades, the polarization has\nbeen likely to grow within each term. To shed light on the reasons for this\nchange, we introduce here a formal model for competitive dynamics to quantify\nthe evolution of polarization patterns in the legislative branch of the U.S.\ngovernment. Our model represents dynamics of polarization, enabling us to\nsuccessfully predict the direction of polarization changes in 28 out of 30 U.S.\nCongresses elected in the past six decades. From the evolution of polarization\nlevel as measured by the Rice index, our model extracts a hidden parameter -\npolarization utility which determines the convergence point of the polarization\nevolution. The increase in the polarization utility implied by the model\nstrongly correlates with two current trends: growing polarization of voters and\nincreasing influence of election campaign funders. Two largest peaks of the\nmodel's polarization utility correlate with significant political or\nlegislative changes happening at the same time."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The polarization of political opinions among members of the U.S. legislative\nchambers measured by their voting records is greater today than it was thirty\nyears ago. Previous research efforts to find causes of such increase have\nsuggested diverse contributors, like growth of online media, echo chamber\neffects, media biases, or disinformation propagation. Yet, we lack theoretic\ntools to understand, quantify, and predict the emergence of high political\npolarization among voters and their legislators. Here, we analyze millions of\nroll-call votes cast in the U.S. Congress over the past six decades. Our\nanalysis reveals the critical change of polarization patterns that started at\nthe end of 1980's. In earlier decades, polarization within each Congress tended\nto decrease with time. In contrast, in the recent decades, the polarization has\nbeen likely to grow within each term. To shed light on the reasons for this\nchange, we introduce here a formal model for competitive dynamics to quantify\nthe evolution of polarization patterns in the legislative branch of the U.S.\ngovernment. Our model represents dynamics of polarization, enabling us to\nsuccessfully predict the direction of polarization changes in 28 out of 30 U.S.\nCongresses elected in the past six decades. From the evolution of polarization\nlevel as measured by the Rice index, our model extracts a hidden parameter -\npolarization utility which determines the convergence point of the polarization\nevolution. The increase in the polarization utility implied by the model\nstrongly correlates with two current trends: growing polarization of voters and\nincreasing influence of election campaign funders. Two largest peaks of the\nmodel's polarization utility correlate with significant political or\nlegislative changes happening at the same time.""}, 'authors': [{'name': 'Xiaoyan Lu'}, {'name': 'Jianxi Gao'}, {'name': 'Boleslaw K. Szymanski'}], 'author_detail': {'name': 'Boleslaw K. Szymanski'}, 'author': 'Boleslaw K. Szymanski', 'arxiv_doi': '10.1098/rsif.2019.0010', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1098/rsif.2019.0010', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1904.10317v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.10317v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'J. R. Soc. Interface, vol. 16:20190010, 2019', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
141,http://arxiv.org/abs/1904.05386v2,2019-10-20 19:30:09+00:00,2019-04-10 18:42:45+00:00,"Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger Technologies and Blockchain to Combat Digital Deception and Counterfeit Reality","[arxiv.Result.Author('Paula Fraga-Lamas'), arxiv.Result.Author('Tiago M. Fernández-Caramés')]","The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda
and post-truth, often referred to as fake news, raises concerns over the role
of Internet and social media in modern democratic societies. Due to its rapid
and widespread diffusion, digital deception has not only an individual or
societal cost (e.g., to hamper the integrity of elections), but it can lead to
significant economic losses (e.g., to affect stock market performance) or to
risks to national security. Blockchain and other Distributed Ledger
Technologies (DLTs) guarantee the provenance, authenticity and traceability of
data by providing a transparent, immutable and verifiable record of
transactions while creating a peer-to-peer secure platform for storing and
exchanging information. This overview aims to explore the potential of DLTs and
blockchain to combat digital deception, reviewing initiatives that are
currently under development and identifying their main current challenges.
Moreover, some recommendations are enumerated to guide future researchers on
issues that will have to be tackled to face fake news, disinformation and
deepfakes, as an integral part of strengthening the resilience against
cyber-threats on today's online media.",Updated version,,,cs.CY,"['cs.CY', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/1904.05386v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.05386v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.05386v2,"{'id': 'http://arxiv.org/abs/1904.05386v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.05386v2', 'updated': '2019-10-20T19:30:09Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=20, tm_hour=19, tm_min=30, tm_sec=9, tm_wday=6, tm_yday=293, tm_isdst=0), 'published': '2019-04-10T18:42:45Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=10, tm_hour=18, tm_min=42, tm_sec=45, tm_wday=2, tm_yday=100, tm_isdst=0), 'title': 'Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality'}, 'summary': ""The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.""}, 'authors': [{'name': 'Paula Fraga-Lamas'}, {'name': 'Tiago M. Fernández-Caramés'}], 'author_detail': {'name': 'Tiago M. Fernández-Caramés'}, 'author': 'Tiago M. Fernández-Caramés', 'arxiv_comment': 'Updated version', 'links': [{'href': 'http://arxiv.org/abs/1904.05386v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.05386v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
142,http://arxiv.org/abs/1903.11899v1,2019-03-28 11:24:30+00:00,2019-03-28 11:24:30+00:00,Using Blockchain to Rein in The New Post-Truth World and Check The Spread of Fake News,"[arxiv.Result.Author('Adnan Qayyum'), arxiv.Result.Author('Junaid Qadir'), arxiv.Result.Author('Muhammad Umar Janjua'), arxiv.Result.Author('Falak Sher')]","In recent years, `fake news' has become a global issue that raises
unprecedented challenges for human society and democracy. This problem has
arisen due to the emergence of various concomitant phenomena such as (1) the
digitization of human life and the ease of disseminating news through social
networking applications (such as Facebook and WhatsApp); (2) the availability
of `big data' that allows customization of news feeds and the creation of
polarized so-called `filter-bubbles'; and (3) the rapid progress made by
generative machine learning (ML) and deep learning (DL) algorithms in creating
realistic-looking yet fake digital content (such as text, images, and videos).
There is a crucial need to combat the rampant rise of fake news and
disinformation. In this paper, we propose a high-level overview of a
blockchain-based framework for fake news prevention and highlight the various
design issues and consideration of such a blockchain-based framework for
tackling fake news.","This paper has been accepted at IEEE IT Professional magazine.
  Personal use of this material is permitted, permission from IEEE must be
  obtained for all other uses",,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/1903.11899v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.11899v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.11899v1,"{'id': 'http://arxiv.org/abs/1903.11899v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.11899v1', 'updated': '2019-03-28T11:24:30Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=28, tm_hour=11, tm_min=24, tm_sec=30, tm_wday=3, tm_yday=87, tm_isdst=0), 'published': '2019-03-28T11:24:30Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=28, tm_hour=11, tm_min=24, tm_sec=30, tm_wday=3, tm_yday=87, tm_isdst=0), 'title': 'Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News'}, 'summary': ""In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news.""}, 'authors': [{'name': 'Adnan Qayyum'}, {'name': 'Junaid Qadir'}, {'name': 'Muhammad Umar Janjua'}, {'name': 'Falak Sher'}], 'author_detail': {'name': 'Falak Sher'}, 'author': 'Falak Sher', 'arxiv_comment': 'This paper has been accepted at IEEE IT Professional magazine.\n  Personal use of this material is permitted, permission from IEEE must be\n  obtained for all other uses', 'links': [{'href': 'http://arxiv.org/abs/1903.11899v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.11899v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
143,http://arxiv.org/abs/1903.01464v1,2019-03-04 18:12:42+00:00,2019-03-04 18:12:42+00:00,Trust Evaluation Mechanism for User Recruitment in Mobile Crowd-Sensing in the Internet of Things,"[arxiv.Result.Author('Nguyen Binh Truong'), arxiv.Result.Author('Gyu Myoung Lee'), arxiv.Result.Author('Tai-Won Um'), arxiv.Result.Author('Michael Mackay')]","Mobile Crowd-Sensing (MCS) has appeared as a prospective solution for
large-scale data collection, leveraging built-in sensors and social
applications in mobile devices that enables a variety of Internet of Things
(IoT) services. However, the human involvement in MCS results in a high
possibility for unintentionally contributing corrupted and falsified data or
intentionally spreading disinformation for malevolent purposes, consequently
undermining IoT services. Therefore, recruiting trustworthy contributors plays
a crucial role in collecting high-quality data and providing better quality of
services while minimizing the vulnerabilities and risks to MCS systems. In this
article, a novel trust model called Experience-Reputation (E-R) is proposed for
evaluating trust relationships between any two mobile device users in a MCS
platform. To enable the E-R model, virtual interactions among the users are
manipulated by considering an assessment of the quality of contributed data
from such users. Based on these interactions, two indicators of trust called
Experience and Reputation are calculated accordingly. By incorporating the
Experience and Reputation trust indicators (TIs), trust relationships between
the users are established, evaluated and maintained. Based on these trust
relationships, a novel trust-based recruitment scheme is carried out for
selecting the most trustworthy MCS users to contribute to data sensing tasks.
In order to evaluate the performance and effectiveness of the proposed
trust-based mechanism as well as the E-R trust model, we deploy several
recruitment schemes in a MCS testbed which consists of both normal and
malicious users. The results highlight the strength of the trust-based scheme
as it delivers better quality for MCS services while being able to detect
malicious users.","Published in IEEE Transactions on Information Forensics and Security
  on March 2019. 15 pages, 9 figures, 68 references",,10.1109/TIFS.2019.2903659,cs.NI,['cs.NI'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/TIFS.2019.2903659', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1903.01464v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.01464v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.01464v1,"{'id': 'http://arxiv.org/abs/1903.01464v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.01464v1', 'updated': '2019-03-04T18:12:42Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=4, tm_hour=18, tm_min=12, tm_sec=42, tm_wday=0, tm_yday=63, tm_isdst=0), 'published': '2019-03-04T18:12:42Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=4, tm_hour=18, tm_min=12, tm_sec=42, tm_wday=0, tm_yday=63, tm_isdst=0), 'title': 'Trust Evaluation Mechanism for User Recruitment in Mobile Crowd-Sensing\n  in the Internet of Things', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trust Evaluation Mechanism for User Recruitment in Mobile Crowd-Sensing\n  in the Internet of Things'}, 'summary': 'Mobile Crowd-Sensing (MCS) has appeared as a prospective solution for\nlarge-scale data collection, leveraging built-in sensors and social\napplications in mobile devices that enables a variety of Internet of Things\n(IoT) services. However, the human involvement in MCS results in a high\npossibility for unintentionally contributing corrupted and falsified data or\nintentionally spreading disinformation for malevolent purposes, consequently\nundermining IoT services. Therefore, recruiting trustworthy contributors plays\na crucial role in collecting high-quality data and providing better quality of\nservices while minimizing the vulnerabilities and risks to MCS systems. In this\narticle, a novel trust model called Experience-Reputation (E-R) is proposed for\nevaluating trust relationships between any two mobile device users in a MCS\nplatform. To enable the E-R model, virtual interactions among the users are\nmanipulated by considering an assessment of the quality of contributed data\nfrom such users. Based on these interactions, two indicators of trust called\nExperience and Reputation are calculated accordingly. By incorporating the\nExperience and Reputation trust indicators (TIs), trust relationships between\nthe users are established, evaluated and maintained. Based on these trust\nrelationships, a novel trust-based recruitment scheme is carried out for\nselecting the most trustworthy MCS users to contribute to data sensing tasks.\nIn order to evaluate the performance and effectiveness of the proposed\ntrust-based mechanism as well as the E-R trust model, we deploy several\nrecruitment schemes in a MCS testbed which consists of both normal and\nmalicious users. The results highlight the strength of the trust-based scheme\nas it delivers better quality for MCS services while being able to detect\nmalicious users.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mobile Crowd-Sensing (MCS) has appeared as a prospective solution for\nlarge-scale data collection, leveraging built-in sensors and social\napplications in mobile devices that enables a variety of Internet of Things\n(IoT) services. However, the human involvement in MCS results in a high\npossibility for unintentionally contributing corrupted and falsified data or\nintentionally spreading disinformation for malevolent purposes, consequently\nundermining IoT services. Therefore, recruiting trustworthy contributors plays\na crucial role in collecting high-quality data and providing better quality of\nservices while minimizing the vulnerabilities and risks to MCS systems. In this\narticle, a novel trust model called Experience-Reputation (E-R) is proposed for\nevaluating trust relationships between any two mobile device users in a MCS\nplatform. To enable the E-R model, virtual interactions among the users are\nmanipulated by considering an assessment of the quality of contributed data\nfrom such users. Based on these interactions, two indicators of trust called\nExperience and Reputation are calculated accordingly. By incorporating the\nExperience and Reputation trust indicators (TIs), trust relationships between\nthe users are established, evaluated and maintained. Based on these trust\nrelationships, a novel trust-based recruitment scheme is carried out for\nselecting the most trustworthy MCS users to contribute to data sensing tasks.\nIn order to evaluate the performance and effectiveness of the proposed\ntrust-based mechanism as well as the E-R trust model, we deploy several\nrecruitment schemes in a MCS testbed which consists of both normal and\nmalicious users. The results highlight the strength of the trust-based scheme\nas it delivers better quality for MCS services while being able to detect\nmalicious users.'}, 'authors': [{'name': 'Nguyen Binh Truong'}, {'name': 'Gyu Myoung Lee'}, {'name': 'Tai-Won Um'}, {'name': 'Michael Mackay'}], 'author_detail': {'name': 'Michael Mackay'}, 'author': 'Michael Mackay', 'arxiv_doi': '10.1109/TIFS.2019.2903659', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TIFS.2019.2903659', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1903.01464v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.01464v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published in IEEE Transactions on Information Forensics and Security\n  on March 2019. 15 pages, 9 figures, 68 references', 'arxiv_primary_category': {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
144,http://arxiv.org/abs/1902.07285v6,2021-04-21 10:14:36+00:00,2019-02-12 02:42:54+00:00,Towards a Robust Deep Neural Network in Texts: A Survey,"[arxiv.Result.Author('Wenqi Wang'), arxiv.Result.Author('Run Wang'), arxiv.Result.Author('Lina Wang'), arxiv.Result.Author('Zhibo Wang'), arxiv.Result.Author('Aoshuang Ye')]","Deep neural networks (DNNs) have achieved remarkable success in various tasks
(e.g., image classification, speech recognition, and natural language
processing (NLP)). However, researchers have demonstrated that DNN-based models
are vulnerable to adversarial examples, which cause erroneous predictions by
adding imperceptible perturbations into legitimate inputs. Recently, studies
have revealed adversarial examples in the text domain, which could effectively
evade various DNN-based text analyzers and further bring the threats of the
proliferation of disinformation. In this paper, we give a comprehensive survey
on the existing studies of adversarial techniques for generating adversarial
texts written by both English and Chinese characters and the corresponding
defense methods. More importantly, we hope that our work could inspire future
studies to develop more robust DNN-based text analyzers against known and
unknown adversarial techniques.
  We classify the existing adversarial techniques for crafting adversarial
texts based on the perturbation units, helping to better understand the
generation of adversarial texts and build robust models for defense. In
presenting the taxonomy of adversarial attacks and defenses in the text domain,
we introduce the adversarial techniques from the perspective of different NLP
tasks. Finally, we discuss the existing challenges of adversarial attacks and
defenses in texts and present the future research directions in this emerging
and challenging field.",,,,cs.CL,"['cs.CL', 'cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1902.07285v6', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.07285v6', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.07285v6,"{'id': 'http://arxiv.org/abs/1902.07285v6', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.07285v6', 'updated': '2021-04-21T10:14:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=21, tm_hour=10, tm_min=14, tm_sec=36, tm_wday=2, tm_yday=111, tm_isdst=0), 'published': '2019-02-12T02:42:54Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=12, tm_hour=2, tm_min=42, tm_sec=54, tm_wday=1, tm_yday=43, tm_isdst=0), 'title': 'Towards a Robust Deep Neural Network in Texts: A Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards a Robust Deep Neural Network in Texts: A Survey'}, 'summary': 'Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.'}, 'authors': [{'name': 'Wenqi Wang'}, {'name': 'Run Wang'}, {'name': 'Lina Wang'}, {'name': 'Zhibo Wang'}, {'name': 'Aoshuang Ye'}], 'author_detail': {'name': 'Aoshuang Ye'}, 'author': 'Aoshuang Ye', 'links': [{'href': 'http://arxiv.org/abs/1902.07285v6', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.07285v6', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
145,http://arxiv.org/abs/1902.01970v1,2019-02-05 23:19:48+00:00,2019-02-05 23:19:48+00:00,Hawkes Process for Understanding the Influence of Pathogenic Social Media Accounts,"[arxiv.Result.Author('Hamidreza Alvari'), arxiv.Result.Author('Paulo Shakarian')]","Over the past years, political events and public opinion on the Web have been
allegedly manipulated by accounts dedicated to spreading disinformation and
performing malicious activities on social media. These accounts hereafter
referred to as ""Pathogenic Social Media (PSM)"" accounts, are often controlled
by terrorist supporters, water armies or fake news writers and hence can pose
threats to social media and general public. Understanding and analyzing PSMs
could help social media firms devise sophisticated and automated techniques
that could be deployed to stop them from reaching their audience and
consequently reduce their threat. In this paper, we leverage the well-known
statistical technique ""Hawkes Process"" to quantify the influence of PSM
accounts on the dissemination of malicious information on social media
platforms. Our findings on a real-world ISIS-related dataset from Twitter
indicate that PSMs are significantly different from regular users in making a
message viral. Specifically, we observed that PSMs do not usually post URLs
from mainstream news sources. Instead, their tweets usually receive large
impact on audience, if contained URLs from Facebook and alternative news
outlets. In contrary, tweets posted by regular users receive nearly equal
impression regardless of the posted URLs and their sources. Our findings can
further shed light on understanding and detecting PSM accounts.",IEEE Conference on Data Intelligence and Security (ICDIS) 2019,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1902.01970v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.01970v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.01970v1,"{'id': 'http://arxiv.org/abs/1902.01970v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.01970v1', 'updated': '2019-02-05T23:19:48Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=23, tm_min=19, tm_sec=48, tm_wday=1, tm_yday=36, tm_isdst=0), 'published': '2019-02-05T23:19:48Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=23, tm_min=19, tm_sec=48, tm_wday=1, tm_yday=36, tm_isdst=0), 'title': 'Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts'}, 'summary': 'Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as ""Pathogenic Social Media (PSM)"" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique ""Hawkes Process"" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as ""Pathogenic Social Media (PSM)"" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique ""Hawkes Process"" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.'}, 'authors': [{'name': 'Hamidreza Alvari'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'arxiv_comment': 'IEEE Conference on Data Intelligence and Security (ICDIS) 2019', 'links': [{'href': 'http://arxiv.org/abs/1902.01970v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.01970v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
146,http://arxiv.org/abs/1901.01464v1,2019-01-05 20:23:02+00:00,2019-01-05 20:23:02+00:00,The Value of Misinformation and Disinformation,"[arxiv.Result.Author('Yanling Chang'), arxiv.Result.Author('Matthew F. Keblis'), arxiv.Result.Author('Ran Li'), arxiv.Result.Author('Eleftherios Iakovou'), arxiv.Result.Author('Chelsea C. White III')]","Information is a critical dimension in warfare. Inaccurate information such
as misinformation or disinformation further complicates military operations. In
this paper, we examine the value of misinformation and disinformation to a
military leader who through investment in people, programs and technology is
able to affect the accuracy of information communicated between other actors.
We model the problem as a partially observable stochastic game with three
agents, a leader and two followers. We determine the value to the leader of
misinformation or disinformation being communicated between two (i) adversarial
followers and (ii) allied followers. We demonstrate that only under certain
conditions, the prevalent intuition that the leader would benefit from less
(more) accurate communication between adversarial (allied) followers is valid.
We analyzed why the intuition may fail and show a holistic paradigm taking into
account both the reward structures and policies of agents is necessary in order
to correctly determine the value of misinformation and disinformation. Our
research identifies efficient targeted investments to affect the accuracy of
information communicated between followers to the leader's advantage.",,,,math.OC,['math.OC'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.01464v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.01464v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.01464v1,"{'id': 'http://arxiv.org/abs/1901.01464v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.01464v1', 'updated': '2019-01-05T20:23:02Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=5, tm_hour=20, tm_min=23, tm_sec=2, tm_wday=5, tm_yday=5, tm_isdst=0), 'published': '2019-01-05T20:23:02Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=5, tm_hour=20, tm_min=23, tm_sec=2, tm_wday=5, tm_yday=5, tm_isdst=0), 'title': 'The Value of Misinformation and Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Value of Misinformation and Disinformation'}, 'summary': ""Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage.""}, 'authors': [{'name': 'Yanling Chang'}, {'name': 'Matthew F. Keblis'}, {'name': 'Ran Li'}, {'name': 'Eleftherios Iakovou'}, {'name': 'Chelsea C. White III'}], 'author_detail': {'name': 'Chelsea C. White III'}, 'author': 'Chelsea C. White III', 'links': [{'href': 'http://arxiv.org/abs/1901.01464v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.01464v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
147,http://arxiv.org/abs/1812.09383v2,2019-01-03 14:35:55+00:00,2018-12-21 21:46:34+00:00,"Technology-Enabled Disinformation: Summary, Lessons, and Recommendations","[arxiv.Result.Author('John Akers'), arxiv.Result.Author('Gagan Bansal'), arxiv.Result.Author('Gabriel Cadamuro'), arxiv.Result.Author('Christine Chen'), arxiv.Result.Author('Quanze Chen'), arxiv.Result.Author('Lucy Lin'), arxiv.Result.Author('Phoebe Mulcaire'), arxiv.Result.Author('Rajalakshmi Nandakumar'), arxiv.Result.Author('Matthew Rockett'), arxiv.Result.Author('Lucy Simko'), arxiv.Result.Author('John Toman'), arxiv.Result.Author('Tongshuang Wu'), arxiv.Result.Author('Eric Zeng'), arxiv.Result.Author('Bill Zorn'), arxiv.Result.Author('Franziska Roesner')]","Technology is increasingly used -- unintentionally (misinformation) or
intentionally (disinformation) -- to spread false information at scale, with
potentially broad-reaching societal effects. For example, technology enables
increasingly realistic false images and videos, and hyper-personal targeting
means different people may see different versions of reality. This report is
the culmination of a PhD-level special topics course
(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &
Engineering at the University of Washington's Paul G. Allen School in the fall
of 2018. The goals of this course were to study (1) how technologies and
today's technical platforms enable and support the creation and spread of such
mis- and disinformation, as well as (2) how technical approaches could be used
to mitigate these issues. In this report, we summarize the space of
technology-enabled mis- and disinformation based on our investigations, and
then surface our lessons and recommendations for technologists, researchers,
platform designers, policymakers, and users.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1812.09383v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.09383v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.09383v2,"{'id': 'http://arxiv.org/abs/1812.09383v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.09383v2', 'updated': '2019-01-03T14:35:55Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=3, tm_hour=14, tm_min=35, tm_sec=55, tm_wday=3, tm_yday=3, tm_isdst=0), 'published': '2018-12-21T21:46:34Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=21, tm_hour=21, tm_min=46, tm_sec=34, tm_wday=4, tm_yday=355, tm_isdst=0), 'title': 'Technology-Enabled Disinformation: Summary, Lessons, and Recommendations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Technology-Enabled Disinformation: Summary, Lessons, and Recommendations'}, 'summary': ""Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users.""}, 'authors': [{'name': 'John Akers'}, {'name': 'Gagan Bansal'}, {'name': 'Gabriel Cadamuro'}, {'name': 'Christine Chen'}, {'name': 'Quanze Chen'}, {'name': 'Lucy Lin'}, {'name': 'Phoebe Mulcaire'}, {'name': 'Rajalakshmi Nandakumar'}, {'name': 'Matthew Rockett'}, {'name': 'Lucy Simko'}, {'name': 'John Toman'}, {'name': 'Tongshuang Wu'}, {'name': 'Eric Zeng'}, {'name': 'Bill Zorn'}, {'name': 'Franziska Roesner'}], 'author_detail': {'name': 'Franziska Roesner'}, 'author': 'Franziska Roesner', 'links': [{'href': 'http://arxiv.org/abs/1812.09383v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.09383v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
148,http://arxiv.org/abs/1812.08247v1,2018-12-19 21:12:00+00:00,2018-12-19 21:12:00+00:00,Detecting GAN-generated Imagery using Color Cues,"[arxiv.Result.Author('Scott McCloskey'), arxiv.Result.Author('Michael Albright')]","Image forensics is an increasingly relevant problem, as it can potentially
address online disinformation campaigns and mitigate problematic aspects of
social media. Of particular interest, given its recent successes, is the
detection of imagery produced by Generative Adversarial Networks (GANs), e.g.
`deepfakes'. Leveraging large training sets and extensive computing resources,
recent work has shown that GANs can be trained to generate synthetic imagery
which is (in some ways) indistinguishable from real imagery. We analyze the
structure of the generating network of a popular GAN implementation, and show
that the network's treatment of color is markedly different from a real camera
in two ways. We further show that these two cues can be used to distinguish
GAN-generated imagery from camera imagery, demonstrating effective
discrimination between GAN imagery and real camera images used to train the
GAN.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1812.08247v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.08247v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.08247v1,"{'id': 'http://arxiv.org/abs/1812.08247v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.08247v1', 'updated': '2018-12-19T21:12:00Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=19, tm_hour=21, tm_min=12, tm_sec=0, tm_wday=2, tm_yday=353, tm_isdst=0), 'published': '2018-12-19T21:12:00Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=19, tm_hour=21, tm_min=12, tm_sec=0, tm_wday=2, tm_yday=353, tm_isdst=0), 'title': 'Detecting GAN-generated Imagery using Color Cues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting GAN-generated Imagery using Color Cues'}, 'summary': ""Image forensics is an increasingly relevant problem, as it can potentially\naddress online disinformation campaigns and mitigate problematic aspects of\nsocial media. Of particular interest, given its recent successes, is the\ndetection of imagery produced by Generative Adversarial Networks (GANs), e.g.\n`deepfakes'. Leveraging large training sets and extensive computing resources,\nrecent work has shown that GANs can be trained to generate synthetic imagery\nwhich is (in some ways) indistinguishable from real imagery. We analyze the\nstructure of the generating network of a popular GAN implementation, and show\nthat the network's treatment of color is markedly different from a real camera\nin two ways. We further show that these two cues can be used to distinguish\nGAN-generated imagery from camera imagery, demonstrating effective\ndiscrimination between GAN imagery and real camera images used to train the\nGAN."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Image forensics is an increasingly relevant problem, as it can potentially\naddress online disinformation campaigns and mitigate problematic aspects of\nsocial media. Of particular interest, given its recent successes, is the\ndetection of imagery produced by Generative Adversarial Networks (GANs), e.g.\n`deepfakes'. Leveraging large training sets and extensive computing resources,\nrecent work has shown that GANs can be trained to generate synthetic imagery\nwhich is (in some ways) indistinguishable from real imagery. We analyze the\nstructure of the generating network of a popular GAN implementation, and show\nthat the network's treatment of color is markedly different from a real camera\nin two ways. We further show that these two cues can be used to distinguish\nGAN-generated imagery from camera imagery, demonstrating effective\ndiscrimination between GAN imagery and real camera images used to train the\nGAN.""}, 'authors': [{'name': 'Scott McCloskey'}, {'name': 'Michael Albright'}], 'author_detail': {'name': 'Michael Albright'}, 'author': 'Michael Albright', 'links': [{'href': 'http://arxiv.org/abs/1812.08247v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.08247v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
149,http://arxiv.org/abs/1812.03533v1,2018-12-09 17:53:08+00:00,2018-12-09 17:53:08+00:00,"Propagation from Deceptive News Sources: Who Shares, How Much, How Evenly, and How Quickly?","[arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Tim Weninger'), arxiv.Result.Author('Svitlana Volkova')]","As people rely on social media as their primary sources of news, the spread
of misinformation has become a significant concern. In this large-scale study
of news in social media we analyze eleven million posts and investigate
propagation behavior of users that directly interact with news accounts
identified as spreading trusted versus malicious content. Unlike previous work,
which looks at specific rumors, topics, or events, we consider all content
propagated by various news sources. Moreover, we analyze and contrast
population versus sub-population behaviour (by demographics) when spreading
misinformation, and distinguish between two types of propagation, i.e., direct
retweets and mentions. Our evaluation examines how evenly, how many, how
quickly, and which users propagate content from various types of news sources
on Twitter.
  Our analysis has identified several key differences in propagation behavior
from trusted versus suspicious news sources. These include high inequity in the
diffusion rate based on the source of disinformation, with a small group of
highly active users responsible for the majority of disinformation spread
overall and within each demographic. Analysis by demographics showed that users
with lower annual income and education share more from disinformation sources
compared to their counterparts. News content is shared significantly more
quickly from trusted, conspiracy, and disinformation sources compared to
clickbait and propaganda. Older users propagate news from trusted sources more
quickly than younger users, but they share from suspicious sources after longer
delays. Finally, users who interact with clickbait and conspiracy sources are
likely to share from propaganda accounts, but not the other way around.","12 pages, 6 figures, 7 tables, published in IEEE TCSS December 2018","IEEE Transactions on Computational Social Systems ( Volume: 5 ,
  Issue: 4 , Dec. 2018 )",10.1109/TCSS.2018.2881071,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/TCSS.2018.2881071', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1812.03533v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.03533v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.03533v1,"{'id': 'http://arxiv.org/abs/1812.03533v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.03533v1', 'updated': '2018-12-09T17:53:08Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=9, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=6, tm_yday=343, tm_isdst=0), 'published': '2018-12-09T17:53:08Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=9, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=6, tm_yday=343, tm_isdst=0), 'title': 'Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?'}, 'summary': 'As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.'}, 'authors': [{'name': 'Maria Glenski'}, {'name': 'Tim Weninger'}, {'name': 'Svitlana Volkova'}], 'author_detail': {'name': 'Svitlana Volkova'}, 'author': 'Svitlana Volkova', 'arxiv_doi': '10.1109/TCSS.2018.2881071', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TCSS.2018.2881071', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1812.03533v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.03533v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '12 pages, 6 figures, 7 tables, published in IEEE TCSS December 2018', 'arxiv_journal_ref': 'IEEE Transactions on Computational Social Systems ( Volume: 5 ,\n  Issue: 4 , Dec. 2018 )', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
150,http://arxiv.org/abs/1811.05900v2,2020-10-28 15:05:51+00:00,2018-11-14 16:44:59+00:00,A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections,[arxiv.Result.Author('Michael Bossetta')],"State-sponsored ""bad actors"" increasingly weaponize social media platforms to
launch cyberattacks and disinformation campaigns during elections. Social media
companies, due to their rapid growth and scale, struggle to prevent the
weaponization of their platforms. This study conducts an automated spear
phishing and disinformation campaign on Twitter ahead of the 2018 United States
Midterm Elections. A fake news bot account - the @DCNewsReport - was created
and programmed to automatically send customized tweets with a ""breaking news""
link to 138 Twitter users, before being restricted by Twitter.
  Overall, one in five users clicked the link, which could have potentially led
to the downloading of ransomware or the theft of private information. However,
the link in this experiment was non-malicious and redirected users to a Google
Forms survey. In predicting users' likelihood to click the link on Twitter, no
statistically significant differences were observed between right-wing and
left-wing partisans, or between Web users and mobile users. The findings signal
that politically expressive Americans on Twitter, regardless of their party
preferences or the devices they use to access the platform, are at risk of
being spear phishing on social media.",,"First Monday, 23(12) (2018)",10.5210/fm.v23i12.9540,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.5210/fm.v23i12.9540', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1811.05900v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.05900v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.05900v2,"{'id': 'http://arxiv.org/abs/1811.05900v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.05900v2', 'updated': '2020-10-28T15:05:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=28, tm_hour=15, tm_min=5, tm_sec=51, tm_wday=2, tm_yday=302, tm_isdst=0), 'published': '2018-11-14T16:44:59Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=14, tm_hour=16, tm_min=44, tm_sec=59, tm_wday=2, tm_yday=318, tm_isdst=0), 'title': 'A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections'}, 'summary': 'State-sponsored ""bad actors"" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a ""breaking news""\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users\' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'State-sponsored ""bad actors"" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a ""breaking news""\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users\' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.'}, 'authors': [{'name': 'Michael Bossetta'}], 'author_detail': {'name': 'Michael Bossetta'}, 'author': 'Michael Bossetta', 'arxiv_doi': '10.5210/fm.v23i12.9540', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.5210/fm.v23i12.9540', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1811.05900v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.05900v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'First Monday, 23(12) (2018)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
151,http://arxiv.org/abs/1811.03130v2,2019-02-11 01:46:53+00:00,2018-11-07 19:48:21+00:00,Who Let The Trolls Out? Towards Understanding State-Sponsored Trolls,"[arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Tristan Caulfield'), arxiv.Result.Author('William Setzer'), arxiv.Result.Author('Michael Sirivianos'), arxiv.Result.Author('Gianluca Stringhini'), arxiv.Result.Author('Jeremy Blackburn')]","Recent evidence has emerged linking coordinated campaigns by state-sponsored
actors to manipulate public opinion on the Web. Campaigns revolving around
major political events are enacted via mission-focused ""trolls."" While trolls
are involved in spreading disinformation on social media, there is little
understanding of how they operate, what type of content they disseminate, how
their strategies evolve over time, and how they influence the Web's information
ecosystem. In this paper, we begin to address this gap by analyzing 10M posts
by 5.5K Twitter and Reddit users identified as Russian and Iranian
state-sponsored trolls. We compare the behavior of each group of
state-sponsored trolls with a focus on how their strategies change over time,
the different campaigns they embark on, and differences between the trolls
operated by Russia and Iran. Among other things, we find: 1) that Russian
trolls were pro-Trump while Iranian trolls were anti-Trump; 2) evidence that
campaigns undertaken by such actors are influenced by real-world events; and 3)
that the behavior of such actors is not consistent over time, hence automated
detection is not a straightforward task. Using the Hawkes Processes statistical
model, we quantify the influence these accounts have on pushing URLs on four
social platforms: Twitter, Reddit, 4chan's Politically Incorrect board (/pol/),
and Gab. In general, Russian trolls were more influential and efficient in
pushing URLs to all the other platforms with the exception of /pol/ where
Iranians were more influential. Finally, we release our data and source code to
ensure the reproducibility of our results and to encourage other researchers to
work on understanding other emerging kinds of state-sponsored troll accounts on
Twitter.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1811.03130v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.03130v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.03130v2,"{'id': 'http://arxiv.org/abs/1811.03130v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.03130v2', 'updated': '2019-02-11T01:46:53Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=11, tm_hour=1, tm_min=46, tm_sec=53, tm_wday=0, tm_yday=42, tm_isdst=0), 'published': '2018-11-07T19:48:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=7, tm_hour=19, tm_min=48, tm_sec=21, tm_wday=2, tm_yday=311, tm_isdst=0), 'title': 'Who Let The Trolls Out? Towards Understanding State-Sponsored Trolls', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Who Let The Trolls Out? Towards Understanding State-Sponsored Trolls'}, 'summary': 'Recent evidence has emerged linking coordinated campaigns by state-sponsored\nactors to manipulate public opinion on the Web. Campaigns revolving around\nmajor political events are enacted via mission-focused ""trolls."" While trolls\nare involved in spreading disinformation on social media, there is little\nunderstanding of how they operate, what type of content they disseminate, how\ntheir strategies evolve over time, and how they influence the Web\'s information\necosystem. In this paper, we begin to address this gap by analyzing 10M posts\nby 5.5K Twitter and Reddit users identified as Russian and Iranian\nstate-sponsored trolls. We compare the behavior of each group of\nstate-sponsored trolls with a focus on how their strategies change over time,\nthe different campaigns they embark on, and differences between the trolls\noperated by Russia and Iran. Among other things, we find: 1) that Russian\ntrolls were pro-Trump while Iranian trolls were anti-Trump; 2) evidence that\ncampaigns undertaken by such actors are influenced by real-world events; and 3)\nthat the behavior of such actors is not consistent over time, hence automated\ndetection is not a straightforward task. Using the Hawkes Processes statistical\nmodel, we quantify the influence these accounts have on pushing URLs on four\nsocial platforms: Twitter, Reddit, 4chan\'s Politically Incorrect board (/pol/),\nand Gab. In general, Russian trolls were more influential and efficient in\npushing URLs to all the other platforms with the exception of /pol/ where\nIranians were more influential. Finally, we release our data and source code to\nensure the reproducibility of our results and to encourage other researchers to\nwork on understanding other emerging kinds of state-sponsored troll accounts on\nTwitter.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent evidence has emerged linking coordinated campaigns by state-sponsored\nactors to manipulate public opinion on the Web. Campaigns revolving around\nmajor political events are enacted via mission-focused ""trolls."" While trolls\nare involved in spreading disinformation on social media, there is little\nunderstanding of how they operate, what type of content they disseminate, how\ntheir strategies evolve over time, and how they influence the Web\'s information\necosystem. In this paper, we begin to address this gap by analyzing 10M posts\nby 5.5K Twitter and Reddit users identified as Russian and Iranian\nstate-sponsored trolls. We compare the behavior of each group of\nstate-sponsored trolls with a focus on how their strategies change over time,\nthe different campaigns they embark on, and differences between the trolls\noperated by Russia and Iran. Among other things, we find: 1) that Russian\ntrolls were pro-Trump while Iranian trolls were anti-Trump; 2) evidence that\ncampaigns undertaken by such actors are influenced by real-world events; and 3)\nthat the behavior of such actors is not consistent over time, hence automated\ndetection is not a straightforward task. Using the Hawkes Processes statistical\nmodel, we quantify the influence these accounts have on pushing URLs on four\nsocial platforms: Twitter, Reddit, 4chan\'s Politically Incorrect board (/pol/),\nand Gab. In general, Russian trolls were more influential and efficient in\npushing URLs to all the other platforms with the exception of /pol/ where\nIranians were more influential. Finally, we release our data and source code to\nensure the reproducibility of our results and to encourage other researchers to\nwork on understanding other emerging kinds of state-sponsored troll accounts on\nTwitter.'}, 'authors': [{'name': 'Savvas Zannettou'}, {'name': 'Tristan Caulfield'}, {'name': 'William Setzer'}, {'name': 'Michael Sirivianos'}, {'name': 'Gianluca Stringhini'}, {'name': 'Jeremy Blackburn'}], 'author_detail': {'name': 'Jeremy Blackburn'}, 'author': 'Jeremy Blackburn', 'links': [{'href': 'http://arxiv.org/abs/1811.03130v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.03130v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
152,http://arxiv.org/abs/1811.01852v1,2018-11-05 17:17:18+00:00,2018-11-05 17:17:18+00:00,Differences between Health Related News Articles from Reliable and Unreliable Media,"[arxiv.Result.Author('Sameer Dhoju'), arxiv.Result.Author('Md Main Uddin Rony'), arxiv.Result.Author('Naeemul Hassan')]","In this study, we examine a collection of health-related news articles
published by reliable and unreliable media outlets. Our analysis shows that
there are structural, topical, and semantic differences in the way reliable and
unreliable media outlets conduct health journalism. We argue that the findings
from this study will be useful for combating health disinformation problem.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1811.01852v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.01852v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.01852v1,"{'id': 'http://arxiv.org/abs/1811.01852v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.01852v1', 'updated': '2018-11-05T17:17:18Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=5, tm_hour=17, tm_min=17, tm_sec=18, tm_wday=0, tm_yday=309, tm_isdst=0), 'published': '2018-11-05T17:17:18Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=5, tm_hour=17, tm_min=17, tm_sec=18, tm_wday=0, tm_yday=309, tm_isdst=0), 'title': 'Differences between Health Related News Articles from Reliable and\n  Unreliable Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Differences between Health Related News Articles from Reliable and\n  Unreliable Media'}, 'summary': 'In this study, we examine a collection of health-related news articles\npublished by reliable and unreliable media outlets. Our analysis shows that\nthere are structural, topical, and semantic differences in the way reliable and\nunreliable media outlets conduct health journalism. We argue that the findings\nfrom this study will be useful for combating health disinformation problem.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this study, we examine a collection of health-related news articles\npublished by reliable and unreliable media outlets. Our analysis shows that\nthere are structural, topical, and semantic differences in the way reliable and\nunreliable media outlets conduct health journalism. We argue that the findings\nfrom this study will be useful for combating health disinformation problem.'}, 'authors': [{'name': 'Sameer Dhoju'}, {'name': 'Md Main Uddin Rony'}, {'name': 'Naeemul Hassan'}], 'author_detail': {'name': 'Naeemul Hassan'}, 'author': 'Naeemul Hassan', 'links': [{'href': 'http://arxiv.org/abs/1811.01852v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.01852v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
153,http://arxiv.org/abs/1810.11063v1,2018-10-25 18:42:01+00:00,2018-10-25 18:42:01+00:00,Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering,"[arxiv.Result.Author('Adam Trowbridge'), arxiv.Result.Author('Jessica Westbrook'), arxiv.Result.Author('Filipo Sharevski')]","In this paper we argue, drawing from the perspectives of cybersecurity and
social psychology, that Internet-based manipulation of an individual or group
reality using ambient tactical deception is possible using only software and
changing words in a web browser. We call this attack Ambient Tactical Deception
(ATD). Ambient, in artificial intelligence, describes software that is
""unobtrusive,"" and completely integrated into a user's life. Tactical deception
is an information warfare term for the use of deception on an opposing force.
We suggest that an ATD attack could change the sentiment of text in a web
browser. This could alter the victim's perception of reality by providing
disinformation. Within the limit of online communication, even a pause in
replying to a text can affect how people perceive each other. The outcomes of
an ATD attack could include alienation, upsetting a victim, and influencing
their feelings about an election, a spouse, or a corporation.",,,,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/1810.11063v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1810.11063v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1810.11063v1,"{'id': 'http://arxiv.org/abs/1810.11063v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1810.11063v1', 'updated': '2018-10-25T18:42:01Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=25, tm_hour=18, tm_min=42, tm_sec=1, tm_wday=3, tm_yday=298, tm_isdst=0), 'published': '2018-10-25T18:42:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=25, tm_hour=18, tm_min=42, tm_sec=1, tm_wday=3, tm_yday=298, tm_isdst=0), 'title': 'Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering'}, 'summary': 'In this paper we argue, drawing from the perspectives of cybersecurity and\nsocial psychology, that Internet-based manipulation of an individual or group\nreality using ambient tactical deception is possible using only software and\nchanging words in a web browser. We call this attack Ambient Tactical Deception\n(ATD). Ambient, in artificial intelligence, describes software that is\n""unobtrusive,"" and completely integrated into a user\'s life. Tactical deception\nis an information warfare term for the use of deception on an opposing force.\nWe suggest that an ATD attack could change the sentiment of text in a web\nbrowser. This could alter the victim\'s perception of reality by providing\ndisinformation. Within the limit of online communication, even a pause in\nreplying to a text can affect how people perceive each other. The outcomes of\nan ATD attack could include alienation, upsetting a victim, and influencing\ntheir feelings about an election, a spouse, or a corporation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper we argue, drawing from the perspectives of cybersecurity and\nsocial psychology, that Internet-based manipulation of an individual or group\nreality using ambient tactical deception is possible using only software and\nchanging words in a web browser. We call this attack Ambient Tactical Deception\n(ATD). Ambient, in artificial intelligence, describes software that is\n""unobtrusive,"" and completely integrated into a user\'s life. Tactical deception\nis an information warfare term for the use of deception on an opposing force.\nWe suggest that an ATD attack could change the sentiment of text in a web\nbrowser. This could alter the victim\'s perception of reality by providing\ndisinformation. Within the limit of online communication, even a pause in\nreplying to a text can affect how people perceive each other. The outcomes of\nan ATD attack could include alienation, upsetting a victim, and influencing\ntheir feelings about an election, a spouse, or a corporation.'}, 'authors': [{'name': 'Adam Trowbridge'}, {'name': 'Jessica Westbrook'}, {'name': 'Filipo Sharevski'}], 'author_detail': {'name': 'Filipo Sharevski'}, 'author': 'Filipo Sharevski', 'links': [{'href': 'http://arxiv.org/abs/1810.11063v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1810.11063v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
154,http://arxiv.org/abs/1808.09325v1,2018-08-28 14:31:01+00:00,2018-08-28 14:31:01+00:00,"""Life never matters in the DEMOCRATS MIND"": Examining Strategies of Retweeted Social Bots During a Mass Shooting Event","[arxiv.Result.Author('Vanessa L. Kitzie'), arxiv.Result.Author('Ehsan Mohammadi'), arxiv.Result.Author('Amir Karami')]","This exploratory study examines the strategies of social bots on Twitter that
were retweeted following a mass shooting event. Using a case study method to
frame our work, we collected over seven million tweets during a one-month
period following a mass shooting in Parkland, Florida. From this dataset, we
selected retweets of content generated by over 400 social bot accounts to
determine what strategies these bots were using and the effectiveness of these
strategies as indicated by the number of retweets. We employed qualitative and
quantitative methods to capture both macro- and micro-level perspectives. Our
findings suggest that bots engage in more diverse strategies than solely waging
disinformation campaigns, including baiting and sharing information. Further,
we found that while bots amplify conversation about mass shootings, humans were
primarily responsible for disseminating bot-generated content. These findings
add depth to the current understanding of bot strategies and their
effectiveness. Understanding these strategies can inform efforts to combat
dubious information as well as more insidious disinformation campaigns.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1808.09325v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.09325v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.09325v1,"{'id': 'http://arxiv.org/abs/1808.09325v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.09325v1', 'updated': '2018-08-28T14:31:01Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=28, tm_hour=14, tm_min=31, tm_sec=1, tm_wday=1, tm_yday=240, tm_isdst=0), 'published': '2018-08-28T14:31:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=28, tm_hour=14, tm_min=31, tm_sec=1, tm_wday=1, tm_yday=240, tm_isdst=0), 'title': '""Life never matters in the DEMOCRATS MIND"": Examining Strategies of\n  Retweeted Social Bots During a Mass Shooting Event', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Life never matters in the DEMOCRATS MIND"": Examining Strategies of\n  Retweeted Social Bots During a Mass Shooting Event'}, 'summary': 'This exploratory study examines the strategies of social bots on Twitter that\nwere retweeted following a mass shooting event. Using a case study method to\nframe our work, we collected over seven million tweets during a one-month\nperiod following a mass shooting in Parkland, Florida. From this dataset, we\nselected retweets of content generated by over 400 social bot accounts to\ndetermine what strategies these bots were using and the effectiveness of these\nstrategies as indicated by the number of retweets. We employed qualitative and\nquantitative methods to capture both macro- and micro-level perspectives. Our\nfindings suggest that bots engage in more diverse strategies than solely waging\ndisinformation campaigns, including baiting and sharing information. Further,\nwe found that while bots amplify conversation about mass shootings, humans were\nprimarily responsible for disseminating bot-generated content. These findings\nadd depth to the current understanding of bot strategies and their\neffectiveness. Understanding these strategies can inform efforts to combat\ndubious information as well as more insidious disinformation campaigns.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This exploratory study examines the strategies of social bots on Twitter that\nwere retweeted following a mass shooting event. Using a case study method to\nframe our work, we collected over seven million tweets during a one-month\nperiod following a mass shooting in Parkland, Florida. From this dataset, we\nselected retweets of content generated by over 400 social bot accounts to\ndetermine what strategies these bots were using and the effectiveness of these\nstrategies as indicated by the number of retweets. We employed qualitative and\nquantitative methods to capture both macro- and micro-level perspectives. Our\nfindings suggest that bots engage in more diverse strategies than solely waging\ndisinformation campaigns, including baiting and sharing information. Further,\nwe found that while bots amplify conversation about mass shootings, humans were\nprimarily responsible for disseminating bot-generated content. These findings\nadd depth to the current understanding of bot strategies and their\neffectiveness. Understanding these strategies can inform efforts to combat\ndubious information as well as more insidious disinformation campaigns.'}, 'authors': [{'name': 'Vanessa L. Kitzie'}, {'name': 'Ehsan Mohammadi'}, {'name': 'Amir Karami'}], 'author_detail': {'name': 'Amir Karami'}, 'author': 'Amir Karami', 'links': [{'href': 'http://arxiv.org/abs/1808.09325v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.09325v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
155,http://arxiv.org/abs/1808.03281v1,2018-08-09 18:00:05+00:00,2018-08-09 18:00:05+00:00,Who Falls for Online Political Manipulation?,"[arxiv.Result.Author('Adam Badawy'), arxiv.Result.Author('Kristina Lerman'), arxiv.Result.Author('Emilio Ferrara')]","Social media, once hailed as a vehicle for democratization and the promotion
of positive social change across the globe, are under attack for becoming a
tool of political manipulation and spread of disinformation. A case in point is
the alleged use of trolls by Russia to spread malicious content in Western
elections. This paper examines the Russian interference campaign in the 2016 US
presidential election on Twitter. Our aim is twofold: first, we test whether
predicting users who spread trolls' content is feasible in order to gain
insight on how to contain their influence in the future; second, we identify
features that are most predictive of users who either intentionally or
unintentionally play a vital role in spreading this malicious content. We
collected a dataset with over 43 million elections-related posts shared on
Twitter between September 16 and November 9, 2016, by about 5.7 million users.
This dataset includes accounts associated with the Russian trolls identified by
the US Congress. Proposed models are able to very accurately identify users who
spread the trolls' content (average AUC score of 96%, using 10-fold
validation). We show that political ideology, bot likelihood scores, and some
activity-related account meta data are the most predictive features of whether
a user spreads trolls' content or not.",,,,cs.SI,"['cs.SI', 'cs.HC', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1808.03281v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.03281v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.03281v1,"{'id': 'http://arxiv.org/abs/1808.03281v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.03281v1', 'updated': '2018-08-09T18:00:05Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=9, tm_hour=18, tm_min=0, tm_sec=5, tm_wday=3, tm_yday=221, tm_isdst=0), 'published': '2018-08-09T18:00:05Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=9, tm_hour=18, tm_min=0, tm_sec=5, tm_wday=3, tm_yday=221, tm_isdst=0), 'title': 'Who Falls for Online Political Manipulation?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Who Falls for Online Political Manipulation?'}, 'summary': ""Social media, once hailed as a vehicle for democratization and the promotion\nof positive social change across the globe, are under attack for becoming a\ntool of political manipulation and spread of disinformation. A case in point is\nthe alleged use of trolls by Russia to spread malicious content in Western\nelections. This paper examines the Russian interference campaign in the 2016 US\npresidential election on Twitter. Our aim is twofold: first, we test whether\npredicting users who spread trolls' content is feasible in order to gain\ninsight on how to contain their influence in the future; second, we identify\nfeatures that are most predictive of users who either intentionally or\nunintentionally play a vital role in spreading this malicious content. We\ncollected a dataset with over 43 million elections-related posts shared on\nTwitter between September 16 and November 9, 2016, by about 5.7 million users.\nThis dataset includes accounts associated with the Russian trolls identified by\nthe US Congress. Proposed models are able to very accurately identify users who\nspread the trolls' content (average AUC score of 96%, using 10-fold\nvalidation). We show that political ideology, bot likelihood scores, and some\nactivity-related account meta data are the most predictive features of whether\na user spreads trolls' content or not."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media, once hailed as a vehicle for democratization and the promotion\nof positive social change across the globe, are under attack for becoming a\ntool of political manipulation and spread of disinformation. A case in point is\nthe alleged use of trolls by Russia to spread malicious content in Western\nelections. This paper examines the Russian interference campaign in the 2016 US\npresidential election on Twitter. Our aim is twofold: first, we test whether\npredicting users who spread trolls' content is feasible in order to gain\ninsight on how to contain their influence in the future; second, we identify\nfeatures that are most predictive of users who either intentionally or\nunintentionally play a vital role in spreading this malicious content. We\ncollected a dataset with over 43 million elections-related posts shared on\nTwitter between September 16 and November 9, 2016, by about 5.7 million users.\nThis dataset includes accounts associated with the Russian trolls identified by\nthe US Congress. Proposed models are able to very accurately identify users who\nspread the trolls' content (average AUC score of 96%, using 10-fold\nvalidation). We show that political ideology, bot likelihood scores, and some\nactivity-related account meta data are the most predictive features of whether\na user spreads trolls' content or not.""}, 'authors': [{'name': 'Adam Badawy'}, {'name': 'Kristina Lerman'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'links': [{'href': 'http://arxiv.org/abs/1808.03281v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.03281v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
156,http://arxiv.org/abs/1807.06958v1,2018-07-18 14:19:49+00:00,2018-07-18 14:19:49+00:00,Quantifying Biases in Online Information Exposure,"[arxiv.Result.Author('Dimitar Nikolov'), arxiv.Result.Author('Mounia Lalmas'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Our consumption of online information is mediated by filtering, ranking, and
recommendation algorithms that introduce unintentional biases as they attempt
to deliver relevant and engaging content. It has been suggested that our
reliance on online technologies such as search engines and social media may
limit exposure to diverse points of view and make us vulnerable to manipulation
by disinformation. In this paper, we mine a massive dataset of Web traffic to
quantify two kinds of bias: (i) homogeneity bias, which is the tendency to
consume content from a narrow set of information sources, and (ii) popularity
bias, which is the selective exposure to content from top sites. Our analysis
reveals different bias levels across several widely used Web platforms. Search
exposes users to a diverse set of sources, while social media traffic tends to
exhibit high popularity and homogeneity bias. When we focus our analysis on
traffic to news sites, we find higher levels of popularity bias, with smaller
differences across applications. Overall, our results quantify the extent to
which our choices of online systems confine us inside ""social bubbles.""","25 pages, 10 figures, to appear in the Journal of the Association for
  Information Science and Technology (JASIST)","JASIST 70 (3): 218-229, 2019",10.1002/asi.24121,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1002/asi.24121', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1807.06958v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.06958v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.06958v1,"{'id': 'http://arxiv.org/abs/1807.06958v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.06958v1', 'updated': '2018-07-18T14:19:49Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=18, tm_hour=14, tm_min=19, tm_sec=49, tm_wday=2, tm_yday=199, tm_isdst=0), 'published': '2018-07-18T14:19:49Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=18, tm_hour=14, tm_min=19, tm_sec=49, tm_wday=2, tm_yday=199, tm_isdst=0), 'title': 'Quantifying Biases in Online Information Exposure', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Quantifying Biases in Online Information Exposure'}, 'summary': 'Our consumption of online information is mediated by filtering, ranking, and\nrecommendation algorithms that introduce unintentional biases as they attempt\nto deliver relevant and engaging content. It has been suggested that our\nreliance on online technologies such as search engines and social media may\nlimit exposure to diverse points of view and make us vulnerable to manipulation\nby disinformation. In this paper, we mine a massive dataset of Web traffic to\nquantify two kinds of bias: (i) homogeneity bias, which is the tendency to\nconsume content from a narrow set of information sources, and (ii) popularity\nbias, which is the selective exposure to content from top sites. Our analysis\nreveals different bias levels across several widely used Web platforms. Search\nexposes users to a diverse set of sources, while social media traffic tends to\nexhibit high popularity and homogeneity bias. When we focus our analysis on\ntraffic to news sites, we find higher levels of popularity bias, with smaller\ndifferences across applications. Overall, our results quantify the extent to\nwhich our choices of online systems confine us inside ""social bubbles.""', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Our consumption of online information is mediated by filtering, ranking, and\nrecommendation algorithms that introduce unintentional biases as they attempt\nto deliver relevant and engaging content. It has been suggested that our\nreliance on online technologies such as search engines and social media may\nlimit exposure to diverse points of view and make us vulnerable to manipulation\nby disinformation. In this paper, we mine a massive dataset of Web traffic to\nquantify two kinds of bias: (i) homogeneity bias, which is the tendency to\nconsume content from a narrow set of information sources, and (ii) popularity\nbias, which is the selective exposure to content from top sites. Our analysis\nreveals different bias levels across several widely used Web platforms. Search\nexposes users to a diverse set of sources, while social media traffic tends to\nexhibit high popularity and homogeneity bias. When we focus our analysis on\ntraffic to news sites, we find higher levels of popularity bias, with smaller\ndifferences across applications. Overall, our results quantify the extent to\nwhich our choices of online systems confine us inside ""social bubbles.""'}, 'authors': [{'name': 'Dimitar Nikolov'}, {'name': 'Mounia Lalmas'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1002/asi.24121', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1002/asi.24121', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1807.06958v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.06958v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '25 pages, 10 figures, to appear in the Journal of the Association for\n  Information Science and Technology (JASIST)', 'arxiv_journal_ref': 'JASIST 70 (3): 218-229, 2019', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
157,http://arxiv.org/abs/1804.04109v1,2018-04-11 17:28:41+00:00,2018-04-11 17:28:41+00:00,Influence Estimation on Social Media Networks Using Causal Inference,"[arxiv.Result.Author('Steven T. Smith'), arxiv.Result.Author('Edward K. Kao'), arxiv.Result.Author('Danelle C. Shah'), arxiv.Result.Author('Olga Simek'), arxiv.Result.Author('Donald B. Rubin')]","Estimating influence on social media networks is an important practical and
theoretical problem, especially because this new medium is widely exploited as
a platform for disinformation and propaganda. This paper introduces a novel
approach to influence estimation on social media networks and applies it to the
real-world problem of characterizing active influence operations on Twitter
during the 2017 French presidential elections. The new influence estimation
approach attributes impact by accounting for narrative propagation over the
network using a network causal inference framework applied to data arising from
graph sampling and filtering. This causal framework infers the difference in
outcome as a function of exposure, in contrast to existing approaches that
attribute impact to activity volume or topological features, which do not
explicitly measure nor necessarily indicate actual network influence.
Cram\'er-Rao estimation bounds are derived for parameter estimation as a step
in the causal analysis, and used to achieve geometrical insight on the causal
inference problem. The ability to infer high causal influence is demonstrated
on real-world social media accounts that are later independently confirmed to
be either directly affiliated or correlated with foreign influence operations
using evidence supplied by the U.S. Congress and journalistic reports.","5 pages, 4 figures, 1 table","IEEE Statistical Signal Processing Workshop (SSP), June 2018",10.1109/SSP.2018.8450823,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1109/SSP.2018.8450823', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1804.04109v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.04109v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.04109v1,"{'id': 'http://arxiv.org/abs/1804.04109v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.04109v1', 'updated': '2018-04-11T17:28:41Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=11, tm_hour=17, tm_min=28, tm_sec=41, tm_wday=2, tm_yday=101, tm_isdst=0), 'published': '2018-04-11T17:28:41Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=11, tm_hour=17, tm_min=28, tm_sec=41, tm_wday=2, tm_yday=101, tm_isdst=0), 'title': 'Influence Estimation on Social Media Networks Using Causal Inference', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Influence Estimation on Social Media Networks Using Causal Inference'}, 'summary': ""Estimating influence on social media networks is an important practical and\ntheoretical problem, especially because this new medium is widely exploited as\na platform for disinformation and propaganda. This paper introduces a novel\napproach to influence estimation on social media networks and applies it to the\nreal-world problem of characterizing active influence operations on Twitter\nduring the 2017 French presidential elections. The new influence estimation\napproach attributes impact by accounting for narrative propagation over the\nnetwork using a network causal inference framework applied to data arising from\ngraph sampling and filtering. This causal framework infers the difference in\noutcome as a function of exposure, in contrast to existing approaches that\nattribute impact to activity volume or topological features, which do not\nexplicitly measure nor necessarily indicate actual network influence.\nCram\\'er-Rao estimation bounds are derived for parameter estimation as a step\nin the causal analysis, and used to achieve geometrical insight on the causal\ninference problem. The ability to infer high causal influence is demonstrated\non real-world social media accounts that are later independently confirmed to\nbe either directly affiliated or correlated with foreign influence operations\nusing evidence supplied by the U.S. Congress and journalistic reports."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Estimating influence on social media networks is an important practical and\ntheoretical problem, especially because this new medium is widely exploited as\na platform for disinformation and propaganda. This paper introduces a novel\napproach to influence estimation on social media networks and applies it to the\nreal-world problem of characterizing active influence operations on Twitter\nduring the 2017 French presidential elections. The new influence estimation\napproach attributes impact by accounting for narrative propagation over the\nnetwork using a network causal inference framework applied to data arising from\ngraph sampling and filtering. This causal framework infers the difference in\noutcome as a function of exposure, in contrast to existing approaches that\nattribute impact to activity volume or topological features, which do not\nexplicitly measure nor necessarily indicate actual network influence.\nCram\\'er-Rao estimation bounds are derived for parameter estimation as a step\nin the causal analysis, and used to achieve geometrical insight on the causal\ninference problem. The ability to infer high causal influence is demonstrated\non real-world social media accounts that are later independently confirmed to\nbe either directly affiliated or correlated with foreign influence operations\nusing evidence supplied by the U.S. Congress and journalistic reports.""}, 'authors': [{'name': 'Steven T. Smith'}, {'name': 'Edward K. Kao'}, {'name': 'Danelle C. Shah'}, {'name': 'Olga Simek'}, {'name': 'Donald B. Rubin'}], 'author_detail': {'name': 'Donald B. Rubin'}, 'author': 'Donald B. Rubin', 'arxiv_doi': '10.1109/SSP.2018.8450823', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/SSP.2018.8450823', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1804.04109v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.04109v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '5 pages, 4 figures, 1 table', 'arxiv_journal_ref': 'IEEE Statistical Signal Processing Workshop (SSP), June 2018', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
158,http://arxiv.org/abs/1801.09288v2,2019-03-04 15:11:28+00:00,2018-01-28 21:00:52+00:00,Disinformation Warfare: Understanding State-Sponsored Trolls on Twitter and Their Influence on the Web,"[arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Tristan Caulfield'), arxiv.Result.Author('Emiliano De Cristofaro'), arxiv.Result.Author('Michael Sirivianos'), arxiv.Result.Author('Gianluca Stringhini'), arxiv.Result.Author('Jeremy Blackburn')]","Over the past couple of years, anecdotal evidence has emerged linking
coordinated campaigns by state-sponsored actors with efforts to manipulate
public opinion on the Web, often around major political events, through
dedicated accounts, or ""trolls."" Although they are often involved in spreading
disinformation on social media, there is little understanding of how these
trolls operate, what type of content they disseminate, and most importantly
their influence on the information ecosystem.
  In this paper, we shed light on these questions by analyzing 27K tweets
posted by 1K Twitter users identified as having ties with Russia's Internet
Research Agency and thus likely state-sponsored trolls. We compare their
behavior to a random set of Twitter users, finding interesting differences in
terms of the content they disseminate, the evolution of their account, as well
as their general behavior and use of Twitter. Then, using Hawkes Processes, we
quantify the influence that trolls had on the dissemination of news on social
platforms like Twitter, Reddit, and 4chan. Overall, our findings indicate that
Russian trolls managed to stay active for long periods of time and to reach a
substantial number of Twitter users with their tweets. When looking at their
ability of spreading news content and making it viral, however, we find that
their effect on social platforms was minor, with the significant exception of
news published by the Russian state-sponsored news outlet RT (Russia Today).","A preliminary version of this paper appears in the 4th Workshop on
  The Fourth Workshop on Computational Methods in Online Misbehavior
  (CyberSafety 2019) -- WWW'19 Companion Proceedings. This is the full version",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1801.09288v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1801.09288v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1801.09288v2,"{'id': 'http://arxiv.org/abs/1801.09288v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1801.09288v2', 'updated': '2019-03-04T15:11:28Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=4, tm_hour=15, tm_min=11, tm_sec=28, tm_wday=0, tm_yday=63, tm_isdst=0), 'published': '2018-01-28T21:00:52Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=28, tm_hour=21, tm_min=0, tm_sec=52, tm_wday=6, tm_yday=28, tm_isdst=0), 'title': 'Disinformation Warfare: Understanding State-Sponsored Trolls on Twitter\n  and Their Influence on the Web', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation Warfare: Understanding State-Sponsored Trolls on Twitter\n  and Their Influence on the Web'}, 'summary': 'Over the past couple of years, anecdotal evidence has emerged linking\ncoordinated campaigns by state-sponsored actors with efforts to manipulate\npublic opinion on the Web, often around major political events, through\ndedicated accounts, or ""trolls."" Although they are often involved in spreading\ndisinformation on social media, there is little understanding of how these\ntrolls operate, what type of content they disseminate, and most importantly\ntheir influence on the information ecosystem.\n  In this paper, we shed light on these questions by analyzing 27K tweets\nposted by 1K Twitter users identified as having ties with Russia\'s Internet\nResearch Agency and thus likely state-sponsored trolls. We compare their\nbehavior to a random set of Twitter users, finding interesting differences in\nterms of the content they disseminate, the evolution of their account, as well\nas their general behavior and use of Twitter. Then, using Hawkes Processes, we\nquantify the influence that trolls had on the dissemination of news on social\nplatforms like Twitter, Reddit, and 4chan. Overall, our findings indicate that\nRussian trolls managed to stay active for long periods of time and to reach a\nsubstantial number of Twitter users with their tweets. When looking at their\nability of spreading news content and making it viral, however, we find that\ntheir effect on social platforms was minor, with the significant exception of\nnews published by the Russian state-sponsored news outlet RT (Russia Today).', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past couple of years, anecdotal evidence has emerged linking\ncoordinated campaigns by state-sponsored actors with efforts to manipulate\npublic opinion on the Web, often around major political events, through\ndedicated accounts, or ""trolls."" Although they are often involved in spreading\ndisinformation on social media, there is little understanding of how these\ntrolls operate, what type of content they disseminate, and most importantly\ntheir influence on the information ecosystem.\n  In this paper, we shed light on these questions by analyzing 27K tweets\nposted by 1K Twitter users identified as having ties with Russia\'s Internet\nResearch Agency and thus likely state-sponsored trolls. We compare their\nbehavior to a random set of Twitter users, finding interesting differences in\nterms of the content they disseminate, the evolution of their account, as well\nas their general behavior and use of Twitter. Then, using Hawkes Processes, we\nquantify the influence that trolls had on the dissemination of news on social\nplatforms like Twitter, Reddit, and 4chan. Overall, our findings indicate that\nRussian trolls managed to stay active for long periods of time and to reach a\nsubstantial number of Twitter users with their tweets. When looking at their\nability of spreading news content and making it viral, however, we find that\ntheir effect on social platforms was minor, with the significant exception of\nnews published by the Russian state-sponsored news outlet RT (Russia Today).'}, 'authors': [{'name': 'Savvas Zannettou'}, {'name': 'Tristan Caulfield'}, {'name': 'Emiliano De Cristofaro'}, {'name': 'Michael Sirivianos'}, {'name': 'Gianluca Stringhini'}, {'name': 'Jeremy Blackburn'}], 'author_detail': {'name': 'Jeremy Blackburn'}, 'author': 'Jeremy Blackburn', 'arxiv_comment': ""A preliminary version of this paper appears in the 4th Workshop on\n  The Fourth Workshop on Computational Methods in Online Misbehavior\n  (CyberSafety 2019) -- WWW'19 Companion Proceedings. This is the full version"", 'links': [{'href': 'http://arxiv.org/abs/1801.09288v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1801.09288v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
159,http://arxiv.org/abs/1707.00086v1,2017-07-01 02:37:13+00:00,2017-07-01 02:37:13+00:00,Disinformation and Social Bot Operations in the Run Up to the 2017 French Presidential Election,[arxiv.Result.Author('Emilio Ferrara')],"Recent accounts from researchers, journalists, as well as federal
investigators, reached a unanimous conclusion: social media are systematically
exploited to manipulate and alter public opinion. Some disinformation campaigns
have been coordinated by means of bots, social media accounts controlled by
computer scripts that try to disguise themselves as legitimate human users. In
this study, we describe one such operation occurred in the run up to the 2017
French presidential election. We collected a massive Twitter dataset of nearly
17 million posts occurred between April 27 and May 7, 2017 (Election Day). We
then set to study the MacronLeaks disinformation campaign: By leveraging a mix
of machine learning and cognitive behavioral modeling techniques, we separated
humans from bots, and then studied the activities of the two groups taken
independently, as well as their interplay. We provide a characterization of
both the bots and the users who engaged with them and oppose it to those users
who didn't. Prior interests of disinformation adopters pinpoint to the reasons
of the scarce success of this campaign: the users who engaged with MacronLeaks
are mostly foreigners with a preexisting interest in alt-right topics and
alternative news media, rather than French users with diverse political views.
Concluding, anomalous account usage patterns suggest the possible existence of
a black-market for reusable political disinformation bots.","33 pages, 6 figures, 9 tables; submitted to First Monday","First Monday, 22(8), 2017",10.5210/fm.v22i8.8005,cs.SI,"['cs.SI', 'cs.HC', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.5210/fm.v22i8.8005', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1707.00086v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1707.00086v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1707.00086v1,"{'id': 'http://arxiv.org/abs/1707.00086v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1707.00086v1', 'updated': '2017-07-01T02:37:13Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=1, tm_hour=2, tm_min=37, tm_sec=13, tm_wday=5, tm_yday=182, tm_isdst=0), 'published': '2017-07-01T02:37:13Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=1, tm_hour=2, tm_min=37, tm_sec=13, tm_wday=5, tm_yday=182, tm_isdst=0), 'title': 'Disinformation and Social Bot Operations in the Run Up to the 2017\n  French Presidential Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation and Social Bot Operations in the Run Up to the 2017\n  French Presidential Election'}, 'summary': ""Recent accounts from researchers, journalists, as well as federal\ninvestigators, reached a unanimous conclusion: social media are systematically\nexploited to manipulate and alter public opinion. Some disinformation campaigns\nhave been coordinated by means of bots, social media accounts controlled by\ncomputer scripts that try to disguise themselves as legitimate human users. In\nthis study, we describe one such operation occurred in the run up to the 2017\nFrench presidential election. We collected a massive Twitter dataset of nearly\n17 million posts occurred between April 27 and May 7, 2017 (Election Day). We\nthen set to study the MacronLeaks disinformation campaign: By leveraging a mix\nof machine learning and cognitive behavioral modeling techniques, we separated\nhumans from bots, and then studied the activities of the two groups taken\nindependently, as well as their interplay. We provide a characterization of\nboth the bots and the users who engaged with them and oppose it to those users\nwho didn't. Prior interests of disinformation adopters pinpoint to the reasons\nof the scarce success of this campaign: the users who engaged with MacronLeaks\nare mostly foreigners with a preexisting interest in alt-right topics and\nalternative news media, rather than French users with diverse political views.\nConcluding, anomalous account usage patterns suggest the possible existence of\na black-market for reusable political disinformation bots."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recent accounts from researchers, journalists, as well as federal\ninvestigators, reached a unanimous conclusion: social media are systematically\nexploited to manipulate and alter public opinion. Some disinformation campaigns\nhave been coordinated by means of bots, social media accounts controlled by\ncomputer scripts that try to disguise themselves as legitimate human users. In\nthis study, we describe one such operation occurred in the run up to the 2017\nFrench presidential election. We collected a massive Twitter dataset of nearly\n17 million posts occurred between April 27 and May 7, 2017 (Election Day). We\nthen set to study the MacronLeaks disinformation campaign: By leveraging a mix\nof machine learning and cognitive behavioral modeling techniques, we separated\nhumans from bots, and then studied the activities of the two groups taken\nindependently, as well as their interplay. We provide a characterization of\nboth the bots and the users who engaged with them and oppose it to those users\nwho didn't. Prior interests of disinformation adopters pinpoint to the reasons\nof the scarce success of this campaign: the users who engaged with MacronLeaks\nare mostly foreigners with a preexisting interest in alt-right topics and\nalternative news media, rather than French users with diverse political views.\nConcluding, anomalous account usage patterns suggest the possible existence of\na black-market for reusable political disinformation bots.""}, 'authors': [{'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'arxiv_doi': '10.5210/fm.v22i8.8005', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.5210/fm.v22i8.8005', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1707.00086v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1707.00086v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '33 pages, 6 figures, 9 tables; submitted to First Monday', 'arxiv_journal_ref': 'First Monday, 22(8), 2017', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
160,http://arxiv.org/abs/1611.02588v2,2016-11-11 10:57:07+00:00,2016-11-08 16:19:17+00:00,Contradiction Detection for Rumorous Claims,"[arxiv.Result.Author('Piroska Lendvai'), arxiv.Result.Author('Uwe D. Reichel')]","The utilization of social media material in journalistic workflows is
increasing, demanding automated methods for the identification of mis- and
disinformation. Since textual contradiction across social media posts can be a
signal of rumorousness, we seek to model how claims in Twitter posts are being
textually contradicted. We identify two different contexts in which
contradiction emerges: its broader form can be observed across independently
posted tweets and its more specific form in threaded conversations. We define
how the two scenarios differ in terms of central elements of argumentation:
claims and conversation structure. We design and evaluate models for the two
scenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to
represent claims and conversation structure implicitly in a generic inference
model, while previous studies used explicit or no representation of these
properties. To address noisy text, our classifiers use simple similarity
features derived from the string and part-of-speech level. Corpus statistics
reveal distribution differences for these features in contradictory as opposed
to non-contradictory tweet relations, and the classifiers yield state of the
art performance.","To appear in: Proceedings of Extra-Propositional Aspects of Meaning
  (ExProM) in Computational Linguistics, Osaka, Japan, 2016","Proc. Extra-Propositional Aspects of Meaning (ExProM) in
  Computational Linguistics, Osaka, Japan, 2016, pp 31-40",,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1611.02588v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1611.02588v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1611.02588v2,"{'id': 'http://arxiv.org/abs/1611.02588v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1611.02588v2', 'updated': '2016-11-11T10:57:07Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=11, tm_mday=11, tm_hour=10, tm_min=57, tm_sec=7, tm_wday=4, tm_yday=316, tm_isdst=0), 'published': '2016-11-08T16:19:17Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=11, tm_mday=8, tm_hour=16, tm_min=19, tm_sec=17, tm_wday=1, tm_yday=313, tm_isdst=0), 'title': 'Contradiction Detection for Rumorous Claims', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Contradiction Detection for Rumorous Claims'}, 'summary': 'The utilization of social media material in journalistic workflows is\nincreasing, demanding automated methods for the identification of mis- and\ndisinformation. Since textual contradiction across social media posts can be a\nsignal of rumorousness, we seek to model how claims in Twitter posts are being\ntextually contradicted. We identify two different contexts in which\ncontradiction emerges: its broader form can be observed across independently\nposted tweets and its more specific form in threaded conversations. We define\nhow the two scenarios differ in terms of central elements of argumentation:\nclaims and conversation structure. We design and evaluate models for the two\nscenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to\nrepresent claims and conversation structure implicitly in a generic inference\nmodel, while previous studies used explicit or no representation of these\nproperties. To address noisy text, our classifiers use simple similarity\nfeatures derived from the string and part-of-speech level. Corpus statistics\nreveal distribution differences for these features in contradictory as opposed\nto non-contradictory tweet relations, and the classifiers yield state of the\nart performance.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The utilization of social media material in journalistic workflows is\nincreasing, demanding automated methods for the identification of mis- and\ndisinformation. Since textual contradiction across social media posts can be a\nsignal of rumorousness, we seek to model how claims in Twitter posts are being\ntextually contradicted. We identify two different contexts in which\ncontradiction emerges: its broader form can be observed across independently\nposted tweets and its more specific form in threaded conversations. We define\nhow the two scenarios differ in terms of central elements of argumentation:\nclaims and conversation structure. We design and evaluate models for the two\nscenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to\nrepresent claims and conversation structure implicitly in a generic inference\nmodel, while previous studies used explicit or no representation of these\nproperties. To address noisy text, our classifiers use simple similarity\nfeatures derived from the string and part-of-speech level. Corpus statistics\nreveal distribution differences for these features in contradictory as opposed\nto non-contradictory tweet relations, and the classifiers yield state of the\nart performance.'}, 'authors': [{'name': 'Piroska Lendvai'}, {'name': 'Uwe D. Reichel'}], 'author_detail': {'name': 'Uwe D. Reichel'}, 'author': 'Uwe D. Reichel', 'arxiv_comment': 'To appear in: Proceedings of Extra-Propositional Aspects of Meaning\n  (ExProM) in Computational Linguistics, Osaka, Japan, 2016', 'arxiv_journal_ref': 'Proc. Extra-Propositional Aspects of Meaning (ExProM) in\n  Computational Linguistics, Osaka, Japan, 2016, pp 31-40', 'links': [{'href': 'http://arxiv.org/abs/1611.02588v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1611.02588v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
161,http://arxiv.org/abs/1505.00956v2,2015-06-02 17:30:59+00:00,2015-05-05 11:15:43+00:00,Informational parasites in code evolution,"[arxiv.Result.Author('Andres C. Burgos'), arxiv.Result.Author('Daniel Polani')]","In a previous study, we considered an information-theoretic model of code
evolution. In it, agents obtain information about their (common) environment by
the perception of messages of other agents, which is determined by an
interaction probability (the structure of the population). For an agent to
understand another agent's messages, the former must either know the identity
of the latter, or the code producing the messages must be universally
interpretable. A universal code, however, introduces a vulnerability: a
parasitic entity can take advantage of it. Here, we investigate this problem.
In our specific setting, we consider a parasite to be an agent that tries to
inflict as much damage as possible in the mutual understanding of the
population (i.e. the parasite acts as a disinformation agent). We show that,
after introducing a parasite in the population, the former adopts a code such
that it captures the information about the environment that is missing in the
population. Such agent would be of great value, but only if the rest of the
population could understand its messages. However, it is of little use here,
since the parasite utilises the most common messages in the population to
express different concepts. Now we let the population respond by updating their
codes such that, in this arms race, they again maximise their mutual
understanding. As a result, there is a code drift in the population where the
utilisation of the messages of the parasite is avoided. A consequence of this
is that the information that the parasite possesses but the agents lack becomes
understandable and readily available.","Accepted for the 13th European Conference on Artificial Life (ECAL
  2015)",,,cs.MA,['cs.MA'],"[arxiv.Result.Link('http://arxiv.org/abs/1505.00956v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1505.00956v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1505.00956v2,"{'id': 'http://arxiv.org/abs/1505.00956v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1505.00956v2', 'updated': '2015-06-02T17:30:59Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=6, tm_mday=2, tm_hour=17, tm_min=30, tm_sec=59, tm_wday=1, tm_yday=153, tm_isdst=0), 'published': '2015-05-05T11:15:43Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=5, tm_mday=5, tm_hour=11, tm_min=15, tm_sec=43, tm_wday=1, tm_yday=125, tm_isdst=0), 'title': 'Informational parasites in code evolution', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Informational parasites in code evolution'}, 'summary': ""In a previous study, we considered an information-theoretic model of code\nevolution. In it, agents obtain information about their (common) environment by\nthe perception of messages of other agents, which is determined by an\ninteraction probability (the structure of the population). For an agent to\nunderstand another agent's messages, the former must either know the identity\nof the latter, or the code producing the messages must be universally\ninterpretable. A universal code, however, introduces a vulnerability: a\nparasitic entity can take advantage of it. Here, we investigate this problem.\nIn our specific setting, we consider a parasite to be an agent that tries to\ninflict as much damage as possible in the mutual understanding of the\npopulation (i.e. the parasite acts as a disinformation agent). We show that,\nafter introducing a parasite in the population, the former adopts a code such\nthat it captures the information about the environment that is missing in the\npopulation. Such agent would be of great value, but only if the rest of the\npopulation could understand its messages. However, it is of little use here,\nsince the parasite utilises the most common messages in the population to\nexpress different concepts. Now we let the population respond by updating their\ncodes such that, in this arms race, they again maximise their mutual\nunderstanding. As a result, there is a code drift in the population where the\nutilisation of the messages of the parasite is avoided. A consequence of this\nis that the information that the parasite possesses but the agents lack becomes\nunderstandable and readily available."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In a previous study, we considered an information-theoretic model of code\nevolution. In it, agents obtain information about their (common) environment by\nthe perception of messages of other agents, which is determined by an\ninteraction probability (the structure of the population). For an agent to\nunderstand another agent's messages, the former must either know the identity\nof the latter, or the code producing the messages must be universally\ninterpretable. A universal code, however, introduces a vulnerability: a\nparasitic entity can take advantage of it. Here, we investigate this problem.\nIn our specific setting, we consider a parasite to be an agent that tries to\ninflict as much damage as possible in the mutual understanding of the\npopulation (i.e. the parasite acts as a disinformation agent). We show that,\nafter introducing a parasite in the population, the former adopts a code such\nthat it captures the information about the environment that is missing in the\npopulation. Such agent would be of great value, but only if the rest of the\npopulation could understand its messages. However, it is of little use here,\nsince the parasite utilises the most common messages in the population to\nexpress different concepts. Now we let the population respond by updating their\ncodes such that, in this arms race, they again maximise their mutual\nunderstanding. As a result, there is a code drift in the population where the\nutilisation of the messages of the parasite is avoided. A consequence of this\nis that the information that the parasite possesses but the agents lack becomes\nunderstandable and readily available.""}, 'authors': [{'name': 'Andres C. Burgos'}, {'name': 'Daniel Polani'}], 'author_detail': {'name': 'Daniel Polani'}, 'author': 'Daniel Polani', 'arxiv_comment': 'Accepted for the 13th European Conference on Artificial Life (ECAL\n  2015)', 'links': [{'href': 'http://arxiv.org/abs/1505.00956v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1505.00956v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
162,http://arxiv.org/abs/0707.4036v2,2008-07-17 14:43:04+00:00,2007-07-27 04:13:21+00:00,"Disrupting Terrorist Networks, a dynamic fitness landscape approach","[arxiv.Result.Author('Philip V. Fellman'), arxiv.Result.Author('Jonathan P. Clemens'), arxiv.Result.Author('Roxana Wright'), arxiv.Result.Author('Jonathan Vos Post'), arxiv.Result.Author('Matthew Dadmun')]","Over a period of approximately five years, Pankaj Ghemawat of Harvard
Business School and Daniel Levinthal of the Wharton School have been working on
a detailed simulation (producing approximately a million fitness landscape
graphs) in order to determine optimal patterns of decision-making for
corporations. In 2006, we adapted this study, combining it with our own work on
terrorism to examine what would happen if we inverted Ghemawat and Levinthal's
findings and sought to provide disinformation or otherwise interfere with the
communications and decision processes of terrorist organizations in order to
optimize poor decision making and inefficiencies in organizational
coordination, command and control.
  The bulk of this study was then presented at the 2006 annual meeting of the
North American Association for Computation in the Social and Organizational
Sciences. We present here an updated version of that study, emphasizing the
rather counter-intuitive finding that ""soft"" targets have almost no value and
that unless one can influence key factors, an effort directed at the easy to
reach elements of terrorist organizations may actually be worse than mounting
no effort at all. We conclude with the recommendation that some fundamental
rethinking may be required if the United States is to effectively defend itself
from future terrorist attacks.","12 pages, 8 figures. Proceedings of the 2006 annual meeting of the
  North American Association for Computation in the Social and Organizational
  Sciences","InterJournal Complex Systems, 2060",,nlin.AO,['nlin.AO'],"[arxiv.Result.Link('http://arxiv.org/abs/0707.4036v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/0707.4036v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/0707.4036v2,"{'id': 'http://arxiv.org/abs/0707.4036v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/0707.4036v2', 'updated': '2008-07-17T14:43:04Z', 'updated_parsed': time.struct_time(tm_year=2008, tm_mon=7, tm_mday=17, tm_hour=14, tm_min=43, tm_sec=4, tm_wday=3, tm_yday=199, tm_isdst=0), 'published': '2007-07-27T04:13:21Z', 'published_parsed': time.struct_time(tm_year=2007, tm_mon=7, tm_mday=27, tm_hour=4, tm_min=13, tm_sec=21, tm_wday=4, tm_yday=208, tm_isdst=0), 'title': 'Disrupting Terrorist Networks, a dynamic fitness landscape approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disrupting Terrorist Networks, a dynamic fitness landscape approach'}, 'summary': 'Over a period of approximately five years, Pankaj Ghemawat of Harvard\nBusiness School and Daniel Levinthal of the Wharton School have been working on\na detailed simulation (producing approximately a million fitness landscape\ngraphs) in order to determine optimal patterns of decision-making for\ncorporations. In 2006, we adapted this study, combining it with our own work on\nterrorism to examine what would happen if we inverted Ghemawat and Levinthal\'s\nfindings and sought to provide disinformation or otherwise interfere with the\ncommunications and decision processes of terrorist organizations in order to\noptimize poor decision making and inefficiencies in organizational\ncoordination, command and control.\n  The bulk of this study was then presented at the 2006 annual meeting of the\nNorth American Association for Computation in the Social and Organizational\nSciences. We present here an updated version of that study, emphasizing the\nrather counter-intuitive finding that ""soft"" targets have almost no value and\nthat unless one can influence key factors, an effort directed at the easy to\nreach elements of terrorist organizations may actually be worse than mounting\nno effort at all. We conclude with the recommendation that some fundamental\nrethinking may be required if the United States is to effectively defend itself\nfrom future terrorist attacks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over a period of approximately five years, Pankaj Ghemawat of Harvard\nBusiness School and Daniel Levinthal of the Wharton School have been working on\na detailed simulation (producing approximately a million fitness landscape\ngraphs) in order to determine optimal patterns of decision-making for\ncorporations. In 2006, we adapted this study, combining it with our own work on\nterrorism to examine what would happen if we inverted Ghemawat and Levinthal\'s\nfindings and sought to provide disinformation or otherwise interfere with the\ncommunications and decision processes of terrorist organizations in order to\noptimize poor decision making and inefficiencies in organizational\ncoordination, command and control.\n  The bulk of this study was then presented at the 2006 annual meeting of the\nNorth American Association for Computation in the Social and Organizational\nSciences. We present here an updated version of that study, emphasizing the\nrather counter-intuitive finding that ""soft"" targets have almost no value and\nthat unless one can influence key factors, an effort directed at the easy to\nreach elements of terrorist organizations may actually be worse than mounting\nno effort at all. We conclude with the recommendation that some fundamental\nrethinking may be required if the United States is to effectively defend itself\nfrom future terrorist attacks.'}, 'authors': [{'name': 'Philip V. Fellman'}, {'name': 'Jonathan P. Clemens'}, {'name': 'Roxana Wright'}, {'name': 'Jonathan Vos Post'}, {'name': 'Matthew Dadmun'}], 'author_detail': {'name': 'Matthew Dadmun'}, 'author': 'Matthew Dadmun', 'arxiv_comment': '12 pages, 8 figures. Proceedings of the 2006 annual meeting of the\n  North American Association for Computation in the Social and Organizational\n  Sciences', 'arxiv_journal_ref': 'InterJournal Complex Systems, 2060', 'links': [{'href': 'http://arxiv.org/abs/0707.4036v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/0707.4036v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
163,http://arxiv.org/abs/cond-mat/0312266v1,2003-12-10 19:26:05+00:00,2003-12-10 19:26:05+00:00,Efficiency through disinformation,"[arxiv.Result.Author('Richard Metzler'), arxiv.Result.Author('Mark Klein'), arxiv.Result.Author('Yaneer Bar-Yam')]","We study the impact of disinformation on a model of resource allocation with
independent selfish agents: clients send requests to one of two servers,
depending on which one is perceived as offering shorter waiting times. Delays
in the information about the servers' state leads to oscillations in load.
Servers can give false information about their state (global disinformation) or
refuse service to individual clients (local disinformation). We discuss the
tradeoff between positive effects of disinformation (attenuation of
oscillations) and negative effects (increased fluctuations and reduced
adaptability) for different parameter values.","6 pages, 3 figures",Physical Review B 69 (2004) 235309,,cond-mat.dis-nn,['cond-mat.dis-nn'],"[arxiv.Result.Link('http://arxiv.org/abs/cond-mat/0312266v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/cond-mat/0312266v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/cond-mat/0312266v1,"{'id': 'http://arxiv.org/abs/cond-mat/0312266v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/cond-mat/0312266v1', 'updated': '2003-12-10T19:26:05Z', 'updated_parsed': time.struct_time(tm_year=2003, tm_mon=12, tm_mday=10, tm_hour=19, tm_min=26, tm_sec=5, tm_wday=2, tm_yday=344, tm_isdst=0), 'published': '2003-12-10T19:26:05Z', 'published_parsed': time.struct_time(tm_year=2003, tm_mon=12, tm_mday=10, tm_hour=19, tm_min=26, tm_sec=5, tm_wday=2, tm_yday=344, tm_isdst=0), 'title': 'Efficiency through disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Efficiency through disinformation'}, 'summary': ""We study the impact of disinformation on a model of resource allocation with\nindependent selfish agents: clients send requests to one of two servers,\ndepending on which one is perceived as offering shorter waiting times. Delays\nin the information about the servers' state leads to oscillations in load.\nServers can give false information about their state (global disinformation) or\nrefuse service to individual clients (local disinformation). We discuss the\ntradeoff between positive effects of disinformation (attenuation of\noscillations) and negative effects (increased fluctuations and reduced\nadaptability) for different parameter values."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Adisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We study the impact of disinformation on a model of resource allocation with\nindependent selfish agents: clients send requests to one of two servers,\ndepending on which one is perceived as offering shorter waiting times. Delays\nin the information about the servers' state leads to oscillations in load.\nServers can give false information about their state (global disinformation) or\nrefuse service to individual clients (local disinformation). We discuss the\ntradeoff between positive effects of disinformation (attenuation of\noscillations) and negative effects (increased fluctuations and reduced\nadaptability) for different parameter values.""}, 'authors': [{'name': 'Richard Metzler'}, {'name': 'Mark Klein'}, {'name': 'Yaneer Bar-Yam'}], 'author_detail': {'name': 'Yaneer Bar-Yam'}, 'author': 'Yaneer Bar-Yam', 'arxiv_comment': '6 pages, 3 figures', 'arxiv_journal_ref': 'Physical Review B 69 (2004) 235309', 'links': [{'href': 'http://arxiv.org/abs/cond-mat/0312266v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/cond-mat/0312266v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cond-mat.dis-nn', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cond-mat.dis-nn', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:disinformation
