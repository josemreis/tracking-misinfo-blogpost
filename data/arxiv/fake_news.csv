,entry_id,updated,published,title,authors,summary,comment,journal_ref,doi,primary_category,categories,links,pdf_url,_raw,query
0,http://arxiv.org/abs/2110.07574v1,2021-10-14 17:38:12+00:00,2021-10-14 17:38:12+00:00,Delphi: Towards Machine Ethics and Norms,"[arxiv.Result.Author('Liwei Jiang'), arxiv.Result.Author('Jena D. Hwang'), arxiv.Result.Author('Chandra Bhagavatula'), arxiv.Result.Author('Ronan Le Bras'), arxiv.Result.Author('Maxwell Forbes'), arxiv.Result.Author('Jon Borchardt'), arxiv.Result.Author('Jenny Liang'), arxiv.Result.Author('Oren Etzioni'), arxiv.Result.Author('Maarten Sap'), arxiv.Result.Author('Yejin Choi')]","What would it take to teach a machine to behave ethically? While broad
ethical rules may seem straightforward to state (""thou shalt not kill""),
applying such rules to real-world situations is far more complex. For example,
while ""helping a friend"" is generally a good thing to do, ""helping a friend
spread fake news"" is not. We identify four underlying challenges towards
machine ethics and norms: (1) an understanding of moral precepts and social
norms; (2) the ability to perceive real-world situations visually or by reading
natural language descriptions; (3) commonsense reasoning to anticipate the
outcome of alternative actions in different contexts; (4) most importantly, the
ability to make ethical judgments given the interplay between competing values
and their grounding in different contexts (e.g., the right to freedom of
expression vs. preventing the spread of fake news).
  Our paper begins to address these questions within the deep learning
paradigm. Our prototype model, Delphi, demonstrates strong promise of
language-based commonsense moral reasoning, with up to 92.1% accuracy vetted by
humans. This is in stark contrast to the zero-shot performance of GPT-3 of
52.3%, which suggests that massive scale alone does not endow pre-trained
neural language models with human values. Thus, we present Commonsense Norm
Bank, a moral textbook customized for machines, which compiles 1.7M examples of
people's ethical judgments on a broad spectrum of everyday situations. In
addition to the new resources and baseline performances for future research,
our study provides new insights that lead to several important open research
questions: differentiating between universal human values and personal values,
modeling different moral frameworks, and explainable, consistent approaches to
machine ethics.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2110.07574v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.07574v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.07574v1,"{'id': 'http://arxiv.org/abs/2110.07574v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.07574v1', 'updated': '2021-10-14T17:38:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=14, tm_hour=17, tm_min=38, tm_sec=12, tm_wday=3, tm_yday=287, tm_isdst=0), 'published': '2021-10-14T17:38:12Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=14, tm_hour=17, tm_min=38, tm_sec=12, tm_wday=3, tm_yday=287, tm_isdst=0), 'title': 'Delphi: Towards Machine Ethics and Norms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Delphi: Towards Machine Ethics and Norms'}, 'summary': 'What would it take to teach a machine to behave ethically? While broad\nethical rules may seem straightforward to state (""thou shalt not kill""),\napplying such rules to real-world situations is far more complex. For example,\nwhile ""helping a friend"" is generally a good thing to do, ""helping a friend\nspread fake news"" is not. We identify four underlying challenges towards\nmachine ethics and norms: (1) an understanding of moral precepts and social\nnorms; (2) the ability to perceive real-world situations visually or by reading\nnatural language descriptions; (3) commonsense reasoning to anticipate the\noutcome of alternative actions in different contexts; (4) most importantly, the\nability to make ethical judgments given the interplay between competing values\nand their grounding in different contexts (e.g., the right to freedom of\nexpression vs. preventing the spread of fake news).\n  Our paper begins to address these questions within the deep learning\nparadigm. Our prototype model, Delphi, demonstrates strong promise of\nlanguage-based commonsense moral reasoning, with up to 92.1% accuracy vetted by\nhumans. This is in stark contrast to the zero-shot performance of GPT-3 of\n52.3%, which suggests that massive scale alone does not endow pre-trained\nneural language models with human values. Thus, we present Commonsense Norm\nBank, a moral textbook customized for machines, which compiles 1.7M examples of\npeople\'s ethical judgments on a broad spectrum of everyday situations. In\naddition to the new resources and baseline performances for future research,\nour study provides new insights that lead to several important open research\nquestions: differentiating between universal human values and personal values,\nmodeling different moral frameworks, and explainable, consistent approaches to\nmachine ethics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What would it take to teach a machine to behave ethically? While broad\nethical rules may seem straightforward to state (""thou shalt not kill""),\napplying such rules to real-world situations is far more complex. For example,\nwhile ""helping a friend"" is generally a good thing to do, ""helping a friend\nspread fake news"" is not. We identify four underlying challenges towards\nmachine ethics and norms: (1) an understanding of moral precepts and social\nnorms; (2) the ability to perceive real-world situations visually or by reading\nnatural language descriptions; (3) commonsense reasoning to anticipate the\noutcome of alternative actions in different contexts; (4) most importantly, the\nability to make ethical judgments given the interplay between competing values\nand their grounding in different contexts (e.g., the right to freedom of\nexpression vs. preventing the spread of fake news).\n  Our paper begins to address these questions within the deep learning\nparadigm. Our prototype model, Delphi, demonstrates strong promise of\nlanguage-based commonsense moral reasoning, with up to 92.1% accuracy vetted by\nhumans. This is in stark contrast to the zero-shot performance of GPT-3 of\n52.3%, which suggests that massive scale alone does not endow pre-trained\nneural language models with human values. Thus, we present Commonsense Norm\nBank, a moral textbook customized for machines, which compiles 1.7M examples of\npeople\'s ethical judgments on a broad spectrum of everyday situations. In\naddition to the new resources and baseline performances for future research,\nour study provides new insights that lead to several important open research\nquestions: differentiating between universal human values and personal values,\nmodeling different moral frameworks, and explainable, consistent approaches to\nmachine ethics.'}, 'authors': [{'name': 'Liwei Jiang'}, {'name': 'Jena D. Hwang'}, {'name': 'Chandra Bhagavatula'}, {'name': 'Ronan Le Bras'}, {'name': 'Maxwell Forbes'}, {'name': 'Jon Borchardt'}, {'name': 'Jenny Liang'}, {'name': 'Oren Etzioni'}, {'name': 'Maarten Sap'}, {'name': 'Yejin Choi'}], 'author_detail': {'name': 'Yejin Choi'}, 'author': 'Yejin Choi', 'links': [{'href': 'http://arxiv.org/abs/2110.07574v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.07574v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
1,http://arxiv.org/abs/2110.06495v1,2021-10-13 04:44:02+00:00,2021-10-13 04:44:02+00:00,Cross-lingual COVID-19 Fake News Detection,"[arxiv.Result.Author('Jiangshu Du'), arxiv.Result.Author('Yingtong Dou'), arxiv.Result.Author('Congying Xia'), arxiv.Result.Author('Limeng Cui'), arxiv.Result.Author('Jing Ma'), arxiv.Result.Author('Philip S. Yu')]","The COVID-19 pandemic poses a great threat to global public health.
Meanwhile, there is massive misinformation associated with the pandemic which
advocates unfounded or unscientific claims. Even major social media and news
outlets have made an extra effort in debunking COVID-19 misinformation, most of
the fact-checking information is in English, whereas some unmoderated COVID-19
misinformation is still circulating in other languages, threatening the health
of less-informed people in immigrant communities and developing countries. In
this paper, we make the first attempt to detect COVID-19 misinformation in a
low-resource language (Chinese) only using the fact-checked news in a
high-resource language (English). We start by curating a Chinese real&fake news
dataset according to existing fact-checking information. Then, we propose a
deep learning framework named CrossFake to jointly encode the cross-lingual
news body texts and capture the news content as much as possible. Empirical
results on our dataset demonstrate the effectiveness of CorssFake under the
cross-lingual setting and it also outperforms several monolingual and
cross-lingual fake news detectors. The dataset is available at
https://github.com/YingtongDou/CrossFake.","Accepted by SDM at ICDM, data is available at
  https://github.com/YingtongDou/CrossFake",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2110.06495v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.06495v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.06495v1,"{'id': 'http://arxiv.org/abs/2110.06495v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.06495v1', 'updated': '2021-10-13T04:44:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=4, tm_min=44, tm_sec=2, tm_wday=2, tm_yday=286, tm_isdst=0), 'published': '2021-10-13T04:44:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=4, tm_min=44, tm_sec=2, tm_wday=2, tm_yday=286, tm_isdst=0), 'title': 'Cross-lingual COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cross-lingual COVID-19 Fake News Detection'}, 'summary': 'The COVID-19 pandemic poses a great threat to global public health.\nMeanwhile, there is massive misinformation associated with the pandemic which\nadvocates unfounded or unscientific claims. Even major social media and news\noutlets have made an extra effort in debunking COVID-19 misinformation, most of\nthe fact-checking information is in English, whereas some unmoderated COVID-19\nmisinformation is still circulating in other languages, threatening the health\nof less-informed people in immigrant communities and developing countries. In\nthis paper, we make the first attempt to detect COVID-19 misinformation in a\nlow-resource language (Chinese) only using the fact-checked news in a\nhigh-resource language (English). We start by curating a Chinese real&fake news\ndataset according to existing fact-checking information. Then, we propose a\ndeep learning framework named CrossFake to jointly encode the cross-lingual\nnews body texts and capture the news content as much as possible. Empirical\nresults on our dataset demonstrate the effectiveness of CorssFake under the\ncross-lingual setting and it also outperforms several monolingual and\ncross-lingual fake news detectors. The dataset is available at\nhttps://github.com/YingtongDou/CrossFake.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic poses a great threat to global public health.\nMeanwhile, there is massive misinformation associated with the pandemic which\nadvocates unfounded or unscientific claims. Even major social media and news\noutlets have made an extra effort in debunking COVID-19 misinformation, most of\nthe fact-checking information is in English, whereas some unmoderated COVID-19\nmisinformation is still circulating in other languages, threatening the health\nof less-informed people in immigrant communities and developing countries. In\nthis paper, we make the first attempt to detect COVID-19 misinformation in a\nlow-resource language (Chinese) only using the fact-checked news in a\nhigh-resource language (English). We start by curating a Chinese real&fake news\ndataset according to existing fact-checking information. Then, we propose a\ndeep learning framework named CrossFake to jointly encode the cross-lingual\nnews body texts and capture the news content as much as possible. Empirical\nresults on our dataset demonstrate the effectiveness of CorssFake under the\ncross-lingual setting and it also outperforms several monolingual and\ncross-lingual fake news detectors. The dataset is available at\nhttps://github.com/YingtongDou/CrossFake.'}, 'authors': [{'name': 'Jiangshu Du'}, {'name': 'Yingtong Dou'}, {'name': 'Congying Xia'}, {'name': 'Limeng Cui'}, {'name': 'Jing Ma'}, {'name': 'Philip S. Yu'}], 'author_detail': {'name': 'Philip S. Yu'}, 'author': 'Philip S. Yu', 'arxiv_comment': 'Accepted by SDM at ICDM, data is available at\n  https://github.com/YingtongDou/CrossFake', 'links': [{'href': 'http://arxiv.org/abs/2110.06495v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.06495v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
2,http://arxiv.org/abs/2110.06461v1,2021-10-13 02:56:16+00:00,2021-10-13 02:56:16+00:00,Fake News Detection in Spanish Using Deep Learning Techniques,"[arxiv.Result.Author('Kevin Martínez-Gallego'), arxiv.Result.Author('Andrés M. Álvarez-Ortiz'), arxiv.Result.Author('Julián D. Arias-Londoño')]","This paper addresses the problem of fake news detection in Spanish using
Machine Learning techniques. It is fundamentally the same problem tackled for
the English language; however, there is not a significant amount of publicly
available and adequately labeled fake news in Spanish to effectively train a
Machine Learning model, similarly to those proposed for the English language.
Therefore, this work explores different training strategies and architectures
to establish a baseline for further research in this area. Four datasets were
used, two in English and two in Spanish, and four experimental schemes were
tested, including a baseline with classical Machine Learning models, trained
and validated using a small dataset in Spanish. The remaining schemes include
state-of-the-art Deep Learning models trained (or fine-tuned) and validated in
English, trained and validated in Spanish, and fitted in English and validated
with automatic translated Spanish sentences. The Deep Learning architectures
were built on top of different pre-trained Word Embedding representations,
including GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus
in Spanish). According to the results, the best strategy was a combination of a
pre-trained BETO model and a Recurrent Neural Network based on LSTM layers,
yielding an accuracy of up to 80%; nonetheless, a baseline model using a Random
Forest estimator obtained similar outcomes. Additionally, the translation
strategy did not yield acceptable results because of the propagation error;
there was also observed a significant difference in models performance when
trained in English or Spanish, mainly attributable to the number of samples
available for each language.",,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2110.06461v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.06461v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.06461v1,"{'id': 'http://arxiv.org/abs/2110.06461v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.06461v1', 'updated': '2021-10-13T02:56:16Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=2, tm_min=56, tm_sec=16, tm_wday=2, tm_yday=286, tm_isdst=0), 'published': '2021-10-13T02:56:16Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=2, tm_min=56, tm_sec=16, tm_wday=2, tm_yday=286, tm_isdst=0), 'title': 'Fake News Detection in Spanish Using Deep Learning Techniques', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection in Spanish Using Deep Learning Techniques'}, 'summary': 'This paper addresses the problem of fake news detection in Spanish using\nMachine Learning techniques. It is fundamentally the same problem tackled for\nthe English language; however, there is not a significant amount of publicly\navailable and adequately labeled fake news in Spanish to effectively train a\nMachine Learning model, similarly to those proposed for the English language.\nTherefore, this work explores different training strategies and architectures\nto establish a baseline for further research in this area. Four datasets were\nused, two in English and two in Spanish, and four experimental schemes were\ntested, including a baseline with classical Machine Learning models, trained\nand validated using a small dataset in Spanish. The remaining schemes include\nstate-of-the-art Deep Learning models trained (or fine-tuned) and validated in\nEnglish, trained and validated in Spanish, and fitted in English and validated\nwith automatic translated Spanish sentences. The Deep Learning architectures\nwere built on top of different pre-trained Word Embedding representations,\nincluding GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus\nin Spanish). According to the results, the best strategy was a combination of a\npre-trained BETO model and a Recurrent Neural Network based on LSTM layers,\nyielding an accuracy of up to 80%; nonetheless, a baseline model using a Random\nForest estimator obtained similar outcomes. Additionally, the translation\nstrategy did not yield acceptable results because of the propagation error;\nthere was also observed a significant difference in models performance when\ntrained in English or Spanish, mainly attributable to the number of samples\navailable for each language.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper addresses the problem of fake news detection in Spanish using\nMachine Learning techniques. It is fundamentally the same problem tackled for\nthe English language; however, there is not a significant amount of publicly\navailable and adequately labeled fake news in Spanish to effectively train a\nMachine Learning model, similarly to those proposed for the English language.\nTherefore, this work explores different training strategies and architectures\nto establish a baseline for further research in this area. Four datasets were\nused, two in English and two in Spanish, and four experimental schemes were\ntested, including a baseline with classical Machine Learning models, trained\nand validated using a small dataset in Spanish. The remaining schemes include\nstate-of-the-art Deep Learning models trained (or fine-tuned) and validated in\nEnglish, trained and validated in Spanish, and fitted in English and validated\nwith automatic translated Spanish sentences. The Deep Learning architectures\nwere built on top of different pre-trained Word Embedding representations,\nincluding GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus\nin Spanish). According to the results, the best strategy was a combination of a\npre-trained BETO model and a Recurrent Neural Network based on LSTM layers,\nyielding an accuracy of up to 80%; nonetheless, a baseline model using a Random\nForest estimator obtained similar outcomes. Additionally, the translation\nstrategy did not yield acceptable results because of the propagation error;\nthere was also observed a significant difference in models performance when\ntrained in English or Spanish, mainly attributable to the number of samples\navailable for each language.'}, 'authors': [{'name': 'Kevin Martínez-Gallego'}, {'name': 'Andrés M. Álvarez-Ortiz'}, {'name': 'Julián D. Arias-Londoño'}], 'author_detail': {'name': 'Julián D. Arias-Londoño'}, 'author': 'Julián D. Arias-Londoño', 'links': [{'href': 'http://arxiv.org/abs/2110.06461v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.06461v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
3,http://arxiv.org/abs/2110.05369v1,2021-10-11 15:55:11+00:00,2021-10-11 15:55:11+00:00,Explainable Fact-checking through Question Answering,"[arxiv.Result.Author('Jing Yang'), arxiv.Result.Author('Didier Vega-Oliveros'), arxiv.Result.Author('Taís Seibt'), arxiv.Result.Author('Anderson Rocha')]","Misleading or false information has been creating chaos in some places around
the world. To mitigate this issue, many researchers have proposed automated
fact-checking methods to fight the spread of fake news. However, most methods
cannot explain the reasoning behind their decisions, failing to build trust
between machines and humans using such technology. Trust is essential for
fact-checking to be applied in the real world. Here, we address fact-checking
explainability through question answering. In particular, we propose generating
questions and answers from claims and answering the same questions from
evidence. We also propose an answer comparison model with an attention
mechanism attached to each question. Leveraging question answering as a proxy,
we break down automated fact-checking into several steps -- this separation
aids models' explainability as it allows for more detailed analysis of their
decision-making processes. Experimental results show that the proposed model
can achieve state-of-the-art performance while providing reasonable explainable
capabilities.","5 pages, 3 figures, 2 tables. Submitted to the 2022 International
  Conference on Acoustics, Speech, & Signal Processing (ICASSP)",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2110.05369v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.05369v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.05369v1,"{'id': 'http://arxiv.org/abs/2110.05369v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.05369v1', 'updated': '2021-10-11T15:55:11Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=11, tm_hour=15, tm_min=55, tm_sec=11, tm_wday=0, tm_yday=284, tm_isdst=0), 'published': '2021-10-11T15:55:11Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=11, tm_hour=15, tm_min=55, tm_sec=11, tm_wday=0, tm_yday=284, tm_isdst=0), 'title': 'Explainable Fact-checking through Question Answering', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Explainable Fact-checking through Question Answering'}, 'summary': ""Misleading or false information has been creating chaos in some places around\nthe world. To mitigate this issue, many researchers have proposed automated\nfact-checking methods to fight the spread of fake news. However, most methods\ncannot explain the reasoning behind their decisions, failing to build trust\nbetween machines and humans using such technology. Trust is essential for\nfact-checking to be applied in the real world. Here, we address fact-checking\nexplainability through question answering. In particular, we propose generating\nquestions and answers from claims and answering the same questions from\nevidence. We also propose an answer comparison model with an attention\nmechanism attached to each question. Leveraging question answering as a proxy,\nwe break down automated fact-checking into several steps -- this separation\naids models' explainability as it allows for more detailed analysis of their\ndecision-making processes. Experimental results show that the proposed model\ncan achieve state-of-the-art performance while providing reasonable explainable\ncapabilities."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Misleading or false information has been creating chaos in some places around\nthe world. To mitigate this issue, many researchers have proposed automated\nfact-checking methods to fight the spread of fake news. However, most methods\ncannot explain the reasoning behind their decisions, failing to build trust\nbetween machines and humans using such technology. Trust is essential for\nfact-checking to be applied in the real world. Here, we address fact-checking\nexplainability through question answering. In particular, we propose generating\nquestions and answers from claims and answering the same questions from\nevidence. We also propose an answer comparison model with an attention\nmechanism attached to each question. Leveraging question answering as a proxy,\nwe break down automated fact-checking into several steps -- this separation\naids models' explainability as it allows for more detailed analysis of their\ndecision-making processes. Experimental results show that the proposed model\ncan achieve state-of-the-art performance while providing reasonable explainable\ncapabilities.""}, 'authors': [{'name': 'Jing Yang'}, {'name': 'Didier Vega-Oliveros'}, {'name': 'Taís Seibt'}, {'name': 'Anderson Rocha'}], 'author_detail': {'name': 'Anderson Rocha'}, 'author': 'Anderson Rocha', 'arxiv_comment': '5 pages, 3 figures, 2 tables. Submitted to the 2022 International\n  Conference on Acoustics, Speech, & Signal Processing (ICASSP)', 'links': [{'href': 'http://arxiv.org/abs/2110.05369v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.05369v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
4,http://arxiv.org/abs/2110.03432v1,2021-10-05 16:11:08+00:00,2021-10-05 16:11:08+00:00,"Fake news, noise, and tenacious Bayesians",[arxiv.Result.Author('Dorje C. Brody')],"A modelling framework, based on the theory of signal processing, for
characterising the dynamics of systems driven by the unravelling of information
is outlined, and is applied to describe the process of decision makings. The
model input of this approach is the specification of the flow of information.
This enables the representation of (i) reliable information, (ii) noise, and
(iii) disinformation, in a unified framework. Because the approach is designed
to characterise the dynamics of the system under study, it is possible to
quantify the impact of information control, including those resulting from the
dissemination of disinformation. It is shown that if a decision maker assigns
an exceptionally high weight on one of the alternative realities, then under
the Bayesian logic their perception hardly changes in time even if evidences
presented indicate that this alternative corresponds to a false reality. By
observing the role played by noise in other areas of natural sciences, a new
approach to tackle the dark forces of fake news is proposed.","16 pages, 4 figures",,,econ.TH,"['econ.TH', 'econ.GN', 'math.PR', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/2110.03432v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.03432v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.03432v1,"{'id': 'http://arxiv.org/abs/2110.03432v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.03432v1', 'updated': '2021-10-05T16:11:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=5, tm_hour=16, tm_min=11, tm_sec=8, tm_wday=1, tm_yday=278, tm_isdst=0), 'published': '2021-10-05T16:11:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=5, tm_hour=16, tm_min=11, tm_sec=8, tm_wday=1, tm_yday=278, tm_isdst=0), 'title': 'Fake news, noise, and tenacious Bayesians', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news, noise, and tenacious Bayesians'}, 'summary': 'A modelling framework, based on the theory of signal processing, for\ncharacterising the dynamics of systems driven by the unravelling of information\nis outlined, and is applied to describe the process of decision makings. The\nmodel input of this approach is the specification of the flow of information.\nThis enables the representation of (i) reliable information, (ii) noise, and\n(iii) disinformation, in a unified framework. Because the approach is designed\nto characterise the dynamics of the system under study, it is possible to\nquantify the impact of information control, including those resulting from the\ndissemination of disinformation. It is shown that if a decision maker assigns\nan exceptionally high weight on one of the alternative realities, then under\nthe Bayesian logic their perception hardly changes in time even if evidences\npresented indicate that this alternative corresponds to a false reality. By\nobserving the role played by noise in other areas of natural sciences, a new\napproach to tackle the dark forces of fake news is proposed.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A modelling framework, based on the theory of signal processing, for\ncharacterising the dynamics of systems driven by the unravelling of information\nis outlined, and is applied to describe the process of decision makings. The\nmodel input of this approach is the specification of the flow of information.\nThis enables the representation of (i) reliable information, (ii) noise, and\n(iii) disinformation, in a unified framework. Because the approach is designed\nto characterise the dynamics of the system under study, it is possible to\nquantify the impact of information control, including those resulting from the\ndissemination of disinformation. It is shown that if a decision maker assigns\nan exceptionally high weight on one of the alternative realities, then under\nthe Bayesian logic their perception hardly changes in time even if evidences\npresented indicate that this alternative corresponds to a false reality. By\nobserving the role played by noise in other areas of natural sciences, a new\napproach to tackle the dark forces of fake news is proposed.'}, 'authors': [{'name': 'Dorje C. Brody'}], 'author_detail': {'name': 'Dorje C. Brody'}, 'author': 'Dorje C. Brody', 'arxiv_comment': '16 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2110.03432v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.03432v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
5,http://arxiv.org/abs/2110.00230v1,2021-10-01 06:38:19+00:00,2021-10-01 06:38:19+00:00,Users' ability to perceive misinformation: An information quality assessment approach,"[arxiv.Result.Author('Aljaž Zrnec'), arxiv.Result.Author('Marko Poženel'), arxiv.Result.Author('Dejan Lavbič')]","Digital information exchange enables quick creation and sharing of
information and thus changes existing habits. Social media is becoming the main
source of news for end-users replacing traditional media. This also enables the
proliferation of fake news, which misinforms readers and is used to serve the
interests of the creators. As a result, automated fake news detection systems
are attracting attention. However, automatic fake news detection presents a
major challenge; content evaluation is increasingly becoming the responsibility
of the end-user. Thus, in the present study we used information quality (IQ) as
an instrument to investigate how users can detect fake news. Specifically, we
examined how users perceive fake news in the form of shorter paragraphs on
individual IQ dimensions. We also investigated which user characteristics might
affect fake news detection. We performed an empirical study with 1123 users,
who evaluated randomly generated stories with statements of various level of
correctness by individual IQ dimensions. The results reveal that IQ can be used
as a tool for fake news detection. Our findings show that (1) domain knowledge
has a positive impact on fake news detection; (2) education in combination with
domain knowledge improves fake news detection; and (3) personality trait
conscientiousness contributes significantly to fake news detection in all
dimensions.",,Information Processing & Management 59 (2020),10.1016/j.ipm.2021.102739,cs.IT,"['cs.IT', 'math.IT']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.ipm.2021.102739', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2110.00230v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.00230v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.00230v1,"{'id': 'http://arxiv.org/abs/2110.00230v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.00230v1', 'updated': '2021-10-01T06:38:19Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=1, tm_hour=6, tm_min=38, tm_sec=19, tm_wday=4, tm_yday=274, tm_isdst=0), 'published': '2021-10-01T06:38:19Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=1, tm_hour=6, tm_min=38, tm_sec=19, tm_wday=4, tm_yday=274, tm_isdst=0), 'title': ""Users' ability to perceive misinformation: An information quality\n  assessment approach"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Users' ability to perceive misinformation: An information quality\n  assessment approach""}, 'summary': 'Digital information exchange enables quick creation and sharing of\ninformation and thus changes existing habits. Social media is becoming the main\nsource of news for end-users replacing traditional media. This also enables the\nproliferation of fake news, which misinforms readers and is used to serve the\ninterests of the creators. As a result, automated fake news detection systems\nare attracting attention. However, automatic fake news detection presents a\nmajor challenge; content evaluation is increasingly becoming the responsibility\nof the end-user. Thus, in the present study we used information quality (IQ) as\nan instrument to investigate how users can detect fake news. Specifically, we\nexamined how users perceive fake news in the form of shorter paragraphs on\nindividual IQ dimensions. We also investigated which user characteristics might\naffect fake news detection. We performed an empirical study with 1123 users,\nwho evaluated randomly generated stories with statements of various level of\ncorrectness by individual IQ dimensions. The results reveal that IQ can be used\nas a tool for fake news detection. Our findings show that (1) domain knowledge\nhas a positive impact on fake news detection; (2) education in combination with\ndomain knowledge improves fake news detection; and (3) personality trait\nconscientiousness contributes significantly to fake news detection in all\ndimensions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Digital information exchange enables quick creation and sharing of\ninformation and thus changes existing habits. Social media is becoming the main\nsource of news for end-users replacing traditional media. This also enables the\nproliferation of fake news, which misinforms readers and is used to serve the\ninterests of the creators. As a result, automated fake news detection systems\nare attracting attention. However, automatic fake news detection presents a\nmajor challenge; content evaluation is increasingly becoming the responsibility\nof the end-user. Thus, in the present study we used information quality (IQ) as\nan instrument to investigate how users can detect fake news. Specifically, we\nexamined how users perceive fake news in the form of shorter paragraphs on\nindividual IQ dimensions. We also investigated which user characteristics might\naffect fake news detection. We performed an empirical study with 1123 users,\nwho evaluated randomly generated stories with statements of various level of\ncorrectness by individual IQ dimensions. The results reveal that IQ can be used\nas a tool for fake news detection. Our findings show that (1) domain knowledge\nhas a positive impact on fake news detection; (2) education in combination with\ndomain knowledge improves fake news detection; and (3) personality trait\nconscientiousness contributes significantly to fake news detection in all\ndimensions.'}, 'authors': [{'name': 'Aljaž Zrnec'}, {'name': 'Marko Poženel'}, {'name': 'Dejan Lavbič'}], 'author_detail': {'name': 'Dejan Lavbič'}, 'author': 'Dejan Lavbič', 'arxiv_doi': '10.1016/j.ipm.2021.102739', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.ipm.2021.102739', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2110.00230v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.00230v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Information Processing & Management 59 (2020)', 'arxiv_primary_category': {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
6,http://arxiv.org/abs/2109.14816v2,2021-10-01 15:45:54+00:00,2021-09-30 02:50:05+00:00,COVID-19 Fake News Detection Using Bidirectional Encoder Representations from Transformers Based Models,"[arxiv.Result.Author('Yuxiang Wang'), arxiv.Result.Author('Yongheng Zhang'), arxiv.Result.Author('Xuebo Li'), arxiv.Result.Author('Xinyao Yu')]","Nowadays, the development of social media allows people to access the latest
news easily. During the COVID-19 pandemic, it is important for people to access
the news so that they can take corresponding protective measures. However, the
fake news is flooding and is a serious issue especially under the global
pandemic. The misleading fake news can cause significant loss in terms of the
individuals and the society. COVID-19 fake news detection has become a novel
and important task in the NLP field. However, fake news always contain the
correct portion and the incorrect portion. This fact increases the difficulty
of the classification task. In this paper, we fine tune the pre-trained
Bidirectional Encoder Representations from Transformers (BERT) model as our
base model. We add BiLSTM layers and CNN layers on the top of the finetuned
BERT model with frozen parameters or not frozen parameters methods
respectively. The model performance evaluation results showcase that our best
model (BERT finetuned model with frozen parameters plus BiLSTM layers) achieves
state-of-the-art results towards COVID-19 fake news detection task. We also
explore keywords evaluation methods using our best model and evaluate the model
performance after removing keywords.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.14816v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.14816v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.14816v2,"{'id': 'http://arxiv.org/abs/2109.14816v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.14816v2', 'updated': '2021-10-01T15:45:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=1, tm_hour=15, tm_min=45, tm_sec=54, tm_wday=4, tm_yday=274, tm_isdst=0), 'published': '2021-09-30T02:50:05Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=30, tm_hour=2, tm_min=50, tm_sec=5, tm_wday=3, tm_yday=273, tm_isdst=0), 'title': 'COVID-19 Fake News Detection Using Bidirectional Encoder Representations\n  from Transformers Based Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Fake News Detection Using Bidirectional Encoder Representations\n  from Transformers Based Models'}, 'summary': 'Nowadays, the development of social media allows people to access the latest\nnews easily. During the COVID-19 pandemic, it is important for people to access\nthe news so that they can take corresponding protective measures. However, the\nfake news is flooding and is a serious issue especially under the global\npandemic. The misleading fake news can cause significant loss in terms of the\nindividuals and the society. COVID-19 fake news detection has become a novel\nand important task in the NLP field. However, fake news always contain the\ncorrect portion and the incorrect portion. This fact increases the difficulty\nof the classification task. In this paper, we fine tune the pre-trained\nBidirectional Encoder Representations from Transformers (BERT) model as our\nbase model. We add BiLSTM layers and CNN layers on the top of the finetuned\nBERT model with frozen parameters or not frozen parameters methods\nrespectively. The model performance evaluation results showcase that our best\nmodel (BERT finetuned model with frozen parameters plus BiLSTM layers) achieves\nstate-of-the-art results towards COVID-19 fake news detection task. We also\nexplore keywords evaluation methods using our best model and evaluate the model\nperformance after removing keywords.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Nowadays, the development of social media allows people to access the latest\nnews easily. During the COVID-19 pandemic, it is important for people to access\nthe news so that they can take corresponding protective measures. However, the\nfake news is flooding and is a serious issue especially under the global\npandemic. The misleading fake news can cause significant loss in terms of the\nindividuals and the society. COVID-19 fake news detection has become a novel\nand important task in the NLP field. However, fake news always contain the\ncorrect portion and the incorrect portion. This fact increases the difficulty\nof the classification task. In this paper, we fine tune the pre-trained\nBidirectional Encoder Representations from Transformers (BERT) model as our\nbase model. We add BiLSTM layers and CNN layers on the top of the finetuned\nBERT model with frozen parameters or not frozen parameters methods\nrespectively. The model performance evaluation results showcase that our best\nmodel (BERT finetuned model with frozen parameters plus BiLSTM layers) achieves\nstate-of-the-art results towards COVID-19 fake news detection task. We also\nexplore keywords evaluation methods using our best model and evaluate the model\nperformance after removing keywords.'}, 'authors': [{'name': 'Yuxiang Wang'}, {'name': 'Yongheng Zhang'}, {'name': 'Xuebo Li'}, {'name': 'Xinyao Yu'}], 'author_detail': {'name': 'Xinyao Yu'}, 'author': 'Xinyao Yu', 'links': [{'href': 'http://arxiv.org/abs/2109.14816v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.14816v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
7,http://arxiv.org/abs/2109.14087v1,2021-09-28 23:05:46+00:00,2021-09-28 23:05:46+00:00,"Spreading of fake news, competence, and learning: kinetic modeling and numerical approximation","[arxiv.Result.Author('Jonathan Franceschi'), arxiv.Result.Author('Lorenzo Pareschi')]","The rise of social networks as the primary means of communication in almost
every country in the world has simultaneously triggered an increase in the
amount of fake news circulating online. This fact became particularly evident
during the 2016 U.S. political elections and even more so with the advent of
the COVID-19 pandemic. Several research studies have shown how the effects of
fake news dissemination can be mitigated by promoting greater competence
through lifelong learning and discussion communities, and generally rigorous
training in the scientific method and broad interdisciplinary education. The
urgent need for models that can describe the growing infodemic of fake news has
been highlighted by the current pandemic. The resulting slowdown in vaccination
campaigns due to misinformation and generally the inability of individuals to
discern the reliability of information is posing enormous risks to the
governments of many countries. In this research using the tools of kinetic
theory we describe the interaction between fake news spreading and competence
of individuals through multi-population models in which fake news spreads
analogously to an infectious disease with different impact depending on the
level of competence of individuals. The level of competence, in particular, is
subject to an evolutionary dynamic due to both social interactions between
agents and external learning dynamics. The results show how the model is able
to correctly describe the dynamics of diffusion of fake news and the important
role of competence in their containment.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.NA', 'cs.SI', 'math.NA']","[arxiv.Result.Link('http://arxiv.org/abs/2109.14087v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.14087v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.14087v1,"{'id': 'http://arxiv.org/abs/2109.14087v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.14087v1', 'updated': '2021-09-28T23:05:46Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=23, tm_min=5, tm_sec=46, tm_wday=1, tm_yday=271, tm_isdst=0), 'published': '2021-09-28T23:05:46Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=23, tm_min=5, tm_sec=46, tm_wday=1, tm_yday=271, tm_isdst=0), 'title': 'Spreading of fake news, competence, and learning: kinetic modeling and\n  numerical approximation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Spreading of fake news, competence, and learning: kinetic modeling and\n  numerical approximation'}, 'summary': 'The rise of social networks as the primary means of communication in almost\nevery country in the world has simultaneously triggered an increase in the\namount of fake news circulating online. This fact became particularly evident\nduring the 2016 U.S. political elections and even more so with the advent of\nthe COVID-19 pandemic. Several research studies have shown how the effects of\nfake news dissemination can be mitigated by promoting greater competence\nthrough lifelong learning and discussion communities, and generally rigorous\ntraining in the scientific method and broad interdisciplinary education. The\nurgent need for models that can describe the growing infodemic of fake news has\nbeen highlighted by the current pandemic. The resulting slowdown in vaccination\ncampaigns due to misinformation and generally the inability of individuals to\ndiscern the reliability of information is posing enormous risks to the\ngovernments of many countries. In this research using the tools of kinetic\ntheory we describe the interaction between fake news spreading and competence\nof individuals through multi-population models in which fake news spreads\nanalogously to an infectious disease with different impact depending on the\nlevel of competence of individuals. The level of competence, in particular, is\nsubject to an evolutionary dynamic due to both social interactions between\nagents and external learning dynamics. The results show how the model is able\nto correctly describe the dynamics of diffusion of fake news and the important\nrole of competence in their containment.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of social networks as the primary means of communication in almost\nevery country in the world has simultaneously triggered an increase in the\namount of fake news circulating online. This fact became particularly evident\nduring the 2016 U.S. political elections and even more so with the advent of\nthe COVID-19 pandemic. Several research studies have shown how the effects of\nfake news dissemination can be mitigated by promoting greater competence\nthrough lifelong learning and discussion communities, and generally rigorous\ntraining in the scientific method and broad interdisciplinary education. The\nurgent need for models that can describe the growing infodemic of fake news has\nbeen highlighted by the current pandemic. The resulting slowdown in vaccination\ncampaigns due to misinformation and generally the inability of individuals to\ndiscern the reliability of information is posing enormous risks to the\ngovernments of many countries. In this research using the tools of kinetic\ntheory we describe the interaction between fake news spreading and competence\nof individuals through multi-population models in which fake news spreads\nanalogously to an infectious disease with different impact depending on the\nlevel of competence of individuals. The level of competence, in particular, is\nsubject to an evolutionary dynamic due to both social interactions between\nagents and external learning dynamics. The results show how the model is able\nto correctly describe the dynamics of diffusion of fake news and the important\nrole of competence in their containment.'}, 'authors': [{'name': 'Jonathan Franceschi'}, {'name': 'Lorenzo Pareschi'}], 'author_detail': {'name': 'Lorenzo Pareschi'}, 'author': 'Lorenzo Pareschi', 'links': [{'href': 'http://arxiv.org/abs/2109.14087v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.14087v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
8,http://arxiv.org/abs/2109.14045v1,2021-09-28 21:00:03+00:00,2021-09-28 21:00:03+00:00,Habituation Effect in Social Networks as a Potential Factor Silently Crushing Influence Maximisation Efforts,[arxiv.Result.Author('Jaroslaw Jankowski')],"Information spreading processes are a key phenomenon observed within real and
digital social networks. Network members are often under pressure from incoming
information with different sources, such as informative campaigns for
increasing awareness, viral marketing, rumours, fake news, or the results of
other activities. Messages are often repeated, and such repetition can improve
performance in the form of cumulative influence. Repeated messages may also be
ignored due to a limited ability to process information. Learning processes are
leading to the repeated messages being ignored, as their content has already
been absorbed. In such cases, responsiveness decreases with repetition, and the
habituation effect can be observed. Here, we analyse spreading processes while
considering the habituation effect and performance drop along with an increased
number of contacts. The the ability to recover when reducing the number of
messages is also considered. The results show that even low habituation and a
decrease in propagation probability may substantially impact network coverage.
This can lead to a significant reduction in the potential for a seed set
selected with an influence maximisation method. Apart from the impact of the
habituation effect on spreading processes, we show how it can be reduced with
the use of the sequential seeding approach. This shows that sequential seeding
is less sensitive to the habituation effect than single-stage seeding, and that
it can be used to limit the negative impact on users overloaded with incoming
messages.",,"Scientific Reports, 11(1), 1-12 (2021)",10.1038/s41598-021-98493-9,cs.SI,"['cs.SI', '91D30', 'J.4']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41598-021-98493-9', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.14045v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.14045v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.14045v1,"{'id': 'http://arxiv.org/abs/2109.14045v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.14045v1', 'updated': '2021-09-28T21:00:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=21, tm_min=0, tm_sec=3, tm_wday=1, tm_yday=271, tm_isdst=0), 'published': '2021-09-28T21:00:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=21, tm_min=0, tm_sec=3, tm_wday=1, tm_yday=271, tm_isdst=0), 'title': 'Habituation Effect in Social Networks as a Potential Factor Silently\n  Crushing Influence Maximisation Efforts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Habituation Effect in Social Networks as a Potential Factor Silently\n  Crushing Influence Maximisation Efforts'}, 'summary': 'Information spreading processes are a key phenomenon observed within real and\ndigital social networks. Network members are often under pressure from incoming\ninformation with different sources, such as informative campaigns for\nincreasing awareness, viral marketing, rumours, fake news, or the results of\nother activities. Messages are often repeated, and such repetition can improve\nperformance in the form of cumulative influence. Repeated messages may also be\nignored due to a limited ability to process information. Learning processes are\nleading to the repeated messages being ignored, as their content has already\nbeen absorbed. In such cases, responsiveness decreases with repetition, and the\nhabituation effect can be observed. Here, we analyse spreading processes while\nconsidering the habituation effect and performance drop along with an increased\nnumber of contacts. The the ability to recover when reducing the number of\nmessages is also considered. The results show that even low habituation and a\ndecrease in propagation probability may substantially impact network coverage.\nThis can lead to a significant reduction in the potential for a seed set\nselected with an influence maximisation method. Apart from the impact of the\nhabituation effect on spreading processes, we show how it can be reduced with\nthe use of the sequential seeding approach. This shows that sequential seeding\nis less sensitive to the habituation effect than single-stage seeding, and that\nit can be used to limit the negative impact on users overloaded with incoming\nmessages.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information spreading processes are a key phenomenon observed within real and\ndigital social networks. Network members are often under pressure from incoming\ninformation with different sources, such as informative campaigns for\nincreasing awareness, viral marketing, rumours, fake news, or the results of\nother activities. Messages are often repeated, and such repetition can improve\nperformance in the form of cumulative influence. Repeated messages may also be\nignored due to a limited ability to process information. Learning processes are\nleading to the repeated messages being ignored, as their content has already\nbeen absorbed. In such cases, responsiveness decreases with repetition, and the\nhabituation effect can be observed. Here, we analyse spreading processes while\nconsidering the habituation effect and performance drop along with an increased\nnumber of contacts. The the ability to recover when reducing the number of\nmessages is also considered. The results show that even low habituation and a\ndecrease in propagation probability may substantially impact network coverage.\nThis can lead to a significant reduction in the potential for a seed set\nselected with an influence maximisation method. Apart from the impact of the\nhabituation effect on spreading processes, we show how it can be reduced with\nthe use of the sequential seeding approach. This shows that sequential seeding\nis less sensitive to the habituation effect than single-stage seeding, and that\nit can be used to limit the negative impact on users overloaded with incoming\nmessages.'}, 'authors': [{'name': 'Jaroslaw Jankowski'}], 'author_detail': {'name': 'Jaroslaw Jankowski'}, 'author': 'Jaroslaw Jankowski', 'arxiv_doi': '10.1038/s41598-021-98493-9', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41598-021-98493-9', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.14045v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.14045v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Scientific Reports, 11(1), 1-12 (2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '91D30', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
9,http://arxiv.org/abs/2109.13476v1,2021-09-28 04:21:07+00:00,2021-09-28 04:21:07+00:00,Fake News Detection using Semi-Supervised Graph Convolutional Network,"[arxiv.Result.Author('Priyanka Meel'), arxiv.Result.Author('Dinesh Kumar Vishwakarma')]","Social media becomes the central way for people to obtain and utilise news,
due to its rapidness and inexpensive value of data distribution. Though, such
features of social media platforms also present it a root cause of fake news
distribution, causing adverse consequences on both people and culture. Hence,
detecting fake news has become a significant research interest for bringing
feasible real time solutions to the problem. Most current techniques of fake
news disclosure are supervised, that need large cost in terms of time and
effort to make a certainly interpreted dataset. The proposed framework
concentrates on the text-based detection of fake news items while considering
that only limited number of labels are available. Graphs are functioned
extensively under several purposes of real-world problems on the strength of
their property to structure things easily. Deep neural networks are used to
generate great results within tasks that utilizes graph classification. The
Graph Convolution Network works as a deep learning paradigm which works on
graphs. Our proposed framework deals with limited amount of labelled data; we
go for a semi-supervised learning method. We come up with a semi-supervised
fake news detection technique based on GCN (Graph Convolutional Networks). The
recommended architecture comprises of three basic components: collecting word
embeddings from the news articles in datasets utilising GloVe, building
similarity graph using Word Movers Distance (WMD) and finally applying Graph
Convolution Network (GCN) for binary classification of news articles in
semi-supervised paradigm. The implemented technique is validated on three
different datasets by varying the volume of labelled data achieving 95.27 %
highest accuracy on Real or Fake dataset. Comparison with other contemporary
techniques also reinforced the supremacy of the proposed framework.","25 pages, 7 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.13476v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.13476v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.13476v1,"{'id': 'http://arxiv.org/abs/2109.13476v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.13476v1', 'updated': '2021-09-28T04:21:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=4, tm_min=21, tm_sec=7, tm_wday=1, tm_yday=271, tm_isdst=0), 'published': '2021-09-28T04:21:07Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=4, tm_min=21, tm_sec=7, tm_wday=1, tm_yday=271, tm_isdst=0), 'title': 'Fake News Detection using Semi-Supervised Graph Convolutional Network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection using Semi-Supervised Graph Convolutional Network'}, 'summary': 'Social media becomes the central way for people to obtain and utilise news,\ndue to its rapidness and inexpensive value of data distribution. Though, such\nfeatures of social media platforms also present it a root cause of fake news\ndistribution, causing adverse consequences on both people and culture. Hence,\ndetecting fake news has become a significant research interest for bringing\nfeasible real time solutions to the problem. Most current techniques of fake\nnews disclosure are supervised, that need large cost in terms of time and\neffort to make a certainly interpreted dataset. The proposed framework\nconcentrates on the text-based detection of fake news items while considering\nthat only limited number of labels are available. Graphs are functioned\nextensively under several purposes of real-world problems on the strength of\ntheir property to structure things easily. Deep neural networks are used to\ngenerate great results within tasks that utilizes graph classification. The\nGraph Convolution Network works as a deep learning paradigm which works on\ngraphs. Our proposed framework deals with limited amount of labelled data; we\ngo for a semi-supervised learning method. We come up with a semi-supervised\nfake news detection technique based on GCN (Graph Convolutional Networks). The\nrecommended architecture comprises of three basic components: collecting word\nembeddings from the news articles in datasets utilising GloVe, building\nsimilarity graph using Word Movers Distance (WMD) and finally applying Graph\nConvolution Network (GCN) for binary classification of news articles in\nsemi-supervised paradigm. The implemented technique is validated on three\ndifferent datasets by varying the volume of labelled data achieving 95.27 %\nhighest accuracy on Real or Fake dataset. Comparison with other contemporary\ntechniques also reinforced the supremacy of the proposed framework.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media becomes the central way for people to obtain and utilise news,\ndue to its rapidness and inexpensive value of data distribution. Though, such\nfeatures of social media platforms also present it a root cause of fake news\ndistribution, causing adverse consequences on both people and culture. Hence,\ndetecting fake news has become a significant research interest for bringing\nfeasible real time solutions to the problem. Most current techniques of fake\nnews disclosure are supervised, that need large cost in terms of time and\neffort to make a certainly interpreted dataset. The proposed framework\nconcentrates on the text-based detection of fake news items while considering\nthat only limited number of labels are available. Graphs are functioned\nextensively under several purposes of real-world problems on the strength of\ntheir property to structure things easily. Deep neural networks are used to\ngenerate great results within tasks that utilizes graph classification. The\nGraph Convolution Network works as a deep learning paradigm which works on\ngraphs. Our proposed framework deals with limited amount of labelled data; we\ngo for a semi-supervised learning method. We come up with a semi-supervised\nfake news detection technique based on GCN (Graph Convolutional Networks). The\nrecommended architecture comprises of three basic components: collecting word\nembeddings from the news articles in datasets utilising GloVe, building\nsimilarity graph using Word Movers Distance (WMD) and finally applying Graph\nConvolution Network (GCN) for binary classification of news articles in\nsemi-supervised paradigm. The implemented technique is validated on three\ndifferent datasets by varying the volume of labelled data achieving 95.27 %\nhighest accuracy on Real or Fake dataset. Comparison with other contemporary\ntechniques also reinforced the supremacy of the proposed framework.'}, 'authors': [{'name': 'Priyanka Meel'}, {'name': 'Dinesh Kumar Vishwakarma'}], 'author_detail': {'name': 'Dinesh Kumar Vishwakarma'}, 'author': 'Dinesh Kumar Vishwakarma', 'arxiv_comment': '25 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/2109.13476v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.13476v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
10,http://arxiv.org/abs/2109.13296v1,2021-09-27 18:35:33+00:00,2021-09-27 18:35:33+00:00,TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation,"[arxiv.Result.Author('Adaku Uchendu'), arxiv.Result.Author('Zeyu Ma'), arxiv.Result.Author('Thai Le'), arxiv.Result.Author('Rui Zhang'), arxiv.Result.Author('Dongwon Lee')]","Recent progress in generative language models has enabled machines to
generate astonishingly realistic texts. While there are many legitimate
applications of such models, there is also a rising need to distinguish
machine-generated texts from human-written ones (e.g., fake news detection).
However, to our best knowledge, there is currently no benchmark environment
with datasets and tasks to systematically study the so-called ""Turing Test""
problem for neural text generation methods. In this work, we present the
TuringBench benchmark environment, which is comprised of (1) a dataset with
200K human- or machine-generated samples across 20 labels {Human, GPT-1,
GPT-2_small, GPT-2_medium, GPT-2_large, GPT-2_xl, GPT-2_PyTorch, GPT-3,
GROVER_base, GROVER_large, GROVER_mega, CTRL, XLM, XLNET_base, XLNET_large,
FAIR_wmt19, FAIR_wmt20, TRANSFORMER_XL, PPLM_distil, PPLM_gpt2}, (2) two
benchmark tasks -- i.e., Turing Test (TT) and Authorship Attribution (AA), and
(3) a website with leaderboards. Our preliminary experimental results using
TuringBench show that FAIR_wmt20 and GPT-3 are the current winners, among all
language models tested, in generating the most human-like indistinguishable
texts with the lowest F1 score by five state-of-the-art TT detection models.
The TuringBench is available at: https://turingbench.ist.psu.edu/",Accepted to Findings of EMNLP 2021,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.13296v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.13296v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.13296v1,"{'id': 'http://arxiv.org/abs/2109.13296v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.13296v1', 'updated': '2021-09-27T18:35:33Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=18, tm_min=35, tm_sec=33, tm_wday=0, tm_yday=270, tm_isdst=0), 'published': '2021-09-27T18:35:33Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=18, tm_min=35, tm_sec=33, tm_wday=0, tm_yday=270, tm_isdst=0), 'title': 'TURINGBENCH: A Benchmark Environment for Turing Test in the Age of\n  Neural Text Generation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TURINGBENCH: A Benchmark Environment for Turing Test in the Age of\n  Neural Text Generation'}, 'summary': 'Recent progress in generative language models has enabled machines to\ngenerate astonishingly realistic texts. While there are many legitimate\napplications of such models, there is also a rising need to distinguish\nmachine-generated texts from human-written ones (e.g., fake news detection).\nHowever, to our best knowledge, there is currently no benchmark environment\nwith datasets and tasks to systematically study the so-called ""Turing Test""\nproblem for neural text generation methods. In this work, we present the\nTuringBench benchmark environment, which is comprised of (1) a dataset with\n200K human- or machine-generated samples across 20 labels {Human, GPT-1,\nGPT-2_small, GPT-2_medium, GPT-2_large, GPT-2_xl, GPT-2_PyTorch, GPT-3,\nGROVER_base, GROVER_large, GROVER_mega, CTRL, XLM, XLNET_base, XLNET_large,\nFAIR_wmt19, FAIR_wmt20, TRANSFORMER_XL, PPLM_distil, PPLM_gpt2}, (2) two\nbenchmark tasks -- i.e., Turing Test (TT) and Authorship Attribution (AA), and\n(3) a website with leaderboards. Our preliminary experimental results using\nTuringBench show that FAIR_wmt20 and GPT-3 are the current winners, among all\nlanguage models tested, in generating the most human-like indistinguishable\ntexts with the lowest F1 score by five state-of-the-art TT detection models.\nThe TuringBench is available at: https://turingbench.ist.psu.edu/', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent progress in generative language models has enabled machines to\ngenerate astonishingly realistic texts. While there are many legitimate\napplications of such models, there is also a rising need to distinguish\nmachine-generated texts from human-written ones (e.g., fake news detection).\nHowever, to our best knowledge, there is currently no benchmark environment\nwith datasets and tasks to systematically study the so-called ""Turing Test""\nproblem for neural text generation methods. In this work, we present the\nTuringBench benchmark environment, which is comprised of (1) a dataset with\n200K human- or machine-generated samples across 20 labels {Human, GPT-1,\nGPT-2_small, GPT-2_medium, GPT-2_large, GPT-2_xl, GPT-2_PyTorch, GPT-3,\nGROVER_base, GROVER_large, GROVER_mega, CTRL, XLM, XLNET_base, XLNET_large,\nFAIR_wmt19, FAIR_wmt20, TRANSFORMER_XL, PPLM_distil, PPLM_gpt2}, (2) two\nbenchmark tasks -- i.e., Turing Test (TT) and Authorship Attribution (AA), and\n(3) a website with leaderboards. Our preliminary experimental results using\nTuringBench show that FAIR_wmt20 and GPT-3 are the current winners, among all\nlanguage models tested, in generating the most human-like indistinguishable\ntexts with the lowest F1 score by five state-of-the-art TT detection models.\nThe TuringBench is available at: https://turingbench.ist.psu.edu/'}, 'authors': [{'name': 'Adaku Uchendu'}, {'name': 'Zeyu Ma'}, {'name': 'Thai Le'}, {'name': 'Rui Zhang'}, {'name': 'Dongwon Lee'}], 'author_detail': {'name': 'Dongwon Lee'}, 'author': 'Dongwon Lee', 'arxiv_comment': 'Accepted to Findings of EMNLP 2021', 'links': [{'href': 'http://arxiv.org/abs/2109.13296v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.13296v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
11,http://arxiv.org/abs/2109.12914v1,2021-09-27 10:00:44+00:00,2021-09-27 10:00:44+00:00,Fake News Detection: Experiments and Approaches beyond Linguistic Features,"[arxiv.Result.Author('Shaily Bhatt'), arxiv.Result.Author('Sakshi Kalra'), arxiv.Result.Author('Naman Goenka'), arxiv.Result.Author('Yashvardhan Sharma')]","Easier access to the internet and social media has made disseminating
information through online sources very easy. Sources like Facebook, Twitter,
online news sites and personal blogs of self-proclaimed journalists have become
significant players in providing news content. The sheer amount of information
and the speed at which it is generated online makes it practically beyond the
scope of human verification. There is, hence, a pressing need to develop
technologies that can assist humans with automatic fact-checking and reliable
identification of fake news. This paper summarizes the multiple approaches that
were undertaken and the experiments that were carried out for the task.
Credibility information and metadata associated with the news article have been
used for improved results. The experiments also show how modelling
justification or evidence can lead to improved results. Additionally, the use
of visual features in addition to linguistic features is demonstrated. A
detailed comparison of the results showing that our models perform
significantly well when compared to robust baselines as well as
state-of-the-art models are presented.",,,10.1007/978-981-16-2937-2_9,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/978-981-16-2937-2_9', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.12914v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12914v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12914v1,"{'id': 'http://arxiv.org/abs/2109.12914v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12914v1', 'updated': '2021-09-27T10:00:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=10, tm_min=0, tm_sec=44, tm_wday=0, tm_yday=270, tm_isdst=0), 'published': '2021-09-27T10:00:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=10, tm_min=0, tm_sec=44, tm_wday=0, tm_yday=270, tm_isdst=0), 'title': 'Fake News Detection: Experiments and Approaches beyond Linguistic\n  Features', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection: Experiments and Approaches beyond Linguistic\n  Features'}, 'summary': 'Easier access to the internet and social media has made disseminating\ninformation through online sources very easy. Sources like Facebook, Twitter,\nonline news sites and personal blogs of self-proclaimed journalists have become\nsignificant players in providing news content. The sheer amount of information\nand the speed at which it is generated online makes it practically beyond the\nscope of human verification. There is, hence, a pressing need to develop\ntechnologies that can assist humans with automatic fact-checking and reliable\nidentification of fake news. This paper summarizes the multiple approaches that\nwere undertaken and the experiments that were carried out for the task.\nCredibility information and metadata associated with the news article have been\nused for improved results. The experiments also show how modelling\njustification or evidence can lead to improved results. Additionally, the use\nof visual features in addition to linguistic features is demonstrated. A\ndetailed comparison of the results showing that our models perform\nsignificantly well when compared to robust baselines as well as\nstate-of-the-art models are presented.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Easier access to the internet and social media has made disseminating\ninformation through online sources very easy. Sources like Facebook, Twitter,\nonline news sites and personal blogs of self-proclaimed journalists have become\nsignificant players in providing news content. The sheer amount of information\nand the speed at which it is generated online makes it practically beyond the\nscope of human verification. There is, hence, a pressing need to develop\ntechnologies that can assist humans with automatic fact-checking and reliable\nidentification of fake news. This paper summarizes the multiple approaches that\nwere undertaken and the experiments that were carried out for the task.\nCredibility information and metadata associated with the news article have been\nused for improved results. The experiments also show how modelling\njustification or evidence can lead to improved results. Additionally, the use\nof visual features in addition to linguistic features is demonstrated. A\ndetailed comparison of the results showing that our models perform\nsignificantly well when compared to robust baselines as well as\nstate-of-the-art models are presented.'}, 'authors': [{'name': 'Shaily Bhatt'}, {'name': 'Sakshi Kalra'}, {'name': 'Naman Goenka'}, {'name': 'Yashvardhan Sharma'}], 'author_detail': {'name': 'Yashvardhan Sharma'}, 'author': 'Yashvardhan Sharma', 'arxiv_doi': '10.1007/978-981-16-2937-2_9', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-981-16-2937-2_9', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.12914v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12914v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
12,http://arxiv.org/abs/2109.12547v1,2021-09-26 09:52:48+00:00,2021-09-26 09:52:48+00:00,Multi-modal Fusion using Fine-tuned Self-attention and Transfer Learning for Veracity Analysis of Web Information,"[arxiv.Result.Author('Priyanka Meel'), arxiv.Result.Author('Dinesh Kumar Vishwakarma')]","The nuisance of misinformation and fake news has escalated many folds since
the advent of online social networks. Human consciousness and decision-making
capabilities are negatively influenced by manipulated, fabricated, biased or
unverified news posts. Therefore, there is a high demand for designing veracity
analysis systems to detect fake information contents in multiple data
modalities. In an attempt to find a sophisticated solution to this critical
issue, we proposed an architecture to consider both the textual and visual
attributes of the data. After the data pre-processing is done, text and image
features are extracted from the training data using separate deep learning
models. Feature extraction from text is done using BERT and ALBERT language
models that leverage the benefits of bidirectional training of transformers
using a deep self-attention mechanism. The Inception-ResNet-v2 deep neural
network model is employed for image data to perform the task. The proposed
framework focused on two independent multi-modal fusion architectures of BERT
and Inception-ResNet-v2 as well as ALBERT and Inception-ResNet-v2. Multi-modal
fusion of textual and visual branches is extensively experimented and analysed
using concatenation of feature vectors and weighted averaging of probabilities
named as Early Fusion and Late Fusion respectively. Three publicly available
broadly accepted datasets All Data, Weibo and MediaEval 2016 that incorporates
English news articles, Chinese news articles, and Tweets correspondingly are
used so that our designed framework's outcomes can be properly tested and
compared with previous notable work in the domain.","31 pages, 12 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.12547v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12547v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12547v1,"{'id': 'http://arxiv.org/abs/2109.12547v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12547v1', 'updated': '2021-09-26T09:52:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=9, tm_min=52, tm_sec=48, tm_wday=6, tm_yday=269, tm_isdst=0), 'published': '2021-09-26T09:52:48Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=9, tm_min=52, tm_sec=48, tm_wday=6, tm_yday=269, tm_isdst=0), 'title': 'Multi-modal Fusion using Fine-tuned Self-attention and Transfer Learning\n  for Veracity Analysis of Web Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multi-modal Fusion using Fine-tuned Self-attention and Transfer Learning\n  for Veracity Analysis of Web Information'}, 'summary': ""The nuisance of misinformation and fake news has escalated many folds since\nthe advent of online social networks. Human consciousness and decision-making\ncapabilities are negatively influenced by manipulated, fabricated, biased or\nunverified news posts. Therefore, there is a high demand for designing veracity\nanalysis systems to detect fake information contents in multiple data\nmodalities. In an attempt to find a sophisticated solution to this critical\nissue, we proposed an architecture to consider both the textual and visual\nattributes of the data. After the data pre-processing is done, text and image\nfeatures are extracted from the training data using separate deep learning\nmodels. Feature extraction from text is done using BERT and ALBERT language\nmodels that leverage the benefits of bidirectional training of transformers\nusing a deep self-attention mechanism. The Inception-ResNet-v2 deep neural\nnetwork model is employed for image data to perform the task. The proposed\nframework focused on two independent multi-modal fusion architectures of BERT\nand Inception-ResNet-v2 as well as ALBERT and Inception-ResNet-v2. Multi-modal\nfusion of textual and visual branches is extensively experimented and analysed\nusing concatenation of feature vectors and weighted averaging of probabilities\nnamed as Early Fusion and Late Fusion respectively. Three publicly available\nbroadly accepted datasets All Data, Weibo and MediaEval 2016 that incorporates\nEnglish news articles, Chinese news articles, and Tweets correspondingly are\nused so that our designed framework's outcomes can be properly tested and\ncompared with previous notable work in the domain."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The nuisance of misinformation and fake news has escalated many folds since\nthe advent of online social networks. Human consciousness and decision-making\ncapabilities are negatively influenced by manipulated, fabricated, biased or\nunverified news posts. Therefore, there is a high demand for designing veracity\nanalysis systems to detect fake information contents in multiple data\nmodalities. In an attempt to find a sophisticated solution to this critical\nissue, we proposed an architecture to consider both the textual and visual\nattributes of the data. After the data pre-processing is done, text and image\nfeatures are extracted from the training data using separate deep learning\nmodels. Feature extraction from text is done using BERT and ALBERT language\nmodels that leverage the benefits of bidirectional training of transformers\nusing a deep self-attention mechanism. The Inception-ResNet-v2 deep neural\nnetwork model is employed for image data to perform the task. The proposed\nframework focused on two independent multi-modal fusion architectures of BERT\nand Inception-ResNet-v2 as well as ALBERT and Inception-ResNet-v2. Multi-modal\nfusion of textual and visual branches is extensively experimented and analysed\nusing concatenation of feature vectors and weighted averaging of probabilities\nnamed as Early Fusion and Late Fusion respectively. Three publicly available\nbroadly accepted datasets All Data, Weibo and MediaEval 2016 that incorporates\nEnglish news articles, Chinese news articles, and Tweets correspondingly are\nused so that our designed framework's outcomes can be properly tested and\ncompared with previous notable work in the domain.""}, 'authors': [{'name': 'Priyanka Meel'}, {'name': 'Dinesh Kumar Vishwakarma'}], 'author_detail': {'name': 'Dinesh Kumar Vishwakarma'}, 'author': 'Dinesh Kumar Vishwakarma', 'arxiv_comment': '31 pages, 12 figures', 'links': [{'href': 'http://arxiv.org/abs/2109.12547v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12547v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
13,http://arxiv.org/abs/2109.12523v1,2021-09-26 08:11:17+00:00,2021-09-26 08:11:17+00:00,A Study of Fake News Reading and Annotating in Social Media Context,"[arxiv.Result.Author('Jakub Simko'), arxiv.Result.Author('Patrik Racsko'), arxiv.Result.Author('Matus Tomlein'), arxiv.Result.Author('Martin Hanakova'), arxiv.Result.Author('Maria Bielikova')]","The online spreading of fake news is a major issue threatening entire
societies. Much of this spreading is enabled by new media formats, namely
social networks and online media sites. Researchers and practitioners have been
trying to answer this by characterizing the fake news and devising automated
methods for detecting them. The detection methods had so far only limited
success, mostly due to the complexity of the news content and context and lack
of properly annotated datasets. One possible way to boost the efficiency of
automated misinformation detection methods, is to imitate the detection work of
humans. It is also important to understand the news consumption behavior of
online users. In this paper, we present an eye-tracking study, in which we let
44 lay participants to casually read through a social media feed containing
posts with news articles, some of which were fake. In a second run, we asked
the participants to decide on the truthfulness of these articles. We also
describe a follow-up qualitative study with a similar scenario but this time
with 7 expert fake news annotators. We present the description of both studies,
characteristics of the resulting dataset (which we hereby publish) and several
findings.",,New Review of Hypermedia and Multimedia. pages 1-31 (2021),10.1080/13614568.2021.1889691,cs.HC,"['cs.HC', 'cs.CY', 'cs.LG', 'cs.SI', 'H.5.2; H.5.4; K.4.2; H.3.1']","[arxiv.Result.Link('http://dx.doi.org/10.1080/13614568.2021.1889691', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.12523v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12523v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12523v1,"{'id': 'http://arxiv.org/abs/2109.12523v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12523v1', 'updated': '2021-09-26T08:11:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=8, tm_min=11, tm_sec=17, tm_wday=6, tm_yday=269, tm_isdst=0), 'published': '2021-09-26T08:11:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=8, tm_min=11, tm_sec=17, tm_wday=6, tm_yday=269, tm_isdst=0), 'title': 'A Study of Fake News Reading and Annotating in Social Media Context', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Study of Fake News Reading and Annotating in Social Media Context'}, 'summary': 'The online spreading of fake news is a major issue threatening entire\nsocieties. Much of this spreading is enabled by new media formats, namely\nsocial networks and online media sites. Researchers and practitioners have been\ntrying to answer this by characterizing the fake news and devising automated\nmethods for detecting them. The detection methods had so far only limited\nsuccess, mostly due to the complexity of the news content and context and lack\nof properly annotated datasets. One possible way to boost the efficiency of\nautomated misinformation detection methods, is to imitate the detection work of\nhumans. It is also important to understand the news consumption behavior of\nonline users. In this paper, we present an eye-tracking study, in which we let\n44 lay participants to casually read through a social media feed containing\nposts with news articles, some of which were fake. In a second run, we asked\nthe participants to decide on the truthfulness of these articles. We also\ndescribe a follow-up qualitative study with a similar scenario but this time\nwith 7 expert fake news annotators. We present the description of both studies,\ncharacteristics of the resulting dataset (which we hereby publish) and several\nfindings.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The online spreading of fake news is a major issue threatening entire\nsocieties. Much of this spreading is enabled by new media formats, namely\nsocial networks and online media sites. Researchers and practitioners have been\ntrying to answer this by characterizing the fake news and devising automated\nmethods for detecting them. The detection methods had so far only limited\nsuccess, mostly due to the complexity of the news content and context and lack\nof properly annotated datasets. One possible way to boost the efficiency of\nautomated misinformation detection methods, is to imitate the detection work of\nhumans. It is also important to understand the news consumption behavior of\nonline users. In this paper, we present an eye-tracking study, in which we let\n44 lay participants to casually read through a social media feed containing\nposts with news articles, some of which were fake. In a second run, we asked\nthe participants to decide on the truthfulness of these articles. We also\ndescribe a follow-up qualitative study with a similar scenario but this time\nwith 7 expert fake news annotators. We present the description of both studies,\ncharacteristics of the resulting dataset (which we hereby publish) and several\nfindings.'}, 'authors': [{'name': 'Jakub Simko'}, {'name': 'Patrik Racsko'}, {'name': 'Matus Tomlein'}, {'name': 'Martin Hanakova'}, {'name': 'Maria Bielikova'}], 'author_detail': {'name': 'Maria Bielikova'}, 'author': 'Maria Bielikova', 'arxiv_doi': '10.1080/13614568.2021.1889691', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1080/13614568.2021.1889691', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.12523v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12523v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'New Review of Hypermedia and Multimedia. pages 1-31 (2021)', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.2; H.5.4; K.4.2; H.3.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
14,http://arxiv.org/abs/2109.11333v1,2021-09-23 12:28:55+00:00,2021-09-23 12:28:55+00:00,Integrating Pattern- and Fact-based Fake News Detection via Model Preference Learning,"[arxiv.Result.Author('Qiang Sheng'), arxiv.Result.Author('Xueyao Zhang'), arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('Lei Zhong')]","To defend against fake news, researchers have developed various methods based
on texts. These methods can be grouped as 1) pattern-based methods, which focus
on shared patterns among fake news posts rather than the claim itself; and 2)
fact-based methods, which retrieve from external sources to verify the claim's
veracity without considering patterns. The two groups of methods, which have
different preferences of textual clues, actually play complementary roles in
detecting fake news. However, few works consider their integration. In this
paper, we study the problem of integrating pattern- and fact-based models into
one framework via modeling their preference differences, i.e., making the
pattern- and fact-based models focus on respective preferred parts in a post
and mitigate interference from non-preferred parts as possible. To this end, we
build a Preference-aware Fake News Detection Framework (Pref-FEND), which
learns the respective preferences of pattern- and fact-based models for joint
detection. We first design a heterogeneous dynamic graph convolutional network
to generate the respective preference maps, and then use these maps to guide
the joint learning of pattern- and fact-based models for final prediction.
Experiments on two real-world datasets show that Pref-FEND effectively captures
model preferences and improves the performance of models based on patterns,
facts, or both.",ACM CIKM 2021 Full Paper,,10.1145/3459637.3482440,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3459637.3482440', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.11333v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.11333v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.11333v1,"{'id': 'http://arxiv.org/abs/2109.11333v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.11333v1', 'updated': '2021-09-23T12:28:55Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=23, tm_hour=12, tm_min=28, tm_sec=55, tm_wday=3, tm_yday=266, tm_isdst=0), 'published': '2021-09-23T12:28:55Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=23, tm_hour=12, tm_min=28, tm_sec=55, tm_wday=3, tm_yday=266, tm_isdst=0), 'title': 'Integrating Pattern- and Fact-based Fake News Detection via Model\n  Preference Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Integrating Pattern- and Fact-based Fake News Detection via Model\n  Preference Learning'}, 'summary': ""To defend against fake news, researchers have developed various methods based\non texts. These methods can be grouped as 1) pattern-based methods, which focus\non shared patterns among fake news posts rather than the claim itself; and 2)\nfact-based methods, which retrieve from external sources to verify the claim's\nveracity without considering patterns. The two groups of methods, which have\ndifferent preferences of textual clues, actually play complementary roles in\ndetecting fake news. However, few works consider their integration. In this\npaper, we study the problem of integrating pattern- and fact-based models into\none framework via modeling their preference differences, i.e., making the\npattern- and fact-based models focus on respective preferred parts in a post\nand mitigate interference from non-preferred parts as possible. To this end, we\nbuild a Preference-aware Fake News Detection Framework (Pref-FEND), which\nlearns the respective preferences of pattern- and fact-based models for joint\ndetection. We first design a heterogeneous dynamic graph convolutional network\nto generate the respective preference maps, and then use these maps to guide\nthe joint learning of pattern- and fact-based models for final prediction.\nExperiments on two real-world datasets show that Pref-FEND effectively captures\nmodel preferences and improves the performance of models based on patterns,\nfacts, or both."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""To defend against fake news, researchers have developed various methods based\non texts. These methods can be grouped as 1) pattern-based methods, which focus\non shared patterns among fake news posts rather than the claim itself; and 2)\nfact-based methods, which retrieve from external sources to verify the claim's\nveracity without considering patterns. The two groups of methods, which have\ndifferent preferences of textual clues, actually play complementary roles in\ndetecting fake news. However, few works consider their integration. In this\npaper, we study the problem of integrating pattern- and fact-based models into\none framework via modeling their preference differences, i.e., making the\npattern- and fact-based models focus on respective preferred parts in a post\nand mitigate interference from non-preferred parts as possible. To this end, we\nbuild a Preference-aware Fake News Detection Framework (Pref-FEND), which\nlearns the respective preferences of pattern- and fact-based models for joint\ndetection. We first design a heterogeneous dynamic graph convolutional network\nto generate the respective preference maps, and then use these maps to guide\nthe joint learning of pattern- and fact-based models for final prediction.\nExperiments on two real-world datasets show that Pref-FEND effectively captures\nmodel preferences and improves the performance of models based on patterns,\nfacts, or both.""}, 'authors': [{'name': 'Qiang Sheng'}, {'name': 'Xueyao Zhang'}, {'name': 'Juan Cao'}, {'name': 'Lei Zhong'}], 'author_detail': {'name': 'Lei Zhong'}, 'author': 'Lei Zhong', 'arxiv_doi': '10.1145/3459637.3482440', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3459637.3482440', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.11333v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.11333v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'ACM CIKM 2021 Full Paper', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
15,http://arxiv.org/abs/2109.11372v1,2021-09-22 14:26:08+00:00,2021-09-22 14:26:08+00:00,A Second Pandemic? Analysis of Fake News About COVID-19 Vaccines in Qatar,"[arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Yifan Zhang')]","While COVID-19 vaccines are finally becoming widely available, a second
pandemic that revolves around the circulation of anti-vaxxer fake news may
hinder efforts to recover from the first one. With this in mind, we performed
an extensive analysis of Arabic and English tweets about COVID-19 vaccines,
with focus on messages originating from Qatar. We found that Arabic tweets
contain a lot of false information and rumors, while English tweets are mostly
factual. However, English tweets are much more propagandistic than Arabic ones.
In terms of propaganda techniques, about half of the Arabic tweets express
doubt, and 1/5 use loaded language, while English tweets are abundant in loaded
language, exaggeration, fear, name-calling, doubt, and flag-waving. Finally, in
terms of framing, Arabic tweets adopt a health and safety perspective, while in
English economic concerns dominate.","COVID-19, disinformation, misinformation, factuality, fact-checking,
  fact-checkers, check-worthiness, framing, harmfulness, social media
  platforms, social media",RANLP-2021,,cs.CL,"['cs.CL', 'cs.SI', '68T50', 'F.2.2; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2109.11372v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.11372v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.11372v1,"{'id': 'http://arxiv.org/abs/2109.11372v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.11372v1', 'updated': '2021-09-22T14:26:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=14, tm_min=26, tm_sec=8, tm_wday=2, tm_yday=265, tm_isdst=0), 'published': '2021-09-22T14:26:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=14, tm_min=26, tm_sec=8, tm_wday=2, tm_yday=265, tm_isdst=0), 'title': 'A Second Pandemic? Analysis of Fake News About COVID-19 Vaccines in\n  Qatar', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Second Pandemic? Analysis of Fake News About COVID-19 Vaccines in\n  Qatar'}, 'summary': 'While COVID-19 vaccines are finally becoming widely available, a second\npandemic that revolves around the circulation of anti-vaxxer fake news may\nhinder efforts to recover from the first one. With this in mind, we performed\nan extensive analysis of Arabic and English tweets about COVID-19 vaccines,\nwith focus on messages originating from Qatar. We found that Arabic tweets\ncontain a lot of false information and rumors, while English tweets are mostly\nfactual. However, English tweets are much more propagandistic than Arabic ones.\nIn terms of propaganda techniques, about half of the Arabic tweets express\ndoubt, and 1/5 use loaded language, while English tweets are abundant in loaded\nlanguage, exaggeration, fear, name-calling, doubt, and flag-waving. Finally, in\nterms of framing, Arabic tweets adopt a health and safety perspective, while in\nEnglish economic concerns dominate.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While COVID-19 vaccines are finally becoming widely available, a second\npandemic that revolves around the circulation of anti-vaxxer fake news may\nhinder efforts to recover from the first one. With this in mind, we performed\nan extensive analysis of Arabic and English tweets about COVID-19 vaccines,\nwith focus on messages originating from Qatar. We found that Arabic tweets\ncontain a lot of false information and rumors, while English tweets are mostly\nfactual. However, English tweets are much more propagandistic than Arabic ones.\nIn terms of propaganda techniques, about half of the Arabic tweets express\ndoubt, and 1/5 use loaded language, while English tweets are abundant in loaded\nlanguage, exaggeration, fear, name-calling, doubt, and flag-waving. Finally, in\nterms of framing, Arabic tweets adopt a health and safety perspective, while in\nEnglish economic concerns dominate.'}, 'authors': [{'name': 'Preslav Nakov'}, {'name': 'Firoj Alam'}, {'name': 'Shaden Shaar'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Yifan Zhang'}], 'author_detail': {'name': 'Yifan Zhang'}, 'author': 'Yifan Zhang', 'arxiv_comment': 'COVID-19, disinformation, misinformation, factuality, fact-checking,\n  fact-checkers, check-worthiness, framing, harmfulness, social media\n  platforms, social media', 'arxiv_journal_ref': 'RANLP-2021', 'links': [{'href': 'http://arxiv.org/abs/2109.11372v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.11372v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'F.2.2; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
16,http://arxiv.org/abs/2109.13336v1,2021-09-21 10:56:01+00:00,2021-09-21 10:56:01+00:00,Fake or Credible? Towards Designing Services to Support Users' Credibility Assessment of News Content,"[arxiv.Result.Author('Enrico Bunde'), arxiv.Result.Author('Niklas Kühl'), arxiv.Result.Author('Christian Meske')]","Fake news has become omnipresent in digitalized areas such as social media
platforms. While being disseminated online, it also poses a threat to
individuals and societies offline, for example, in the context of democratic
elections. Research and practice have investigated the detection of fake news
with behavioral science or method-related perspectives. However, to date, we
lack design knowledge on presenting fake news warnings to users to support
their individual news credibility assessment. We present the journey through
the first design cycle on developing a fake news detection service focusing on
the user interface design. The design is grounded in concepts from the field of
source credibility theory and instantiated in a prototype that was
qualitatively evaluated. The 13 participants communicated their interest in a
lightweight application that aids in the news credibility assessment and rated
the design features as useful as well as desirable.",Hawaii International Conference on System Sciences 2022 (HICSS-55),,,cs.HC,"['cs.HC', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2109.13336v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.13336v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.13336v1,"{'id': 'http://arxiv.org/abs/2109.13336v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.13336v1', 'updated': '2021-09-21T10:56:01Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=21, tm_hour=10, tm_min=56, tm_sec=1, tm_wday=1, tm_yday=264, tm_isdst=0), 'published': '2021-09-21T10:56:01Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=21, tm_hour=10, tm_min=56, tm_sec=1, tm_wday=1, tm_yday=264, tm_isdst=0), 'title': ""Fake or Credible? Towards Designing Services to Support Users'\n  Credibility Assessment of News Content"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake or Credible? Towards Designing Services to Support Users'\n  Credibility Assessment of News Content""}, 'summary': 'Fake news has become omnipresent in digitalized areas such as social media\nplatforms. While being disseminated online, it also poses a threat to\nindividuals and societies offline, for example, in the context of democratic\nelections. Research and practice have investigated the detection of fake news\nwith behavioral science or method-related perspectives. However, to date, we\nlack design knowledge on presenting fake news warnings to users to support\ntheir individual news credibility assessment. We present the journey through\nthe first design cycle on developing a fake news detection service focusing on\nthe user interface design. The design is grounded in concepts from the field of\nsource credibility theory and instantiated in a prototype that was\nqualitatively evaluated. The 13 participants communicated their interest in a\nlightweight application that aids in the news credibility assessment and rated\nthe design features as useful as well as desirable.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news has become omnipresent in digitalized areas such as social media\nplatforms. While being disseminated online, it also poses a threat to\nindividuals and societies offline, for example, in the context of democratic\nelections. Research and practice have investigated the detection of fake news\nwith behavioral science or method-related perspectives. However, to date, we\nlack design knowledge on presenting fake news warnings to users to support\ntheir individual news credibility assessment. We present the journey through\nthe first design cycle on developing a fake news detection service focusing on\nthe user interface design. The design is grounded in concepts from the field of\nsource credibility theory and instantiated in a prototype that was\nqualitatively evaluated. The 13 participants communicated their interest in a\nlightweight application that aids in the news credibility assessment and rated\nthe design features as useful as well as desirable.'}, 'authors': [{'name': 'Enrico Bunde'}, {'name': 'Niklas Kühl'}, {'name': 'Christian Meske'}], 'author_detail': {'name': 'Christian Meske'}, 'author': 'Christian Meske', 'arxiv_comment': 'Hawaii International Conference on System Sciences 2022 (HICSS-55)', 'links': [{'href': 'http://arxiv.org/abs/2109.13336v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.13336v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
17,http://arxiv.org/abs/2109.09796v1,2021-09-20 19:03:16+00:00,2021-09-20 19:03:16+00:00,Transforming Fake News: Robust Generalisable News Classification Using Transformers,"[arxiv.Result.Author('Ciara Blackledge'), arxiv.Result.Author('Amir Atapour-Abarghouei')]","As online news has become increasingly popular and fake news increasingly
prevalent, the ability to audit the veracity of online news content has become
more important than ever. Such a task represents a binary classification
challenge, for which transformers have achieved state-of-the-art results. Using
the publicly available ISOT and Combined Corpus datasets, this study explores
transformers' abilities to identify fake news, with particular attention given
to investigating generalisation to unseen datasets with varying styles, topics
and class distributions. Moreover, we explore the idea that opinion-based news
articles cannot be classified as real or fake due to their subjective nature
and often sensationalised language, and propose a novel two-step classification
pipeline to remove such articles from both model training and the final
deployed inference system. Experiments over the ISOT and Combined Corpus
datasets show that transformers achieve an increase in F1 scores of up to 4.9%
for out of distribution generalisation compared to baseline approaches, with a
further increase of 10.1% following the implementation of our two-step
classification pipeline. To the best of our knowledge, this study is the first
to investigate generalisation of transformers in this context.",9 pages,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.09796v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.09796v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.09796v1,"{'id': 'http://arxiv.org/abs/2109.09796v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.09796v1', 'updated': '2021-09-20T19:03:16Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=19, tm_min=3, tm_sec=16, tm_wday=0, tm_yday=263, tm_isdst=0), 'published': '2021-09-20T19:03:16Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=19, tm_min=3, tm_sec=16, tm_wday=0, tm_yday=263, tm_isdst=0), 'title': 'Transforming Fake News: Robust Generalisable News Classification Using\n  Transformers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transforming Fake News: Robust Generalisable News Classification Using\n  Transformers'}, 'summary': ""As online news has become increasingly popular and fake news increasingly\nprevalent, the ability to audit the veracity of online news content has become\nmore important than ever. Such a task represents a binary classification\nchallenge, for which transformers have achieved state-of-the-art results. Using\nthe publicly available ISOT and Combined Corpus datasets, this study explores\ntransformers' abilities to identify fake news, with particular attention given\nto investigating generalisation to unseen datasets with varying styles, topics\nand class distributions. Moreover, we explore the idea that opinion-based news\narticles cannot be classified as real or fake due to their subjective nature\nand often sensationalised language, and propose a novel two-step classification\npipeline to remove such articles from both model training and the final\ndeployed inference system. Experiments over the ISOT and Combined Corpus\ndatasets show that transformers achieve an increase in F1 scores of up to 4.9%\nfor out of distribution generalisation compared to baseline approaches, with a\nfurther increase of 10.1% following the implementation of our two-step\nclassification pipeline. To the best of our knowledge, this study is the first\nto investigate generalisation of transformers in this context."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As online news has become increasingly popular and fake news increasingly\nprevalent, the ability to audit the veracity of online news content has become\nmore important than ever. Such a task represents a binary classification\nchallenge, for which transformers have achieved state-of-the-art results. Using\nthe publicly available ISOT and Combined Corpus datasets, this study explores\ntransformers' abilities to identify fake news, with particular attention given\nto investigating generalisation to unseen datasets with varying styles, topics\nand class distributions. Moreover, we explore the idea that opinion-based news\narticles cannot be classified as real or fake due to their subjective nature\nand often sensationalised language, and propose a novel two-step classification\npipeline to remove such articles from both model training and the final\ndeployed inference system. Experiments over the ISOT and Combined Corpus\ndatasets show that transformers achieve an increase in F1 scores of up to 4.9%\nfor out of distribution generalisation compared to baseline approaches, with a\nfurther increase of 10.1% following the implementation of our two-step\nclassification pipeline. To the best of our knowledge, this study is the first\nto investigate generalisation of transformers in this context.""}, 'authors': [{'name': 'Ciara Blackledge'}, {'name': 'Amir Atapour-Abarghouei'}], 'author_detail': {'name': 'Amir Atapour-Abarghouei'}, 'author': 'Amir Atapour-Abarghouei', 'arxiv_comment': '9 pages', 'links': [{'href': 'http://arxiv.org/abs/2109.09796v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.09796v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
18,http://arxiv.org/abs/2109.06533v1,2021-09-14 09:05:29+00:00,2021-09-14 09:05:29+00:00,Los fact-checkers iberoamericanos frente a la COVID-19. Análisis de actividad en Facebook / The Ibero-American fact-checkers facing the COVID-19. Analysis of activity on Facebook,"[arxiv.Result.Author('Alberto Dafonte-Gómez'), arxiv.Result.Author('María-Isabel Míguez-González'), arxiv.Result.Author('Xabier Martínez-Rolán')]","Introduction: The COVID-19 pandemic revealed infodemics as an aggravating
factor in health emergencies, a situation that enhanced the role of data
verification journalism in crisis situations. This article aims to know the
dynamics of publication and interaction on Facebook of the international
fact-checking group LatamChequea Coronavirus during the first two months after
the declaration of the COVID-19 pandemic by the WHO (March 11, 2020 - May 11,
2020). Methodology: The contents, metadata and reactions generated in a total
of 5736 posts published by 31 different fact-checkers were collected with
Crowdtangle and analyzed. Results: Among the most shared publications, those
related to the COVID-19 generated more reactions and comments than those
referring to other topics; the volume of shares is high in relation to other
generally more frequent interactions and publications that include links
achieved more interactions of all kinds than those based on videos or images.
There are positive correlations between the number of likes and the number of
shares, and between the angry reaction and the number of comments. Discussion
and conclusions: The relevance of sharing in the set of interactions would
indicate a high interest of the users to share the denials about fake news,
something that distances from previous referenced investigations. The results
also point to the influence of the emotional reaction expressed in the
interaction with the content in the form of sharing or commenting.","Preprint aceptado en Observatorio (OBS*) Journal, 22 p\'aginas, in
  Spanish, 7 tablas, 1 gr\'afico",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.06533v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.06533v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.06533v1,"{'id': 'http://arxiv.org/abs/2109.06533v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.06533v1', 'updated': '2021-09-14T09:05:29Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=14, tm_hour=9, tm_min=5, tm_sec=29, tm_wday=1, tm_yday=257, tm_isdst=0), 'published': '2021-09-14T09:05:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=14, tm_hour=9, tm_min=5, tm_sec=29, tm_wday=1, tm_yday=257, tm_isdst=0), 'title': 'Los fact-checkers iberoamericanos frente a la COVID-19. Análisis de\n  actividad en Facebook / The Ibero-American fact-checkers facing the COVID-19.\n  Analysis of activity on Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Los fact-checkers iberoamericanos frente a la COVID-19. Análisis de\n  actividad en Facebook / The Ibero-American fact-checkers facing the COVID-19.\n  Analysis of activity on Facebook'}, 'summary': 'Introduction: The COVID-19 pandemic revealed infodemics as an aggravating\nfactor in health emergencies, a situation that enhanced the role of data\nverification journalism in crisis situations. This article aims to know the\ndynamics of publication and interaction on Facebook of the international\nfact-checking group LatamChequea Coronavirus during the first two months after\nthe declaration of the COVID-19 pandemic by the WHO (March 11, 2020 - May 11,\n2020). Methodology: The contents, metadata and reactions generated in a total\nof 5736 posts published by 31 different fact-checkers were collected with\nCrowdtangle and analyzed. Results: Among the most shared publications, those\nrelated to the COVID-19 generated more reactions and comments than those\nreferring to other topics; the volume of shares is high in relation to other\ngenerally more frequent interactions and publications that include links\nachieved more interactions of all kinds than those based on videos or images.\nThere are positive correlations between the number of likes and the number of\nshares, and between the angry reaction and the number of comments. Discussion\nand conclusions: The relevance of sharing in the set of interactions would\nindicate a high interest of the users to share the denials about fake news,\nsomething that distances from previous referenced investigations. The results\nalso point to the influence of the emotional reaction expressed in the\ninteraction with the content in the form of sharing or commenting.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Introduction: The COVID-19 pandemic revealed infodemics as an aggravating\nfactor in health emergencies, a situation that enhanced the role of data\nverification journalism in crisis situations. This article aims to know the\ndynamics of publication and interaction on Facebook of the international\nfact-checking group LatamChequea Coronavirus during the first two months after\nthe declaration of the COVID-19 pandemic by the WHO (March 11, 2020 - May 11,\n2020). Methodology: The contents, metadata and reactions generated in a total\nof 5736 posts published by 31 different fact-checkers were collected with\nCrowdtangle and analyzed. Results: Among the most shared publications, those\nrelated to the COVID-19 generated more reactions and comments than those\nreferring to other topics; the volume of shares is high in relation to other\ngenerally more frequent interactions and publications that include links\nachieved more interactions of all kinds than those based on videos or images.\nThere are positive correlations between the number of likes and the number of\nshares, and between the angry reaction and the number of comments. Discussion\nand conclusions: The relevance of sharing in the set of interactions would\nindicate a high interest of the users to share the denials about fake news,\nsomething that distances from previous referenced investigations. The results\nalso point to the influence of the emotional reaction expressed in the\ninteraction with the content in the form of sharing or commenting.'}, 'authors': [{'name': 'Alberto Dafonte-Gómez'}, {'name': 'María-Isabel Míguez-González'}, {'name': 'Xabier Martínez-Rolán'}], 'author_detail': {'name': 'Xabier Martínez-Rolán'}, 'author': 'Xabier Martínez-Rolán', 'arxiv_comment': ""Preprint aceptado en Observatorio (OBS*) Journal, 22 p\\'aginas, in\n  Spanish, 7 tablas, 1 gr\\'afico"", 'links': [{'href': 'http://arxiv.org/abs/2109.06533v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.06533v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
19,http://arxiv.org/abs/2109.06416v2,2021-09-23 19:57:17+00:00,2021-09-14 03:57:50+00:00,MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake News Detection and a Baseline Architecture for Classification,"[arxiv.Result.Author('Mingxuan Chen'), arxiv.Result.Author('Xinqiao Chu'), arxiv.Result.Author('K. P. Subbalakshmi')]","The outbreak of COVID-19 has resulted in an ""infodemic"" that has encouraged
the propagation of misinformation about COVID-19 and cure methods which, in
turn, could negatively affect the adoption of recommended public health
measures in the larger population. In this paper, we provide a new multimodal
(consisting of images, text and temporal information) labeled dataset
containing news articles and tweets on the COVID-19 vaccine. We collected 2,593
news articles from 80 publishers for one year between Feb 16th 2020 to May 8th
2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th
2021). We combine ratings from two news media ranking sites: Medias Bias Chart
and Media Bias/Fact Check (MBFC) to classify the news dataset into two levels
of credibility: reliable and unreliable. The combination of two filters allows
for higher precision of labeling. We also propose a stance detection mechanism
to annotate tweets into three levels of credibility: reliable, unreliable and
inconclusive. We provide several statistics as well as other analytics like,
publisher distribution, publication date distribution, topic analysis, etc. We
also provide a novel architecture that classifies the news data into
misinformation or truth to provide a baseline performance for this dataset. We
find that the proposed architecture has an F-Score of 0.919 and accuracy of
0.882 for fake news detection. Furthermore, we provide benchmark performance
for misinformation detection on tweet dataset. This new multimodal dataset can
be used in research on COVID-19 vaccine, including misinformation detection,
influence of fake COVID-19 vaccine information, etc.","12 pages, 8 figures. This paper has been accepted for publication in
  ASONAM 2021",,,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2109.06416v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.06416v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.06416v2,"{'id': 'http://arxiv.org/abs/2109.06416v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.06416v2', 'updated': '2021-09-23T19:57:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=23, tm_hour=19, tm_min=57, tm_sec=17, tm_wday=3, tm_yday=266, tm_isdst=0), 'published': '2021-09-14T03:57:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=14, tm_hour=3, tm_min=57, tm_sec=50, tm_wday=1, tm_yday=257, tm_isdst=0), 'title': 'MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake\n  News Detection and a Baseline Architecture for Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake\n  News Detection and a Baseline Architecture for Classification'}, 'summary': 'The outbreak of COVID-19 has resulted in an ""infodemic"" that has encouraged\nthe propagation of misinformation about COVID-19 and cure methods which, in\nturn, could negatively affect the adoption of recommended public health\nmeasures in the larger population. In this paper, we provide a new multimodal\n(consisting of images, text and temporal information) labeled dataset\ncontaining news articles and tweets on the COVID-19 vaccine. We collected 2,593\nnews articles from 80 publishers for one year between Feb 16th 2020 to May 8th\n2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th\n2021). We combine ratings from two news media ranking sites: Medias Bias Chart\nand Media Bias/Fact Check (MBFC) to classify the news dataset into two levels\nof credibility: reliable and unreliable. The combination of two filters allows\nfor higher precision of labeling. We also propose a stance detection mechanism\nto annotate tweets into three levels of credibility: reliable, unreliable and\ninconclusive. We provide several statistics as well as other analytics like,\npublisher distribution, publication date distribution, topic analysis, etc. We\nalso provide a novel architecture that classifies the news data into\nmisinformation or truth to provide a baseline performance for this dataset. We\nfind that the proposed architecture has an F-Score of 0.919 and accuracy of\n0.882 for fake news detection. Furthermore, we provide benchmark performance\nfor misinformation detection on tweet dataset. This new multimodal dataset can\nbe used in research on COVID-19 vaccine, including misinformation detection,\ninfluence of fake COVID-19 vaccine information, etc.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The outbreak of COVID-19 has resulted in an ""infodemic"" that has encouraged\nthe propagation of misinformation about COVID-19 and cure methods which, in\nturn, could negatively affect the adoption of recommended public health\nmeasures in the larger population. In this paper, we provide a new multimodal\n(consisting of images, text and temporal information) labeled dataset\ncontaining news articles and tweets on the COVID-19 vaccine. We collected 2,593\nnews articles from 80 publishers for one year between Feb 16th 2020 to May 8th\n2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th\n2021). We combine ratings from two news media ranking sites: Medias Bias Chart\nand Media Bias/Fact Check (MBFC) to classify the news dataset into two levels\nof credibility: reliable and unreliable. The combination of two filters allows\nfor higher precision of labeling. We also propose a stance detection mechanism\nto annotate tweets into three levels of credibility: reliable, unreliable and\ninconclusive. We provide several statistics as well as other analytics like,\npublisher distribution, publication date distribution, topic analysis, etc. We\nalso provide a novel architecture that classifies the news data into\nmisinformation or truth to provide a baseline performance for this dataset. We\nfind that the proposed architecture has an F-Score of 0.919 and accuracy of\n0.882 for fake news detection. Furthermore, we provide benchmark performance\nfor misinformation detection on tweet dataset. This new multimodal dataset can\nbe used in research on COVID-19 vaccine, including misinformation detection,\ninfluence of fake COVID-19 vaccine information, etc.'}, 'authors': [{'name': 'Mingxuan Chen'}, {'name': 'Xinqiao Chu'}, {'name': 'K. P. Subbalakshmi'}], 'author_detail': {'name': 'K. P. Subbalakshmi'}, 'author': 'K. P. Subbalakshmi', 'arxiv_comment': '12 pages, 8 figures. This paper has been accepted for publication in\n  ASONAM 2021', 'links': [{'href': 'http://arxiv.org/abs/2109.06416v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.06416v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
20,http://arxiv.org/abs/2109.08022v1,2021-09-13 15:21:44+00:00,2021-09-13 15:21:44+00:00,Hetero-SCAN: Towards Social Context Aware Fake News Detection via Heterogeneous Graph Neural Network,"[arxiv.Result.Author('Jian Cui'), arxiv.Result.Author('Kwanwoo Kim'), arxiv.Result.Author('Seung Ho Na'), arxiv.Result.Author('Seungwon Shin')]","Fake news, false or misleading information presented as news, has a great
impact on many aspects of society, such as politics and healthcare. To handle
this emerging problem, many fake news detection methods have been proposed,
applying Natural Language Processing (NLP) techniques on the article text.
Considering that even people cannot easily distinguish fake news by news
content, these text-based solutions are insufficient. To further improve fake
news detection, researchers suggested graph-based solutions, utilizing the
social context information such as user engagement or publishers information.
However, existing graph-based methods still suffer from the following four
major drawbacks: 1) expensive computational cost due to a large number of user
nodes in the graph, 2) the error in sub-tasks, such as textual encoding or
stance detection, 3) loss of rich social context due to homogeneous
representation of news graphs, and 4) the absence of temporal information
utilization. In order to overcome the aforementioned issues, we propose a novel
social context aware fake news detection method, Hetero-SCAN, based on a
heterogeneous graph neural network. Hetero-SCAN learns the news representation
from the heterogeneous graph of news in an end-to-end manner. We demonstrate
that Hetero-SCAN yields significant improvement over state-of-the-art
text-based and graph-based fake news detection methods in terms of performance
and efficiency.",,,,cs.SI,"['cs.SI', 'cs.AI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2109.08022v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.08022v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.08022v1,"{'id': 'http://arxiv.org/abs/2109.08022v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.08022v1', 'updated': '2021-09-13T15:21:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=13, tm_hour=15, tm_min=21, tm_sec=44, tm_wday=0, tm_yday=256, tm_isdst=0), 'published': '2021-09-13T15:21:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=13, tm_hour=15, tm_min=21, tm_sec=44, tm_wday=0, tm_yday=256, tm_isdst=0), 'title': 'Hetero-SCAN: Towards Social Context Aware Fake News Detection via\n  Heterogeneous Graph Neural Network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hetero-SCAN: Towards Social Context Aware Fake News Detection via\n  Heterogeneous Graph Neural Network'}, 'summary': 'Fake news, false or misleading information presented as news, has a great\nimpact on many aspects of society, such as politics and healthcare. To handle\nthis emerging problem, many fake news detection methods have been proposed,\napplying Natural Language Processing (NLP) techniques on the article text.\nConsidering that even people cannot easily distinguish fake news by news\ncontent, these text-based solutions are insufficient. To further improve fake\nnews detection, researchers suggested graph-based solutions, utilizing the\nsocial context information such as user engagement or publishers information.\nHowever, existing graph-based methods still suffer from the following four\nmajor drawbacks: 1) expensive computational cost due to a large number of user\nnodes in the graph, 2) the error in sub-tasks, such as textual encoding or\nstance detection, 3) loss of rich social context due to homogeneous\nrepresentation of news graphs, and 4) the absence of temporal information\nutilization. In order to overcome the aforementioned issues, we propose a novel\nsocial context aware fake news detection method, Hetero-SCAN, based on a\nheterogeneous graph neural network. Hetero-SCAN learns the news representation\nfrom the heterogeneous graph of news in an end-to-end manner. We demonstrate\nthat Hetero-SCAN yields significant improvement over state-of-the-art\ntext-based and graph-based fake news detection methods in terms of performance\nand efficiency.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news, false or misleading information presented as news, has a great\nimpact on many aspects of society, such as politics and healthcare. To handle\nthis emerging problem, many fake news detection methods have been proposed,\napplying Natural Language Processing (NLP) techniques on the article text.\nConsidering that even people cannot easily distinguish fake news by news\ncontent, these text-based solutions are insufficient. To further improve fake\nnews detection, researchers suggested graph-based solutions, utilizing the\nsocial context information such as user engagement or publishers information.\nHowever, existing graph-based methods still suffer from the following four\nmajor drawbacks: 1) expensive computational cost due to a large number of user\nnodes in the graph, 2) the error in sub-tasks, such as textual encoding or\nstance detection, 3) loss of rich social context due to homogeneous\nrepresentation of news graphs, and 4) the absence of temporal information\nutilization. In order to overcome the aforementioned issues, we propose a novel\nsocial context aware fake news detection method, Hetero-SCAN, based on a\nheterogeneous graph neural network. Hetero-SCAN learns the news representation\nfrom the heterogeneous graph of news in an end-to-end manner. We demonstrate\nthat Hetero-SCAN yields significant improvement over state-of-the-art\ntext-based and graph-based fake news detection methods in terms of performance\nand efficiency.'}, 'authors': [{'name': 'Jian Cui'}, {'name': 'Kwanwoo Kim'}, {'name': 'Seung Ho Na'}, {'name': 'Seungwon Shin'}], 'author_detail': {'name': 'Seungwon Shin'}, 'author': 'Seungwon Shin', 'links': [{'href': 'http://arxiv.org/abs/2109.08022v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.08022v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
21,http://arxiv.org/abs/2109.07909v1,2021-09-13 14:10:44+00:00,2021-09-13 14:10:44+00:00,Surveying the Research on Fake News in Social Media: a Tale of Networks and Language,"[arxiv.Result.Author('Giancarlo Ruffo'), arxiv.Result.Author('Alfonso Semeraro'), arxiv.Result.Author('Anastasia Giachanou'), arxiv.Result.Author('Paolo Rosso')]","The history of journalism and news diffusion is tightly coupled with the
effort to dispel hoaxes, misinformation, propaganda, unverified rumours, poor
reporting, and messages containing hate and divisions. With the explosive
growth of online social media and billions of individuals engaged with
consuming, creating, and sharing news, this ancient problem has surfaced with a
renewed intensity threatening our democracies, public health, and news outlets
credibility. This has triggered many researchers to develop new methods for
studying, understanding, detecting, and preventing fake-news diffusion; as a
consequence, thousands of scientific papers have been published in a relatively
short period, making researchers of different disciplines to struggle in search
of open problems and most relevant trends. The aim of this survey is threefold:
first, we want to provide the researchers interested in this multidisciplinary
and challenging area with a network-based analysis of the existing literature
to assist them with a visual exploration of papers that can be of interest;
second, we present a selection of the main results achieved so far adopting the
network as an unifying framework to represent and make sense of data, to model
diffusion processes, and to evaluate different debunking strategies. Finally,
we present an outline of the most relevant research trends focusing on the
moving target of fake-news, bots, and trolls identification by means of data
mining and text technologies; despite scholars working on computational
linguistics and networks traditionally belong to different scientific
communities, we expect that forthcoming computational approaches to prevent
fake news from polluting the social media must be developed using hybrid and
up-to-date methodologies.","43 pages, 8 figures",,,cs.CY,"['cs.CY', 'cs.CL', 'cs.SI', 'A.1; J.4; G.2; K.4; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2109.07909v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.07909v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.07909v1,"{'id': 'http://arxiv.org/abs/2109.07909v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.07909v1', 'updated': '2021-09-13T14:10:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=13, tm_hour=14, tm_min=10, tm_sec=44, tm_wday=0, tm_yday=256, tm_isdst=0), 'published': '2021-09-13T14:10:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=13, tm_hour=14, tm_min=10, tm_sec=44, tm_wday=0, tm_yday=256, tm_isdst=0), 'title': 'Surveying the Research on Fake News in Social Media: a Tale of Networks\n  and Language', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Surveying the Research on Fake News in Social Media: a Tale of Networks\n  and Language'}, 'summary': 'The history of journalism and news diffusion is tightly coupled with the\neffort to dispel hoaxes, misinformation, propaganda, unverified rumours, poor\nreporting, and messages containing hate and divisions. With the explosive\ngrowth of online social media and billions of individuals engaged with\nconsuming, creating, and sharing news, this ancient problem has surfaced with a\nrenewed intensity threatening our democracies, public health, and news outlets\ncredibility. This has triggered many researchers to develop new methods for\nstudying, understanding, detecting, and preventing fake-news diffusion; as a\nconsequence, thousands of scientific papers have been published in a relatively\nshort period, making researchers of different disciplines to struggle in search\nof open problems and most relevant trends. The aim of this survey is threefold:\nfirst, we want to provide the researchers interested in this multidisciplinary\nand challenging area with a network-based analysis of the existing literature\nto assist them with a visual exploration of papers that can be of interest;\nsecond, we present a selection of the main results achieved so far adopting the\nnetwork as an unifying framework to represent and make sense of data, to model\ndiffusion processes, and to evaluate different debunking strategies. Finally,\nwe present an outline of the most relevant research trends focusing on the\nmoving target of fake-news, bots, and trolls identification by means of data\nmining and text technologies; despite scholars working on computational\nlinguistics and networks traditionally belong to different scientific\ncommunities, we expect that forthcoming computational approaches to prevent\nfake news from polluting the social media must be developed using hybrid and\nup-to-date methodologies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The history of journalism and news diffusion is tightly coupled with the\neffort to dispel hoaxes, misinformation, propaganda, unverified rumours, poor\nreporting, and messages containing hate and divisions. With the explosive\ngrowth of online social media and billions of individuals engaged with\nconsuming, creating, and sharing news, this ancient problem has surfaced with a\nrenewed intensity threatening our democracies, public health, and news outlets\ncredibility. This has triggered many researchers to develop new methods for\nstudying, understanding, detecting, and preventing fake-news diffusion; as a\nconsequence, thousands of scientific papers have been published in a relatively\nshort period, making researchers of different disciplines to struggle in search\nof open problems and most relevant trends. The aim of this survey is threefold:\nfirst, we want to provide the researchers interested in this multidisciplinary\nand challenging area with a network-based analysis of the existing literature\nto assist them with a visual exploration of papers that can be of interest;\nsecond, we present a selection of the main results achieved so far adopting the\nnetwork as an unifying framework to represent and make sense of data, to model\ndiffusion processes, and to evaluate different debunking strategies. Finally,\nwe present an outline of the most relevant research trends focusing on the\nmoving target of fake-news, bots, and trolls identification by means of data\nmining and text technologies; despite scholars working on computational\nlinguistics and networks traditionally belong to different scientific\ncommunities, we expect that forthcoming computational approaches to prevent\nfake news from polluting the social media must be developed using hybrid and\nup-to-date methodologies.'}, 'authors': [{'name': 'Giancarlo Ruffo'}, {'name': 'Alfonso Semeraro'}, {'name': 'Anastasia Giachanou'}, {'name': 'Paolo Rosso'}], 'author_detail': {'name': 'Paolo Rosso'}, 'arxiv_affiliation': 'Universitat Politècnica de València', 'author': 'Paolo Rosso', 'arxiv_comment': '43 pages, 8 figures', 'links': [{'href': 'http://arxiv.org/abs/2109.07909v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.07909v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'A.1; J.4; G.2; K.4; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
22,http://arxiv.org/abs/2109.04835v1,2021-09-10 12:39:00+00:00,2021-09-10 12:39:00+00:00,FR-Detect: A Multi-Modal Framework for Early Fake News Detection on Social Media Using Publishers Features,"[arxiv.Result.Author('Ali Jarrahi'), arxiv.Result.Author('Leila Safari')]","In recent years, with the expansion of the Internet and attractive social
media infrastructures, people prefer to follow the news through these media.
Despite the many advantages of these media in the news field, the lack of any
control and verification mechanism has led to the spread of fake news, as one
of the most important threats to democracy, economy, journalism and freedom of
expression. Designing and using automatic methods to detect fake news on social
media has become a significant challenge. In this paper, we examine the
publishers' role in detecting fake news on social media. We also suggest a high
accurate multi-modal framework, namely FR-Detect, using user-related and
content-related features with early detection capability. For this purpose, two
new user-related features, namely Activity Credibility and Influence, have been
introduced for publishers. Furthermore, a sentence-level convolutional neural
network is provided to combine these features with latent textual content
features properly. Experimental results have shown that the publishers'
features can improve the performance of content-based models by up to 13% and
29% in accuracy and F1-score, respectively.",,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2109.04835v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.04835v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.04835v1,"{'id': 'http://arxiv.org/abs/2109.04835v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.04835v1', 'updated': '2021-09-10T12:39:00Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=10, tm_hour=12, tm_min=39, tm_sec=0, tm_wday=4, tm_yday=253, tm_isdst=0), 'published': '2021-09-10T12:39:00Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=10, tm_hour=12, tm_min=39, tm_sec=0, tm_wday=4, tm_yday=253, tm_isdst=0), 'title': 'FR-Detect: A Multi-Modal Framework for Early Fake News Detection on\n  Social Media Using Publishers Features', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FR-Detect: A Multi-Modal Framework for Early Fake News Detection on\n  Social Media Using Publishers Features'}, 'summary': ""In recent years, with the expansion of the Internet and attractive social\nmedia infrastructures, people prefer to follow the news through these media.\nDespite the many advantages of these media in the news field, the lack of any\ncontrol and verification mechanism has led to the spread of fake news, as one\nof the most important threats to democracy, economy, journalism and freedom of\nexpression. Designing and using automatic methods to detect fake news on social\nmedia has become a significant challenge. In this paper, we examine the\npublishers' role in detecting fake news on social media. We also suggest a high\naccurate multi-modal framework, namely FR-Detect, using user-related and\ncontent-related features with early detection capability. For this purpose, two\nnew user-related features, namely Activity Credibility and Influence, have been\nintroduced for publishers. Furthermore, a sentence-level convolutional neural\nnetwork is provided to combine these features with latent textual content\nfeatures properly. Experimental results have shown that the publishers'\nfeatures can improve the performance of content-based models by up to 13% and\n29% in accuracy and F1-score, respectively."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In recent years, with the expansion of the Internet and attractive social\nmedia infrastructures, people prefer to follow the news through these media.\nDespite the many advantages of these media in the news field, the lack of any\ncontrol and verification mechanism has led to the spread of fake news, as one\nof the most important threats to democracy, economy, journalism and freedom of\nexpression. Designing and using automatic methods to detect fake news on social\nmedia has become a significant challenge. In this paper, we examine the\npublishers' role in detecting fake news on social media. We also suggest a high\naccurate multi-modal framework, namely FR-Detect, using user-related and\ncontent-related features with early detection capability. For this purpose, two\nnew user-related features, namely Activity Credibility and Influence, have been\nintroduced for publishers. Furthermore, a sentence-level convolutional neural\nnetwork is provided to combine these features with latent textual content\nfeatures properly. Experimental results have shown that the publishers'\nfeatures can improve the performance of content-based models by up to 13% and\n29% in accuracy and F1-score, respectively.""}, 'authors': [{'name': 'Ali Jarrahi'}, {'name': 'Leila Safari'}], 'author_detail': {'name': 'Leila Safari'}, 'author': 'Leila Safari', 'links': [{'href': 'http://arxiv.org/abs/2109.04835v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.04835v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
23,http://arxiv.org/abs/2109.04825v1,2021-09-10 12:13:45+00:00,2021-09-10 12:13:45+00:00,Artificial Text Detection via Examining the Topology of Attention Maps,"[arxiv.Result.Author('Laida Kushnareva'), arxiv.Result.Author('Daniil Cherniavskii'), arxiv.Result.Author('Vladislav Mikhailov'), arxiv.Result.Author('Ekaterina Artemova'), arxiv.Result.Author('Serguei Barannikov'), arxiv.Result.Author('Alexander Bernstein'), arxiv.Result.Author('Irina Piontkovskaya'), arxiv.Result.Author('Dmitri Piontkovski'), arxiv.Result.Author('Evgeny Burnaev')]","The impressive capabilities of recent generative models to create texts that
are challenging to distinguish from the human-written ones can be misused for
generating fake news, product reviews, and even abusive content. Despite the
prominent performance of existing methods for artificial text detection, they
still lack interpretability and robustness towards unseen models. To this end,
we propose three novel types of interpretable topological features for this
task based on Topological Data Analysis (TDA) which is currently understudied
in the field of NLP. We empirically show that the features derived from the
BERT model outperform count- and neural-based baselines up to 10\% on three
common datasets, and tend to be the most robust towards unseen GPT-style
generation models as opposed to existing methods. The probing analysis of the
features reveals their sensitivity to the surface and syntactic properties. The
results demonstrate that TDA is a promising line with respect to NLP tasks,
specifically the ones that incorporate surface and structural information.",Accepted to EMNLP 2021,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2109.04825v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.04825v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.04825v1,"{'id': 'http://arxiv.org/abs/2109.04825v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.04825v1', 'updated': '2021-09-10T12:13:45Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=10, tm_hour=12, tm_min=13, tm_sec=45, tm_wday=4, tm_yday=253, tm_isdst=0), 'published': '2021-09-10T12:13:45Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=10, tm_hour=12, tm_min=13, tm_sec=45, tm_wday=4, tm_yday=253, tm_isdst=0), 'title': 'Artificial Text Detection via Examining the Topology of Attention Maps', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Artificial Text Detection via Examining the Topology of Attention Maps'}, 'summary': 'The impressive capabilities of recent generative models to create texts that\nare challenging to distinguish from the human-written ones can be misused for\ngenerating fake news, product reviews, and even abusive content. Despite the\nprominent performance of existing methods for artificial text detection, they\nstill lack interpretability and robustness towards unseen models. To this end,\nwe propose three novel types of interpretable topological features for this\ntask based on Topological Data Analysis (TDA) which is currently understudied\nin the field of NLP. We empirically show that the features derived from the\nBERT model outperform count- and neural-based baselines up to 10\\% on three\ncommon datasets, and tend to be the most robust towards unseen GPT-style\ngeneration models as opposed to existing methods. The probing analysis of the\nfeatures reveals their sensitivity to the surface and syntactic properties. The\nresults demonstrate that TDA is a promising line with respect to NLP tasks,\nspecifically the ones that incorporate surface and structural information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The impressive capabilities of recent generative models to create texts that\nare challenging to distinguish from the human-written ones can be misused for\ngenerating fake news, product reviews, and even abusive content. Despite the\nprominent performance of existing methods for artificial text detection, they\nstill lack interpretability and robustness towards unseen models. To this end,\nwe propose three novel types of interpretable topological features for this\ntask based on Topological Data Analysis (TDA) which is currently understudied\nin the field of NLP. We empirically show that the features derived from the\nBERT model outperform count- and neural-based baselines up to 10\\% on three\ncommon datasets, and tend to be the most robust towards unseen GPT-style\ngeneration models as opposed to existing methods. The probing analysis of the\nfeatures reveals their sensitivity to the surface and syntactic properties. The\nresults demonstrate that TDA is a promising line with respect to NLP tasks,\nspecifically the ones that incorporate surface and structural information.'}, 'authors': [{'name': 'Laida Kushnareva'}, {'name': 'Daniil Cherniavskii'}, {'name': 'Vladislav Mikhailov'}, {'name': 'Ekaterina Artemova'}, {'name': 'Serguei Barannikov'}, {'name': 'Alexander Bernstein'}, {'name': 'Irina Piontkovskaya'}, {'name': 'Dmitri Piontkovski'}, {'name': 'Evgeny Burnaev'}], 'author_detail': {'name': 'Evgeny Burnaev'}, 'author': 'Evgeny Burnaev', 'arxiv_comment': 'Accepted to EMNLP 2021', 'links': [{'href': 'http://arxiv.org/abs/2109.04825v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.04825v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
24,http://arxiv.org/abs/2109.03710v1,2021-09-08 15:17:10+00:00,2021-09-08 15:17:10+00:00,BotSpot: Deep Learning Classification of Bot Accounts within Twitter,"[arxiv.Result.Author('Christopher Braker'), arxiv.Result.Author('Stavros Shiaeles'), arxiv.Result.Author('Gueltoum Bendiab'), arxiv.Result.Author('Nick Savage'), arxiv.Result.Author('Konstantinos Limniotis')]","The openness feature of Twitter allows programs to generate and control
Twitter accounts automatically via the Twitter API. These accounts, which are
known as bots, can automatically perform actions such as tweeting, re-tweeting,
following, unfollowing, or direct messaging other accounts, just like real
people. They can also conduct malicious tasks such as spreading of fake news,
spams, malicious software and other cyber-crimes. In this paper, we introduce a
novel bot detection approach using deep learning, with the Multi-layer
Perceptron Neural Networks and nine features of a bot account. A web crawler is
developed to automatically collect data from public Twitter accounts and build
the testing and training datasets, with 860 samples of human and bot accounts.
After the initial training is done, the Multilayer Perceptron Neural Networks
achieved an overall accuracy rate of 92%, which proves the performance of the
proposed approach.","7 pages, 3 figures, 2 tables","NEW2AN 2020, ruSMART 2020: Internet of Things, Smart Spaces, and
  Next Generation Networks and Systems pp 165-175",10.1007/978-3-030-65726-0_16,cs.CR,"['cs.CR', 'cs.AI', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-65726-0_16', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.03710v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.03710v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.03710v1,"{'id': 'http://arxiv.org/abs/2109.03710v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.03710v1', 'updated': '2021-09-08T15:17:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=8, tm_hour=15, tm_min=17, tm_sec=10, tm_wday=2, tm_yday=251, tm_isdst=0), 'published': '2021-09-08T15:17:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=8, tm_hour=15, tm_min=17, tm_sec=10, tm_wday=2, tm_yday=251, tm_isdst=0), 'title': 'BotSpot: Deep Learning Classification of Bot Accounts within Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BotSpot: Deep Learning Classification of Bot Accounts within Twitter'}, 'summary': 'The openness feature of Twitter allows programs to generate and control\nTwitter accounts automatically via the Twitter API. These accounts, which are\nknown as bots, can automatically perform actions such as tweeting, re-tweeting,\nfollowing, unfollowing, or direct messaging other accounts, just like real\npeople. They can also conduct malicious tasks such as spreading of fake news,\nspams, malicious software and other cyber-crimes. In this paper, we introduce a\nnovel bot detection approach using deep learning, with the Multi-layer\nPerceptron Neural Networks and nine features of a bot account. A web crawler is\ndeveloped to automatically collect data from public Twitter accounts and build\nthe testing and training datasets, with 860 samples of human and bot accounts.\nAfter the initial training is done, the Multilayer Perceptron Neural Networks\nachieved an overall accuracy rate of 92%, which proves the performance of the\nproposed approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The openness feature of Twitter allows programs to generate and control\nTwitter accounts automatically via the Twitter API. These accounts, which are\nknown as bots, can automatically perform actions such as tweeting, re-tweeting,\nfollowing, unfollowing, or direct messaging other accounts, just like real\npeople. They can also conduct malicious tasks such as spreading of fake news,\nspams, malicious software and other cyber-crimes. In this paper, we introduce a\nnovel bot detection approach using deep learning, with the Multi-layer\nPerceptron Neural Networks and nine features of a bot account. A web crawler is\ndeveloped to automatically collect data from public Twitter accounts and build\nthe testing and training datasets, with 860 samples of human and bot accounts.\nAfter the initial training is done, the Multilayer Perceptron Neural Networks\nachieved an overall accuracy rate of 92%, which proves the performance of the\nproposed approach.'}, 'authors': [{'name': 'Christopher Braker'}, {'name': 'Stavros Shiaeles'}, {'name': 'Gueltoum Bendiab'}, {'name': 'Nick Savage'}, {'name': 'Konstantinos Limniotis'}], 'author_detail': {'name': 'Konstantinos Limniotis'}, 'author': 'Konstantinos Limniotis', 'arxiv_doi': '10.1007/978-3-030-65726-0_16', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-65726-0_16', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.03710v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.03710v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '7 pages, 3 figures, 2 tables', 'arxiv_journal_ref': 'NEW2AN 2020, ruSMART 2020: Internet of Things, Smart Spaces, and\n  Next Generation Networks and Systems pp 165-175', 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
25,http://arxiv.org/abs/2109.02271v1,2021-09-06 07:41:21+00:00,2021-09-06 07:41:21+00:00,MONITOR: A Multimodal Fusion Framework to Assess Message Veracity in Social Networks,"[arxiv.Result.Author('Abderrazek Azri'), arxiv.Result.Author('Cécile Favre'), arxiv.Result.Author('Nouria Harbi'), arxiv.Result.Author('Jérôme Darmont'), arxiv.Result.Author('Camille Noûs')]","Users of social networks tend to post and share content with little
restraint. Hence, rumors and fake news can quickly spread on a huge scale. This
may pose a threat to the credibility of social media and can cause serious
consequences in real life. Therefore, the task of rumor detection and
verification has become extremely important. Assessing the veracity of a social
media message (e.g., by fact checkers) involves analyzing the text of the
message, its context and any multimedia attachment. This is a very
time-consuming task that can be much helped by machine learning. In the
literature, most message veracity verification methods only exploit textual
contents and metadata. Very few take both textual and visual contents, and more
particularly images, into account. In this paper, we second the hypothesis that
exploiting all of the components of a social media post enhances the accuracy
of veracity detection. To further the state of the art, we first propose using
a set of advanced image features that are inspired from the field of image
quality assessment, which effectively contributes to rumor detection. These
metrics are good indicators for the detection of fake images, even for those
generated by advanced techniques like generative adversarial networks (GANs).
Then, we introduce the Multimodal fusiON framework to assess message veracIty
in social neTwORks (MONITOR), which exploits all message features (i.e., text,
social context, and image features) by supervised machine learning. Such
algorithms provide interpretability and explainability in the decisions taken,
which we believe is particularly important in the context of rumor
verification. Experimental results show that MONITOR can detect rumors with an
accuracy of 96% and 89% on the MediaEval benchmark and the FakeNewsNet dataset,
respectively. These results are significantly better than those of
state-of-the-art machine learning baselines.","25th European Conference on Advances in Databases and Information
  Systems (ADBIS 2021), Aug 2021, Tartu, Estonia",,10.1007/978-3-030-82472-3,cs.SI,"['cs.SI', 'cs.AI', 'cs.DB']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-82472-3', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.02271v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.02271v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.02271v1,"{'id': 'http://arxiv.org/abs/2109.02271v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.02271v1', 'updated': '2021-09-06T07:41:21Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=7, tm_min=41, tm_sec=21, tm_wday=0, tm_yday=249, tm_isdst=0), 'published': '2021-09-06T07:41:21Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=7, tm_min=41, tm_sec=21, tm_wday=0, tm_yday=249, tm_isdst=0), 'title': 'MONITOR: A Multimodal Fusion Framework to Assess Message Veracity in\n  Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MONITOR: A Multimodal Fusion Framework to Assess Message Veracity in\n  Social Networks'}, 'summary': 'Users of social networks tend to post and share content with little\nrestraint. Hence, rumors and fake news can quickly spread on a huge scale. This\nmay pose a threat to the credibility of social media and can cause serious\nconsequences in real life. Therefore, the task of rumor detection and\nverification has become extremely important. Assessing the veracity of a social\nmedia message (e.g., by fact checkers) involves analyzing the text of the\nmessage, its context and any multimedia attachment. This is a very\ntime-consuming task that can be much helped by machine learning. In the\nliterature, most message veracity verification methods only exploit textual\ncontents and metadata. Very few take both textual and visual contents, and more\nparticularly images, into account. In this paper, we second the hypothesis that\nexploiting all of the components of a social media post enhances the accuracy\nof veracity detection. To further the state of the art, we first propose using\na set of advanced image features that are inspired from the field of image\nquality assessment, which effectively contributes to rumor detection. These\nmetrics are good indicators for the detection of fake images, even for those\ngenerated by advanced techniques like generative adversarial networks (GANs).\nThen, we introduce the Multimodal fusiON framework to assess message veracIty\nin social neTwORks (MONITOR), which exploits all message features (i.e., text,\nsocial context, and image features) by supervised machine learning. Such\nalgorithms provide interpretability and explainability in the decisions taken,\nwhich we believe is particularly important in the context of rumor\nverification. Experimental results show that MONITOR can detect rumors with an\naccuracy of 96% and 89% on the MediaEval benchmark and the FakeNewsNet dataset,\nrespectively. These results are significantly better than those of\nstate-of-the-art machine learning baselines.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Users of social networks tend to post and share content with little\nrestraint. Hence, rumors and fake news can quickly spread on a huge scale. This\nmay pose a threat to the credibility of social media and can cause serious\nconsequences in real life. Therefore, the task of rumor detection and\nverification has become extremely important. Assessing the veracity of a social\nmedia message (e.g., by fact checkers) involves analyzing the text of the\nmessage, its context and any multimedia attachment. This is a very\ntime-consuming task that can be much helped by machine learning. In the\nliterature, most message veracity verification methods only exploit textual\ncontents and metadata. Very few take both textual and visual contents, and more\nparticularly images, into account. In this paper, we second the hypothesis that\nexploiting all of the components of a social media post enhances the accuracy\nof veracity detection. To further the state of the art, we first propose using\na set of advanced image features that are inspired from the field of image\nquality assessment, which effectively contributes to rumor detection. These\nmetrics are good indicators for the detection of fake images, even for those\ngenerated by advanced techniques like generative adversarial networks (GANs).\nThen, we introduce the Multimodal fusiON framework to assess message veracIty\nin social neTwORks (MONITOR), which exploits all message features (i.e., text,\nsocial context, and image features) by supervised machine learning. Such\nalgorithms provide interpretability and explainability in the decisions taken,\nwhich we believe is particularly important in the context of rumor\nverification. Experimental results show that MONITOR can detect rumors with an\naccuracy of 96% and 89% on the MediaEval benchmark and the FakeNewsNet dataset,\nrespectively. These results are significantly better than those of\nstate-of-the-art machine learning baselines.'}, 'authors': [{'name': 'Abderrazek Azri'}, {'name': 'Cécile Favre'}, {'name': 'Nouria Harbi'}, {'name': 'Jérôme Darmont'}, {'name': 'Camille Noûs'}], 'author_detail': {'name': 'Camille Noûs'}, 'arxiv_affiliation': 'ERIC', 'author': 'Camille Noûs', 'arxiv_doi': '10.1007/978-3-030-82472-3', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-82472-3', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.02271v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.02271v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '25th European Conference on Advances in Databases and Information\n  Systems (ADBIS 2021), Aug 2021, Tartu, Estonia', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
26,http://arxiv.org/abs/2109.01850v2,2021-09-09 20:03:36+00:00,2021-09-04 11:53:37+00:00,Supervised Contrastive Learning for Multimodal Unreliable News Detection in COVID-19 Pandemic,"[arxiv.Result.Author('Wenjia Zhang'), arxiv.Result.Author('Lin Gui'), arxiv.Result.Author('Yulan He')]","As the digital news industry becomes the main channel of information
dissemination, the adverse impact of fake news is explosively magnified. The
credibility of a news report should not be considered in isolation. Rather,
previously published news articles on the similar event could be used to assess
the credibility of a news report. Inspired by this, we propose a BERT-based
multimodal unreliable news detection framework, which captures both textual and
visual information from unreliable articles utilising the contrastive learning
strategy. The contrastive learner interacts with the unreliable news classifier
to push similar credible news (or similar unreliable news) closer while moving
news articles with similar content but opposite credibility labels away from
each other in the multimodal embedding space. Experimental results on a
COVID-19 related dataset, ReCOVery, show that our model outperforms a number of
competitive baseline in unreliable news detection.",Accepted by the CIKM 2021,,10.1145/3459637.3482196,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3459637.3482196', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.01850v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.01850v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.01850v2,"{'id': 'http://arxiv.org/abs/2109.01850v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.01850v2', 'updated': '2021-09-09T20:03:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=9, tm_hour=20, tm_min=3, tm_sec=36, tm_wday=3, tm_yday=252, tm_isdst=0), 'published': '2021-09-04T11:53:37Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=4, tm_hour=11, tm_min=53, tm_sec=37, tm_wday=5, tm_yday=247, tm_isdst=0), 'title': 'Supervised Contrastive Learning for Multimodal Unreliable News Detection\n  in COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Supervised Contrastive Learning for Multimodal Unreliable News Detection\n  in COVID-19 Pandemic'}, 'summary': 'As the digital news industry becomes the main channel of information\ndissemination, the adverse impact of fake news is explosively magnified. The\ncredibility of a news report should not be considered in isolation. Rather,\npreviously published news articles on the similar event could be used to assess\nthe credibility of a news report. Inspired by this, we propose a BERT-based\nmultimodal unreliable news detection framework, which captures both textual and\nvisual information from unreliable articles utilising the contrastive learning\nstrategy. The contrastive learner interacts with the unreliable news classifier\nto push similar credible news (or similar unreliable news) closer while moving\nnews articles with similar content but opposite credibility labels away from\neach other in the multimodal embedding space. Experimental results on a\nCOVID-19 related dataset, ReCOVery, show that our model outperforms a number of\ncompetitive baseline in unreliable news detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the digital news industry becomes the main channel of information\ndissemination, the adverse impact of fake news is explosively magnified. The\ncredibility of a news report should not be considered in isolation. Rather,\npreviously published news articles on the similar event could be used to assess\nthe credibility of a news report. Inspired by this, we propose a BERT-based\nmultimodal unreliable news detection framework, which captures both textual and\nvisual information from unreliable articles utilising the contrastive learning\nstrategy. The contrastive learner interacts with the unreliable news classifier\nto push similar credible news (or similar unreliable news) closer while moving\nnews articles with similar content but opposite credibility labels away from\neach other in the multimodal embedding space. Experimental results on a\nCOVID-19 related dataset, ReCOVery, show that our model outperforms a number of\ncompetitive baseline in unreliable news detection.'}, 'authors': [{'name': 'Wenjia Zhang'}, {'name': 'Lin Gui'}, {'name': 'Yulan He'}], 'author_detail': {'name': 'Yulan He'}, 'author': 'Yulan He', 'arxiv_doi': '10.1145/3459637.3482196', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3459637.3482196', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.01850v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.01850v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted by the CIKM 2021', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
27,http://arxiv.org/abs/2109.00835v1,2021-09-02 10:45:07+00:00,2021-09-02 10:45:07+00:00,WikiCheck: An end-to-end open source Automatic Fact-Checking API based on Wikipedia,"[arxiv.Result.Author('Mykola Trokhymovych'), arxiv.Result.Author('Diego Saez-Trumper')]","With the growth of fake news and disinformation, the NLP community has been
working to assist humans in fact-checking. However, most academic research has
focused on model accuracy without paying attention to resource efficiency,
which is crucial in real-life scenarios. In this work, we review the
State-of-the-Art datasets and solutions for Automatic Fact-checking and test
their applicability in production environments. We discover overfitting issues
in those models, and we propose a data filtering method that improves the
model's performance and generalization. Then, we design an unsupervised
fine-tuning of the Masked Language models to improve its accuracy working with
Wikipedia. We also propose a novel query enhancing method to improve evidence
discovery using the Wikipedia Search API. Finally, we present a new
fact-checking system, the \textit{WikiCheck} API that automatically performs a
facts validation process based on the Wikipedia knowledge base. It is
comparable to SOTA solutions in terms of accuracy and can be used on low-memory
CPU instances.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.00835v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.00835v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.00835v1,"{'id': 'http://arxiv.org/abs/2109.00835v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.00835v1', 'updated': '2021-09-02T10:45:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=2, tm_hour=10, tm_min=45, tm_sec=7, tm_wday=3, tm_yday=245, tm_isdst=0), 'published': '2021-09-02T10:45:07Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=2, tm_hour=10, tm_min=45, tm_sec=7, tm_wday=3, tm_yday=245, tm_isdst=0), 'title': 'WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia'}, 'summary': ""With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.""}, 'authors': [{'name': 'Mykola Trokhymovych'}, {'name': 'Diego Saez-Trumper'}], 'author_detail': {'name': 'Diego Saez-Trumper'}, 'author': 'Diego Saez-Trumper', 'links': [{'href': 'http://arxiv.org/abs/2109.00835v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.00835v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
28,http://arxiv.org/abs/2108.13687v2,2021-09-23 16:33:27+00:00,2021-08-31 08:55:47+00:00,The coercive logic of fake news,"[arxiv.Result.Author('Alexander J. Stewart'), arxiv.Result.Author('Antonio A. Arechar'), arxiv.Result.Author('David G. Rand'), arxiv.Result.Author('Joshua B. Plotkin')]","The spread of misinformation and ""fake news"" continues to be a major focus of
public concern. A great deal of research has examined who falls for
misinformation and why, and what can be done to make people more discerning
consumers of news. Comparatively little work, however, has considered the
choices of those who produce misinformation, and how these choices interact
with the psychology of news consumers. Here we use game-theoretic models to
study the strategic interaction between news publishers and news readers. We
show that publishers who seek to spread misinformation can generate high
engagement with falsehoods by using strategies that mix true and false stories
over time, in such a way that they serve more false stories to more loyal
readers. These coercive strategies cause false stories to receive higher reader
engagement than true stories - even when readers strictly prefer truth over
falsehood. In contrast, publishers who seek to promote engagement with accurate
information will use strategies that generate more engagement with true stories
than with false stories. We confirm these predictions empirically by examining
1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook
engagement data with 20,000 perceived accuracy ratings collected in a survey
experiment. We show that engagement is positively correlated with accuracy
among mainstream sites, but negatively correlated with accuracy among
misinformation sites. We then use our model to analyze the conditions under
which news sites seeking engagement will produce false stories. We show that if
a publisher incorrectly assumes that readers prefer falsehoods, their resulting
publication strategy can nonetheless manufacture greater engagement with false
news - leading to a self-reinforcing cycle of false news promotion.",,,,econ.TH,['econ.TH'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.13687v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.13687v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.13687v2,"{'id': 'http://arxiv.org/abs/2108.13687v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.13687v2', 'updated': '2021-09-23T16:33:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=23, tm_hour=16, tm_min=33, tm_sec=27, tm_wday=3, tm_yday=266, tm_isdst=0), 'published': '2021-08-31T08:55:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=31, tm_hour=8, tm_min=55, tm_sec=47, tm_wday=1, tm_yday=243, tm_isdst=0), 'title': 'The coercive logic of fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The coercive logic of fake news'}, 'summary': 'The spread of misinformation and ""fake news"" continues to be a major focus of\npublic concern. A great deal of research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We show that engagement is positively correlated with accuracy\namong mainstream sites, but negatively correlated with accuracy among\nmisinformation sites. We then use our model to analyze the conditions under\nwhich news sites seeking engagement will produce false stories. We show that if\na publisher incorrectly assumes that readers prefer falsehoods, their resulting\npublication strategy can nonetheless manufacture greater engagement with false\nnews - leading to a self-reinforcing cycle of false news promotion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of misinformation and ""fake news"" continues to be a major focus of\npublic concern. A great deal of research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We show that engagement is positively correlated with accuracy\namong mainstream sites, but negatively correlated with accuracy among\nmisinformation sites. We then use our model to analyze the conditions under\nwhich news sites seeking engagement will produce false stories. We show that if\na publisher incorrectly assumes that readers prefer falsehoods, their resulting\npublication strategy can nonetheless manufacture greater engagement with false\nnews - leading to a self-reinforcing cycle of false news promotion.'}, 'authors': [{'name': 'Alexander J. Stewart'}, {'name': 'Antonio A. Arechar'}, {'name': 'David G. Rand'}, {'name': 'Joshua B. Plotkin'}], 'author_detail': {'name': 'Joshua B. Plotkin'}, 'author': 'Joshua B. Plotkin', 'links': [{'href': 'http://arxiv.org/abs/2108.13687v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.13687v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
29,http://arxiv.org/abs/2108.12601v1,2021-08-28 08:25:29+00:00,2021-08-28 08:25:29+00:00,Mitigation of Diachronic Bias in Fake News Detection Dataset,"[arxiv.Result.Author('Taichi Murayama'), arxiv.Result.Author('Shoko Wakamiya'), arxiv.Result.Author('Eiji Aramaki')]","Fake news causes significant damage to society.To deal with these fake news,
several studies on building detection models and arranging datasets have been
conducted. Most of the fake news datasets depend on a specific time period.
Consequently, the detection models trained on such a dataset have difficulty
detecting novel fake news generated by political changes and social changes;
they may possibly result in biased output from the input, including specific
person names and organizational names. We refer to this problem as
\textbf{Diachronic Bias} because it is caused by the creation date of news in
each dataset. In this study, we confirm the bias, especially proper nouns
including person names, from the deviation of phrase appearances in each
dataset. Based on these findings, we propose masking methods using Wikidata to
mitigate the influence of person names and validate whether they make fake news
detection models robust through experiments with in-domain and out-of-domain
data.",7 pages,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2108.12601v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.12601v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.12601v1,"{'id': 'http://arxiv.org/abs/2108.12601v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.12601v1', 'updated': '2021-08-28T08:25:29Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=28, tm_hour=8, tm_min=25, tm_sec=29, tm_wday=5, tm_yday=240, tm_isdst=0), 'published': '2021-08-28T08:25:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=28, tm_hour=8, tm_min=25, tm_sec=29, tm_wday=5, tm_yday=240, tm_isdst=0), 'title': 'Mitigation of Diachronic Bias in Fake News Detection Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mitigation of Diachronic Bias in Fake News Detection Dataset'}, 'summary': 'Fake news causes significant damage to society.To deal with these fake news,\nseveral studies on building detection models and arranging datasets have been\nconducted. Most of the fake news datasets depend on a specific time period.\nConsequently, the detection models trained on such a dataset have difficulty\ndetecting novel fake news generated by political changes and social changes;\nthey may possibly result in biased output from the input, including specific\nperson names and organizational names. We refer to this problem as\n\\textbf{Diachronic Bias} because it is caused by the creation date of news in\neach dataset. In this study, we confirm the bias, especially proper nouns\nincluding person names, from the deviation of phrase appearances in each\ndataset. Based on these findings, we propose masking methods using Wikidata to\nmitigate the influence of person names and validate whether they make fake news\ndetection models robust through experiments with in-domain and out-of-domain\ndata.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news causes significant damage to society.To deal with these fake news,\nseveral studies on building detection models and arranging datasets have been\nconducted. Most of the fake news datasets depend on a specific time period.\nConsequently, the detection models trained on such a dataset have difficulty\ndetecting novel fake news generated by political changes and social changes;\nthey may possibly result in biased output from the input, including specific\nperson names and organizational names. We refer to this problem as\n\\textbf{Diachronic Bias} because it is caused by the creation date of news in\neach dataset. In this study, we confirm the bias, especially proper nouns\nincluding person names, from the deviation of phrase appearances in each\ndataset. Based on these findings, we propose masking methods using Wikidata to\nmitigate the influence of person names and validate whether they make fake news\ndetection models robust through experiments with in-domain and out-of-domain\ndata.'}, 'authors': [{'name': 'Taichi Murayama'}, {'name': 'Shoko Wakamiya'}, {'name': 'Eiji Aramaki'}], 'author_detail': {'name': 'Eiji Aramaki'}, 'author': 'Eiji Aramaki', 'arxiv_comment': '7 pages', 'links': [{'href': 'http://arxiv.org/abs/2108.12601v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.12601v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
30,http://arxiv.org/abs/2108.10942v1,2021-08-24 20:27:38+00:00,2021-08-24 20:27:38+00:00,Profiling Fake News Spreaders on Social Media through Psychological and Motivational Factors,"[arxiv.Result.Author('Mansooreh Karami'), arxiv.Result.Author('Tahora H. Nazer'), arxiv.Result.Author('Huan Liu')]","The rise of fake news in the past decade has brought with it a host of
consequences, from swaying opinions on elections to generating uncertainty
during a pandemic. A majority of methods developed to combat disinformation
either focus on fake news content or malicious actors who generate it. However,
the virality of fake news is largely dependent upon the users who propagate it.
A deeper understanding of these users can contribute to the development of a
framework for identifying users who are likely to spread fake news. In this
work, we study the characteristics and motivational factors of fake news
spreaders on social media with input from psychological theories and behavioral
studies. We then perform a series of experiments to determine if fake news
spreaders can be found to exhibit different characteristics than other users.
Further, we investigate our findings by testing whether the characteristics we
observe amongst fake news spreaders in our experiments can be applied to the
detection of fake news spreaders in a real social media environment.",,,10.1145/3465336.3475097,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3465336.3475097', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.10942v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10942v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10942v1,"{'id': 'http://arxiv.org/abs/2108.10942v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10942v1', 'updated': '2021-08-24T20:27:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=20, tm_min=27, tm_sec=38, tm_wday=1, tm_yday=236, tm_isdst=0), 'published': '2021-08-24T20:27:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=20, tm_min=27, tm_sec=38, tm_wday=1, tm_yday=236, tm_isdst=0), 'title': 'Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors'}, 'summary': 'The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.'}, 'authors': [{'name': 'Mansooreh Karami'}, {'name': 'Tahora H. Nazer'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_doi': '10.1145/3465336.3475097', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3465336.3475097', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.10942v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10942v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
31,http://arxiv.org/abs/2108.10509v1,2021-08-24 03:36:07+00:00,2021-08-24 03:36:07+00:00,Improving Fake News Detection by Using an Entity-enhanced Framework to Fuse Diverse Multimodal Clues,"[arxiv.Result.Author('Peng Qi'), arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('Xirong Li'), arxiv.Result.Author('Huan Liu'), arxiv.Result.Author('Qiang Sheng'), arxiv.Result.Author('Xiaoyue Mi'), arxiv.Result.Author('Qin He'), arxiv.Result.Author('Yongbiao Lv'), arxiv.Result.Author('Chenyang Guo'), arxiv.Result.Author('Yingchao Yu')]","Recently, fake news with text and images have achieved more effective
diffusion than text-only fake news, raising a severe issue of multimodal fake
news detection. Current studies on this issue have made significant
contributions to developing multimodal models, but they are defective in
modeling the multimodal content sufficiently. Most of them only preliminarily
model the basic semantics of the images as a supplement to the text, which
limits their performance on detection. In this paper, we find three valuable
text-image correlations in multimodal fake news: entity inconsistency, mutual
enhancement, and text complementation. To effectively capture these multimodal
clues, we innovatively extract visual entities (such as celebrities and
landmarks) to understand the news-related high-level semantics of images, and
then model the multimodal entity inconsistency and mutual enhancement with the
help of visual entities. Moreover, we extract the embedded text in images as
the complementation of the original text. All things considered, we propose a
novel entity-enhanced multimodal fusion framework, which simultaneously models
three cross-modal correlations to detect diverse multimodal fake news.
Extensive experiments demonstrate the superiority of our model compared to the
state of the art.",To appear in MM 2021 industrial track (long paper),,10.1145/3474085.3481548,cs.MM,['cs.MM'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3474085.3481548', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.10509v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10509v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10509v1,"{'id': 'http://arxiv.org/abs/2108.10509v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10509v1', 'updated': '2021-08-24T03:36:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=3, tm_min=36, tm_sec=7, tm_wday=1, tm_yday=236, tm_isdst=0), 'published': '2021-08-24T03:36:07Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=3, tm_min=36, tm_sec=7, tm_wday=1, tm_yday=236, tm_isdst=0), 'title': 'Improving Fake News Detection by Using an Entity-enhanced Framework to\n  Fuse Diverse Multimodal Clues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Improving Fake News Detection by Using an Entity-enhanced Framework to\n  Fuse Diverse Multimodal Clues'}, 'summary': 'Recently, fake news with text and images have achieved more effective\ndiffusion than text-only fake news, raising a severe issue of multimodal fake\nnews detection. Current studies on this issue have made significant\ncontributions to developing multimodal models, but they are defective in\nmodeling the multimodal content sufficiently. Most of them only preliminarily\nmodel the basic semantics of the images as a supplement to the text, which\nlimits their performance on detection. In this paper, we find three valuable\ntext-image correlations in multimodal fake news: entity inconsistency, mutual\nenhancement, and text complementation. To effectively capture these multimodal\nclues, we innovatively extract visual entities (such as celebrities and\nlandmarks) to understand the news-related high-level semantics of images, and\nthen model the multimodal entity inconsistency and mutual enhancement with the\nhelp of visual entities. Moreover, we extract the embedded text in images as\nthe complementation of the original text. All things considered, we propose a\nnovel entity-enhanced multimodal fusion framework, which simultaneously models\nthree cross-modal correlations to detect diverse multimodal fake news.\nExtensive experiments demonstrate the superiority of our model compared to the\nstate of the art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, fake news with text and images have achieved more effective\ndiffusion than text-only fake news, raising a severe issue of multimodal fake\nnews detection. Current studies on this issue have made significant\ncontributions to developing multimodal models, but they are defective in\nmodeling the multimodal content sufficiently. Most of them only preliminarily\nmodel the basic semantics of the images as a supplement to the text, which\nlimits their performance on detection. In this paper, we find three valuable\ntext-image correlations in multimodal fake news: entity inconsistency, mutual\nenhancement, and text complementation. To effectively capture these multimodal\nclues, we innovatively extract visual entities (such as celebrities and\nlandmarks) to understand the news-related high-level semantics of images, and\nthen model the multimodal entity inconsistency and mutual enhancement with the\nhelp of visual entities. Moreover, we extract the embedded text in images as\nthe complementation of the original text. All things considered, we propose a\nnovel entity-enhanced multimodal fusion framework, which simultaneously models\nthree cross-modal correlations to detect diverse multimodal fake news.\nExtensive experiments demonstrate the superiority of our model compared to the\nstate of the art.'}, 'authors': [{'name': 'Peng Qi'}, {'name': 'Juan Cao'}, {'name': 'Xirong Li'}, {'name': 'Huan Liu'}, {'name': 'Qiang Sheng'}, {'name': 'Xiaoyue Mi'}, {'name': 'Qin He'}, {'name': 'Yongbiao Lv'}, {'name': 'Chenyang Guo'}, {'name': 'Yingchao Yu'}], 'author_detail': {'name': 'Yingchao Yu'}, 'author': 'Yingchao Yu', 'arxiv_doi': '10.1145/3474085.3481548', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3474085.3481548', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.10509v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10509v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'To appear in MM 2021 industrial track (long paper)', 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
32,http://arxiv.org/abs/2108.05419v1,2021-08-11 19:13:04+00:00,2021-08-11 19:13:04+00:00,NoFake at CheckThat! 2021: Fake News Detection Using BERT,[arxiv.Result.Author('Sushma Kumari')],"Much research has been done for debunking and analysing fake news. Many
researchers study fake news detection in the last year, but many are limited to
social media data. Currently, multiples fact-checkers are publishing their
results in various formats. Also, multiple fact-checkers use different labels
for the fake news, making it difficult to make a generalisable classifier. With
the merge classes, the performance of the machine model can be enhanced. This
domain categorisation will help group the article, which will help save the
manual effort in assigning the claim verification. In this paper, we have
presented BERT based classification model to predict the domain and
classification. We have also used additional data from fact-checked articles.
We have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B
using the additional training data.",CLEF Task 3,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2108.05419v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.05419v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.05419v1,"{'id': 'http://arxiv.org/abs/2108.05419v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.05419v1', 'updated': '2021-08-11T19:13:04Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=19, tm_min=13, tm_sec=4, tm_wday=2, tm_yday=223, tm_isdst=0), 'published': '2021-08-11T19:13:04Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=19, tm_min=13, tm_sec=4, tm_wday=2, tm_yday=223, tm_isdst=0), 'title': 'NoFake at CheckThat! 2021: Fake News Detection Using BERT', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'NoFake at CheckThat! 2021: Fake News Detection Using BERT'}, 'summary': 'Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.'}, 'authors': [{'name': 'Sushma Kumari'}], 'author_detail': {'name': 'Sushma Kumari'}, 'author': 'Sushma Kumari', 'arxiv_comment': 'CLEF Task 3', 'links': [{'href': 'http://arxiv.org/abs/2108.05419v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.05419v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
33,http://arxiv.org/abs/2108.04418v1,2021-08-10 02:58:34+00:00,2021-08-10 02:58:34+00:00,Knowledge Enhanced Multi-modal Fake News Detection,"[arxiv.Result.Author('Yi Han'), arxiv.Result.Author('Amila Silva'), arxiv.Result.Author('Ling Luo'), arxiv.Result.Author('Shanika Karunasekera'), arxiv.Result.Author('Christopher Leckie')]","Recent years have witnessed the significant damage caused by various types of
fake news. Although considerable effort has been applied to address this issue
and much progress has been made on detecting fake news, most existing
approaches mainly rely on the textual content and/or social context, while
knowledge-level information---entities extracted from the news content and the
relations between them---is much less explored. Within the limited work on
knowledge-based fake news detection, an external knowledge graph is often
required, which may introduce additional problems: it is quite common for
entities and relations, especially with respect to new concepts, to be missing
in existing knowledge graphs, and both entity prediction and link prediction
are open research questions themselves. Therefore, in this work, we investigate
\textbf{knowledge-based fake news detection that does not require any external
knowledge graph.} Specifically, our contributions include: (1) transforming the
problem of detecting fake news into a subgraph classification task---entities
and relations are extracted from each news item to form a single knowledge
graph, where a news item is represented by a subgraph. Then a graph neural
network (GNN) model is trained to classify each subgraph/news item. (2) Further
improving the performance of this model through a simple but effective
multi-modal technique that combines extracted knowledge, textual content and
social context. Experiments on multiple datasets with thousands of labelled
news items demonstrate that our knowledge-based algorithm outperforms existing
counterpart methods, and its performance can be further boosted by the
multi-modal approach.","10 pages, 4 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.04418v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.04418v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.04418v1,"{'id': 'http://arxiv.org/abs/2108.04418v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.04418v1', 'updated': '2021-08-10T02:58:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=10, tm_hour=2, tm_min=58, tm_sec=34, tm_wday=1, tm_yday=222, tm_isdst=0), 'published': '2021-08-10T02:58:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=10, tm_hour=2, tm_min=58, tm_sec=34, tm_wday=1, tm_yday=222, tm_isdst=0), 'title': 'Knowledge Enhanced Multi-modal Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Knowledge Enhanced Multi-modal Fake News Detection'}, 'summary': 'Recent years have witnessed the significant damage caused by various types of\nfake news. Although considerable effort has been applied to address this issue\nand much progress has been made on detecting fake news, most existing\napproaches mainly rely on the textual content and/or social context, while\nknowledge-level information---entities extracted from the news content and the\nrelations between them---is much less explored. Within the limited work on\nknowledge-based fake news detection, an external knowledge graph is often\nrequired, which may introduce additional problems: it is quite common for\nentities and relations, especially with respect to new concepts, to be missing\nin existing knowledge graphs, and both entity prediction and link prediction\nare open research questions themselves. Therefore, in this work, we investigate\n\\textbf{knowledge-based fake news detection that does not require any external\nknowledge graph.} Specifically, our contributions include: (1) transforming the\nproblem of detecting fake news into a subgraph classification task---entities\nand relations are extracted from each news item to form a single knowledge\ngraph, where a news item is represented by a subgraph. Then a graph neural\nnetwork (GNN) model is trained to classify each subgraph/news item. (2) Further\nimproving the performance of this model through a simple but effective\nmulti-modal technique that combines extracted knowledge, textual content and\nsocial context. Experiments on multiple datasets with thousands of labelled\nnews items demonstrate that our knowledge-based algorithm outperforms existing\ncounterpart methods, and its performance can be further boosted by the\nmulti-modal approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed the significant damage caused by various types of\nfake news. Although considerable effort has been applied to address this issue\nand much progress has been made on detecting fake news, most existing\napproaches mainly rely on the textual content and/or social context, while\nknowledge-level information---entities extracted from the news content and the\nrelations between them---is much less explored. Within the limited work on\nknowledge-based fake news detection, an external knowledge graph is often\nrequired, which may introduce additional problems: it is quite common for\nentities and relations, especially with respect to new concepts, to be missing\nin existing knowledge graphs, and both entity prediction and link prediction\nare open research questions themselves. Therefore, in this work, we investigate\n\\textbf{knowledge-based fake news detection that does not require any external\nknowledge graph.} Specifically, our contributions include: (1) transforming the\nproblem of detecting fake news into a subgraph classification task---entities\nand relations are extracted from each news item to form a single knowledge\ngraph, where a news item is represented by a subgraph. Then a graph neural\nnetwork (GNN) model is trained to classify each subgraph/news item. (2) Further\nimproving the performance of this model through a simple but effective\nmulti-modal technique that combines extracted knowledge, textual content and\nsocial context. Experiments on multiple datasets with thousands of labelled\nnews items demonstrate that our knowledge-based algorithm outperforms existing\ncounterpart methods, and its performance can be further boosted by the\nmulti-modal approach.'}, 'authors': [{'name': 'Yi Han'}, {'name': 'Amila Silva'}, {'name': 'Ling Luo'}, {'name': 'Shanika Karunasekera'}, {'name': 'Christopher Leckie'}], 'author_detail': {'name': 'Christopher Leckie'}, 'author': 'Christopher Leckie', 'arxiv_comment': '10 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2108.04418v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.04418v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
34,http://arxiv.org/abs/2108.02941v2,2021-08-09 17:23:05+00:00,2021-08-06 04:54:03+00:00,Is it Fake? News Disinformation Detection on South African News Websites,"[arxiv.Result.Author('Harm de Wet'), arxiv.Result.Author('Vukosi Marivate')]","Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.","6 pages, Accepted and to be published in AFRICON 2021",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2108.02941v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.02941v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.02941v2,"{'id': 'http://arxiv.org/abs/2108.02941v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.02941v2', 'updated': '2021-08-09T17:23:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=9, tm_hour=17, tm_min=23, tm_sec=5, tm_wday=0, tm_yday=221, tm_isdst=0), 'published': '2021-08-06T04:54:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=6, tm_hour=4, tm_min=54, tm_sec=3, tm_wday=4, tm_yday=218, tm_isdst=0), 'title': 'Is it Fake? News Disinformation Detection on South African News Websites', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Is it Fake? News Disinformation Detection on South African News Websites'}, 'summary': ""Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning.""}, 'authors': [{'name': 'Harm de Wet'}, {'name': 'Vukosi Marivate'}], 'author_detail': {'name': 'Vukosi Marivate'}, 'author': 'Vukosi Marivate', 'arxiv_comment': '6 pages, Accepted and to be published in AFRICON 2021', 'links': [{'href': 'http://arxiv.org/abs/2108.02941v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.02941v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
35,http://arxiv.org/abs/2108.08264v1,2021-08-04 15:25:32+00:00,2021-08-04 15:25:32+00:00,Fake News and Phishing Detection Using a Machine Learning Trained Expert System,"[arxiv.Result.Author('Benjamin Fitzpatrick'), arxiv.Result.Author('Xinyu ""Sherwin"" Liang'), arxiv.Result.Author('Jeremy Straub')]","Expert systems have been used to enable computers to make recommendations and
decisions. This paper presents the use of a machine learning trained expert
system (MLES) for phishing site detection and fake news detection. Both topics
share a similar goal: to design a rule-fact network that allows a computer to
make explainable decisions like domain experts in each respective area. The
phishing website detection study uses a MLES to detect potential phishing
websites by analyzing site properties (like URL length and expiration time).
The fake news detection study uses a MLES rule-fact network to gauge news story
truthfulness based on factors such as emotion, the speaker's political
affiliation status, and job. The two studies use different MLES network
implementations, which are presented and compared herein. The fake news study
utilized a more linear design while the phishing project utilized a more
complex connection structure. Both networks' inputs are based on commonly
available data sets.",,,,cs.CR,"['cs.CR', 'cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2108.08264v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.08264v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.08264v1,"{'id': 'http://arxiv.org/abs/2108.08264v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.08264v1', 'updated': '2021-08-04T15:25:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=4, tm_hour=15, tm_min=25, tm_sec=32, tm_wday=2, tm_yday=216, tm_isdst=0), 'published': '2021-08-04T15:25:32Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=4, tm_hour=15, tm_min=25, tm_sec=32, tm_wday=2, tm_yday=216, tm_isdst=0), 'title': 'Fake News and Phishing Detection Using a Machine Learning Trained Expert\n  System', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News and Phishing Detection Using a Machine Learning Trained Expert\n  System'}, 'summary': ""Expert systems have been used to enable computers to make recommendations and\ndecisions. This paper presents the use of a machine learning trained expert\nsystem (MLES) for phishing site detection and fake news detection. Both topics\nshare a similar goal: to design a rule-fact network that allows a computer to\nmake explainable decisions like domain experts in each respective area. The\nphishing website detection study uses a MLES to detect potential phishing\nwebsites by analyzing site properties (like URL length and expiration time).\nThe fake news detection study uses a MLES rule-fact network to gauge news story\ntruthfulness based on factors such as emotion, the speaker's political\naffiliation status, and job. The two studies use different MLES network\nimplementations, which are presented and compared herein. The fake news study\nutilized a more linear design while the phishing project utilized a more\ncomplex connection structure. Both networks' inputs are based on commonly\navailable data sets."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Expert systems have been used to enable computers to make recommendations and\ndecisions. This paper presents the use of a machine learning trained expert\nsystem (MLES) for phishing site detection and fake news detection. Both topics\nshare a similar goal: to design a rule-fact network that allows a computer to\nmake explainable decisions like domain experts in each respective area. The\nphishing website detection study uses a MLES to detect potential phishing\nwebsites by analyzing site properties (like URL length and expiration time).\nThe fake news detection study uses a MLES rule-fact network to gauge news story\ntruthfulness based on factors such as emotion, the speaker's political\naffiliation status, and job. The two studies use different MLES network\nimplementations, which are presented and compared herein. The fake news study\nutilized a more linear design while the phishing project utilized a more\ncomplex connection structure. Both networks' inputs are based on commonly\navailable data sets.""}, 'authors': [{'name': 'Benjamin Fitzpatrick'}, {'name': 'Xinyu ""Sherwin"" Liang'}, {'name': 'Jeremy Straub'}], 'author_detail': {'name': 'Jeremy Straub'}, 'author': 'Jeremy Straub', 'links': [{'href': 'http://arxiv.org/abs/2108.08264v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.08264v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
36,http://arxiv.org/abs/2108.01222v2,2021-08-23 04:21:58+00:00,2021-08-03 00:44:55+00:00,The Many Dimensions of Truthfulness: Crowdsourcing Misinformation Assessments on a Multidimensional Scale,"[arxiv.Result.Author('Michael Soprano'), arxiv.Result.Author('Kevin Roitero'), arxiv.Result.Author('David La Barbera'), arxiv.Result.Author('Davide Ceolin'), arxiv.Result.Author('Damiano Spina'), arxiv.Result.Author('Stefano Mizzaro'), arxiv.Result.Author('Gianluca Demartini')]","Recent work has demonstrated the viability of using crowdsourcing as a tool
for evaluating the truthfulness of public statements. Under certain conditions
such as: (1) having a balanced set of workers with different backgrounds and
cognitive abilities; (2) using an adequate set of mechanisms to control the
quality of the collected data; and (3) using a coarse grained assessment scale,
the crowd can provide reliable identification of fake news. However, fake news
are a subtle matter: statements can be just biased (""cherrypicked""), imprecise,
wrong, etc. and the unidimensional truth scale used in existing work cannot
account for such differences. In this paper we propose a multidimensional
notion of truthfulness and we ask the crowd workers to assess seven different
dimensions of truthfulness selected based on existing literature: Correctness,
Neutrality, Comprehensibility, Precision, Completeness, Speaker's
Trustworthiness, and Informativeness. We deploy a set of quality control
mechanisms to ensure that the thousands of assessments collected on 180
publicly available fact-checked statements distributed over two datasets are of
adequate quality, including a custom search engine used by the crowd workers to
find web pages supporting their truthfulness assessments. A comprehensive
analysis of crowdsourced judgments shows that: (1) the crowdsourced assessments
are reliable when compared to an expert-provided gold standard; (2) the
proposed dimensions of truthfulness capture independent pieces of information;
(3) the crowdsourcing task can be easily learned by the workers; and (4) the
resulting assessments provide a useful basis for a more complete estimation of
statement truthfulness.","33 pages; Paper accepted at Information Processing & Management on
  July 28, 2021; IP&M Special Issue on Dis/Misinformation Mining from Social
  Media","Information Processing & Management Information Processing &
  Management, Volume 58, Issue 6, November 2021, 102710",10.1016/j.ipm.2021.102710,cs.IR,"['cs.IR', '68P20', 'H.3']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.ipm.2021.102710', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.01222v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.01222v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.01222v2,"{'id': 'http://arxiv.org/abs/2108.01222v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.01222v2', 'updated': '2021-08-23T04:21:58Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=23, tm_hour=4, tm_min=21, tm_sec=58, tm_wday=0, tm_yday=235, tm_isdst=0), 'published': '2021-08-03T00:44:55Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=3, tm_hour=0, tm_min=44, tm_sec=55, tm_wday=1, tm_yday=215, tm_isdst=0), 'title': 'The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale'}, 'summary': 'Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (""cherrypicked""), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker\'s\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (""cherrypicked""), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker\'s\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.'}, 'authors': [{'name': 'Michael Soprano'}, {'name': 'Kevin Roitero'}, {'name': 'David La Barbera'}, {'name': 'Davide Ceolin'}, {'name': 'Damiano Spina'}, {'name': 'Stefano Mizzaro'}, {'name': 'Gianluca Demartini'}], 'author_detail': {'name': 'Gianluca Demartini'}, 'author': 'Gianluca Demartini', 'arxiv_doi': '10.1016/j.ipm.2021.102710', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.ipm.2021.102710', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.01222v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.01222v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '33 pages; Paper accepted at Information Processing & Management on\n  July 28, 2021; IP&M Special Issue on Dis/Misinformation Mining from Social\n  Media', 'arxiv_journal_ref': 'Information Processing & Management Information Processing &\n  Management, Volume 58, Issue 6, November 2021, 102710', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68P20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
37,http://arxiv.org/abs/2107.12312v1,2021-07-26 16:33:47+00:00,2021-07-26 16:33:47+00:00,"'No, auntie, that's false': Female baby boomers develop critical skills to confront fake news with guidance from relatives","[arxiv.Result.Author('Andrea Pecho-Ninapaytan'), arxiv.Result.Author('Stefany Zambrano-Zuta'), arxiv.Result.Author('Lizardo Vargas-Bianchi')]","The spread of fake news has been increasing, which gives rise to a special
interest in the development of identification and coping skills among news
consumers so that they can filter out misleading information. Studies suggest
that older people share more fake news from social media. There is scarce
literature that analyse how baby boomers behave in the face of fake news. The
purpose of this study is to examine how female baby boomers deal with fake news
on Facebook and their available resources to learn how to identify and handle
dubious information. A qualitative study and thematic analysis were conducted
using information obtained from interviewing female baby boomers. Four themes
emerge from the analysis, revealing that participants recognise that they can
identify fake news but may not always be able to do so due to limitations in
their understanding of an issue or uncertainty about its source. Participants
show participants empirically develop critical identification and filtering
skills with the assistance from close family members.","14 pages, 1 table",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.12312v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.12312v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.12312v1,"{'id': 'http://arxiv.org/abs/2107.12312v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.12312v1', 'updated': '2021-07-26T16:33:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=16, tm_min=33, tm_sec=47, tm_wday=0, tm_yday=207, tm_isdst=0), 'published': '2021-07-26T16:33:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=16, tm_min=33, tm_sec=47, tm_wday=0, tm_yday=207, tm_isdst=0), 'title': ""'No, auntie, that's false': Female baby boomers develop critical skills\n  to confront fake news with guidance from relatives"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""'No, auntie, that's false': Female baby boomers develop critical skills\n  to confront fake news with guidance from relatives""}, 'summary': 'The spread of fake news has been increasing, which gives rise to a special\ninterest in the development of identification and coping skills among news\nconsumers so that they can filter out misleading information. Studies suggest\nthat older people share more fake news from social media. There is scarce\nliterature that analyse how baby boomers behave in the face of fake news. The\npurpose of this study is to examine how female baby boomers deal with fake news\non Facebook and their available resources to learn how to identify and handle\ndubious information. A qualitative study and thematic analysis were conducted\nusing information obtained from interviewing female baby boomers. Four themes\nemerge from the analysis, revealing that participants recognise that they can\nidentify fake news but may not always be able to do so due to limitations in\ntheir understanding of an issue or uncertainty about its source. Participants\nshow participants empirically develop critical identification and filtering\nskills with the assistance from close family members.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of fake news has been increasing, which gives rise to a special\ninterest in the development of identification and coping skills among news\nconsumers so that they can filter out misleading information. Studies suggest\nthat older people share more fake news from social media. There is scarce\nliterature that analyse how baby boomers behave in the face of fake news. The\npurpose of this study is to examine how female baby boomers deal with fake news\non Facebook and their available resources to learn how to identify and handle\ndubious information. A qualitative study and thematic analysis were conducted\nusing information obtained from interviewing female baby boomers. Four themes\nemerge from the analysis, revealing that participants recognise that they can\nidentify fake news but may not always be able to do so due to limitations in\ntheir understanding of an issue or uncertainty about its source. Participants\nshow participants empirically develop critical identification and filtering\nskills with the assistance from close family members.'}, 'authors': [{'name': 'Andrea Pecho-Ninapaytan'}, {'name': 'Stefany Zambrano-Zuta'}, {'name': 'Lizardo Vargas-Bianchi'}], 'author_detail': {'name': 'Lizardo Vargas-Bianchi'}, 'author': 'Lizardo Vargas-Bianchi', 'arxiv_comment': '14 pages, 1 table', 'links': [{'href': 'http://arxiv.org/abs/2107.12312v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.12312v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
38,http://arxiv.org/abs/2107.12073v1,2021-07-26 09:51:54+00:00,2021-07-26 09:51:54+00:00,Uncovering the structure of the French media ecosystem,"[arxiv.Result.Author('Jean-Philippe Cointet'), arxiv.Result.Author('Dominique Cardon'), arxiv.Result.Author('Andreï Mogoutov'), arxiv.Result.Author('Benjamin Ooghe-Tabanou'), arxiv.Result.Author('Guillaume Plique'), arxiv.Result.Author('Pedro Morales')]","This study provides a large-scale mapping of the French media space using
digital methods to estimate political polarization and to study information
circuits. We collect data about the production and circulation of online news
stories in France over the course of one year, adopting a multi-layer
perspective on the media ecosystem. We source our data from websites, Twitter
and Facebook. We also identify a certain number of important structural
features. A stochastic block model of the hyperlinks structure shows the
systematic rejection of counter-informational press in a separate cluster which
hardly receives any attention from the mainstream media. Counter-informational
sub-spaces are also peripheral on the consumption side. We measure their
respective audiences on Twitter and Facebook and do not observe a large
discrepancy between both social networks, with counter-information space, far
right and far left media gathering limited audiences. Finally, we also measure
the ideological distribution of news stories using Twitter data, which also
suggests that the French media landscape is quite balanced. We therefore
conclude that the French media ecosystem does not suffer from the same level of
polarization as the US media ecosystem. The comparison with the American
situation also allows us to consolidate a result from studies on
disinformation: the polarization of the journalistic space and the circulation
of fake news are phenomena that only become more widespread when dominant and
influential actors in the political or journalistic space spread topics and
dubious content originally circulating in the fringe of the information space.","IC2S2, Jul 2021, Zurich, Switzerland",,,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2107.12073v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.12073v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.12073v1,"{'id': 'http://arxiv.org/abs/2107.12073v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.12073v1', 'updated': '2021-07-26T09:51:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=9, tm_min=51, tm_sec=54, tm_wday=0, tm_yday=207, tm_isdst=0), 'published': '2021-07-26T09:51:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=9, tm_min=51, tm_sec=54, tm_wday=0, tm_yday=207, tm_isdst=0), 'title': 'Uncovering the structure of the French media ecosystem', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Uncovering the structure of the French media ecosystem'}, 'summary': 'This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.'}, 'authors': [{'name': 'Jean-Philippe Cointet'}, {'name': 'Dominique Cardon'}, {'name': 'Andreï Mogoutov'}, {'name': 'Benjamin Ooghe-Tabanou'}, {'name': 'Guillaume Plique'}, {'name': 'Pedro Morales'}], 'author_detail': {'name': 'Pedro Morales'}, 'arxiv_affiliation': 'Médialab', 'author': 'Pedro Morales', 'arxiv_comment': 'IC2S2, Jul 2021, Zurich, Switzerland', 'links': [{'href': 'http://arxiv.org/abs/2107.12073v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.12073v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
39,http://arxiv.org/abs/2107.10935v1,2021-07-22 21:32:54+00:00,2021-07-22 21:32:54+00:00,DeepTitle -- Leveraging BERT to generate Search Engine Optimized Headlines,"[arxiv.Result.Author('Cristian Anastasiu'), arxiv.Result.Author('Hanna Behnke'), arxiv.Result.Author('Sarah Lück'), arxiv.Result.Author('Viktor Malesevic'), arxiv.Result.Author('Aamna Najmi'), arxiv.Result.Author('Javier Poveda-Panter')]","Automated headline generation for online news articles is not a trivial task
- machine generated titles need to be grammatically correct, informative,
capture attention and generate search traffic without being ""click baits"" or
""fake news"". In this paper we showcase how a pre-trained language model can be
leveraged to create an abstractive news headline generator for German language.
We incorporate state of the art fine-tuning techniques for abstractive text
summarization, i.e. we use different optimizers for the encoder and decoder
where the former is pre-trained and the latter is trained from scratch. We
modify the headline generation to incorporate frequently sought keywords
relevant for search engine optimization. We conduct experiments on a German
news data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we
address the limitations of ROUGE for measuring the quality of text
summarization by introducing a sentence similarity metric and human evaluation.","9 pages, 4 figures",,,cs.LG,"['cs.LG', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2107.10935v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.10935v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.10935v1,"{'id': 'http://arxiv.org/abs/2107.10935v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.10935v1', 'updated': '2021-07-22T21:32:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=22, tm_hour=21, tm_min=32, tm_sec=54, tm_wday=3, tm_yday=203, tm_isdst=0), 'published': '2021-07-22T21:32:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=22, tm_hour=21, tm_min=32, tm_sec=54, tm_wday=3, tm_yday=203, tm_isdst=0), 'title': 'DeepTitle -- Leveraging BERT to generate Search Engine Optimized\n  Headlines', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DeepTitle -- Leveraging BERT to generate Search Engine Optimized\n  Headlines'}, 'summary': 'Automated headline generation for online news articles is not a trivial task\n- machine generated titles need to be grammatically correct, informative,\ncapture attention and generate search traffic without being ""click baits"" or\n""fake news"". In this paper we showcase how a pre-trained language model can be\nleveraged to create an abstractive news headline generator for German language.\nWe incorporate state of the art fine-tuning techniques for abstractive text\nsummarization, i.e. we use different optimizers for the encoder and decoder\nwhere the former is pre-trained and the latter is trained from scratch. We\nmodify the headline generation to incorporate frequently sought keywords\nrelevant for search engine optimization. We conduct experiments on a German\nnews data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we\naddress the limitations of ROUGE for measuring the quality of text\nsummarization by introducing a sentence similarity metric and human evaluation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automated headline generation for online news articles is not a trivial task\n- machine generated titles need to be grammatically correct, informative,\ncapture attention and generate search traffic without being ""click baits"" or\n""fake news"". In this paper we showcase how a pre-trained language model can be\nleveraged to create an abstractive news headline generator for German language.\nWe incorporate state of the art fine-tuning techniques for abstractive text\nsummarization, i.e. we use different optimizers for the encoder and decoder\nwhere the former is pre-trained and the latter is trained from scratch. We\nmodify the headline generation to incorporate frequently sought keywords\nrelevant for search engine optimization. We conduct experiments on a German\nnews data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we\naddress the limitations of ROUGE for measuring the quality of text\nsummarization by introducing a sentence similarity metric and human evaluation.'}, 'authors': [{'name': 'Cristian Anastasiu'}, {'name': 'Hanna Behnke'}, {'name': 'Sarah Lück'}, {'name': 'Viktor Malesevic'}, {'name': 'Aamna Najmi'}, {'name': 'Javier Poveda-Panter'}], 'author_detail': {'name': 'Javier Poveda-Panter'}, 'author': 'Javier Poveda-Panter', 'arxiv_comment': '9 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2107.10935v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.10935v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
40,http://arxiv.org/abs/2107.09183v2,2021-09-03 19:53:03+00:00,2021-07-19 22:47:17+00:00,Analysis of External Content in the Vaccination Discussion on Twitter,"[arxiv.Result.Author('Richard Kuzma'), arxiv.Result.Author('Iain J. Cruickshank'), arxiv.Result.Author('Kathleen M. Carley')]","The spread of coronavirus and anti-vaccine conspiracies online hindered
public health responses to the pandemic. We examined the content of external
articles shared on Twitter from February to June 2020 to understand how
conspiracy theories and fake news competed with legitimate sources of
information. Examining external content--articles, rather than social media
posts--is a novel methodology that allows for non-social media specific
analysis of misinformation, tracking of changing narratives over time, and
determining which types of resources (government, news, scientific, or dubious)
dominate the pandemic vaccine conversation. We find that distinct narratives
emerge, those narratives change over time, and lack of government and
scientific messaging on coronavirus created an information vacuum filled by
both traditional news and conspiracy theories.",Data Ownership Issues,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2107.09183v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.09183v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.09183v2,"{'id': 'http://arxiv.org/abs/2107.09183v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.09183v2', 'updated': '2021-09-03T19:53:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=3, tm_hour=19, tm_min=53, tm_sec=3, tm_wday=4, tm_yday=246, tm_isdst=0), 'published': '2021-07-19T22:47:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=19, tm_hour=22, tm_min=47, tm_sec=17, tm_wday=0, tm_yday=200, tm_isdst=0), 'title': 'Analysis of External Content in the Vaccination Discussion on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysis of External Content in the Vaccination Discussion on Twitter'}, 'summary': 'The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.'}, 'authors': [{'name': 'Richard Kuzma'}, {'name': 'Iain J. Cruickshank'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_comment': 'Data Ownership Issues', 'links': [{'href': 'http://arxiv.org/abs/2107.09183v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.09183v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
41,http://arxiv.org/abs/2107.07970v1,2021-07-16 15:36:03+00:00,2021-07-16 15:36:03+00:00,How Vulnerable Are Automatic Fake News Detection Methods to Adversarial Attacks?,"[arxiv.Result.Author('Camille Koenders'), arxiv.Result.Author('Johannes Filla'), arxiv.Result.Author('Nicolai Schneider'), arxiv.Result.Author('Vinicius Woloszyn')]","As the spread of false information on the internet has increased dramatically
in recent years, more and more attention is being paid to automated fake news
detection. Some fake news detection methods are already quite successful.
Nevertheless, there are still many vulnerabilities in the detection algorithms.
The reason for this is that fake news publishers can structure and formulate
their texts in such a way that a detection algorithm does not expose this text
as fake news. This paper shows that it is possible to automatically attack
state-of-the-art models that have been trained to detect Fake News, making
these vulnerable. For this purpose, corresponding models were first trained
based on a dataset. Then, using Text-Attack, an attempt was made to manipulate
the trained models in such a way that previously correctly identified fake news
was classified as true news. The results show that it is possible to
automatically bypass Fake News detection mechanisms, leading to implications
concerning existing policy initiatives.","9 pages, Github:
  https://github.com/nicolaischneider/FakeNewsDetectionVulnerability",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.07970v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.07970v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.07970v1,"{'id': 'http://arxiv.org/abs/2107.07970v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.07970v1', 'updated': '2021-07-16T15:36:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=16, tm_hour=15, tm_min=36, tm_sec=3, tm_wday=4, tm_yday=197, tm_isdst=0), 'published': '2021-07-16T15:36:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=16, tm_hour=15, tm_min=36, tm_sec=3, tm_wday=4, tm_yday=197, tm_isdst=0), 'title': 'How Vulnerable Are Automatic Fake News Detection Methods to Adversarial\n  Attacks?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How Vulnerable Are Automatic Fake News Detection Methods to Adversarial\n  Attacks?'}, 'summary': 'As the spread of false information on the internet has increased dramatically\nin recent years, more and more attention is being paid to automated fake news\ndetection. Some fake news detection methods are already quite successful.\nNevertheless, there are still many vulnerabilities in the detection algorithms.\nThe reason for this is that fake news publishers can structure and formulate\ntheir texts in such a way that a detection algorithm does not expose this text\nas fake news. This paper shows that it is possible to automatically attack\nstate-of-the-art models that have been trained to detect Fake News, making\nthese vulnerable. For this purpose, corresponding models were first trained\nbased on a dataset. Then, using Text-Attack, an attempt was made to manipulate\nthe trained models in such a way that previously correctly identified fake news\nwas classified as true news. The results show that it is possible to\nautomatically bypass Fake News detection mechanisms, leading to implications\nconcerning existing policy initiatives.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the spread of false information on the internet has increased dramatically\nin recent years, more and more attention is being paid to automated fake news\ndetection. Some fake news detection methods are already quite successful.\nNevertheless, there are still many vulnerabilities in the detection algorithms.\nThe reason for this is that fake news publishers can structure and formulate\ntheir texts in such a way that a detection algorithm does not expose this text\nas fake news. This paper shows that it is possible to automatically attack\nstate-of-the-art models that have been trained to detect Fake News, making\nthese vulnerable. For this purpose, corresponding models were first trained\nbased on a dataset. Then, using Text-Attack, an attempt was made to manipulate\nthe trained models in such a way that previously correctly identified fake news\nwas classified as true news. The results show that it is possible to\nautomatically bypass Fake News detection mechanisms, leading to implications\nconcerning existing policy initiatives.'}, 'authors': [{'name': 'Camille Koenders'}, {'name': 'Johannes Filla'}, {'name': 'Nicolai Schneider'}, {'name': 'Vinicius Woloszyn'}], 'author_detail': {'name': 'Vinicius Woloszyn'}, 'author': 'Vinicius Woloszyn', 'arxiv_comment': '9 pages, Github:\n  https://github.com/nicolaischneider/FakeNewsDetectionVulnerability', 'links': [{'href': 'http://arxiv.org/abs/2107.07970v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.07970v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
42,http://arxiv.org/abs/2107.06796v1,2021-07-14 15:52:15+00:00,2021-07-14 15:52:15+00:00,Indonesia's Fake News Detection using Transformer Network,"[arxiv.Result.Author('Aisyah Awalina'), arxiv.Result.Author('Jibran Fawaid'), arxiv.Result.Author('Rifky Yunus Krisnabayu'), arxiv.Result.Author('Novanto Yudistira')]","Fake news is a problem faced by society in this era. It is not rare for fake
news to cause provocation and problem for the people. Indonesia, as a country
with the 4th largest population, has a problem in dealing with fake news. More
than 30% of rural and urban population are deceived by this fake news problem.
As we have been studying, there is only few literatures on preventing the
spread of fake news in Bahasa Indonesia. So, this research is conducted to
prevent these problems. The dataset used in this research was obtained from a
news portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on
this page, we got 1116 data consisting of valid news and fake news. The dataset
can be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This
dataset will be combined with other available datasets. The methods used are
CNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This
research shows that the BERT method with Transformer Network has the best
results with an accuracy of up to 90%.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2107.06796v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.06796v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.06796v1,"{'id': 'http://arxiv.org/abs/2107.06796v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.06796v1', 'updated': '2021-07-14T15:52:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=14, tm_hour=15, tm_min=52, tm_sec=15, tm_wday=2, tm_yday=195, tm_isdst=0), 'published': '2021-07-14T15:52:15Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=14, tm_hour=15, tm_min=52, tm_sec=15, tm_wday=2, tm_yday=195, tm_isdst=0), 'title': ""Indonesia's Fake News Detection using Transformer Network"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Indonesia's Fake News Detection using Transformer Network""}, 'summary': 'Fake news is a problem faced by society in this era. It is not rare for fake\nnews to cause provocation and problem for the people. Indonesia, as a country\nwith the 4th largest population, has a problem in dealing with fake news. More\nthan 30% of rural and urban population are deceived by this fake news problem.\nAs we have been studying, there is only few literatures on preventing the\nspread of fake news in Bahasa Indonesia. So, this research is conducted to\nprevent these problems. The dataset used in this research was obtained from a\nnews portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on\nthis page, we got 1116 data consisting of valid news and fake news. The dataset\ncan be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This\ndataset will be combined with other available datasets. The methods used are\nCNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This\nresearch shows that the BERT method with Transformer Network has the best\nresults with an accuracy of up to 90%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news is a problem faced by society in this era. It is not rare for fake\nnews to cause provocation and problem for the people. Indonesia, as a country\nwith the 4th largest population, has a problem in dealing with fake news. More\nthan 30% of rural and urban population are deceived by this fake news problem.\nAs we have been studying, there is only few literatures on preventing the\nspread of fake news in Bahasa Indonesia. So, this research is conducted to\nprevent these problems. The dataset used in this research was obtained from a\nnews portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on\nthis page, we got 1116 data consisting of valid news and fake news. The dataset\ncan be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This\ndataset will be combined with other available datasets. The methods used are\nCNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This\nresearch shows that the BERT method with Transformer Network has the best\nresults with an accuracy of up to 90%.'}, 'authors': [{'name': 'Aisyah Awalina'}, {'name': 'Jibran Fawaid'}, {'name': 'Rifky Yunus Krisnabayu'}, {'name': 'Novanto Yudistira'}], 'author_detail': {'name': 'Novanto Yudistira'}, 'author': 'Novanto Yudistira', 'links': [{'href': 'http://arxiv.org/abs/2107.06796v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.06796v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
43,http://arxiv.org/abs/2107.06051v2,2021-07-14 10:51:41+00:00,2021-07-13 13:05:11+00:00,Rating Facts under Coarse-to-fine Regimes,[arxiv.Result.Author('Guojun Wu')],"The rise of manipulating fake news as a political weapon has become a global
concern and highlighted the incapability of manually fact checking against
rapidly produced fake news. Thus, statistical approaches are required if we are
to address this problem efficiently. The shortage of publicly available
datasets is one major bottleneck of automated fact checking. To remedy this, we
collected 24K manually rated statements from PolitiFact. The class values
exhibit a natural order with respect to truthfulness as shown in Table 1. Thus,
our task represents a twist from standard classification, due to the various
degrees of similarity between classes. To investigate this, we defined
coarse-to-fine classification regimes, which presents new challenge for
classification. To address this, we propose BERT-based models. After training,
class similarity is sensible over the multi-class datasets, especially in the
fine-grained one. Under all the regimes, BERT achieves state of the art, while
the additional layers provide insignificant improvement.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.06051v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.06051v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.06051v2,"{'id': 'http://arxiv.org/abs/2107.06051v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.06051v2', 'updated': '2021-07-14T10:51:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=14, tm_hour=10, tm_min=51, tm_sec=41, tm_wday=2, tm_yday=195, tm_isdst=0), 'published': '2021-07-13T13:05:11Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=13, tm_hour=13, tm_min=5, tm_sec=11, tm_wday=1, tm_yday=194, tm_isdst=0), 'title': 'Rating Facts under Coarse-to-fine Regimes', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Rating Facts under Coarse-to-fine Regimes'}, 'summary': 'The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.'}, 'authors': [{'name': 'Guojun Wu'}], 'author_detail': {'name': 'Guojun Wu'}, 'author': 'Guojun Wu', 'links': [{'href': 'http://arxiv.org/abs/2107.06051v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.06051v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
44,http://arxiv.org/abs/2107.03766v1,2021-07-08 11:24:50+00:00,2021-07-08 11:24:50+00:00,Exploring the effect of social media and spatial characteristics during the COVID-19 pandemic in China,"[arxiv.Result.Author('Xiu-Xiu Zhan'), arxiv.Result.Author('Kaiyue Zhang'), arxiv.Result.Author('Lun Ge'), arxiv.Result.Author('Junming Huang'), arxiv.Result.Author('Zinan Zhang'), arxiv.Result.Author('Lu Wei'), arxiv.Result.Author('Gui-Quan Sun'), arxiv.Result.Author('Chuang Liu'), arxiv.Result.Author('Zi-Ke Zhang')]","The declaration of COVID-19 as a pandemic has largely amplified the spread of
related information on social media, such as Twitter, Facebook, and
WeChat.Unlike the previous studies which focused on how to detect the
misinformation or fake news related toCOVID-19, we investigate how the disease
and information co-evolve in the population. We focus onCOVID-19and its
information during the period when the disease was widely spread in China,
i.e., from January 25th to March 24th, 2020. We first explore how the disease
and information co-evolve via the spatial analysis of the two spreading
processes. We visualize the geo-location of both disease and information at the
province level and find that disease is more geo-localized compared to
information. We find a high correlation between the disease and information
data, and also people care about the spread only when it comes to their
neighborhood. Regard to the content of the information, we find that positive
messages are more negatively correlated with the disease compared to negative
and neutral messages. Additionally, we introduce machine learning algorithms,
i.e., linear regression and random forest, to further predict the number of
infected using different disease spatial related and information-related
characteristics. We obtain that the disease spatial related characteristics of
nearby cities can help to improve the prediction accuracy. Meanwhile,
information-related characteristics can also help to improve the prediction
performance, but with a delay, i.e., the improvement comes from using, for
instance, the number of messages 10 days ago, for disease prediction. The
methodology proposed in this paper may shed light on new clues of emerging
infections",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.03766v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.03766v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.03766v1,"{'id': 'http://arxiv.org/abs/2107.03766v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.03766v1', 'updated': '2021-07-08T11:24:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=8, tm_hour=11, tm_min=24, tm_sec=50, tm_wday=3, tm_yday=189, tm_isdst=0), 'published': '2021-07-08T11:24:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=8, tm_hour=11, tm_min=24, tm_sec=50, tm_wday=3, tm_yday=189, tm_isdst=0), 'title': 'Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China'}, 'summary': 'The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections'}, 'authors': [{'name': 'Xiu-Xiu Zhan'}, {'name': 'Kaiyue Zhang'}, {'name': 'Lun Ge'}, {'name': 'Junming Huang'}, {'name': 'Zinan Zhang'}, {'name': 'Lu Wei'}, {'name': 'Gui-Quan Sun'}, {'name': 'Chuang Liu'}, {'name': 'Zi-Ke Zhang'}], 'author_detail': {'name': 'Zi-Ke Zhang'}, 'author': 'Zi-Ke Zhang', 'links': [{'href': 'http://arxiv.org/abs/2107.03766v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.03766v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
45,http://arxiv.org/abs/2107.02775v1,2021-07-06 17:37:56+00:00,2021-07-06 17:37:56+00:00,Countering Misinformation on Social Media Through Educational Interventions: Evidence from a Randomized Experiment in Pakistan,"[arxiv.Result.Author('Ayesha Ali'), arxiv.Result.Author('Ihsan Ayyub Qazi')]","Fake news is a growing problem in developing countries with potentially
far-reaching consequences. We conduct a randomized experiment in urban Pakistan
to evaluate the effectiveness of two educational interventions to counter
misinformation among low-digital literacy populations. We do not find a
significant effect of video-based general educational messages about
misinformation. However, when such messages are augmented with personalized
feedback based on individuals' past engagement with fake news, we find an
improvement of 0.14 standard deviations in identifying fake news. We also find
negative but insignificant effects on identifying true news, driven by female
respondents. Our results suggest that educational interventions can enable
information discernment but their effectiveness critically depends on how well
their features and delivery are customized for the population of interest.",,,,econ.GN,"['econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/2107.02775v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.02775v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.02775v1,"{'id': 'http://arxiv.org/abs/2107.02775v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.02775v1', 'updated': '2021-07-06T17:37:56Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=17, tm_min=37, tm_sec=56, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2021-07-06T17:37:56Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=17, tm_min=37, tm_sec=56, tm_wday=1, tm_yday=187, tm_isdst=0), 'title': 'Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan'}, 'summary': ""Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest.""}, 'authors': [{'name': 'Ayesha Ali'}, {'name': 'Ihsan Ayyub Qazi'}], 'author_detail': {'name': 'Ihsan Ayyub Qazi'}, 'author': 'Ihsan Ayyub Qazi', 'links': [{'href': 'http://arxiv.org/abs/2107.02775v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.02775v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
46,http://arxiv.org/abs/2107.01651v2,2021-07-06 07:29:01+00:00,2021-07-04 14:37:17+00:00,The hidden dependence of spreading vulnerability on topological complexity,"[arxiv.Result.Author('Mark M. Dekker'), arxiv.Result.Author('Raoul D. Schram'), arxiv.Result.Author('Jiamin Ou'), arxiv.Result.Author('Debabrata Panja')]","Many dynamical phenomena, e.g., pathogen transmission, disruptions in
transport over networks, and (fake) news purveyance, concern spreading that
plays out on top of networks with changing architectures over time - commonly
known as temporal networks. Assessing a system's proneness to facilitate
spreading phenomena, which we refer to as its spreading vulnerability, from its
topological information alone remains a challenging task. We report a
methodological advance in terms of a novel metric for topological complexity:
'entanglement entropy'. Using publicly available datasets, we demonstrate that
the metric naturally allows for topological comparisons across vastly different
systems, and importantly, reveals that the spreading vulnerability of a system
can be quantitatively related to its topological complexity. In doing so, the
metric opens itself for applications in a wide variety of natural, social,
biological and engineered systems.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.01651v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.01651v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.01651v2,"{'id': 'http://arxiv.org/abs/2107.01651v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.01651v2', 'updated': '2021-07-06T07:29:01Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=7, tm_min=29, tm_sec=1, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2021-07-04T14:37:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=4, tm_hour=14, tm_min=37, tm_sec=17, tm_wday=6, tm_yday=185, tm_isdst=0), 'title': 'The hidden dependence of spreading vulnerability on topological\n  complexity', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The hidden dependence of spreading vulnerability on topological\n  complexity'}, 'summary': ""Many dynamical phenomena, e.g., pathogen transmission, disruptions in\ntransport over networks, and (fake) news purveyance, concern spreading that\nplays out on top of networks with changing architectures over time - commonly\nknown as temporal networks. Assessing a system's proneness to facilitate\nspreading phenomena, which we refer to as its spreading vulnerability, from its\ntopological information alone remains a challenging task. We report a\nmethodological advance in terms of a novel metric for topological complexity:\n'entanglement entropy'. Using publicly available datasets, we demonstrate that\nthe metric naturally allows for topological comparisons across vastly different\nsystems, and importantly, reveals that the spreading vulnerability of a system\ncan be quantitatively related to its topological complexity. In doing so, the\nmetric opens itself for applications in a wide variety of natural, social,\nbiological and engineered systems."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Many dynamical phenomena, e.g., pathogen transmission, disruptions in\ntransport over networks, and (fake) news purveyance, concern spreading that\nplays out on top of networks with changing architectures over time - commonly\nknown as temporal networks. Assessing a system's proneness to facilitate\nspreading phenomena, which we refer to as its spreading vulnerability, from its\ntopological information alone remains a challenging task. We report a\nmethodological advance in terms of a novel metric for topological complexity:\n'entanglement entropy'. Using publicly available datasets, we demonstrate that\nthe metric naturally allows for topological comparisons across vastly different\nsystems, and importantly, reveals that the spreading vulnerability of a system\ncan be quantitatively related to its topological complexity. In doing so, the\nmetric opens itself for applications in a wide variety of natural, social,\nbiological and engineered systems.""}, 'authors': [{'name': 'Mark M. Dekker'}, {'name': 'Raoul D. Schram'}, {'name': 'Jiamin Ou'}, {'name': 'Debabrata Panja'}], 'author_detail': {'name': 'Debabrata Panja'}, 'author': 'Debabrata Panja', 'links': [{'href': 'http://arxiv.org/abs/2107.01651v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.01651v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
47,http://arxiv.org/abs/2107.10648v1,2021-07-04 07:09:59+00:00,2021-07-04 07:09:59+00:00,DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection,"[arxiv.Result.Author('Mohit Mayank'), arxiv.Result.Author('Shakshi Sharma'), arxiv.Result.Author('Rajesh Sharma')]","Fake News on social media platforms has attracted a lot of attention in
recent times, primarily for events related to politics (2016 US Presidential
elections), healthcare (infodemic during COVID-19), to name a few. Various
methods have been proposed for detecting Fake News. The approaches span from
exploiting techniques related to network analysis, Natural Language Processing
(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose
DEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying
Fake News. Our approach is a combination of the NLP -- where we encode the news
content, and the GNN technique -- where we encode the Knowledge Graph (KG). A
variety of these encodings provides a complementary advantage to our detector.
We evaluate our framework using two publicly available datasets containing
articles from domains such as politics, business, technology, and healthcare.
As part of dataset pre-processing, we also remove the bias, such as the source
of the articles, which could impact the performance of the models. DEAP-FAKED
obtains an F1-score of 88% and 78% for the two datasets, which is an
improvement of 21%, and 3% respectively, which shows the effectiveness of the
approach.",8,,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.10648v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.10648v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.10648v1,"{'id': 'http://arxiv.org/abs/2107.10648v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.10648v1', 'updated': '2021-07-04T07:09:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=4, tm_hour=7, tm_min=9, tm_sec=59, tm_wday=6, tm_yday=185, tm_isdst=0), 'published': '2021-07-04T07:09:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=4, tm_hour=7, tm_min=9, tm_sec=59, tm_wday=6, tm_yday=185, tm_isdst=0), 'title': 'DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection'}, 'summary': 'Fake News on social media platforms has attracted a lot of attention in\nrecent times, primarily for events related to politics (2016 US Presidential\nelections), healthcare (infodemic during COVID-19), to name a few. Various\nmethods have been proposed for detecting Fake News. The approaches span from\nexploiting techniques related to network analysis, Natural Language Processing\n(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose\nDEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying\nFake News. Our approach is a combination of the NLP -- where we encode the news\ncontent, and the GNN technique -- where we encode the Knowledge Graph (KG). A\nvariety of these encodings provides a complementary advantage to our detector.\nWe evaluate our framework using two publicly available datasets containing\narticles from domains such as politics, business, technology, and healthcare.\nAs part of dataset pre-processing, we also remove the bias, such as the source\nof the articles, which could impact the performance of the models. DEAP-FAKED\nobtains an F1-score of 88% and 78% for the two datasets, which is an\nimprovement of 21%, and 3% respectively, which shows the effectiveness of the\napproach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News on social media platforms has attracted a lot of attention in\nrecent times, primarily for events related to politics (2016 US Presidential\nelections), healthcare (infodemic during COVID-19), to name a few. Various\nmethods have been proposed for detecting Fake News. The approaches span from\nexploiting techniques related to network analysis, Natural Language Processing\n(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose\nDEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying\nFake News. Our approach is a combination of the NLP -- where we encode the news\ncontent, and the GNN technique -- where we encode the Knowledge Graph (KG). A\nvariety of these encodings provides a complementary advantage to our detector.\nWe evaluate our framework using two publicly available datasets containing\narticles from domains such as politics, business, technology, and healthcare.\nAs part of dataset pre-processing, we also remove the bias, such as the source\nof the articles, which could impact the performance of the models. DEAP-FAKED\nobtains an F1-score of 88% and 78% for the two datasets, which is an\nimprovement of 21%, and 3% respectively, which shows the effectiveness of the\napproach.'}, 'authors': [{'name': 'Mohit Mayank'}, {'name': 'Shakshi Sharma'}, {'name': 'Rajesh Sharma'}], 'author_detail': {'name': 'Rajesh Sharma'}, 'author': 'Rajesh Sharma', 'arxiv_comment': '8', 'links': [{'href': 'http://arxiv.org/abs/2107.10648v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.10648v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
48,http://arxiv.org/abs/2107.01443v1,2021-07-03 14:21:34+00:00,2021-07-03 14:21:34+00:00,Quantifying agent impacts on contact sequences in social interactions,"[arxiv.Result.Author('Mark M. Dekker'), arxiv.Result.Author('Tessa F. Blanken'), arxiv.Result.Author('Fabian Dablander'), arxiv.Result.Author('Jiamin Ou'), arxiv.Result.Author('Denny Borsboom'), arxiv.Result.Author('Debabrata Panja')]","Human social behavior plays a crucial role in how pathogens like SARS-CoV-2
or fake news spread in a population. Social interactions determine the contact
network among individuals, while spreading, requiring individual-to-individual
transmission, takes place on top of the network. Studying the topological
aspects of a contact network, therefore, not only has the potential of leading
to valuable insights into how the behavior of individuals impacts spreading
phenomena, but it may also open up possibilities for devising effective
behavioral interventions. Because of the temporal nature of interactions -
since the topology of the network, containing who is in contact with whom,
when, for how long, and in which precise sequence, varies (rapidly) in time -
analyzing them requires developing network methods and metrics that respect
temporal variability, in contrast to those developed for static (i.e.,
time-invariant) networks. Here, by means of event mapping, we propose a method
to quantify how quickly agents mingle by transforming temporal network data of
agent contacts. We define a novel measure called 'contact sequence centrality',
which quantifies the impact of an individual on the contact sequences,
reflecting the individual's behavioral potential for spreading. Comparing
contact sequence centrality across agents allows for ranking the impact of
agents and identifying potential 'behavioral super-spreaders'. The method is
applied to social interaction data collected at an art fair in Amsterdam. We
relate the measure to the existing network metrics, both temporal and static,
and find that (mostly at longer time scales) traditional metrics lose their
resemblance to contact sequence centrality. Our work highlights the importance
of accounting for the sequential nature of contacts when analyzing social
interactions.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.01443v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.01443v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.01443v1,"{'id': 'http://arxiv.org/abs/2107.01443v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.01443v1', 'updated': '2021-07-03T14:21:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=3, tm_hour=14, tm_min=21, tm_sec=34, tm_wday=5, tm_yday=184, tm_isdst=0), 'published': '2021-07-03T14:21:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=3, tm_hour=14, tm_min=21, tm_sec=34, tm_wday=5, tm_yday=184, tm_isdst=0), 'title': 'Quantifying agent impacts on contact sequences in social interactions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Quantifying agent impacts on contact sequences in social interactions'}, 'summary': ""Human social behavior plays a crucial role in how pathogens like SARS-CoV-2\nor fake news spread in a population. Social interactions determine the contact\nnetwork among individuals, while spreading, requiring individual-to-individual\ntransmission, takes place on top of the network. Studying the topological\naspects of a contact network, therefore, not only has the potential of leading\nto valuable insights into how the behavior of individuals impacts spreading\nphenomena, but it may also open up possibilities for devising effective\nbehavioral interventions. Because of the temporal nature of interactions -\nsince the topology of the network, containing who is in contact with whom,\nwhen, for how long, and in which precise sequence, varies (rapidly) in time -\nanalyzing them requires developing network methods and metrics that respect\ntemporal variability, in contrast to those developed for static (i.e.,\ntime-invariant) networks. Here, by means of event mapping, we propose a method\nto quantify how quickly agents mingle by transforming temporal network data of\nagent contacts. We define a novel measure called 'contact sequence centrality',\nwhich quantifies the impact of an individual on the contact sequences,\nreflecting the individual's behavioral potential for spreading. Comparing\ncontact sequence centrality across agents allows for ranking the impact of\nagents and identifying potential 'behavioral super-spreaders'. The method is\napplied to social interaction data collected at an art fair in Amsterdam. We\nrelate the measure to the existing network metrics, both temporal and static,\nand find that (mostly at longer time scales) traditional metrics lose their\nresemblance to contact sequence centrality. Our work highlights the importance\nof accounting for the sequential nature of contacts when analyzing social\ninteractions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Human social behavior plays a crucial role in how pathogens like SARS-CoV-2\nor fake news spread in a population. Social interactions determine the contact\nnetwork among individuals, while spreading, requiring individual-to-individual\ntransmission, takes place on top of the network. Studying the topological\naspects of a contact network, therefore, not only has the potential of leading\nto valuable insights into how the behavior of individuals impacts spreading\nphenomena, but it may also open up possibilities for devising effective\nbehavioral interventions. Because of the temporal nature of interactions -\nsince the topology of the network, containing who is in contact with whom,\nwhen, for how long, and in which precise sequence, varies (rapidly) in time -\nanalyzing them requires developing network methods and metrics that respect\ntemporal variability, in contrast to those developed for static (i.e.,\ntime-invariant) networks. Here, by means of event mapping, we propose a method\nto quantify how quickly agents mingle by transforming temporal network data of\nagent contacts. We define a novel measure called 'contact sequence centrality',\nwhich quantifies the impact of an individual on the contact sequences,\nreflecting the individual's behavioral potential for spreading. Comparing\ncontact sequence centrality across agents allows for ranking the impact of\nagents and identifying potential 'behavioral super-spreaders'. The method is\napplied to social interaction data collected at an art fair in Amsterdam. We\nrelate the measure to the existing network metrics, both temporal and static,\nand find that (mostly at longer time scales) traditional metrics lose their\nresemblance to contact sequence centrality. Our work highlights the importance\nof accounting for the sequential nature of contacts when analyzing social\ninteractions.""}, 'authors': [{'name': 'Mark M. Dekker'}, {'name': 'Tessa F. Blanken'}, {'name': 'Fabian Dablander'}, {'name': 'Jiamin Ou'}, {'name': 'Denny Borsboom'}, {'name': 'Debabrata Panja'}], 'author_detail': {'name': 'Debabrata Panja'}, 'author': 'Debabrata Panja', 'links': [{'href': 'http://arxiv.org/abs/2107.01443v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.01443v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
49,http://arxiv.org/abs/2107.02012v1,2021-07-01 11:07:47+00:00,2021-07-01 11:07:47+00:00,Tackling COVID-19 Infodemic using Deep Learning,"[arxiv.Result.Author('Prathmesh Pathwar'), arxiv.Result.Author('Simran Gill')]","Humanity is battling one of the most deleterious virus in modern history, the
COVID-19 pandemic, but along with the pandemic there's an infodemic permeating
the pupil and society with misinformation which exacerbates the current malady.
We try to detect and classify fake news on online media to detect fake
information relating to COVID-19 and coronavirus. The dataset contained fake
posts, articles and news gathered from fact checking websites like politifact
whereas real tweets were taken from verified twitter handles. We incorporated
multiple conventional classification techniques like Naive Bayes, KNN, Gradient
Boost and Random Forest along with Deep learning approaches, specifically CNN,
RNN, DNN and the ensemble model RMDL. We analyzed these approaches with two
feature extraction techniques, TF-IDF and GloVe Word Embeddings which would
provide deeper insights into the dataset containing COVID-19 info on online
media.","15 pages, 4 figures, Accepted in 4th International Conference on
  Computational Intelligence and Data Engineering",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2107.02012v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.02012v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.02012v1,"{'id': 'http://arxiv.org/abs/2107.02012v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.02012v1', 'updated': '2021-07-01T11:07:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=1, tm_hour=11, tm_min=7, tm_sec=47, tm_wday=3, tm_yday=182, tm_isdst=0), 'published': '2021-07-01T11:07:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=1, tm_hour=11, tm_min=7, tm_sec=47, tm_wday=3, tm_yday=182, tm_isdst=0), 'title': 'Tackling COVID-19 Infodemic using Deep Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tackling COVID-19 Infodemic using Deep Learning'}, 'summary': ""Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.""}, 'authors': [{'name': 'Prathmesh Pathwar'}, {'name': 'Simran Gill'}], 'author_detail': {'name': 'Simran Gill'}, 'author': 'Simran Gill', 'arxiv_comment': '15 pages, 4 figures, Accepted in 4th International Conference on\n  Computational Intelligence and Data Engineering', 'links': [{'href': 'http://arxiv.org/abs/2107.02012v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.02012v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
50,http://arxiv.org/abs/2107.00153v2,2021-07-14 23:30:49+00:00,2021-07-01 00:11:04+00:00,Root and community inference on the latent growth process of a network using noisy attachment models,"[arxiv.Result.Author('Harry Crane'), arxiv.Result.Author('Min Xu')]","We introduce the PAPER (Preferential Attachment Plus Erd\H{o}s--R\'{e}nyi)
model for random networks, where we let a random network G be the union of a
preferential attachment (PA) tree T and additional Erd\H{o}s--R\'{e}nyi (ER)
random edges. The PA tree component captures the fact that real world networks
often have an underlying growth/recruitment process where vertices and edges
are added sequentially, while the ER component can be regarded as random noise.
Given only a single snapshot of the final network G, we study the problem of
constructing confidence sets for the early history, in particular the root
node, of the unobserved growth process; the root node can be patient zero in a
disease infection network or the source of fake news in a social media network.
We propose an inference algorithm based on Gibbs sampling that scales to
networks with millions of nodes and provide theoretical analysis showing that
the expected size of the confidence set is small so long as the noise level of
the ER edges is not too large. We also propose variations of the model in which
multiple growth processes occur simultaneously, reflecting the growth of
multiple communities, and we use these models to provide a new approach
community detection.",52 pages; 20 figures,,,stat.ME,"['stat.ME', 'math.PR', 'stat.CO', '62M99, 05C80']","[arxiv.Result.Link('http://arxiv.org/abs/2107.00153v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.00153v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.00153v2,"{'id': 'http://arxiv.org/abs/2107.00153v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.00153v2', 'updated': '2021-07-14T23:30:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=14, tm_hour=23, tm_min=30, tm_sec=49, tm_wday=2, tm_yday=195, tm_isdst=0), 'published': '2021-07-01T00:11:04Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=1, tm_hour=0, tm_min=11, tm_sec=4, tm_wday=3, tm_yday=182, tm_isdst=0), 'title': 'Root and community inference on the latent growth process of a network\n  using noisy attachment models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Root and community inference on the latent growth process of a network\n  using noisy attachment models'}, 'summary': ""We introduce the PAPER (Preferential Attachment Plus Erd\\H{o}s--R\\'{e}nyi)\nmodel for random networks, where we let a random network G be the union of a\npreferential attachment (PA) tree T and additional Erd\\H{o}s--R\\'{e}nyi (ER)\nrandom edges. The PA tree component captures the fact that real world networks\noften have an underlying growth/recruitment process where vertices and edges\nare added sequentially, while the ER component can be regarded as random noise.\nGiven only a single snapshot of the final network G, we study the problem of\nconstructing confidence sets for the early history, in particular the root\nnode, of the unobserved growth process; the root node can be patient zero in a\ndisease infection network or the source of fake news in a social media network.\nWe propose an inference algorithm based on Gibbs sampling that scales to\nnetworks with millions of nodes and provide theoretical analysis showing that\nthe expected size of the confidence set is small so long as the noise level of\nthe ER edges is not too large. We also propose variations of the model in which\nmultiple growth processes occur simultaneously, reflecting the growth of\nmultiple communities, and we use these models to provide a new approach\ncommunity detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We introduce the PAPER (Preferential Attachment Plus Erd\\H{o}s--R\\'{e}nyi)\nmodel for random networks, where we let a random network G be the union of a\npreferential attachment (PA) tree T and additional Erd\\H{o}s--R\\'{e}nyi (ER)\nrandom edges. The PA tree component captures the fact that real world networks\noften have an underlying growth/recruitment process where vertices and edges\nare added sequentially, while the ER component can be regarded as random noise.\nGiven only a single snapshot of the final network G, we study the problem of\nconstructing confidence sets for the early history, in particular the root\nnode, of the unobserved growth process; the root node can be patient zero in a\ndisease infection network or the source of fake news in a social media network.\nWe propose an inference algorithm based on Gibbs sampling that scales to\nnetworks with millions of nodes and provide theoretical analysis showing that\nthe expected size of the confidence set is small so long as the noise level of\nthe ER edges is not too large. We also propose variations of the model in which\nmultiple growth processes occur simultaneously, reflecting the growth of\nmultiple communities, and we use these models to provide a new approach\ncommunity detection.""}, 'authors': [{'name': 'Harry Crane'}, {'name': 'Min Xu'}], 'author_detail': {'name': 'Min Xu'}, 'author': 'Min Xu', 'arxiv_comment': '52 pages; 20 figures', 'links': [{'href': 'http://arxiv.org/abs/2107.00153v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.00153v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '62M99, 05C80', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
51,http://arxiv.org/abs/2106.14490v1,2021-06-28 09:09:14+00:00,2021-06-28 09:09:14+00:00,Making Images Real Again: A Comprehensive Survey on Deep Image Composition,"[arxiv.Result.Author('Li Niu'), arxiv.Result.Author('Wenyan Cong'), arxiv.Result.Author('Liu Liu'), arxiv.Result.Author('Yan Hong'), arxiv.Result.Author('Bo Zhang'), arxiv.Result.Author('Jing Liang'), arxiv.Result.Author('Liqing Zhang')]","As a common image editing operation, image composition aims to cut the
foreground from one image and paste it on another image, resulting in a
composite image. However, there are many issues that could make the composite
images unrealistic. These issues can be summarized as the inconsistency between
foreground and background, which include appearance inconsistency (e.g.,
incompatible color and illumination) and geometry inconsistency (e.g.,
unreasonable size and location). Previous works on image composition target at
one or more issues. Since each individual issue is a complicated problem, there
are some research directions (e.g., image harmonization, object placement)
which focus on only one issue. By putting all the efforts together, we can
acquire realistic composite images. Sometimes, we expect the composite images
to be not only realistic but also aesthetic, in which case aesthetic evaluation
needs to be considered. In this survey, we summarize the datasets and methods
for the above research directions. We also discuss the limitations and
potential directions to facilitate the future research for image composition.
Finally, as a double-edged sword, image composition may also have negative
effect on our lives (e.g., fake news) and thus it is imperative to develop
algorithms to fight against composite images. Datasets and codes for image
composition are summarized at
https://github.com/bcmi/Awesome-Image-Composition.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.14490v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.14490v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.14490v1,"{'id': 'http://arxiv.org/abs/2106.14490v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.14490v1', 'updated': '2021-06-28T09:09:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=28, tm_hour=9, tm_min=9, tm_sec=14, tm_wday=0, tm_yday=179, tm_isdst=0), 'published': '2021-06-28T09:09:14Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=28, tm_hour=9, tm_min=9, tm_sec=14, tm_wday=0, tm_yday=179, tm_isdst=0), 'title': 'Making Images Real Again: A Comprehensive Survey on Deep Image\n  Composition', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Making Images Real Again: A Comprehensive Survey on Deep Image\n  Composition'}, 'summary': 'As a common image editing operation, image composition aims to cut the\nforeground from one image and paste it on another image, resulting in a\ncomposite image. However, there are many issues that could make the composite\nimages unrealistic. These issues can be summarized as the inconsistency between\nforeground and background, which include appearance inconsistency (e.g.,\nincompatible color and illumination) and geometry inconsistency (e.g.,\nunreasonable size and location). Previous works on image composition target at\none or more issues. Since each individual issue is a complicated problem, there\nare some research directions (e.g., image harmonization, object placement)\nwhich focus on only one issue. By putting all the efforts together, we can\nacquire realistic composite images. Sometimes, we expect the composite images\nto be not only realistic but also aesthetic, in which case aesthetic evaluation\nneeds to be considered. In this survey, we summarize the datasets and methods\nfor the above research directions. We also discuss the limitations and\npotential directions to facilitate the future research for image composition.\nFinally, as a double-edged sword, image composition may also have negative\neffect on our lives (e.g., fake news) and thus it is imperative to develop\nalgorithms to fight against composite images. Datasets and codes for image\ncomposition are summarized at\nhttps://github.com/bcmi/Awesome-Image-Composition.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As a common image editing operation, image composition aims to cut the\nforeground from one image and paste it on another image, resulting in a\ncomposite image. However, there are many issues that could make the composite\nimages unrealistic. These issues can be summarized as the inconsistency between\nforeground and background, which include appearance inconsistency (e.g.,\nincompatible color and illumination) and geometry inconsistency (e.g.,\nunreasonable size and location). Previous works on image composition target at\none or more issues. Since each individual issue is a complicated problem, there\nare some research directions (e.g., image harmonization, object placement)\nwhich focus on only one issue. By putting all the efforts together, we can\nacquire realistic composite images. Sometimes, we expect the composite images\nto be not only realistic but also aesthetic, in which case aesthetic evaluation\nneeds to be considered. In this survey, we summarize the datasets and methods\nfor the above research directions. We also discuss the limitations and\npotential directions to facilitate the future research for image composition.\nFinally, as a double-edged sword, image composition may also have negative\neffect on our lives (e.g., fake news) and thus it is imperative to develop\nalgorithms to fight against composite images. Datasets and codes for image\ncomposition are summarized at\nhttps://github.com/bcmi/Awesome-Image-Composition.'}, 'authors': [{'name': 'Li Niu'}, {'name': 'Wenyan Cong'}, {'name': 'Liu Liu'}, {'name': 'Yan Hong'}, {'name': 'Bo Zhang'}, {'name': 'Jing Liang'}, {'name': 'Liqing Zhang'}], 'author_detail': {'name': 'Liqing Zhang'}, 'author': 'Liqing Zhang', 'links': [{'href': 'http://arxiv.org/abs/2106.14490v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.14490v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
52,http://arxiv.org/abs/2106.13711v1,2021-06-22 21:21:29+00:00,2021-06-22 21:21:29+00:00,Multimodal Emergent Fake News Detection via Meta Neural Process Networks,"[arxiv.Result.Author('Yaqing Wang'), arxiv.Result.Author('Fenglong Ma'), arxiv.Result.Author('Haoyu Wang'), arxiv.Result.Author('Kishlay Jha'), arxiv.Result.Author('Jing Gao')]","Fake news travels at unprecedented speeds, reaches global audiences and puts
users and communities at great risk via social media platforms. Deep learning
based models show good performance when trained on large amounts of labeled
data on events of interest, whereas the performance of models tends to degrade
on other events due to domain shift. Therefore, significant challenges are
posed for existing detection approaches to detect fake news on emergent events,
where large-scale labeled datasets are difficult to obtain. Moreover, adding
the knowledge from newly emergent events requires to build a new model from
scratch or continue to fine-tune the model, which can be challenging,
expensive, and unrealistic for real-world settings. In order to address those
challenges, we propose an end-to-end fake news detection framework named
MetaFEND, which is able to learn quickly to detect fake news on emergent events
with a few verified posts. Specifically, the proposed model integrates
meta-learning and neural process methods together to enjoy the benefits of
these approaches. In particular, a label embedding module and a hard attention
mechanism are proposed to enhance the effectiveness by handling categorical
information and trimming irrelevant posts. Extensive experiments are conducted
on multimedia datasets collected from Twitter and Weibo. The experimental
results show our proposed MetaFEND model can detect fake news on never-seen
events effectively and outperform the state-of-the-art methods.",accepted by KDD 2021,,10.1145/3447548.3467153,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3447548.3467153', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2106.13711v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.13711v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.13711v1,"{'id': 'http://arxiv.org/abs/2106.13711v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.13711v1', 'updated': '2021-06-22T21:21:29Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=21, tm_min=21, tm_sec=29, tm_wday=1, tm_yday=173, tm_isdst=0), 'published': '2021-06-22T21:21:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=21, tm_min=21, tm_sec=29, tm_wday=1, tm_yday=173, tm_isdst=0), 'title': 'Multimodal Emergent Fake News Detection via Meta Neural Process Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multimodal Emergent Fake News Detection via Meta Neural Process Networks'}, 'summary': 'Fake news travels at unprecedented speeds, reaches global audiences and puts\nusers and communities at great risk via social media platforms. Deep learning\nbased models show good performance when trained on large amounts of labeled\ndata on events of interest, whereas the performance of models tends to degrade\non other events due to domain shift. Therefore, significant challenges are\nposed for existing detection approaches to detect fake news on emergent events,\nwhere large-scale labeled datasets are difficult to obtain. Moreover, adding\nthe knowledge from newly emergent events requires to build a new model from\nscratch or continue to fine-tune the model, which can be challenging,\nexpensive, and unrealistic for real-world settings. In order to address those\nchallenges, we propose an end-to-end fake news detection framework named\nMetaFEND, which is able to learn quickly to detect fake news on emergent events\nwith a few verified posts. Specifically, the proposed model integrates\nmeta-learning and neural process methods together to enjoy the benefits of\nthese approaches. In particular, a label embedding module and a hard attention\nmechanism are proposed to enhance the effectiveness by handling categorical\ninformation and trimming irrelevant posts. Extensive experiments are conducted\non multimedia datasets collected from Twitter and Weibo. The experimental\nresults show our proposed MetaFEND model can detect fake news on never-seen\nevents effectively and outperform the state-of-the-art methods.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news travels at unprecedented speeds, reaches global audiences and puts\nusers and communities at great risk via social media platforms. Deep learning\nbased models show good performance when trained on large amounts of labeled\ndata on events of interest, whereas the performance of models tends to degrade\non other events due to domain shift. Therefore, significant challenges are\nposed for existing detection approaches to detect fake news on emergent events,\nwhere large-scale labeled datasets are difficult to obtain. Moreover, adding\nthe knowledge from newly emergent events requires to build a new model from\nscratch or continue to fine-tune the model, which can be challenging,\nexpensive, and unrealistic for real-world settings. In order to address those\nchallenges, we propose an end-to-end fake news detection framework named\nMetaFEND, which is able to learn quickly to detect fake news on emergent events\nwith a few verified posts. Specifically, the proposed model integrates\nmeta-learning and neural process methods together to enjoy the benefits of\nthese approaches. In particular, a label embedding module and a hard attention\nmechanism are proposed to enhance the effectiveness by handling categorical\ninformation and trimming irrelevant posts. Extensive experiments are conducted\non multimedia datasets collected from Twitter and Weibo. The experimental\nresults show our proposed MetaFEND model can detect fake news on never-seen\nevents effectively and outperform the state-of-the-art methods.'}, 'authors': [{'name': 'Yaqing Wang'}, {'name': 'Fenglong Ma'}, {'name': 'Haoyu Wang'}, {'name': 'Kishlay Jha'}, {'name': 'Jing Gao'}], 'author_detail': {'name': 'Jing Gao'}, 'author': 'Jing Gao', 'arxiv_doi': '10.1145/3447548.3467153', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3447548.3467153', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2106.13711v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.13711v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'accepted by KDD 2021', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
53,http://arxiv.org/abs/2106.11177v1,2021-06-21 15:17:31+00:00,2021-06-21 15:17:31+00:00,MetaDetector: Meta Event Knowledge Transfer for Fake News Detection,"[arxiv.Result.Author('Yasan Ding'), arxiv.Result.Author('Bin Guo'), arxiv.Result.Author('Yan Liu'), arxiv.Result.Author('Yunji Liang'), arxiv.Result.Author('Haocheng Shen'), arxiv.Result.Author('Zhiwen Yu')]","The blooming of fake news on social networks has devastating impacts on
society, economy, and public security. Although numerous studies are conducted
for the automatic detection of fake news, the majority tend to utilize deep
neural networks to learn event-specific features for superior detection
performance on specific datasets. However, the trained models heavily rely on
the training datasets and are infeasible to apply to upcoming events due to the
discrepancy between event distributions. Inspired by domain adaptation
theories, we propose an end-to-end adversarial adaptation network, dubbed as
MetaDetector, to transfer meta knowledge (event-shared features) between
different events. Specifically, MetaDetector pushes the feature extractor and
event discriminator to eliminate event-specific features and preserve required
event-shared features by adversarial training. Furthermore, the pseudo-event
discriminator is utilized to evaluate the importance of historical event posts
to obtain partial shared features that are discriminative for detecting fake
news. Under the coordinated optimization among the four submodules,
MetaDetector accurately transfers the meta-knowledge of historical events to
the upcoming event for fact checking. We conduct extensive experiments on two
large-scale datasets collected from Weibo and Twitter. The experimental results
demonstrate that MetaDetector outperforms the state-of-the-art methods,
especially when the distribution shift between events is significant.
Furthermore, we find that MetaDetector is able to learn the event-shared
features, and alleviate the negative transfer caused by the large distribution
shift between events.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.11177v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.11177v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.11177v1,"{'id': 'http://arxiv.org/abs/2106.11177v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.11177v1', 'updated': '2021-06-21T15:17:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=15, tm_min=17, tm_sec=31, tm_wday=0, tm_yday=172, tm_isdst=0), 'published': '2021-06-21T15:17:31Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=15, tm_min=17, tm_sec=31, tm_wday=0, tm_yday=172, tm_isdst=0), 'title': 'MetaDetector: Meta Event Knowledge Transfer for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MetaDetector: Meta Event Knowledge Transfer for Fake News Detection'}, 'summary': 'The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.'}, 'authors': [{'name': 'Yasan Ding'}, {'name': 'Bin Guo'}, {'name': 'Yan Liu'}, {'name': 'Yunji Liang'}, {'name': 'Haocheng Shen'}, {'name': 'Zhiwen Yu'}], 'author_detail': {'name': 'Zhiwen Yu'}, 'author': 'Zhiwen Yu', 'links': [{'href': 'http://arxiv.org/abs/2106.11177v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11177v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
54,http://arxiv.org/abs/2106.09586v1,2021-06-17 15:13:08+00:00,2021-06-17 15:13:08+00:00,Prevalence and Propagation of Fake News,"[arxiv.Result.Author('Banafsheh Behzad'), arxiv.Result.Author('Bhavana Bheem'), arxiv.Result.Author('Daniela Elizondo'), arxiv.Result.Author('Deyana Marsh'), arxiv.Result.Author('Susan Martonosi')]","In recent years, scholars have raised concerns on the effects that unreliable
news, or ""fake news,"" has on our political sphere, and our democracy as a
whole. For example, the propagation of fake news on social media is widely
believed to have influenced the outcome of national elections, including the
2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives
the propagation of fake news on an individual level, and which interventions
could effectively reduce the propagation rate? Our model disentangles bias from
truthfulness of an article and examines the relationship between these two
parameters and a reader's own beliefs. Using the model, we create policy
recommendations for both social media platforms and individual social media
users to reduce the spread of untruthful or highly biased news. We recommend
that platforms sponsor unbiased truthful news, focus fact-checking efforts on
mild to moderately biased news, recommend friend suggestions across the
political spectrum, and provide users with reports about the political
alignment of their feed. We recommend that individual social media users fact
check news that strongly aligns with their political bias and read articles of
opposing political bias.","45 pages, 22 figures. Submitted for peer review on 7 May 2021",,,cs.SI,"['cs.SI', 'math.OC', 'stat.AP', '90B50', 'J.4']","[arxiv.Result.Link('http://arxiv.org/abs/2106.09586v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.09586v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.09586v1,"{'id': 'http://arxiv.org/abs/2106.09586v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.09586v1', 'updated': '2021-06-17T15:13:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=13, tm_sec=8, tm_wday=3, tm_yday=168, tm_isdst=0), 'published': '2021-06-17T15:13:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=13, tm_sec=8, tm_wday=3, tm_yday=168, tm_isdst=0), 'title': 'Prevalence and Propagation of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Prevalence and Propagation of Fake News'}, 'summary': 'In recent years, scholars have raised concerns on the effects that unreliable\nnews, or ""fake news,"" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader\'s own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, scholars have raised concerns on the effects that unreliable\nnews, or ""fake news,"" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader\'s own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.'}, 'authors': [{'name': 'Banafsheh Behzad'}, {'name': 'Bhavana Bheem'}, {'name': 'Daniela Elizondo'}, {'name': 'Deyana Marsh'}, {'name': 'Susan Martonosi'}], 'author_detail': {'name': 'Susan Martonosi'}, 'author': 'Susan Martonosi', 'arxiv_comment': '45 pages, 22 figures. Submitted for peer review on 7 May 2021', 'links': [{'href': 'http://arxiv.org/abs/2106.09586v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09586v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '90B50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
55,http://arxiv.org/abs/2106.09338v2,2021-08-08 17:03:44+00:00,2021-06-17 09:19:45+00:00,Investigating Misinformation Dissemination on Social Media in Pakistan,"[arxiv.Result.Author('Danyal Haroon'), arxiv.Result.Author('Hammad Arif'), arxiv.Result.Author('Ahmed Abdullah Tariq'), arxiv.Result.Author('fareeda nawaz'), arxiv.Result.Author('Dr. Ihsan Ayyub Qazi'), arxiv.Result.Author('Dr. Maryam mustafa')]","Fake news and misinformation are one of the most significant challenges
brought about by advances in communication technologies. We chose to research
the spread of fake news in Pakistan because of some unfortunate incidents that
took place during 2020. These included the downplaying of the severity of the
COVID-19 pandemic, and protests by right-wing political movements. We observed
that fake news and misinformation contributed significantly to these events and
especially affected low-literate and low-income populations. We conducted a
cross-platform comparison of misinformation on WhatsApp, Twitter and YouTube
with a primary focus on messages shared in public WhatsApp groups, and analysed
the characteristics of misinformation, techniques used to make is believable,
and how users respond to it. To the best of our knowledge, this is the first
attempt to compare misinformation on all three platforms in Pakistan. Data
collected over a span of eight months helped us identify fake news and
misinformation related to politics, religion and health, among other
categories. Common elements which were used by fake news creators in Pakistan
to make false content seem believable included: appeals to emotion, conspiracy
theories, political and religious polarization, incorrect facts and
impersonation of credible sources.",i want to further work on it,,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.09338v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.09338v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.09338v2,"{'id': 'http://arxiv.org/abs/2106.09338v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.09338v2', 'updated': '2021-08-08T17:03:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=8, tm_hour=17, tm_min=3, tm_sec=44, tm_wday=6, tm_yday=220, tm_isdst=0), 'published': '2021-06-17T09:19:45Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=9, tm_min=19, tm_sec=45, tm_wday=3, tm_yday=168, tm_isdst=0), 'title': 'Investigating Misinformation Dissemination on Social Media in Pakistan', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Misinformation Dissemination on Social Media in Pakistan'}, 'summary': 'Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.'}, 'authors': [{'name': 'Danyal Haroon'}, {'name': 'Hammad Arif'}, {'name': 'Ahmed Abdullah Tariq'}, {'name': 'fareeda nawaz'}, {'name': 'Dr. Ihsan Ayyub Qazi'}, {'name': 'Dr. Maryam mustafa'}], 'author_detail': {'name': 'Dr. Maryam mustafa'}, 'author': 'Dr. Maryam mustafa', 'arxiv_comment': 'i want to further work on it', 'links': [{'href': 'http://arxiv.org/abs/2106.09338v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09338v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
56,http://arxiv.org/abs/2106.08843v1,2021-06-16 15:01:29+00:00,2021-06-16 15:01:29+00:00,Visualizing Evolving Trees,"[arxiv.Result.Author('Kathryn Gray'), arxiv.Result.Author('Mingwei Li'), arxiv.Result.Author('Reyan Ahmed'), arxiv.Result.Author('Stephen Kobourov')]","Evolving trees arise in many real-life scenarios from computer file systems
and dynamic call graphs, to fake news propagation and disease spread. Most
layout algorithms for static trees, however, do not work well in an evolving
setting (e.g., they are not designed to be stable between time steps). Dynamic
graph layout algorithms are better suited to this task, although they often
introduce unnecessary edge crossings. With this in mind we propose two methods
for visualizing evolving trees that guarantee no edge crossings, while
optimizing (1) desired edge length realization, (2) layout compactness, and (3)
stability. We evaluate the two new methods, along with four prior approaches
(two static and two dynamic), on real-world datasets using quantitative
metrics: stress, desired edge length realization, layout compactness,
stability, and running time. The new methods are fully functional and available
on github.",,,,cs.CG,['cs.CG'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.08843v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.08843v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.08843v1,"{'id': 'http://arxiv.org/abs/2106.08843v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.08843v1', 'updated': '2021-06-16T15:01:29Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=15, tm_min=1, tm_sec=29, tm_wday=2, tm_yday=167, tm_isdst=0), 'published': '2021-06-16T15:01:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=15, tm_min=1, tm_sec=29, tm_wday=2, tm_yday=167, tm_isdst=0), 'title': 'Visualizing Evolving Trees', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Visualizing Evolving Trees'}, 'summary': 'Evolving trees arise in many real-life scenarios from computer file systems\nand dynamic call graphs, to fake news propagation and disease spread. Most\nlayout algorithms for static trees, however, do not work well in an evolving\nsetting (e.g., they are not designed to be stable between time steps). Dynamic\ngraph layout algorithms are better suited to this task, although they often\nintroduce unnecessary edge crossings. With this in mind we propose two methods\nfor visualizing evolving trees that guarantee no edge crossings, while\noptimizing (1) desired edge length realization, (2) layout compactness, and (3)\nstability. We evaluate the two new methods, along with four prior approaches\n(two static and two dynamic), on real-world datasets using quantitative\nmetrics: stress, desired edge length realization, layout compactness,\nstability, and running time. The new methods are fully functional and available\non github.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evolving trees arise in many real-life scenarios from computer file systems\nand dynamic call graphs, to fake news propagation and disease spread. Most\nlayout algorithms for static trees, however, do not work well in an evolving\nsetting (e.g., they are not designed to be stable between time steps). Dynamic\ngraph layout algorithms are better suited to this task, although they often\nintroduce unnecessary edge crossings. With this in mind we propose two methods\nfor visualizing evolving trees that guarantee no edge crossings, while\noptimizing (1) desired edge length realization, (2) layout compactness, and (3)\nstability. We evaluate the two new methods, along with four prior approaches\n(two static and two dynamic), on real-world datasets using quantitative\nmetrics: stress, desired edge length realization, layout compactness,\nstability, and running time. The new methods are fully functional and available\non github.'}, 'authors': [{'name': 'Kathryn Gray'}, {'name': 'Mingwei Li'}, {'name': 'Reyan Ahmed'}, {'name': 'Stephen Kobourov'}], 'author_detail': {'name': 'Stephen Kobourov'}, 'author': 'Stephen Kobourov', 'links': [{'href': 'http://arxiv.org/abs/2106.08843v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08843v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
57,http://arxiv.org/abs/2106.07823v1,2021-06-15 00:53:55+00:00,2021-06-15 00:53:55+00:00,Challenges and Considerations with Code-Mixed NLP for Multilingual Societies,"[arxiv.Result.Author('Vivek Srivastava'), arxiv.Result.Author('Mayank Singh')]","Multilingualism refers to the high degree of proficiency in two or more
languages in the written and oral communication modes. It often results in
language mixing, a.k.a. code-mixing, when a multilingual speaker switches
between multiple languages in a single utterance of a text or speech. This
paper discusses the current state of the NLP research, limitations, and
foreseeable pitfalls in addressing five real-world applications for social good
crisis management, healthcare, political campaigning, fake news, and hate
speech for multilingual societies. We also propose futuristic datasets, models,
and tools that can significantly advance the current research in multilingual
NLP applications for the societal good. As a representative example, we
consider English-Hindi code-mixing but draw similar inferences for other
language pairs",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2106.07823v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.07823v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.07823v1,"{'id': 'http://arxiv.org/abs/2106.07823v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.07823v1', 'updated': '2021-06-15T00:53:55Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=0, tm_min=53, tm_sec=55, tm_wday=1, tm_yday=166, tm_isdst=0), 'published': '2021-06-15T00:53:55Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=0, tm_min=53, tm_sec=55, tm_wday=1, tm_yday=166, tm_isdst=0), 'title': 'Challenges and Considerations with Code-Mixed NLP for Multilingual\n  Societies', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Challenges and Considerations with Code-Mixed NLP for Multilingual\n  Societies'}, 'summary': 'Multilingualism refers to the high degree of proficiency in two or more\nlanguages in the written and oral communication modes. It often results in\nlanguage mixing, a.k.a. code-mixing, when a multilingual speaker switches\nbetween multiple languages in a single utterance of a text or speech. This\npaper discusses the current state of the NLP research, limitations, and\nforeseeable pitfalls in addressing five real-world applications for social good\ncrisis management, healthcare, political campaigning, fake news, and hate\nspeech for multilingual societies. We also propose futuristic datasets, models,\nand tools that can significantly advance the current research in multilingual\nNLP applications for the societal good. As a representative example, we\nconsider English-Hindi code-mixing but draw similar inferences for other\nlanguage pairs', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multilingualism refers to the high degree of proficiency in two or more\nlanguages in the written and oral communication modes. It often results in\nlanguage mixing, a.k.a. code-mixing, when a multilingual speaker switches\nbetween multiple languages in a single utterance of a text or speech. This\npaper discusses the current state of the NLP research, limitations, and\nforeseeable pitfalls in addressing five real-world applications for social good\ncrisis management, healthcare, political campaigning, fake news, and hate\nspeech for multilingual societies. We also propose futuristic datasets, models,\nand tools that can significantly advance the current research in multilingual\nNLP applications for the societal good. As a representative example, we\nconsider English-Hindi code-mixing but draw similar inferences for other\nlanguage pairs'}, 'authors': [{'name': 'Vivek Srivastava'}, {'name': 'Mayank Singh'}], 'author_detail': {'name': 'Mayank Singh'}, 'author': 'Mayank Singh', 'links': [{'href': 'http://arxiv.org/abs/2106.07823v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.07823v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
58,http://arxiv.org/abs/2106.07435v1,2021-06-14 13:56:26+00:00,2021-06-14 13:56:26+00:00,Both Rates of Fake News and Fact-based News on Twitter Negatively Correlate with the State-level COVID-19 Vaccine Uptake,"[arxiv.Result.Author('Hanjia Lyu'), arxiv.Result.Author('Zihe Zheng'), arxiv.Result.Author('Jiebo Luo')]","There is evidence of misinformation in the online discourses and discussions
about the COVID-19 vaccines. Using a sample of 1.6 million geotagged English
tweets and the data from the CDC COVID Data Tracker, we conduct a quantitative
study to understand the influence of both misinformation and fact-based news on
Twitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.
adults were vaccine eligible to May 7, 2021, after controlling state-level
factors such as demographics, education, and the pandemic severity. We identify
the tweets related to either misinformation or fact-based news by analyzing the
URLs. By analyzing the content of the most frequent tweets of these two groups,
we find that their structures are similar, making it difficult for Twitter
users to distinguish one from another by reading the text alone. The users who
spread both fake news and fact-based news tend to show a negative attitude
towards the vaccines. We further conduct the Fama-MacBeth regression with the
Newey-West adjustment to examine the effect of fake-news-related and
fact-related tweets on the vaccination rate, and find marginally negative
correlations.",6 pages,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.07435v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.07435v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.07435v1,"{'id': 'http://arxiv.org/abs/2106.07435v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.07435v1', 'updated': '2021-06-14T13:56:26Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=14, tm_hour=13, tm_min=56, tm_sec=26, tm_wday=0, tm_yday=165, tm_isdst=0), 'published': '2021-06-14T13:56:26Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=14, tm_hour=13, tm_min=56, tm_sec=26, tm_wday=0, tm_yday=165, tm_isdst=0), 'title': 'Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake'}, 'summary': 'There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.'}, 'authors': [{'name': 'Hanjia Lyu'}, {'name': 'Zihe Zheng'}, {'name': 'Jiebo Luo'}], 'author_detail': {'name': 'Jiebo Luo'}, 'author': 'Jiebo Luo', 'arxiv_comment': '6 pages', 'links': [{'href': 'http://arxiv.org/abs/2106.07435v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.07435v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
59,http://arxiv.org/abs/2106.01784v1,2021-06-03 12:16:08+00:00,2021-06-03 12:16:08+00:00,The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and Technology in Action,[arxiv.Result.Author('Ben Green')],"Recent controversies related to topics such as fake news, privacy, and
algorithmic bias have prompted increased public scrutiny of digital
technologies and soul-searching among many of the people associated with their
development. In response, the tech industry, academia, civil society, and
governments have rapidly increased their attention to ""ethics"" in the design
and use of digital technologies (""tech ethics""). Yet almost as quickly as
ethics discourse has proliferated across the world of digital technologies, the
limitations of these approaches have also become apparent: tech ethics is vague
and toothless, is subsumed into corporate logics and incentives, and has a
myopic focus on individual engineers and technology design rather than on the
structures and cultures of technology production. As a result of these
limitations, many have grown skeptical of tech ethics and its proponents,
charging them with ""ethics-washing"": promoting ethics research and discourse to
defuse criticism and government regulation without committing to ethical
behavior. By looking at how ethics has been taken up in both science and
business in superficial and depoliticizing ways, I recast tech ethics as a
terrain of contestation where the central fault line is not whether it is
desirable to be ethical, but what ""ethics"" entails and who gets to define it.
This framing highlights the significant limits of current approaches to tech
ethics and the importance of studying the formulation and real-world effects of
tech ethics. In order to identify and develop more rigorous strategies for
reforming digital technologies and the social relations that they mediate, I
describe a sociotechnical approach to tech ethics, one that reflexively applies
many of tech ethics' own lessons regarding digital technologies to tech ethics
itself.",,,,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2106.01784v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.01784v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.01784v1,"{'id': 'http://arxiv.org/abs/2106.01784v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.01784v1', 'updated': '2021-06-03T12:16:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=12, tm_min=16, tm_sec=8, tm_wday=3, tm_yday=154, tm_isdst=0), 'published': '2021-06-03T12:16:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=12, tm_min=16, tm_sec=8, tm_wday=3, tm_yday=154, tm_isdst=0), 'title': 'The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and\n  Technology in Action', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and\n  Technology in Action'}, 'summary': 'Recent controversies related to topics such as fake news, privacy, and\nalgorithmic bias have prompted increased public scrutiny of digital\ntechnologies and soul-searching among many of the people associated with their\ndevelopment. In response, the tech industry, academia, civil society, and\ngovernments have rapidly increased their attention to ""ethics"" in the design\nand use of digital technologies (""tech ethics""). Yet almost as quickly as\nethics discourse has proliferated across the world of digital technologies, the\nlimitations of these approaches have also become apparent: tech ethics is vague\nand toothless, is subsumed into corporate logics and incentives, and has a\nmyopic focus on individual engineers and technology design rather than on the\nstructures and cultures of technology production. As a result of these\nlimitations, many have grown skeptical of tech ethics and its proponents,\ncharging them with ""ethics-washing"": promoting ethics research and discourse to\ndefuse criticism and government regulation without committing to ethical\nbehavior. By looking at how ethics has been taken up in both science and\nbusiness in superficial and depoliticizing ways, I recast tech ethics as a\nterrain of contestation where the central fault line is not whether it is\ndesirable to be ethical, but what ""ethics"" entails and who gets to define it.\nThis framing highlights the significant limits of current approaches to tech\nethics and the importance of studying the formulation and real-world effects of\ntech ethics. In order to identify and develop more rigorous strategies for\nreforming digital technologies and the social relations that they mediate, I\ndescribe a sociotechnical approach to tech ethics, one that reflexively applies\nmany of tech ethics\' own lessons regarding digital technologies to tech ethics\nitself.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent controversies related to topics such as fake news, privacy, and\nalgorithmic bias have prompted increased public scrutiny of digital\ntechnologies and soul-searching among many of the people associated with their\ndevelopment. In response, the tech industry, academia, civil society, and\ngovernments have rapidly increased their attention to ""ethics"" in the design\nand use of digital technologies (""tech ethics""). Yet almost as quickly as\nethics discourse has proliferated across the world of digital technologies, the\nlimitations of these approaches have also become apparent: tech ethics is vague\nand toothless, is subsumed into corporate logics and incentives, and has a\nmyopic focus on individual engineers and technology design rather than on the\nstructures and cultures of technology production. As a result of these\nlimitations, many have grown skeptical of tech ethics and its proponents,\ncharging them with ""ethics-washing"": promoting ethics research and discourse to\ndefuse criticism and government regulation without committing to ethical\nbehavior. By looking at how ethics has been taken up in both science and\nbusiness in superficial and depoliticizing ways, I recast tech ethics as a\nterrain of contestation where the central fault line is not whether it is\ndesirable to be ethical, but what ""ethics"" entails and who gets to define it.\nThis framing highlights the significant limits of current approaches to tech\nethics and the importance of studying the formulation and real-world effects of\ntech ethics. In order to identify and develop more rigorous strategies for\nreforming digital technologies and the social relations that they mediate, I\ndescribe a sociotechnical approach to tech ethics, one that reflexively applies\nmany of tech ethics\' own lessons regarding digital technologies to tech ethics\nitself.'}, 'authors': [{'name': 'Ben Green'}], 'author_detail': {'name': 'Ben Green'}, 'author': 'Ben Green', 'links': [{'href': 'http://arxiv.org/abs/2106.01784v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.01784v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
60,http://arxiv.org/abs/2105.15172v1,2021-05-31 17:32:06+00:00,2021-05-31 17:32:06+00:00,Assessing disinformation through the dynamics of supply and demand in the news ecosystem,"[arxiv.Result.Author('Pietro Gravino'), arxiv.Result.Author('Giulio Prevedello'), arxiv.Result.Author('Martina Galletti'), arxiv.Result.Author('Vittorio Loreto')]","Social dialogue, the foundation of our democracies, is currently threatened
by disinformation and partisanship, with their disrupting role on individual
and collective awareness and detrimental effects on decision-making processes.
Despite a great deal of attention to the news sphere itself, little is known
about the subtle interplay between the offer and the demand for information.
Still, a broader perspective on the news ecosystem, including both the
producers and the consumers of information, is needed to build new tools to
assess the health of the infosphere. Here, we combine in the same framework
news supply, as mirrored by a fairly complete Italian news database - partially
annotated for fake news, and news demand, as captured through the Google Trends
data for Italy. Our investigation focuses on the temporal and semantic
interplay of news, fake news, and searches in several domains, including the
virus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is
extremely reactive to people's interests and tends to thrive, especially when
there is a mismatch between what people are interested in and what news outlets
provide. Second, a suitably defined index can assess the level of
disinformation only based on the available volumes of news and searches.
Although our results mainly concern the Coronavirus subject, we provide hints
that the same findings can have more general applications. We contend these
results can be a powerful asset in informing campaigns against disinformation
and providing news outlets and institutions with potentially relevant
strategies.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2105.15172v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.15172v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.15172v1,"{'id': 'http://arxiv.org/abs/2105.15172v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.15172v1', 'updated': '2021-05-31T17:32:06Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=32, tm_sec=6, tm_wday=0, tm_yday=151, tm_isdst=0), 'published': '2021-05-31T17:32:06Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=32, tm_sec=6, tm_wday=0, tm_yday=151, tm_isdst=0), 'title': 'Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem'}, 'summary': ""Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.""}, 'authors': [{'name': 'Pietro Gravino'}, {'name': 'Giulio Prevedello'}, {'name': 'Martina Galletti'}, {'name': 'Vittorio Loreto'}], 'author_detail': {'name': 'Vittorio Loreto'}, 'author': 'Vittorio Loreto', 'links': [{'href': 'http://arxiv.org/abs/2105.15172v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.15172v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
61,http://arxiv.org/abs/2105.15165v1,2021-05-31 17:13:47+00:00,2021-05-31 17:13:47+00:00,Multimodal Detection of Information Disorder from Social Media,"[arxiv.Result.Author('Armin Kirchknopf'), arxiv.Result.Author('Djordje Slijepcevic'), arxiv.Result.Author('Matthias Zeppelzauer')]","Social media is accompanied by an increasing proportion of content that
provides fake information or misleading content, known as information disorder.
In this paper, we study the problem of multimodal fake news detection on a
largescale multimodal dataset. We propose a multimodal network architecture
that enables different levels and types of information fusion. In addition to
the textual and visual content of a posting, we further leverage secondary
information, i.e. user comments and metadata. We fuse information at multiple
levels to account for the specific intrinsic structure of the modalities. Our
results show that multimodal analysis is highly effective for the task and all
modalities contribute positively when fused properly.","4 pages, 2 figures, 2 tables, PrePrint CBMI 2021",,,cs.IR,"['cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2105.15165v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.15165v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.15165v1,"{'id': 'http://arxiv.org/abs/2105.15165v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.15165v1', 'updated': '2021-05-31T17:13:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=13, tm_sec=47, tm_wday=0, tm_yday=151, tm_isdst=0), 'published': '2021-05-31T17:13:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=13, tm_sec=47, tm_wday=0, tm_yday=151, tm_isdst=0), 'title': 'Multimodal Detection of Information Disorder from Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multimodal Detection of Information Disorder from Social Media'}, 'summary': 'Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.'}, 'authors': [{'name': 'Armin Kirchknopf'}, {'name': 'Djordje Slijepcevic'}, {'name': 'Matthias Zeppelzauer'}], 'author_detail': {'name': 'Matthias Zeppelzauer'}, 'author': 'Matthias Zeppelzauer', 'arxiv_comment': '4 pages, 2 figures, 2 tables, PrePrint CBMI 2021', 'links': [{'href': 'http://arxiv.org/abs/2105.15165v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.15165v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
62,http://arxiv.org/abs/2105.10799v1,2021-05-22 19:28:10+00:00,2021-05-22 19:28:10+00:00,Sockpuppet Detection: a Telegram case study,"[arxiv.Result.Author('Gabriele Pisciotta'), arxiv.Result.Author('Miriana Somenzi'), arxiv.Result.Author('Elisa Barisani'), arxiv.Result.Author('Giulio Rossetti')]","In Online Social Networks (OSN) numerous are the cases in which users create
multiple accounts that publicly seem to belong to different people but are
actually fake identities of the same person. These fictitious characters can be
exploited to carry out abusive behaviors such as manipulating opinions,
spreading fake news and disturbing other users. In literature this problem is
known as the Sockpuppet problem. In our work we focus on Telegram, a
wide-spread instant messaging application, often known for its exploitation by
members of organized crime and terrorism, and more in general for its high
presence of people who have offensive behaviors.",,"The 9th International Conference on Complex Networks and their
  Applications - Book of Abstract (2021), pp. 414 (978-2-9557050-4-9)",10.5281/zenodo.4744934,cs.SI,"['cs.SI', 'cs.AI', 'J.4']","[arxiv.Result.Link('http://dx.doi.org/10.5281/zenodo.4744934', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2105.10799v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.10799v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.10799v1,"{'id': 'http://arxiv.org/abs/2105.10799v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.10799v1', 'updated': '2021-05-22T19:28:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=19, tm_min=28, tm_sec=10, tm_wday=5, tm_yday=142, tm_isdst=0), 'published': '2021-05-22T19:28:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=19, tm_min=28, tm_sec=10, tm_wday=5, tm_yday=142, tm_isdst=0), 'title': 'Sockpuppet Detection: a Telegram case study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sockpuppet Detection: a Telegram case study'}, 'summary': 'In Online Social Networks (OSN) numerous are the cases in which users create\nmultiple accounts that publicly seem to belong to different people but are\nactually fake identities of the same person. These fictitious characters can be\nexploited to carry out abusive behaviors such as manipulating opinions,\nspreading fake news and disturbing other users. In literature this problem is\nknown as the Sockpuppet problem. In our work we focus on Telegram, a\nwide-spread instant messaging application, often known for its exploitation by\nmembers of organized crime and terrorism, and more in general for its high\npresence of people who have offensive behaviors.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In Online Social Networks (OSN) numerous are the cases in which users create\nmultiple accounts that publicly seem to belong to different people but are\nactually fake identities of the same person. These fictitious characters can be\nexploited to carry out abusive behaviors such as manipulating opinions,\nspreading fake news and disturbing other users. In literature this problem is\nknown as the Sockpuppet problem. In our work we focus on Telegram, a\nwide-spread instant messaging application, often known for its exploitation by\nmembers of organized crime and terrorism, and more in general for its high\npresence of people who have offensive behaviors.'}, 'authors': [{'name': 'Gabriele Pisciotta'}, {'name': 'Miriana Somenzi'}, {'name': 'Elisa Barisani'}, {'name': 'Giulio Rossetti'}], 'author_detail': {'name': 'Giulio Rossetti'}, 'author': 'Giulio Rossetti', 'arxiv_doi': '10.5281/zenodo.4744934', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.5281/zenodo.4744934', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2105.10799v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.10799v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'The 9th International Conference on Complex Networks and their\n  Applications - Book of Abstract (2021), pp. 414 (978-2-9557050-4-9)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
63,http://arxiv.org/abs/2105.10671v1,2021-05-22 09:26:13+00:00,2021-05-22 09:26:13+00:00,SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?,"[arxiv.Result.Author('Tanveer Khan'), arxiv.Result.Author('Antonis Michalas'), arxiv.Result.Author('Adnan Akhunzada')]","Social Networks' omnipresence and ease of use has revolutionized the
generation and distribution of information in today's world. However, easy
access to information does not equal an increased level of public knowledge.
Unlike traditional media channels, social networks also facilitate faster and
wider spread of disinformation and misinformation. Viral spread of false
information has serious implications on the behaviors, attitudes and beliefs of
the public, and ultimately can seriously endanger the democratic processes.
Limiting false information's negative impact through early detection and
control of extensive spread presents the main challenge facing researchers
today. In this survey paper, we extensively analyze a wide range of different
solutions for the early detection of fake news in the existing literature. More
precisely, we examine Machine Learning (ML) models for the identification and
classification of fake news, online fake news detection competitions,
statistical outputs as well as the advantages and disadvantages of some of the
available data sets. Finally, we evaluate the online web browsing tools
available for detecting and mitigating fake news and present some open research
challenges.","34 pages, 3 figures",,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2105.10671v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.10671v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.10671v1,"{'id': 'http://arxiv.org/abs/2105.10671v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.10671v1', 'updated': '2021-05-22T09:26:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=9, tm_min=26, tm_sec=13, tm_wday=5, tm_yday=142, tm_isdst=0), 'published': '2021-05-22T09:26:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=9, tm_min=26, tm_sec=13, tm_wday=5, tm_yday=142, tm_isdst=0), 'title': 'SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?'}, 'summary': ""Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.""}, 'authors': [{'name': 'Tanveer Khan'}, {'name': 'Antonis Michalas'}, {'name': 'Adnan Akhunzada'}], 'author_detail': {'name': 'Adnan Akhunzada'}, 'author': 'Adnan Akhunzada', 'arxiv_comment': '34 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/2105.10671v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.10671v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
64,http://arxiv.org/abs/2105.10272v1,2021-05-21 10:46:43+00:00,2021-05-21 10:46:43+00:00,Stance Detection with BERT Embeddings for Credibility Analysis of Information on Social Media,"[arxiv.Result.Author('Hema Karande'), arxiv.Result.Author('Rahee Walambe'), arxiv.Result.Author('Victor Benjamin'), arxiv.Result.Author('Ketan Kotecha'), arxiv.Result.Author('T. S. Raghu')]","The evolution of electronic media is a mixed blessing. Due to the easy
access, low cost, and faster reach of the information, people search out and
devour news from online social networks. In contrast, the increasing acceptance
of social media reporting leads to the spread of fake news. This is a minacious
problem that causes disputes and endangers societal stability and harmony. Fake
news spread has gained attention from researchers due to its vicious nature.
proliferation of misinformation in all media, from the internet to cable news,
paid advertising and local news outlets, has made it essential for people to
identify the misinformation and sort through the facts. Researchers are trying
to analyze the credibility of information and curtail false information on such
platforms. Credibility is the believability of the piece of information at
hand. Analyzing the credibility of fake news is challenging due to the intent
of its creation and the polychromatic nature of the news. In this work, we
propose a model for detecting fake news. Our method investigates the content of
the news at the early stage i.e. when the news is published but is yet to be
disseminated through social media. Our work interprets the content with
automatic feature extraction and the relevance of the text pieces. In summary,
we introduce stance as one of the features along with the content of the
article and employ the pre-trained contextualized word embeddings BERT to
obtain the state-of-art results for fake news detection. The experiment
conducted on the real-world dataset indicates that our model outperforms the
previous work and enables fake news detection with an accuracy of 95.32%.",,,10.7717/peerj-cs.467,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.7717/peerj-cs.467', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2105.10272v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.10272v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.10272v1,"{'id': 'http://arxiv.org/abs/2105.10272v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.10272v1', 'updated': '2021-05-21T10:46:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=21, tm_hour=10, tm_min=46, tm_sec=43, tm_wday=4, tm_yday=141, tm_isdst=0), 'published': '2021-05-21T10:46:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=21, tm_hour=10, tm_min=46, tm_sec=43, tm_wday=4, tm_yday=141, tm_isdst=0), 'title': 'Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media'}, 'summary': 'The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.'}, 'authors': [{'name': 'Hema Karande'}, {'name': 'Rahee Walambe'}, {'name': 'Victor Benjamin'}, {'name': 'Ketan Kotecha'}, {'name': 'T. S. Raghu'}], 'author_detail': {'name': 'T. S. Raghu'}, 'author': 'T. S. Raghu', 'arxiv_doi': '10.7717/peerj-cs.467', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.7717/peerj-cs.467', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2105.10272v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.10272v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
65,http://arxiv.org/abs/2105.09672v1,2021-05-20 11:20:37+00:00,2021-05-20 11:20:37+00:00,Newsalyze: Enabling News Consumers to Understand Media Bias,"[arxiv.Result.Author('Felix Hamborg'), arxiv.Result.Author('Anastasia Zhukova'), arxiv.Result.Author('Karsten Donnay'), arxiv.Result.Author('Bela Gipp')]","News is a central source of information for individuals to inform themselves
on current topics. Knowing a news article's slant and authenticity is of
crucial importance in times of ""fake news,"" news bots, and centralization of
media ownership. We introduce Newsalyze, a bias-aware news reader focusing on a
subtle, yet powerful form of media bias, named bias by word choice and labeling
(WCL). WCL bias can alter the assessment of entities reported in the news,
e.g., ""freedom fighters"" vs. ""terrorists."" At the core of the analysis is a
neural model that uses a news-adapted BERT language model to determine
target-dependent sentiment, a high-level effect of WCL bias. While the analysis
currently focuses on only this form of bias, the visualizations already reveal
patterns of bias when contrasting articles (overview) and in-text instances of
bias (article view).",,,10.1145/3383583.3398561,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3383583.3398561', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2105.09672v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.09672v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.09672v1,"{'id': 'http://arxiv.org/abs/2105.09672v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.09672v1', 'updated': '2021-05-20T11:20:37Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=20, tm_hour=11, tm_min=20, tm_sec=37, tm_wday=3, tm_yday=140, tm_isdst=0), 'published': '2021-05-20T11:20:37Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=20, tm_hour=11, tm_min=20, tm_sec=37, tm_wday=3, tm_yday=140, tm_isdst=0), 'title': 'Newsalyze: Enabling News Consumers to Understand Media Bias', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Newsalyze: Enabling News Consumers to Understand Media Bias'}, 'summary': 'News is a central source of information for individuals to inform themselves\non current topics. Knowing a news article\'s slant and authenticity is of\ncrucial importance in times of ""fake news,"" news bots, and centralization of\nmedia ownership. We introduce Newsalyze, a bias-aware news reader focusing on a\nsubtle, yet powerful form of media bias, named bias by word choice and labeling\n(WCL). WCL bias can alter the assessment of entities reported in the news,\ne.g., ""freedom fighters"" vs. ""terrorists."" At the core of the analysis is a\nneural model that uses a news-adapted BERT language model to determine\ntarget-dependent sentiment, a high-level effect of WCL bias. While the analysis\ncurrently focuses on only this form of bias, the visualizations already reveal\npatterns of bias when contrasting articles (overview) and in-text instances of\nbias (article view).', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'News is a central source of information for individuals to inform themselves\non current topics. Knowing a news article\'s slant and authenticity is of\ncrucial importance in times of ""fake news,"" news bots, and centralization of\nmedia ownership. We introduce Newsalyze, a bias-aware news reader focusing on a\nsubtle, yet powerful form of media bias, named bias by word choice and labeling\n(WCL). WCL bias can alter the assessment of entities reported in the news,\ne.g., ""freedom fighters"" vs. ""terrorists."" At the core of the analysis is a\nneural model that uses a news-adapted BERT language model to determine\ntarget-dependent sentiment, a high-level effect of WCL bias. While the analysis\ncurrently focuses on only this form of bias, the visualizations already reveal\npatterns of bias when contrasting articles (overview) and in-text instances of\nbias (article view).'}, 'authors': [{'name': 'Felix Hamborg'}, {'name': 'Anastasia Zhukova'}, {'name': 'Karsten Donnay'}, {'name': 'Bela Gipp'}], 'author_detail': {'name': 'Bela Gipp'}, 'author': 'Bela Gipp', 'arxiv_doi': '10.1145/3383583.3398561', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3383583.3398561', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2105.09672v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.09672v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
66,http://arxiv.org/abs/2105.09114v1,2021-05-19 13:18:02+00:00,2021-05-19 13:18:02+00:00,Explainable Tsetlin Machine framework for fake news detection with credibility score assessment,"[arxiv.Result.Author('Bimal Bhattarai'), arxiv.Result.Author('Ole-Christoffer Granmo'), arxiv.Result.Author('Lei Jiao')]","The proliferation of fake news, i.e., news intentionally spread for
misinformation, poses a threat to individuals and society. Despite various
fact-checking websites such as PolitiFact, robust detection techniques are
required to deal with the increase in fake news. Several deep learning models
show promising results for fake news classification, however, their black-box
nature makes it difficult to explain their classification decisions and
quality-assure the models. We here address this problem by proposing a novel
interpretable fake news detection framework based on the recently introduced
Tsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to
capture lexical and semantic properties of both true and fake news text.
Further, we use the clause ensembles to calculate the credibility of fake news.
For evaluation, we conduct experiments on two publicly available datasets,
PolitiFact and GossipCop, and demonstrate that the TM framework significantly
outperforms previously published baselines by at least $5\%$ in terms of
accuracy, with the added benefit of an interpretable logic-based
representation. Further, our approach provides higher F1-score than BERT and
XLNet, however, we obtain slightly lower accuracy. We finally present a case
study on our model's explainability, demonstrating how it decomposes into
meaningful words and their negations.","11 pages, 4 figures, 4 tables",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG', 'I.2; I.5; I.7']","[arxiv.Result.Link('http://arxiv.org/abs/2105.09114v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.09114v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.09114v1,"{'id': 'http://arxiv.org/abs/2105.09114v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.09114v1', 'updated': '2021-05-19T13:18:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=13, tm_min=18, tm_sec=2, tm_wday=2, tm_yday=139, tm_isdst=0), 'published': '2021-05-19T13:18:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=13, tm_min=18, tm_sec=2, tm_wday=2, tm_yday=139, tm_isdst=0), 'title': 'Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment'}, 'summary': ""The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.""}, 'authors': [{'name': 'Bimal Bhattarai'}, {'name': 'Ole-Christoffer Granmo'}, {'name': 'Lei Jiao'}], 'author_detail': {'name': 'Lei Jiao'}, 'author': 'Lei Jiao', 'arxiv_comment': '11 pages, 4 figures, 4 tables', 'links': [{'href': 'http://arxiv.org/abs/2105.09114v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.09114v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; I.5; I.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
67,http://arxiv.org/abs/2105.08929v1,2021-05-19 05:24:13+00:00,2021-05-19 05:24:13+00:00,Three prophylactic interventions to counter fake news on social media,"[arxiv.Result.Author('David A. Eccles'), arxiv.Result.Author('Tilman Dingler')]","Fake news on Social Media undermines democratic institutions and processes.
Especially since 2016, researchers from many disciplines have focussed on ways
to address the phenomenon. Much of the research focus to date has been on
identification and understanding the nature of the phenomenon in and between
social networks and of a rather reactive nature. We propose interventions that
focus on individual user empowerment, and social media structural change that
is prophylactic (pre exposure), rather than therapeutic (post exposure) with
the goal of reducing the population exposed to fake news. We investigate
interventions that result in greater user elaboration (cognitive effort) before
exposure to fake news. We propose three interventions i) psychological
inoculation, ii) fostering digital and media literacy and iii) imposition of
user transaction costs. Each intervention promises to illicit greater cognitive
effort in message evaluation and reduce the likelihood of creating, sharing,
liking and consuming 'fake news'.",7 pages,,,cs.HC,"['cs.HC', 'cs.CY', 'H.4; K.4']","[arxiv.Result.Link('http://arxiv.org/abs/2105.08929v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.08929v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.08929v1,"{'id': 'http://arxiv.org/abs/2105.08929v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.08929v1', 'updated': '2021-05-19T05:24:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=5, tm_min=24, tm_sec=13, tm_wday=2, tm_yday=139, tm_isdst=0), 'published': '2021-05-19T05:24:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=5, tm_min=24, tm_sec=13, tm_wday=2, tm_yday=139, tm_isdst=0), 'title': 'Three prophylactic interventions to counter fake news on social media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Three prophylactic interventions to counter fake news on social media'}, 'summary': ""Fake news on Social Media undermines democratic institutions and processes.\nEspecially since 2016, researchers from many disciplines have focussed on ways\nto address the phenomenon. Much of the research focus to date has been on\nidentification and understanding the nature of the phenomenon in and between\nsocial networks and of a rather reactive nature. We propose interventions that\nfocus on individual user empowerment, and social media structural change that\nis prophylactic (pre exposure), rather than therapeutic (post exposure) with\nthe goal of reducing the population exposed to fake news. We investigate\ninterventions that result in greater user elaboration (cognitive effort) before\nexposure to fake news. We propose three interventions i) psychological\ninoculation, ii) fostering digital and media literacy and iii) imposition of\nuser transaction costs. Each intervention promises to illicit greater cognitive\neffort in message evaluation and reduce the likelihood of creating, sharing,\nliking and consuming 'fake news'."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news on Social Media undermines democratic institutions and processes.\nEspecially since 2016, researchers from many disciplines have focussed on ways\nto address the phenomenon. Much of the research focus to date has been on\nidentification and understanding the nature of the phenomenon in and between\nsocial networks and of a rather reactive nature. We propose interventions that\nfocus on individual user empowerment, and social media structural change that\nis prophylactic (pre exposure), rather than therapeutic (post exposure) with\nthe goal of reducing the population exposed to fake news. We investigate\ninterventions that result in greater user elaboration (cognitive effort) before\nexposure to fake news. We propose three interventions i) psychological\ninoculation, ii) fostering digital and media literacy and iii) imposition of\nuser transaction costs. Each intervention promises to illicit greater cognitive\neffort in message evaluation and reduce the likelihood of creating, sharing,\nliking and consuming 'fake news'.""}, 'authors': [{'name': 'David A. Eccles'}, {'name': 'Tilman Dingler'}], 'author_detail': {'name': 'Tilman Dingler'}, 'author': 'Tilman Dingler', 'arxiv_comment': '7 pages', 'links': [{'href': 'http://arxiv.org/abs/2105.08929v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.08929v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.4; K.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
68,http://arxiv.org/abs/2105.08827v1,2021-05-18 20:55:11+00:00,2021-05-18 20:55:11+00:00,"Educators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements","[arxiv.Result.Author('Shruti Phadke'), arxiv.Result.Author('Tanushree Mitra')]","Social media provides the means by which extremist social movements, such as
white supremacy and anti LGBTQ, thrive online. Yet, we know little about the
roles played by the participants of such movements. In this paper, we
investigate these participants to characterize their roles, their role
dynamics, and their influence in spreading online extremism. Our participants,
online extremist accounts, are 4,876 public Facebook pages or groups that have
shared information from the websites of 289 Southern Poverty Law Center
designated extremist groups. By clustering the quantitative features followed
by qualitative expert validation, we identify five roles surrounding extremist
activism: educators, solicitors, flamers, motivators, sympathizers. For
example, solicitors use links from extremist websites to attract donations and
participation in extremist issues, whereas flamers share inflammatory extremist
content inciting anger. We further investigate role dynamics such as, how
stable these roles are over time and how likely will extremist accounts
transition from one role into another. We find that roles core to the movement,
educators and solicitors, are more stable, while flamers and motivators can
transition to sympathizers with high probability. We further find that
educators and solicitors exert the most influence in triggering extremist link
posts, whereas flamers are influential in triggering the spread of information
from fake news sources. Our results help in situating various roles on the
trajectory of deeper engagement into the extremist movements and understanding
the potential effect of various counter extremism interventions. Our findings
have implications for understanding how online extremist movements flourish
through participatory activism and how they gain a spectrum of allies for
mobilizing extremism online.",Accepted at Computer Supported Cooperative Work (CSCW 2021),,,cs.SI,"['cs.SI', 'cs.CY', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2105.08827v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.08827v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.08827v1,"{'id': 'http://arxiv.org/abs/2105.08827v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.08827v1', 'updated': '2021-05-18T20:55:11Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=18, tm_hour=20, tm_min=55, tm_sec=11, tm_wday=1, tm_yday=138, tm_isdst=0), 'published': '2021-05-18T20:55:11Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=18, tm_hour=20, tm_min=55, tm_sec=11, tm_wday=1, tm_yday=138, tm_isdst=0), 'title': 'Educators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing\n  Roles in Online Extremist Movements', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Educators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing\n  Roles in Online Extremist Movements'}, 'summary': 'Social media provides the means by which extremist social movements, such as\nwhite supremacy and anti LGBTQ, thrive online. Yet, we know little about the\nroles played by the participants of such movements. In this paper, we\ninvestigate these participants to characterize their roles, their role\ndynamics, and their influence in spreading online extremism. Our participants,\nonline extremist accounts, are 4,876 public Facebook pages or groups that have\nshared information from the websites of 289 Southern Poverty Law Center\ndesignated extremist groups. By clustering the quantitative features followed\nby qualitative expert validation, we identify five roles surrounding extremist\nactivism: educators, solicitors, flamers, motivators, sympathizers. For\nexample, solicitors use links from extremist websites to attract donations and\nparticipation in extremist issues, whereas flamers share inflammatory extremist\ncontent inciting anger. We further investigate role dynamics such as, how\nstable these roles are over time and how likely will extremist accounts\ntransition from one role into another. We find that roles core to the movement,\neducators and solicitors, are more stable, while flamers and motivators can\ntransition to sympathizers with high probability. We further find that\neducators and solicitors exert the most influence in triggering extremist link\nposts, whereas flamers are influential in triggering the spread of information\nfrom fake news sources. Our results help in situating various roles on the\ntrajectory of deeper engagement into the extremist movements and understanding\nthe potential effect of various counter extremism interventions. Our findings\nhave implications for understanding how online extremist movements flourish\nthrough participatory activism and how they gain a spectrum of allies for\nmobilizing extremism online.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media provides the means by which extremist social movements, such as\nwhite supremacy and anti LGBTQ, thrive online. Yet, we know little about the\nroles played by the participants of such movements. In this paper, we\ninvestigate these participants to characterize their roles, their role\ndynamics, and their influence in spreading online extremism. Our participants,\nonline extremist accounts, are 4,876 public Facebook pages or groups that have\nshared information from the websites of 289 Southern Poverty Law Center\ndesignated extremist groups. By clustering the quantitative features followed\nby qualitative expert validation, we identify five roles surrounding extremist\nactivism: educators, solicitors, flamers, motivators, sympathizers. For\nexample, solicitors use links from extremist websites to attract donations and\nparticipation in extremist issues, whereas flamers share inflammatory extremist\ncontent inciting anger. We further investigate role dynamics such as, how\nstable these roles are over time and how likely will extremist accounts\ntransition from one role into another. We find that roles core to the movement,\neducators and solicitors, are more stable, while flamers and motivators can\ntransition to sympathizers with high probability. We further find that\neducators and solicitors exert the most influence in triggering extremist link\nposts, whereas flamers are influential in triggering the spread of information\nfrom fake news sources. Our results help in situating various roles on the\ntrajectory of deeper engagement into the extremist movements and understanding\nthe potential effect of various counter extremism interventions. Our findings\nhave implications for understanding how online extremist movements flourish\nthrough participatory activism and how they gain a spectrum of allies for\nmobilizing extremism online.'}, 'authors': [{'name': 'Shruti Phadke'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_comment': 'Accepted at Computer Supported Cooperative Work (CSCW 2021)', 'links': [{'href': 'http://arxiv.org/abs/2105.08827v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.08827v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
69,http://arxiv.org/abs/2105.07698v1,2021-05-17 09:34:03+00:00,2021-05-17 09:34:03+00:00,Automatic Fake News Detection: Are Models Learning to Reason?,"[arxiv.Result.Author('Casper Hansen'), arxiv.Result.Author('Christian Hansen'), arxiv.Result.Author('Lucas Chaves Lima')]","Most fact checking models for automatic fake news detection are based on
reasoning: given a claim with associated evidence, the models aim to estimate
the claim veracity based on the supporting or refuting content within the
evidence. When these models perform well, it is generally assumed to be due to
the models having learned to reason over the evidence with regards to the
claim. In this paper, we investigate this assumption of reasoning, by exploring
the relationship and importance of both claim and evidence. Surprisingly, we
find on political fact checking datasets that most often the highest
effectiveness is obtained by utilizing only the evidence, as the impact of
including the claim is either negligible or harmful to the effectiveness. This
highlights an important problem in what constitutes evidence in existing
approaches for automatic fake news detection.",Accepted at ACL 2021,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2105.07698v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.07698v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.07698v1,"{'id': 'http://arxiv.org/abs/2105.07698v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.07698v1', 'updated': '2021-05-17T09:34:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=17, tm_hour=9, tm_min=34, tm_sec=3, tm_wday=0, tm_yday=137, tm_isdst=0), 'published': '2021-05-17T09:34:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=17, tm_hour=9, tm_min=34, tm_sec=3, tm_wday=0, tm_yday=137, tm_isdst=0), 'title': 'Automatic Fake News Detection: Are Models Learning to Reason?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic Fake News Detection: Are Models Learning to Reason?'}, 'summary': 'Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.'}, 'authors': [{'name': 'Casper Hansen'}, {'name': 'Christian Hansen'}, {'name': 'Lucas Chaves Lima'}], 'author_detail': {'name': 'Lucas Chaves Lima'}, 'author': 'Lucas Chaves Lima', 'arxiv_comment': 'Accepted at ACL 2021', 'links': [{'href': 'http://arxiv.org/abs/2105.07698v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.07698v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
70,http://arxiv.org/abs/2105.03143v1,2021-05-07 09:52:44+00:00,2021-05-07 09:52:44+00:00,AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech Detection Dataset,"[arxiv.Result.Author('Mohamed Seghir Hadj Ameur'), arxiv.Result.Author('Hassina Aliane')]","Along with the COVID-19 pandemic, an ""infodemic"" of false and misleading
information has emerged and has complicated the COVID-19 response efforts.
Social networking sites such as Facebook and Twitter have contributed largely
to the spread of rumors, conspiracy theories, hate, xenophobia, racism, and
prejudice. To combat the spread of fake news, researchers around the world have
and are still making considerable efforts to build and share COVID-19 related
research articles, models, and datasets. This paper releases ""AraCOVID19-MFH"" a
manually annotated multi-label Arabic COVID-19 fake news and hate speech
detection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10
different labels. The labels have been designed to consider some aspects
relevant to the fact-checking task, such as the tweet's check worthiness,
positivity/negativity, and factuality. To confirm our annotated dataset's
practical utility, we used it to train and evaluate several classification
models and reported the obtained results. Though the dataset is mainly designed
for fake news detection, it can also be used for hate speech detection,
opinion/news classification, dialect identification, and many other tasks.",,,,cs.CL,"['cs.CL', 'cs.AI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2105.03143v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.03143v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.03143v1,"{'id': 'http://arxiv.org/abs/2105.03143v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.03143v1', 'updated': '2021-05-07T09:52:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=7, tm_hour=9, tm_min=52, tm_sec=44, tm_wday=4, tm_yday=127, tm_isdst=0), 'published': '2021-05-07T09:52:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=7, tm_hour=9, tm_min=52, tm_sec=44, tm_wday=4, tm_yday=127, tm_isdst=0), 'title': 'AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset'}, 'summary': 'Along with the COVID-19 pandemic, an ""infodemic"" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases ""AraCOVID19-MFH"" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet\'s check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset\'s\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Along with the COVID-19 pandemic, an ""infodemic"" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases ""AraCOVID19-MFH"" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet\'s check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset\'s\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.'}, 'authors': [{'name': 'Mohamed Seghir Hadj Ameur'}, {'name': 'Hassina Aliane'}], 'author_detail': {'name': 'Hassina Aliane'}, 'author': 'Hassina Aliane', 'links': [{'href': 'http://arxiv.org/abs/2105.03143v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.03143v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
71,http://arxiv.org/abs/2104.12259v1,2021-04-25 21:19:24+00:00,2021-04-25 21:19:24+00:00,User Preference-aware Fake News Detection,"[arxiv.Result.Author('Yingtong Dou'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Congying Xia'), arxiv.Result.Author('Philip S. Yu'), arxiv.Result.Author('Lichao Sun')]","Disinformation and fake news have posed detrimental effects on individuals
and society in recent years, attracting broad attention to fake news detection.
The majority of existing fake news detection algorithms focus on mining news
content and/or the surrounding exogenous context for discovering deceptive
signals; while the endogenous preference of a user when he/she decides to
spread a piece of fake news or not is ignored. The confirmation bias theory has
indicated that a user is more likely to spread a piece of fake news when it
confirms his/her existing beliefs/preferences. Users' historical, social
engagements such as posts provide rich information about users' preferences
toward news and have great potential to advance fake news detection. However,
the work on exploring user preference for fake news detection is somewhat
limited. Therefore, in this paper, we study the novel problem of exploiting
user preference for fake news detection. We propose a new framework, UPFD,
which simultaneously captures various signals from user preferences by joint
content and graph modeling. Experimental results on real-world datasets
demonstrate the effectiveness of the proposed framework. We release our code
and data as a benchmark for GNN-based fake news detection:
https://github.com/safe-graph/GNN-FakeNews.","Accepted by SIGIR'21. Code is available at
  https://github.com/safe-graph/GNN-FakeNews",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2104.12259v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.12259v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.12259v1,"{'id': 'http://arxiv.org/abs/2104.12259v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.12259v1', 'updated': '2021-04-25T21:19:24Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=21, tm_min=19, tm_sec=24, tm_wday=6, tm_yday=115, tm_isdst=0), 'published': '2021-04-25T21:19:24Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=21, tm_min=19, tm_sec=24, tm_wday=6, tm_yday=115, tm_isdst=0), 'title': 'User Preference-aware Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'User Preference-aware Fake News Detection'}, 'summary': ""Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.""}, 'authors': [{'name': 'Yingtong Dou'}, {'name': 'Kai Shu'}, {'name': 'Congying Xia'}, {'name': 'Philip S. Yu'}, {'name': 'Lichao Sun'}], 'author_detail': {'name': 'Lichao Sun'}, 'author': 'Lichao Sun', 'arxiv_comment': ""Accepted by SIGIR'21. Code is available at\n  https://github.com/safe-graph/GNN-FakeNews"", 'links': [{'href': 'http://arxiv.org/abs/2104.12259v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.12259v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
72,http://arxiv.org/abs/2104.13352v2,2021-06-13 12:27:10+00:00,2021-04-24 08:54:02+00:00,Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of Red Fort Riots 2021,"[arxiv.Result.Author('Ajay Agarwal'), arxiv.Result.Author('Basant Agarwal')]","On 26 January 2021, India witnessed a national embarrassment from the
demographic least expected from - farmers. People across the nation watched in
horror as a pseudo-patriotic mob of farmers stormed capital Delhi and
vandalized the national pride- Red Fort. Investigations that followed the event
revealed the existence of a social media trail that led to the likes of such an
event. Consequently, it became essential and necessary to archive this trail
for social media analysis - not only to understand the bread-crumbs that are
dispersed across the trail but also to visualize the role played by
misinformation and fake news in this event. In this paper, we propose the
tractor2twitter dataset which contains around 0.05 million tweets that were
posted before, during, and after this event. Also, we benchmark our dataset
with an Explainable AI ML model for classification of each tweet into either of
the three categories - disinformation, misinformation, and opinion.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.13352v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13352v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13352v2,"{'id': 'http://arxiv.org/abs/2104.13352v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13352v2', 'updated': '2021-06-13T12:27:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=13, tm_hour=12, tm_min=27, tm_sec=10, tm_wday=6, tm_yday=164, tm_isdst=0), 'published': '2021-04-24T08:54:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=24, tm_hour=8, tm_min=54, tm_sec=2, tm_wday=5, tm_yday=114, tm_isdst=0), 'title': 'Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021'}, 'summary': 'On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.'}, 'authors': [{'name': 'Ajay Agarwal'}, {'name': 'Basant Agarwal'}], 'author_detail': {'name': 'Basant Agarwal'}, 'author': 'Basant Agarwal', 'links': [{'href': 'http://arxiv.org/abs/2104.13352v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13352v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
73,http://arxiv.org/abs/2104.11639v2,2021-05-01 18:22:39+00:00,2021-04-23 14:45:31+00:00,Claim Detection in Biomedical Twitter Posts,"[arxiv.Result.Author('Amelie Wührl'), arxiv.Result.Author('Roman Klinger')]","Social media contains unfiltered and unique information, which is potentially
of great value, but, in the case of misinformation, can also do great harm.
With regards to biomedical topics, false information can be particularly
dangerous. Methods of automatic fact-checking and fake news detection address
this problem, but have not been applied to the biomedical domain in social
media yet. We aim to fill this research gap and annotate a corpus of 1200
tweets for implicit and explicit biomedical claims (the latter also with span
annotations for the claim phrase). With this corpus, which we sample to be
related to COVID-19, measles, cystic fibrosis, and depression, we develop
baseline models which detect tweets that contain a claim automatically. Our
analyses reveal that biomedical tweets are densely populated with claims (45 %
in a corpus sampled to contain 1200 tweets focused on the domains mentioned
above). Baseline classification experiments with embedding-based classifiers
and BERT-based transfer learning demonstrate that the detection is challenging,
however, shows acceptable performance for the identification of explicit
expressions of claims. Implicit claim tweets are more challenging to detect.",Accepted at the BioNLP Workshop at NAACL 2021,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.11639v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.11639v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.11639v2,"{'id': 'http://arxiv.org/abs/2104.11639v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.11639v2', 'updated': '2021-05-01T18:22:39Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=1, tm_hour=18, tm_min=22, tm_sec=39, tm_wday=5, tm_yday=121, tm_isdst=0), 'published': '2021-04-23T14:45:31Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=23, tm_hour=14, tm_min=45, tm_sec=31, tm_wday=4, tm_yday=113, tm_isdst=0), 'title': 'Claim Detection in Biomedical Twitter Posts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Claim Detection in Biomedical Twitter Posts'}, 'summary': 'Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.'}, 'authors': [{'name': 'Amelie Wührl'}, {'name': 'Roman Klinger'}], 'author_detail': {'name': 'Roman Klinger'}, 'author': 'Roman Klinger', 'arxiv_comment': 'Accepted at the BioNLP Workshop at NAACL 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.11639v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.11639v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
74,http://arxiv.org/abs/2104.11476v2,2021-04-27 05:16:15+00:00,2021-04-23 08:47:54+00:00,Multimodal Fusion with BERT and Attention Mechanism for Fake News Detection,"[arxiv.Result.Author('Nguyen Manh Duc Tuan'), arxiv.Result.Author('Pham Quang Nhat Minh')]","Fake news detection is an important task for increasing the credibility of
information on the media since fake news is constantly spreading on social
media every day and it is a very serious concern in our society. Fake news is
usually created by manipulating images, texts, and videos. In this paper, we
present a novel method for detecting fake news by fusing multimodal features
derived from textual and visual data. Specifically, we used a pre-trained BERT
model to learn text features and a VGG-19 model pre-trained on the ImageNet
dataset to extract image features. We proposed a scale-dot product attention
mechanism to capture the relationship between text features and visual
features. Experimental results showed that our approach performs better than
the current state-of-the-art method on a public Twitter dataset by 3.1%
accuracy.",RIVF 2021,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.11476v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.11476v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.11476v2,"{'id': 'http://arxiv.org/abs/2104.11476v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.11476v2', 'updated': '2021-04-27T05:16:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=27, tm_hour=5, tm_min=16, tm_sec=15, tm_wday=1, tm_yday=117, tm_isdst=0), 'published': '2021-04-23T08:47:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=23, tm_hour=8, tm_min=47, tm_sec=54, tm_wday=4, tm_yday=113, tm_isdst=0), 'title': 'Multimodal Fusion with BERT and Attention Mechanism for Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multimodal Fusion with BERT and Attention Mechanism for Fake News\n  Detection'}, 'summary': 'Fake news detection is an important task for increasing the credibility of\ninformation on the media since fake news is constantly spreading on social\nmedia every day and it is a very serious concern in our society. Fake news is\nusually created by manipulating images, texts, and videos. In this paper, we\npresent a novel method for detecting fake news by fusing multimodal features\nderived from textual and visual data. Specifically, we used a pre-trained BERT\nmodel to learn text features and a VGG-19 model pre-trained on the ImageNet\ndataset to extract image features. We proposed a scale-dot product attention\nmechanism to capture the relationship between text features and visual\nfeatures. Experimental results showed that our approach performs better than\nthe current state-of-the-art method on a public Twitter dataset by 3.1%\naccuracy.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news detection is an important task for increasing the credibility of\ninformation on the media since fake news is constantly spreading on social\nmedia every day and it is a very serious concern in our society. Fake news is\nusually created by manipulating images, texts, and videos. In this paper, we\npresent a novel method for detecting fake news by fusing multimodal features\nderived from textual and visual data. Specifically, we used a pre-trained BERT\nmodel to learn text features and a VGG-19 model pre-trained on the ImageNet\ndataset to extract image features. We proposed a scale-dot product attention\nmechanism to capture the relationship between text features and visual\nfeatures. Experimental results showed that our approach performs better than\nthe current state-of-the-art method on a public Twitter dataset by 3.1%\naccuracy.'}, 'authors': [{'name': 'Nguyen Manh Duc Tuan'}, {'name': 'Pham Quang Nhat Minh'}], 'author_detail': {'name': 'Pham Quang Nhat Minh'}, 'author': 'Pham Quang Nhat Minh', 'arxiv_comment': 'RIVF 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.11476v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.11476v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
75,http://arxiv.org/abs/2104.06952v1,2021-04-14 16:25:22+00:00,2021-04-14 16:25:22+00:00,The Surprising Performance of Simple Baselines for Misinformation Detection,"[arxiv.Result.Author('Kellin Pelrine'), arxiv.Result.Author('Jacob Danovitch'), arxiv.Result.Author('Reihaneh Rabbany')]","As social media becomes increasingly prominent in our day to day lives, it is
increasingly important to detect informative content and prevent the spread of
disinformation and unverified rumours. While many sophisticated and successful
models have been proposed in the literature, they are often compared with older
NLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the
performance of a broad set of modern transformer-based language models and show
that with basic fine-tuning, these models are competitive with and can even
significantly outperform recently proposed state-of-the-art methods. We present
our framework as a baseline for creating and evaluating new methods for
misinformation detection. We further study a comprehensive set of benchmark
datasets, and discuss potential data leakage and the need for careful design of
the experiments and understanding of datasets to account for confounding
variables. As an extreme case example, we show that classifying only based on
the first three digits of tweet ids, which contain information on the date,
gives state-of-the-art performance on a commonly used benchmark dataset for
fake news detection --Twitter16. We provide a simple tool to detect this
problem and suggest steps to mitigate it in future datasets.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.06952v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.06952v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.06952v1,"{'id': 'http://arxiv.org/abs/2104.06952v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.06952v1', 'updated': '2021-04-14T16:25:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=22, tm_wday=2, tm_yday=104, tm_isdst=0), 'published': '2021-04-14T16:25:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=22, tm_wday=2, tm_yday=104, tm_isdst=0), 'title': 'The Surprising Performance of Simple Baselines for Misinformation\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Surprising Performance of Simple Baselines for Misinformation\n  Detection'}, 'summary': 'As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.'}, 'authors': [{'name': 'Kellin Pelrine'}, {'name': 'Jacob Danovitch'}, {'name': 'Reihaneh Rabbany'}], 'author_detail': {'name': 'Reihaneh Rabbany'}, 'author': 'Reihaneh Rabbany', 'links': [{'href': 'http://arxiv.org/abs/2104.06952v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.06952v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
76,http://arxiv.org/abs/2104.05321v1,2021-04-12 10:01:44+00:00,2021-04-12 10:01:44+00:00,Combining exogenous and endogenous signals with a semi-supervised co-attention network for early detection of COVID-19 fake tweets,"[arxiv.Result.Author('Rachit Bansal'), arxiv.Result.Author('William Scott Paka'), arxiv.Result.Author('Nidhi'), arxiv.Result.Author('Shubhashis Sengupta'), arxiv.Result.Author('Tanmoy Chakraborty')]","Fake tweets are observed to be ever-increasing, demanding immediate
countermeasures to combat their spread. During COVID-19, tweets with
misinformation should be flagged and neutralized in their early stages to
mitigate the damages. Most of the existing methods for early detection of fake
news assume to have enough propagation information for large labeled tweets --
which may not be an ideal setting for cases like COVID-19 where both aspects
are largely absent. In this work, we present ENDEMIC, a novel early detection
model which leverages exogenous and endogenous signals related to tweets, while
learning on limited labeled data. We first develop a novel dataset, called CTF
for early COVID-19 Twitter fake news, with additional behavioral test sets to
validate early detection. We build a heterogeneous graph with
follower-followee, user-tweet, and tweet-retweet connections and train a graph
embedding model to aggregate propagation information. Graph embeddings and
contextual features constitute endogenous, while time-relative web-scraped
information constitutes exogenous signals. ENDEMIC is trained in a
semi-supervised fashion, overcoming the challenge of limited labeled data. We
propose a co-attention mechanism to fuse signal representations optimally.
Experimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is
highly reliable in detecting early fake tweets, outperforming nine
state-of-the-art methods significantly.","Pacific-Asia Conference on Knowledge Discovery and Data Mining
  (PAKDD) 2021",,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.05321v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05321v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05321v1,"{'id': 'http://arxiv.org/abs/2104.05321v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05321v1', 'updated': '2021-04-12T10:01:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=10, tm_min=1, tm_sec=44, tm_wday=0, tm_yday=102, tm_isdst=0), 'published': '2021-04-12T10:01:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=10, tm_min=1, tm_sec=44, tm_wday=0, tm_yday=102, tm_isdst=0), 'title': 'Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets'}, 'summary': 'Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.'}, 'authors': [{'name': 'Rachit Bansal'}, {'name': 'William Scott Paka'}, {'name': 'Nidhi'}, {'name': 'Shubhashis Sengupta'}, {'name': 'Tanmoy Chakraborty'}], 'author_detail': {'name': 'Tanmoy Chakraborty'}, 'author': 'Tanmoy Chakraborty', 'arxiv_comment': 'Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.05321v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05321v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
77,http://arxiv.org/abs/2104.05243v1,2021-04-12 07:25:49+00:00,2021-04-12 07:25:49+00:00,On Unifying Misinformation Detection,"[arxiv.Result.Author('Nayeon Lee'), arxiv.Result.Author('Belinda Z. Li'), arxiv.Result.Author('Sinong Wang'), arxiv.Result.Author('Pascale Fung'), arxiv.Result.Author('Hao Ma'), arxiv.Result.Author('Wen-tau Yih'), arxiv.Result.Author('Madian Khabsa')]","In this paper, we introduce UnifiedM2, a general-purpose misinformation model
that jointly models multiple domains of misinformation with a single, unified
setup. The model is trained to handle four tasks: detecting news bias,
clickbait, fake news, and verifying rumors. By grouping these tasks together,
UnifiedM2learns a richer representation of misinformation, which leads to
state-of-the-art or comparable performance across all tasks. Furthermore, we
demonstrate that UnifiedM2's learned representation is helpful for few-shot
learning of unseen misinformation tasks/datasets and model's generalizability
to unseen events.",Accepted to NAACL2021,,,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2104.05243v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05243v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05243v1,"{'id': 'http://arxiv.org/abs/2104.05243v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05243v1', 'updated': '2021-04-12T07:25:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=7, tm_min=25, tm_sec=49, tm_wday=0, tm_yday=102, tm_isdst=0), 'published': '2021-04-12T07:25:49Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=7, tm_min=25, tm_sec=49, tm_wday=0, tm_yday=102, tm_isdst=0), 'title': 'On Unifying Misinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On Unifying Misinformation Detection'}, 'summary': ""In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.""}, 'authors': [{'name': 'Nayeon Lee'}, {'name': 'Belinda Z. Li'}, {'name': 'Sinong Wang'}, {'name': 'Pascale Fung'}, {'name': 'Hao Ma'}, {'name': 'Wen-tau Yih'}, {'name': 'Madian Khabsa'}], 'author_detail': {'name': 'Madian Khabsa'}, 'author': 'Madian Khabsa', 'arxiv_comment': 'Accepted to NAACL2021', 'links': [{'href': 'http://arxiv.org/abs/2104.05243v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05243v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
78,http://arxiv.org/abs/2104.04671v1,2021-04-10 03:05:34+00:00,2021-04-10 03:05:34+00:00,A Web Infrastructure for Certifying Multimedia News Content for Fake News Defense,"[arxiv.Result.Author('Edward L. Amoruso'), arxiv.Result.Author('Stephen P. Johnson'), arxiv.Result.Author('Raghu Avula'), arxiv.Result.Author('Cliff C. Zou')]","In dealing with altered visual multimedia content, also referred to as fake
news, we present a ready-to-deploy extension of the current public key
infrastructure (PKI), to provide an endorsement and integrity check platform
for newsworthy visual multimedia content. PKI, which is primarily used for Web
domain authentication, can directly be utilized with any visual multimedia
file. Unlike many other fake news researches that focus on technical multimedia
data processing and verification, we enable various news organizations to use
our developed program to certify/endorse a multimedia news content when they
believe this news piece is truthiness and newsworthy. Our program digitally
signs the multimedia news content with the news organization's private key, and
the endorsed news content can be posted not only by the endorser, but also by
any other websites. By installing a web browser extension developed by us, an
end user can easily verify whether a multimedia news content has been endorsed
and by which organization. During verification, our browser extension will
present to the end user a floating logo next to the image or video. This logo,
in the shape of a shield, will show whether the image has been endorsed, by
which news organization, and a few more pieces of essential text information of
the news multimedia content. The proposed system can be easily integrated to
other closed-web system such as social media networks and easily applied to
other non-visual multimedia files.","7 pages, 6 figures",,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.04671v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04671v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04671v1,"{'id': 'http://arxiv.org/abs/2104.04671v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04671v1', 'updated': '2021-04-10T03:05:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=10, tm_hour=3, tm_min=5, tm_sec=34, tm_wday=5, tm_yday=100, tm_isdst=0), 'published': '2021-04-10T03:05:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=10, tm_hour=3, tm_min=5, tm_sec=34, tm_wday=5, tm_yday=100, tm_isdst=0), 'title': 'A Web Infrastructure for Certifying Multimedia News Content for Fake\n  News Defense', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Web Infrastructure for Certifying Multimedia News Content for Fake\n  News Defense'}, 'summary': ""In dealing with altered visual multimedia content, also referred to as fake\nnews, we present a ready-to-deploy extension of the current public key\ninfrastructure (PKI), to provide an endorsement and integrity check platform\nfor newsworthy visual multimedia content. PKI, which is primarily used for Web\ndomain authentication, can directly be utilized with any visual multimedia\nfile. Unlike many other fake news researches that focus on technical multimedia\ndata processing and verification, we enable various news organizations to use\nour developed program to certify/endorse a multimedia news content when they\nbelieve this news piece is truthiness and newsworthy. Our program digitally\nsigns the multimedia news content with the news organization's private key, and\nthe endorsed news content can be posted not only by the endorser, but also by\nany other websites. By installing a web browser extension developed by us, an\nend user can easily verify whether a multimedia news content has been endorsed\nand by which organization. During verification, our browser extension will\npresent to the end user a floating logo next to the image or video. This logo,\nin the shape of a shield, will show whether the image has been endorsed, by\nwhich news organization, and a few more pieces of essential text information of\nthe news multimedia content. The proposed system can be easily integrated to\nother closed-web system such as social media networks and easily applied to\nother non-visual multimedia files."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In dealing with altered visual multimedia content, also referred to as fake\nnews, we present a ready-to-deploy extension of the current public key\ninfrastructure (PKI), to provide an endorsement and integrity check platform\nfor newsworthy visual multimedia content. PKI, which is primarily used for Web\ndomain authentication, can directly be utilized with any visual multimedia\nfile. Unlike many other fake news researches that focus on technical multimedia\ndata processing and verification, we enable various news organizations to use\nour developed program to certify/endorse a multimedia news content when they\nbelieve this news piece is truthiness and newsworthy. Our program digitally\nsigns the multimedia news content with the news organization's private key, and\nthe endorsed news content can be posted not only by the endorser, but also by\nany other websites. By installing a web browser extension developed by us, an\nend user can easily verify whether a multimedia news content has been endorsed\nand by which organization. During verification, our browser extension will\npresent to the end user a floating logo next to the image or video. This logo,\nin the shape of a shield, will show whether the image has been endorsed, by\nwhich news organization, and a few more pieces of essential text information of\nthe news multimedia content. The proposed system can be easily integrated to\nother closed-web system such as social media networks and easily applied to\nother non-visual multimedia files.""}, 'authors': [{'name': 'Edward L. Amoruso'}, {'name': 'Stephen P. Johnson'}, {'name': 'Raghu Avula'}, {'name': 'Cliff C. Zou'}], 'author_detail': {'name': 'Cliff C. Zou'}, 'author': 'Cliff C. Zou', 'arxiv_comment': '7 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2104.04671v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04671v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
79,http://arxiv.org/abs/2104.01791v1,2021-04-05 06:35:30+00:00,2021-04-05 06:35:30+00:00,A Heuristic-driven Uncertainty based Ensemble Framework for Fake News Detection in Tweets and News Articles,"[arxiv.Result.Author('Sourya Dipta Das'), arxiv.Result.Author('Ayan Basak'), arxiv.Result.Author('Saikat Dutta')]","The significance of social media has increased manifold in the past few
decades as it helps people from even the most remote corners of the world to
stay connected. With the advent of technology, digital media has become more
relevant and widely used than ever before and along with this, there has been a
resurgence in the circulation of fake news and tweets that demand immediate
attention. In this paper, we describe a novel Fake News Detection system that
automatically identifies whether a news item is ""real"" or ""fake"", as an
extension of our work in the CONSTRAINT COVID-19 Fake News Detection in English
challenge. We have used an ensemble model consisting of pre-trained models
followed by a statistical feature fusion network , along with a novel heuristic
algorithm by incorporating various attributes present in news items or tweets
like source, username handles, URL domains and authors as statistical feature.
Our proposed framework have also quantified reliable predictive uncertainty
along with proper class output confidence level for the classification task. We
have evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet
dataset to show the effectiveness of the proposed algorithm on detecting fake
news in short news content as well as in news articles. We obtained a best
F1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9073 on the
FakeNewsNet dataset.","submitted to Neurocomputing. arXiv admin note: substantial text
  overlap with arXiv:2101.03545",,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.01791v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.01791v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.01791v1,"{'id': 'http://arxiv.org/abs/2104.01791v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.01791v1', 'updated': '2021-04-05T06:35:30Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=5, tm_hour=6, tm_min=35, tm_sec=30, tm_wday=0, tm_yday=95, tm_isdst=0), 'published': '2021-04-05T06:35:30Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=5, tm_hour=6, tm_min=35, tm_sec=30, tm_wday=0, tm_yday=95, tm_isdst=0), 'title': 'A Heuristic-driven Uncertainty based Ensemble Framework for Fake News\n  Detection in Tweets and News Articles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Heuristic-driven Uncertainty based Ensemble Framework for Fake News\n  Detection in Tweets and News Articles'}, 'summary': 'The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world to\nstay connected. With the advent of technology, digital media has become more\nrelevant and widely used than ever before and along with this, there has been a\nresurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe a novel Fake News Detection system that\nautomatically identifies whether a news item is ""real"" or ""fake"", as an\nextension of our work in the CONSTRAINT COVID-19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models\nfollowed by a statistical feature fusion network , along with a novel heuristic\nalgorithm by incorporating various attributes present in news items or tweets\nlike source, username handles, URL domains and authors as statistical feature.\nOur proposed framework have also quantified reliable predictive uncertainty\nalong with proper class output confidence level for the classification task. We\nhave evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet\ndataset to show the effectiveness of the proposed algorithm on detecting fake\nnews in short news content as well as in news articles. We obtained a best\nF1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9073 on the\nFakeNewsNet dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world to\nstay connected. With the advent of technology, digital media has become more\nrelevant and widely used than ever before and along with this, there has been a\nresurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe a novel Fake News Detection system that\nautomatically identifies whether a news item is ""real"" or ""fake"", as an\nextension of our work in the CONSTRAINT COVID-19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models\nfollowed by a statistical feature fusion network , along with a novel heuristic\nalgorithm by incorporating various attributes present in news items or tweets\nlike source, username handles, URL domains and authors as statistical feature.\nOur proposed framework have also quantified reliable predictive uncertainty\nalong with proper class output confidence level for the classification task. We\nhave evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet\ndataset to show the effectiveness of the proposed algorithm on detecting fake\nnews in short news content as well as in news articles. We obtained a best\nF1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9073 on the\nFakeNewsNet dataset.'}, 'authors': [{'name': 'Sourya Dipta Das'}, {'name': 'Ayan Basak'}, {'name': 'Saikat Dutta'}], 'author_detail': {'name': 'Saikat Dutta'}, 'author': 'Saikat Dutta', 'arxiv_comment': 'submitted to Neurocomputing. arXiv admin note: substantial text\n  overlap with arXiv:2101.03545', 'links': [{'href': 'http://arxiv.org/abs/2104.01791v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.01791v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
80,http://arxiv.org/abs/2103.15581v1,2021-03-29 12:56:59+00:00,2021-03-29 12:56:59+00:00,Supporting verification of news articles with automated search for semantically similar articles,"[arxiv.Result.Author('Vishwani Gupta'), arxiv.Result.Author('Katharina Beckh'), arxiv.Result.Author('Sven Giesselbach'), arxiv.Result.Author('Dennis Wegener'), arxiv.Result.Author('Tim Wirtz')]","Fake information poses one of the major threats for society in the 21st
century. Identifying misinformation has become a key challenge due to the
amount of fake news that is published daily. Yet, no approach is established
that addresses the dynamics and versatility of fake news editorials. Instead of
classifying content, we propose an evidence retrieval approach to handle fake
news. The learning task is formulated as an unsupervised machine learning
problem. For validation purpose, we provide the user with a set of news
articles from reliable news sources supporting the hypothesis of the news
article in query and the final decision is left to the user. Technically we
propose a two-step process: (i) Aggregation-step: With information extracted
from the given text we query for similar content from reliable news sources.
(ii) Refining-step: We narrow the supporting evidence down by measuring the
semantic distance of the text with the collection from step (i). The distance
is calculated based on Word2Vec and the Word Mover's Distance. In our
experiments, only content that is below a certain distance threshold is
considered as supporting evidence. We find that our approach is agnostic to
concept drifts, i.e. the machine learning task is independent of the hypotheses
in a text. This makes it highly adaptable in times where fake news is as
diverse as classical news is. Our pipeline offers the possibility for further
analysis in the future, such as investigating bias and differences in news
reporting.",,,,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2103.15581v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.15581v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.15581v1,"{'id': 'http://arxiv.org/abs/2103.15581v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.15581v1', 'updated': '2021-03-29T12:56:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=29, tm_hour=12, tm_min=56, tm_sec=59, tm_wday=0, tm_yday=88, tm_isdst=0), 'published': '2021-03-29T12:56:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=29, tm_hour=12, tm_min=56, tm_sec=59, tm_wday=0, tm_yday=88, tm_isdst=0), 'title': 'Supporting verification of news articles with automated search for\n  semantically similar articles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Supporting verification of news articles with automated search for\n  semantically similar articles'}, 'summary': ""Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting.""}, 'authors': [{'name': 'Vishwani Gupta'}, {'name': 'Katharina Beckh'}, {'name': 'Sven Giesselbach'}, {'name': 'Dennis Wegener'}, {'name': 'Tim Wirtz'}], 'author_detail': {'name': 'Tim Wirtz'}, 'author': 'Tim Wirtz', 'links': [{'href': 'http://arxiv.org/abs/2103.15581v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.15581v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
81,http://arxiv.org/abs/2103.11804v2,2021-06-05 20:42:13+00:00,2021-03-22 13:07:26+00:00,Detection of fake news on CoViD-19 on Web Search Engines,"[arxiv.Result.Author('V. Mazzeo'), arxiv.Result.Author('A. Rapisarda'), arxiv.Result.Author('G. Giuffrida')]","In early January 2020, after China reported the first cases of the new
coronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully
accurate information has started spreading faster than the virus itself.
Alongside this pandemic, people have experienced a parallel infodemic, i.e., an
overabundance of information, some of which misleading or even harmful, that
has widely spread around the globe. Although Social Media are increasingly
being used as information source, Web Search Engines, like Google or Yahoo!,
still represent a powerful and trustworthy resource for finding information on
the Web. This is due to their capability to capture the largest amount of
information, helping users quickly identify the most relevant, useful, although
not always the most reliable, results for their search queries. This study aims
to detect potential misleading and fake contents by capturing and analysing
textual information, which flow through Search Engines. By using a real-world
dataset associated with recent CoViD-19 pandemic, we first apply re-sampling
techniques for class imbalance, then we use existing Machine Learning
algorithms for classification of not reliable news. By extracting lexical and
host-based features of associated Uniform Resource Locators (URLs) for news
articles, we show that the proposed methods, so common in phishing and
malicious URLs detection, can improve the efficiency and performance of
classifiers. Based on these findings, we suggest that the use of both textual
and URLs features can improve the effectiveness of fake news detection methods.",,,,cs.LG,"['cs.LG', 'cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2103.11804v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.11804v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.11804v2,"{'id': 'http://arxiv.org/abs/2103.11804v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.11804v2', 'updated': '2021-06-05T20:42:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=5, tm_hour=20, tm_min=42, tm_sec=13, tm_wday=5, tm_yday=156, tm_isdst=0), 'published': '2021-03-22T13:07:26Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=22, tm_hour=13, tm_min=7, tm_sec=26, tm_wday=0, tm_yday=81, tm_isdst=0), 'title': 'Detection of fake news on CoViD-19 on Web Search Engines', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detection of fake news on CoViD-19 on Web Search Engines'}, 'summary': 'In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.'}, 'authors': [{'name': 'V. Mazzeo'}, {'name': 'A. Rapisarda'}, {'name': 'G. Giuffrida'}], 'author_detail': {'name': 'G. Giuffrida'}, 'author': 'G. Giuffrida', 'links': [{'href': 'http://arxiv.org/abs/2103.11804v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.11804v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
82,http://arxiv.org/abs/2103.09602v1,2021-03-17 12:40:27+00:00,2021-03-17 12:40:27+00:00,On the Role of Images for Analyzing Claims in Social Media,"[arxiv.Result.Author('Gullal S. Cheema'), arxiv.Result.Author('Sherzod Hakimov'), arxiv.Result.Author('Eric Müller-Budack'), arxiv.Result.Author('Ralph Ewerth')]","Fake news is a severe problem in social media. In this paper, we present an
empirical study on visual, textual, and multimodal models for the tasks of
claim, claim check-worthiness, and conspiracy detection, all of which are
related to fake news detection. Recent work suggests that images are more
influential than text and often appear alongside fake text. To this end,
several multimodal models have been proposed in recent years that use images
along with text to detect fake news on social media sites like Twitter.
However, the role of images is not well understood for claim detection,
specifically using transformer-based textual and multimodal models. We
investigate state-of-the-art models for images, text (Transformer-based), and
multimodal information for four different datasets across two languages to
understand the role of images in the task of claim and conspiracy detection.",CLEOPATRA-2021 Workshop co-located with The Web Conf 2021,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CV']","[arxiv.Result.Link('http://arxiv.org/abs/2103.09602v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.09602v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.09602v1,"{'id': 'http://arxiv.org/abs/2103.09602v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.09602v1', 'updated': '2021-03-17T12:40:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=17, tm_hour=12, tm_min=40, tm_sec=27, tm_wday=2, tm_yday=76, tm_isdst=0), 'published': '2021-03-17T12:40:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=17, tm_hour=12, tm_min=40, tm_sec=27, tm_wday=2, tm_yday=76, tm_isdst=0), 'title': 'On the Role of Images for Analyzing Claims in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the Role of Images for Analyzing Claims in Social Media'}, 'summary': 'Fake news is a severe problem in social media. In this paper, we present an\nempirical study on visual, textual, and multimodal models for the tasks of\nclaim, claim check-worthiness, and conspiracy detection, all of which are\nrelated to fake news detection. Recent work suggests that images are more\ninfluential than text and often appear alongside fake text. To this end,\nseveral multimodal models have been proposed in recent years that use images\nalong with text to detect fake news on social media sites like Twitter.\nHowever, the role of images is not well understood for claim detection,\nspecifically using transformer-based textual and multimodal models. We\ninvestigate state-of-the-art models for images, text (Transformer-based), and\nmultimodal information for four different datasets across two languages to\nunderstand the role of images in the task of claim and conspiracy detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news is a severe problem in social media. In this paper, we present an\nempirical study on visual, textual, and multimodal models for the tasks of\nclaim, claim check-worthiness, and conspiracy detection, all of which are\nrelated to fake news detection. Recent work suggests that images are more\ninfluential than text and often appear alongside fake text. To this end,\nseveral multimodal models have been proposed in recent years that use images\nalong with text to detect fake news on social media sites like Twitter.\nHowever, the role of images is not well understood for claim detection,\nspecifically using transformer-based textual and multimodal models. We\ninvestigate state-of-the-art models for images, text (Transformer-based), and\nmultimodal information for four different datasets across two languages to\nunderstand the role of images in the task of claim and conspiracy detection.'}, 'authors': [{'name': 'Gullal S. Cheema'}, {'name': 'Sherzod Hakimov'}, {'name': 'Eric Müller-Budack'}, {'name': 'Ralph Ewerth'}], 'author_detail': {'name': 'Ralph Ewerth'}, 'author': 'Ralph Ewerth', 'arxiv_comment': 'CLEOPATRA-2021 Workshop co-located with The Web Conf 2021', 'links': [{'href': 'http://arxiv.org/abs/2103.09602v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.09602v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
83,http://arxiv.org/abs/2103.09258v1,2021-03-16 18:10:22+00:00,2021-03-16 18:10:22+00:00,The Rise and Fall of Fake News sites: A Traffic Analysis,"[arxiv.Result.Author('Manolis Chalkiadakis'), arxiv.Result.Author('Alexandros Kornilakis'), arxiv.Result.Author('Panagiotis Papadopoulos'), arxiv.Result.Author('Evangelos P. Markatos'), arxiv.Result.Author('Nicolas Kourtellis')]","Over the past decade, we have witnessed the rise of misinformation on the
Internet, with online users constantly falling victims of fake news. A
multitude of past studies have analyzed fake news diffusion mechanics and
detection and mitigation techniques. However, there are still open questions
about their operational behavior such as: How old are fake news websites? Do
they typically stay online for long periods of time? Do such websites
synchronize with each other their up and down time? Do they share similar
content through time? Which third-parties support their operations? How much
user traffic do they attract, in comparison to mainstream or real news
websites? In this paper, we perform a first of its kind investigation to answer
such questions regarding the online presence of fake news websites and
characterize their behavior in comparison to real news websites. Based on our
findings, we build a content-agnostic ML classifier for automatic detection of
fake news websites (i.e. accuracy) that are not yet included in manually
curated blacklists.",,,,cs.SI,"['cs.SI', 'cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2103.09258v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.09258v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.09258v1,"{'id': 'http://arxiv.org/abs/2103.09258v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.09258v1', 'updated': '2021-03-16T18:10:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=16, tm_hour=18, tm_min=10, tm_sec=22, tm_wday=1, tm_yday=75, tm_isdst=0), 'published': '2021-03-16T18:10:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=16, tm_hour=18, tm_min=10, tm_sec=22, tm_wday=1, tm_yday=75, tm_isdst=0), 'title': 'The Rise and Fall of Fake News sites: A Traffic Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Rise and Fall of Fake News sites: A Traffic Analysis'}, 'summary': 'Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.'}, 'authors': [{'name': 'Manolis Chalkiadakis'}, {'name': 'Alexandros Kornilakis'}, {'name': 'Panagiotis Papadopoulos'}, {'name': 'Evangelos P. Markatos'}, {'name': 'Nicolas Kourtellis'}], 'author_detail': {'name': 'Nicolas Kourtellis'}, 'author': 'Nicolas Kourtellis', 'links': [{'href': 'http://arxiv.org/abs/2103.09258v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.09258v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
84,http://arxiv.org/abs/2103.12506v1,2021-03-16 11:11:54+00:00,2021-03-16 11:11:54+00:00,A Survey on Predicting the Factuality and the Bias of News Media,"[arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Husrev Taha Sencar'), arxiv.Result.Author('Jisun An'), arxiv.Result.Author('Haewoon Kwak')]","The present level of proliferation of fake, biased, and propagandistic
content online has made it impossible to fact-check every single suspicious
claim or article, either manually or automatically. Thus, many researchers are
shifting their attention to higher granularity, aiming to profile entire news
outlets, which makes it possible to detect likely ""fake news"" the moment it is
published, by simply checking the reliability of its source. Source factuality
is also an important element of systems for automatic fact-checking and ""fake
news"" detection, as they need to assess the reliability of the evidence they
retrieve online. Political bias detection, which in the Western political
landscape is about predicting left-center-right bias, is an equally important
topic, which has experienced a similar shift towards profiling entire news
outlets. Moreover, there is a clear connection between the two, as highly
biased media are less likely to be factual; yet, the two problems have been
addressed separately. In this survey, we review the state of the art on media
profiling for factuality and bias, arguing for the need to model them jointly.
We further discuss interesting recent advances in using different information
sources and modalities, which go beyond the text of the articles the target
news outlet has published. Finally, we discuss current challenges and outline
future research directions.","factuality of reporting, fact-checking, political ideology, media
  bias, disinformation, propaganda, social media, news media",,,cs.SI,"['cs.SI', 'cs.CL', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2103.12506v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.12506v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.12506v1,"{'id': 'http://arxiv.org/abs/2103.12506v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.12506v1', 'updated': '2021-03-16T11:11:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=16, tm_hour=11, tm_min=11, tm_sec=54, tm_wday=1, tm_yday=75, tm_isdst=0), 'published': '2021-03-16T11:11:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=16, tm_hour=11, tm_min=11, tm_sec=54, tm_wday=1, tm_yday=75, tm_isdst=0), 'title': 'A Survey on Predicting the Factuality and the Bias of News Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Predicting the Factuality and the Bias of News Media'}, 'summary': 'The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely ""fake news"" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and ""fake\nnews"" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely ""fake news"" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and ""fake\nnews"" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.'}, 'authors': [{'name': 'Preslav Nakov'}, {'name': 'Husrev Taha Sencar'}, {'name': 'Jisun An'}, {'name': 'Haewoon Kwak'}], 'author_detail': {'name': 'Haewoon Kwak'}, 'author': 'Haewoon Kwak', 'arxiv_comment': 'factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media', 'links': [{'href': 'http://arxiv.org/abs/2103.12506v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.12506v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
85,http://arxiv.org/abs/2103.12541v1,2021-03-13 18:04:17+00:00,2021-03-13 18:04:17+00:00,A Survey on Multimodal Disinformation Detection,"[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Stefano Cresci'), arxiv.Result.Author('Tanmoy Chakraborty'), arxiv.Result.Author('Fabrizio Silvestri'), arxiv.Result.Author('Dimiter Dimitrov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Hamed Firooz'), arxiv.Result.Author('Preslav Nakov')]","Recent years have witnessed the proliferation of fake news, propaganda,
misinformation, and disinformation online. While initially this was mostly
about textual content, over time images and videos gained popularity, as they
are much easier to consume, attract much more attention, and spread further
than simple text. As a result, researchers started targeting different
modalities and combinations thereof. As different modalities are studied in
different research communities, with insufficient interaction, here we offer a
survey that explores the state-of-the-art on multimodal disinformation
detection covering various combinations of modalities: text, images, audio,
video, network structure, and temporal information. Moreover, while some
studies focused on factuality, others investigated how harmful the content is.
While these two components in the definition of disinformation -- (i)
factuality and (ii) harmfulness, are equally important, they are typically
studied in isolation. Thus, we argue for the need to tackle disinformation
detection by taking into account multiple modalities as well as both factuality
and harmfulness, in the same framework. Finally, we discuss current challenges
and future research directions.","disinformation, misinformation, factuality, harmfulness, fake news,
  propaganda, multimodality, text, images, videos, network structure,
  temporality",,,cs.MM,"['cs.MM', 'cs.AI', 'cs.CL', 'cs.CR', 'cs.CY', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2103.12541v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.12541v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.12541v1,"{'id': 'http://arxiv.org/abs/2103.12541v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.12541v1', 'updated': '2021-03-13T18:04:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=17, tm_wday=5, tm_yday=72, tm_isdst=0), 'published': '2021-03-13T18:04:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=17, tm_wday=5, tm_yday=72, tm_isdst=0), 'title': 'A Survey on Multimodal Disinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Multimodal Disinformation Detection'}, 'summary': 'Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Stefano Cresci'}, {'name': 'Tanmoy Chakraborty'}, {'name': 'Fabrizio Silvestri'}, {'name': 'Dimiter Dimitrov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Shaden Shaar'}, {'name': 'Hamed Firooz'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality', 'links': [{'href': 'http://arxiv.org/abs/2103.12541v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.12541v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
86,http://arxiv.org/abs/2103.05944v1,2021-03-10 09:01:34+00:00,2021-03-10 09:01:34+00:00,How does Truth Evolve into Fake News? An Empirical Study of Fake News Evolution,"[arxiv.Result.Author('Mingfei Guo'), arxiv.Result.Author('Xiuying Chen'), arxiv.Result.Author('Juntao Li'), arxiv.Result.Author('Dongyan Zhao'), arxiv.Result.Author('Rui Yan')]","Automatically identifying fake news from the Internet is a challenging
problem in deception detection tasks. Online news is modified constantly during
its propagation, e.g., malicious users distort the original truth and make up
fake news. However, the continuous evolution process would generate
unprecedented fake news and cheat the original model. We present the Fake News
Evolution (FNE) dataset: a new dataset tracking the fake news evolution
process. Our dataset is composed of 950 paired data, each of which consists of
articles representing the three significant phases of the evolution process,
which are the truth, the fake news, and the evolved fake news. We observe the
features during the evolution and they are the disinformation techniques, text
similarity, top 10 keywords, classification accuracy, parts of speech, and
sentiment properties.","5 pages, 2 figures","The Web Conference 2021, Workshop on News Recommendation and
  Intelligence",,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.05944v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.05944v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.05944v1,"{'id': 'http://arxiv.org/abs/2103.05944v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.05944v1', 'updated': '2021-03-10T09:01:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=10, tm_hour=9, tm_min=1, tm_sec=34, tm_wday=2, tm_yday=69, tm_isdst=0), 'published': '2021-03-10T09:01:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=10, tm_hour=9, tm_min=1, tm_sec=34, tm_wday=2, tm_yday=69, tm_isdst=0), 'title': 'How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution'}, 'summary': 'Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.'}, 'authors': [{'name': 'Mingfei Guo'}, {'name': 'Xiuying Chen'}, {'name': 'Juntao Li'}, {'name': 'Dongyan Zhao'}, {'name': 'Rui Yan'}], 'author_detail': {'name': 'Rui Yan'}, 'author': 'Rui Yan', 'arxiv_comment': '5 pages, 2 figures', 'arxiv_journal_ref': 'The Web Conference 2021, Workshop on News Recommendation and\n  Intelligence', 'links': [{'href': 'http://arxiv.org/abs/2103.05944v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.05944v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
87,http://arxiv.org/abs/2103.00747v1,2021-03-01 04:28:39+00:00,2021-03-01 04:28:39+00:00,Combat COVID-19 Infodemic Using Explainable Natural Language Processing Models,"[arxiv.Result.Author('Jackie Ayoub'), arxiv.Result.Author('X. Jessie Yang'), arxiv.Result.Author('Feng Zhou')]","Misinformation of COVID-19 is prevalent on social media as the pandemic
unfolds, and the associated risks are extremely high. Thus, it is critical to
detect and combat such misinformation. Recently, deep learning models using
natural language processing techniques, such as BERT (Bidirectional Encoder
Representations from Transformers), have achieved great successes in detecting
misinformation. In this paper, we proposed an explainable natural language
processing model based on DistilBERT and SHAP (Shapley Additive exPlanations)
to combat misinformation about COVID-19 due to their efficiency and
effectiveness. First, we collected a dataset of 984 claims about COVID-19 with
fact checking. By augmenting the data using back-translation, we doubled the
sample size of the dataset and the DistilBERT model was able to obtain good
performance (accuracy: 0.972; areas under the curve: 0.993) in detecting
misinformation about COVID-19. Our model was also tested on a larger dataset
for AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good
performance (accuracy: 0.938; areas under the curve: 0.985). The performance on
both datasets was better than traditional machine learning models. Second, in
order to boost public trust in model prediction, we employed SHAP to improve
model explainability, which was further evaluated using a between-subjects
experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),
and text+SHAP explanation+source and evidence (TSESE). The participants were
significantly more likely to trust and share information related to COVID-19 in
the TSE and TSESE conditions than in the T condition. Our results provided good
implications in detecting misinformation about COVID-19 and improving public
trust.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.00747v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.00747v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.00747v1,"{'id': 'http://arxiv.org/abs/2103.00747v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.00747v1', 'updated': '2021-03-01T04:28:39Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=4, tm_min=28, tm_sec=39, tm_wday=0, tm_yday=60, tm_isdst=0), 'published': '2021-03-01T04:28:39Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=4, tm_min=28, tm_sec=39, tm_wday=0, tm_yday=60, tm_isdst=0), 'title': 'Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models'}, 'summary': 'Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.'}, 'authors': [{'name': 'Jackie Ayoub'}, {'name': 'X. Jessie Yang'}, {'name': 'Feng Zhou'}], 'author_detail': {'name': 'Feng Zhou'}, 'author': 'Feng Zhou', 'links': [{'href': 'http://arxiv.org/abs/2103.00747v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.00747v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
88,http://arxiv.org/abs/2102.13433v1,2021-02-26 12:39:03+00:00,2021-02-26 12:39:03+00:00,An organized review of key factors for fake news detection,"[arxiv.Result.Author('Nuno Guimarães'), arxiv.Result.Author('Álvaro Figueira'), arxiv.Result.Author('Luís Torgo')]","Fake news in social media has quickly become one of the most discussed topics
in today's society. With false information proliferating and causing a
significant impact in the political, economical, and social domains, research
efforts to analyze and automatically identify this type of content have being
conducted in the past few years. In this paper, we attempt to summarize the
principal findings on the topic of fake news in social media, highlighting the
main research path taken and giving a particular focus on the detection of fake
news and bot accounts.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2102.13433v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.13433v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.13433v1,"{'id': 'http://arxiv.org/abs/2102.13433v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.13433v1', 'updated': '2021-02-26T12:39:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=26, tm_hour=12, tm_min=39, tm_sec=3, tm_wday=4, tm_yday=57, tm_isdst=0), 'published': '2021-02-26T12:39:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=26, tm_hour=12, tm_min=39, tm_sec=3, tm_wday=4, tm_yday=57, tm_isdst=0), 'title': 'An organized review of key factors for fake news detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An organized review of key factors for fake news detection'}, 'summary': ""Fake news in social media has quickly become one of the most discussed topics\nin today's society. With false information proliferating and causing a\nsignificant impact in the political, economical, and social domains, research\nefforts to analyze and automatically identify this type of content have being\nconducted in the past few years. In this paper, we attempt to summarize the\nprincipal findings on the topic of fake news in social media, highlighting the\nmain research path taken and giving a particular focus on the detection of fake\nnews and bot accounts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news in social media has quickly become one of the most discussed topics\nin today's society. With false information proliferating and causing a\nsignificant impact in the political, economical, and social domains, research\nefforts to analyze and automatically identify this type of content have being\nconducted in the past few years. In this paper, we attempt to summarize the\nprincipal findings on the topic of fake news in social media, highlighting the\nmain research path taken and giving a particular focus on the detection of fake\nnews and bot accounts.""}, 'authors': [{'name': 'Nuno Guimarães'}, {'name': 'Álvaro Figueira'}, {'name': 'Luís Torgo'}], 'author_detail': {'name': 'Luís Torgo'}, 'author': 'Luís Torgo', 'links': [{'href': 'http://arxiv.org/abs/2102.13433v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.13433v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
89,http://arxiv.org/abs/2102.11276v1,2021-02-23 16:47:41+00:00,2021-02-23 16:47:41+00:00,Factorization of Fact-Checks for Low Resource Indian Languages,"[arxiv.Result.Author('Shivangi Singhal'), arxiv.Result.Author('Rajiv Ratn Shah'), arxiv.Result.Author('Ponnurangam Kumaraguru')]","The advancement in technology and accessibility of internet to each
individual is revolutionizing the real time information. The liberty to express
your thoughts without passing through any credibility check is leading to
dissemination of fake content in the ecosystem. It can have disastrous effects
on both individuals and society as a whole. The amplification of fake news is
becoming rampant in India too. Debunked information often gets republished with
a replacement description, claiming it to depict some different incidence. To
curb such fabricated stories, it is necessary to investigate such deduplicates
and false claims made in public. The majority of studies on automatic
fact-checking and fake news detection is restricted to English only. But for a
country like India where only 10% of the literate population speak English,
role of regional languages in spreading falsity cannot be undermined. In this
paper, we introduce FactDRIL: the first large scale multilingual Fact-checking
Dataset for Regional Indian Languages. We collect an exhaustive dataset across
7 months covering 11 low-resource languages. Our propose dataset consists of
9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222
samples are distributed across various regional languages, i.e. Bangla,
Marathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and
Burmese. We also present the detailed characterization of three M's
(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the
complete list of other varied attributes making it a unique dataset to study.
Lastly, we present some potential use cases of the dataset. We expect this
dataset will be a valuable resource and serve as a starting point to fight
proliferation of fake news in low resource languages.","15 pages, 6 figures",,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2102.11276v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.11276v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.11276v1,"{'id': 'http://arxiv.org/abs/2102.11276v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.11276v1', 'updated': '2021-02-23T16:47:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=23, tm_hour=16, tm_min=47, tm_sec=41, tm_wday=1, tm_yday=54, tm_isdst=0), 'published': '2021-02-23T16:47:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=23, tm_hour=16, tm_min=47, tm_sec=41, tm_wday=1, tm_yday=54, tm_isdst=0), 'title': 'Factorization of Fact-Checks for Low Resource Indian Languages', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Factorization of Fact-Checks for Low Resource Indian Languages'}, 'summary': ""The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages.""}, 'authors': [{'name': 'Shivangi Singhal'}, {'name': 'Rajiv Ratn Shah'}, {'name': 'Ponnurangam Kumaraguru'}], 'author_detail': {'name': 'Ponnurangam Kumaraguru'}, 'author': 'Ponnurangam Kumaraguru', 'arxiv_comment': '15 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2102.11276v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.11276v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
90,http://arxiv.org/abs/2102.09470v1,2021-02-18 16:42:28+00:00,2021-02-18 16:42:28+00:00,Fake News Detection: a comparison between available Deep Learning techniques in vector space,[arxiv.Result.Author('Lovedeep Singh')],"Fake News Detection is an essential problem in the field of Natural Language
Processing. The benefits of an effective solution in this area are manifold for
the goodwill of society. On a surface level, it broadly matches with the
general problem of text classification. Researchers have proposed various
approaches to tackle fake news using simple as well as some complex techniques.
In this paper, we try to make a comparison between the present Deep Learning
techniques by representing the news instances in some vector space using a
combination of common mathematical operations with available vector space
representations. We do a number of experiments using various combinations and
permutations. Finally, we conclude with a sound analysis of the results and
evaluate the reasons for such results.","for citiation purpose, use details available on official IEEE Xplore
  page: https://doi.org/10.1109/CICT51604.2020.9312099","2020 IEEE 4th Conference on Information & Communication Technology
  (CICT)",10.1109/CICT51604.2020.9312099,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://dx.doi.org/10.1109/CICT51604.2020.9312099', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2102.09470v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.09470v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.09470v1,"{'id': 'http://arxiv.org/abs/2102.09470v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.09470v1', 'updated': '2021-02-18T16:42:28Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=42, tm_sec=28, tm_wday=3, tm_yday=49, tm_isdst=0), 'published': '2021-02-18T16:42:28Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=42, tm_sec=28, tm_wday=3, tm_yday=49, tm_isdst=0), 'title': 'Fake News Detection: a comparison between available Deep Learning\n  techniques in vector space', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection: a comparison between available Deep Learning\n  techniques in vector space'}, 'summary': 'Fake News Detection is an essential problem in the field of Natural Language\nProcessing. The benefits of an effective solution in this area are manifold for\nthe goodwill of society. On a surface level, it broadly matches with the\ngeneral problem of text classification. Researchers have proposed various\napproaches to tackle fake news using simple as well as some complex techniques.\nIn this paper, we try to make a comparison between the present Deep Learning\ntechniques by representing the news instances in some vector space using a\ncombination of common mathematical operations with available vector space\nrepresentations. We do a number of experiments using various combinations and\npermutations. Finally, we conclude with a sound analysis of the results and\nevaluate the reasons for such results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection is an essential problem in the field of Natural Language\nProcessing. The benefits of an effective solution in this area are manifold for\nthe goodwill of society. On a surface level, it broadly matches with the\ngeneral problem of text classification. Researchers have proposed various\napproaches to tackle fake news using simple as well as some complex techniques.\nIn this paper, we try to make a comparison between the present Deep Learning\ntechniques by representing the news instances in some vector space using a\ncombination of common mathematical operations with available vector space\nrepresentations. We do a number of experiments using various combinations and\npermutations. Finally, we conclude with a sound analysis of the results and\nevaluate the reasons for such results.'}, 'authors': [{'name': 'Lovedeep Singh'}], 'author_detail': {'name': 'Lovedeep Singh'}, 'author': 'Lovedeep Singh', 'arxiv_doi': '10.1109/CICT51604.2020.9312099', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/CICT51604.2020.9312099', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2102.09470v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.09470v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'for citiation purpose, use details available on official IEEE Xplore\n  page: https://doi.org/10.1109/CICT51604.2020.9312099', 'arxiv_journal_ref': '2020 IEEE 4th Conference on Information & Communication Technology\n  (CICT)', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
91,http://arxiv.org/abs/2102.08924v3,2021-04-13 08:38:02+00:00,2021-02-17 18:30:43+00:00,Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for COVID-19 Fake News Detection,"[arxiv.Result.Author('William Scott Paka'), arxiv.Result.Author('Rachit Bansal'), arxiv.Result.Author('Abhay Kaushik'), arxiv.Result.Author('Shubhashis Sengupta'), arxiv.Result.Author('Tanmoy Chakraborty')]","As the COVID-19 pandemic sweeps across the world, it has been accompanied by
a tsunami of fake news and misinformation on social media. At the time when
reliable information is vital for public health and safety, COVID-19 related
fake news has been spreading even faster than the facts. During times such as
the COVID-19 pandemic, fake news can not only cause intellectual confusion but
can also place lives of people at risk. This calls for an immediate need to
contain the spread of such misinformation on social media. We introduce CTF,
the first COVID-19 Twitter fake news dataset with labeled genuine and fake
tweets. Additionally, we propose Cross-SEAN, a cross-stitch based
semi-supervised end-to-end neural attention model, which leverages the large
amount of unlabelled data. Cross-SEAN partially generalises to emerging fake
news as it learns from relevant external knowledge. We compare Cross-SEAN with
seven state-of-the-art fake news detection methods. We observe that it achieves
$0.95$ F1 Score on CTF, outperforming the best baseline by $9\%$. We also
develop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time
detection of fake tweets.",The Journal of Applied Soft Computing,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2102.08924v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.08924v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.08924v3,"{'id': 'http://arxiv.org/abs/2102.08924v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.08924v3', 'updated': '2021-04-13T08:38:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=13, tm_hour=8, tm_min=38, tm_sec=2, tm_wday=1, tm_yday=103, tm_isdst=0), 'published': '2021-02-17T18:30:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=30, tm_sec=43, tm_wday=2, tm_yday=48, tm_isdst=0), 'title': 'Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection'}, 'summary': 'As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.'}, 'authors': [{'name': 'William Scott Paka'}, {'name': 'Rachit Bansal'}, {'name': 'Abhay Kaushik'}, {'name': 'Shubhashis Sengupta'}, {'name': 'Tanmoy Chakraborty'}], 'author_detail': {'name': 'Tanmoy Chakraborty'}, 'author': 'Tanmoy Chakraborty', 'arxiv_comment': 'The Journal of Applied Soft Computing', 'links': [{'href': 'http://arxiv.org/abs/2102.08924v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.08924v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
92,http://arxiv.org/abs/2102.06314v4,2021-02-24 07:03:59+00:00,2021-02-11 23:31:14+00:00,Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data,"[arxiv.Result.Author('Amila Silva'), arxiv.Result.Author('Ling Luo'), arxiv.Result.Author('Shanika Karunasekera'), arxiv.Result.Author('Christopher Leckie')]","With the rapid evolution of social media, fake news has become a significant
social problem, which cannot be addressed in a timely manner using manual
investigation. This has motivated numerous studies on automating fake news
detection. Most studies explore supervised training models with different
modalities (e.g., text, images, and propagation networks) of news records to
identify fake news. However, the performance of such techniques generally drops
if news records are coming from different domains (e.g., politics,
entertainment), especially for domains that are unseen or rarely-seen during
training. As motivation, we empirically show that news records from different
domains have significantly different word usage and propagation patterns.
Furthermore, due to the sheer volume of unlabelled news records, it is
challenging to select news records for manual labelling so that the
domain-coverage of the labelled dataset is maximized. Hence, this work: (1)
proposes a novel framework that jointly preserves domain-specific and
cross-domain knowledge in news records to detect fake news from different
domains; and (2) introduces an unsupervised technique to select a set of
unlabelled informative news records for manual labelling, which can be
ultimately used to train a fake news detection model that performs well for
many domains while minimizing the labelling cost. Our experiments show that the
integration of the proposed fake news model and the selective annotation
approach achieves state-of-the-art performance for cross-domain news datasets,
while yielding notable improvements for rarely-appearing domains in news
datasets.",,,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2102.06314v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.06314v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.06314v4,"{'id': 'http://arxiv.org/abs/2102.06314v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.06314v4', 'updated': '2021-02-24T07:03:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=24, tm_hour=7, tm_min=3, tm_sec=59, tm_wday=2, tm_yday=55, tm_isdst=0), 'published': '2021-02-11T23:31:14Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=11, tm_hour=23, tm_min=31, tm_sec=14, tm_wday=3, tm_yday=42, tm_isdst=0), 'title': 'Embracing Domain Differences in Fake News: Cross-domain Fake News\n  Detection using Multi-modal Data', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Embracing Domain Differences in Fake News: Cross-domain Fake News\n  Detection using Multi-modal Data'}, 'summary': 'With the rapid evolution of social media, fake news has become a significant\nsocial problem, which cannot be addressed in a timely manner using manual\ninvestigation. This has motivated numerous studies on automating fake news\ndetection. Most studies explore supervised training models with different\nmodalities (e.g., text, images, and propagation networks) of news records to\nidentify fake news. However, the performance of such techniques generally drops\nif news records are coming from different domains (e.g., politics,\nentertainment), especially for domains that are unseen or rarely-seen during\ntraining. As motivation, we empirically show that news records from different\ndomains have significantly different word usage and propagation patterns.\nFurthermore, due to the sheer volume of unlabelled news records, it is\nchallenging to select news records for manual labelling so that the\ndomain-coverage of the labelled dataset is maximized. Hence, this work: (1)\nproposes a novel framework that jointly preserves domain-specific and\ncross-domain knowledge in news records to detect fake news from different\ndomains; and (2) introduces an unsupervised technique to select a set of\nunlabelled informative news records for manual labelling, which can be\nultimately used to train a fake news detection model that performs well for\nmany domains while minimizing the labelling cost. Our experiments show that the\nintegration of the proposed fake news model and the selective annotation\napproach achieves state-of-the-art performance for cross-domain news datasets,\nwhile yielding notable improvements for rarely-appearing domains in news\ndatasets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the rapid evolution of social media, fake news has become a significant\nsocial problem, which cannot be addressed in a timely manner using manual\ninvestigation. This has motivated numerous studies on automating fake news\ndetection. Most studies explore supervised training models with different\nmodalities (e.g., text, images, and propagation networks) of news records to\nidentify fake news. However, the performance of such techniques generally drops\nif news records are coming from different domains (e.g., politics,\nentertainment), especially for domains that are unseen or rarely-seen during\ntraining. As motivation, we empirically show that news records from different\ndomains have significantly different word usage and propagation patterns.\nFurthermore, due to the sheer volume of unlabelled news records, it is\nchallenging to select news records for manual labelling so that the\ndomain-coverage of the labelled dataset is maximized. Hence, this work: (1)\nproposes a novel framework that jointly preserves domain-specific and\ncross-domain knowledge in news records to detect fake news from different\ndomains; and (2) introduces an unsupervised technique to select a set of\nunlabelled informative news records for manual labelling, which can be\nultimately used to train a fake news detection model that performs well for\nmany domains while minimizing the labelling cost. Our experiments show that the\nintegration of the proposed fake news model and the selective annotation\napproach achieves state-of-the-art performance for cross-domain news datasets,\nwhile yielding notable improvements for rarely-appearing domains in news\ndatasets.'}, 'authors': [{'name': 'Amila Silva'}, {'name': 'Ling Luo'}, {'name': 'Shanika Karunasekera'}, {'name': 'Christopher Leckie'}], 'author_detail': {'name': 'Christopher Leckie'}, 'author': 'Christopher Leckie', 'links': [{'href': 'http://arxiv.org/abs/2102.06314v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.06314v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
93,http://arxiv.org/abs/2102.04458v1,2021-02-08 21:36:00+00:00,2021-02-08 21:36:00+00:00,Detecting Fake News Using Machine Learning : A Systematic Literature Review,"[arxiv.Result.Author('Alim Al Ayub Ahmed'), arxiv.Result.Author('Ayman Aljabouh'), arxiv.Result.Author('Praveen Kumar Donepudi'), arxiv.Result.Author('Myung Suh Choi')]","Internet is one of the important inventions and a large number of persons are
its users. These persons use this for different purposes. There are different
social media platforms that are accessible to these users. Any user can make a
post or spread the news through the online platforms. These platforms do not
verify the users or their posts. So some of the users try to spread fake news
through these platforms. These news can be propaganda against an individual,
society, organization or political party. A human being is unable to detect all
these fake news. So there is a need for machine learning classifiers that can
detect these fake news automatically. Use of machine learning classifiers for
detecting fake news is described in this systematic literature review.","8 pages, 2 figures",,,cs.CY,"['cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2102.04458v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.04458v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.04458v1,"{'id': 'http://arxiv.org/abs/2102.04458v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.04458v1', 'updated': '2021-02-08T21:36:00Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=8, tm_hour=21, tm_min=36, tm_sec=0, tm_wday=0, tm_yday=39, tm_isdst=0), 'published': '2021-02-08T21:36:00Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=8, tm_hour=21, tm_min=36, tm_sec=0, tm_wday=0, tm_yday=39, tm_isdst=0), 'title': 'Detecting Fake News Using Machine Learning : A Systematic Literature\n  Review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Fake News Using Machine Learning : A Systematic Literature\n  Review'}, 'summary': 'Internet is one of the important inventions and a large number of persons are\nits users. These persons use this for different purposes. There are different\nsocial media platforms that are accessible to these users. Any user can make a\npost or spread the news through the online platforms. These platforms do not\nverify the users or their posts. So some of the users try to spread fake news\nthrough these platforms. These news can be propaganda against an individual,\nsociety, organization or political party. A human being is unable to detect all\nthese fake news. So there is a need for machine learning classifiers that can\ndetect these fake news automatically. Use of machine learning classifiers for\ndetecting fake news is described in this systematic literature review.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Internet is one of the important inventions and a large number of persons are\nits users. These persons use this for different purposes. There are different\nsocial media platforms that are accessible to these users. Any user can make a\npost or spread the news through the online platforms. These platforms do not\nverify the users or their posts. So some of the users try to spread fake news\nthrough these platforms. These news can be propaganda against an individual,\nsociety, organization or political party. A human being is unable to detect all\nthese fake news. So there is a need for machine learning classifiers that can\ndetect these fake news automatically. Use of machine learning classifiers for\ndetecting fake news is described in this systematic literature review.'}, 'authors': [{'name': 'Alim Al Ayub Ahmed'}, {'name': 'Ayman Aljabouh'}, {'name': 'Praveen Kumar Donepudi'}, {'name': 'Myung Suh Choi'}], 'author_detail': {'name': 'Myung Suh Choi'}, 'author': 'Myung Suh Choi', 'arxiv_comment': '8 pages, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/2102.04458v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.04458v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
94,http://arxiv.org/abs/2102.03537v1,2021-02-06 08:52:44+00:00,2021-02-06 08:52:44+00:00,Parameterized Complexity of Immunization in the Threshold Model,"[arxiv.Result.Author('Gennaro Cordasco'), arxiv.Result.Author('Luisa Gargano'), arxiv.Result.Author('Adele Anna Rescigno')]","We consider the problem of controlling the spread of harmful items in
networks, such as the contagion proliferation of diseases or the diffusion of
fake news. We assume the linear threshold model of diffusion where each node
has a threshold that measures the node resistance to the contagion. We study
the parameterized complexity of the problem: Given a network, a set of
initially contaminated nodes, and two integers $k$ and $\ell$, is it possible
to limit the diffusion to at most $k$ other nodes of the network by immunizing
at most $\ell$ nodes? We consider several parameters associated to the input,
including: the bounds $k$ and $\ell$, the maximum node degree $\Delta$, the
treewidth, and the neighborhood diversity of the network. We first give $W[1]$
or $W[2]$-hardness results for each of the considered parameters. Then we give
fixed-parameter algorithms for some parameter combinations.",,,,cs.CC,"['cs.CC', 'cs.DM', 'cs.DS', 'math.CO']","[arxiv.Result.Link('http://arxiv.org/abs/2102.03537v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.03537v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.03537v1,"{'id': 'http://arxiv.org/abs/2102.03537v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.03537v1', 'updated': '2021-02-06T08:52:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=6, tm_hour=8, tm_min=52, tm_sec=44, tm_wday=5, tm_yday=37, tm_isdst=0), 'published': '2021-02-06T08:52:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=6, tm_hour=8, tm_min=52, tm_sec=44, tm_wday=5, tm_yday=37, tm_isdst=0), 'title': 'Parameterized Complexity of Immunization in the Threshold Model', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Parameterized Complexity of Immunization in the Threshold Model'}, 'summary': 'We consider the problem of controlling the spread of harmful items in\nnetworks, such as the contagion proliferation of diseases or the diffusion of\nfake news. We assume the linear threshold model of diffusion where each node\nhas a threshold that measures the node resistance to the contagion. We study\nthe parameterized complexity of the problem: Given a network, a set of\ninitially contaminated nodes, and two integers $k$ and $\\ell$, is it possible\nto limit the diffusion to at most $k$ other nodes of the network by immunizing\nat most $\\ell$ nodes? We consider several parameters associated to the input,\nincluding: the bounds $k$ and $\\ell$, the maximum node degree $\\Delta$, the\ntreewidth, and the neighborhood diversity of the network. We first give $W[1]$\nor $W[2]$-hardness results for each of the considered parameters. Then we give\nfixed-parameter algorithms for some parameter combinations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We consider the problem of controlling the spread of harmful items in\nnetworks, such as the contagion proliferation of diseases or the diffusion of\nfake news. We assume the linear threshold model of diffusion where each node\nhas a threshold that measures the node resistance to the contagion. We study\nthe parameterized complexity of the problem: Given a network, a set of\ninitially contaminated nodes, and two integers $k$ and $\\ell$, is it possible\nto limit the diffusion to at most $k$ other nodes of the network by immunizing\nat most $\\ell$ nodes? We consider several parameters associated to the input,\nincluding: the bounds $k$ and $\\ell$, the maximum node degree $\\Delta$, the\ntreewidth, and the neighborhood diversity of the network. We first give $W[1]$\nor $W[2]$-hardness results for each of the considered parameters. Then we give\nfixed-parameter algorithms for some parameter combinations.'}, 'authors': [{'name': 'Gennaro Cordasco'}, {'name': 'Luisa Gargano'}, {'name': 'Adele Anna Rescigno'}], 'author_detail': {'name': 'Adele Anna Rescigno'}, 'author': 'Adele Anna Rescigno', 'links': [{'href': 'http://arxiv.org/abs/2102.03537v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.03537v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
95,http://arxiv.org/abs/2102.04293v1,2021-02-04 22:54:44+00:00,2021-02-04 22:54:44+00:00,High-level Approaches to Detect Malicious Political Activity on Twitter,[arxiv.Result.Author('Miguel Sozinho Ramalho')],"Our work represents another step into the detection and prevention of these
ever-more present political manipulation efforts. We, therefore, start by
focusing on understanding what the state-of-the-art approaches lack -- since
the problem remains, this is a fair assumption. We find concerning issues
within the current literature and follow a diverging path. Notably, by placing
emphasis on using data features that are less susceptible to malicious
manipulation and also on looking for high-level approaches that avoid a
granularity level that is biased towards easy-to-spot and low impact cases.
  We designed and implemented a framework -- Twitter Watch -- that performs
structured Twitter data collection, applying it to the Portuguese
Twittersphere. We investigate a data snapshot taken on May 2020, with around 5
million accounts and over 120 million tweets (this value has since increased to
over 175 million). The analyzed time period stretches from August 2019 to May
2020, with a focus on the Portuguese elections of October 6th, 2019. However,
the Covid-19 pandemic showed itself in our data, and we also delve into how it
affected typical Twitter behavior.
  We performed three main approaches: content-oriented, metadata-oriented, and
network interaction-oriented. We learn that Twitter's suspension patterns are
not adequate to the type of political trolling found in the Portuguese
Twittersphere -- identified by this work and by an independent peer - nor to
fake news posting accounts. We also surmised that the different types of
malicious accounts we independently gathered are very similar both in terms of
content and interaction, through two distinct analysis, and are simultaneously
very distinct from regular accounts.",Master's thesis,,,cs.SI,"['cs.SI', 'cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2102.04293v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.04293v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.04293v1,"{'id': 'http://arxiv.org/abs/2102.04293v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.04293v1', 'updated': '2021-02-04T22:54:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=22, tm_min=54, tm_sec=44, tm_wday=3, tm_yday=35, tm_isdst=0), 'published': '2021-02-04T22:54:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=22, tm_min=54, tm_sec=44, tm_wday=3, tm_yday=35, tm_isdst=0), 'title': 'High-level Approaches to Detect Malicious Political Activity on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'High-level Approaches to Detect Malicious Political Activity on Twitter'}, 'summary': ""Our work represents another step into the detection and prevention of these\never-more present political manipulation efforts. We, therefore, start by\nfocusing on understanding what the state-of-the-art approaches lack -- since\nthe problem remains, this is a fair assumption. We find concerning issues\nwithin the current literature and follow a diverging path. Notably, by placing\nemphasis on using data features that are less susceptible to malicious\nmanipulation and also on looking for high-level approaches that avoid a\ngranularity level that is biased towards easy-to-spot and low impact cases.\n  We designed and implemented a framework -- Twitter Watch -- that performs\nstructured Twitter data collection, applying it to the Portuguese\nTwittersphere. We investigate a data snapshot taken on May 2020, with around 5\nmillion accounts and over 120 million tweets (this value has since increased to\nover 175 million). The analyzed time period stretches from August 2019 to May\n2020, with a focus on the Portuguese elections of October 6th, 2019. However,\nthe Covid-19 pandemic showed itself in our data, and we also delve into how it\naffected typical Twitter behavior.\n  We performed three main approaches: content-oriented, metadata-oriented, and\nnetwork interaction-oriented. We learn that Twitter's suspension patterns are\nnot adequate to the type of political trolling found in the Portuguese\nTwittersphere -- identified by this work and by an independent peer - nor to\nfake news posting accounts. We also surmised that the different types of\nmalicious accounts we independently gathered are very similar both in terms of\ncontent and interaction, through two distinct analysis, and are simultaneously\nvery distinct from regular accounts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Our work represents another step into the detection and prevention of these\never-more present political manipulation efforts. We, therefore, start by\nfocusing on understanding what the state-of-the-art approaches lack -- since\nthe problem remains, this is a fair assumption. We find concerning issues\nwithin the current literature and follow a diverging path. Notably, by placing\nemphasis on using data features that are less susceptible to malicious\nmanipulation and also on looking for high-level approaches that avoid a\ngranularity level that is biased towards easy-to-spot and low impact cases.\n  We designed and implemented a framework -- Twitter Watch -- that performs\nstructured Twitter data collection, applying it to the Portuguese\nTwittersphere. We investigate a data snapshot taken on May 2020, with around 5\nmillion accounts and over 120 million tweets (this value has since increased to\nover 175 million). The analyzed time period stretches from August 2019 to May\n2020, with a focus on the Portuguese elections of October 6th, 2019. However,\nthe Covid-19 pandemic showed itself in our data, and we also delve into how it\naffected typical Twitter behavior.\n  We performed three main approaches: content-oriented, metadata-oriented, and\nnetwork interaction-oriented. We learn that Twitter's suspension patterns are\nnot adequate to the type of political trolling found in the Portuguese\nTwittersphere -- identified by this work and by an independent peer - nor to\nfake news posting accounts. We also surmised that the different types of\nmalicious accounts we independently gathered are very similar both in terms of\ncontent and interaction, through two distinct analysis, and are simultaneously\nvery distinct from regular accounts.""}, 'authors': [{'name': 'Miguel Sozinho Ramalho'}], 'author_detail': {'name': 'Miguel Sozinho Ramalho'}, 'author': 'Miguel Sozinho Ramalho', 'arxiv_comment': ""Master's thesis"", 'links': [{'href': 'http://arxiv.org/abs/2102.04293v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.04293v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
96,http://arxiv.org/abs/2102.02680v1,2021-02-04 15:18:44+00:00,2021-02-04 15:18:44+00:00,Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","The widespread of fake news and misinformation in various domains ranging
from politics, economics to public health has posed an urgent need to
automatically fact-check information. A recent trend in fake news detection is
to utilize evidence from external sources. However, existing evidence-aware
fake news detection methods focused on either only word-level attention or
evidence-level attention, which may result in suboptimal performance. In this
paper, we propose a Hierarchical Multi-head Attentive Network to fact-check
textual claims. Our model jointly combines multi-head word-level attention and
multi-head document-level attention, which aid explanation in both word-level
and evidence-level. Experiments on two real-word datasets show that our model
outperforms seven state-of-the-art baselines. Improvements over baselines are
from 6\% to 18\%. Our source code and datasets are released at
\texttt{\url{https://github.com/nguyenvo09/EACL2021}}.",EACL2021,,,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2102.02680v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.02680v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.02680v1,"{'id': 'http://arxiv.org/abs/2102.02680v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.02680v1', 'updated': '2021-02-04T15:18:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=15, tm_min=18, tm_sec=44, tm_wday=3, tm_yday=35, tm_isdst=0), 'published': '2021-02-04T15:18:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=15, tm_min=18, tm_sec=44, tm_wday=3, tm_yday=35, tm_isdst=0), 'title': 'Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection'}, 'summary': 'The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.'}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'EACL2021', 'links': [{'href': 'http://arxiv.org/abs/2102.02680v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.02680v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
97,http://arxiv.org/abs/2102.02434v1,2021-02-04 06:35:27+00:00,2021-02-04 06:35:27+00:00,Assessing Individual and Community Vulnerability to Fake News in Social Networks,"[arxiv.Result.Author('Bhavtosh Rath'), arxiv.Result.Author('Wei Gao'), arxiv.Result.Author('Jaideep Srivastava')]","The plague of false information, popularly called fake news has affected
lives of news consumers ever since the prevalence of social media. Thus
understanding the spread of false information in social networks has gained a
lot of attention in the literature. While most proposed models do content
analysis of the information, no much work has been done by exploring the
community structures that also play an important role in determining how people
get exposed to it. In this paper we base our idea on Computational Trust in
social networks to propose a novel Community Health Assessment model against
fake news. Based on the concepts of neighbor, boundary and core nodes of a
community, we propose novel evaluation metrics to quantify the vulnerability of
nodes (individual-level) and communities (group-level) to spreading false
information. Our model hypothesizes that if the boundary nodes trust the
neighbor nodes of a community who are spreaders, the densely-connected core
nodes of the community are highly likely to become spreaders. We test our model
with communities generated using three popular community detection algorithms
based on two new datasets of information spreading networks collected from
Twitter. Our experimental results show that the proposed metrics perform
clearly better on the networks spreading false information than on those
spreading true ones, indicating our community health assessment model is
effective.","Extension work on our ASONAM 19 paper (Evaluating vulnerability to
  fake news in social networks: A community health assessment model)",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2102.02434v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.02434v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.02434v1,"{'id': 'http://arxiv.org/abs/2102.02434v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.02434v1', 'updated': '2021-02-04T06:35:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=6, tm_min=35, tm_sec=27, tm_wday=3, tm_yday=35, tm_isdst=0), 'published': '2021-02-04T06:35:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=6, tm_min=35, tm_sec=27, tm_wday=3, tm_yday=35, tm_isdst=0), 'title': 'Assessing Individual and Community Vulnerability to Fake News in Social\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Assessing Individual and Community Vulnerability to Fake News in Social\n  Networks'}, 'summary': 'The plague of false information, popularly called fake news has affected\nlives of news consumers ever since the prevalence of social media. Thus\nunderstanding the spread of false information in social networks has gained a\nlot of attention in the literature. While most proposed models do content\nanalysis of the information, no much work has been done by exploring the\ncommunity structures that also play an important role in determining how people\nget exposed to it. In this paper we base our idea on Computational Trust in\nsocial networks to propose a novel Community Health Assessment model against\nfake news. Based on the concepts of neighbor, boundary and core nodes of a\ncommunity, we propose novel evaluation metrics to quantify the vulnerability of\nnodes (individual-level) and communities (group-level) to spreading false\ninformation. Our model hypothesizes that if the boundary nodes trust the\nneighbor nodes of a community who are spreaders, the densely-connected core\nnodes of the community are highly likely to become spreaders. We test our model\nwith communities generated using three popular community detection algorithms\nbased on two new datasets of information spreading networks collected from\nTwitter. Our experimental results show that the proposed metrics perform\nclearly better on the networks spreading false information than on those\nspreading true ones, indicating our community health assessment model is\neffective.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The plague of false information, popularly called fake news has affected\nlives of news consumers ever since the prevalence of social media. Thus\nunderstanding the spread of false information in social networks has gained a\nlot of attention in the literature. While most proposed models do content\nanalysis of the information, no much work has been done by exploring the\ncommunity structures that also play an important role in determining how people\nget exposed to it. In this paper we base our idea on Computational Trust in\nsocial networks to propose a novel Community Health Assessment model against\nfake news. Based on the concepts of neighbor, boundary and core nodes of a\ncommunity, we propose novel evaluation metrics to quantify the vulnerability of\nnodes (individual-level) and communities (group-level) to spreading false\ninformation. Our model hypothesizes that if the boundary nodes trust the\nneighbor nodes of a community who are spreaders, the densely-connected core\nnodes of the community are highly likely to become spreaders. We test our model\nwith communities generated using three popular community detection algorithms\nbased on two new datasets of information spreading networks collected from\nTwitter. Our experimental results show that the proposed metrics perform\nclearly better on the networks spreading false information than on those\nspreading true ones, indicating our community health assessment model is\neffective.'}, 'authors': [{'name': 'Bhavtosh Rath'}, {'name': 'Wei Gao'}, {'name': 'Jaideep Srivastava'}], 'author_detail': {'name': 'Jaideep Srivastava'}, 'author': 'Jaideep Srivastava', 'arxiv_comment': 'Extension work on our ASONAM 19 paper (Evaluating vulnerability to\n  fake news in social networks: A community health assessment model)', 'links': [{'href': 'http://arxiv.org/abs/2102.02434v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.02434v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
98,http://arxiv.org/abs/2102.02335v1,2021-02-03 23:37:09+00:00,2021-02-03 23:37:09+00:00,Self-Supervised Claim Identification for Automated Fact Checking,"[arxiv.Result.Author('Archita Pathak'), arxiv.Result.Author('Mohammad Abuzar Shaikh'), arxiv.Result.Author('Rohini Srihari')]","We propose a novel, attention-based self-supervised approach to identify
""claim-worthy"" sentences in a fake news article, an important first step in
automated fact-checking. We leverage ""aboutness"" of headline and content using
attention mechanism for this task. The identified claims can be used for
downstream task of claim verification for which we are releasing a benchmark
dataset of manually selected compelling articles with veracity labels and
associated evidence. This work goes beyond stylistic analysis to identifying
content that influences reader belief. Experiments with three datasets show the
strength of our model. Data and code available at
https://github.com/architapathak/Self-Supervised-ClaimIdentification","15 pages, 4 figures, Accepted at ICON 2020",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2102.02335v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.02335v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.02335v1,"{'id': 'http://arxiv.org/abs/2102.02335v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.02335v1', 'updated': '2021-02-03T23:37:09Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=3, tm_hour=23, tm_min=37, tm_sec=9, tm_wday=2, tm_yday=34, tm_isdst=0), 'published': '2021-02-03T23:37:09Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=3, tm_hour=23, tm_min=37, tm_sec=9, tm_wday=2, tm_yday=34, tm_isdst=0), 'title': 'Self-Supervised Claim Identification for Automated Fact Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Self-Supervised Claim Identification for Automated Fact Checking'}, 'summary': 'We propose a novel, attention-based self-supervised approach to identify\n""claim-worthy"" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage ""aboutness"" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We propose a novel, attention-based self-supervised approach to identify\n""claim-worthy"" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage ""aboutness"" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification'}, 'authors': [{'name': 'Archita Pathak'}, {'name': 'Mohammad Abuzar Shaikh'}, {'name': 'Rohini Srihari'}], 'author_detail': {'name': 'Rohini Srihari'}, 'author': 'Rohini Srihari', 'arxiv_comment': '15 pages, 4 figures, Accepted at ICON 2020', 'links': [{'href': 'http://arxiv.org/abs/2102.02335v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.02335v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
99,http://arxiv.org/abs/2102.00214v1,2021-01-30 11:53:56+00:00,2021-01-30 11:53:56+00:00,Taxonomic survey of Hindi Language NLP systems,"[arxiv.Result.Author('Nikita P. Desai'), arxiv.Result.Author('Prof.'), arxiv.Result.Author('Vipul K. Dabhi')]","Natural Language processing (NLP) represents the task of automatic handling
of natural human language by machines.There is large spectrum of possible
applications of NLP which help in automating tasks like translating text from
one language to other, retrieving and summarizing data from very huge
repositories, spam email filtering, identifying fake news in digital media,
find sentiment and feedback of people, find political opinions and views of
people on various government policies, provide effective medical assistance
based on past history records of patient etc. Hindi is the official language of
India with nearly 691 million users in India and 366 million in rest of world.
At present, a number of government and private sector projects and researchers
in India and abroad, are working towards developing NLP applications and
resources for Indian languages. This survey gives a report of the resources and
applications available for Hindi language NLP.",,,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2102.00214v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.00214v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.00214v1,"{'id': 'http://arxiv.org/abs/2102.00214v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.00214v1', 'updated': '2021-01-30T11:53:56Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=30, tm_hour=11, tm_min=53, tm_sec=56, tm_wday=5, tm_yday=30, tm_isdst=0), 'published': '2021-01-30T11:53:56Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=30, tm_hour=11, tm_min=53, tm_sec=56, tm_wday=5, tm_yday=30, tm_isdst=0), 'title': 'Taxonomic survey of Hindi Language NLP systems', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Taxonomic survey of Hindi Language NLP systems'}, 'summary': 'Natural Language processing (NLP) represents the task of automatic handling\nof natural human language by machines.There is large spectrum of possible\napplications of NLP which help in automating tasks like translating text from\none language to other, retrieving and summarizing data from very huge\nrepositories, spam email filtering, identifying fake news in digital media,\nfind sentiment and feedback of people, find political opinions and views of\npeople on various government policies, provide effective medical assistance\nbased on past history records of patient etc. Hindi is the official language of\nIndia with nearly 691 million users in India and 366 million in rest of world.\nAt present, a number of government and private sector projects and researchers\nin India and abroad, are working towards developing NLP applications and\nresources for Indian languages. This survey gives a report of the resources and\napplications available for Hindi language NLP.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Natural Language processing (NLP) represents the task of automatic handling\nof natural human language by machines.There is large spectrum of possible\napplications of NLP which help in automating tasks like translating text from\none language to other, retrieving and summarizing data from very huge\nrepositories, spam email filtering, identifying fake news in digital media,\nfind sentiment and feedback of people, find political opinions and views of\npeople on various government policies, provide effective medical assistance\nbased on past history records of patient etc. Hindi is the official language of\nIndia with nearly 691 million users in India and 366 million in rest of world.\nAt present, a number of government and private sector projects and researchers\nin India and abroad, are working towards developing NLP applications and\nresources for Indian languages. This survey gives a report of the resources and\napplications available for Hindi language NLP.'}, 'authors': [{'name': 'Nikita P. Desai'}, {'name': 'Prof.'}, {'name': 'Vipul K. Dabhi'}], 'author_detail': {'name': 'Vipul K. Dabhi'}, 'arxiv_affiliation': 'Dr.', 'author': 'Vipul K. Dabhi', 'links': [{'href': 'http://arxiv.org/abs/2102.00214v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.00214v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
100,http://arxiv.org/abs/2101.12027v1,2021-01-28 14:43:42+00:00,2021-01-28 14:43:42+00:00,A transformer based approach for fighting COVID-19 fake news,"[arxiv.Result.Author('S. M. Sadiq-Ur-Rahman Shifath'), arxiv.Result.Author('Mohammad Faiyaz Khan'), arxiv.Result.Author('Md. Saiful Islam')]","The rapid outbreak of COVID-19 has caused humanity to come to a stand-still
and brought with it a plethora of other problems. COVID-19 is the first
pandemic in history when humanity is the most technologically advanced and
relies heavily on social media platforms for connectivity and other benefits.
Unfortunately, fake news and misinformation regarding this virus is also
available to people and causing some massive problems. So, fighting this
infodemic has become a significant challenge. We present our solution for the
""Constraint@AAAI2021 - COVID19 Fake News Detection in English"" challenge in
this work. After extensive experimentation with numerous architectures and
techniques, we use eight different transformer-based pre-trained models with
additional layers to construct a stacking ensemble classifier and fine-tuned
them for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,
0.979906542 recall, and 0.979907901 f1-score on the test dataset of the
competition.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.12027v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.12027v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.12027v1,"{'id': 'http://arxiv.org/abs/2101.12027v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.12027v1', 'updated': '2021-01-28T14:43:42Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=28, tm_hour=14, tm_min=43, tm_sec=42, tm_wday=3, tm_yday=28, tm_isdst=0), 'published': '2021-01-28T14:43:42Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=28, tm_hour=14, tm_min=43, tm_sec=42, tm_wday=3, tm_yday=28, tm_isdst=0), 'title': 'A transformer based approach for fighting COVID-19 fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A transformer based approach for fighting COVID-19 fake news'}, 'summary': 'The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n""Constraint@AAAI2021 - COVID19 Fake News Detection in English"" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n""Constraint@AAAI2021 - COVID19 Fake News Detection in English"" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.'}, 'authors': [{'name': 'S. M. Sadiq-Ur-Rahman Shifath'}, {'name': 'Mohammad Faiyaz Khan'}, {'name': 'Md. Saiful Islam'}], 'author_detail': {'name': 'Md. Saiful Islam'}, 'author': 'Md. Saiful Islam', 'links': [{'href': 'http://arxiv.org/abs/2101.12027v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.12027v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
101,http://arxiv.org/abs/2101.11954v2,2021-02-01 22:27:07+00:00,2021-01-28 12:12:50+00:00,Identifying COVID-19 Fake News in Social Media,"[arxiv.Result.Author('Tathagata Raha'), arxiv.Result.Author('Vijayasaradhi Indurthi'), arxiv.Result.Author('Aayush Upadhyaya'), arxiv.Result.Author('Jeevesh Kataria'), arxiv.Result.Author('Pramud Bommakanti'), arxiv.Result.Author('Vikram Keswani'), arxiv.Result.Author('Vasudeva Varma')]","The evolution of social media platforms have empowered everyone to access
information easily. Social media users can easily share information with the
rest of the world. This may sometimes encourage spread of fake news, which can
result in undesirable consequences. In this work, we train models which can
identify health news related to COVID-19 pandemic as real or fake. Our models
achieve a high F1-score of 98.64%. Our models achieve second place on the
leaderboard, tailing the first position with a very narrow margin 0.05% points.",CONSTRAINT@AAAI,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2101.11954v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.11954v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.11954v2,"{'id': 'http://arxiv.org/abs/2101.11954v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.11954v2', 'updated': '2021-02-01T22:27:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=22, tm_min=27, tm_sec=7, tm_wday=0, tm_yday=32, tm_isdst=0), 'published': '2021-01-28T12:12:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=28, tm_hour=12, tm_min=12, tm_sec=50, tm_wday=3, tm_yday=28, tm_isdst=0), 'title': 'Identifying COVID-19 Fake News in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying COVID-19 Fake News in Social Media'}, 'summary': 'The evolution of social media platforms have empowered everyone to access\ninformation easily. Social media users can easily share information with the\nrest of the world. This may sometimes encourage spread of fake news, which can\nresult in undesirable consequences. In this work, we train models which can\nidentify health news related to COVID-19 pandemic as real or fake. Our models\nachieve a high F1-score of 98.64%. Our models achieve second place on the\nleaderboard, tailing the first position with a very narrow margin 0.05% points.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The evolution of social media platforms have empowered everyone to access\ninformation easily. Social media users can easily share information with the\nrest of the world. This may sometimes encourage spread of fake news, which can\nresult in undesirable consequences. In this work, we train models which can\nidentify health news related to COVID-19 pandemic as real or fake. Our models\nachieve a high F1-score of 98.64%. Our models achieve second place on the\nleaderboard, tailing the first position with a very narrow margin 0.05% points.'}, 'authors': [{'name': 'Tathagata Raha'}, {'name': 'Vijayasaradhi Indurthi'}, {'name': 'Aayush Upadhyaya'}, {'name': 'Jeevesh Kataria'}, {'name': 'Pramud Bommakanti'}, {'name': 'Vikram Keswani'}, {'name': 'Vasudeva Varma'}], 'author_detail': {'name': 'Vasudeva Varma'}, 'author': 'Vasudeva Varma', 'arxiv_comment': 'CONSTRAINT@AAAI', 'links': [{'href': 'http://arxiv.org/abs/2101.11954v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.11954v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
102,http://arxiv.org/abs/2101.11563v1,2021-01-27 17:37:23+00:00,2021-01-27 17:37:23+00:00,Detecting Deepfake Videos Using Euler Video Magnification,"[arxiv.Result.Author('Rashmiranjan Das'), arxiv.Result.Author('Gaurav Negi'), arxiv.Result.Author('Alan F. Smeaton')]","Recent advances in artificial intelligence make it progressively hard to
distinguish between genuine and counterfeit media, especially images and
videos. One recent development is the rise of deepfake videos, based on
manipulating videos using advanced machine learning techniques. This involves
replacing the face of an individual from a source video with the face of a
second person, in the destination video. This idea is becoming progressively
refined as deepfakes are getting progressively seamless and simpler to compute.
Combined with the outreach and speed of social media, deepfakes could easily
fool individuals when depicting someone saying things that never happened and
thus could persuade people in believing fictional scenarios, creating distress,
and spreading fake news. In this paper, we examine a technique for possible
identification of deepfake videos. We use Euler video magnification which
applies spatial decomposition and temporal filtering on video data to highlight
and magnify hidden features like skin pulsation and subtle motions. Our
approach uses features extracted from the Euler technique to train three models
to classify counterfeit and unaltered videos and compare the results with
existing techniques.","Presented at Electronic Imaging: Media Watermarking, Security, and
  Forensics, 27 January 2021, 6 pages, 6 figures",,10.2352/ISSN.2470-1173.2021.4.MWSF-272,cs.CV,"['cs.CV', 'cs.AI', 'cs.MM']","[arxiv.Result.Link('http://dx.doi.org/10.2352/ISSN.2470-1173.2021.4.MWSF-272', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.11563v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.11563v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.11563v1,"{'id': 'http://arxiv.org/abs/2101.11563v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.11563v1', 'updated': '2021-01-27T17:37:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=27, tm_hour=17, tm_min=37, tm_sec=23, tm_wday=2, tm_yday=27, tm_isdst=0), 'published': '2021-01-27T17:37:23Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=27, tm_hour=17, tm_min=37, tm_sec=23, tm_wday=2, tm_yday=27, tm_isdst=0), 'title': 'Detecting Deepfake Videos Using Euler Video Magnification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Deepfake Videos Using Euler Video Magnification'}, 'summary': 'Recent advances in artificial intelligence make it progressively hard to\ndistinguish between genuine and counterfeit media, especially images and\nvideos. One recent development is the rise of deepfake videos, based on\nmanipulating videos using advanced machine learning techniques. This involves\nreplacing the face of an individual from a source video with the face of a\nsecond person, in the destination video. This idea is becoming progressively\nrefined as deepfakes are getting progressively seamless and simpler to compute.\nCombined with the outreach and speed of social media, deepfakes could easily\nfool individuals when depicting someone saying things that never happened and\nthus could persuade people in believing fictional scenarios, creating distress,\nand spreading fake news. In this paper, we examine a technique for possible\nidentification of deepfake videos. We use Euler video magnification which\napplies spatial decomposition and temporal filtering on video data to highlight\nand magnify hidden features like skin pulsation and subtle motions. Our\napproach uses features extracted from the Euler technique to train three models\nto classify counterfeit and unaltered videos and compare the results with\nexisting techniques.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent advances in artificial intelligence make it progressively hard to\ndistinguish between genuine and counterfeit media, especially images and\nvideos. One recent development is the rise of deepfake videos, based on\nmanipulating videos using advanced machine learning techniques. This involves\nreplacing the face of an individual from a source video with the face of a\nsecond person, in the destination video. This idea is becoming progressively\nrefined as deepfakes are getting progressively seamless and simpler to compute.\nCombined with the outreach and speed of social media, deepfakes could easily\nfool individuals when depicting someone saying things that never happened and\nthus could persuade people in believing fictional scenarios, creating distress,\nand spreading fake news. In this paper, we examine a technique for possible\nidentification of deepfake videos. We use Euler video magnification which\napplies spatial decomposition and temporal filtering on video data to highlight\nand magnify hidden features like skin pulsation and subtle motions. Our\napproach uses features extracted from the Euler technique to train three models\nto classify counterfeit and unaltered videos and compare the results with\nexisting techniques.'}, 'authors': [{'name': 'Rashmiranjan Das'}, {'name': 'Gaurav Negi'}, {'name': 'Alan F. Smeaton'}], 'author_detail': {'name': 'Alan F. Smeaton'}, 'author': 'Alan F. Smeaton', 'arxiv_doi': '10.2352/ISSN.2470-1173.2021.4.MWSF-272', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.2352/ISSN.2470-1173.2021.4.MWSF-272', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.11563v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.11563v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Presented at Electronic Imaging: Media Watermarking, Security, and\n  Forensics, 27 January 2021, 6 pages, 6 figures', 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
103,http://arxiv.org/abs/2101.11337v2,2021-02-04 11:53:20+00:00,2021-01-27 11:58:04+00:00,Launchers and Targets in Social Networks,"[arxiv.Result.Author('Pedro Martins'), arxiv.Result.Author('Filipa Alarcão Martins')]","Influence propagation in social networks is a subject of growing interest. A
relevant issue in those networks involves the identification of key
influencers. These players have an important role on viral marketing strategies
and message propagation, including political propaganda and fake news. In
effect, an important way to fight malicious usage on social networks is to
understand their properties, their structure and the way messages propagate.
  This paper proposes two new indices for analysing message propagation in
social networks, based on the network topological nature and the power of the
message. The first index involves the strength of each node as a launcher of
the message, dividing the nodes into launchers and non-launchers. The second
index addresses the potential of each member as a receiver (target) of the
message, dividing the nodes into targets and non-targets. Launcher individuals
should indicate strong influencers and target individuals should identify the
best target consumers. These indices can assist other known metrics when used
to select efficient influencers in a social network. For instance, instead of
choosing a strong and probably expensive member according to its degree in the
network (number of followers), we may previously select those belonging to the
launchers group and look for the lowest degree members, which are probably
cheaper but still guarantying almost the same influence effectiveness as the
largest degree members.
  On a different direction, using the second index, the strong target members
should characterize relevant consumers of information in the network, which may
include fake news' regular collectors.
  We discuss these indices using small-world randomly generated graphs and a
number of real-world social networks available in known datasets repositories.","30 pages, 6 figures",,,cs.SI,"['cs.SI', '68R10, 90B18']","[arxiv.Result.Link('http://arxiv.org/abs/2101.11337v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.11337v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.11337v2,"{'id': 'http://arxiv.org/abs/2101.11337v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.11337v2', 'updated': '2021-02-04T11:53:20Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=11, tm_min=53, tm_sec=20, tm_wday=3, tm_yday=35, tm_isdst=0), 'published': '2021-01-27T11:58:04Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=27, tm_hour=11, tm_min=58, tm_sec=4, tm_wday=2, tm_yday=27, tm_isdst=0), 'title': 'Launchers and Targets in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Launchers and Targets in Social Networks'}, 'summary': ""Influence propagation in social networks is a subject of growing interest. A\nrelevant issue in those networks involves the identification of key\ninfluencers. These players have an important role on viral marketing strategies\nand message propagation, including political propaganda and fake news. In\neffect, an important way to fight malicious usage on social networks is to\nunderstand their properties, their structure and the way messages propagate.\n  This paper proposes two new indices for analysing message propagation in\nsocial networks, based on the network topological nature and the power of the\nmessage. The first index involves the strength of each node as a launcher of\nthe message, dividing the nodes into launchers and non-launchers. The second\nindex addresses the potential of each member as a receiver (target) of the\nmessage, dividing the nodes into targets and non-targets. Launcher individuals\nshould indicate strong influencers and target individuals should identify the\nbest target consumers. These indices can assist other known metrics when used\nto select efficient influencers in a social network. For instance, instead of\nchoosing a strong and probably expensive member according to its degree in the\nnetwork (number of followers), we may previously select those belonging to the\nlaunchers group and look for the lowest degree members, which are probably\ncheaper but still guarantying almost the same influence effectiveness as the\nlargest degree members.\n  On a different direction, using the second index, the strong target members\nshould characterize relevant consumers of information in the network, which may\ninclude fake news' regular collectors.\n  We discuss these indices using small-world randomly generated graphs and a\nnumber of real-world social networks available in known datasets repositories."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Influence propagation in social networks is a subject of growing interest. A\nrelevant issue in those networks involves the identification of key\ninfluencers. These players have an important role on viral marketing strategies\nand message propagation, including political propaganda and fake news. In\neffect, an important way to fight malicious usage on social networks is to\nunderstand their properties, their structure and the way messages propagate.\n  This paper proposes two new indices for analysing message propagation in\nsocial networks, based on the network topological nature and the power of the\nmessage. The first index involves the strength of each node as a launcher of\nthe message, dividing the nodes into launchers and non-launchers. The second\nindex addresses the potential of each member as a receiver (target) of the\nmessage, dividing the nodes into targets and non-targets. Launcher individuals\nshould indicate strong influencers and target individuals should identify the\nbest target consumers. These indices can assist other known metrics when used\nto select efficient influencers in a social network. For instance, instead of\nchoosing a strong and probably expensive member according to its degree in the\nnetwork (number of followers), we may previously select those belonging to the\nlaunchers group and look for the lowest degree members, which are probably\ncheaper but still guarantying almost the same influence effectiveness as the\nlargest degree members.\n  On a different direction, using the second index, the strong target members\nshould characterize relevant consumers of information in the network, which may\ninclude fake news' regular collectors.\n  We discuss these indices using small-world randomly generated graphs and a\nnumber of real-world social networks available in known datasets repositories.""}, 'authors': [{'name': 'Pedro Martins'}, {'name': 'Filipa Alarcão Martins'}], 'author_detail': {'name': 'Filipa Alarcão Martins'}, 'author': 'Filipa Alarcão Martins', 'arxiv_comment': '30 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2101.11337v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.11337v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68R10, 90B18', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
104,http://arxiv.org/abs/2101.11206v1,2021-01-27 05:05:25+00:00,2021-01-27 05:05:25+00:00,Adversarial Active Learning based Heterogeneous Graph Neural Network for Fake News Detection,"[arxiv.Result.Author('Yuxiang Ren'), arxiv.Result.Author('Bo Wang'), arxiv.Result.Author('Jiawei Zhang'), arxiv.Result.Author('Yi Chang')]","The explosive growth of fake news along with destructive effects on politics,
economy, and public safety has increased the demand for fake news detection.
Fake news on social media does not exist independently in the form of an
article. Many other entities, such as news creators, news subjects, and so on,
exist on social media and have relationships with news articles. Different
entities and relationships can be modeled as a heterogeneous information
network (HIN). In this paper, we attempt to solve the fake news detection
problem with the support of a news-oriented HIN. We propose a novel fake news
detection framework, namely Adversarial Active Learning-based Heterogeneous
Graph Neural Network (AA-HGNN) which employs a novel hierarchical attention
mechanism to perform node representation learning in the HIN. AA-HGNN utilizes
an active learning framework to enhance learning performance, especially when
facing the paucity of labeled data. An adversarial selector will be trained to
query high-value candidates for the active learning framework. When the
adversarial active learning is completed, AA-HGNN detects fake news by
classifying news article nodes. Experiments with two real-world fake news
datasets show that our model can outperform text-based models and other
graph-based models when using less labeled data benefiting from the adversarial
active learning. As a model with generalizability, AA-HGNN also has the ability
to be widely used in other node classification-related applications on
heterogeneous graphs.","Accepted by ICDM 2020. arXiv admin note: text overlap with
  arXiv:2002.04397",,,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2101.11206v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.11206v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.11206v1,"{'id': 'http://arxiv.org/abs/2101.11206v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.11206v1', 'updated': '2021-01-27T05:05:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=27, tm_hour=5, tm_min=5, tm_sec=25, tm_wday=2, tm_yday=27, tm_isdst=0), 'published': '2021-01-27T05:05:25Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=27, tm_hour=5, tm_min=5, tm_sec=25, tm_wday=2, tm_yday=27, tm_isdst=0), 'title': 'Adversarial Active Learning based Heterogeneous Graph Neural Network for\n  Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversarial Active Learning based Heterogeneous Graph Neural Network for\n  Fake News Detection'}, 'summary': 'The explosive growth of fake news along with destructive effects on politics,\neconomy, and public safety has increased the demand for fake news detection.\nFake news on social media does not exist independently in the form of an\narticle. Many other entities, such as news creators, news subjects, and so on,\nexist on social media and have relationships with news articles. Different\nentities and relationships can be modeled as a heterogeneous information\nnetwork (HIN). In this paper, we attempt to solve the fake news detection\nproblem with the support of a news-oriented HIN. We propose a novel fake news\ndetection framework, namely Adversarial Active Learning-based Heterogeneous\nGraph Neural Network (AA-HGNN) which employs a novel hierarchical attention\nmechanism to perform node representation learning in the HIN. AA-HGNN utilizes\nan active learning framework to enhance learning performance, especially when\nfacing the paucity of labeled data. An adversarial selector will be trained to\nquery high-value candidates for the active learning framework. When the\nadversarial active learning is completed, AA-HGNN detects fake news by\nclassifying news article nodes. Experiments with two real-world fake news\ndatasets show that our model can outperform text-based models and other\ngraph-based models when using less labeled data benefiting from the adversarial\nactive learning. As a model with generalizability, AA-HGNN also has the ability\nto be widely used in other node classification-related applications on\nheterogeneous graphs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The explosive growth of fake news along with destructive effects on politics,\neconomy, and public safety has increased the demand for fake news detection.\nFake news on social media does not exist independently in the form of an\narticle. Many other entities, such as news creators, news subjects, and so on,\nexist on social media and have relationships with news articles. Different\nentities and relationships can be modeled as a heterogeneous information\nnetwork (HIN). In this paper, we attempt to solve the fake news detection\nproblem with the support of a news-oriented HIN. We propose a novel fake news\ndetection framework, namely Adversarial Active Learning-based Heterogeneous\nGraph Neural Network (AA-HGNN) which employs a novel hierarchical attention\nmechanism to perform node representation learning in the HIN. AA-HGNN utilizes\nan active learning framework to enhance learning performance, especially when\nfacing the paucity of labeled data. An adversarial selector will be trained to\nquery high-value candidates for the active learning framework. When the\nadversarial active learning is completed, AA-HGNN detects fake news by\nclassifying news article nodes. Experiments with two real-world fake news\ndatasets show that our model can outperform text-based models and other\ngraph-based models when using less labeled data benefiting from the adversarial\nactive learning. As a model with generalizability, AA-HGNN also has the ability\nto be widely used in other node classification-related applications on\nheterogeneous graphs.'}, 'authors': [{'name': 'Yuxiang Ren'}, {'name': 'Bo Wang'}, {'name': 'Jiawei Zhang'}, {'name': 'Yi Chang'}], 'author_detail': {'name': 'Yi Chang'}, 'author': 'Yi Chang', 'arxiv_comment': 'Accepted by ICDM 2020. arXiv admin note: text overlap with\n  arXiv:2002.04397', 'links': [{'href': 'http://arxiv.org/abs/2101.11206v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.11206v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
105,http://arxiv.org/abs/2101.09810v1,2021-01-24 21:55:28+00:00,2021-01-24 21:55:28+00:00,FakeFlow: Fake News Detection by Modeling the Flow of Affective Information,"[arxiv.Result.Author('Bilal Ghanem'), arxiv.Result.Author('Simone Paolo Ponzetto'), arxiv.Result.Author('Paolo Rosso'), arxiv.Result.Author('Francisco Rangel')]","Fake news articles often stir the readers' attention by means of emotional
appeals that arouse their feelings. Unlike in short news texts, authors of
longer articles can exploit such affective factors to manipulate readers by
adding exaggerations or fabricating events, in order to affect the readers'
emotions. To capture this, we propose in this paper to model the flow of
affective information in fake news articles using a neural architecture. The
proposed model, FakeFlow, learns this flow by combining topic and affective
information extracted from text. We evaluate the model's performance with
several experiments on four real-world datasets. The results show that FakeFlow
achieves superior results when compared against state-of-the-art methods, thus
confirming the importance of capturing the flow of the affective information in
news articles.","9 pages, 6 figures, EACL-2021",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.09810v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.09810v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.09810v1,"{'id': 'http://arxiv.org/abs/2101.09810v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.09810v1', 'updated': '2021-01-24T21:55:28Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=24, tm_hour=21, tm_min=55, tm_sec=28, tm_wday=6, tm_yday=24, tm_isdst=0), 'published': '2021-01-24T21:55:28Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=24, tm_hour=21, tm_min=55, tm_sec=28, tm_wday=6, tm_yday=24, tm_isdst=0), 'title': 'FakeFlow: Fake News Detection by Modeling the Flow of Affective\n  Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeFlow: Fake News Detection by Modeling the Flow of Affective\n  Information'}, 'summary': ""Fake news articles often stir the readers' attention by means of emotional\nappeals that arouse their feelings. Unlike in short news texts, authors of\nlonger articles can exploit such affective factors to manipulate readers by\nadding exaggerations or fabricating events, in order to affect the readers'\nemotions. To capture this, we propose in this paper to model the flow of\naffective information in fake news articles using a neural architecture. The\nproposed model, FakeFlow, learns this flow by combining topic and affective\ninformation extracted from text. We evaluate the model's performance with\nseveral experiments on four real-world datasets. The results show that FakeFlow\nachieves superior results when compared against state-of-the-art methods, thus\nconfirming the importance of capturing the flow of the affective information in\nnews articles."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news articles often stir the readers' attention by means of emotional\nappeals that arouse their feelings. Unlike in short news texts, authors of\nlonger articles can exploit such affective factors to manipulate readers by\nadding exaggerations or fabricating events, in order to affect the readers'\nemotions. To capture this, we propose in this paper to model the flow of\naffective information in fake news articles using a neural architecture. The\nproposed model, FakeFlow, learns this flow by combining topic and affective\ninformation extracted from text. We evaluate the model's performance with\nseveral experiments on four real-world datasets. The results show that FakeFlow\nachieves superior results when compared against state-of-the-art methods, thus\nconfirming the importance of capturing the flow of the affective information in\nnews articles.""}, 'authors': [{'name': 'Bilal Ghanem'}, {'name': 'Simone Paolo Ponzetto'}, {'name': 'Paolo Rosso'}, {'name': 'Francisco Rangel'}], 'author_detail': {'name': 'Francisco Rangel'}, 'author': 'Francisco Rangel', 'arxiv_comment': '9 pages, 6 figures, EACL-2021', 'links': [{'href': 'http://arxiv.org/abs/2101.09810v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.09810v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
106,http://arxiv.org/abs/2101.09251v1,2021-01-22 18:03:57+00:00,2021-01-22 18:03:57+00:00,How to Deal with Fake News: Visualizing Disinformation,"[arxiv.Result.Author('F. Espinoza'), arxiv.Result.Author('Department of Physics'), arxiv.Result.Author('Astronomy'), arxiv.Result.Author('Hofstra University'), arxiv.Result.Author('Hempstead'), arxiv.Result.Author('NY. USA.'), arxiv.Result.Author('Department of Chemistry'), arxiv.Result.Author('Physics-Adolescence Education'), arxiv.Result.Author('SUNY Old Westbury'), arxiv.Result.Author('Old Westbury'), arxiv.Result.Author('NY. USA')]","The current public sense of anxiety in dealing with disinformation as
manifested by so-called fake news is acutely displayed by the reaction to
recent events prompted by a belief in conspiracies among certain groups. A
model to deal with disinformation is proposed; it is based on a demonstration
of the analogous behavior of disinformation to that of wave phenomena. Two
criteria form the basis to combat the deleterious effects of disinformation:
the use of a refractive medium based on skepticism as the default mode, and
polarization as a filter mechanism to analyze its merits based on evidence.
Critical thinking is enhanced since the first one tackles the pernicious effect
of the confirmation bias, and the second the tendency towards attribution, both
of which undermine our efforts to think and act rationally. The benefits of
such a strategy include an epistemic reformulation of disinformation as an
independently existing phenomenon, that removes its negative connotations when
perceived as being possessed by groups or individuals.","Four figures explaining the proposed mechanism that describe wave
  properties and behavior. The quantitative details are kept to a minimum so as
  to highlight the relevance of the treatment of disinformation as a wave, to
  the larger public sphere",,,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.09251v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.09251v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.09251v1,"{'id': 'http://arxiv.org/abs/2101.09251v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.09251v1', 'updated': '2021-01-22T18:03:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=18, tm_min=3, tm_sec=57, tm_wday=4, tm_yday=22, tm_isdst=0), 'published': '2021-01-22T18:03:57Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=18, tm_min=3, tm_sec=57, tm_wday=4, tm_yday=22, tm_isdst=0), 'title': 'How to Deal with Fake News: Visualizing Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How to Deal with Fake News: Visualizing Disinformation'}, 'summary': 'The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.'}, 'authors': [{'name': 'F. Espinoza'}, {'name': 'Department of Physics'}, {'name': 'Astronomy'}, {'name': 'Hofstra University'}, {'name': 'Hempstead'}, {'name': 'NY. USA.'}, {'name': 'Department of Chemistry'}, {'name': 'Physics-Adolescence Education'}, {'name': 'SUNY Old Westbury'}, {'name': 'Old Westbury'}, {'name': 'NY. USA'}], 'author_detail': {'name': 'NY. USA'}, 'author': 'NY. USA', 'arxiv_comment': 'Four figures explaining the proposed mechanism that describe wave\n  properties and behavior. The quantitative details are kept to a minimum so as\n  to highlight the relevance of the treatment of disinformation as a wave, to\n  the larger public sphere', 'links': [{'href': 'http://arxiv.org/abs/2101.09251v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.09251v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
107,http://arxiv.org/abs/2101.10112v1,2021-01-22 03:42:36+00:00,2021-01-22 03:42:36+00:00,Fringe News Networks: Dynamics of US News Viewership following the 2020 Presidential Election,"[arxiv.Result.Author('Ashiqur R. KhudaBukhsh'), arxiv.Result.Author('Rupak Sarkar'), arxiv.Result.Author('Mark S. Kamlet'), arxiv.Result.Author('Tom M. Mitchell')]","The growing political polarization of the American electorate over the last
several decades has been widely studied and documented. During the
administration of President Donald Trump, charges of ""fake news"" made social
and news media not only the means but, to an unprecedented extent, the topic of
political communication. Using data from before the November 3rd, 2020 US
Presidential election, recent work has demonstrated the viability of using
YouTube's social media ecosystem to obtain insights into the extent of US
political polarization as well as the relationship between this polarization
and the nature of the content and commentary provided by different US news
networks. With that work as background, this paper looks at the sharp
transformation of the relationship between news consumers and here-to-fore
""fringe"" news media channels in the 64 days between the US presidential
election and the violence that took place at US Capitol on January 6th. This
paper makes two distinct types of contributions. The first is to introduce a
novel methodology to analyze large social media data to study the dynamics of
social political news networks and their viewers. The second is to provide
insights into what actually happened regarding US political social media
channels and their viewerships during this volatile 64 day period.",,,,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2101.10112v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.10112v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.10112v1,"{'id': 'http://arxiv.org/abs/2101.10112v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.10112v1', 'updated': '2021-01-22T03:42:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=3, tm_min=42, tm_sec=36, tm_wday=4, tm_yday=22, tm_isdst=0), 'published': '2021-01-22T03:42:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=22, tm_hour=3, tm_min=42, tm_sec=36, tm_wday=4, tm_yday=22, tm_isdst=0), 'title': 'Fringe News Networks: Dynamics of US News Viewership following the 2020\n  Presidential Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fringe News Networks: Dynamics of US News Viewership following the 2020\n  Presidential Election'}, 'summary': 'The growing political polarization of the American electorate over the last\nseveral decades has been widely studied and documented. During the\nadministration of President Donald Trump, charges of ""fake news"" made social\nand news media not only the means but, to an unprecedented extent, the topic of\npolitical communication. Using data from before the November 3rd, 2020 US\nPresidential election, recent work has demonstrated the viability of using\nYouTube\'s social media ecosystem to obtain insights into the extent of US\npolitical polarization as well as the relationship between this polarization\nand the nature of the content and commentary provided by different US news\nnetworks. With that work as background, this paper looks at the sharp\ntransformation of the relationship between news consumers and here-to-fore\n""fringe"" news media channels in the 64 days between the US presidential\nelection and the violence that took place at US Capitol on January 6th. This\npaper makes two distinct types of contributions. The first is to introduce a\nnovel methodology to analyze large social media data to study the dynamics of\nsocial political news networks and their viewers. The second is to provide\ninsights into what actually happened regarding US political social media\nchannels and their viewerships during this volatile 64 day period.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The growing political polarization of the American electorate over the last\nseveral decades has been widely studied and documented. During the\nadministration of President Donald Trump, charges of ""fake news"" made social\nand news media not only the means but, to an unprecedented extent, the topic of\npolitical communication. Using data from before the November 3rd, 2020 US\nPresidential election, recent work has demonstrated the viability of using\nYouTube\'s social media ecosystem to obtain insights into the extent of US\npolitical polarization as well as the relationship between this polarization\nand the nature of the content and commentary provided by different US news\nnetworks. With that work as background, this paper looks at the sharp\ntransformation of the relationship between news consumers and here-to-fore\n""fringe"" news media channels in the 64 days between the US presidential\nelection and the violence that took place at US Capitol on January 6th. This\npaper makes two distinct types of contributions. The first is to introduce a\nnovel methodology to analyze large social media data to study the dynamics of\nsocial political news networks and their viewers. The second is to provide\ninsights into what actually happened regarding US political social media\nchannels and their viewerships during this volatile 64 day period.'}, 'authors': [{'name': 'Ashiqur R. KhudaBukhsh'}, {'name': 'Rupak Sarkar'}, {'name': 'Mark S. Kamlet'}, {'name': 'Tom M. Mitchell'}], 'author_detail': {'name': 'Tom M. Mitchell'}, 'author': 'Tom M. Mitchell', 'links': [{'href': 'http://arxiv.org/abs/2101.10112v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.10112v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
108,http://arxiv.org/abs/2101.07419v2,2021-01-29 05:44:31+00:00,2021-01-19 02:29:40+00:00,GIID-Net: Generalizable Image Inpainting Detection via Neural Architecture Search and Attention,"[arxiv.Result.Author('Haiwei Wu'), arxiv.Result.Author('Jiantao Zhou')]","Deep learning (DL) has demonstrated its powerful capabilities in the field of
image inpainting, which could produce visually plausible results. Meanwhile,
the malicious use of advanced image inpainting tools (e.g. removing key objects
to report fake news) has led to increasing threats to the reliability of image
data. To fight against the inpainting forgeries, in this work, we propose a
novel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),
to detect the inpainted regions at pixel accuracy. The proposed GIID-Net
consists of three sub-blocks: the enhancement block, the extraction block and
the decision block. Specifically, the enhancement block aims to enhance the
inpainting traces by using hierarchically combined special layers. The
extraction block, automatically designed by Neural Architecture Search (NAS)
algorithm, is targeted to extract features for the actual inpainting detection
tasks. In order to further optimize the extracted latent features, we integrate
global and local attention modules in the decision block, where the global
attention reduces the intra-class differences by measuring the similarity of
global features, while the local attention strengthens the consistency of local
features. Furthermore, we thoroughly study the generalizability of our
GIID-Net, and find that different training data could result in vastly
different generalization capability. Extensive experimental results are
presented to validate the superiority of the proposed GIID-Net, compared with
the state-of-the-art competitors. Our results would suggest that common
artifacts are shared across diverse image inpainting methods. Finally, we build
a public inpainting dataset of 10K image pairs for the future research in this
area.","Some errors are found in the Section V of Experimental Results, and
  more experiments are needed to be added. Besides, there are some
  modifications we want to present in the Section III of the Methods, e.g.,
  updating the figures for better describe the proposed methods. Thanks!",,,cs.CV,"['cs.CV', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.07419v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.07419v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.07419v2,"{'id': 'http://arxiv.org/abs/2101.07419v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.07419v2', 'updated': '2021-01-29T05:44:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=29, tm_hour=5, tm_min=44, tm_sec=31, tm_wday=4, tm_yday=29, tm_isdst=0), 'published': '2021-01-19T02:29:40Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=19, tm_hour=2, tm_min=29, tm_sec=40, tm_wday=1, tm_yday=19, tm_isdst=0), 'title': 'GIID-Net: Generalizable Image Inpainting Detection via Neural\n  Architecture Search and Attention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'GIID-Net: Generalizable Image Inpainting Detection via Neural\n  Architecture Search and Attention'}, 'summary': 'Deep learning (DL) has demonstrated its powerful capabilities in the field of\nimage inpainting, which could produce visually plausible results. Meanwhile,\nthe malicious use of advanced image inpainting tools (e.g. removing key objects\nto report fake news) has led to increasing threats to the reliability of image\ndata. To fight against the inpainting forgeries, in this work, we propose a\nnovel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),\nto detect the inpainted regions at pixel accuracy. The proposed GIID-Net\nconsists of three sub-blocks: the enhancement block, the extraction block and\nthe decision block. Specifically, the enhancement block aims to enhance the\ninpainting traces by using hierarchically combined special layers. The\nextraction block, automatically designed by Neural Architecture Search (NAS)\nalgorithm, is targeted to extract features for the actual inpainting detection\ntasks. In order to further optimize the extracted latent features, we integrate\nglobal and local attention modules in the decision block, where the global\nattention reduces the intra-class differences by measuring the similarity of\nglobal features, while the local attention strengthens the consistency of local\nfeatures. Furthermore, we thoroughly study the generalizability of our\nGIID-Net, and find that different training data could result in vastly\ndifferent generalization capability. Extensive experimental results are\npresented to validate the superiority of the proposed GIID-Net, compared with\nthe state-of-the-art competitors. Our results would suggest that common\nartifacts are shared across diverse image inpainting methods. Finally, we build\na public inpainting dataset of 10K image pairs for the future research in this\narea.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deep learning (DL) has demonstrated its powerful capabilities in the field of\nimage inpainting, which could produce visually plausible results. Meanwhile,\nthe malicious use of advanced image inpainting tools (e.g. removing key objects\nto report fake news) has led to increasing threats to the reliability of image\ndata. To fight against the inpainting forgeries, in this work, we propose a\nnovel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),\nto detect the inpainted regions at pixel accuracy. The proposed GIID-Net\nconsists of three sub-blocks: the enhancement block, the extraction block and\nthe decision block. Specifically, the enhancement block aims to enhance the\ninpainting traces by using hierarchically combined special layers. The\nextraction block, automatically designed by Neural Architecture Search (NAS)\nalgorithm, is targeted to extract features for the actual inpainting detection\ntasks. In order to further optimize the extracted latent features, we integrate\nglobal and local attention modules in the decision block, where the global\nattention reduces the intra-class differences by measuring the similarity of\nglobal features, while the local attention strengthens the consistency of local\nfeatures. Furthermore, we thoroughly study the generalizability of our\nGIID-Net, and find that different training data could result in vastly\ndifferent generalization capability. Extensive experimental results are\npresented to validate the superiority of the proposed GIID-Net, compared with\nthe state-of-the-art competitors. Our results would suggest that common\nartifacts are shared across diverse image inpainting methods. Finally, we build\na public inpainting dataset of 10K image pairs for the future research in this\narea.'}, 'authors': [{'name': 'Haiwei Wu'}, {'name': 'Jiantao Zhou'}], 'author_detail': {'name': 'Jiantao Zhou'}, 'author': 'Jiantao Zhou', 'arxiv_comment': 'Some errors are found in the Section V of Experimental Results, and\n  more experiments are needed to be added. Besides, there are some\n  modifications we want to present in the Section III of the Methods, e.g.,\n  updating the figures for better describe the proposed methods. Thanks!', 'links': [{'href': 'http://arxiv.org/abs/2101.07419v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.07419v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
109,http://arxiv.org/abs/2101.05953v1,2021-01-15 03:24:36+00:00,2021-01-15 03:24:36+00:00,Hostility Detection and Covid-19 Fake News Detection in Social Media,"[arxiv.Result.Author('Ayush Gupta'), arxiv.Result.Author('Rohan Sukumaran'), arxiv.Result.Author('Kevin John'), arxiv.Result.Author('Sundeep Teki')]","Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the
content shared online. Consequently, the propagation of fake news and hostile
messages on social media platforms has also skyrocketed. In this paper, we
address the problem of detecting hostile and fake content in the Devanagari
(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we
build a model that makes use of an abusive language detector coupled with
features extracted via Hindi BERT and Hindi FastText models and metadata. Our
model achieves a 0.97 F1 score on coarse grain evaluation on Hostility
detection task. Additionally, we built models to identify fake news related to
Covid-19 in English tweets. We leverage entity information extracted from the
tweets along with textual representations learned from word embeddings and
achieve a 0.93 F1 score on the English fake news detection task.","13 pages, 3 figures, 3 tables",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2101.05953v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.05953v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.05953v1,"{'id': 'http://arxiv.org/abs/2101.05953v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.05953v1', 'updated': '2021-01-15T03:24:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=15, tm_hour=3, tm_min=24, tm_sec=36, tm_wday=4, tm_yday=15, tm_isdst=0), 'published': '2021-01-15T03:24:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=15, tm_hour=3, tm_min=24, tm_sec=36, tm_wday=4, tm_yday=15, tm_isdst=0), 'title': 'Hostility Detection and Covid-19 Fake News Detection in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hostility Detection and Covid-19 Fake News Detection in Social Media'}, 'summary': 'Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the\ncontent shared online. Consequently, the propagation of fake news and hostile\nmessages on social media platforms has also skyrocketed. In this paper, we\naddress the problem of detecting hostile and fake content in the Devanagari\n(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we\nbuild a model that makes use of an abusive language detector coupled with\nfeatures extracted via Hindi BERT and Hindi FastText models and metadata. Our\nmodel achieves a 0.97 F1 score on coarse grain evaluation on Hostility\ndetection task. Additionally, we built models to identify fake news related to\nCovid-19 in English tweets. We leverage entity information extracted from the\ntweets along with textual representations learned from word embeddings and\nachieve a 0.93 F1 score on the English fake news detection task.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the\ncontent shared online. Consequently, the propagation of fake news and hostile\nmessages on social media platforms has also skyrocketed. In this paper, we\naddress the problem of detecting hostile and fake content in the Devanagari\n(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we\nbuild a model that makes use of an abusive language detector coupled with\nfeatures extracted via Hindi BERT and Hindi FastText models and metadata. Our\nmodel achieves a 0.97 F1 score on coarse grain evaluation on Hostility\ndetection task. Additionally, we built models to identify fake news related to\nCovid-19 in English tweets. We leverage entity information extracted from the\ntweets along with textual representations learned from word embeddings and\nachieve a 0.93 F1 score on the English fake news detection task.'}, 'authors': [{'name': 'Ayush Gupta'}, {'name': 'Rohan Sukumaran'}, {'name': 'Kevin John'}, {'name': 'Sundeep Teki'}], 'author_detail': {'name': 'Sundeep Teki'}, 'author': 'Sundeep Teki', 'arxiv_comment': '13 pages, 3 figures, 3 tables', 'links': [{'href': 'http://arxiv.org/abs/2101.05953v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.05953v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
110,http://arxiv.org/abs/2101.05701v1,2021-01-14 16:25:32+00:00,2021-01-14 16:25:32+00:00,TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection,"[arxiv.Result.Author('Elena Shushkevich'), arxiv.Result.Author('John Cardiff')]","The paper is devoted to the participation of the TUDublin team in
Constraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem
of fake news detection is more acute than ever in connection with the pandemic.
The number of fake news is increasing rapidly and it is necessary to create AI
tools that allow us to identify and prevent the spread of false information
about COVID-19 urgently. The main goal of the work was to create a model that
would carry out a binary classification of messages from social media as real
or fake news in the context of COVID-19. Our team constructed the ensemble
consisting of Bidirectional Long Short Term Memory, Support Vector Machine,
Logistic Regression, Naive Bayes and a combination of Logistic Regression and
Naive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\%
of the best result.",8 pages,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.05701v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.05701v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.05701v1,"{'id': 'http://arxiv.org/abs/2101.05701v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.05701v1', 'updated': '2021-01-14T16:25:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=32, tm_wday=3, tm_yday=14, tm_isdst=0), 'published': '2021-01-14T16:25:32Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=32, tm_wday=3, tm_yday=14, tm_isdst=0), 'title': 'TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection'}, 'summary': 'The paper is devoted to the participation of the TUDublin team in\nConstraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem\nof fake news detection is more acute than ever in connection with the pandemic.\nThe number of fake news is increasing rapidly and it is necessary to create AI\ntools that allow us to identify and prevent the spread of false information\nabout COVID-19 urgently. The main goal of the work was to create a model that\nwould carry out a binary classification of messages from social media as real\nor fake news in the context of COVID-19. Our team constructed the ensemble\nconsisting of Bidirectional Long Short Term Memory, Support Vector Machine,\nLogistic Regression, Naive Bayes and a combination of Logistic Regression and\nNaive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\\%\nof the best result.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The paper is devoted to the participation of the TUDublin team in\nConstraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem\nof fake news detection is more acute than ever in connection with the pandemic.\nThe number of fake news is increasing rapidly and it is necessary to create AI\ntools that allow us to identify and prevent the spread of false information\nabout COVID-19 urgently. The main goal of the work was to create a model that\nwould carry out a binary classification of messages from social media as real\nor fake news in the context of COVID-19. Our team constructed the ensemble\nconsisting of Bidirectional Long Short Term Memory, Support Vector Machine,\nLogistic Regression, Naive Bayes and a combination of Logistic Regression and\nNaive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\\%\nof the best result.'}, 'authors': [{'name': 'Elena Shushkevich'}, {'name': 'John Cardiff'}], 'author_detail': {'name': 'John Cardiff'}, 'author': 'John Cardiff', 'arxiv_comment': '8 pages', 'links': [{'href': 'http://arxiv.org/abs/2101.05701v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.05701v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
111,http://arxiv.org/abs/2101.05509v2,2021-01-18 15:53:22+00:00,2021-01-14 09:05:42+00:00,Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake News Detection,"[arxiv.Result.Author('Ben Chen'), arxiv.Result.Author('Bin Chen'), arxiv.Result.Author('Dehong Gao'), arxiv.Result.Author('Qijin Chen'), arxiv.Result.Author('Chengfu Huo'), arxiv.Result.Author('Xiaonan Meng'), arxiv.Result.Author('Weijun Ren'), arxiv.Result.Author('Yang Zhou')]","With the pandemic of COVID-19, relevant fake news is spreading all over the
sky throughout the social media. Believing in them without discrimination can
cause great trouble to people's life. However, universal language models may
perform weakly in these fake news detection for lack of large-scale annotated
data and sufficient semantic understanding of domain-specific knowledge. While
the model trained on corresponding corpora is also mediocre for insufficient
learning. In this paper, we propose a novel transformer-based language model
fine-tuning approach for these fake news detection. First, the token vocabulary
of individual model is expanded for the actual semantics of professional
phrases. Second, we adapt the heated-up softmax loss to distinguish the
hard-mining samples, which are common for fake news because of the
disambiguation of short text. Then, we involve adversarial training to improve
the model's robustness. Last, the predicted features extracted by universal
language model RoBERTa and domain-specific model CT-BERT are fused by one
multiple layer perception to integrate fine-grained and high-level specific
representations. Quantitative experimental results evaluated on existing
COVID-19 fake news dataset show its superior performances compared to the
state-of-the-art methods among various evaluation metrics. Furthermore, the
best weighted average F1 score achieves 99.02%.","9 pages, 1 figures",,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.05509v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.05509v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.05509v2,"{'id': 'http://arxiv.org/abs/2101.05509v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.05509v2', 'updated': '2021-01-18T15:53:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=18, tm_hour=15, tm_min=53, tm_sec=22, tm_wday=0, tm_yday=18, tm_isdst=0), 'published': '2021-01-14T09:05:42Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=14, tm_hour=9, tm_min=5, tm_sec=42, tm_wday=3, tm_yday=14, tm_isdst=0), 'title': 'Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection'}, 'summary': ""With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%.""}, 'authors': [{'name': 'Ben Chen'}, {'name': 'Bin Chen'}, {'name': 'Dehong Gao'}, {'name': 'Qijin Chen'}, {'name': 'Chengfu Huo'}, {'name': 'Xiaonan Meng'}, {'name': 'Weijun Ren'}, {'name': 'Yang Zhou'}], 'author_detail': {'name': 'Yang Zhou'}, 'author': 'Yang Zhou', 'arxiv_comment': '9 pages, 1 figures', 'links': [{'href': 'http://arxiv.org/abs/2101.05509v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.05509v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
112,http://arxiv.org/abs/2101.05499v1,2021-01-14 08:39:50+00:00,2021-01-14 08:39:50+00:00,"ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and Source Information","[arxiv.Result.Author('Ipek Baris'), arxiv.Result.Author('Zeyd Boukhers')]","Social media platforms are vulnerable to fake news dissemination, which
causes negative consequences such as panic and wrong medication in the
healthcare domain. Therefore, it is important to automatically detect fake news
in an early stage before they get widely spread. This paper analyzes the impact
of incorporating content information, prior knowledge, and credibility of
sources into models for the early detection of fake news. We propose a
framework modeling those features by using BERT language model and external
sources, namely Simple English Wikipedia and source reliability tags. The
conducted experiments on CONSTRAINT datasets demonstrated the benefit of
integrating these features for the early detection of fake news in the
healthcare domain.",to be published in Constraint-2021 Workshop @ AAAI,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2101.05499v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.05499v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.05499v1,"{'id': 'http://arxiv.org/abs/2101.05499v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.05499v1', 'updated': '2021-01-14T08:39:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=14, tm_hour=8, tm_min=39, tm_sec=50, tm_wday=3, tm_yday=14, tm_isdst=0), 'published': '2021-01-14T08:39:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=14, tm_hour=8, tm_min=39, tm_sec=50, tm_wday=3, tm_yday=14, tm_isdst=0), 'title': 'ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and\n  Source Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and\n  Source Information'}, 'summary': 'Social media platforms are vulnerable to fake news dissemination, which\ncauses negative consequences such as panic and wrong medication in the\nhealthcare domain. Therefore, it is important to automatically detect fake news\nin an early stage before they get widely spread. This paper analyzes the impact\nof incorporating content information, prior knowledge, and credibility of\nsources into models for the early detection of fake news. We propose a\nframework modeling those features by using BERT language model and external\nsources, namely Simple English Wikipedia and source reliability tags. The\nconducted experiments on CONSTRAINT datasets demonstrated the benefit of\nintegrating these features for the early detection of fake news in the\nhealthcare domain.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media platforms are vulnerable to fake news dissemination, which\ncauses negative consequences such as panic and wrong medication in the\nhealthcare domain. Therefore, it is important to automatically detect fake news\nin an early stage before they get widely spread. This paper analyzes the impact\nof incorporating content information, prior knowledge, and credibility of\nsources into models for the early detection of fake news. We propose a\nframework modeling those features by using BERT language model and external\nsources, namely Simple English Wikipedia and source reliability tags. The\nconducted experiments on CONSTRAINT datasets demonstrated the benefit of\nintegrating these features for the early detection of fake news in the\nhealthcare domain.'}, 'authors': [{'name': 'Ipek Baris'}, {'name': 'Zeyd Boukhers'}], 'author_detail': {'name': 'Zeyd Boukhers'}, 'author': 'Zeyd Boukhers', 'arxiv_comment': 'to be published in Constraint-2021 Workshop @ AAAI', 'links': [{'href': 'http://arxiv.org/abs/2101.05499v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.05499v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
113,http://arxiv.org/abs/2101.04965v1,2021-01-13 09:52:04+00:00,2021-01-13 09:52:04+00:00,LaDiff ULMFiT: A Layer Differentiated training approach for ULMFiT,"[arxiv.Result.Author('Mohammed Azhan'), arxiv.Result.Author('Mohammad Ahmad')]","In our paper, we present Deep Learning models with a layer differentiated
training method which were used for the SHARED TASK@ CONSTRAINT 2021 sub-tasks
COVID19 Fake News Detection in English and Hostile Post Detection in Hindi. We
propose a Layer Differentiated training procedure for training a pre-trained
ULMFiT arXiv:1801.06146 model. We used special tokens to annotate specific
parts of the tweets to improve language understanding and gain insights on the
model making the tweets more interpretable. The other two submissions included
a modified RoBERTa model and a simple Random Forest Classifier. The proposed
approach scored a precision and f1 score of 0.96728972 and 0.967324832
respectively for sub-task ""COVID19 Fake News Detection in English"". Also,
Coarse-Grained Hostility f1 Score and Weighted FineGrained f1 score of 0.908648
and 0.533907 respectively for sub-task Hostile Post Detection in Hindi. The
proposed approach ranked 61st out of 164 in the sub-task ""COVID19 Fake News
Detection in English and 18th out of 45 in the sub-task Hostile Post Detection
in Hindi"".",,,,cs.CL,"['cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2101.04965v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.04965v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.04965v1,"{'id': 'http://arxiv.org/abs/2101.04965v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.04965v1', 'updated': '2021-01-13T09:52:04Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=9, tm_min=52, tm_sec=4, tm_wday=2, tm_yday=13, tm_isdst=0), 'published': '2021-01-13T09:52:04Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=9, tm_min=52, tm_sec=4, tm_wday=2, tm_yday=13, tm_isdst=0), 'title': 'LaDiff ULMFiT: A Layer Differentiated training approach for ULMFiT', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'LaDiff ULMFiT: A Layer Differentiated training approach for ULMFiT'}, 'summary': 'In our paper, we present Deep Learning models with a layer differentiated\ntraining method which were used for the SHARED TASK@ CONSTRAINT 2021 sub-tasks\nCOVID19 Fake News Detection in English and Hostile Post Detection in Hindi. We\npropose a Layer Differentiated training procedure for training a pre-trained\nULMFiT arXiv:1801.06146 model. We used special tokens to annotate specific\nparts of the tweets to improve language understanding and gain insights on the\nmodel making the tweets more interpretable. The other two submissions included\na modified RoBERTa model and a simple Random Forest Classifier. The proposed\napproach scored a precision and f1 score of 0.96728972 and 0.967324832\nrespectively for sub-task ""COVID19 Fake News Detection in English"". Also,\nCoarse-Grained Hostility f1 Score and Weighted FineGrained f1 score of 0.908648\nand 0.533907 respectively for sub-task Hostile Post Detection in Hindi. The\nproposed approach ranked 61st out of 164 in the sub-task ""COVID19 Fake News\nDetection in English and 18th out of 45 in the sub-task Hostile Post Detection\nin Hindi"".', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In our paper, we present Deep Learning models with a layer differentiated\ntraining method which were used for the SHARED TASK@ CONSTRAINT 2021 sub-tasks\nCOVID19 Fake News Detection in English and Hostile Post Detection in Hindi. We\npropose a Layer Differentiated training procedure for training a pre-trained\nULMFiT arXiv:1801.06146 model. We used special tokens to annotate specific\nparts of the tweets to improve language understanding and gain insights on the\nmodel making the tweets more interpretable. The other two submissions included\na modified RoBERTa model and a simple Random Forest Classifier. The proposed\napproach scored a precision and f1 score of 0.96728972 and 0.967324832\nrespectively for sub-task ""COVID19 Fake News Detection in English"". Also,\nCoarse-Grained Hostility f1 Score and Weighted FineGrained f1 score of 0.908648\nand 0.533907 respectively for sub-task Hostile Post Detection in Hindi. The\nproposed approach ranked 61st out of 164 in the sub-task ""COVID19 Fake News\nDetection in English and 18th out of 45 in the sub-task Hostile Post Detection\nin Hindi"".'}, 'authors': [{'name': 'Mohammed Azhan'}, {'name': 'Mohammad Ahmad'}], 'author_detail': {'name': 'Mohammad Ahmad'}, 'author': 'Mohammad Ahmad', 'links': [{'href': 'http://arxiv.org/abs/2101.04965v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.04965v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
114,http://arxiv.org/abs/2101.11425v1,2021-01-12 16:23:24+00:00,2021-01-12 16:23:24+00:00,Fake News Detection System using XLNet model with Topic Distributions: CONSTRAINT@AAAI2021 Shared Task,"[arxiv.Result.Author('Akansha Gautam'), arxiv.Result.Author('Venktesh V'), arxiv.Result.Author('Sarah Masud')]","With the ease of access to information, and its rapid dissemination over the
internet (both velocity and volume), it has become challenging to filter out
truthful information from fake ones. The research community is now faced with
the task of automatic detection of fake news, which carries real-world
socio-political impact. One such research contribution came in the form of the
Constraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In
this paper, we shed light on a novel method we proposed as a part of this
shared task. Our team introduced an approach to combine topical distributions
from Latent Dirichlet Allocation (LDA) with contextualized representations from
XLNet. We also compared our method with existing baselines to show that XLNet +
Topic Distributions outperforms other approaches by attaining an F1-score of
0.967.","Accepted at CONSTRAINT@AAAI2021 Shared Task for the CONSTRAINT
  workshop, collocated with AAAI 2021",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.11425v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.11425v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.11425v1,"{'id': 'http://arxiv.org/abs/2101.11425v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.11425v1', 'updated': '2021-01-12T16:23:24Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=12, tm_hour=16, tm_min=23, tm_sec=24, tm_wday=1, tm_yday=12, tm_isdst=0), 'published': '2021-01-12T16:23:24Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=12, tm_hour=16, tm_min=23, tm_sec=24, tm_wday=1, tm_yday=12, tm_isdst=0), 'title': 'Fake News Detection System using XLNet model with Topic Distributions:\n  CONSTRAINT@AAAI2021 Shared Task', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection System using XLNet model with Topic Distributions:\n  CONSTRAINT@AAAI2021 Shared Task'}, 'summary': 'With the ease of access to information, and its rapid dissemination over the\ninternet (both velocity and volume), it has become challenging to filter out\ntruthful information from fake ones. The research community is now faced with\nthe task of automatic detection of fake news, which carries real-world\nsocio-political impact. One such research contribution came in the form of the\nConstraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In\nthis paper, we shed light on a novel method we proposed as a part of this\nshared task. Our team introduced an approach to combine topical distributions\nfrom Latent Dirichlet Allocation (LDA) with contextualized representations from\nXLNet. We also compared our method with existing baselines to show that XLNet +\nTopic Distributions outperforms other approaches by attaining an F1-score of\n0.967.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the ease of access to information, and its rapid dissemination over the\ninternet (both velocity and volume), it has become challenging to filter out\ntruthful information from fake ones. The research community is now faced with\nthe task of automatic detection of fake news, which carries real-world\nsocio-political impact. One such research contribution came in the form of the\nConstraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In\nthis paper, we shed light on a novel method we proposed as a part of this\nshared task. Our team introduced an approach to combine topical distributions\nfrom Latent Dirichlet Allocation (LDA) with contextualized representations from\nXLNet. We also compared our method with existing baselines to show that XLNet +\nTopic Distributions outperforms other approaches by attaining an F1-score of\n0.967.'}, 'authors': [{'name': 'Akansha Gautam'}, {'name': 'Venktesh V'}, {'name': 'Sarah Masud'}], 'author_detail': {'name': 'Sarah Masud'}, 'author': 'Sarah Masud', 'arxiv_comment': 'Accepted at CONSTRAINT@AAAI2021 Shared Task for the CONSTRAINT\n  workshop, collocated with AAAI 2021', 'links': [{'href': 'http://arxiv.org/abs/2101.11425v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.11425v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
115,http://arxiv.org/abs/2101.04012v2,2021-01-13 17:18:02+00:00,2021-01-11 16:39:03+00:00,Evaluating Deep Learning Approaches for Covid19 Fake News Detection,"[arxiv.Result.Author('Apurva Wani'), arxiv.Result.Author('Isha Joshi'), arxiv.Result.Author('Snehal Khandve'), arxiv.Result.Author('Vedangi Wagh'), arxiv.Result.Author('Raviraj Joshi')]","Social media platforms like Facebook, Twitter, and Instagram have enabled
connection and communication on a large scale. It has revolutionized the rate
at which information is shared and enhanced its reach. However, another side of
the coin dictates an alarming story. These platforms have led to an increase in
the creation and spread of fake news. The fake news has not only influenced
people in the wrong direction but also claimed human lives. During these
critical times of the Covid19 pandemic, it is easy to mislead people and make
them believe in fatal information. Therefore it is important to curb fake news
at source and prevent it from spreading to a larger audience. We look at
automated techniques for fake news detection from a data mining perspective. We
evaluate different supervised text classification algorithms on Contraint@AAAI
2021 Covid-19 Fake news detection dataset. The classification algorithms are
based on Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM),
and Bidirectional Encoder Representations from Transformers (BERT). We also
evaluate the importance of unsupervised learning in the form of language model
pre-training and distributed word representations using unlabelled covid tweets
corpus. We report the best accuracy of 98.41\% on the Covid-19 Fake news
detection dataset.",Accepted at Contraint@AAAI 2021,,10.1007/978-3-030-73696-5_15,cs.LG,"['cs.LG', 'cs.IR']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-73696-5_15', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.04012v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.04012v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.04012v2,"{'id': 'http://arxiv.org/abs/2101.04012v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.04012v2', 'updated': '2021-01-13T17:18:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=17, tm_min=18, tm_sec=2, tm_wday=2, tm_yday=13, tm_isdst=0), 'published': '2021-01-11T16:39:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=16, tm_min=39, tm_sec=3, tm_wday=0, tm_yday=11, tm_isdst=0), 'title': 'Evaluating Deep Learning Approaches for Covid19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evaluating Deep Learning Approaches for Covid19 Fake News Detection'}, 'summary': 'Social media platforms like Facebook, Twitter, and Instagram have enabled\nconnection and communication on a large scale. It has revolutionized the rate\nat which information is shared and enhanced its reach. However, another side of\nthe coin dictates an alarming story. These platforms have led to an increase in\nthe creation and spread of fake news. The fake news has not only influenced\npeople in the wrong direction but also claimed human lives. During these\ncritical times of the Covid19 pandemic, it is easy to mislead people and make\nthem believe in fatal information. Therefore it is important to curb fake news\nat source and prevent it from spreading to a larger audience. We look at\nautomated techniques for fake news detection from a data mining perspective. We\nevaluate different supervised text classification algorithms on Contraint@AAAI\n2021 Covid-19 Fake news detection dataset. The classification algorithms are\nbased on Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM),\nand Bidirectional Encoder Representations from Transformers (BERT). We also\nevaluate the importance of unsupervised learning in the form of language model\npre-training and distributed word representations using unlabelled covid tweets\ncorpus. We report the best accuracy of 98.41\\% on the Covid-19 Fake news\ndetection dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media platforms like Facebook, Twitter, and Instagram have enabled\nconnection and communication on a large scale. It has revolutionized the rate\nat which information is shared and enhanced its reach. However, another side of\nthe coin dictates an alarming story. These platforms have led to an increase in\nthe creation and spread of fake news. The fake news has not only influenced\npeople in the wrong direction but also claimed human lives. During these\ncritical times of the Covid19 pandemic, it is easy to mislead people and make\nthem believe in fatal information. Therefore it is important to curb fake news\nat source and prevent it from spreading to a larger audience. We look at\nautomated techniques for fake news detection from a data mining perspective. We\nevaluate different supervised text classification algorithms on Contraint@AAAI\n2021 Covid-19 Fake news detection dataset. The classification algorithms are\nbased on Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM),\nand Bidirectional Encoder Representations from Transformers (BERT). We also\nevaluate the importance of unsupervised learning in the form of language model\npre-training and distributed word representations using unlabelled covid tweets\ncorpus. We report the best accuracy of 98.41\\% on the Covid-19 Fake news\ndetection dataset.'}, 'authors': [{'name': 'Apurva Wani'}, {'name': 'Isha Joshi'}, {'name': 'Snehal Khandve'}, {'name': 'Vedangi Wagh'}, {'name': 'Raviraj Joshi'}], 'author_detail': {'name': 'Raviraj Joshi'}, 'author': 'Raviraj Joshi', 'arxiv_doi': '10.1007/978-3-030-73696-5_15', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-73696-5_15', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.04012v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.04012v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted at Contraint@AAAI 2021', 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
116,http://arxiv.org/abs/2101.03988v2,2021-06-30 18:35:03+00:00,2021-01-11 15:52:37+00:00,Identification of COVID-19 related Fake News via Neural Stacking,"[arxiv.Result.Author('Boshko Koloski'), arxiv.Result.Author('Timen Stepišnik Perdih'), arxiv.Result.Author('Senja Pollak'), arxiv.Result.Author('Blaž Škrlj')]","Identification of Fake News plays a prominent role in the ongoing pandemic,
impacting multiple aspects of day-to-day life. In this work we present a
solution to the shared task titled COVID19 Fake News Detection in English,
scoring the 50th place amongst 168 submissions. The solution was within 1.5% of
the best performing solution. The proposed solution employs a heterogeneous
representation ensemble, adapted for the classification task via an additional
neural classification head comprised of multiple hidden layers. The paper
consists of detailed ablation studies further displaying the proposed method's
behavior and possible implications. The solution is freely available.
\url{https://gitlab.com/boshko.koloski/covid19-fake-news}",Published at CONSTRAIN 2021 (AAAI),,10.1007/978-3-030-73696-5_17,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-73696-5_17', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.03988v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03988v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03988v2,"{'id': 'http://arxiv.org/abs/2101.03988v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03988v2', 'updated': '2021-06-30T18:35:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=30, tm_hour=18, tm_min=35, tm_sec=3, tm_wday=2, tm_yday=181, tm_isdst=0), 'published': '2021-01-11T15:52:37Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=15, tm_min=52, tm_sec=37, tm_wday=0, tm_yday=11, tm_isdst=0), 'title': 'Identification of COVID-19 related Fake News via Neural Stacking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identification of COVID-19 related Fake News via Neural Stacking'}, 'summary': ""Identification of Fake News plays a prominent role in the ongoing pandemic,\nimpacting multiple aspects of day-to-day life. In this work we present a\nsolution to the shared task titled COVID19 Fake News Detection in English,\nscoring the 50th place amongst 168 submissions. The solution was within 1.5% of\nthe best performing solution. The proposed solution employs a heterogeneous\nrepresentation ensemble, adapted for the classification task via an additional\nneural classification head comprised of multiple hidden layers. The paper\nconsists of detailed ablation studies further displaying the proposed method's\nbehavior and possible implications. The solution is freely available.\n\\url{https://gitlab.com/boshko.koloski/covid19-fake-news}"", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Identification of Fake News plays a prominent role in the ongoing pandemic,\nimpacting multiple aspects of day-to-day life. In this work we present a\nsolution to the shared task titled COVID19 Fake News Detection in English,\nscoring the 50th place amongst 168 submissions. The solution was within 1.5% of\nthe best performing solution. The proposed solution employs a heterogeneous\nrepresentation ensemble, adapted for the classification task via an additional\nneural classification head comprised of multiple hidden layers. The paper\nconsists of detailed ablation studies further displaying the proposed method's\nbehavior and possible implications. The solution is freely available.\n\\url{https://gitlab.com/boshko.koloski/covid19-fake-news}""}, 'authors': [{'name': 'Boshko Koloski'}, {'name': 'Timen Stepišnik Perdih'}, {'name': 'Senja Pollak'}, {'name': 'Blaž Škrlj'}], 'author_detail': {'name': 'Blaž Škrlj'}, 'author': 'Blaž Škrlj', 'arxiv_doi': '10.1007/978-3-030-73696-5_17', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-73696-5_17', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.03988v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03988v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published at CONSTRAIN 2021 (AAAI)', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
117,http://arxiv.org/abs/2101.03841v1,2021-01-11 12:23:41+00:00,2021-01-11 12:23:41+00:00,Model Generalization on COVID-19 Fake News Detection,"[arxiv.Result.Author('Yejin Bang'), arxiv.Result.Author('Etsuko Ishii'), arxiv.Result.Author('Samuel Cahyawijaya'), arxiv.Result.Author('Ziwei Ji'), arxiv.Result.Author('Pascale Fung')]","Amid the pandemic COVID-19, the world is facing unprecedented infodemic with
the proliferation of both fake and real information. Considering the
problematic consequences that the COVID-19 fake-news have brought, the
scientific community has put effort to tackle it. To contribute to this fight
against the infodemic, we aim to achieve a robust model for the COVID-19
fake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking
two separate approaches: 1) fine-tuning transformers based language models with
robust loss functions and 2) removing harmful training instances through
influence calculation. We further evaluate the robustness of our models by
evaluating on different COVID-19 misinformation test set (Tweets-19) to
understand model generalization ability. With the first approach, we achieve
98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on
the Tweets-19 highest. On the contrary, by performing influence data cleansing,
our model with 99% cleansing percentage can achieve 54.33% W-F1 score on
Tweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news
test sets, we suggest the importance of model generalization ability in this
task to step forward to tackle the COVID-19 fake-news problem in online social
media platforms.",CONSTRAINT Workshop 2021 (Camera Ready Version),,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.03841v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03841v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03841v1,"{'id': 'http://arxiv.org/abs/2101.03841v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03841v1', 'updated': '2021-01-11T12:23:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=12, tm_min=23, tm_sec=41, tm_wday=0, tm_yday=11, tm_isdst=0), 'published': '2021-01-11T12:23:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=12, tm_min=23, tm_sec=41, tm_wday=0, tm_yday=11, tm_isdst=0), 'title': 'Model Generalization on COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Model Generalization on COVID-19 Fake News Detection'}, 'summary': 'Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.'}, 'authors': [{'name': 'Yejin Bang'}, {'name': 'Etsuko Ishii'}, {'name': 'Samuel Cahyawijaya'}, {'name': 'Ziwei Ji'}, {'name': 'Pascale Fung'}], 'author_detail': {'name': 'Pascale Fung'}, 'author': 'Pascale Fung', 'arxiv_comment': 'CONSTRAINT Workshop 2021 (Camera Ready Version)', 'links': [{'href': 'http://arxiv.org/abs/2101.03841v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03841v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
118,http://arxiv.org/abs/2101.03717v2,2021-01-13 00:06:45+00:00,2021-01-11 05:57:32+00:00,Constraint 2021: Machine Learning Models for COVID-19 Fake News Detection Shared Task,[arxiv.Result.Author('Thomas Felber')],"In this system paper we present our contribution to the Constraint 2021
COVID-19 Fake News Detection Shared Task, which poses the challenge of
classifying COVID-19 related social media posts as either fake or real. In our
system, we address this challenge by applying classical machine learning
algorithms together with several linguistic features, such as n-grams,
readability, emotional tone and punctuation. In terms of pre-processing, we
experiment with various steps like stop word removal, stemming/lemmatization,
link removal and more. We find our best performing system to be based on a
linear SVM, which obtains a weighted average F1 score of 95.19% on test data,
which lands a place in the middle of the leaderboard (place 80 of 167).","Constraint 2021, AAAI 21, 10 pages",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.03717v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03717v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03717v2,"{'id': 'http://arxiv.org/abs/2101.03717v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03717v2', 'updated': '2021-01-13T00:06:45Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=0, tm_min=6, tm_sec=45, tm_wday=2, tm_yday=13, tm_isdst=0), 'published': '2021-01-11T05:57:32Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=5, tm_min=57, tm_sec=32, tm_wday=0, tm_yday=11, tm_isdst=0), 'title': 'Constraint 2021: Machine Learning Models for COVID-19 Fake News\n  Detection Shared Task', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Constraint 2021: Machine Learning Models for COVID-19 Fake News\n  Detection Shared Task'}, 'summary': 'In this system paper we present our contribution to the Constraint 2021\nCOVID-19 Fake News Detection Shared Task, which poses the challenge of\nclassifying COVID-19 related social media posts as either fake or real. In our\nsystem, we address this challenge by applying classical machine learning\nalgorithms together with several linguistic features, such as n-grams,\nreadability, emotional tone and punctuation. In terms of pre-processing, we\nexperiment with various steps like stop word removal, stemming/lemmatization,\nlink removal and more. We find our best performing system to be based on a\nlinear SVM, which obtains a weighted average F1 score of 95.19% on test data,\nwhich lands a place in the middle of the leaderboard (place 80 of 167).', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this system paper we present our contribution to the Constraint 2021\nCOVID-19 Fake News Detection Shared Task, which poses the challenge of\nclassifying COVID-19 related social media posts as either fake or real. In our\nsystem, we address this challenge by applying classical machine learning\nalgorithms together with several linguistic features, such as n-grams,\nreadability, emotional tone and punctuation. In terms of pre-processing, we\nexperiment with various steps like stop word removal, stemming/lemmatization,\nlink removal and more. We find our best performing system to be based on a\nlinear SVM, which obtains a weighted average F1 score of 95.19% on test data,\nwhich lands a place in the middle of the leaderboard (place 80 of 167).'}, 'authors': [{'name': 'Thomas Felber'}], 'author_detail': {'name': 'Thomas Felber'}, 'author': 'Thomas Felber', 'arxiv_comment': 'Constraint 2021, AAAI 21, 10 pages', 'links': [{'href': 'http://arxiv.org/abs/2101.03717v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03717v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
119,http://arxiv.org/abs/2101.03545v1,2021-01-10 13:21:08+00:00,2021-01-10 13:21:08+00:00,A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection,"[arxiv.Result.Author('Sourya Dipta Das'), arxiv.Result.Author('Ayan Basak'), arxiv.Result.Author('Saikat Dutta')]","The significance of social media has increased manifold in the past few
decades as it helps people from even the most remote corners of the world stay
connected. With the COVID-19 pandemic raging, social media has become more
relevant and widely used than ever before, and along with this, there has been
a resurgence in the circulation of fake news and tweets that demand immediate
attention. In this paper, we describe our Fake News Detection system that
automatically identifies whether a tweet related to COVID-19 is ""real"" or
""fake"", as a part of CONSTRAINT COVID19 Fake News Detection in English
challenge. We have used an ensemble model consisting of pre-trained models that
has helped us achieve a joint 8th position on the leader board. We have
achieved an F1-score of 0.9831 against a top score of 0.9869. Post completion
of the competition, we have been able to drastically improve our system by
incorporating a novel heuristic algorithm based on username handles and link
domains in tweets fetching an F1-score of 0.9883 and achieving state-of-the art
results on the given dataset.","Accepted to CONSTRAINT Workshop, AAAI'21",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2101.03545v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03545v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03545v1,"{'id': 'http://arxiv.org/abs/2101.03545v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03545v1', 'updated': '2021-01-10T13:21:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=10, tm_hour=13, tm_min=21, tm_sec=8, tm_wday=6, tm_yday=10, tm_isdst=0), 'published': '2021-01-10T13:21:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=10, tm_hour=13, tm_min=21, tm_sec=8, tm_wday=6, tm_yday=10, tm_isdst=0), 'title': 'A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection'}, 'summary': 'The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world stay\nconnected. With the COVID-19 pandemic raging, social media has become more\nrelevant and widely used than ever before, and along with this, there has been\na resurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe our Fake News Detection system that\nautomatically identifies whether a tweet related to COVID-19 is ""real"" or\n""fake"", as a part of CONSTRAINT COVID19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models that\nhas helped us achieve a joint 8th position on the leader board. We have\nachieved an F1-score of 0.9831 against a top score of 0.9869. Post completion\nof the competition, we have been able to drastically improve our system by\nincorporating a novel heuristic algorithm based on username handles and link\ndomains in tweets fetching an F1-score of 0.9883 and achieving state-of-the art\nresults on the given dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world stay\nconnected. With the COVID-19 pandemic raging, social media has become more\nrelevant and widely used than ever before, and along with this, there has been\na resurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe our Fake News Detection system that\nautomatically identifies whether a tweet related to COVID-19 is ""real"" or\n""fake"", as a part of CONSTRAINT COVID19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models that\nhas helped us achieve a joint 8th position on the leader board. We have\nachieved an F1-score of 0.9831 against a top score of 0.9869. Post completion\nof the competition, we have been able to drastically improve our system by\nincorporating a novel heuristic algorithm based on username handles and link\ndomains in tweets fetching an F1-score of 0.9883 and achieving state-of-the art\nresults on the given dataset.'}, 'authors': [{'name': 'Sourya Dipta Das'}, {'name': 'Ayan Basak'}, {'name': 'Saikat Dutta'}], 'author_detail': {'name': 'Saikat Dutta'}, 'author': 'Saikat Dutta', 'arxiv_comment': ""Accepted to CONSTRAINT Workshop, AAAI'21"", 'links': [{'href': 'http://arxiv.org/abs/2101.03545v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03545v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
120,http://arxiv.org/abs/2101.03529v1,2021-01-10 11:52:17+00:00,2021-01-10 11:52:17+00:00,TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on Corona Virus and 5G Conspiracy,"[arxiv.Result.Author('Gullal S. Cheema'), arxiv.Result.Author('Sherzod Hakimov'), arxiv.Result.Author('Ralph Ewerth')]","Fake news on social media has become a hot topic of research as it negatively
impacts the discourse of real news in the public. Specifically, the ongoing
COVID-19 pandemic has seen a rise of inaccurate and misleading information due
to the surrounding controversies and unknown details at the beginning of the
pandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating
a challenge to automatically detect tweets containing misinformation based on
text and structure from Twitter follower network. In this paper, we present a
simple approach that uses BERT embeddings and a shallow neural network for
classifying tweets using only text, and discuss our findings and limitations of
the approach in text-based misinformation detection.",MediaEval 2020 Fake News Task,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.03529v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03529v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03529v1,"{'id': 'http://arxiv.org/abs/2101.03529v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03529v1', 'updated': '2021-01-10T11:52:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=10, tm_hour=11, tm_min=52, tm_sec=17, tm_wday=6, tm_yday=10, tm_isdst=0), 'published': '2021-01-10T11:52:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=10, tm_hour=11, tm_min=52, tm_sec=17, tm_wday=6, tm_yday=10, tm_isdst=0), 'title': ""TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy""}, 'summary': 'Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.'}, 'authors': [{'name': 'Gullal S. Cheema'}, {'name': 'Sherzod Hakimov'}, {'name': 'Ralph Ewerth'}], 'author_detail': {'name': 'Ralph Ewerth'}, 'author': 'Ralph Ewerth', 'arxiv_comment': 'MediaEval 2020 Fake News Task', 'links': [{'href': 'http://arxiv.org/abs/2101.03529v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03529v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
121,http://arxiv.org/abs/2101.03291v1,2021-01-09 05:15:41+00:00,2021-01-09 05:15:41+00:00,Combating Hostility: Covid-19 Fake News and Hostile Post Detection in Social Media,"[arxiv.Result.Author('Omar Sharif'), arxiv.Result.Author('Eftekhar Hossain'), arxiv.Result.Author('Mohammed Moshiul Hoque')]","This paper illustrates a detail description of the system and its results
that developed as a part of the participation at CONSTRAINT shared task in
AAAI-2021. The shared task comprises two tasks: a) COVID19 fake news detection
in English b) Hostile post detection in Hindi. Task-A is a binary
classification problem with fake and real class, while task-B is a multi-label
multi-class classification task with five hostile classes (i.e. defame, fake,
hate, offense, non-hostile). Various techniques are used to perform the
classification task, including SVM, CNN, BiLSTM, and CNN+BiLSTM with tf-idf and
Word2Vec embedding techniques. Results indicate that SVM with tf-idf features
achieved the highest 94.39% weighted $f_1$ score on the test set in task-A.
Label powerset SVM with n-gram features obtained the maximum coarse-grained and
fine-grained $f_1$ score of 86.03% and 50.98% on the task-B test set
respectively.","Shared task description paper in CONSTRAINT workshop collocated with
  AAAI-2021, 11 pages",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.03291v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03291v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03291v1,"{'id': 'http://arxiv.org/abs/2101.03291v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03291v1', 'updated': '2021-01-09T05:15:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=9, tm_hour=5, tm_min=15, tm_sec=41, tm_wday=5, tm_yday=9, tm_isdst=0), 'published': '2021-01-09T05:15:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=9, tm_hour=5, tm_min=15, tm_sec=41, tm_wday=5, tm_yday=9, tm_isdst=0), 'title': 'Combating Hostility: Covid-19 Fake News and Hostile Post Detection in\n  Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Hostility: Covid-19 Fake News and Hostile Post Detection in\n  Social Media'}, 'summary': 'This paper illustrates a detail description of the system and its results\nthat developed as a part of the participation at CONSTRAINT shared task in\nAAAI-2021. The shared task comprises two tasks: a) COVID19 fake news detection\nin English b) Hostile post detection in Hindi. Task-A is a binary\nclassification problem with fake and real class, while task-B is a multi-label\nmulti-class classification task with five hostile classes (i.e. defame, fake,\nhate, offense, non-hostile). Various techniques are used to perform the\nclassification task, including SVM, CNN, BiLSTM, and CNN+BiLSTM with tf-idf and\nWord2Vec embedding techniques. Results indicate that SVM with tf-idf features\nachieved the highest 94.39% weighted $f_1$ score on the test set in task-A.\nLabel powerset SVM with n-gram features obtained the maximum coarse-grained and\nfine-grained $f_1$ score of 86.03% and 50.98% on the task-B test set\nrespectively.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper illustrates a detail description of the system and its results\nthat developed as a part of the participation at CONSTRAINT shared task in\nAAAI-2021. The shared task comprises two tasks: a) COVID19 fake news detection\nin English b) Hostile post detection in Hindi. Task-A is a binary\nclassification problem with fake and real class, while task-B is a multi-label\nmulti-class classification task with five hostile classes (i.e. defame, fake,\nhate, offense, non-hostile). Various techniques are used to perform the\nclassification task, including SVM, CNN, BiLSTM, and CNN+BiLSTM with tf-idf and\nWord2Vec embedding techniques. Results indicate that SVM with tf-idf features\nachieved the highest 94.39% weighted $f_1$ score on the test set in task-A.\nLabel powerset SVM with n-gram features obtained the maximum coarse-grained and\nfine-grained $f_1$ score of 86.03% and 50.98% on the task-B test set\nrespectively.'}, 'authors': [{'name': 'Omar Sharif'}, {'name': 'Eftekhar Hossain'}, {'name': 'Mohammed Moshiul Hoque'}], 'author_detail': {'name': 'Mohammed Moshiul Hoque'}, 'author': 'Mohammed Moshiul Hoque', 'arxiv_comment': 'Shared task description paper in CONSTRAINT workshop collocated with\n  AAAI-2021, 11 pages', 'links': [{'href': 'http://arxiv.org/abs/2101.03291v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03291v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
122,http://arxiv.org/abs/2101.02359v1,2021-01-07 04:01:13+00:00,2021-01-07 04:01:13+00:00,Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News Detection in English,"[arxiv.Result.Author('Xiangyang Li'), arxiv.Result.Author('Yu Xia'), arxiv.Result.Author('Xiang Long'), arxiv.Result.Author('Zheng Li'), arxiv.Result.Author('Sujian Li')]","In this paper, we describe our system for the AAAI 2021 shared task of
COVID-19 Fake News Detection in English, where we achieved the 3rd position
with the weighted F1 score of 0.9859 on the test set. Specifically, we proposed
an ensemble method of different pre-trained language models such as BERT,
Roberta, Ernie, etc. with various training strategies including
warm-up,learning rate schedule and k-fold cross-validation. We also conduct an
extensive analysis of the samples that are not correctly classified. The code
is available
at:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.","3rd solution of 'Constraint@AAAI2021 - COVID19 Fake News Detection in
  English'","First International Workshop, CONSTRAINT 2021 co-located with AAAI
  2021",,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2101.02359v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.02359v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.02359v1,"{'id': 'http://arxiv.org/abs/2101.02359v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.02359v1', 'updated': '2021-01-07T04:01:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=4, tm_min=1, tm_sec=13, tm_wday=3, tm_yday=7, tm_isdst=0), 'published': '2021-01-07T04:01:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=4, tm_min=1, tm_sec=13, tm_wday=3, tm_yday=7, tm_isdst=0), 'title': 'Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News\n  Detection in English', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News\n  Detection in English'}, 'summary': 'In this paper, we describe our system for the AAAI 2021 shared task of\nCOVID-19 Fake News Detection in English, where we achieved the 3rd position\nwith the weighted F1 score of 0.9859 on the test set. Specifically, we proposed\nan ensemble method of different pre-trained language models such as BERT,\nRoberta, Ernie, etc. with various training strategies including\nwarm-up,learning rate schedule and k-fold cross-validation. We also conduct an\nextensive analysis of the samples that are not correctly classified. The code\nis available\nat:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we describe our system for the AAAI 2021 shared task of\nCOVID-19 Fake News Detection in English, where we achieved the 3rd position\nwith the weighted F1 score of 0.9859 on the test set. Specifically, we proposed\nan ensemble method of different pre-trained language models such as BERT,\nRoberta, Ernie, etc. with various training strategies including\nwarm-up,learning rate schedule and k-fold cross-validation. We also conduct an\nextensive analysis of the samples that are not correctly classified. The code\nis available\nat:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.'}, 'authors': [{'name': 'Xiangyang Li'}, {'name': 'Yu Xia'}, {'name': 'Xiang Long'}, {'name': 'Zheng Li'}, {'name': 'Sujian Li'}], 'author_detail': {'name': 'Sujian Li'}, 'author': 'Sujian Li', 'arxiv_comment': ""3rd solution of 'Constraint@AAAI2021 - COVID19 Fake News Detection in\n  English'"", 'arxiv_journal_ref': 'First International Workshop, CONSTRAINT 2021 co-located with AAAI\n  2021', 'links': [{'href': 'http://arxiv.org/abs/2101.02359v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.02359v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
123,http://arxiv.org/abs/2101.00606v1,2021-01-03 11:12:23+00:00,2021-01-03 11:12:23+00:00,News Image Steganography: A Novel Architecture Facilitates the Fake News Identification,"[arxiv.Result.Author('Jizhe Zhou'), arxiv.Result.Author('Chi-Man Pun'), arxiv.Result.Author('Yu Tong')]","A larger portion of fake news quotes untampered images from other sources
with ulterior motives rather than conducting image forgery. Such elaborate
engraftments keep the inconsistency between images and text reports stealthy,
thereby, palm off the spurious for the genuine. This paper proposes an
architecture named News Image Steganography (NIS) to reveal the aforementioned
inconsistency through image steganography based on GAN. Extractive
summarization about a news image is generated based on its source texts, and a
learned steganographic algorithm encodes and decodes the summarization of the
image in a manner that approaches perceptual invisibility. Once an encoded
image is quoted, its source summarization can be decoded and further presented
as the ground truth to verify the quoting news. The pairwise encoder and
decoder endow images of the capability to carry along their imperceptible
summarization. Our NIS reveals the underlying inconsistency, thereby, according
to our experiments and investigations, contributes to the identification
accuracy of fake news that engrafts untampered images.",,,10.1109/VCIP49819.2020.9301846,cs.CV,"['cs.CV', 'cs.CR', 'cs.MM']","[arxiv.Result.Link('http://dx.doi.org/10.1109/VCIP49819.2020.9301846', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.00606v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.00606v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.00606v1,"{'id': 'http://arxiv.org/abs/2101.00606v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.00606v1', 'updated': '2021-01-03T11:12:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=3, tm_hour=11, tm_min=12, tm_sec=23, tm_wday=6, tm_yday=3, tm_isdst=0), 'published': '2021-01-03T11:12:23Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=3, tm_hour=11, tm_min=12, tm_sec=23, tm_wday=6, tm_yday=3, tm_isdst=0), 'title': 'News Image Steganography: A Novel Architecture Facilitates the Fake News\n  Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'News Image Steganography: A Novel Architecture Facilitates the Fake News\n  Identification'}, 'summary': 'A larger portion of fake news quotes untampered images from other sources\nwith ulterior motives rather than conducting image forgery. Such elaborate\nengraftments keep the inconsistency between images and text reports stealthy,\nthereby, palm off the spurious for the genuine. This paper proposes an\narchitecture named News Image Steganography (NIS) to reveal the aforementioned\ninconsistency through image steganography based on GAN. Extractive\nsummarization about a news image is generated based on its source texts, and a\nlearned steganographic algorithm encodes and decodes the summarization of the\nimage in a manner that approaches perceptual invisibility. Once an encoded\nimage is quoted, its source summarization can be decoded and further presented\nas the ground truth to verify the quoting news. The pairwise encoder and\ndecoder endow images of the capability to carry along their imperceptible\nsummarization. Our NIS reveals the underlying inconsistency, thereby, according\nto our experiments and investigations, contributes to the identification\naccuracy of fake news that engrafts untampered images.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A larger portion of fake news quotes untampered images from other sources\nwith ulterior motives rather than conducting image forgery. Such elaborate\nengraftments keep the inconsistency between images and text reports stealthy,\nthereby, palm off the spurious for the genuine. This paper proposes an\narchitecture named News Image Steganography (NIS) to reveal the aforementioned\ninconsistency through image steganography based on GAN. Extractive\nsummarization about a news image is generated based on its source texts, and a\nlearned steganographic algorithm encodes and decodes the summarization of the\nimage in a manner that approaches perceptual invisibility. Once an encoded\nimage is quoted, its source summarization can be decoded and further presented\nas the ground truth to verify the quoting news. The pairwise encoder and\ndecoder endow images of the capability to carry along their imperceptible\nsummarization. Our NIS reveals the underlying inconsistency, thereby, according\nto our experiments and investigations, contributes to the identification\naccuracy of fake news that engrafts untampered images.'}, 'authors': [{'name': 'Jizhe Zhou'}, {'name': 'Chi-Man Pun'}, {'name': 'Yu Tong'}], 'author_detail': {'name': 'Yu Tong'}, 'author': 'Yu Tong', 'arxiv_doi': '10.1109/VCIP49819.2020.9301846', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/VCIP49819.2020.9301846', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.00606v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.00606v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
124,http://arxiv.org/abs/2101.00180v3,2021-01-21 15:18:40+00:00,2021-01-01 06:49:27+00:00,Transformer based Automatic COVID-19 Fake News Detection System,"[arxiv.Result.Author('Sunil Gundapu'), arxiv.Result.Author('Radhika Mamidi')]","Recent rapid technological advancements in online social networks such as
Twitter have led to a great incline in spreading false information and fake
news. Misinformation is especially prevalent in the ongoing coronavirus disease
(COVID-19) pandemic, leading to individuals accepting bogus and potentially
deleterious claims and articles. Quick detection of fake news can reduce the
spread of panic and confusion among the public. For our analysis in this paper,
we report a methodology to analyze the reliability of information shared on
social media pertaining to the COVID-19 pandemic. Our best approach is based on
an ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting
fake news. This model was trained and evaluated in the context of the
ConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our
system obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.","First Workshop on Combating Online Hostile Posts in Regional
  Languages during Emergency Situation, 12 pages",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.00180v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.00180v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.00180v3,"{'id': 'http://arxiv.org/abs/2101.00180v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.00180v3', 'updated': '2021-01-21T15:18:40Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=21, tm_hour=15, tm_min=18, tm_sec=40, tm_wday=3, tm_yday=21, tm_isdst=0), 'published': '2021-01-01T06:49:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=1, tm_hour=6, tm_min=49, tm_sec=27, tm_wday=4, tm_yday=1, tm_isdst=0), 'title': 'Transformer based Automatic COVID-19 Fake News Detection System', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transformer based Automatic COVID-19 Fake News Detection System'}, 'summary': 'Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.'}, 'authors': [{'name': 'Sunil Gundapu'}, {'name': 'Radhika Mamidi'}], 'author_detail': {'name': 'Radhika Mamidi'}, 'author': 'Radhika Mamidi', 'arxiv_comment': 'First Workshop on Combating Online Hostile Posts in Regional\n  Languages during Emergency Situation, 12 pages', 'links': [{'href': 'http://arxiv.org/abs/2101.00180v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.00180v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
125,http://arxiv.org/abs/2101.01142v1,2020-12-28 13:07:42+00:00,2020-12-28 13:07:42+00:00,Advanced Machine Learning Techniques for Fake News (Online Disinformation) Detection: A Systematic Mapping Study,"[arxiv.Result.Author('Michal Choras'), arxiv.Result.Author('Konstantinos Demestichas'), arxiv.Result.Author('Agata Gielczyk'), arxiv.Result.Author('Alvaro Herrero'), arxiv.Result.Author('Pawel Ksieniewicz'), arxiv.Result.Author('Konstantina Remoundou'), arxiv.Result.Author('Daniel Urda'), arxiv.Result.Author('Michal Wozniak')]","Fake news has now grown into a big problem for societies and also a major
challenge for people fighting disinformation. This phenomenon plagues
democratic elections, reputations of individual persons or organizations, and
has negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US
or Brazil). Hence, developing effective tools to fight this phenomenon by
employing advanced Machine Learning (ML) methods poses a significant challenge.
The following paper displays the present body of knowledge on the application
of such intelligent tools in the fight against disinformation. It starts by
showing the historical perspective and the current role of fake news in the
information war. Proposed solutions based solely on the work of experts are
analysed and the most important directions of the application of intelligent
systems in the detection of misinformation sources are pointed out.
Additionally, the paper presents some useful resources (mainly datasets useful
when assessing ML solutions for fake news detection) and provides a short
overview of the most important R&D projects related to this subject. The main
purpose of this work is to analyse the current state of knowledge in detecting
fake news; on the one hand to show possible solutions, and on the other hand to
identify the main challenges and methodological gaps to motivate future
research.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.01142v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.01142v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.01142v1,"{'id': 'http://arxiv.org/abs/2101.01142v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.01142v1', 'updated': '2020-12-28T13:07:42Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=13, tm_min=7, tm_sec=42, tm_wday=0, tm_yday=363, tm_isdst=0), 'published': '2020-12-28T13:07:42Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=13, tm_min=7, tm_sec=42, tm_wday=0, tm_yday=363, tm_isdst=0), 'title': 'Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study'}, 'summary': 'Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.'}, 'authors': [{'name': 'Michal Choras'}, {'name': 'Konstantinos Demestichas'}, {'name': 'Agata Gielczyk'}, {'name': 'Alvaro Herrero'}, {'name': 'Pawel Ksieniewicz'}, {'name': 'Konstantina Remoundou'}, {'name': 'Daniel Urda'}, {'name': 'Michal Wozniak'}], 'author_detail': {'name': 'Michal Wozniak'}, 'author': 'Michal Wozniak', 'links': [{'href': 'http://arxiv.org/abs/2101.01142v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.01142v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
126,http://arxiv.org/abs/2012.12498v2,2021-02-21 11:38:57+00:00,2020-12-23 05:40:15+00:00,Fake News Data Collection and Classification: Iterative Query Selection for Opaque Search Engines with Pseudo Relevance Feedback,"[arxiv.Result.Author('Aviad Elyashar'), arxiv.Result.Author('Maor Reuben'), arxiv.Result.Author('Rami Puzis')]","Retrieving information from an online search engine, is the first and most
important step in many data mining tasks. Most of the search engines currently
available on the web, including all social media platforms, are black-boxes
(a.k.a opaque) supporting short keyword queries. In these settings, retrieving
all posts and comments discussing a particular news item automatically and at
large scales is a challenging task. In this paper, we propose a method for
generating short keyword queries given a prototype document. The proposed
iterative query selection algorithm (IQS) interacts with the opaque search
engine to iteratively improve the query. It is evaluated on the Twitter TREC
Microblog 2012 and TREC-COVID 2019 datasets showing superior performance
compared to state-of-the-art. IQS is applied to automatically collect a
large-scale fake news dataset of about 70K true and fake news items. The
dataset, publicly available for research, includes more than 22M accounts and
61M tweets in Twitter approved format. We demonstrate the usefulness of the
dataset for fake news detection task achieving state-of-the-art performance.",,,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.12498v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.12498v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.12498v2,"{'id': 'http://arxiv.org/abs/2012.12498v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.12498v2', 'updated': '2021-02-21T11:38:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=21, tm_hour=11, tm_min=38, tm_sec=57, tm_wday=6, tm_yday=52, tm_isdst=0), 'published': '2020-12-23T05:40:15Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=23, tm_hour=5, tm_min=40, tm_sec=15, tm_wday=2, tm_yday=358, tm_isdst=0), 'title': 'Fake News Data Collection and Classification: Iterative Query Selection\n  for Opaque Search Engines with Pseudo Relevance Feedback', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Data Collection and Classification: Iterative Query Selection\n  for Opaque Search Engines with Pseudo Relevance Feedback'}, 'summary': 'Retrieving information from an online search engine, is the first and most\nimportant step in many data mining tasks. Most of the search engines currently\navailable on the web, including all social media platforms, are black-boxes\n(a.k.a opaque) supporting short keyword queries. In these settings, retrieving\nall posts and comments discussing a particular news item automatically and at\nlarge scales is a challenging task. In this paper, we propose a method for\ngenerating short keyword queries given a prototype document. The proposed\niterative query selection algorithm (IQS) interacts with the opaque search\nengine to iteratively improve the query. It is evaluated on the Twitter TREC\nMicroblog 2012 and TREC-COVID 2019 datasets showing superior performance\ncompared to state-of-the-art. IQS is applied to automatically collect a\nlarge-scale fake news dataset of about 70K true and fake news items. The\ndataset, publicly available for research, includes more than 22M accounts and\n61M tweets in Twitter approved format. We demonstrate the usefulness of the\ndataset for fake news detection task achieving state-of-the-art performance.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Retrieving information from an online search engine, is the first and most\nimportant step in many data mining tasks. Most of the search engines currently\navailable on the web, including all social media platforms, are black-boxes\n(a.k.a opaque) supporting short keyword queries. In these settings, retrieving\nall posts and comments discussing a particular news item automatically and at\nlarge scales is a challenging task. In this paper, we propose a method for\ngenerating short keyword queries given a prototype document. The proposed\niterative query selection algorithm (IQS) interacts with the opaque search\nengine to iteratively improve the query. It is evaluated on the Twitter TREC\nMicroblog 2012 and TREC-COVID 2019 datasets showing superior performance\ncompared to state-of-the-art. IQS is applied to automatically collect a\nlarge-scale fake news dataset of about 70K true and fake news items. The\ndataset, publicly available for research, includes more than 22M accounts and\n61M tweets in Twitter approved format. We demonstrate the usefulness of the\ndataset for fake news detection task achieving state-of-the-art performance.'}, 'authors': [{'name': 'Aviad Elyashar'}, {'name': 'Maor Reuben'}, {'name': 'Rami Puzis'}], 'author_detail': {'name': 'Rami Puzis'}, 'author': 'Rami Puzis', 'links': [{'href': 'http://arxiv.org/abs/2012.12498v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.12498v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
127,http://arxiv.org/abs/2012.11967v3,2021-01-13 11:36:32+00:00,2020-12-22 12:43:12+00:00,g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning for COVID-19 Fake News Detection,"[arxiv.Result.Author('Anna Glazkova'), arxiv.Result.Author('Maksim Glazkov'), arxiv.Result.Author('Timofey Trifonov')]","The COVID-19 pandemic has had a huge impact on various areas of human life.
Hence, the coronavirus pandemic and its consequences are being actively
discussed on social media. However, not all social media posts are truthful.
Many of them spread fake news that cause panic among readers, misinform people
and thus exacerbate the effect of the pandemic. In this paper, we present our
results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in
English. In particular, we propose our approach using the transformer-based
ensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,
the ways of text preprocessing and adding extra data. As a result, our best
model achieved the weighted F1-score of 98.69 on the test set (the first place
in the leaderboard) of this shared task that attracted 166 submitted teams in
total.",The winning solution at the Constraint shared task (AAAI-2021),"Combating Online Hostile Posts in Regional Languages during
  Emergency Situation, 116-127, 2021. Springer, Cham",10.1007/978-3-030-73696-5_12,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', '68T50', 'I.2.7; I.7.m; H.3.3']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-73696-5_12', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.11967v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.11967v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.11967v3,"{'id': 'http://arxiv.org/abs/2012.11967v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.11967v3', 'updated': '2021-01-13T11:36:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=11, tm_min=36, tm_sec=32, tm_wday=2, tm_yday=13, tm_isdst=0), 'published': '2020-12-22T12:43:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=22, tm_hour=12, tm_min=43, tm_sec=12, tm_wday=1, tm_yday=357, tm_isdst=0), 'title': 'g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection'}, 'summary': 'The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.'}, 'authors': [{'name': 'Anna Glazkova'}, {'name': 'Maksim Glazkov'}, {'name': 'Timofey Trifonov'}], 'author_detail': {'name': 'Timofey Trifonov'}, 'author': 'Timofey Trifonov', 'arxiv_doi': '10.1007/978-3-030-73696-5_12', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-73696-5_12', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.11967v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.11967v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'The winning solution at the Constraint shared task (AAAI-2021)', 'arxiv_journal_ref': 'Combating Online Hostile Posts in Regional Languages during\n  Emergency Situation, 116-127, 2021. Springer, Cham', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.7.m; H.3.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
128,http://arxiv.org/abs/2012.11004v1,2020-12-20 19:35:25+00:00,2020-12-20 19:35:25+00:00,Fake news agenda in the era of COVID-19: Identifying trends through fact-checking content,"[arxiv.Result.Author('Wilson Ceron'), arxiv.Result.Author('Mathias-Felipe de-Lima-Santos'), arxiv.Result.Author('Marcos G. Quiles')]","The rise of social media has ignited an unprecedented circulation of false
information in our society. It is even more evident in times of crises, such as
the COVID-19 pandemic. Fact-checking efforts have expanded greatly and have
been touted as among the most promising solutions to fake news, especially in
times like these. Several studies have reported the development of
fact-checking organizations in Western societies, albeit little attention has
been given to the Global South. Here, to fill this gap, we introduce a novel
Markov-inspired computational method for identifying topics in tweets. In
contrast to other topic modeling approaches, our method clusters topics and
their current evolution in a predefined time window. Through these, we
collected data from Twitter accounts of two Brazilian fact-checking outlets and
presented the topics debunked by these initiatives in fortnights throughout the
pandemic. By comparing these organizations, we could identify similarities and
differences in what was shared by them. Our method resulted in an important
technique to cluster topics in a wide range of scenarios, including an
infodemic -- a period overabundance of the same information. In particular, the
data clearly revealed a complex intertwining between politics and the health
crisis during this period. We conclude by proposing a generic model which, in
our opinion, is suitable for topic modeling and an agenda for future research.",,"Online Social Networks and Media, 2020",10.1016/j.osnem.2020.100116,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.osnem.2020.100116', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.11004v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.11004v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.11004v1,"{'id': 'http://arxiv.org/abs/2012.11004v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.11004v1', 'updated': '2020-12-20T19:35:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=20, tm_hour=19, tm_min=35, tm_sec=25, tm_wday=6, tm_yday=355, tm_isdst=0), 'published': '2020-12-20T19:35:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=20, tm_hour=19, tm_min=35, tm_sec=25, tm_wday=6, tm_yday=355, tm_isdst=0), 'title': 'Fake news agenda in the era of COVID-19: Identifying trends through\n  fact-checking content', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news agenda in the era of COVID-19: Identifying trends through\n  fact-checking content'}, 'summary': 'The rise of social media has ignited an unprecedented circulation of false\ninformation in our society. It is even more evident in times of crises, such as\nthe COVID-19 pandemic. Fact-checking efforts have expanded greatly and have\nbeen touted as among the most promising solutions to fake news, especially in\ntimes like these. Several studies have reported the development of\nfact-checking organizations in Western societies, albeit little attention has\nbeen given to the Global South. Here, to fill this gap, we introduce a novel\nMarkov-inspired computational method for identifying topics in tweets. In\ncontrast to other topic modeling approaches, our method clusters topics and\ntheir current evolution in a predefined time window. Through these, we\ncollected data from Twitter accounts of two Brazilian fact-checking outlets and\npresented the topics debunked by these initiatives in fortnights throughout the\npandemic. By comparing these organizations, we could identify similarities and\ndifferences in what was shared by them. Our method resulted in an important\ntechnique to cluster topics in a wide range of scenarios, including an\ninfodemic -- a period overabundance of the same information. In particular, the\ndata clearly revealed a complex intertwining between politics and the health\ncrisis during this period. We conclude by proposing a generic model which, in\nour opinion, is suitable for topic modeling and an agenda for future research.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of social media has ignited an unprecedented circulation of false\ninformation in our society. It is even more evident in times of crises, such as\nthe COVID-19 pandemic. Fact-checking efforts have expanded greatly and have\nbeen touted as among the most promising solutions to fake news, especially in\ntimes like these. Several studies have reported the development of\nfact-checking organizations in Western societies, albeit little attention has\nbeen given to the Global South. Here, to fill this gap, we introduce a novel\nMarkov-inspired computational method for identifying topics in tweets. In\ncontrast to other topic modeling approaches, our method clusters topics and\ntheir current evolution in a predefined time window. Through these, we\ncollected data from Twitter accounts of two Brazilian fact-checking outlets and\npresented the topics debunked by these initiatives in fortnights throughout the\npandemic. By comparing these organizations, we could identify similarities and\ndifferences in what was shared by them. Our method resulted in an important\ntechnique to cluster topics in a wide range of scenarios, including an\ninfodemic -- a period overabundance of the same information. In particular, the\ndata clearly revealed a complex intertwining between politics and the health\ncrisis during this period. We conclude by proposing a generic model which, in\nour opinion, is suitable for topic modeling and an agenda for future research.'}, 'authors': [{'name': 'Wilson Ceron'}, {'name': 'Mathias-Felipe de-Lima-Santos'}, {'name': 'Marcos G. Quiles'}], 'author_detail': {'name': 'Marcos G. Quiles'}, 'author': 'Marcos G. Quiles', 'arxiv_doi': '10.1016/j.osnem.2020.100116', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.osnem.2020.100116', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.11004v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.11004v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Online Social Networks and Media, 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
129,http://arxiv.org/abs/2012.09118v2,2020-12-17 01:56:29+00:00,2020-12-16 18:01:04+00:00,Exploring Thematic Coherence in Fake News,"[arxiv.Result.Author('Martins Samuel Dogo'), arxiv.Result.Author('Deepak P'), arxiv.Result.Author('Anna Jurek-Loughrey')]","The spread of fake news remains a serious global issue; understanding and
curtailing it is paramount. One way of differentiating between deceptive and
truthful stories is by analyzing their coherence. This study explores the use
of topic models to analyze the coherence of cross-domain news shared online.
Experimental results on seven cross-domain datasets demonstrate that fake news
shows a greater thematic deviation between its opening sentences and its
remainder.","10 pages, 1 figure, to be published in Proceedings of the 8th
  International Workshop on News Recommendation and Analytics (INRA 2020)",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.09118v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.09118v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.09118v2,"{'id': 'http://arxiv.org/abs/2012.09118v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.09118v2', 'updated': '2020-12-17T01:56:29Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=17, tm_hour=1, tm_min=56, tm_sec=29, tm_wday=3, tm_yday=352, tm_isdst=0), 'published': '2020-12-16T18:01:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=16, tm_hour=18, tm_min=1, tm_sec=4, tm_wday=2, tm_yday=351, tm_isdst=0), 'title': 'Exploring Thematic Coherence in Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring Thematic Coherence in Fake News'}, 'summary': 'The spread of fake news remains a serious global issue; understanding and\ncurtailing it is paramount. One way of differentiating between deceptive and\ntruthful stories is by analyzing their coherence. This study explores the use\nof topic models to analyze the coherence of cross-domain news shared online.\nExperimental results on seven cross-domain datasets demonstrate that fake news\nshows a greater thematic deviation between its opening sentences and its\nremainder.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of fake news remains a serious global issue; understanding and\ncurtailing it is paramount. One way of differentiating between deceptive and\ntruthful stories is by analyzing their coherence. This study explores the use\nof topic models to analyze the coherence of cross-domain news shared online.\nExperimental results on seven cross-domain datasets demonstrate that fake news\nshows a greater thematic deviation between its opening sentences and its\nremainder.'}, 'authors': [{'name': 'Martins Samuel Dogo'}, {'name': 'Deepak P'}, {'name': 'Anna Jurek-Loughrey'}], 'author_detail': {'name': 'Anna Jurek-Loughrey'}, 'author': 'Anna Jurek-Loughrey', 'arxiv_comment': '10 pages, 1 figure, to be published in Proceedings of the 8th\n  International Workshop on News Recommendation and Analytics (INRA 2020)', 'links': [{'href': 'http://arxiv.org/abs/2012.09118v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.09118v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
130,http://arxiv.org/abs/2012.05491v2,2020-12-13 07:52:18+00:00,2020-12-10 07:31:07+00:00,An Event Correlation Filtering Method for Fake News Detection,"[arxiv.Result.Author('Hao Li'), arxiv.Result.Author('Huan Wang'), arxiv.Result.Author('Guanghua Liu')]","Nowadays, social network platforms have been the prime source for people to
experience news and events due to their capacities to spread information
rapidly, which inevitably provides a fertile ground for the dissemination of
fake news. Thus, it is significant to detect fake news otherwise it could cause
public misleading and panic. Existing deep learning models have achieved great
progress to tackle the problem of fake news detection. However, training an
effective deep learning model usually requires a large amount of labeled news,
while it is expensive and time-consuming to provide sufficient labeled news in
actual applications. To improve the detection performance of fake news, we take
advantage of the event correlations of news and propose an event correlation
filtering method (ECFM) for fake news detection, mainly consisting of the news
characterizer, the pseudo label annotator, the event credibility updater, and
the news entropy selector. The news characterizer is responsible for extracting
textual features from news, which cooperates with the pseudo label annotator to
assign pseudo labels for unlabeled news by fully exploiting the event
correlations of news. In addition, the event credibility updater employs
adaptive Kalman filter to weaken the credibility fluctuations of events. To
further improve the detection performance, the news entropy selector
automatically discovers high-quality samples from pseudo labeled news by
quantifying their news entropy. Finally, ECFM is proposed to integrate them to
detect fake news in an event correlation filtering manner. Extensive
experiments prove that the explainable introduction of the event correlations
of news is beneficial to improve the detection performance of fake news.","24 pages, 5 figures, 3 tables",,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.05491v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.05491v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.05491v2,"{'id': 'http://arxiv.org/abs/2012.05491v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.05491v2', 'updated': '2020-12-13T07:52:18Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=13, tm_hour=7, tm_min=52, tm_sec=18, tm_wday=6, tm_yday=348, tm_isdst=0), 'published': '2020-12-10T07:31:07Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=10, tm_hour=7, tm_min=31, tm_sec=7, tm_wday=3, tm_yday=345, tm_isdst=0), 'title': 'An Event Correlation Filtering Method for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Event Correlation Filtering Method for Fake News Detection'}, 'summary': 'Nowadays, social network platforms have been the prime source for people to\nexperience news and events due to their capacities to spread information\nrapidly, which inevitably provides a fertile ground for the dissemination of\nfake news. Thus, it is significant to detect fake news otherwise it could cause\npublic misleading and panic. Existing deep learning models have achieved great\nprogress to tackle the problem of fake news detection. However, training an\neffective deep learning model usually requires a large amount of labeled news,\nwhile it is expensive and time-consuming to provide sufficient labeled news in\nactual applications. To improve the detection performance of fake news, we take\nadvantage of the event correlations of news and propose an event correlation\nfiltering method (ECFM) for fake news detection, mainly consisting of the news\ncharacterizer, the pseudo label annotator, the event credibility updater, and\nthe news entropy selector. The news characterizer is responsible for extracting\ntextual features from news, which cooperates with the pseudo label annotator to\nassign pseudo labels for unlabeled news by fully exploiting the event\ncorrelations of news. In addition, the event credibility updater employs\nadaptive Kalman filter to weaken the credibility fluctuations of events. To\nfurther improve the detection performance, the news entropy selector\nautomatically discovers high-quality samples from pseudo labeled news by\nquantifying their news entropy. Finally, ECFM is proposed to integrate them to\ndetect fake news in an event correlation filtering manner. Extensive\nexperiments prove that the explainable introduction of the event correlations\nof news is beneficial to improve the detection performance of fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Nowadays, social network platforms have been the prime source for people to\nexperience news and events due to their capacities to spread information\nrapidly, which inevitably provides a fertile ground for the dissemination of\nfake news. Thus, it is significant to detect fake news otherwise it could cause\npublic misleading and panic. Existing deep learning models have achieved great\nprogress to tackle the problem of fake news detection. However, training an\neffective deep learning model usually requires a large amount of labeled news,\nwhile it is expensive and time-consuming to provide sufficient labeled news in\nactual applications. To improve the detection performance of fake news, we take\nadvantage of the event correlations of news and propose an event correlation\nfiltering method (ECFM) for fake news detection, mainly consisting of the news\ncharacterizer, the pseudo label annotator, the event credibility updater, and\nthe news entropy selector. The news characterizer is responsible for extracting\ntextual features from news, which cooperates with the pseudo label annotator to\nassign pseudo labels for unlabeled news by fully exploiting the event\ncorrelations of news. In addition, the event credibility updater employs\nadaptive Kalman filter to weaken the credibility fluctuations of events. To\nfurther improve the detection performance, the news entropy selector\nautomatically discovers high-quality samples from pseudo labeled news by\nquantifying their news entropy. Finally, ECFM is proposed to integrate them to\ndetect fake news in an event correlation filtering manner. Extensive\nexperiments prove that the explainable introduction of the event correlations\nof news is beneficial to improve the detection performance of fake news.'}, 'authors': [{'name': 'Hao Li'}, {'name': 'Huan Wang'}, {'name': 'Guanghua Liu'}], 'author_detail': {'name': 'Guanghua Liu'}, 'arxiv_affiliation': 'Department of Computer Science and Engineering, University at Buffalo, The State University of New York', 'author': 'Guanghua Liu', 'arxiv_comment': '24 pages, 5 figures, 3 tables', 'links': [{'href': 'http://arxiv.org/abs/2012.05491v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.05491v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
131,http://arxiv.org/abs/2012.04778v2,2020-12-13 04:56:25+00:00,2020-12-08 22:54:35+00:00,Fact-Enhanced Synthetic News Generation,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Yichuan Li'), arxiv.Result.Author('Kaize Ding'), arxiv.Result.Author('Huan Liu')]","The advanced text generation methods have witnessed great success in text
summarization, language translation, and synthetic news generation. However,
these techniques can be abused to generate disinformation and fake news. To
better understand the potential threats of synthetic news, we develop a new
generation method FactGen to generate high-quality news content. The existing
text generation methods either afford limited supplementary information or lose
consistency between the input and output which makes the synthetic news less
trustworthy. To address these issues, FactGen retrieves external facts to
enrich the output and reconstructs the input claim from the generated content
to improve the consistency among the input and the output. Experiment results
on real-world datasets show that the generated news contents of FactGen are
consistent and contain rich facts. We also discuss the possible defending
method to identify these synthetic news pieces if FactGen is used to generate
synthetic news.",AAAI 2021 Preprint Version,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.04778v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.04778v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.04778v2,"{'id': 'http://arxiv.org/abs/2012.04778v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.04778v2', 'updated': '2020-12-13T04:56:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=13, tm_hour=4, tm_min=56, tm_sec=25, tm_wday=6, tm_yday=348, tm_isdst=0), 'published': '2020-12-08T22:54:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=22, tm_min=54, tm_sec=35, tm_wday=1, tm_yday=343, tm_isdst=0), 'title': 'Fact-Enhanced Synthetic News Generation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact-Enhanced Synthetic News Generation'}, 'summary': 'The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Yichuan Li'}, {'name': 'Kaize Ding'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'AAAI 2021 Preprint Version', 'links': [{'href': 'http://arxiv.org/abs/2012.04778v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.04778v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
132,http://arxiv.org/abs/2012.04252v2,2021-03-09 14:30:33+00:00,2020-12-08 07:12:47+00:00,Increase of Low-Frequency Modes of User Dynamics in Online Social Networks During Overheating of Discussions,"[arxiv.Result.Author('Masaki Aida'), arxiv.Result.Author('Koichi Nagatani'), arxiv.Result.Author('Chisa Takano')]","User dynamics in online social networks have a significant impact on not only
the online community but also real-world activities. As examples, we can
mention explosive user dynamics triggered by social polarization, echo chamber
phenomena, fake news, etc. Explosive user dynamics are frequently called online
flaming. The wave equation-based model for online social networks (called the
oscillation model) is a theoretical model proposed to describe user dynamics in
online social networks. This model can be used to understand the relationship
between explosive user dynamics and the structure of social networks. However,
since the oscillation model was introduced as a purely theoretical model of
social networks, it is necessary to confirm whether the model describes real
phenomena correctly or not. In this paper, we first show a prediction from the
oscillation model; the low-frequency oscillation mode of user dynamics will be
dominant when the structure of online social networks changes so that user
activity is activated. To verify the predictions with actual data, we show
spectral analyses of both the log data of posts on an electronic bulletin board
site and the frequency data of word search from Google Trends. The results
support the predictions from the theoretical model.","14 pages, 23 figures, submitted to Physical Review Research",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2012.04252v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.04252v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.04252v2,"{'id': 'http://arxiv.org/abs/2012.04252v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.04252v2', 'updated': '2021-03-09T14:30:33Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=9, tm_hour=14, tm_min=30, tm_sec=33, tm_wday=1, tm_yday=68, tm_isdst=0), 'published': '2020-12-08T07:12:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=7, tm_min=12, tm_sec=47, tm_wday=1, tm_yday=343, tm_isdst=0), 'title': 'Increase of Low-Frequency Modes of User Dynamics in Online Social\n  Networks During Overheating of Discussions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Increase of Low-Frequency Modes of User Dynamics in Online Social\n  Networks During Overheating of Discussions'}, 'summary': 'User dynamics in online social networks have a significant impact on not only\nthe online community but also real-world activities. As examples, we can\nmention explosive user dynamics triggered by social polarization, echo chamber\nphenomena, fake news, etc. Explosive user dynamics are frequently called online\nflaming. The wave equation-based model for online social networks (called the\noscillation model) is a theoretical model proposed to describe user dynamics in\nonline social networks. This model can be used to understand the relationship\nbetween explosive user dynamics and the structure of social networks. However,\nsince the oscillation model was introduced as a purely theoretical model of\nsocial networks, it is necessary to confirm whether the model describes real\nphenomena correctly or not. In this paper, we first show a prediction from the\noscillation model; the low-frequency oscillation mode of user dynamics will be\ndominant when the structure of online social networks changes so that user\nactivity is activated. To verify the predictions with actual data, we show\nspectral analyses of both the log data of posts on an electronic bulletin board\nsite and the frequency data of word search from Google Trends. The results\nsupport the predictions from the theoretical model.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'User dynamics in online social networks have a significant impact on not only\nthe online community but also real-world activities. As examples, we can\nmention explosive user dynamics triggered by social polarization, echo chamber\nphenomena, fake news, etc. Explosive user dynamics are frequently called online\nflaming. The wave equation-based model for online social networks (called the\noscillation model) is a theoretical model proposed to describe user dynamics in\nonline social networks. This model can be used to understand the relationship\nbetween explosive user dynamics and the structure of social networks. However,\nsince the oscillation model was introduced as a purely theoretical model of\nsocial networks, it is necessary to confirm whether the model describes real\nphenomena correctly or not. In this paper, we first show a prediction from the\noscillation model; the low-frequency oscillation mode of user dynamics will be\ndominant when the structure of online social networks changes so that user\nactivity is activated. To verify the predictions with actual data, we show\nspectral analyses of both the log data of posts on an electronic bulletin board\nsite and the frequency data of word search from Google Trends. The results\nsupport the predictions from the theoretical model.'}, 'authors': [{'name': 'Masaki Aida'}, {'name': 'Koichi Nagatani'}, {'name': 'Chisa Takano'}], 'author_detail': {'name': 'Chisa Takano'}, 'author': 'Chisa Takano', 'arxiv_comment': '14 pages, 23 figures, submitted to Physical Review Research', 'links': [{'href': 'http://arxiv.org/abs/2012.04252v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.04252v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
133,http://arxiv.org/abs/2012.04233v2,2020-12-14 01:27:46+00:00,2020-12-08 05:53:33+00:00,"Early Detection of Fake News by Utilizing the Credibility of News, Publishers, and Users Based on Weakly Supervised Learning","[arxiv.Result.Author('Chunyuan Yuan'), arxiv.Result.Author('Qianwen Ma'), arxiv.Result.Author('Wei Zhou'), arxiv.Result.Author('Jizhong Han'), arxiv.Result.Author('Songlin Hu')]","The dissemination of fake news significantly affects personal reputation and
public trust. Recently, fake news detection has attracted tremendous attention,
and previous studies mainly focused on finding clues from news content or
diffusion path. However, the required features of previous models are often
unavailable or insufficient in early detection scenarios, resulting in poor
performance. Thus, early fake news detection remains a tough challenge.
Intuitively, the news from trusted and authoritative sources or shared by many
users with a good reputation is more reliable than other news. Using the
credibility of publishers and users as prior weakly supervised information, we
can quickly locate fake news in massive news and detect them in the early
stages of dissemination.
  In this paper, we propose a novel Structure-aware Multi-head Attention
Network (SMAN), which combines the news content, publishing, and reposting
relations of publishers and users, to jointly optimize the fake news detection
and credibility prediction tasks. In this way, we can explicitly exploit the
credibility of publishers and users for early fake news detection. We conducted
experiments on three real-world datasets, and the results show that SMAN can
detect fake news in 4 hours with an accuracy of over 91%, which is much faster
than the state-of-the-art models.",Accepted as a long paper at COLING 2020,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.04233v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.04233v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.04233v2,"{'id': 'http://arxiv.org/abs/2012.04233v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.04233v2', 'updated': '2020-12-14T01:27:46Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=14, tm_hour=1, tm_min=27, tm_sec=46, tm_wday=0, tm_yday=349, tm_isdst=0), 'published': '2020-12-08T05:53:33Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=5, tm_min=53, tm_sec=33, tm_wday=1, tm_yday=343, tm_isdst=0), 'title': 'Early Detection of Fake News by Utilizing the Credibility of News,\n  Publishers, and Users Based on Weakly Supervised Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Early Detection of Fake News by Utilizing the Credibility of News,\n  Publishers, and Users Based on Weakly Supervised Learning'}, 'summary': 'The dissemination of fake news significantly affects personal reputation and\npublic trust. Recently, fake news detection has attracted tremendous attention,\nand previous studies mainly focused on finding clues from news content or\ndiffusion path. However, the required features of previous models are often\nunavailable or insufficient in early detection scenarios, resulting in poor\nperformance. Thus, early fake news detection remains a tough challenge.\nIntuitively, the news from trusted and authoritative sources or shared by many\nusers with a good reputation is more reliable than other news. Using the\ncredibility of publishers and users as prior weakly supervised information, we\ncan quickly locate fake news in massive news and detect them in the early\nstages of dissemination.\n  In this paper, we propose a novel Structure-aware Multi-head Attention\nNetwork (SMAN), which combines the news content, publishing, and reposting\nrelations of publishers and users, to jointly optimize the fake news detection\nand credibility prediction tasks. In this way, we can explicitly exploit the\ncredibility of publishers and users for early fake news detection. We conducted\nexperiments on three real-world datasets, and the results show that SMAN can\ndetect fake news in 4 hours with an accuracy of over 91%, which is much faster\nthan the state-of-the-art models.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The dissemination of fake news significantly affects personal reputation and\npublic trust. Recently, fake news detection has attracted tremendous attention,\nand previous studies mainly focused on finding clues from news content or\ndiffusion path. However, the required features of previous models are often\nunavailable or insufficient in early detection scenarios, resulting in poor\nperformance. Thus, early fake news detection remains a tough challenge.\nIntuitively, the news from trusted and authoritative sources or shared by many\nusers with a good reputation is more reliable than other news. Using the\ncredibility of publishers and users as prior weakly supervised information, we\ncan quickly locate fake news in massive news and detect them in the early\nstages of dissemination.\n  In this paper, we propose a novel Structure-aware Multi-head Attention\nNetwork (SMAN), which combines the news content, publishing, and reposting\nrelations of publishers and users, to jointly optimize the fake news detection\nand credibility prediction tasks. In this way, we can explicitly exploit the\ncredibility of publishers and users for early fake news detection. We conducted\nexperiments on three real-world datasets, and the results show that SMAN can\ndetect fake news in 4 hours with an accuracy of over 91%, which is much faster\nthan the state-of-the-art models.'}, 'authors': [{'name': 'Chunyuan Yuan'}, {'name': 'Qianwen Ma'}, {'name': 'Wei Zhou'}, {'name': 'Jizhong Han'}, {'name': 'Songlin Hu'}], 'author_detail': {'name': 'Songlin Hu'}, 'author': 'Songlin Hu', 'arxiv_comment': 'Accepted as a long paper at COLING 2020', 'links': [{'href': 'http://arxiv.org/abs/2012.04233v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.04233v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
134,http://arxiv.org/abs/2012.02613v1,2020-12-04 14:17:46+00:00,2020-12-04 14:17:46+00:00,FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity Annotation,"[arxiv.Result.Author('Krister Lindén'), arxiv.Result.Author('Tommi Jauhiainen'), arxiv.Result.Author('Sam Hardwick')]","Sentiment analysis and opinion mining is an important task with obvious
application areas in social media, e.g. when indicating hate speech and fake
news. In our survey of previous work, we note that there is no large-scale
social media data set with sentiment polarity annotations for Finnish. This
publications aims to remedy this shortcoming by introducing a 27,000 sentence
data set annotated independently with sentiment polarity by three native
annotators. We had the same three annotators for the whole data set, which
provides a unique opportunity for further studies of annotator behaviour over
time. We analyse their inter-annotator agreement and provide two baselines to
validate the usefulness of the data set.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.02613v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.02613v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.02613v1,"{'id': 'http://arxiv.org/abs/2012.02613v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.02613v1', 'updated': '2020-12-04T14:17:46Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=4, tm_hour=14, tm_min=17, tm_sec=46, tm_wday=4, tm_yday=339, tm_isdst=0), 'published': '2020-12-04T14:17:46Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=4, tm_hour=14, tm_min=17, tm_sec=46, tm_wday=4, tm_yday=339, tm_isdst=0), 'title': 'FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity\n  Annotation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity\n  Annotation'}, 'summary': 'Sentiment analysis and opinion mining is an important task with obvious\napplication areas in social media, e.g. when indicating hate speech and fake\nnews. In our survey of previous work, we note that there is no large-scale\nsocial media data set with sentiment polarity annotations for Finnish. This\npublications aims to remedy this shortcoming by introducing a 27,000 sentence\ndata set annotated independently with sentiment polarity by three native\nannotators. We had the same three annotators for the whole data set, which\nprovides a unique opportunity for further studies of annotator behaviour over\ntime. We analyse their inter-annotator agreement and provide two baselines to\nvalidate the usefulness of the data set.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sentiment analysis and opinion mining is an important task with obvious\napplication areas in social media, e.g. when indicating hate speech and fake\nnews. In our survey of previous work, we note that there is no large-scale\nsocial media data set with sentiment polarity annotations for Finnish. This\npublications aims to remedy this shortcoming by introducing a 27,000 sentence\ndata set annotated independently with sentiment polarity by three native\nannotators. We had the same three annotators for the whole data set, which\nprovides a unique opportunity for further studies of annotator behaviour over\ntime. We analyse their inter-annotator agreement and provide two baselines to\nvalidate the usefulness of the data set.'}, 'authors': [{'name': 'Krister Lindén'}, {'name': 'Tommi Jauhiainen'}, {'name': 'Sam Hardwick'}], 'author_detail': {'name': 'Sam Hardwick'}, 'author': 'Sam Hardwick', 'links': [{'href': 'http://arxiv.org/abs/2012.02613v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.02613v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
135,http://arxiv.org/abs/2012.01876v1,2020-12-03 12:45:29+00:00,2020-12-03 12:45:29+00:00,Optimizing sensors placement in complex networks for localization of hidden signal source: A review,"[arxiv.Result.Author('Robert Paluch'), arxiv.Result.Author('Łukasz G. Gajewski'), arxiv.Result.Author('Janusz A. Hołyst'), arxiv.Result.Author('Boleslaw K. Szymanski')]","As the world becomes more and more interconnected, our everyday objects
become part of the Internet of Things, and our lives get more and more mirrored
in virtual reality, where every piece of~information, including misinformation,
fake news and malware, can spread very fast practically anonymously. To
suppress such uncontrolled spread, efficient computer systems and algorithms
capable to~track down such malicious information spread have to be developed.
Currently, the most effective methods for source localization are based on
sensors which provide the times at which they detect the~spread. We investigate
the problem of the optimal placement of such sensors in complex networks and
propose a new graph measure, called Collective Betweenness, which we compare
against four other metrics. Extensive numerical tests are performed on
different types of complex networks over the wide ranges of densities of
sensors and stochasticities of signal. In these tests, we discovered clear
difference in comparative performance of the investigated optimal placement
methods between real or scale-free synthetic networks versus narrow degree
distribution networks. The former have a clear region for any given method's
dominance in contrast to the latter where the performance maps are less
homogeneous. We find that while choosing the best method is very network and
spread dependent, there are two methods that consistently stand out. High
Variance Observers seem to do very well for spread with low stochasticity
whereas Collective Betwenness, introduced in this paper, thrives when the
spread is highly unpredictable.","28 pages, 18 figures, 11 tables","Future Generation Computer Systems, Volume 112, November 2020,
  Pages 1070-1092",10.1016/j.future.2020.06.023,cs.SI,"['cs.SI', 'cs.CY', 'physics.data-an']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.future.2020.06.023', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.01876v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.01876v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.01876v1,"{'id': 'http://arxiv.org/abs/2012.01876v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.01876v1', 'updated': '2020-12-03T12:45:29Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=3, tm_hour=12, tm_min=45, tm_sec=29, tm_wday=3, tm_yday=338, tm_isdst=0), 'published': '2020-12-03T12:45:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=3, tm_hour=12, tm_min=45, tm_sec=29, tm_wday=3, tm_yday=338, tm_isdst=0), 'title': 'Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review'}, 'summary': ""As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.""}, 'authors': [{'name': 'Robert Paluch'}, {'name': 'Łukasz G. Gajewski'}, {'name': 'Janusz A. Hołyst'}, {'name': 'Boleslaw K. Szymanski'}], 'author_detail': {'name': 'Boleslaw K. Szymanski'}, 'author': 'Boleslaw K. Szymanski', 'arxiv_doi': '10.1016/j.future.2020.06.023', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.future.2020.06.023', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.01876v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.01876v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '28 pages, 18 figures, 11 tables', 'arxiv_journal_ref': 'Future Generation Computer Systems, Volume 112, November 2020,\n  Pages 1070-1092', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
136,http://arxiv.org/abs/2012.07517v1,2020-11-30 16:41:04+00:00,2020-11-30 16:41:04+00:00,Fake News Detection in Social Media using Graph Neural Networks and NLP Techniques: A COVID-19 Use-case,"[arxiv.Result.Author('Abdullah Hamid'), arxiv.Result.Author('Nasrullah Shiekh'), arxiv.Result.Author('Naina Said'), arxiv.Result.Author('Kashif Ahmad'), arxiv.Result.Author('Asma Gul'), arxiv.Result.Author('Laiq Hassan'), arxiv.Result.Author('Ala Al-Fuqaha')]","The paper presents our solutions for the MediaEval 2020 task namely FakeNews:
Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task
aims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect
misinformation spreaders. The task is composed of two sub-tasks namely (i)
text-based, and (ii) structure-based fake news detection. For the first task,
we propose six different solutions relying on Bag of Words (BoW) and BERT
embedding. Three of the methods aim at binary classification task by
differentiating in 5G conspiracy and the rest of the COVID-19 related tweets
while the rest of them treat the task as ternary classification problem. In the
ternary classification task, our BoW and BERT based methods obtained an
F1-score of .606% and .566% on the development set, respectively. On the binary
classification, the BoW and BERT based solutions obtained an average F1-score
of .666% and .693%, respectively. On the other hand, for structure-based fake
news detection, we rely on Graph Neural Networks (GNNs) achieving an average
ROC of .95% on the development set.",3 pages,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.07517v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.07517v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.07517v1,"{'id': 'http://arxiv.org/abs/2012.07517v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.07517v1', 'updated': '2020-11-30T16:41:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=30, tm_hour=16, tm_min=41, tm_sec=4, tm_wday=0, tm_yday=335, tm_isdst=0), 'published': '2020-11-30T16:41:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=30, tm_hour=16, tm_min=41, tm_sec=4, tm_wday=0, tm_yday=335, tm_isdst=0), 'title': 'Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case'}, 'summary': 'The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.'}, 'authors': [{'name': 'Abdullah Hamid'}, {'name': 'Nasrullah Shiekh'}, {'name': 'Naina Said'}, {'name': 'Kashif Ahmad'}, {'name': 'Asma Gul'}, {'name': 'Laiq Hassan'}, {'name': 'Ala Al-Fuqaha'}], 'author_detail': {'name': 'Ala Al-Fuqaha'}, 'author': 'Ala Al-Fuqaha', 'arxiv_comment': '3 pages', 'links': [{'href': 'http://arxiv.org/abs/2012.07517v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.07517v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
137,http://arxiv.org/abs/2011.14146v2,2021-02-15 02:26:25+00:00,2020-11-28 15:30:14+00:00,Towards Combating Pandemic-related Misinformation in Social Media,[arxiv.Result.Author('Isa Inuwa-Dutse')],"Conventional preventive measures during pandemic include social distancing
and lockdown. Such measures in the time of social media brought about a new set
of challenges - vulnerability to the toxic impact of online misinformation is
high. A case in point is the prevailing COVID-19; as the virus propagates, so
does the associated misinformation and fake news about it leading to infodemic.
Since the outbreak, there has been a surge of studies investigating various
aspects of the pandemic. Of interest to this chapter include studies centring
on datasets from online social media platforms where the bulk of the public
discourse happen. Consequently, the main goal is to support the fight against
negative infodemic by (1) contributing a diverse set of curated relevant
datasets (2) recommending relevant areas to study using the datasets (3)
discussion on how relevant datasets, strategies and state-of-the-art IT tools
can be leveraged in managing the pandemic.","13 pages, 5 figures",,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2011.14146v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.14146v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.14146v2,"{'id': 'http://arxiv.org/abs/2011.14146v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.14146v2', 'updated': '2021-02-15T02:26:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=26, tm_sec=25, tm_wday=0, tm_yday=46, tm_isdst=0), 'published': '2020-11-28T15:30:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=28, tm_hour=15, tm_min=30, tm_sec=14, tm_wday=5, tm_yday=333, tm_isdst=0), 'title': 'Towards Combating Pandemic-related Misinformation in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Combating Pandemic-related Misinformation in Social Media'}, 'summary': 'Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.'}, 'authors': [{'name': 'Isa Inuwa-Dutse'}], 'author_detail': {'name': 'Isa Inuwa-Dutse'}, 'author': 'Isa Inuwa-Dutse', 'arxiv_comment': '13 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2011.14146v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.14146v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
138,http://arxiv.org/abs/2011.13327v1,2020-11-26 14:52:01+00:00,2020-11-26 14:52:01+00:00,"Analysing Social Media Network Data with R: Semi-Automated Screening of Users, Comments and Communication Patterns",[arxiv.Result.Author('Dennis Klinkhammer')],"Communication on social media platforms is not only culturally and
politically relevant, it is also increasingly widespread across societies.
Users not only communicate via social media platforms, but also search
specifically for information, disseminate it or post information themselves.
However, fake news, hate speech and even radicalizing elements are part of this
modern form of communication: Sometimes with far-reaching effects on
individuals and societies. A basic understanding of these mechanisms and
communication patterns could help to counteract negative forms of
communication, e.g. bullying among children or extreme political points of
view. To this end, a method will be presented in order to break down the
underlying communication patterns, to trace individual users and to inspect
their comments and range on social media platforms; Or to contrast them later
on via qualitative research. This approeach can identify particularly active
users with an accuracy of 100 percent, if the framing social networks as well
as the topics are taken into account. However, methodological as well as
counteracting approaches must be even more dynamic and flexible to ensure
sensitivity and specifity regarding users who spread hate speech, fake news and
radicalizing elements.","14 pages, 2 figures",,,cs.SI,"['cs.SI', 'cs.CV', 'stat.AP', 'D.1.5; D.3.0; J.4; K.4.1']","[arxiv.Result.Link('http://arxiv.org/abs/2011.13327v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.13327v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.13327v1,"{'id': 'http://arxiv.org/abs/2011.13327v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.13327v1', 'updated': '2020-11-26T14:52:01Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=26, tm_hour=14, tm_min=52, tm_sec=1, tm_wday=3, tm_yday=331, tm_isdst=0), 'published': '2020-11-26T14:52:01Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=26, tm_hour=14, tm_min=52, tm_sec=1, tm_wday=3, tm_yday=331, tm_isdst=0), 'title': 'Analysing Social Media Network Data with R: Semi-Automated Screening of\n  Users, Comments and Communication Patterns', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysing Social Media Network Data with R: Semi-Automated Screening of\n  Users, Comments and Communication Patterns'}, 'summary': 'Communication on social media platforms is not only culturally and\npolitically relevant, it is also increasingly widespread across societies.\nUsers not only communicate via social media platforms, but also search\nspecifically for information, disseminate it or post information themselves.\nHowever, fake news, hate speech and even radicalizing elements are part of this\nmodern form of communication: Sometimes with far-reaching effects on\nindividuals and societies. A basic understanding of these mechanisms and\ncommunication patterns could help to counteract negative forms of\ncommunication, e.g. bullying among children or extreme political points of\nview. To this end, a method will be presented in order to break down the\nunderlying communication patterns, to trace individual users and to inspect\ntheir comments and range on social media platforms; Or to contrast them later\non via qualitative research. This approeach can identify particularly active\nusers with an accuracy of 100 percent, if the framing social networks as well\nas the topics are taken into account. However, methodological as well as\ncounteracting approaches must be even more dynamic and flexible to ensure\nsensitivity and specifity regarding users who spread hate speech, fake news and\nradicalizing elements.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Communication on social media platforms is not only culturally and\npolitically relevant, it is also increasingly widespread across societies.\nUsers not only communicate via social media platforms, but also search\nspecifically for information, disseminate it or post information themselves.\nHowever, fake news, hate speech and even radicalizing elements are part of this\nmodern form of communication: Sometimes with far-reaching effects on\nindividuals and societies. A basic understanding of these mechanisms and\ncommunication patterns could help to counteract negative forms of\ncommunication, e.g. bullying among children or extreme political points of\nview. To this end, a method will be presented in order to break down the\nunderlying communication patterns, to trace individual users and to inspect\ntheir comments and range on social media platforms; Or to contrast them later\non via qualitative research. This approeach can identify particularly active\nusers with an accuracy of 100 percent, if the framing social networks as well\nas the topics are taken into account. However, methodological as well as\ncounteracting approaches must be even more dynamic and flexible to ensure\nsensitivity and specifity regarding users who spread hate speech, fake news and\nradicalizing elements.'}, 'authors': [{'name': 'Dennis Klinkhammer'}], 'author_detail': {'name': 'Dennis Klinkhammer'}, 'author': 'Dennis Klinkhammer', 'arxiv_comment': '14 pages, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/2011.13327v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.13327v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'D.1.5; D.3.0; J.4; K.4.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
139,http://arxiv.org/abs/2011.13253v1,2020-11-26 11:50:45+00:00,2020-11-26 11:50:45+00:00,Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking,"[arxiv.Result.Author('Rutvik Vijjali'), arxiv.Result.Author('Prathyush Potluri'), arxiv.Result.Author('Siddharth Kumar'), arxiv.Result.Author('Sundeep Teki')]","The rapid advancement of technology in online communication via social media
platforms has led to a prolific rise in the spread of misinformation and fake
news. Fake news is especially rampant in the current COVID-19 pandemic, leading
to people believing in false and potentially harmful claims and stories.
Detecting fake news quickly can alleviate the spread of panic, chaos and
potential health hazards. We developed a two stage automated pipeline for
COVID-19 fake news detection using state of the art machine learning models for
natural language processing. The first model leverages a novel fact checking
algorithm that retrieves the most relevant facts concerning user claims about
particular COVID-19 claims. The second model verifies the level of truth in the
claim by computing the textual entailment between the claim and the true facts
retrieved from a manually curated COVID-19 dataset. The dataset is based on a
publicly available knowledge source consisting of more than 5000 COVID-19 false
claims and verified explanations, a subset of which was internally annotated
and cross-validated to train and evaluate our models. We evaluate a series of
models based on classical text-based features to more contextual Transformer
based models and observe that a model pipeline based on BERT and ALBERT for the
two stages respectively yields the best results.",,,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2011.13253v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.13253v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.13253v1,"{'id': 'http://arxiv.org/abs/2011.13253v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.13253v1', 'updated': '2020-11-26T11:50:45Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=26, tm_hour=11, tm_min=50, tm_sec=45, tm_wday=3, tm_yday=331, tm_isdst=0), 'published': '2020-11-26T11:50:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=26, tm_hour=11, tm_min=50, tm_sec=45, tm_wday=3, tm_yday=331, tm_isdst=0), 'title': 'Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking'}, 'summary': 'The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.'}, 'authors': [{'name': 'Rutvik Vijjali'}, {'name': 'Prathyush Potluri'}, {'name': 'Siddharth Kumar'}, {'name': 'Sundeep Teki'}], 'author_detail': {'name': 'Sundeep Teki'}, 'author': 'Sundeep Teki', 'links': [{'href': 'http://arxiv.org/abs/2011.13253v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.13253v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
140,http://arxiv.org/abs/2011.11286v1,2020-11-23 09:01:28+00:00,2020-11-23 09:01:28+00:00,MEG: Multi-Evidence GNN for Multimodal Semantic Forensics,"[arxiv.Result.Author('Ekraam Sabir'), arxiv.Result.Author('Ayush Jaiswal'), arxiv.Result.Author('Wael AbdAlmageed'), arxiv.Result.Author('Prem Natarajan')]","Fake news often involves semantic manipulations across modalities such as
image, text, location etc and requires the development of multimodal semantic
forensics for its detection. Recent research has centered the problem around
images, calling it image repurposing -- where a digitally unmanipulated image
is semantically misrepresented by means of its accompanying multimodal metadata
such as captions, location, etc. The image and metadata together comprise a
multimedia package. The problem setup requires algorithms to perform multimodal
semantic forensics to authenticate a query multimedia package using a reference
dataset of potentially related packages as evidences. Existing methods are
limited to using a single evidence (retrieved package), which ignores potential
performance improvement from the use of multiple evidences. In this work, we
introduce a novel graph neural network based model for multimodal semantic
forensics, which effectively utilizes multiple retrieved packages as evidences
and is scalable with the number of evidences. We compare the scalability and
performance of our model against existing methods. Experimental results show
that the proposed model outperforms existing state-of-the-art algorithms with
an error reduction of up to 25%.",To be published at ICPR 2020,,,cs.MM,"['cs.MM', 'cs.AI', 'cs.CV']","[arxiv.Result.Link('http://arxiv.org/abs/2011.11286v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.11286v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.11286v1,"{'id': 'http://arxiv.org/abs/2011.11286v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.11286v1', 'updated': '2020-11-23T09:01:28Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=23, tm_hour=9, tm_min=1, tm_sec=28, tm_wday=0, tm_yday=328, tm_isdst=0), 'published': '2020-11-23T09:01:28Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=23, tm_hour=9, tm_min=1, tm_sec=28, tm_wday=0, tm_yday=328, tm_isdst=0), 'title': 'MEG: Multi-Evidence GNN for Multimodal Semantic Forensics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MEG: Multi-Evidence GNN for Multimodal Semantic Forensics'}, 'summary': 'Fake news often involves semantic manipulations across modalities such as\nimage, text, location etc and requires the development of multimodal semantic\nforensics for its detection. Recent research has centered the problem around\nimages, calling it image repurposing -- where a digitally unmanipulated image\nis semantically misrepresented by means of its accompanying multimodal metadata\nsuch as captions, location, etc. The image and metadata together comprise a\nmultimedia package. The problem setup requires algorithms to perform multimodal\nsemantic forensics to authenticate a query multimedia package using a reference\ndataset of potentially related packages as evidences. Existing methods are\nlimited to using a single evidence (retrieved package), which ignores potential\nperformance improvement from the use of multiple evidences. In this work, we\nintroduce a novel graph neural network based model for multimodal semantic\nforensics, which effectively utilizes multiple retrieved packages as evidences\nand is scalable with the number of evidences. We compare the scalability and\nperformance of our model against existing methods. Experimental results show\nthat the proposed model outperforms existing state-of-the-art algorithms with\nan error reduction of up to 25%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news often involves semantic manipulations across modalities such as\nimage, text, location etc and requires the development of multimodal semantic\nforensics for its detection. Recent research has centered the problem around\nimages, calling it image repurposing -- where a digitally unmanipulated image\nis semantically misrepresented by means of its accompanying multimodal metadata\nsuch as captions, location, etc. The image and metadata together comprise a\nmultimedia package. The problem setup requires algorithms to perform multimodal\nsemantic forensics to authenticate a query multimedia package using a reference\ndataset of potentially related packages as evidences. Existing methods are\nlimited to using a single evidence (retrieved package), which ignores potential\nperformance improvement from the use of multiple evidences. In this work, we\nintroduce a novel graph neural network based model for multimodal semantic\nforensics, which effectively utilizes multiple retrieved packages as evidences\nand is scalable with the number of evidences. We compare the scalability and\nperformance of our model against existing methods. Experimental results show\nthat the proposed model outperforms existing state-of-the-art algorithms with\nan error reduction of up to 25%.'}, 'authors': [{'name': 'Ekraam Sabir'}, {'name': 'Ayush Jaiswal'}, {'name': 'Wael AbdAlmageed'}, {'name': 'Prem Natarajan'}], 'author_detail': {'name': 'Prem Natarajan'}, 'author': 'Prem Natarajan', 'arxiv_comment': 'To be published at ICPR 2020', 'links': [{'href': 'http://arxiv.org/abs/2011.11286v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.11286v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
141,http://arxiv.org/abs/2011.10817v1,2020-11-21 16:26:54+00:00,2020-11-21 16:26:54+00:00,Detecting Fake News Spreaders in Social Networks using Inductive Representation Learning,"[arxiv.Result.Author('Bhavtosh Rath'), arxiv.Result.Author('Aadesh Salecha'), arxiv.Result.Author('Jaideep Srivastava')]","An important aspect of preventing fake news dissemination is to proactively
detect the likelihood of its spreading. Research in the domain of fake news
spreader detection has not been explored much from a network analysis
perspective. In this paper, we propose a graph neural network based approach to
identify nodes that are likely to become spreaders of false information. Using
the community health assessment model and interpersonal trust we propose an
inductive representation learning framework to predict nodes of
densely-connected community structures that are most likely to spread fake
news, thus making the entire community vulnerable to the infection. Using
topology and interaction based trust properties of nodes in real-world Twitter
networks, we are able to predict false information spreaders with an accuracy
of over 90%.","Accepted to IEEE/ACM International Conference on Advances in Social
  Networks Analysis and Mining (ASONAM, 2020)",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.10817v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.10817v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.10817v1,"{'id': 'http://arxiv.org/abs/2011.10817v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.10817v1', 'updated': '2020-11-21T16:26:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=21, tm_hour=16, tm_min=26, tm_sec=54, tm_wday=5, tm_yday=326, tm_isdst=0), 'published': '2020-11-21T16:26:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=21, tm_hour=16, tm_min=26, tm_sec=54, tm_wday=5, tm_yday=326, tm_isdst=0), 'title': 'Detecting Fake News Spreaders in Social Networks using Inductive\n  Representation Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Fake News Spreaders in Social Networks using Inductive\n  Representation Learning'}, 'summary': 'An important aspect of preventing fake news dissemination is to proactively\ndetect the likelihood of its spreading. Research in the domain of fake news\nspreader detection has not been explored much from a network analysis\nperspective. In this paper, we propose a graph neural network based approach to\nidentify nodes that are likely to become spreaders of false information. Using\nthe community health assessment model and interpersonal trust we propose an\ninductive representation learning framework to predict nodes of\ndensely-connected community structures that are most likely to spread fake\nnews, thus making the entire community vulnerable to the infection. Using\ntopology and interaction based trust properties of nodes in real-world Twitter\nnetworks, we are able to predict false information spreaders with an accuracy\nof over 90%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An important aspect of preventing fake news dissemination is to proactively\ndetect the likelihood of its spreading. Research in the domain of fake news\nspreader detection has not been explored much from a network analysis\nperspective. In this paper, we propose a graph neural network based approach to\nidentify nodes that are likely to become spreaders of false information. Using\nthe community health assessment model and interpersonal trust we propose an\ninductive representation learning framework to predict nodes of\ndensely-connected community structures that are most likely to spread fake\nnews, thus making the entire community vulnerable to the infection. Using\ntopology and interaction based trust properties of nodes in real-world Twitter\nnetworks, we are able to predict false information spreaders with an accuracy\nof over 90%.'}, 'authors': [{'name': 'Bhavtosh Rath'}, {'name': 'Aadesh Salecha'}, {'name': 'Jaideep Srivastava'}], 'author_detail': {'name': 'Jaideep Srivastava'}, 'author': 'Jaideep Srivastava', 'arxiv_comment': 'Accepted to IEEE/ACM International Conference on Advances in Social\n  Networks Analysis and Mining (ASONAM, 2020)', 'links': [{'href': 'http://arxiv.org/abs/2011.10817v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.10817v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
142,http://arxiv.org/abs/2011.07389v1,2020-11-14 21:14:17+00:00,2020-11-14 21:14:17+00:00,Words are the Window to the Soul: Language-based User Representations for Fake News Detection,"[arxiv.Result.Author('Marco Del Tredici'), arxiv.Result.Author('Raquel Fernández')]","Cognitive and social traits of individuals are reflected in language use.
Moreover, individuals who are prone to spread fake news online often share
common traits. Building on these ideas, we introduce a model that creates
representations of individuals on social media based only on the language they
produce, and use them to detect fake news. We show that language-based user
representations are beneficial for this task. We also present an extended
analysis of the language of fake news spreaders, showing that its main features
are mostly domain independent and consistent across two English datasets.
Finally, we exploit the relation between language use and connections in the
social graph to assess the presence of the Echo Chamber effect in our data.","9 pages, accepted at COLING 2020",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.07389v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.07389v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.07389v1,"{'id': 'http://arxiv.org/abs/2011.07389v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.07389v1', 'updated': '2020-11-14T21:14:17Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=14, tm_hour=21, tm_min=14, tm_sec=17, tm_wday=5, tm_yday=319, tm_isdst=0), 'published': '2020-11-14T21:14:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=14, tm_hour=21, tm_min=14, tm_sec=17, tm_wday=5, tm_yday=319, tm_isdst=0), 'title': 'Words are the Window to the Soul: Language-based User Representations\n  for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Words are the Window to the Soul: Language-based User Representations\n  for Fake News Detection'}, 'summary': 'Cognitive and social traits of individuals are reflected in language use.\nMoreover, individuals who are prone to spread fake news online often share\ncommon traits. Building on these ideas, we introduce a model that creates\nrepresentations of individuals on social media based only on the language they\nproduce, and use them to detect fake news. We show that language-based user\nrepresentations are beneficial for this task. We also present an extended\nanalysis of the language of fake news spreaders, showing that its main features\nare mostly domain independent and consistent across two English datasets.\nFinally, we exploit the relation between language use and connections in the\nsocial graph to assess the presence of the Echo Chamber effect in our data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cognitive and social traits of individuals are reflected in language use.\nMoreover, individuals who are prone to spread fake news online often share\ncommon traits. Building on these ideas, we introduce a model that creates\nrepresentations of individuals on social media based only on the language they\nproduce, and use them to detect fake news. We show that language-based user\nrepresentations are beneficial for this task. We also present an extended\nanalysis of the language of fake news spreaders, showing that its main features\nare mostly domain independent and consistent across two English datasets.\nFinally, we exploit the relation between language use and connections in the\nsocial graph to assess the presence of the Echo Chamber effect in our data.'}, 'authors': [{'name': 'Marco Del Tredici'}, {'name': 'Raquel Fernández'}], 'author_detail': {'name': 'Raquel Fernández'}, 'author': 'Raquel Fernández', 'arxiv_comment': '9 pages, accepted at COLING 2020', 'links': [{'href': 'http://arxiv.org/abs/2011.07389v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.07389v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
143,http://arxiv.org/abs/2011.04857v1,2020-11-10 02:11:21+00:00,2020-11-10 02:11:21+00:00,Competitive Influence Propagation and Fake News Mitigation in the Presence of Strong User Bias,"[arxiv.Result.Author('Akrati Saxena'), arxiv.Result.Author('Harsh Saxena'), arxiv.Result.Author('Ralucca Gera')]","Due to the extensive role of social networks in social media, it is easy for
people to share the news, and it spreads faster than ever before. These
platforms also have been exploited to share the rumor or fake information,
which is a threat to society. One method to reduce the impact of fake
information is making people aware of the correct information based on hard
proof. In this work, first, we propose a propagation model called Competitive
Independent Cascade Model with users' Bias (CICMB) that considers the presence
of strong user bias towards different opinions, believes, or political parties.
We further propose a method, called $k-TruthScore$, to identify an optimal set
of truth campaigners from a given set of prospective truth campaigners to
minimize the influence of rumor spreaders on the network. We compare
$k-TruthScore$ with state of the art methods, and we measure their performances
as the percentage of the saved nodes (nodes that would have believed in the
fake news in the absence of the truth campaigners). We present these results on
a few real-world networks, and the results show that $k-TruthScore$ method
outperforms baseline methods.",Accepted in CSoNet 2020,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.04857v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.04857v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.04857v1,"{'id': 'http://arxiv.org/abs/2011.04857v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.04857v1', 'updated': '2020-11-10T02:11:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=2, tm_min=11, tm_sec=21, tm_wday=1, tm_yday=315, tm_isdst=0), 'published': '2020-11-10T02:11:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=2, tm_min=11, tm_sec=21, tm_wday=1, tm_yday=315, tm_isdst=0), 'title': 'Competitive Influence Propagation and Fake News Mitigation in the\n  Presence of Strong User Bias', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Competitive Influence Propagation and Fake News Mitigation in the\n  Presence of Strong User Bias'}, 'summary': ""Due to the extensive role of social networks in social media, it is easy for\npeople to share the news, and it spreads faster than ever before. These\nplatforms also have been exploited to share the rumor or fake information,\nwhich is a threat to society. One method to reduce the impact of fake\ninformation is making people aware of the correct information based on hard\nproof. In this work, first, we propose a propagation model called Competitive\nIndependent Cascade Model with users' Bias (CICMB) that considers the presence\nof strong user bias towards different opinions, believes, or political parties.\nWe further propose a method, called $k-TruthScore$, to identify an optimal set\nof truth campaigners from a given set of prospective truth campaigners to\nminimize the influence of rumor spreaders on the network. We compare\n$k-TruthScore$ with state of the art methods, and we measure their performances\nas the percentage of the saved nodes (nodes that would have believed in the\nfake news in the absence of the truth campaigners). We present these results on\na few real-world networks, and the results show that $k-TruthScore$ method\noutperforms baseline methods."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Due to the extensive role of social networks in social media, it is easy for\npeople to share the news, and it spreads faster than ever before. These\nplatforms also have been exploited to share the rumor or fake information,\nwhich is a threat to society. One method to reduce the impact of fake\ninformation is making people aware of the correct information based on hard\nproof. In this work, first, we propose a propagation model called Competitive\nIndependent Cascade Model with users' Bias (CICMB) that considers the presence\nof strong user bias towards different opinions, believes, or political parties.\nWe further propose a method, called $k-TruthScore$, to identify an optimal set\nof truth campaigners from a given set of prospective truth campaigners to\nminimize the influence of rumor spreaders on the network. We compare\n$k-TruthScore$ with state of the art methods, and we measure their performances\nas the percentage of the saved nodes (nodes that would have believed in the\nfake news in the absence of the truth campaigners). We present these results on\na few real-world networks, and the results show that $k-TruthScore$ method\noutperforms baseline methods.""}, 'authors': [{'name': 'Akrati Saxena'}, {'name': 'Harsh Saxena'}, {'name': 'Ralucca Gera'}], 'author_detail': {'name': 'Ralucca Gera'}, 'author': 'Ralucca Gera', 'arxiv_comment': 'Accepted in CSoNet 2020', 'links': [{'href': 'http://arxiv.org/abs/2011.04857v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.04857v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
144,http://arxiv.org/abs/2011.04088v2,2020-11-23 06:04:23+00:00,2020-11-08 21:42:03+00:00,MM-COVID: A Multilingual and Multimodal Data Repository for Combating COVID-19 Disinformation,"[arxiv.Result.Author('Yichuan Li'), arxiv.Result.Author('Bohan Jiang'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Huan Liu')]","The COVID-19 epidemic is considered as the global health crisis of the whole
society and the greatest challenge mankind faced since World War Two.
Unfortunately, the fake news about COVID-19 is spreading as fast as the virus
itself. The incorrect health measurements, anxiety, and hate speeches will have
bad consequences on people's physical health, as well as their mental health in
the whole world. To help better combat the COVID-19 fake news, we propose a new
fake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19
Fake News Data Repository). This dataset provides the multilingual fake news
and the relevant social context. We collect 3981 pieces of fake news content
and 7192 trustworthy information from English, Spanish, Portuguese, Hindi,
French and Italian, 6 different languages. We present a detailed and
exploratory analysis of MM-COVID from different perspectives and demonstrate
the utility of MM-COVID in several potential applications of COVID-19 fake news
study on multilingual and social media.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2011.04088v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.04088v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.04088v2,"{'id': 'http://arxiv.org/abs/2011.04088v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.04088v2', 'updated': '2020-11-23T06:04:23Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=23, tm_hour=6, tm_min=4, tm_sec=23, tm_wday=0, tm_yday=328, tm_isdst=0), 'published': '2020-11-08T21:42:03Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=8, tm_hour=21, tm_min=42, tm_sec=3, tm_wday=6, tm_yday=313, tm_isdst=0), 'title': 'MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation'}, 'summary': ""The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media.""}, 'authors': [{'name': 'Yichuan Li'}, {'name': 'Bohan Jiang'}, {'name': 'Kai Shu'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'links': [{'href': 'http://arxiv.org/abs/2011.04088v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.04088v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
145,http://arxiv.org/abs/2011.03588v1,2020-11-06 20:33:12+00:00,2020-11-06 20:33:12+00:00,Hostility Detection Dataset in Hindi,"[arxiv.Result.Author('Mohit Bhardwaj'), arxiv.Result.Author('Md Shad Akhtar'), arxiv.Result.Author('Asif Ekbal'), arxiv.Result.Author('Amitava Das'), arxiv.Result.Author('Tanmoy Chakraborty')]","In this paper, we present a novel hostility detection dataset in Hindi
language. We collect and manually annotate ~8200 online posts. The annotated
dataset covers four hostility dimensions: fake news, hate speech, offensive,
and defamation posts, along with a non-hostile label. The hostile posts are
also considered for multi-label tags due to a significant overlap among the
hostile classes. We release this dataset as part of the CONSTRAINT-2021 shared
task on hostile post detection.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.03588v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.03588v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.03588v1,"{'id': 'http://arxiv.org/abs/2011.03588v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.03588v1', 'updated': '2020-11-06T20:33:12Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=6, tm_hour=20, tm_min=33, tm_sec=12, tm_wday=4, tm_yday=311, tm_isdst=0), 'published': '2020-11-06T20:33:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=6, tm_hour=20, tm_min=33, tm_sec=12, tm_wday=4, tm_yday=311, tm_isdst=0), 'title': 'Hostility Detection Dataset in Hindi', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hostility Detection Dataset in Hindi'}, 'summary': 'In this paper, we present a novel hostility detection dataset in Hindi\nlanguage. We collect and manually annotate ~8200 online posts. The annotated\ndataset covers four hostility dimensions: fake news, hate speech, offensive,\nand defamation posts, along with a non-hostile label. The hostile posts are\nalso considered for multi-label tags due to a significant overlap among the\nhostile classes. We release this dataset as part of the CONSTRAINT-2021 shared\ntask on hostile post detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we present a novel hostility detection dataset in Hindi\nlanguage. We collect and manually annotate ~8200 online posts. The annotated\ndataset covers four hostility dimensions: fake news, hate speech, offensive,\nand defamation posts, along with a non-hostile label. The hostile posts are\nalso considered for multi-label tags due to a significant overlap among the\nhostile classes. We release this dataset as part of the CONSTRAINT-2021 shared\ntask on hostile post detection.'}, 'authors': [{'name': 'Mohit Bhardwaj'}, {'name': 'Md Shad Akhtar'}, {'name': 'Asif Ekbal'}, {'name': 'Amitava Das'}, {'name': 'Tanmoy Chakraborty'}], 'author_detail': {'name': 'Tanmoy Chakraborty'}, 'author': 'Tanmoy Chakraborty', 'links': [{'href': 'http://arxiv.org/abs/2011.03588v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.03588v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
146,http://arxiv.org/abs/2011.03327v4,2021-05-26 15:38:55+00:00,2020-11-06 13:09:37+00:00,Fighting an Infodemic: COVID-19 Fake News Dataset,"[arxiv.Result.Author('Parth Patwa'), arxiv.Result.Author('Shivam Sharma'), arxiv.Result.Author('Srinivas Pykl'), arxiv.Result.Author('Vineeth Guptha'), arxiv.Result.Author('Gitanjali Kumari'), arxiv.Result.Author('Md Shad Akhtar'), arxiv.Result.Author('Asif Ekbal'), arxiv.Result.Author('Amitava Das'), arxiv.Result.Author('Tanmoy Chakraborty')]","Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news
and rumors are rampant on social media. Believing in rumors can cause
significant harm. This is further exacerbated at the time of a pandemic. To
tackle this, we curate and release a manually annotated dataset of 10,700
social media posts and articles of real and fake news on COVID-19. We benchmark
the annotated dataset with four machine learning baselines - Decision Tree,
Logistic Regression, Gradient Boost, and Support Vector Machine (SVM). We
obtain the best performance of 93.46% F1-score with SVM. The data and code is
available at: https://github.com/parthpatwa/covid19-fake-news-dectection","Published at CONSTRAINT-2021, Collocated with AAAI-2021",,10.1007/978-3-030-73696-5_3,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-73696-5_3', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2011.03327v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.03327v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.03327v4,"{'id': 'http://arxiv.org/abs/2011.03327v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.03327v4', 'updated': '2021-05-26T15:38:55Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=26, tm_hour=15, tm_min=38, tm_sec=55, tm_wday=2, tm_yday=146, tm_isdst=0), 'published': '2020-11-06T13:09:37Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=6, tm_hour=13, tm_min=9, tm_sec=37, tm_wday=4, tm_yday=311, tm_isdst=0), 'title': 'Fighting an Infodemic: COVID-19 Fake News Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting an Infodemic: COVID-19 Fake News Dataset'}, 'summary': ""Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news\nand rumors are rampant on social media. Believing in rumors can cause\nsignificant harm. This is further exacerbated at the time of a pandemic. To\ntackle this, we curate and release a manually annotated dataset of 10,700\nsocial media posts and articles of real and fake news on COVID-19. We benchmark\nthe annotated dataset with four machine learning baselines - Decision Tree,\nLogistic Regression, Gradient Boost, and Support Vector Machine (SVM). We\nobtain the best performance of 93.46% F1-score with SVM. The data and code is\navailable at: https://github.com/parthpatwa/covid19-fake-news-dectection"", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news\nand rumors are rampant on social media. Believing in rumors can cause\nsignificant harm. This is further exacerbated at the time of a pandemic. To\ntackle this, we curate and release a manually annotated dataset of 10,700\nsocial media posts and articles of real and fake news on COVID-19. We benchmark\nthe annotated dataset with four machine learning baselines - Decision Tree,\nLogistic Regression, Gradient Boost, and Support Vector Machine (SVM). We\nobtain the best performance of 93.46% F1-score with SVM. The data and code is\navailable at: https://github.com/parthpatwa/covid19-fake-news-dectection""}, 'authors': [{'name': 'Parth Patwa'}, {'name': 'Shivam Sharma'}, {'name': 'Srinivas Pykl'}, {'name': 'Vineeth Guptha'}, {'name': 'Gitanjali Kumari'}, {'name': 'Md Shad Akhtar'}, {'name': 'Asif Ekbal'}, {'name': 'Amitava Das'}, {'name': 'Tanmoy Chakraborty'}], 'author_detail': {'name': 'Tanmoy Chakraborty'}, 'author': 'Tanmoy Chakraborty', 'arxiv_doi': '10.1007/978-3-030-73696-5_3', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-73696-5_3', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2011.03327v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.03327v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published at CONSTRAINT-2021, Collocated with AAAI-2021', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
147,http://arxiv.org/abs/2011.03092v1,2020-11-05 20:50:22+00:00,2020-11-05 20:50:22+00:00,Machine Generation and Detection of Arabic Manipulated and Fake News,"[arxiv.Result.Author('El Moatez Billah Nagoudi'), arxiv.Result.Author('AbdelRahim Elmadany'), arxiv.Result.Author('Muhammad Abdul-Mageed'), arxiv.Result.Author('Tariq Alhindi'), arxiv.Result.Author('Hasan Cavusoglu')]","Fake news and deceptive machine-generated text are serious problems
threatening modern societies, including in the Arab world. This motivates work
on detecting false and manipulated stories online. However, a bottleneck for
this research is lack of sufficient data to train detection models. We present
a novel method for automatically generating Arabic manipulated (and potentially
fake) news stories. Our method is simple and only depends on availability of
true stories, which are abundant online, and a part of speech tagger (POS). To
facilitate future work, we dispense with both of these requirements altogether
by providing AraNews, a novel and large POS-tagged news dataset that can be
used off-the-shelf. Using stories generated based on AraNews, we carry out a
human annotation study that casts light on the effects of machine manipulation
on text veracity. The study also measures human ability to detect Arabic
machine manipulated text generated by our method. Finally, we develop the first
models for detecting manipulated Arabic news and achieve state-of-the-art
results on Arabic fake news detection (macro F1=70.06). Our models and data are
publicly available.","10 pages, accepted in The Fifth Arabic Natural Language Processing
  Workshop (WANLP 2020)",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2011.03092v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.03092v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.03092v1,"{'id': 'http://arxiv.org/abs/2011.03092v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.03092v1', 'updated': '2020-11-05T20:50:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=5, tm_hour=20, tm_min=50, tm_sec=22, tm_wday=3, tm_yday=310, tm_isdst=0), 'published': '2020-11-05T20:50:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=5, tm_hour=20, tm_min=50, tm_sec=22, tm_wday=3, tm_yday=310, tm_isdst=0), 'title': 'Machine Generation and Detection of Arabic Manipulated and Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Machine Generation and Detection of Arabic Manipulated and Fake News'}, 'summary': 'Fake news and deceptive machine-generated text are serious problems\nthreatening modern societies, including in the Arab world. This motivates work\non detecting false and manipulated stories online. However, a bottleneck for\nthis research is lack of sufficient data to train detection models. We present\na novel method for automatically generating Arabic manipulated (and potentially\nfake) news stories. Our method is simple and only depends on availability of\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\nfacilitate future work, we dispense with both of these requirements altogether\nby providing AraNews, a novel and large POS-tagged news dataset that can be\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\nhuman annotation study that casts light on the effects of machine manipulation\non text veracity. The study also measures human ability to detect Arabic\nmachine manipulated text generated by our method. Finally, we develop the first\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\npublicly available.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and deceptive machine-generated text are serious problems\nthreatening modern societies, including in the Arab world. This motivates work\non detecting false and manipulated stories online. However, a bottleneck for\nthis research is lack of sufficient data to train detection models. We present\na novel method for automatically generating Arabic manipulated (and potentially\nfake) news stories. Our method is simple and only depends on availability of\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\nfacilitate future work, we dispense with both of these requirements altogether\nby providing AraNews, a novel and large POS-tagged news dataset that can be\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\nhuman annotation study that casts light on the effects of machine manipulation\non text veracity. The study also measures human ability to detect Arabic\nmachine manipulated text generated by our method. Finally, we develop the first\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\npublicly available.'}, 'authors': [{'name': 'El Moatez Billah Nagoudi'}, {'name': 'AbdelRahim Elmadany'}, {'name': 'Muhammad Abdul-Mageed'}, {'name': 'Tariq Alhindi'}, {'name': 'Hasan Cavusoglu'}], 'author_detail': {'name': 'Hasan Cavusoglu'}, 'author': 'Hasan Cavusoglu', 'arxiv_comment': '10 pages, accepted in The Fifth Arabic Natural Language Processing\n  Workshop (WANLP 2020)', 'links': [{'href': 'http://arxiv.org/abs/2011.03092v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.03092v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
148,http://arxiv.org/abs/2011.01579v2,2021-01-29 12:10:26+00:00,2020-11-03 09:09:51+00:00,Fake News Detection through Graph Comment Advanced Learning,"[arxiv.Result.Author('Hao Liao'), arxiv.Result.Author('Qixin Liu'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Xing xie')]","Disinformation has long been regarded as a severe social problem, where fake
news is one of the most representative issues. What is worse, today's highly
developed social media makes fake news widely spread at incredible speed,
bringing in substantial harm to various aspects of human life. Yet, the
popularity of social media also provides opportunities to better detect fake
news. Unlike conventional means which merely focus on either content or user
comments, effective collaboration of heterogeneous social media information,
including content and context factors of news, users' comments and the
engagement of social media with users, will hopefully give rise to better
detection of fake news.
  Motivated by the above observations, a novel detection framework, namely
graph comment-user advanced learning framework (GCAL) is proposed in this
paper. User-comment information is crucial but not well studied in fake news
detection. Thus, we model user-comment context through network representation
learning based on heterogeneous graph neural network. We conduct experiments on
two real-world datasets, which demonstrate that the proposed joint model
outperforms 8 state-of-the-art baseline methods for fake news detection (at
least 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method
is also explainable.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.01579v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.01579v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.01579v2,"{'id': 'http://arxiv.org/abs/2011.01579v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.01579v2', 'updated': '2021-01-29T12:10:26Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=29, tm_hour=12, tm_min=10, tm_sec=26, tm_wday=4, tm_yday=29, tm_isdst=0), 'published': '2020-11-03T09:09:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=9, tm_min=9, tm_sec=51, tm_wday=1, tm_yday=308, tm_isdst=0), 'title': 'Fake News Detection through Graph Comment Advanced Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection through Graph Comment Advanced Learning'}, 'summary': ""Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable.""}, 'authors': [{'name': 'Hao Liao'}, {'name': 'Qixin Liu'}, {'name': 'Kai Shu'}, {'name': 'Xing xie'}], 'author_detail': {'name': 'Xing xie'}, 'author': 'Xing xie', 'links': [{'href': 'http://arxiv.org/abs/2011.01579v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.01579v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
149,http://arxiv.org/abs/2011.01523v1,2020-11-03 07:31:46+00:00,2020-11-03 07:31:46+00:00,Model of Trust Management for Digital Industry Services. Towards E-Commerce 4.0,"[arxiv.Result.Author('Wolfgang Bauer'), arxiv.Result.Author('Natalia Kryvinska'), arxiv.Result.Author('Jürgen Dorn')]","The progressive digitalization is changing the way businesses work and
interact. Concepts like Internet of Things, Cloud Computing, Industry 4.0,
Service 4.0, Smart Production or Smart Cities are based on systems that are
linked to the Internet. The online access to the provided data creates
potential to optimize processes and cost reductions, but also exposes it to a
risk for an inappropriate use. Trust management systems are necessary in terms
of data security, but also to assure the trustworthiness of data that is
distributed. Fake news in social media is an example for problems with online
data that is not trustable. Security and trustworthiness of data are major
concerns today. The speed in digitalization makes it even a greater challenge
for future research. This article introduces therefore a model of online trust
content usable to compute the trust of an online service advertisement. It
contributes to standardize business service descriptions necessary to realize
visions of E-commerce 4.0, because it is the basis for the development of AI
systems that are able to match an service request to a service advertisement.
It is necessary for building trust enhancing architectures in B2B e-commerce.
To do so, we conducted case studies, analysed websites, developed a prototype
system and verified it by conducting expert interviews.","12 pages, 16 figures",,,cs.SI,"['cs.SI', 'cs.NI', 'E.m']","[arxiv.Result.Link('http://arxiv.org/abs/2011.01523v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.01523v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.01523v1,"{'id': 'http://arxiv.org/abs/2011.01523v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.01523v1', 'updated': '2020-11-03T07:31:46Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=7, tm_min=31, tm_sec=46, tm_wday=1, tm_yday=308, tm_isdst=0), 'published': '2020-11-03T07:31:46Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=7, tm_min=31, tm_sec=46, tm_wday=1, tm_yday=308, tm_isdst=0), 'title': 'Model of Trust Management for Digital Industry Services. Towards\n  E-Commerce 4.0', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Model of Trust Management for Digital Industry Services. Towards\n  E-Commerce 4.0'}, 'summary': 'The progressive digitalization is changing the way businesses work and\ninteract. Concepts like Internet of Things, Cloud Computing, Industry 4.0,\nService 4.0, Smart Production or Smart Cities are based on systems that are\nlinked to the Internet. The online access to the provided data creates\npotential to optimize processes and cost reductions, but also exposes it to a\nrisk for an inappropriate use. Trust management systems are necessary in terms\nof data security, but also to assure the trustworthiness of data that is\ndistributed. Fake news in social media is an example for problems with online\ndata that is not trustable. Security and trustworthiness of data are major\nconcerns today. The speed in digitalization makes it even a greater challenge\nfor future research. This article introduces therefore a model of online trust\ncontent usable to compute the trust of an online service advertisement. It\ncontributes to standardize business service descriptions necessary to realize\nvisions of E-commerce 4.0, because it is the basis for the development of AI\nsystems that are able to match an service request to a service advertisement.\nIt is necessary for building trust enhancing architectures in B2B e-commerce.\nTo do so, we conducted case studies, analysed websites, developed a prototype\nsystem and verified it by conducting expert interviews.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The progressive digitalization is changing the way businesses work and\ninteract. Concepts like Internet of Things, Cloud Computing, Industry 4.0,\nService 4.0, Smart Production or Smart Cities are based on systems that are\nlinked to the Internet. The online access to the provided data creates\npotential to optimize processes and cost reductions, but also exposes it to a\nrisk for an inappropriate use. Trust management systems are necessary in terms\nof data security, but also to assure the trustworthiness of data that is\ndistributed. Fake news in social media is an example for problems with online\ndata that is not trustable. Security and trustworthiness of data are major\nconcerns today. The speed in digitalization makes it even a greater challenge\nfor future research. This article introduces therefore a model of online trust\ncontent usable to compute the trust of an online service advertisement. It\ncontributes to standardize business service descriptions necessary to realize\nvisions of E-commerce 4.0, because it is the basis for the development of AI\nsystems that are able to match an service request to a service advertisement.\nIt is necessary for building trust enhancing architectures in B2B e-commerce.\nTo do so, we conducted case studies, analysed websites, developed a prototype\nsystem and verified it by conducting expert interviews.'}, 'authors': [{'name': 'Wolfgang Bauer'}, {'name': 'Natalia Kryvinska'}, {'name': 'Jürgen Dorn'}], 'author_detail': {'name': 'Jürgen Dorn'}, 'arxiv_affiliation': 'Technical University in Vienna, Institute for Information Systems Engineering', 'author': 'Jürgen Dorn', 'arxiv_comment': '12 pages, 16 figures', 'links': [{'href': 'http://arxiv.org/abs/2011.01523v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.01523v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'E.m', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
150,http://arxiv.org/abs/2011.01314v1,2020-11-02 20:59:26+00:00,2020-11-02 20:59:26+00:00,Automatic Detection of Machine Generated Text: A Critical Survey,"[arxiv.Result.Author('Ganesh Jawahar'), arxiv.Result.Author('Muhammad Abdul-Mageed'), arxiv.Result.Author('Laks V. S. Lakshmanan')]","Text generative models (TGMs) excel in producing text that matches the style
of human language reasonably well. Such TGMs can be misused by adversaries,
e.g., by automatically generating fake news and fake product reviews that can
look authentic and fool humans. Detectors that can distinguish text generated
by TGM from human written text play a vital role in mitigating such misuse of
TGMs. Recently, there has been a flurry of works from both natural language
processing (NLP) and machine learning (ML) communities to build accurate
detectors for English. Despite the importance of this problem, there is
currently no work that surveys this fast-growing literature and introduces
newcomers to important research challenges. In this work, we fill this void by
providing a critical survey and review of this literature to facilitate a
comprehensive understanding of this problem. We conduct an in-depth error
analysis of the state-of-the-art detector and discuss research directions to
guide future work in this exciting area.","The 28th International Conference on Computational Linguistics
  (COLING), 2020",,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2011.01314v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.01314v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.01314v1,"{'id': 'http://arxiv.org/abs/2011.01314v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.01314v1', 'updated': '2020-11-02T20:59:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=2, tm_hour=20, tm_min=59, tm_sec=26, tm_wday=0, tm_yday=307, tm_isdst=0), 'published': '2020-11-02T20:59:26Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=2, tm_hour=20, tm_min=59, tm_sec=26, tm_wday=0, tm_yday=307, tm_isdst=0), 'title': 'Automatic Detection of Machine Generated Text: A Critical Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic Detection of Machine Generated Text: A Critical Survey'}, 'summary': 'Text generative models (TGMs) excel in producing text that matches the style\nof human language reasonably well. Such TGMs can be misused by adversaries,\ne.g., by automatically generating fake news and fake product reviews that can\nlook authentic and fool humans. Detectors that can distinguish text generated\nby TGM from human written text play a vital role in mitigating such misuse of\nTGMs. Recently, there has been a flurry of works from both natural language\nprocessing (NLP) and machine learning (ML) communities to build accurate\ndetectors for English. Despite the importance of this problem, there is\ncurrently no work that surveys this fast-growing literature and introduces\nnewcomers to important research challenges. In this work, we fill this void by\nproviding a critical survey and review of this literature to facilitate a\ncomprehensive understanding of this problem. We conduct an in-depth error\nanalysis of the state-of-the-art detector and discuss research directions to\nguide future work in this exciting area.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Text generative models (TGMs) excel in producing text that matches the style\nof human language reasonably well. Such TGMs can be misused by adversaries,\ne.g., by automatically generating fake news and fake product reviews that can\nlook authentic and fool humans. Detectors that can distinguish text generated\nby TGM from human written text play a vital role in mitigating such misuse of\nTGMs. Recently, there has been a flurry of works from both natural language\nprocessing (NLP) and machine learning (ML) communities to build accurate\ndetectors for English. Despite the importance of this problem, there is\ncurrently no work that surveys this fast-growing literature and introduces\nnewcomers to important research challenges. In this work, we fill this void by\nproviding a critical survey and review of this literature to facilitate a\ncomprehensive understanding of this problem. We conduct an in-depth error\nanalysis of the state-of-the-art detector and discuss research directions to\nguide future work in this exciting area.'}, 'authors': [{'name': 'Ganesh Jawahar'}, {'name': 'Muhammad Abdul-Mageed'}, {'name': 'Laks V. S. Lakshmanan'}], 'author_detail': {'name': 'Laks V. S. Lakshmanan'}, 'author': 'Laks V. S. Lakshmanan', 'arxiv_comment': 'The 28th International Conference on Computational Linguistics\n  (COLING), 2020', 'links': [{'href': 'http://arxiv.org/abs/2011.01314v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.01314v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
151,http://arxiv.org/abs/2011.00452v1,2020-11-01 08:56:56+00:00,2020-11-01 08:56:56+00:00,Fake or Real? A Study of Arabic Satirical Fake News,"[arxiv.Result.Author('Hadeel Saadany'), arxiv.Result.Author('Emad Mohamed'), arxiv.Result.Author('Constantin Orasan')]","One very common type of fake news is satire which comes in a form of a news
website or an online platform that parodies reputable real news agencies to
create a sarcastic version of reality. This type of fake news is often
disseminated by individuals on their online platforms as it has a much stronger
effect in delivering criticism than through a straightforward message. However,
when the satirical text is disseminated via social media without mention of its
source, it can be mistaken for real news. This study conducts several
exploratory analyses to identify the linguistic properties of Arabic fake news
with satirical content. We exploit these features to build a number of machine
learning models capable of identifying satirical fake news with an accuracy of
up to 98.6%.",11 pages,"Proceedings of the 3rd International Workshop on Rumours and
  Deception in Social Media (RDSM) 2020",,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.00452v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.00452v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.00452v1,"{'id': 'http://arxiv.org/abs/2011.00452v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.00452v1', 'updated': '2020-11-01T08:56:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=1, tm_hour=8, tm_min=56, tm_sec=56, tm_wday=6, tm_yday=306, tm_isdst=0), 'published': '2020-11-01T08:56:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=1, tm_hour=8, tm_min=56, tm_sec=56, tm_wday=6, tm_yday=306, tm_isdst=0), 'title': 'Fake or Real? A Study of Arabic Satirical Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake or Real? A Study of Arabic Satirical Fake News'}, 'summary': 'One very common type of fake news is satire which comes in a form of a news\nwebsite or an online platform that parodies reputable real news agencies to\ncreate a sarcastic version of reality. This type of fake news is often\ndisseminated by individuals on their online platforms as it has a much stronger\neffect in delivering criticism than through a straightforward message. However,\nwhen the satirical text is disseminated via social media without mention of its\nsource, it can be mistaken for real news. This study conducts several\nexploratory analyses to identify the linguistic properties of Arabic fake news\nwith satirical content. We exploit these features to build a number of machine\nlearning models capable of identifying satirical fake news with an accuracy of\nup to 98.6%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'One very common type of fake news is satire which comes in a form of a news\nwebsite or an online platform that parodies reputable real news agencies to\ncreate a sarcastic version of reality. This type of fake news is often\ndisseminated by individuals on their online platforms as it has a much stronger\neffect in delivering criticism than through a straightforward message. However,\nwhen the satirical text is disseminated via social media without mention of its\nsource, it can be mistaken for real news. This study conducts several\nexploratory analyses to identify the linguistic properties of Arabic fake news\nwith satirical content. We exploit these features to build a number of machine\nlearning models capable of identifying satirical fake news with an accuracy of\nup to 98.6%.'}, 'authors': [{'name': 'Hadeel Saadany'}, {'name': 'Emad Mohamed'}, {'name': 'Constantin Orasan'}], 'author_detail': {'name': 'Constantin Orasan'}, 'author': 'Constantin Orasan', 'arxiv_comment': '11 pages', 'arxiv_journal_ref': 'Proceedings of the 3rd International Workshop on Rumours and\n  Deception in Social Media (RDSM) 2020', 'links': [{'href': 'http://arxiv.org/abs/2011.00452v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.00452v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
152,http://arxiv.org/abs/2010.16324v1,2020-10-30 15:29:16+00:00,2020-10-30 15:29:16+00:00,Topic-Preserving Synthetic News Generation: An Adversarial Deep Reinforcement Learning Approach,"[arxiv.Result.Author('Ahmadreza Mosallanezhad'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Huan Liu')]","Nowadays, there exist powerful language models such as OpenAI's GPT-2 that
can generate readable text and can be fine-tuned to generate text for a
specific domain. Considering GPT-2, it cannot directly generate synthetic news
with respect to a given topic and the output of the language model cannot be
explicitly controlled. In this paper, we study the novel problem of
topic-preserving synthetic news generation. We propose a novel deep
reinforcement learning-based method to control the output of GPT-2 with respect
to a given news topic. When generating text using GPT-2, by default, the most
probable word is selected from the vocabulary. Instead of selecting the best
word each time from GPT-2's output, an RL agent tries to select words that
optimize the matching of a given topic. In addition, using a fake news detector
as an adversary, we investigate generating realistic news using our proposed
method. In this paper, we consider realistic news as news that cannot be easily
detected by a fake news classifier. Experimental results demonstrate the
effectiveness of the proposed framework on generating topic-preserving news
content than state-of-the-art baselines.","10 pages, under review",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2010.16324v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.16324v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.16324v1,"{'id': 'http://arxiv.org/abs/2010.16324v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.16324v1', 'updated': '2020-10-30T15:29:16Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=30, tm_hour=15, tm_min=29, tm_sec=16, tm_wday=4, tm_yday=304, tm_isdst=0), 'published': '2020-10-30T15:29:16Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=30, tm_hour=15, tm_min=29, tm_sec=16, tm_wday=4, tm_yday=304, tm_isdst=0), 'title': 'Topic-Preserving Synthetic News Generation: An Adversarial Deep\n  Reinforcement Learning Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Topic-Preserving Synthetic News Generation: An Adversarial Deep\n  Reinforcement Learning Approach'}, 'summary': ""Nowadays, there exist powerful language models such as OpenAI's GPT-2 that\ncan generate readable text and can be fine-tuned to generate text for a\nspecific domain. Considering GPT-2, it cannot directly generate synthetic news\nwith respect to a given topic and the output of the language model cannot be\nexplicitly controlled. In this paper, we study the novel problem of\ntopic-preserving synthetic news generation. We propose a novel deep\nreinforcement learning-based method to control the output of GPT-2 with respect\nto a given news topic. When generating text using GPT-2, by default, the most\nprobable word is selected from the vocabulary. Instead of selecting the best\nword each time from GPT-2's output, an RL agent tries to select words that\noptimize the matching of a given topic. In addition, using a fake news detector\nas an adversary, we investigate generating realistic news using our proposed\nmethod. In this paper, we consider realistic news as news that cannot be easily\ndetected by a fake news classifier. Experimental results demonstrate the\neffectiveness of the proposed framework on generating topic-preserving news\ncontent than state-of-the-art baselines."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Nowadays, there exist powerful language models such as OpenAI's GPT-2 that\ncan generate readable text and can be fine-tuned to generate text for a\nspecific domain. Considering GPT-2, it cannot directly generate synthetic news\nwith respect to a given topic and the output of the language model cannot be\nexplicitly controlled. In this paper, we study the novel problem of\ntopic-preserving synthetic news generation. We propose a novel deep\nreinforcement learning-based method to control the output of GPT-2 with respect\nto a given news topic. When generating text using GPT-2, by default, the most\nprobable word is selected from the vocabulary. Instead of selecting the best\nword each time from GPT-2's output, an RL agent tries to select words that\noptimize the matching of a given topic. In addition, using a fake news detector\nas an adversary, we investigate generating realistic news using our proposed\nmethod. In this paper, we consider realistic news as news that cannot be easily\ndetected by a fake news classifier. Experimental results demonstrate the\neffectiveness of the proposed framework on generating topic-preserving news\ncontent than state-of-the-art baselines.""}, 'authors': [{'name': 'Ahmadreza Mosallanezhad'}, {'name': 'Kai Shu'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '10 pages, under review', 'links': [{'href': 'http://arxiv.org/abs/2010.16324v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.16324v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
153,http://arxiv.org/abs/2010.10580v2,2021-07-14 23:14:07+00:00,2020-10-20 19:37:04+00:00,Causal Understanding of Fake News Dissemination on Social Media,"[arxiv.Result.Author('Lu Cheng'), arxiv.Result.Author('Ruocheng Guo'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Huan Liu')]","Recent years have witnessed remarkable progress towards computational fake
news detection. To mitigate its negative impact, we argue that it is critical
to understand what user attributes potentially cause users to share fake news.
The key to this causal-inference problem is to identify confounders --
variables that cause spurious associations between treatments (e.g., user
attributes) and outcome (e.g., user susceptibility). In fake news
dissemination, confounders can be characterized by fake news sharing behavior
that inherently relates to user attributes and online activities. Learning such
user behavior is typically subject to selection bias in users who are
susceptible to share news on social media. Drawing on causal inference
theories, we first propose a principled approach to alleviating selection bias
in fake news dissemination. We then consider the learned unbiased fake news
sharing behavior as the surrogate confounder that can fully capture the causal
links between user attributes and user susceptibility. We theoretically and
empirically characterize the effectiveness of the proposed approach and find
that it could be useful in protecting society from the perils of fake news.","10 pages, 5 figures",,10.1145/3447548.3467321,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3447548.3467321', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.10580v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.10580v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.10580v2,"{'id': 'http://arxiv.org/abs/2010.10580v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.10580v2', 'updated': '2021-07-14T23:14:07Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=14, tm_hour=23, tm_min=14, tm_sec=7, tm_wday=2, tm_yday=195, tm_isdst=0), 'published': '2020-10-20T19:37:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=20, tm_hour=19, tm_min=37, tm_sec=4, tm_wday=1, tm_yday=294, tm_isdst=0), 'title': 'Causal Understanding of Fake News Dissemination on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Causal Understanding of Fake News Dissemination on Social Media'}, 'summary': 'Recent years have witnessed remarkable progress towards computational fake\nnews detection. To mitigate its negative impact, we argue that it is critical\nto understand what user attributes potentially cause users to share fake news.\nThe key to this causal-inference problem is to identify confounders --\nvariables that cause spurious associations between treatments (e.g., user\nattributes) and outcome (e.g., user susceptibility). In fake news\ndissemination, confounders can be characterized by fake news sharing behavior\nthat inherently relates to user attributes and online activities. Learning such\nuser behavior is typically subject to selection bias in users who are\nsusceptible to share news on social media. Drawing on causal inference\ntheories, we first propose a principled approach to alleviating selection bias\nin fake news dissemination. We then consider the learned unbiased fake news\nsharing behavior as the surrogate confounder that can fully capture the causal\nlinks between user attributes and user susceptibility. We theoretically and\nempirically characterize the effectiveness of the proposed approach and find\nthat it could be useful in protecting society from the perils of fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed remarkable progress towards computational fake\nnews detection. To mitigate its negative impact, we argue that it is critical\nto understand what user attributes potentially cause users to share fake news.\nThe key to this causal-inference problem is to identify confounders --\nvariables that cause spurious associations between treatments (e.g., user\nattributes) and outcome (e.g., user susceptibility). In fake news\ndissemination, confounders can be characterized by fake news sharing behavior\nthat inherently relates to user attributes and online activities. Learning such\nuser behavior is typically subject to selection bias in users who are\nsusceptible to share news on social media. Drawing on causal inference\ntheories, we first propose a principled approach to alleviating selection bias\nin fake news dissemination. We then consider the learned unbiased fake news\nsharing behavior as the surrogate confounder that can fully capture the causal\nlinks between user attributes and user susceptibility. We theoretically and\nempirically characterize the effectiveness of the proposed approach and find\nthat it could be useful in protecting society from the perils of fake news.'}, 'authors': [{'name': 'Lu Cheng'}, {'name': 'Ruocheng Guo'}, {'name': 'Kai Shu'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_doi': '10.1145/3447548.3467321', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3447548.3467321', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.10580v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.10580v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '10 pages, 5 figures', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
154,http://arxiv.org/abs/2010.10083v1,2020-10-20 07:21:11+00:00,2020-10-20 07:21:11+00:00,Bias-Resistant Social News Aggregator Based on Blockchain,"[arxiv.Result.Author('Amir Ziashahabi'), arxiv.Result.Author('Mohammad Ali Maddah-Ali'), arxiv.Result.Author('Abbas Heydarnoori')]","In today's world, social networks have become one of the primary sources for
creation and propagation of news. Social news aggregators are one of the actors
in this area in which users post news items and use positive or negative votes
to indicate their preference toward a news item. News items will be ordered and
displayed according to their aggregated votes. This approach suffers from
several problems raging from being prone to the dominance of the majority to
difficulty in discerning between correct and fake news, and lack of incentive
for honest behaviors. In this paper, we propose a graph-based news aggregator
in which instead of voting on the news items, users submit their votes on the
relations between pairs of news items. More precisely, if a user believes two
news items support each other, he will submit a positive vote on the link
between the two items, and if he believes that two news items undermine each
other, he will submit a negative vote on the corresponding link. This approach
has mainly two desirable features: (1) mitigating the effect of personal
preferences on voting, (2) connection of new items to endorsing and disputing
evidence. This approach helps the newsreaders to understand different aspects
of a news item better. We also introduce an incentive layer that uses
blockchain as a distributed transparent manager to encourages users to behave
honestly and abstain from adversary behaviors. The incentive layer takes into
account that users can have different viewpoints toward news, enabling users
from a wide range of viewpoints to contribute to the network and benefit from
its rewards. In addition, we introduce a protocol that enables us to prove
fraud in computations of the incentive layer model on the blockchain.
Ultimately, we will analyze the fraud proof protocol and examine our incentive
layer on a wide range of synthesized datasets.","23 page, 8 figures, Abstract abridged due to arXiv limits",,,cs.DC,"['cs.DC', 'cs.GT']","[arxiv.Result.Link('http://arxiv.org/abs/2010.10083v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.10083v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.10083v1,"{'id': 'http://arxiv.org/abs/2010.10083v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.10083v1', 'updated': '2020-10-20T07:21:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=20, tm_hour=7, tm_min=21, tm_sec=11, tm_wday=1, tm_yday=294, tm_isdst=0), 'published': '2020-10-20T07:21:11Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=20, tm_hour=7, tm_min=21, tm_sec=11, tm_wday=1, tm_yday=294, tm_isdst=0), 'title': 'Bias-Resistant Social News Aggregator Based on Blockchain', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Bias-Resistant Social News Aggregator Based on Blockchain'}, 'summary': ""In today's world, social networks have become one of the primary sources for\ncreation and propagation of news. Social news aggregators are one of the actors\nin this area in which users post news items and use positive or negative votes\nto indicate their preference toward a news item. News items will be ordered and\ndisplayed according to their aggregated votes. This approach suffers from\nseveral problems raging from being prone to the dominance of the majority to\ndifficulty in discerning between correct and fake news, and lack of incentive\nfor honest behaviors. In this paper, we propose a graph-based news aggregator\nin which instead of voting on the news items, users submit their votes on the\nrelations between pairs of news items. More precisely, if a user believes two\nnews items support each other, he will submit a positive vote on the link\nbetween the two items, and if he believes that two news items undermine each\nother, he will submit a negative vote on the corresponding link. This approach\nhas mainly two desirable features: (1) mitigating the effect of personal\npreferences on voting, (2) connection of new items to endorsing and disputing\nevidence. This approach helps the newsreaders to understand different aspects\nof a news item better. We also introduce an incentive layer that uses\nblockchain as a distributed transparent manager to encourages users to behave\nhonestly and abstain from adversary behaviors. The incentive layer takes into\naccount that users can have different viewpoints toward news, enabling users\nfrom a wide range of viewpoints to contribute to the network and benefit from\nits rewards. In addition, we introduce a protocol that enables us to prove\nfraud in computations of the incentive layer model on the blockchain.\nUltimately, we will analyze the fraud proof protocol and examine our incentive\nlayer on a wide range of synthesized datasets."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In today's world, social networks have become one of the primary sources for\ncreation and propagation of news. Social news aggregators are one of the actors\nin this area in which users post news items and use positive or negative votes\nto indicate their preference toward a news item. News items will be ordered and\ndisplayed according to their aggregated votes. This approach suffers from\nseveral problems raging from being prone to the dominance of the majority to\ndifficulty in discerning between correct and fake news, and lack of incentive\nfor honest behaviors. In this paper, we propose a graph-based news aggregator\nin which instead of voting on the news items, users submit their votes on the\nrelations between pairs of news items. More precisely, if a user believes two\nnews items support each other, he will submit a positive vote on the link\nbetween the two items, and if he believes that two news items undermine each\nother, he will submit a negative vote on the corresponding link. This approach\nhas mainly two desirable features: (1) mitigating the effect of personal\npreferences on voting, (2) connection of new items to endorsing and disputing\nevidence. This approach helps the newsreaders to understand different aspects\nof a news item better. We also introduce an incentive layer that uses\nblockchain as a distributed transparent manager to encourages users to behave\nhonestly and abstain from adversary behaviors. The incentive layer takes into\naccount that users can have different viewpoints toward news, enabling users\nfrom a wide range of viewpoints to contribute to the network and benefit from\nits rewards. In addition, we introduce a protocol that enables us to prove\nfraud in computations of the incentive layer model on the blockchain.\nUltimately, we will analyze the fraud proof protocol and examine our incentive\nlayer on a wide range of synthesized datasets.""}, 'authors': [{'name': 'Amir Ziashahabi'}, {'name': 'Mohammad Ali Maddah-Ali'}, {'name': 'Abbas Heydarnoori'}], 'author_detail': {'name': 'Abbas Heydarnoori'}, 'author': 'Abbas Heydarnoori', 'arxiv_comment': '23 page, 8 figures, Abstract abridged due to arXiv limits', 'links': [{'href': 'http://arxiv.org/abs/2010.10083v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.10083v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
155,http://arxiv.org/abs/2010.09029v2,2021-06-13 02:17:47+00:00,2020-10-18 16:52:27+00:00,CHECKED: Chinese COVID-19 Fake News Dataset,"[arxiv.Result.Author('Chen Yang'), arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Reza Zafarani')]","COVID-19 has impacted all lives. To maintain social distancing and avoiding
exposure, works and lives have gradually moved online. Under this trend, social
media usage to obtain COVID-19 news has increased. Also, misinformation on
COVID-19 is frequently spread on social media. In this work, we develop
CHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides
a total 2,104 verified microblogs related to COVID-19 from December 2019 to
August 2020, identified by using a specific list of keywords. Correspondingly,
CHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes
that reveal how these verified microblogs are spread and reacted on Weibo. The
dataset contains a rich set of multimedia information for each microblog
including ground-truth label, textual, visual, temporal, and network
information. Extensive experiments have been conducted to analyze CHECKED data
and to provide benchmark results for well-established methods when predicting
fake news using CHECKED. We hope that CHECKED can facilitate studies that
target misinformation on coronavirus. The dataset is available at
https://github.com/cyang03/CHECKED.",Accepted to Social Network Analysis and Mining (SNAM),,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2010.09029v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.09029v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.09029v2,"{'id': 'http://arxiv.org/abs/2010.09029v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.09029v2', 'updated': '2021-06-13T02:17:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=13, tm_hour=2, tm_min=17, tm_sec=47, tm_wday=6, tm_yday=164, tm_isdst=0), 'published': '2020-10-18T16:52:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=16, tm_min=52, tm_sec=27, tm_wday=6, tm_yday=292, tm_isdst=0), 'title': 'CHECKED: Chinese COVID-19 Fake News Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CHECKED: Chinese COVID-19 Fake News Dataset'}, 'summary': 'COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.'}, 'authors': [{'name': 'Chen Yang'}, {'name': 'Xinyi Zhou'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_comment': 'Accepted to Social Network Analysis and Mining (SNAM)', 'links': [{'href': 'http://arxiv.org/abs/2010.09029v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.09029v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
156,http://arxiv.org/abs/2010.08765v1,2020-10-17 11:11:10+00:00,2020-10-17 11:11:10+00:00,DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain,"[arxiv.Result.Author('Prashansa Agrawal'), arxiv.Result.Author('Parwat Singh Anjana'), arxiv.Result.Author('Sathya Peri')]","The surge in the spread of misleading information, lies, propaganda, and
false facts, frequently known as fake news, raised questions concerning social
media's influence in today's fast-moving democratic society. The widespread and
rapid dissemination of fake news cost us in many ways. For example, individual
or societal costs by hampering elections integrity, significant economic losses
by impacting stock markets, or increases the risk to national security. It is
challenging to overcome the spreading of fake news problems in traditional
centralized systems. However, Blockchain-- a distributed decentralized
technology that ensures data provenance, authenticity, and traceability by
providing a transparent, immutable, and verifiable transaction records can help
in detecting and contending fake news. This paper proposes a novel hybrid model
DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain.
The DeHiDe is a blockchain-based framework for legitimate news sharing by
filtering out the fake news. It combines the benefit of blockchain with an
intelligent deep learning model to reinforce robustness and accuracy in
combating fake news's hurdle. It also compares the proposed method to existing
state-of-the-art methods. The DeHiDe is expected to outperform state-of-the-art
approaches in terms of services, features, and performance.","13 Pages, 5 figures, and 1 table",,10.1145/3427796.3430003,cs.LG,['cs.LG'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3427796.3430003', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.08765v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.08765v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.08765v1,"{'id': 'http://arxiv.org/abs/2010.08765v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.08765v1', 'updated': '2020-10-17T11:11:10Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=11, tm_min=11, tm_sec=10, tm_wday=5, tm_yday=291, tm_isdst=0), 'published': '2020-10-17T11:11:10Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=11, tm_min=11, tm_sec=10, tm_wday=5, tm_yday=291, tm_isdst=0), 'title': 'DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using\n  Blockchain', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using\n  Blockchain'}, 'summary': ""The surge in the spread of misleading information, lies, propaganda, and\nfalse facts, frequently known as fake news, raised questions concerning social\nmedia's influence in today's fast-moving democratic society. The widespread and\nrapid dissemination of fake news cost us in many ways. For example, individual\nor societal costs by hampering elections integrity, significant economic losses\nby impacting stock markets, or increases the risk to national security. It is\nchallenging to overcome the spreading of fake news problems in traditional\ncentralized systems. However, Blockchain-- a distributed decentralized\ntechnology that ensures data provenance, authenticity, and traceability by\nproviding a transparent, immutable, and verifiable transaction records can help\nin detecting and contending fake news. This paper proposes a novel hybrid model\nDeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain.\nThe DeHiDe is a blockchain-based framework for legitimate news sharing by\nfiltering out the fake news. It combines the benefit of blockchain with an\nintelligent deep learning model to reinforce robustness and accuracy in\ncombating fake news's hurdle. It also compares the proposed method to existing\nstate-of-the-art methods. The DeHiDe is expected to outperform state-of-the-art\napproaches in terms of services, features, and performance."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The surge in the spread of misleading information, lies, propaganda, and\nfalse facts, frequently known as fake news, raised questions concerning social\nmedia's influence in today's fast-moving democratic society. The widespread and\nrapid dissemination of fake news cost us in many ways. For example, individual\nor societal costs by hampering elections integrity, significant economic losses\nby impacting stock markets, or increases the risk to national security. It is\nchallenging to overcome the spreading of fake news problems in traditional\ncentralized systems. However, Blockchain-- a distributed decentralized\ntechnology that ensures data provenance, authenticity, and traceability by\nproviding a transparent, immutable, and verifiable transaction records can help\nin detecting and contending fake news. This paper proposes a novel hybrid model\nDeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain.\nThe DeHiDe is a blockchain-based framework for legitimate news sharing by\nfiltering out the fake news. It combines the benefit of blockchain with an\nintelligent deep learning model to reinforce robustness and accuracy in\ncombating fake news's hurdle. It also compares the proposed method to existing\nstate-of-the-art methods. The DeHiDe is expected to outperform state-of-the-art\napproaches in terms of services, features, and performance.""}, 'authors': [{'name': 'Prashansa Agrawal'}, {'name': 'Parwat Singh Anjana'}, {'name': 'Sathya Peri'}], 'author_detail': {'name': 'Sathya Peri'}, 'author': 'Sathya Peri', 'arxiv_doi': '10.1145/3427796.3430003', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3427796.3430003', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.08765v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.08765v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '13 Pages, 5 figures, and 1 table', 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
157,http://arxiv.org/abs/2010.08743v1,2020-10-17 08:34:57+00:00,2020-10-17 08:34:57+00:00,Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed health decision making in the presence of COVID19 misinformation,"[arxiv.Result.Author('Arkin Dharawat'), arxiv.Result.Author('Ismini Lourentzou'), arxiv.Result.Author('Alex Morales'), arxiv.Result.Author('ChengXiang Zhai')]","Given the wide spread of inaccurate medical advice related to the 2019
coronavirus pandemic (COVID-19), such as fake remedies, treatments and
prevention suggestions, misinformation detection has emerged as an open problem
of high importance and interest for the NLP community. To combat potential harm
of COVID19-related misinformation, we release Covid-HeRA, a dataset for health
risk assessment of COVID-19-related social media posts. More specifically, we
study the severity of each misinformation story, i.e., how harmful a message
believed by the audience can be and what type of signals can be used to
discover high malicious fake news and detect refuted claims. We present a
detailed analysis, evaluate several simple and advanced classification models,
and conclude with our experimental analysis that presents open challenges and
future directions.",,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2010.08743v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.08743v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.08743v1,"{'id': 'http://arxiv.org/abs/2010.08743v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.08743v1', 'updated': '2020-10-17T08:34:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=8, tm_min=34, tm_sec=57, tm_wday=5, tm_yday=291, tm_isdst=0), 'published': '2020-10-17T08:34:57Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=8, tm_min=34, tm_sec=57, tm_wday=5, tm_yday=291, tm_isdst=0), 'title': 'Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation'}, 'summary': 'Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.'}, 'authors': [{'name': 'Arkin Dharawat'}, {'name': 'Ismini Lourentzou'}, {'name': 'Alex Morales'}, {'name': 'ChengXiang Zhai'}], 'author_detail': {'name': 'ChengXiang Zhai'}, 'author': 'ChengXiang Zhai', 'links': [{'href': 'http://arxiv.org/abs/2010.08743v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.08743v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
158,http://arxiv.org/abs/2010.11089v1,2020-10-16 20:39:57+00:00,2020-10-16 20:39:57+00:00,Lexicon generation for detecting fake news,"[arxiv.Result.Author('Uğur Mertoğlu'), arxiv.Result.Author('Burkay Genç')]","With the digitization of media, an immense amount of news data has been
generated by online sources, including mainstream media outlets as well as
social networks. However, the ease of production and distribution resulted in
circulation of fake news as well as credible, authentic news. The pervasive
dissemination of fake news has extreme negative impacts on individuals and
society. Therefore, fake news detection has recently become an emerging topic
as an interdisciplinary research field that is attracting significant attention
from many research disciplines, including social sciences and linguistics. In
this study, we propose a method primarily based on lexicons including a scoring
system to facilitate the detection of the fake news in Turkish. We contribute
to the literature by collecting a novel, large scale, and credible dataset of
Turkish news, and by constructing the first fake news detection lexicon for
Turkish.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.11089v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.11089v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.11089v1,"{'id': 'http://arxiv.org/abs/2010.11089v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.11089v1', 'updated': '2020-10-16T20:39:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=16, tm_hour=20, tm_min=39, tm_sec=57, tm_wday=4, tm_yday=290, tm_isdst=0), 'published': '2020-10-16T20:39:57Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=16, tm_hour=20, tm_min=39, tm_sec=57, tm_wday=4, tm_yday=290, tm_isdst=0), 'title': 'Lexicon generation for detecting fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Lexicon generation for detecting fake news'}, 'summary': 'With the digitization of media, an immense amount of news data has been\ngenerated by online sources, including mainstream media outlets as well as\nsocial networks. However, the ease of production and distribution resulted in\ncirculation of fake news as well as credible, authentic news. The pervasive\ndissemination of fake news has extreme negative impacts on individuals and\nsociety. Therefore, fake news detection has recently become an emerging topic\nas an interdisciplinary research field that is attracting significant attention\nfrom many research disciplines, including social sciences and linguistics. In\nthis study, we propose a method primarily based on lexicons including a scoring\nsystem to facilitate the detection of the fake news in Turkish. We contribute\nto the literature by collecting a novel, large scale, and credible dataset of\nTurkish news, and by constructing the first fake news detection lexicon for\nTurkish.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the digitization of media, an immense amount of news data has been\ngenerated by online sources, including mainstream media outlets as well as\nsocial networks. However, the ease of production and distribution resulted in\ncirculation of fake news as well as credible, authentic news. The pervasive\ndissemination of fake news has extreme negative impacts on individuals and\nsociety. Therefore, fake news detection has recently become an emerging topic\nas an interdisciplinary research field that is attracting significant attention\nfrom many research disciplines, including social sciences and linguistics. In\nthis study, we propose a method primarily based on lexicons including a scoring\nsystem to facilitate the detection of the fake news in Turkish. We contribute\nto the literature by collecting a novel, large scale, and credible dataset of\nTurkish news, and by constructing the first fake news detection lexicon for\nTurkish.'}, 'authors': [{'name': 'Uğur Mertoğlu'}, {'name': 'Burkay Genç'}], 'author_detail': {'name': 'Burkay Genç'}, 'author': 'Burkay Genç', 'links': [{'href': 'http://arxiv.org/abs/2010.11089v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.11089v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
159,http://arxiv.org/abs/2010.07647v2,2021-07-06 09:16:25+00:00,2020-10-15 10:31:28+00:00,Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised Learning Approach,"[arxiv.Result.Author('Shakshi Sharma'), arxiv.Result.Author('Rajesh Sharma')]","Online Social Media (OSM) platforms such as Twitter, Facebook are extensively
exploited by the users of these platforms for spreading the (mis)information to
a large audience effortlessly at a rapid pace. It has been observed that the
misinformation can cause panic, fear, and financial loss to society. Thus, it
is important to detect and control the misinformation in such platforms before
it spreads to the masses. In this work, we focus on rumors, which is one type
of misinformation (other types are fake news, hoaxes, etc). One way to control
the spread of the rumors is by identifying users who are possibly the rumor
spreaders, that is, users who are often involved in spreading the rumors. Due
to the lack of availability of rumor spreaders labeled dataset (which is an
expensive task), we use publicly available PHEME dataset, which contains rumor
and non-rumor tweets information, and then apply a weak supervised learning
approach to transform the PHEME dataset into rumor spreaders dataset. We
utilize three types of features, that is, user, text, and ego-network features,
before applying various supervised learning approaches. In particular, to
exploit the inherent network property in this dataset (user-user reply graph),
we explore Graph Convolutional Network (GCN), a type of Graph Neural Network
(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and
LSTM. Extensive experiments performed on the rumor spreaders dataset, where we
achieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the
effectiveness of our methodology for identifying possible rumor spreaders using
the GCN technique.","Published at The International Joint Conference on Neural Networks
  2021 (IJCNN2021). Please cite the IJCNN version",,,cs.AI,['cs.AI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.07647v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.07647v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.07647v2,"{'id': 'http://arxiv.org/abs/2010.07647v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.07647v2', 'updated': '2021-07-06T09:16:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=9, tm_min=16, tm_sec=25, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2020-10-15T10:31:28Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=15, tm_hour=10, tm_min=31, tm_sec=28, tm_wday=3, tm_yday=289, tm_isdst=0), 'title': 'Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach'}, 'summary': 'Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.'}, 'authors': [{'name': 'Shakshi Sharma'}, {'name': 'Rajesh Sharma'}], 'author_detail': {'name': 'Rajesh Sharma'}, 'author': 'Rajesh Sharma', 'arxiv_comment': 'Published at The International Joint Conference on Neural Networks\n  2021 (IJCNN2021). Please cite the IJCNN version', 'links': [{'href': 'http://arxiv.org/abs/2010.07647v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.07647v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
160,http://arxiv.org/abs/2010.07607v1,2020-10-15 09:08:47+00:00,2020-10-15 09:08:47+00:00,Perceptions of News Sharing and Fake News in Singapore,"[arxiv.Result.Author('Gionnieve Lim'), arxiv.Result.Author('Simon T. Perrault')]","Fake news is a prevalent problem that can undermine citizen engagement and
become an obstacle to the goals of civic tech. To understand consumers'
reactions and actions towards fake news, and their trust in various news media,
we conducted a survey in Singapore. We found that fake news stem largely from
instant messaging apps and social media, and that the problem of fake news was
attributed more to its sharing than to its creation. Verification of news was
done mainly by using a search engine to check and cross-reference the news.
Amongst the top three sources to obtain news, there was low trust reported in
social media, high trust in local news channels, and highest trust in
government communication platforms. The strong trust in government
communication platforms suggests that top-down civic tech initiatives may have
great potential to effectively manage fake news and promote citizen engagement
in Singapore.",,,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.07607v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.07607v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.07607v1,"{'id': 'http://arxiv.org/abs/2010.07607v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.07607v1', 'updated': '2020-10-15T09:08:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=15, tm_hour=9, tm_min=8, tm_sec=47, tm_wday=3, tm_yday=289, tm_isdst=0), 'published': '2020-10-15T09:08:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=15, tm_hour=9, tm_min=8, tm_sec=47, tm_wday=3, tm_yday=289, tm_isdst=0), 'title': 'Perceptions of News Sharing and Fake News in Singapore', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Perceptions of News Sharing and Fake News in Singapore'}, 'summary': ""Fake news is a prevalent problem that can undermine citizen engagement and\nbecome an obstacle to the goals of civic tech. To understand consumers'\nreactions and actions towards fake news, and their trust in various news media,\nwe conducted a survey in Singapore. We found that fake news stem largely from\ninstant messaging apps and social media, and that the problem of fake news was\nattributed more to its sharing than to its creation. Verification of news was\ndone mainly by using a search engine to check and cross-reference the news.\nAmongst the top three sources to obtain news, there was low trust reported in\nsocial media, high trust in local news channels, and highest trust in\ngovernment communication platforms. The strong trust in government\ncommunication platforms suggests that top-down civic tech initiatives may have\ngreat potential to effectively manage fake news and promote citizen engagement\nin Singapore."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is a prevalent problem that can undermine citizen engagement and\nbecome an obstacle to the goals of civic tech. To understand consumers'\nreactions and actions towards fake news, and their trust in various news media,\nwe conducted a survey in Singapore. We found that fake news stem largely from\ninstant messaging apps and social media, and that the problem of fake news was\nattributed more to its sharing than to its creation. Verification of news was\ndone mainly by using a search engine to check and cross-reference the news.\nAmongst the top three sources to obtain news, there was low trust reported in\nsocial media, high trust in local news channels, and highest trust in\ngovernment communication platforms. The strong trust in government\ncommunication platforms suggests that top-down civic tech initiatives may have\ngreat potential to effectively manage fake news and promote citizen engagement\nin Singapore.""}, 'authors': [{'name': 'Gionnieve Lim'}, {'name': 'Simon T. Perrault'}], 'author_detail': {'name': 'Simon T. Perrault'}, 'author': 'Simon T. Perrault', 'links': [{'href': 'http://arxiv.org/abs/2010.07607v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.07607v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
161,http://arxiv.org/abs/2010.06906v1,2020-10-14 09:37:51+00:00,2020-10-14 09:37:51+00:00,No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet Detection,"[arxiv.Result.Author('Debanjana Kar'), arxiv.Result.Author('Mohit Bhardwaj'), arxiv.Result.Author('Suranjana Samanta'), arxiv.Result.Author('Amar Prakash Azad')]","The sudden widespread menace created by the present global pandemic COVID-19
has had an unprecedented effect on our lives. Man-kind is going through
humongous fear and dependence on social media like never before. Fear
inevitably leads to panic, speculations, and the spread of misinformation. Many
governments have taken measures to curb the spread of such misinformation for
public well being. Besides global measures, to have effective outreach, systems
for demographically local languages have an important role to play in this
effort. Towards this, we propose an approach to detect fake news about COVID-19
early on from social media, such as tweets, for multiple Indic-Languages
besides English. In addition, we also create an annotated dataset of Hindi and
Bengali tweet for fake news detection. We propose a BERT based model augmented
with additional relevant features extracted from Twitter to identify fake
tweets. To expand our approach to multiple Indic languages, we resort to mBERT
based model which is fine-tuned over created dataset in Hindi and Bengali. We
also propose a zero-shot learning approach to alleviate the data scarcity issue
for such low resource languages. Through rigorous experiments, we show that our
approach reaches around 89% F-Score in fake tweet detection which supercedes
the state-of-the-art (SOTA) results. Moreover, we establish the first benchmark
for two Indic-Languages, Hindi and Bengali. Using our annotated data, our model
achieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our
zero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali
Tweets without any annotated data, which clearly indicates the efficacy of our
approach.","6 pages, 4 figures",,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.06906v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.06906v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.06906v1,"{'id': 'http://arxiv.org/abs/2010.06906v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.06906v1', 'updated': '2020-10-14T09:37:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=14, tm_hour=9, tm_min=37, tm_sec=51, tm_wday=2, tm_yday=288, tm_isdst=0), 'published': '2020-10-14T09:37:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=14, tm_hour=9, tm_min=37, tm_sec=51, tm_wday=2, tm_yday=288, tm_isdst=0), 'title': 'No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection'}, 'summary': 'The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.'}, 'authors': [{'name': 'Debanjana Kar'}, {'name': 'Mohit Bhardwaj'}, {'name': 'Suranjana Samanta'}, {'name': 'Amar Prakash Azad'}], 'author_detail': {'name': 'Amar Prakash Azad'}, 'author': 'Amar Prakash Azad', 'arxiv_comment': '6 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2010.06906v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.06906v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
162,http://arxiv.org/abs/2010.05686v1,2020-10-12 13:25:48+00:00,2020-10-12 13:25:48+00:00,How the Far-Right Polarises Twitter: 'Highjacking' Hashtags in Times of COVID-19,"[arxiv.Result.Author('Philipp Darius'), arxiv.Result.Author('Fabian Stephany')]","Twitter influences political debates. Phenomena like fake news and hate
speech show that political discourse on micro-blogging can become strongly
polarised by algorithmic enforcement of selective perception. Some political
actors actively employ strategies to facilitate polarisation on Twitter, as
past contributions show, via strategies of 'hashjacking'. For the example of
COVID-19 related hashtags and their retweet networks, we examine the case of
partisan accounts of the German far-right party Alternative f\""ur Deutschland
(AfD) and their potential use of 'hashjacking' in May 2020. Our findings
indicate that polarisation of political party hashtags has not changed
significantly in the last two years. We see that right-wing partisans are
actively and effectively polarising the discourse by 'hashjacking' COVID-19
related hashtags, like #CoronaVirusDE or #FlattenTheCurve. This polarisation
strategy is dominated by the activity of a limited set of heavy users. The
results underline the necessity to understand the dynamics of discourse
polarisation, as an active political communication strategy of the far-right,
by only a handful of very active accounts.","10 pages, 3 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.05686v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.05686v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.05686v1,"{'id': 'http://arxiv.org/abs/2010.05686v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.05686v1', 'updated': '2020-10-12T13:25:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=12, tm_hour=13, tm_min=25, tm_sec=48, tm_wday=0, tm_yday=286, tm_isdst=0), 'published': '2020-10-12T13:25:48Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=12, tm_hour=13, tm_min=25, tm_sec=48, tm_wday=0, tm_yday=286, tm_isdst=0), 'title': ""How the Far-Right Polarises Twitter: 'Highjacking' Hashtags in Times of\n  COVID-19"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""How the Far-Right Polarises Twitter: 'Highjacking' Hashtags in Times of\n  COVID-19""}, 'summary': 'Twitter influences political debates. Phenomena like fake news and hate\nspeech show that political discourse on micro-blogging can become strongly\npolarised by algorithmic enforcement of selective perception. Some political\nactors actively employ strategies to facilitate polarisation on Twitter, as\npast contributions show, via strategies of \'hashjacking\'. For the example of\nCOVID-19 related hashtags and their retweet networks, we examine the case of\npartisan accounts of the German far-right party Alternative f\\""ur Deutschland\n(AfD) and their potential use of \'hashjacking\' in May 2020. Our findings\nindicate that polarisation of political party hashtags has not changed\nsignificantly in the last two years. We see that right-wing partisans are\nactively and effectively polarising the discourse by \'hashjacking\' COVID-19\nrelated hashtags, like #CoronaVirusDE or #FlattenTheCurve. This polarisation\nstrategy is dominated by the activity of a limited set of heavy users. The\nresults underline the necessity to understand the dynamics of discourse\npolarisation, as an active political communication strategy of the far-right,\nby only a handful of very active accounts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Twitter influences political debates. Phenomena like fake news and hate\nspeech show that political discourse on micro-blogging can become strongly\npolarised by algorithmic enforcement of selective perception. Some political\nactors actively employ strategies to facilitate polarisation on Twitter, as\npast contributions show, via strategies of \'hashjacking\'. For the example of\nCOVID-19 related hashtags and their retweet networks, we examine the case of\npartisan accounts of the German far-right party Alternative f\\""ur Deutschland\n(AfD) and their potential use of \'hashjacking\' in May 2020. Our findings\nindicate that polarisation of political party hashtags has not changed\nsignificantly in the last two years. We see that right-wing partisans are\nactively and effectively polarising the discourse by \'hashjacking\' COVID-19\nrelated hashtags, like #CoronaVirusDE or #FlattenTheCurve. This polarisation\nstrategy is dominated by the activity of a limited set of heavy users. The\nresults underline the necessity to understand the dynamics of discourse\npolarisation, as an active political communication strategy of the far-right,\nby only a handful of very active accounts.'}, 'authors': [{'name': 'Philipp Darius'}, {'name': 'Fabian Stephany'}], 'author_detail': {'name': 'Fabian Stephany'}, 'author': 'Fabian Stephany', 'arxiv_comment': '10 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/2010.05686v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.05686v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
163,http://arxiv.org/abs/2010.05496v2,2020-11-03 11:32:14+00:00,2020-10-12 07:43:01+00:00,Feature Extraction of Text for Deep Learning Algorithms: Application on Fake News Detection,[arxiv.Result.Author('HyeonJun Kim')],"Feature extraction is an important process of machine learning and deep
learning, as the process make algorithms function more efficiently, and also
accurate. In natural language processing used in deception detection such as
fake news detection, several ways of feature extraction in statistical aspect
had been introduced (e.g. N-gram). In this research, it will be shown that by
using deep learning algorithms and alphabet frequencies of the original text of
a news without any information about the sequence of the alphabet can actually
be used to classify fake news and trustworthy ones in high accuracy (85\%). As
this pre-processing method makes the data notably compact but also include the
feature that is needed for the classifier, it seems that alphabet frequencies
contains some useful features for understanding complex context or meaning of
the original text.",8 pages,,,cs.CL,"['cs.CL', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2010.05496v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.05496v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.05496v2,"{'id': 'http://arxiv.org/abs/2010.05496v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.05496v2', 'updated': '2020-11-03T11:32:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=11, tm_min=32, tm_sec=14, tm_wday=1, tm_yday=308, tm_isdst=0), 'published': '2020-10-12T07:43:01Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=12, tm_hour=7, tm_min=43, tm_sec=1, tm_wday=0, tm_yday=286, tm_isdst=0), 'title': 'Feature Extraction of Text for Deep Learning Algorithms: Application on\n  Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Feature Extraction of Text for Deep Learning Algorithms: Application on\n  Fake News Detection'}, 'summary': 'Feature extraction is an important process of machine learning and deep\nlearning, as the process make algorithms function more efficiently, and also\naccurate. In natural language processing used in deception detection such as\nfake news detection, several ways of feature extraction in statistical aspect\nhad been introduced (e.g. N-gram). In this research, it will be shown that by\nusing deep learning algorithms and alphabet frequencies of the original text of\na news without any information about the sequence of the alphabet can actually\nbe used to classify fake news and trustworthy ones in high accuracy (85\\%). As\nthis pre-processing method makes the data notably compact but also include the\nfeature that is needed for the classifier, it seems that alphabet frequencies\ncontains some useful features for understanding complex context or meaning of\nthe original text.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Feature extraction is an important process of machine learning and deep\nlearning, as the process make algorithms function more efficiently, and also\naccurate. In natural language processing used in deception detection such as\nfake news detection, several ways of feature extraction in statistical aspect\nhad been introduced (e.g. N-gram). In this research, it will be shown that by\nusing deep learning algorithms and alphabet frequencies of the original text of\na news without any information about the sequence of the alphabet can actually\nbe used to classify fake news and trustworthy ones in high accuracy (85\\%). As\nthis pre-processing method makes the data notably compact but also include the\nfeature that is needed for the classifier, it seems that alphabet frequencies\ncontains some useful features for understanding complex context or meaning of\nthe original text.'}, 'authors': [{'name': 'HyeonJun Kim'}], 'author_detail': {'name': 'HyeonJun Kim'}, 'author': 'HyeonJun Kim', 'arxiv_comment': '8 pages', 'links': [{'href': 'http://arxiv.org/abs/2010.05496v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.05496v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
164,http://arxiv.org/abs/2010.05313v3,2021-07-09 06:22:14+00:00,2020-10-11 18:44:50+00:00,Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks,"[arxiv.Result.Author('Eli A. Meirom'), arxiv.Result.Author('Haggai Maron'), arxiv.Result.Author('Shie Mannor'), arxiv.Result.Author('Gal Chechik')]","We consider the problem of controlling a partially-observed dynamic process
on a graph by a limited number of interventions. This problem naturally arises
in contexts such as scheduling virus tests to curb an epidemic; targeted
marketing in order to promote a product; and manually inspecting posts to
detect fake news spreading on social networks.
  We formulate this setup as a sequential decision problem over a temporal
graph process. In face of an exponential state space, combinatorial action
space and partial observability, we design a novel tractable scheme to control
dynamical processes on temporal graphs. We successfully apply our approach to
two popular problems that fall into our framework: prioritizing which nodes
should be tested in order to curb the spread of an epidemic, and influence
maximization on a graph.",ICML 2021,,,cs.LG,"['cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.05313v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.05313v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.05313v3,"{'id': 'http://arxiv.org/abs/2010.05313v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.05313v3', 'updated': '2021-07-09T06:22:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=9, tm_hour=6, tm_min=22, tm_sec=14, tm_wday=4, tm_yday=190, tm_isdst=0), 'published': '2020-10-11T18:44:50Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=11, tm_hour=18, tm_min=44, tm_sec=50, tm_wday=6, tm_yday=285, tm_isdst=0), 'title': 'Controlling Graph Dynamics with Reinforcement Learning and Graph Neural\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Controlling Graph Dynamics with Reinforcement Learning and Graph Neural\n  Networks'}, 'summary': 'We consider the problem of controlling a partially-observed dynamic process\non a graph by a limited number of interventions. This problem naturally arises\nin contexts such as scheduling virus tests to curb an epidemic; targeted\nmarketing in order to promote a product; and manually inspecting posts to\ndetect fake news spreading on social networks.\n  We formulate this setup as a sequential decision problem over a temporal\ngraph process. In face of an exponential state space, combinatorial action\nspace and partial observability, we design a novel tractable scheme to control\ndynamical processes on temporal graphs. We successfully apply our approach to\ntwo popular problems that fall into our framework: prioritizing which nodes\nshould be tested in order to curb the spread of an epidemic, and influence\nmaximization on a graph.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We consider the problem of controlling a partially-observed dynamic process\non a graph by a limited number of interventions. This problem naturally arises\nin contexts such as scheduling virus tests to curb an epidemic; targeted\nmarketing in order to promote a product; and manually inspecting posts to\ndetect fake news spreading on social networks.\n  We formulate this setup as a sequential decision problem over a temporal\ngraph process. In face of an exponential state space, combinatorial action\nspace and partial observability, we design a novel tractable scheme to control\ndynamical processes on temporal graphs. We successfully apply our approach to\ntwo popular problems that fall into our framework: prioritizing which nodes\nshould be tested in order to curb the spread of an epidemic, and influence\nmaximization on a graph.'}, 'authors': [{'name': 'Eli A. Meirom'}, {'name': 'Haggai Maron'}, {'name': 'Shie Mannor'}, {'name': 'Gal Chechik'}], 'author_detail': {'name': 'Gal Chechik'}, 'author': 'Gal Chechik', 'arxiv_comment': 'ICML 2021', 'links': [{'href': 'http://arxiv.org/abs/2010.05313v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.05313v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
165,http://arxiv.org/abs/2010.05202v1,2020-10-11 09:28:52+00:00,2020-10-11 09:28:52+00:00,Connecting the Dots Between Fact Verification and Fake News Detection,"[arxiv.Result.Author('Qifei Li'), arxiv.Result.Author('Wangchunshu Zhou')]","Fact verification models have enjoyed a fast advancement in the last two
years with the development of pre-trained language models like BERT and the
release of large scale datasets such as FEVER. However, the challenging problem
of fake news detection has not benefited from the improvement of fact
verification models, which is closely related to fake news detection. In this
paper, we propose a simple yet effective approach to connect the dots between
fact verification and fake news detection. Our approach first employs a text
summarization model pre-trained on news corpora to summarize the long news
article into a short claim. Then we use a fact verification model pre-trained
on the FEVER dataset to detect whether the input news article is real or fake.
Our approach makes use of the recent success of fact verification models and
enables zero-shot fake news detection, alleviating the need of large-scale
training data to train fake news detection models. Experimental results on
FakenewsNet, a benchmark dataset for fake news detection, demonstrate the
effectiveness of our proposed approach.",Accepted to COLING 2020,,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.05202v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.05202v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.05202v1,"{'id': 'http://arxiv.org/abs/2010.05202v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.05202v1', 'updated': '2020-10-11T09:28:52Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=11, tm_hour=9, tm_min=28, tm_sec=52, tm_wday=6, tm_yday=285, tm_isdst=0), 'published': '2020-10-11T09:28:52Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=11, tm_hour=9, tm_min=28, tm_sec=52, tm_wday=6, tm_yday=285, tm_isdst=0), 'title': 'Connecting the Dots Between Fact Verification and Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Connecting the Dots Between Fact Verification and Fake News Detection'}, 'summary': 'Fact verification models have enjoyed a fast advancement in the last two\nyears with the development of pre-trained language models like BERT and the\nrelease of large scale datasets such as FEVER. However, the challenging problem\nof fake news detection has not benefited from the improvement of fact\nverification models, which is closely related to fake news detection. In this\npaper, we propose a simple yet effective approach to connect the dots between\nfact verification and fake news detection. Our approach first employs a text\nsummarization model pre-trained on news corpora to summarize the long news\narticle into a short claim. Then we use a fact verification model pre-trained\non the FEVER dataset to detect whether the input news article is real or fake.\nOur approach makes use of the recent success of fact verification models and\nenables zero-shot fake news detection, alleviating the need of large-scale\ntraining data to train fake news detection models. Experimental results on\nFakenewsNet, a benchmark dataset for fake news detection, demonstrate the\neffectiveness of our proposed approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact verification models have enjoyed a fast advancement in the last two\nyears with the development of pre-trained language models like BERT and the\nrelease of large scale datasets such as FEVER. However, the challenging problem\nof fake news detection has not benefited from the improvement of fact\nverification models, which is closely related to fake news detection. In this\npaper, we propose a simple yet effective approach to connect the dots between\nfact verification and fake news detection. Our approach first employs a text\nsummarization model pre-trained on news corpora to summarize the long news\narticle into a short claim. Then we use a fact verification model pre-trained\non the FEVER dataset to detect whether the input news article is real or fake.\nOur approach makes use of the recent success of fact verification models and\nenables zero-shot fake news detection, alleviating the need of large-scale\ntraining data to train fake news detection models. Experimental results on\nFakenewsNet, a benchmark dataset for fake news detection, demonstrate the\neffectiveness of our proposed approach.'}, 'authors': [{'name': 'Qifei Li'}, {'name': 'Wangchunshu Zhou'}], 'author_detail': {'name': 'Wangchunshu Zhou'}, 'author': 'Wangchunshu Zhou', 'arxiv_comment': 'Accepted to COLING 2020', 'links': [{'href': 'http://arxiv.org/abs/2010.05202v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.05202v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
166,http://arxiv.org/abs/2010.03159v1,2020-10-07 04:55:34+00:00,2020-10-07 04:55:34+00:00,Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","Although many fact-checking systems have been developed in academia and
industry, fake news is still proliferating on social media. These systems
mostly focus on fact-checking but usually neglect online users who are the main
drivers of the spread of misinformation. How can we use fact-checked
information to improve users' consciousness of fake news to which they are
exposed? How can we stop users from spreading fake news? To tackle these
questions, we propose a novel framework to search for fact-checking articles,
which address the content of an original tweet (that may contain
misinformation) posted by online users. The search can directly warn fake news
posters and online users (e.g. the posters' followers) about misinformation,
discourage them from spreading fake news, and scale up verified content on
social media. Our framework uses both text and images to search for
fact-checking articles, and achieves promising results on real-world datasets.
Our code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.","Full paper, EMNLP 2020",,,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.03159v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.03159v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.03159v1,"{'id': 'http://arxiv.org/abs/2010.03159v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.03159v1', 'updated': '2020-10-07T04:55:34Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=4, tm_min=55, tm_sec=34, tm_wday=2, tm_yday=281, tm_isdst=0), 'published': '2020-10-07T04:55:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=4, tm_min=55, tm_sec=34, tm_wday=2, tm_yday=281, tm_isdst=0), 'title': 'Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News'}, 'summary': ""Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.""}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'Full paper, EMNLP 2020', 'links': [{'href': 'http://arxiv.org/abs/2010.03159v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.03159v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
167,http://arxiv.org/abs/2010.03001v4,2021-08-24 15:40:14+00:00,2020-10-06 20:05:43+00:00,A Review on Fact Extraction and Verification,"[arxiv.Result.Author('Giannis Bekoulis'), arxiv.Result.Author('Christina Papagiannopoulou'), arxiv.Result.Author('Nikos Deligiannis')]","We study the fact checking problem, which aims to identify the veracity of a
given claim. Specifically, we focus on the task of Fact Extraction and
VERification (FEVER) and its accompanied dataset. The task consists of the
subtasks of retrieving the relevant documents (and sentences) from Wikipedia
and validating whether the information in the documents supports or refutes a
given claim. This task is essential and can be the building block of
applications such as fake news detection and medical claim verification. In
this paper, we aim at a better understanding of the challenges of the task by
presenting the literature in a structured and comprehensive way. We describe
the proposed methods by analyzing the technical perspectives of the different
approaches and discussing the performance results on the FEVER dataset, which
is the most well-studied and formally structured dataset on the fact extraction
and verification task. We also conduct the largest experimental study to date
on identifying beneficial loss functions for the sentence retrieval component.
Our analysis indicates that sampling negative sentences is important for
improving the performance and decreasing the computational complexity. Finally,
we describe open issues and future challenges, and we motivate future research
in the task.",author preprint version,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.03001v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.03001v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.03001v4,"{'id': 'http://arxiv.org/abs/2010.03001v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.03001v4', 'updated': '2021-08-24T15:40:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=15, tm_min=40, tm_sec=14, tm_wday=1, tm_yday=236, tm_isdst=0), 'published': '2020-10-06T20:05:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=6, tm_hour=20, tm_min=5, tm_sec=43, tm_wday=1, tm_yday=280, tm_isdst=0), 'title': 'A Review on Fact Extraction and Verification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Review on Fact Extraction and Verification'}, 'summary': 'We study the fact checking problem, which aims to identify the veracity of a\ngiven claim. Specifically, we focus on the task of Fact Extraction and\nVERification (FEVER) and its accompanied dataset. The task consists of the\nsubtasks of retrieving the relevant documents (and sentences) from Wikipedia\nand validating whether the information in the documents supports or refutes a\ngiven claim. This task is essential and can be the building block of\napplications such as fake news detection and medical claim verification. In\nthis paper, we aim at a better understanding of the challenges of the task by\npresenting the literature in a structured and comprehensive way. We describe\nthe proposed methods by analyzing the technical perspectives of the different\napproaches and discussing the performance results on the FEVER dataset, which\nis the most well-studied and formally structured dataset on the fact extraction\nand verification task. We also conduct the largest experimental study to date\non identifying beneficial loss functions for the sentence retrieval component.\nOur analysis indicates that sampling negative sentences is important for\nimproving the performance and decreasing the computational complexity. Finally,\nwe describe open issues and future challenges, and we motivate future research\nin the task.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We study the fact checking problem, which aims to identify the veracity of a\ngiven claim. Specifically, we focus on the task of Fact Extraction and\nVERification (FEVER) and its accompanied dataset. The task consists of the\nsubtasks of retrieving the relevant documents (and sentences) from Wikipedia\nand validating whether the information in the documents supports or refutes a\ngiven claim. This task is essential and can be the building block of\napplications such as fake news detection and medical claim verification. In\nthis paper, we aim at a better understanding of the challenges of the task by\npresenting the literature in a structured and comprehensive way. We describe\nthe proposed methods by analyzing the technical perspectives of the different\napproaches and discussing the performance results on the FEVER dataset, which\nis the most well-studied and formally structured dataset on the fact extraction\nand verification task. We also conduct the largest experimental study to date\non identifying beneficial loss functions for the sentence retrieval component.\nOur analysis indicates that sampling negative sentences is important for\nimproving the performance and decreasing the computational complexity. Finally,\nwe describe open issues and future challenges, and we motivate future research\nin the task.'}, 'authors': [{'name': 'Giannis Bekoulis'}, {'name': 'Christina Papagiannopoulou'}, {'name': 'Nikos Deligiannis'}], 'author_detail': {'name': 'Nikos Deligiannis'}, 'author': 'Nikos Deligiannis', 'arxiv_comment': 'author preprint version', 'links': [{'href': 'http://arxiv.org/abs/2010.03001v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.03001v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
168,http://arxiv.org/abs/2010.02150v1,2020-10-05 16:55:39+00:00,2020-10-05 16:55:39+00:00,Viable Threat on News Reading: Generating Biased News Using Natural Language Models,"[arxiv.Result.Author('Saurabh Gupta'), arxiv.Result.Author('Huy H. Nguyen'), arxiv.Result.Author('Junichi Yamagishi'), arxiv.Result.Author('Isao Echizen')]","Recent advancements in natural language generation has raised serious
concerns. High-performance language models are widely used for language
generation tasks because they are able to produce fluent and meaningful
sentences. These models are already being used to create fake news. They can
also be exploited to generate biased news, which can then be used to attack
news aggregators to change their reader's behavior and influence their bias. In
this paper, we use a threat model to demonstrate that the publicly available
language models can reliably generate biased news content based on an input
original news. We also show that a large number of high-quality biased news
articles can be generated using controllable text generation. A subjective
evaluation with 80 participants demonstrated that the generated biased news is
generally fluent, and a bias evaluation with 24 participants demonstrated that
the bias (left or right) is usually evident in the generated articles and can
be easily identified.","11 pages, 4 figures, 6 tables, Accepted at NLP+CSS Workshop at EMNLP
  2020",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.02150v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.02150v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.02150v1,"{'id': 'http://arxiv.org/abs/2010.02150v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.02150v1', 'updated': '2020-10-05T16:55:39Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=16, tm_min=55, tm_sec=39, tm_wday=0, tm_yday=279, tm_isdst=0), 'published': '2020-10-05T16:55:39Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=16, tm_min=55, tm_sec=39, tm_wday=0, tm_yday=279, tm_isdst=0), 'title': 'Viable Threat on News Reading: Generating Biased News Using Natural\n  Language Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Viable Threat on News Reading: Generating Biased News Using Natural\n  Language Models'}, 'summary': ""Recent advancements in natural language generation has raised serious\nconcerns. High-performance language models are widely used for language\ngeneration tasks because they are able to produce fluent and meaningful\nsentences. These models are already being used to create fake news. They can\nalso be exploited to generate biased news, which can then be used to attack\nnews aggregators to change their reader's behavior and influence their bias. In\nthis paper, we use a threat model to demonstrate that the publicly available\nlanguage models can reliably generate biased news content based on an input\noriginal news. We also show that a large number of high-quality biased news\narticles can be generated using controllable text generation. A subjective\nevaluation with 80 participants demonstrated that the generated biased news is\ngenerally fluent, and a bias evaluation with 24 participants demonstrated that\nthe bias (left or right) is usually evident in the generated articles and can\nbe easily identified."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recent advancements in natural language generation has raised serious\nconcerns. High-performance language models are widely used for language\ngeneration tasks because they are able to produce fluent and meaningful\nsentences. These models are already being used to create fake news. They can\nalso be exploited to generate biased news, which can then be used to attack\nnews aggregators to change their reader's behavior and influence their bias. In\nthis paper, we use a threat model to demonstrate that the publicly available\nlanguage models can reliably generate biased news content based on an input\noriginal news. We also show that a large number of high-quality biased news\narticles can be generated using controllable text generation. A subjective\nevaluation with 80 participants demonstrated that the generated biased news is\ngenerally fluent, and a bias evaluation with 24 participants demonstrated that\nthe bias (left or right) is usually evident in the generated articles and can\nbe easily identified.""}, 'authors': [{'name': 'Saurabh Gupta'}, {'name': 'Huy H. Nguyen'}, {'name': 'Junichi Yamagishi'}, {'name': 'Isao Echizen'}], 'author_detail': {'name': 'Isao Echizen'}, 'author': 'Isao Echizen', 'arxiv_comment': '11 pages, 4 figures, 6 tables, Accepted at NLP+CSS Workshop at EMNLP\n  2020', 'links': [{'href': 'http://arxiv.org/abs/2010.02150v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.02150v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
169,http://arxiv.org/abs/2010.02097v1,2020-10-05 15:34:52+00:00,2020-10-05 15:34:52+00:00,FaNDS: Fake News Detection System Using Energy Flow,"[arxiv.Result.Author('Jiawei Xu'), arxiv.Result.Author('Vladimir Zadorozhny'), arxiv.Result.Author('Danchen Zhang'), arxiv.Result.Author('John Grant')]","Recently, the term ""fake news"" has been broadly and extensively utilized for
disinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,
and junk news. It has become a serious problem around the world. We present a
new system, FaNDS, that detects fake news efficiently. The system is based on
several concepts used in some previous works but in a different context. There
are two main concepts: an Inconsistency Graph and Energy Flow. The
Inconsistency Graph contains news items as nodes and inconsistent opinions
between them for edges. Energy Flow assigns each node an initial energy and
then some energy is propagated along the edges until the energy distribution on
all nodes converges. To illustrate FaNDS we use the original data from the Fake
News Challenge (FNC-1). First, the data has to be reconstructed in order to
generate the Inconsistency Graph. The graph contains various subgraphs with
well-defined shapes that represent different types of connections between the
news items. Then the Energy Flow method is applied. The nodes with high energy
are the candidates for being fake news. In our experiments, all these were
indeed fake news as we checked each using several reliable web sites. We
compared FaNDS to several other fake news detection methods and found it to be
more sensitive in discovering fake news items.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.02097v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.02097v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.02097v1,"{'id': 'http://arxiv.org/abs/2010.02097v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.02097v1', 'updated': '2020-10-05T15:34:52Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=15, tm_min=34, tm_sec=52, tm_wday=0, tm_yday=279, tm_isdst=0), 'published': '2020-10-05T15:34:52Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=15, tm_min=34, tm_sec=52, tm_wday=0, tm_yday=279, tm_isdst=0), 'title': 'FaNDS: Fake News Detection System Using Energy Flow', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FaNDS: Fake News Detection System Using Energy Flow'}, 'summary': 'Recently, the term ""fake news"" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, the term ""fake news"" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.'}, 'authors': [{'name': 'Jiawei Xu'}, {'name': 'Vladimir Zadorozhny'}, {'name': 'Danchen Zhang'}, {'name': 'John Grant'}], 'author_detail': {'name': 'John Grant'}, 'author': 'John Grant', 'links': [{'href': 'http://arxiv.org/abs/2010.02097v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.02097v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
170,http://arxiv.org/abs/2009.13859v1,2020-09-29 08:32:32+00:00,2020-09-29 08:32:32+00:00,Fake News Spreader Detection on Twitter using Character N-Grams. Notebook for PAN at CLEF 2020,"[arxiv.Result.Author('Inna Vogel'), arxiv.Result.Author('Meghana Meghana')]","The authors of fake news often use facts from verified news sources and mix
them with misinformation to create confusion and provoke unrest among the
readers. The spread of fake news can thereby have serious implications on our
society. They can sway political elections, push down the stock price or crush
reputations of corporations or public figures. Several websites have taken on
the mission of checking rumors and allegations, but are often not fast enough
to check the content of all the news being disseminated. Especially social
media websites have offered an easy platform for the fast propagation of
information. Towards limiting fake news from being propagated among social
media users, the task of this year's PAN 2020 challenge lays the focus on the
fake news spreaders. The aim of the task is to determine whether it is possible
to discriminate authors that have shared fake news in the past from those that
have never done it. In this notebook, we describe our profiling system for the
fake news detection task on Twitter. For this, we conduct different feature
extraction techniques and learning experiments from a multilingual perspective,
namely English and Spanish. Our final submitted systems use character n-grams
as features in combination with a linear SVM for English and Logistic
Regression for the Spanish language. Our submitted models achieve an overall
accuracy of 73% and 79% on the English and Spanish official test set,
respectively. Our experiments show that it is difficult to differentiate
solidly fake news spreaders on Twitter from users who share credible
information leaving room for further investigations. Our model ranked 3rd out
of 72 competitors.","CLEF 2020 Labs and Workshops, Notebook Papers",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2009.13859v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.13859v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.13859v1,"{'id': 'http://arxiv.org/abs/2009.13859v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.13859v1', 'updated': '2020-09-29T08:32:32Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=29, tm_hour=8, tm_min=32, tm_sec=32, tm_wday=1, tm_yday=273, tm_isdst=0), 'published': '2020-09-29T08:32:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=29, tm_hour=8, tm_min=32, tm_sec=32, tm_wday=1, tm_yday=273, tm_isdst=0), 'title': 'Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020'}, 'summary': ""The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.""}, 'authors': [{'name': 'Inna Vogel'}, {'name': 'Meghana Meghana'}], 'author_detail': {'name': 'Meghana Meghana'}, 'author': 'Meghana Meghana', 'arxiv_comment': 'CLEF 2020 Labs and Workshops, Notebook Papers', 'links': [{'href': 'http://arxiv.org/abs/2009.13859v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.13859v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
171,http://arxiv.org/abs/2009.13367v2,2021-03-01 12:32:57+00:00,2020-09-28 14:35:31+00:00,Similarity Detection Pipeline for Crawling a Topic Related Fake News Corpus,"[arxiv.Result.Author('Inna Vogel'), arxiv.Result.Author('Jeong-Eun Choi'), arxiv.Result.Author('Meghana Meghana')]","Fake news detection is a challenging task aiming to reduce human time and
effort to check the truthfulness of news. Automated approaches to combat fake
news, however, are limited by the lack of labeled benchmark datasets,
especially in languages other than English. Moreover, many publicly available
corpora have specific limitations that make them difficult to use. To address
this problem, our contribution is threefold. First, we propose a new, publicly
available German topic related corpus for fake news detection. To the best of
our knowledge, this is the first corpus of its kind. In this regard, we
developed a pipeline for crawling similar news articles. As our third
contribution, we conduct different learning experiments to detect fake news.
The best performance was achieved using sentence level embeddings from SBERT in
combination with a Bi-LSTM (k=0.88).",Further development done,,,cs.CL,"['cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2009.13367v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.13367v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.13367v2,"{'id': 'http://arxiv.org/abs/2009.13367v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.13367v2', 'updated': '2021-03-01T12:32:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=12, tm_min=32, tm_sec=57, tm_wday=0, tm_yday=60, tm_isdst=0), 'published': '2020-09-28T14:35:31Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=28, tm_hour=14, tm_min=35, tm_sec=31, tm_wday=0, tm_yday=272, tm_isdst=0), 'title': 'Similarity Detection Pipeline for Crawling a Topic Related Fake News\n  Corpus', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Similarity Detection Pipeline for Crawling a Topic Related Fake News\n  Corpus'}, 'summary': 'Fake news detection is a challenging task aiming to reduce human time and\neffort to check the truthfulness of news. Automated approaches to combat fake\nnews, however, are limited by the lack of labeled benchmark datasets,\nespecially in languages other than English. Moreover, many publicly available\ncorpora have specific limitations that make them difficult to use. To address\nthis problem, our contribution is threefold. First, we propose a new, publicly\navailable German topic related corpus for fake news detection. To the best of\nour knowledge, this is the first corpus of its kind. In this regard, we\ndeveloped a pipeline for crawling similar news articles. As our third\ncontribution, we conduct different learning experiments to detect fake news.\nThe best performance was achieved using sentence level embeddings from SBERT in\ncombination with a Bi-LSTM (k=0.88).', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news detection is a challenging task aiming to reduce human time and\neffort to check the truthfulness of news. Automated approaches to combat fake\nnews, however, are limited by the lack of labeled benchmark datasets,\nespecially in languages other than English. Moreover, many publicly available\ncorpora have specific limitations that make them difficult to use. To address\nthis problem, our contribution is threefold. First, we propose a new, publicly\navailable German topic related corpus for fake news detection. To the best of\nour knowledge, this is the first corpus of its kind. In this regard, we\ndeveloped a pipeline for crawling similar news articles. As our third\ncontribution, we conduct different learning experiments to detect fake news.\nThe best performance was achieved using sentence level embeddings from SBERT in\ncombination with a Bi-LSTM (k=0.88).'}, 'authors': [{'name': 'Inna Vogel'}, {'name': 'Jeong-Eun Choi'}, {'name': 'Meghana Meghana'}], 'author_detail': {'name': 'Meghana Meghana'}, 'author': 'Meghana Meghana', 'arxiv_comment': 'Further development done', 'links': [{'href': 'http://arxiv.org/abs/2009.13367v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.13367v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
172,http://arxiv.org/abs/2009.07698v5,2020-10-21 15:16:20+00:00,2020-09-16 14:13:15+00:00,Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News,"[arxiv.Result.Author('Reuben Tan'), arxiv.Result.Author('Bryan A. Plummer'), arxiv.Result.Author('Kate Saenko')]","Large-scale dissemination of disinformation online intended to mislead or
deceive the general population is a major societal problem. Rapid progression
in image, video, and natural language generative models has only exacerbated
this situation and intensified our need for an effective defense mechanism.
While existing approaches have been proposed to defend against neural fake
news, they are generally constrained to the very limited setting where articles
only have text and metadata such as the title and authors. In this paper, we
introduce the more realistic and challenging task of defending against
machine-generated news that also includes images and captions. To identify the
possible weaknesses that adversaries can exploit, we create a NeuralNews
dataset composed of 4 different types of generated articles as well as conduct
a series of human user study experiments based on this dataset. In addition to
the valuable insights gleaned from our user study experiments, we provide a
relatively effective approach based on detecting visual-semantic
inconsistencies, which will serve as an effective first line of defense and a
useful reference for future work in defending against machine-generated
disinformation.",Accepted at EMNLP 2020,,,cs.AI,"['cs.AI', 'cs.CL', 'cs.CV']","[arxiv.Result.Link('http://arxiv.org/abs/2009.07698v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.07698v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.07698v5,"{'id': 'http://arxiv.org/abs/2009.07698v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.07698v5', 'updated': '2020-10-21T15:16:20Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=21, tm_hour=15, tm_min=16, tm_sec=20, tm_wday=2, tm_yday=295, tm_isdst=0), 'published': '2020-09-16T14:13:15Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=16, tm_hour=14, tm_min=13, tm_sec=15, tm_wday=2, tm_yday=260, tm_isdst=0), 'title': 'Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News'}, 'summary': 'Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.'}, 'authors': [{'name': 'Reuben Tan'}, {'name': 'Bryan A. Plummer'}, {'name': 'Kate Saenko'}], 'author_detail': {'name': 'Kate Saenko'}, 'author': 'Kate Saenko', 'arxiv_comment': 'Accepted at EMNLP 2020', 'links': [{'href': 'http://arxiv.org/abs/2009.07698v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.07698v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
173,http://arxiv.org/abs/2009.02275v2,2020-09-18 04:16:04+00:00,2020-09-04 16:16:27+00:00,Controlling Fake News by Tagging: A Branching Process Analysis,"[arxiv.Result.Author('Suyog Kapsikar'), arxiv.Result.Author('Indrajit Saha'), arxiv.Result.Author('Khushboo Agarwal'), arxiv.Result.Author('Veeraruna Kavitha'), arxiv.Result.Author('Quanyan Zhu')]","The spread of fake news, especially on online social networks, has become a
matter of concern in the last few years. These platforms are also used for
propagating other important authentic information. Thus, there is a need for
mitigating fake news without significantly influencing the spread of real news.
We leverage user's inherent capabilities of identifying fake news and propose a
warning-based control mechanism to curb this spread. Warnings are based on
previous users' responses that indicate the authenticity of the news.
  We use population-size dependent continuous-time multi-type branching
processes to describe the spreading under the warning mechanism. We also have
new results towards these branching processes. The (time) asymptotic
proportions of the individual populations are derived. These results are
instrumental in deriving relevant type-1, type-2 performance measures, and
formulating an optimization problem to design optimal warning parameters. The
fraction of copies tagged as real (fake) are considered for the type-1 (type-2)
performance.
  We derive structural properties of the performance, which help simplify the
optimization problem. We finally demonstrate that the optimal warning mechanism
effectively mitigates fake news, with negligible influences on the propagation
of authentic news. We validate performance measures using Monte Carlo
simulations on ego-network database related to Twitter.","We revised the paper with 1 additional Theorem. The updated paper has
  8 pages, 1 table and 5 figures",,,cs.SI,"['cs.SI', 'math.PR']","[arxiv.Result.Link('http://arxiv.org/abs/2009.02275v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.02275v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.02275v2,"{'id': 'http://arxiv.org/abs/2009.02275v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.02275v2', 'updated': '2020-09-18T04:16:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=18, tm_hour=4, tm_min=16, tm_sec=4, tm_wday=4, tm_yday=262, tm_isdst=0), 'published': '2020-09-04T16:16:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=4, tm_hour=16, tm_min=16, tm_sec=27, tm_wday=4, tm_yday=248, tm_isdst=0), 'title': 'Controlling Fake News by Tagging: A Branching Process Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Controlling Fake News by Tagging: A Branching Process Analysis'}, 'summary': ""The spread of fake news, especially on online social networks, has become a\nmatter of concern in the last few years. These platforms are also used for\npropagating other important authentic information. Thus, there is a need for\nmitigating fake news without significantly influencing the spread of real news.\nWe leverage user's inherent capabilities of identifying fake news and propose a\nwarning-based control mechanism to curb this spread. Warnings are based on\nprevious users' responses that indicate the authenticity of the news.\n  We use population-size dependent continuous-time multi-type branching\nprocesses to describe the spreading under the warning mechanism. We also have\nnew results towards these branching processes. The (time) asymptotic\nproportions of the individual populations are derived. These results are\ninstrumental in deriving relevant type-1, type-2 performance measures, and\nformulating an optimization problem to design optimal warning parameters. The\nfraction of copies tagged as real (fake) are considered for the type-1 (type-2)\nperformance.\n  We derive structural properties of the performance, which help simplify the\noptimization problem. We finally demonstrate that the optimal warning mechanism\neffectively mitigates fake news, with negligible influences on the propagation\nof authentic news. We validate performance measures using Monte Carlo\nsimulations on ego-network database related to Twitter."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The spread of fake news, especially on online social networks, has become a\nmatter of concern in the last few years. These platforms are also used for\npropagating other important authentic information. Thus, there is a need for\nmitigating fake news without significantly influencing the spread of real news.\nWe leverage user's inherent capabilities of identifying fake news and propose a\nwarning-based control mechanism to curb this spread. Warnings are based on\nprevious users' responses that indicate the authenticity of the news.\n  We use population-size dependent continuous-time multi-type branching\nprocesses to describe the spreading under the warning mechanism. We also have\nnew results towards these branching processes. The (time) asymptotic\nproportions of the individual populations are derived. These results are\ninstrumental in deriving relevant type-1, type-2 performance measures, and\nformulating an optimization problem to design optimal warning parameters. The\nfraction of copies tagged as real (fake) are considered for the type-1 (type-2)\nperformance.\n  We derive structural properties of the performance, which help simplify the\noptimization problem. We finally demonstrate that the optimal warning mechanism\neffectively mitigates fake news, with negligible influences on the propagation\nof authentic news. We validate performance measures using Monte Carlo\nsimulations on ego-network database related to Twitter.""}, 'authors': [{'name': 'Suyog Kapsikar'}, {'name': 'Indrajit Saha'}, {'name': 'Khushboo Agarwal'}, {'name': 'Veeraruna Kavitha'}, {'name': 'Quanyan Zhu'}], 'author_detail': {'name': 'Quanyan Zhu'}, 'author': 'Quanyan Zhu', 'arxiv_comment': 'We revised the paper with 1 additional Theorem. The updated paper has\n  8 pages, 1 table and 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2009.02275v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.02275v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
174,http://arxiv.org/abs/2009.01267v1,2020-09-02 18:04:00+00:00,2020-09-02 18:04:00+00:00,COVID-19: The Information Warfare Paradigm Shift,"[arxiv.Result.Author('Jan Kallberg'), arxiv.Result.Author('Rosemary A. Burk'), arxiv.Result.Author('Bhavani Thuraisingham')]","In Kuhn's The Structure of Scientific Revolutions, the critical term is
paradigm-shift when it suddenly becomes evident that earlier assumptions no
longer are correct and the plurality of the scientific community that studies
this domain accepts the change. These types of events can be scientific
findings or as in social science system shock that creates a punctured
equilibrium that sets the stage in the developments. In information warfare,
recent years studies and government lines of efforts have been to engage fake
news, electoral interference, and fight extremist social media as the primary
combat theater in the information space, and the tools to influence a targeted
audience. The COVID-19 pandemic generates a rebuttal of these assumptions. Even
if fake news and extremist social media content may exploit fault lines in our
society and create a civil disturbance, tensions between federal and local
government, and massive protests, it is still effects that impact a part of the
population. What we have seen with COVID-19, as an indicator, is that what is
related to public health is far more powerful to swing public sentiment and
create reactions within the citizenry that are trigger impact at a larger
magnitude that has rippled through society in multiple directions.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2009.01267v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.01267v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.01267v1,"{'id': 'http://arxiv.org/abs/2009.01267v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.01267v1', 'updated': '2020-09-02T18:04:00Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=2, tm_hour=18, tm_min=4, tm_sec=0, tm_wday=2, tm_yday=246, tm_isdst=0), 'published': '2020-09-02T18:04:00Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=2, tm_hour=18, tm_min=4, tm_sec=0, tm_wday=2, tm_yday=246, tm_isdst=0), 'title': 'COVID-19: The Information Warfare Paradigm Shift', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19: The Information Warfare Paradigm Shift'}, 'summary': ""In Kuhn's The Structure of Scientific Revolutions, the critical term is\nparadigm-shift when it suddenly becomes evident that earlier assumptions no\nlonger are correct and the plurality of the scientific community that studies\nthis domain accepts the change. These types of events can be scientific\nfindings or as in social science system shock that creates a punctured\nequilibrium that sets the stage in the developments. In information warfare,\nrecent years studies and government lines of efforts have been to engage fake\nnews, electoral interference, and fight extremist social media as the primary\ncombat theater in the information space, and the tools to influence a targeted\naudience. The COVID-19 pandemic generates a rebuttal of these assumptions. Even\nif fake news and extremist social media content may exploit fault lines in our\nsociety and create a civil disturbance, tensions between federal and local\ngovernment, and massive protests, it is still effects that impact a part of the\npopulation. What we have seen with COVID-19, as an indicator, is that what is\nrelated to public health is far more powerful to swing public sentiment and\ncreate reactions within the citizenry that are trigger impact at a larger\nmagnitude that has rippled through society in multiple directions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In Kuhn's The Structure of Scientific Revolutions, the critical term is\nparadigm-shift when it suddenly becomes evident that earlier assumptions no\nlonger are correct and the plurality of the scientific community that studies\nthis domain accepts the change. These types of events can be scientific\nfindings or as in social science system shock that creates a punctured\nequilibrium that sets the stage in the developments. In information warfare,\nrecent years studies and government lines of efforts have been to engage fake\nnews, electoral interference, and fight extremist social media as the primary\ncombat theater in the information space, and the tools to influence a targeted\naudience. The COVID-19 pandemic generates a rebuttal of these assumptions. Even\nif fake news and extremist social media content may exploit fault lines in our\nsociety and create a civil disturbance, tensions between federal and local\ngovernment, and massive protests, it is still effects that impact a part of the\npopulation. What we have seen with COVID-19, as an indicator, is that what is\nrelated to public health is far more powerful to swing public sentiment and\ncreate reactions within the citizenry that are trigger impact at a larger\nmagnitude that has rippled through society in multiple directions.""}, 'authors': [{'name': 'Jan Kallberg'}, {'name': 'Rosemary A. Burk'}, {'name': 'Bhavani Thuraisingham'}], 'author_detail': {'name': 'Bhavani Thuraisingham'}, 'author': 'Bhavani Thuraisingham', 'links': [{'href': 'http://arxiv.org/abs/2009.01267v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.01267v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
175,http://arxiv.org/abs/2009.01047v2,2020-10-22 04:57:21+00:00,2020-09-01 02:48:11+00:00,Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake Claim Classification,"[arxiv.Result.Author('Bibek Upadhayay'), arxiv.Result.Author('Vahid Behzadan')]","The rampant integration of social media in our every day lives and culture
has given rise to fast and easier access to the flow of information than ever
in human history. However, the inherently unsupervised nature of social media
platforms has also made it easier to spread false information and fake news.
Furthermore, the high volume and velocity of information flow in such platforms
make manual supervision and control of information propagation infeasible. This
paper aims to address this issue by proposing a novel deep learning approach
for automated detection of false short-text claims on social media. We first
introduce Sentimental LIAR, which extends the LIAR dataset of short claims by
adding features based on sentiment and emotion analysis of claims. Furthermore,
we propose a novel deep learning architecture based on the BERT-Base language
model for classification of claims as genuine or fake. Our results demonstrate
that the proposed architecture trained on Sentimental LIAR can achieve an
accuracy of 70%, which is an improvement of ~30% over previously reported
results for the LIAR benchmark.",Accepted for publication in the proceedings of IEEE ISI '20,,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2009.01047v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.01047v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.01047v2,"{'id': 'http://arxiv.org/abs/2009.01047v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.01047v2', 'updated': '2020-10-22T04:57:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=22, tm_hour=4, tm_min=57, tm_sec=21, tm_wday=3, tm_yday=296, tm_isdst=0), 'published': '2020-09-01T02:48:11Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=1, tm_hour=2, tm_min=48, tm_sec=11, tm_wday=1, tm_yday=245, tm_isdst=0), 'title': 'Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification'}, 'summary': 'The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.'}, 'authors': [{'name': 'Bibek Upadhayay'}, {'name': 'Vahid Behzadan'}], 'author_detail': {'name': 'Vahid Behzadan'}, 'author': 'Vahid Behzadan', 'arxiv_comment': ""Accepted for publication in the proceedings of IEEE ISI '20"", 'links': [{'href': 'http://arxiv.org/abs/2009.01047v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.01047v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
176,http://arxiv.org/abs/2009.01048v2,2020-09-27 10:15:06+00:00,2020-09-01 01:26:01+00:00,MALCOM: Generating Malicious Comments to Attack Neural Fake News Detection Models,"[arxiv.Result.Author('Thai Le'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Dongwon Lee')]","In recent years, the proliferation of so-called ""fake news"" has caused much
disruptions in society and weakened the news ecosystem. Therefore, to mitigate
such problems, researchers have developed state-of-the-art models to
auto-detect fake news on social media using sophisticated data science and
machine learning techniques. In this work, then, we ask ""what if adversaries
attempt to attack such detection models?"" and investigate related issues by (i)
proposing a novel threat model against fake news detectors, in which
adversaries can post malicious comments toward news articles to mislead fake
news detectors, and (ii) developing MALCOM, an end-to-end adversarial comment
generation framework to achieve such an attack. Through a comprehensive
evaluation, we demonstrate that about 94% and 93.5% of the time on average
MALCOM can successfully mislead five of the latest neural detection models to
always output targeted real and fake news labels. Furthermore, MALCOM can also
fool black box fake news detectors to always output real news labels 90% of the
time on average. We also compare our attack model with four baselines across
two real-world datasets, not only on attack performance but also on generated
quality, coherency, transferability, and robustness.","Accepted at the 20th IEEE International Conference on Data Mining
  (ICDM 2020)",,,cs.CL,"['cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2009.01048v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.01048v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.01048v2,"{'id': 'http://arxiv.org/abs/2009.01048v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.01048v2', 'updated': '2020-09-27T10:15:06Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=27, tm_hour=10, tm_min=15, tm_sec=6, tm_wday=6, tm_yday=271, tm_isdst=0), 'published': '2020-09-01T01:26:01Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=1, tm_hour=1, tm_min=26, tm_sec=1, tm_wday=1, tm_yday=245, tm_isdst=0), 'title': 'MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models'}, 'summary': 'In recent years, the proliferation of so-called ""fake news"" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask ""what if adversaries\nattempt to attack such detection models?"" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, the proliferation of so-called ""fake news"" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask ""what if adversaries\nattempt to attack such detection models?"" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.'}, 'authors': [{'name': 'Thai Le'}, {'name': 'Suhang Wang'}, {'name': 'Dongwon Lee'}], 'author_detail': {'name': 'Dongwon Lee'}, 'author': 'Dongwon Lee', 'arxiv_comment': 'Accepted at the 20th IEEE International Conference on Data Mining\n  (ICDM 2020)', 'links': [{'href': 'http://arxiv.org/abs/2009.01048v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.01048v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
177,http://arxiv.org/abs/2008.13160v1,2020-08-30 13:03:53+00:00,2020-08-30 13:03:53+00:00,QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness Using an Enhanced CT-BERT with Numeric Expressions,"[arxiv.Result.Author('Rabab Alkhalifa'), arxiv.Result.Author('Theodore Yoong'), arxiv.Result.Author('Elena Kochkina'), arxiv.Result.Author('Arkaitz Zubiaga'), arxiv.Result.Author('Maria Liakata')]","This paper describes the participation of the QMUL-SDS team for Task 1 of the
CLEF 2020 CheckThat! shared task. The purpose of this task is to determine the
check-worthiness of tweets about COVID-19 to identify and prioritise tweets
that need fact-checking. The overarching aim is to further support ongoing
efforts to protect the public from fake news and help people find reliable
information. We describe and analyse the results of our submissions. We show
that a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions
can effectively boost performance from baseline results. We also show results
of training data augmentation with rumours on other topics. Our best system
ranked fourth in the task with encouraging outcomes showing potential for
improved results in the future.",,,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2008.13160v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.13160v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.13160v1,"{'id': 'http://arxiv.org/abs/2008.13160v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.13160v1', 'updated': '2020-08-30T13:03:53Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=13, tm_min=3, tm_sec=53, tm_wday=6, tm_yday=243, tm_isdst=0), 'published': '2020-08-30T13:03:53Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=13, tm_min=3, tm_sec=53, tm_wday=6, tm_yday=243, tm_isdst=0), 'title': 'QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions'}, 'summary': 'This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.'}, 'authors': [{'name': 'Rabab Alkhalifa'}, {'name': 'Theodore Yoong'}, {'name': 'Elena Kochkina'}, {'name': 'Arkaitz Zubiaga'}, {'name': 'Maria Liakata'}], 'author_detail': {'name': 'Maria Liakata'}, 'author': 'Maria Liakata', 'links': [{'href': 'http://arxiv.org/abs/2008.13160v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.13160v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
178,http://arxiv.org/abs/2008.12742v1,2020-08-28 16:55:43+00:00,2020-08-28 16:55:43+00:00,Linked Credibility Reviews for Explainable Misinformation Detection,"[arxiv.Result.Author('Ronald Denaux'), arxiv.Result.Author('Jose Manuel Gomez-Perez')]","In recent years, misinformation on the Web has become increasingly rampant.
The research community has responded by proposing systems and challenges, which
are beginning to be useful for (various subtasks of) detecting misinformation.
However, most proposed systems are based on deep learning techniques which are
fine-tuned to specific domains, are difficult to interpret and produce results
which are not machine readable. This limits their applicability and adoption as
they can only be used by a select expert audience in very specific settings. In
this paper we propose an architecture based on a core concept of Credibility
Reviews (CRs) that can be used to build networks of distributed bots that
collaborate for misinformation detection. The CRs serve as building blocks to
compose graphs of (i) web content, (ii) existing credibility signals
--fact-checked claims and reputation reviews of websites--, and (iii)
automatically computed reviews. We implement this architecture on top of
lightweight extensions to Schema.org and services providing generic NLP tasks
for semantic similarity and stance detection. Evaluations on existing datasets
of social-media posts, fake news and political speeches demonstrates several
advantages over existing systems: extensibility, domain-independence,
composability, explainability and transparency via provenance. Furthermore, we
obtain competitive results without requiring finetuning and establish a new
state of the art on the Clef'18 CheckThat! Factuality task.","Accepted to the 19th International Semantic Web Conference (ISWC
  2020) https://iswc2020.semanticweb.org",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.DL']","[arxiv.Result.Link('http://arxiv.org/abs/2008.12742v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.12742v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.12742v1,"{'id': 'http://arxiv.org/abs/2008.12742v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.12742v1', 'updated': '2020-08-28T16:55:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=55, tm_sec=43, tm_wday=4, tm_yday=241, tm_isdst=0), 'published': '2020-08-28T16:55:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=55, tm_sec=43, tm_wday=4, tm_yday=241, tm_isdst=0), 'title': 'Linked Credibility Reviews for Explainable Misinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Linked Credibility Reviews for Explainable Misinformation Detection'}, 'summary': ""In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.""}, 'authors': [{'name': 'Ronald Denaux'}, {'name': 'Jose Manuel Gomez-Perez'}], 'author_detail': {'name': 'Jose Manuel Gomez-Perez'}, 'author': 'Jose Manuel Gomez-Perez', 'arxiv_comment': 'Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org', 'links': [{'href': 'http://arxiv.org/abs/2008.12742v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.12742v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
179,http://arxiv.org/abs/2008.12723v1,2020-08-28 16:20:36+00:00,2020-08-28 16:20:36+00:00,CD-SEIZ: Cognition-Driven SEIZ Compartmental Model for the Prediction of Information Cascades on Twitter,"[arxiv.Result.Author('Ece Çiğdem Mutlu'), arxiv.Result.Author('Amirarsalan Rajabi'), arxiv.Result.Author('Ivan Garibay')]","Information spreading social media platforms has become ubiquitous in our
lives due to viral information propagation regardless of its veracity. Some
information cascades turn out to be viral since they circulated rapidly on the
Internet. The uncontrollable virality of manipulated or disorientated true
information (fake news) might be quite harmful, while the spread of the true
news is advantageous, especially in emergencies. We tackle the problem of
predicting information cascades by presenting a novel variant of SEIZ
(Susceptible/ Exposed/ Infected/ Skeptics) model that outperforms the original
version by taking into account the cognitive processing depth of users. We
define an information cascade as the set of social media users' reactions to
the original content which requires at least minimal physical and cognitive
effort; therefore, we considered retweet/ reply/ quote (mention) activities and
tested our framework on the Syrian White Helmets Twitter data set from April
1st, 2018 to April 30th, 2019. In the prediction of cascade pattern via
traditional compartmental models, all the activities are grouped, and their
summation is taken into account; however, transition rates between compartments
should vary according to the activity type since their requirements of physical
and cognitive efforts are not same. Based on this assumption, we design a
cognition-driven SEIZ (CD-SEIZ) model in the prediction of information cascades
on Twitter. We tested SIS, SEIZ, and CD-SEIZ models on 1000 Twitter cascades
and found that CD-SEIZ has a significantly low fitting error and provides a
statistically more accurate estimation.",,,,cs.SI,"['cs.SI', 'cs.IT', 'math.IT']","[arxiv.Result.Link('http://arxiv.org/abs/2008.12723v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.12723v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.12723v1,"{'id': 'http://arxiv.org/abs/2008.12723v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.12723v1', 'updated': '2020-08-28T16:20:36Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=20, tm_sec=36, tm_wday=4, tm_yday=241, tm_isdst=0), 'published': '2020-08-28T16:20:36Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=20, tm_sec=36, tm_wday=4, tm_yday=241, tm_isdst=0), 'title': 'CD-SEIZ: Cognition-Driven SEIZ Compartmental Model for the Prediction of\n  Information Cascades on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CD-SEIZ: Cognition-Driven SEIZ Compartmental Model for the Prediction of\n  Information Cascades on Twitter'}, 'summary': ""Information spreading social media platforms has become ubiquitous in our\nlives due to viral information propagation regardless of its veracity. Some\ninformation cascades turn out to be viral since they circulated rapidly on the\nInternet. The uncontrollable virality of manipulated or disorientated true\ninformation (fake news) might be quite harmful, while the spread of the true\nnews is advantageous, especially in emergencies. We tackle the problem of\npredicting information cascades by presenting a novel variant of SEIZ\n(Susceptible/ Exposed/ Infected/ Skeptics) model that outperforms the original\nversion by taking into account the cognitive processing depth of users. We\ndefine an information cascade as the set of social media users' reactions to\nthe original content which requires at least minimal physical and cognitive\neffort; therefore, we considered retweet/ reply/ quote (mention) activities and\ntested our framework on the Syrian White Helmets Twitter data set from April\n1st, 2018 to April 30th, 2019. In the prediction of cascade pattern via\ntraditional compartmental models, all the activities are grouped, and their\nsummation is taken into account; however, transition rates between compartments\nshould vary according to the activity type since their requirements of physical\nand cognitive efforts are not same. Based on this assumption, we design a\ncognition-driven SEIZ (CD-SEIZ) model in the prediction of information cascades\non Twitter. We tested SIS, SEIZ, and CD-SEIZ models on 1000 Twitter cascades\nand found that CD-SEIZ has a significantly low fitting error and provides a\nstatistically more accurate estimation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Information spreading social media platforms has become ubiquitous in our\nlives due to viral information propagation regardless of its veracity. Some\ninformation cascades turn out to be viral since they circulated rapidly on the\nInternet. The uncontrollable virality of manipulated or disorientated true\ninformation (fake news) might be quite harmful, while the spread of the true\nnews is advantageous, especially in emergencies. We tackle the problem of\npredicting information cascades by presenting a novel variant of SEIZ\n(Susceptible/ Exposed/ Infected/ Skeptics) model that outperforms the original\nversion by taking into account the cognitive processing depth of users. We\ndefine an information cascade as the set of social media users' reactions to\nthe original content which requires at least minimal physical and cognitive\neffort; therefore, we considered retweet/ reply/ quote (mention) activities and\ntested our framework on the Syrian White Helmets Twitter data set from April\n1st, 2018 to April 30th, 2019. In the prediction of cascade pattern via\ntraditional compartmental models, all the activities are grouped, and their\nsummation is taken into account; however, transition rates between compartments\nshould vary according to the activity type since their requirements of physical\nand cognitive efforts are not same. Based on this assumption, we design a\ncognition-driven SEIZ (CD-SEIZ) model in the prediction of information cascades\non Twitter. We tested SIS, SEIZ, and CD-SEIZ models on 1000 Twitter cascades\nand found that CD-SEIZ has a significantly low fitting error and provides a\nstatistically more accurate estimation.""}, 'authors': [{'name': 'Ece Çiğdem Mutlu'}, {'name': 'Amirarsalan Rajabi'}, {'name': 'Ivan Garibay'}], 'author_detail': {'name': 'Ivan Garibay'}, 'author': 'Ivan Garibay', 'links': [{'href': 'http://arxiv.org/abs/2008.12723v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.12723v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
180,http://arxiv.org/abs/2008.10454v2,2020-09-04 07:55:11+00:00,2020-08-24 13:55:14+00:00,FOCAL: A Forgery Localization Framework based on Video Coding Self-Consistency,"[arxiv.Result.Author('Sebastiano Verde'), arxiv.Result.Author('Paolo Bestagini'), arxiv.Result.Author('Simone Milani'), arxiv.Result.Author('Giancarlo Calvagno'), arxiv.Result.Author('Stefano Tubaro')]","Forgery operations on video contents are nowadays within the reach of anyone,
thanks to the availability of powerful and user-friendly editing software.
Integrity verification and authentication of videos represent a major interest
in both journalism (e.g., fake news debunking) and legal environments dealing
with digital evidence (e.g., a court of law). While several strategies and
different forensics traces have been proposed in recent years, latest solutions
aim at increasing the accuracy by combining multiple detectors and features.
This paper presents a video forgery localization framework that verifies the
self-consistency of coding traces between and within video frames, by fusing
the information derived from a set of independent feature descriptors. The
feature extraction step is carried out by means of an explainable convolutional
neural network architecture, specifically designed to look for and classify
coding artifacts. The overall framework was validated in two typical forgery
scenarios: temporal and spatial splicing. Experimental results show an
improvement to the state-of-the-art on temporal splicing localization and also
promising performance in the newly tackled case of spatial splicing, on both
synthetic and real-world videos.",,,10.1109/OJSP.2021.3074298,cs.CV,"['cs.CV', 'eess.IV']","[arxiv.Result.Link('http://dx.doi.org/10.1109/OJSP.2021.3074298', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.10454v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.10454v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.10454v2,"{'id': 'http://arxiv.org/abs/2008.10454v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.10454v2', 'updated': '2020-09-04T07:55:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=4, tm_hour=7, tm_min=55, tm_sec=11, tm_wday=4, tm_yday=248, tm_isdst=0), 'published': '2020-08-24T13:55:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=24, tm_hour=13, tm_min=55, tm_sec=14, tm_wday=0, tm_yday=237, tm_isdst=0), 'title': 'FOCAL: A Forgery Localization Framework based on Video Coding\n  Self-Consistency', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FOCAL: A Forgery Localization Framework based on Video Coding\n  Self-Consistency'}, 'summary': 'Forgery operations on video contents are nowadays within the reach of anyone,\nthanks to the availability of powerful and user-friendly editing software.\nIntegrity verification and authentication of videos represent a major interest\nin both journalism (e.g., fake news debunking) and legal environments dealing\nwith digital evidence (e.g., a court of law). While several strategies and\ndifferent forensics traces have been proposed in recent years, latest solutions\naim at increasing the accuracy by combining multiple detectors and features.\nThis paper presents a video forgery localization framework that verifies the\nself-consistency of coding traces between and within video frames, by fusing\nthe information derived from a set of independent feature descriptors. The\nfeature extraction step is carried out by means of an explainable convolutional\nneural network architecture, specifically designed to look for and classify\ncoding artifacts. The overall framework was validated in two typical forgery\nscenarios: temporal and spatial splicing. Experimental results show an\nimprovement to the state-of-the-art on temporal splicing localization and also\npromising performance in the newly tackled case of spatial splicing, on both\nsynthetic and real-world videos.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Forgery operations on video contents are nowadays within the reach of anyone,\nthanks to the availability of powerful and user-friendly editing software.\nIntegrity verification and authentication of videos represent a major interest\nin both journalism (e.g., fake news debunking) and legal environments dealing\nwith digital evidence (e.g., a court of law). While several strategies and\ndifferent forensics traces have been proposed in recent years, latest solutions\naim at increasing the accuracy by combining multiple detectors and features.\nThis paper presents a video forgery localization framework that verifies the\nself-consistency of coding traces between and within video frames, by fusing\nthe information derived from a set of independent feature descriptors. The\nfeature extraction step is carried out by means of an explainable convolutional\nneural network architecture, specifically designed to look for and classify\ncoding artifacts. The overall framework was validated in two typical forgery\nscenarios: temporal and spatial splicing. Experimental results show an\nimprovement to the state-of-the-art on temporal splicing localization and also\npromising performance in the newly tackled case of spatial splicing, on both\nsynthetic and real-world videos.'}, 'authors': [{'name': 'Sebastiano Verde'}, {'name': 'Paolo Bestagini'}, {'name': 'Simone Milani'}, {'name': 'Giancarlo Calvagno'}, {'name': 'Stefano Tubaro'}], 'author_detail': {'name': 'Stefano Tubaro'}, 'author': 'Stefano Tubaro', 'arxiv_doi': '10.1109/OJSP.2021.3074298', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/OJSP.2021.3074298', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.10454v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.10454v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
181,http://arxiv.org/abs/2008.07939v2,2020-10-08 11:45:23+00:00,2020-08-18 14:05:16+00:00,FANG: Leveraging Social Context for Fake News Detection Using Graph Representation,"[arxiv.Result.Author('Van-Hoang Nguyen'), arxiv.Result.Author('Kazunari Sugiyama'), arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Min-Yen Kan')]","We propose Factual News Graph (FANG), a novel graphical social context
representation and learning framework for fake news detection. Unlike previous
contextual models that have targeted performance, our focus is on
representation learning. Compared to transductive models, FANG is scalable in
training as it does not have to maintain all nodes, and it is efficient at
inference time, without the need to re-process the entire graph. Our
experimental results show that FANG is better at capturing the social context
into a high fidelity representation, compared to recent graphical and
non-graphical models. In particular, FANG yields significant improvements for
the task of fake news detection, and it is robust in the case of limited
training data. We further demonstrate that the representations learned by FANG
generalize to related tasks, such as predicting the factuality of reporting of
a news medium.",To appear in CIKM 2020,,10.1145/3340531.3412046,cs.SI,"['cs.SI', 'cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3340531.3412046', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.07939v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.07939v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.07939v2,"{'id': 'http://arxiv.org/abs/2008.07939v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.07939v2', 'updated': '2020-10-08T11:45:23Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=8, tm_hour=11, tm_min=45, tm_sec=23, tm_wday=3, tm_yday=282, tm_isdst=0), 'published': '2020-08-18T14:05:16Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=18, tm_hour=14, tm_min=5, tm_sec=16, tm_wday=1, tm_yday=231, tm_isdst=0), 'title': 'FANG: Leveraging Social Context for Fake News Detection Using Graph\n  Representation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FANG: Leveraging Social Context for Fake News Detection Using Graph\n  Representation'}, 'summary': 'We propose Factual News Graph (FANG), a novel graphical social context\nrepresentation and learning framework for fake news detection. Unlike previous\ncontextual models that have targeted performance, our focus is on\nrepresentation learning. Compared to transductive models, FANG is scalable in\ntraining as it does not have to maintain all nodes, and it is efficient at\ninference time, without the need to re-process the entire graph. Our\nexperimental results show that FANG is better at capturing the social context\ninto a high fidelity representation, compared to recent graphical and\nnon-graphical models. In particular, FANG yields significant improvements for\nthe task of fake news detection, and it is robust in the case of limited\ntraining data. We further demonstrate that the representations learned by FANG\ngeneralize to related tasks, such as predicting the factuality of reporting of\na news medium.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We propose Factual News Graph (FANG), a novel graphical social context\nrepresentation and learning framework for fake news detection. Unlike previous\ncontextual models that have targeted performance, our focus is on\nrepresentation learning. Compared to transductive models, FANG is scalable in\ntraining as it does not have to maintain all nodes, and it is efficient at\ninference time, without the need to re-process the entire graph. Our\nexperimental results show that FANG is better at capturing the social context\ninto a high fidelity representation, compared to recent graphical and\nnon-graphical models. In particular, FANG yields significant improvements for\nthe task of fake news detection, and it is robust in the case of limited\ntraining data. We further demonstrate that the representations learned by FANG\ngeneralize to related tasks, such as predicting the factuality of reporting of\na news medium.'}, 'authors': [{'name': 'Van-Hoang Nguyen'}, {'name': 'Kazunari Sugiyama'}, {'name': 'Preslav Nakov'}, {'name': 'Min-Yen Kan'}], 'author_detail': {'name': 'Min-Yen Kan'}, 'author': 'Min-Yen Kan', 'arxiv_doi': '10.1145/3340531.3412046', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3340531.3412046', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.07939v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.07939v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'To appear in CIKM 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
182,http://arxiv.org/abs/2008.06854v1,2020-08-16 08:06:52+00:00,2020-08-16 08:06:52+00:00,"SGG: Spinbot, Grammarly and GloVe based Fake News Detection","[arxiv.Result.Author('Akansha Gautam'), arxiv.Result.Author('Koteswar Rao Jerripothula')]","Recently, news consumption using online news portals has increased
exponentially due to several reasons, such as low cost and easy accessibility.
However, such online platforms inadvertently also become the cause of spreading
false information across the web. They are being misused quite frequently as a
medium to disseminate misinformation and hoaxes. Such malpractices call for a
robust automatic fake news detection system that can keep us at bay from such
misinformation and hoaxes. We propose a robust yet simple fake news detection
system, leveraging the tools for paraphrasing, grammar-checking, and
word-embedding. In this paper, we try to the potential of these tools in
jointly unearthing the authenticity of a news article. Notably, we leverage
Spinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for
word-embedding) tools for this purpose. Using these tools, we were able to
extract novel features that could yield state-of-the-art results on the Fake
News AMT dataset and comparable results on Celebrity datasets when combined
with some of the essential features. More importantly, the proposed method is
found to be more robust empirically than the existing ones, as revealed in our
cross-domain analysis and multi-domain analysis.","9 pages, 7 figures, Accepted by IEEE International Conference on
  Multimedia Big Data (BigMM), 2020",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2008.06854v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.06854v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.06854v1,"{'id': 'http://arxiv.org/abs/2008.06854v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.06854v1', 'updated': '2020-08-16T08:06:52Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=16, tm_hour=8, tm_min=6, tm_sec=52, tm_wday=6, tm_yday=229, tm_isdst=0), 'published': '2020-08-16T08:06:52Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=16, tm_hour=8, tm_min=6, tm_sec=52, tm_wday=6, tm_yday=229, tm_isdst=0), 'title': 'SGG: Spinbot, Grammarly and GloVe based Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SGG: Spinbot, Grammarly and GloVe based Fake News Detection'}, 'summary': 'Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.'}, 'authors': [{'name': 'Akansha Gautam'}, {'name': 'Koteswar Rao Jerripothula'}], 'author_detail': {'name': 'Koteswar Rao Jerripothula'}, 'author': 'Koteswar Rao Jerripothula', 'arxiv_comment': '9 pages, 7 figures, Accepted by IEEE International Conference on\n  Multimedia Big Data (BigMM), 2020', 'links': [{'href': 'http://arxiv.org/abs/2008.06854v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.06854v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
183,http://arxiv.org/abs/2008.06274v4,2020-11-23 15:07:48+00:00,2020-08-14 10:01:34+00:00,Graph-based Modeling of Online Communities for Fake News Detection,"[arxiv.Result.Author('Shantanu Chandra'), arxiv.Result.Author('Pushkar Mishra'), arxiv.Result.Author('Helen Yannakoudakis'), arxiv.Result.Author('Madhav Nimishakavi'), arxiv.Result.Author('Marzieh Saeidi'), arxiv.Result.Author('Ekaterina Shutova')]","Over the past few years, there has been a substantial effort towards
automated detection of fake news on social media platforms. Existing research
has modeled the structure, style, content, and patterns in dissemination of
online posts, as well as the demographic traits of users who interact with
them. However, no attention has been directed towards modeling the properties
of online communities that interact with the posts. In this work, we propose a
novel social context-aware fake news detection framework, SAFER, based on graph
neural networks (GNNs). The proposed framework aggregates information with
respect to: 1) the nature of the content disseminated, 2) content-sharing
behavior of users, and 3) the social network of those users. We furthermore
perform a systematic comparison of several GNN models for this task and
introduce novel methods based on relational and hyperbolic GNNs, which have not
been previously used for user or community modeling within NLP. We empirically
demonstrate that our framework yields significant improvements over existing
text-based techniques and achieves state-of-the-art results on fake news
datasets from two different domains.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2008.06274v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.06274v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.06274v4,"{'id': 'http://arxiv.org/abs/2008.06274v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.06274v4', 'updated': '2020-11-23T15:07:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=23, tm_hour=15, tm_min=7, tm_sec=48, tm_wday=0, tm_yday=328, tm_isdst=0), 'published': '2020-08-14T10:01:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=14, tm_hour=10, tm_min=1, tm_sec=34, tm_wday=4, tm_yday=227, tm_isdst=0), 'title': 'Graph-based Modeling of Online Communities for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Graph-based Modeling of Online Communities for Fake News Detection'}, 'summary': 'Over the past few years, there has been a substantial effort towards\nautomated detection of fake news on social media platforms. Existing research\nhas modeled the structure, style, content, and patterns in dissemination of\nonline posts, as well as the demographic traits of users who interact with\nthem. However, no attention has been directed towards modeling the properties\nof online communities that interact with the posts. In this work, we propose a\nnovel social context-aware fake news detection framework, SAFER, based on graph\nneural networks (GNNs). The proposed framework aggregates information with\nrespect to: 1) the nature of the content disseminated, 2) content-sharing\nbehavior of users, and 3) the social network of those users. We furthermore\nperform a systematic comparison of several GNN models for this task and\nintroduce novel methods based on relational and hyperbolic GNNs, which have not\nbeen previously used for user or community modeling within NLP. We empirically\ndemonstrate that our framework yields significant improvements over existing\ntext-based techniques and achieves state-of-the-art results on fake news\ndatasets from two different domains.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past few years, there has been a substantial effort towards\nautomated detection of fake news on social media platforms. Existing research\nhas modeled the structure, style, content, and patterns in dissemination of\nonline posts, as well as the demographic traits of users who interact with\nthem. However, no attention has been directed towards modeling the properties\nof online communities that interact with the posts. In this work, we propose a\nnovel social context-aware fake news detection framework, SAFER, based on graph\nneural networks (GNNs). The proposed framework aggregates information with\nrespect to: 1) the nature of the content disseminated, 2) content-sharing\nbehavior of users, and 3) the social network of those users. We furthermore\nperform a systematic comparison of several GNN models for this task and\nintroduce novel methods based on relational and hyperbolic GNNs, which have not\nbeen previously used for user or community modeling within NLP. We empirically\ndemonstrate that our framework yields significant improvements over existing\ntext-based techniques and achieves state-of-the-art results on fake news\ndatasets from two different domains.'}, 'authors': [{'name': 'Shantanu Chandra'}, {'name': 'Pushkar Mishra'}, {'name': 'Helen Yannakoudakis'}, {'name': 'Madhav Nimishakavi'}, {'name': 'Marzieh Saeidi'}, {'name': 'Ekaterina Shutova'}], 'author_detail': {'name': 'Ekaterina Shutova'}, 'author': 'Ekaterina Shutova', 'links': [{'href': 'http://arxiv.org/abs/2008.06274v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.06274v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
184,http://arxiv.org/abs/2008.04374v1,2020-08-10 19:21:06+00:00,2020-08-10 19:21:06+00:00,"Can We Spot the ""Fake News"" Before It Was Even Written?",[arxiv.Result.Author('Preslav Nakov')],"Given the recent proliferation of disinformation online, there has been also
growing research interest in automatically debunking rumors, false claims, and
""fake news."" A number of fact-checking initiatives have been launched so far,
both manual and automatic, but the whole enterprise remains in a state of
crisis: by the time a claim is finally fact-checked, it could have reached
millions of users, and the harm caused could hardly be undone. An arguably more
promising direction is to focus on fact-checking entire news outlets, which can
be done in advance. Then, we could fact-check the news before it was even
written: by checking how trustworthy the outlets that published it is. We
describe how we do this in the Tanbih news aggregator, which makes readers
aware of what they are reading. In particular, we develop media profiles that
show the general factuality of reporting, the degree of propagandistic content,
hyper-partisanship, leading political ideology, general frame of reporting, and
stance with respect to various claims and topics.","Fake News, Disinformation, Media Bias, Propaganda, Infodemic,
  COVID-19",,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2008.04374v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.04374v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.04374v1,"{'id': 'http://arxiv.org/abs/2008.04374v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.04374v1', 'updated': '2020-08-10T19:21:06Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=10, tm_hour=19, tm_min=21, tm_sec=6, tm_wday=0, tm_yday=223, tm_isdst=0), 'published': '2020-08-10T19:21:06Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=10, tm_hour=19, tm_min=21, tm_sec=6, tm_wday=0, tm_yday=223, tm_isdst=0), 'title': 'Can We Spot the ""Fake News"" Before It Was Even Written?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can We Spot the ""Fake News"" Before It Was Even Written?'}, 'summary': 'Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n""fake news."" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n""fake news."" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.'}, 'authors': [{'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19', 'links': [{'href': 'http://arxiv.org/abs/2008.04374v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.04374v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
185,http://arxiv.org/abs/2008.03450v1,2020-08-08 05:59:25+00:00,2020-08-08 05:59:25+00:00,Network Inference from a Mixture of Diffusion Models for Fake News Mitigation,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Xinran He'), arxiv.Result.Author('Sungyong Seo'), arxiv.Result.Author('Yan Liu')]","The dissemination of fake news intended to deceive people, influence public
opinion and manipulate social outcomes, has become a pressing problem on social
media. Moreover, information sharing on social media facilitates diffusion of
viral information cascades. In this work, we focus on understanding and
leveraging diffusion dynamics of false and legitimate contents in order to
facilitate network interventions for fake news mitigation. We analyze
real-world Twitter datasets comprising fake and true news cascades, to
understand differences in diffusion dynamics and user behaviours with regards
to fake and true contents. Based on the analysis, we model the diffusion as a
mixture of Independent Cascade models (MIC) with parameters $\theta_T,
\theta_F$ over the social network graph; and derive unsupervised inference
techniques for parameter estimation of the diffusion mixture model from
observed, unlabeled cascades. Users influential in the propagation of true and
fake contents are identified using the inferred diffusion dynamics.
Characteristics of the identified influential users reveal positive correlation
between influential users identified for fake news and their relative
appearance in fake news cascades. Identified influential users tend to be
related to topics of more viral information cascades than less viral ones; and
identified fake news influential users have relatively fewer counts of direct
followers, compared to the true news influential users. Intervention analysis
on nodes and edges demonstrates capacity of the inferred diffusion dynamics in
supporting network interventions for mitigation.",,"Fifteenth international AAAI conference on web and social media
  (ICWSM 2021)",,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2008.03450v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.03450v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.03450v1,"{'id': 'http://arxiv.org/abs/2008.03450v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.03450v1', 'updated': '2020-08-08T05:59:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=8, tm_hour=5, tm_min=59, tm_sec=25, tm_wday=5, tm_yday=221, tm_isdst=0), 'published': '2020-08-08T05:59:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=8, tm_hour=5, tm_min=59, tm_sec=25, tm_wday=5, tm_yday=221, tm_isdst=0), 'title': 'Network Inference from a Mixture of Diffusion Models for Fake News\n  Mitigation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Network Inference from a Mixture of Diffusion Models for Fake News\n  Mitigation'}, 'summary': 'The dissemination of fake news intended to deceive people, influence public\nopinion and manipulate social outcomes, has become a pressing problem on social\nmedia. Moreover, information sharing on social media facilitates diffusion of\nviral information cascades. In this work, we focus on understanding and\nleveraging diffusion dynamics of false and legitimate contents in order to\nfacilitate network interventions for fake news mitigation. We analyze\nreal-world Twitter datasets comprising fake and true news cascades, to\nunderstand differences in diffusion dynamics and user behaviours with regards\nto fake and true contents. Based on the analysis, we model the diffusion as a\nmixture of Independent Cascade models (MIC) with parameters $\\theta_T,\n\\theta_F$ over the social network graph; and derive unsupervised inference\ntechniques for parameter estimation of the diffusion mixture model from\nobserved, unlabeled cascades. Users influential in the propagation of true and\nfake contents are identified using the inferred diffusion dynamics.\nCharacteristics of the identified influential users reveal positive correlation\nbetween influential users identified for fake news and their relative\nappearance in fake news cascades. Identified influential users tend to be\nrelated to topics of more viral information cascades than less viral ones; and\nidentified fake news influential users have relatively fewer counts of direct\nfollowers, compared to the true news influential users. Intervention analysis\non nodes and edges demonstrates capacity of the inferred diffusion dynamics in\nsupporting network interventions for mitigation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The dissemination of fake news intended to deceive people, influence public\nopinion and manipulate social outcomes, has become a pressing problem on social\nmedia. Moreover, information sharing on social media facilitates diffusion of\nviral information cascades. In this work, we focus on understanding and\nleveraging diffusion dynamics of false and legitimate contents in order to\nfacilitate network interventions for fake news mitigation. We analyze\nreal-world Twitter datasets comprising fake and true news cascades, to\nunderstand differences in diffusion dynamics and user behaviours with regards\nto fake and true contents. Based on the analysis, we model the diffusion as a\nmixture of Independent Cascade models (MIC) with parameters $\\theta_T,\n\\theta_F$ over the social network graph; and derive unsupervised inference\ntechniques for parameter estimation of the diffusion mixture model from\nobserved, unlabeled cascades. Users influential in the propagation of true and\nfake contents are identified using the inferred diffusion dynamics.\nCharacteristics of the identified influential users reveal positive correlation\nbetween influential users identified for fake news and their relative\nappearance in fake news cascades. Identified influential users tend to be\nrelated to topics of more viral information cascades than less viral ones; and\nidentified fake news influential users have relatively fewer counts of direct\nfollowers, compared to the true news influential users. Intervention analysis\non nodes and edges demonstrates capacity of the inferred diffusion dynamics in\nsupporting network interventions for mitigation.'}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Xinran He'}, {'name': 'Sungyong Seo'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_journal_ref': 'Fifteenth international AAAI conference on web and social media\n  (ICWSM 2021)', 'links': [{'href': 'http://arxiv.org/abs/2008.03450v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.03450v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
186,http://arxiv.org/abs/2008.01988v1,2020-08-05 08:17:20+00:00,2020-08-05 08:17:20+00:00,How Fake News Affect Trust in the Output of a Machine Learning System for News Curation,"[arxiv.Result.Author('Hendrik Heuer'), arxiv.Result.Author('Andreas Breiter')]","People are increasingly consuming news curated by machine learning (ML)
systems. Motivated by studies on algorithmic bias, this paper explores which
recommendations of an algorithmic news curation system users trust and how this
trust is affected by untrustworthy news stories like fake news. In a study with
82 vocational school students with a background in IT, we found that users are
able to provide trust ratings that distinguish trustworthy recommendations of
quality news stories from untrustworthy recommendations. However, a single
untrustworthy news story combined with four trustworthy news stories is rated
similarly as five trustworthy news stories. The results could be a first
indication that untrustworthy news stories benefit from appearing in a
trustworthy context. The results also show the limitations of users' abilities
to rate the recommendations of a news curation system. We discuss the
implications of this for the user experience of interactive machine learning
systems.","This is a pre-print of an article published in MISDOOM 2020 - 2nd
  Multidisciplinary International Symposium on Disinformation in Open Online
  Media","MISDOOM 2020 - 2nd Multidisciplinary International Symposium on
  Disinformation in Open Online Media",,cs.HC,"['cs.HC', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2008.01988v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.01988v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.01988v1,"{'id': 'http://arxiv.org/abs/2008.01988v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.01988v1', 'updated': '2020-08-05T08:17:20Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=5, tm_hour=8, tm_min=17, tm_sec=20, tm_wday=2, tm_yday=218, tm_isdst=0), 'published': '2020-08-05T08:17:20Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=5, tm_hour=8, tm_min=17, tm_sec=20, tm_wday=2, tm_yday=218, tm_isdst=0), 'title': 'How Fake News Affect Trust in the Output of a Machine Learning System\n  for News Curation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How Fake News Affect Trust in the Output of a Machine Learning System\n  for News Curation'}, 'summary': ""People are increasingly consuming news curated by machine learning (ML)\nsystems. Motivated by studies on algorithmic bias, this paper explores which\nrecommendations of an algorithmic news curation system users trust and how this\ntrust is affected by untrustworthy news stories like fake news. In a study with\n82 vocational school students with a background in IT, we found that users are\nable to provide trust ratings that distinguish trustworthy recommendations of\nquality news stories from untrustworthy recommendations. However, a single\nuntrustworthy news story combined with four trustworthy news stories is rated\nsimilarly as five trustworthy news stories. The results could be a first\nindication that untrustworthy news stories benefit from appearing in a\ntrustworthy context. The results also show the limitations of users' abilities\nto rate the recommendations of a news curation system. We discuss the\nimplications of this for the user experience of interactive machine learning\nsystems."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""People are increasingly consuming news curated by machine learning (ML)\nsystems. Motivated by studies on algorithmic bias, this paper explores which\nrecommendations of an algorithmic news curation system users trust and how this\ntrust is affected by untrustworthy news stories like fake news. In a study with\n82 vocational school students with a background in IT, we found that users are\nable to provide trust ratings that distinguish trustworthy recommendations of\nquality news stories from untrustworthy recommendations. However, a single\nuntrustworthy news story combined with four trustworthy news stories is rated\nsimilarly as five trustworthy news stories. The results could be a first\nindication that untrustworthy news stories benefit from appearing in a\ntrustworthy context. The results also show the limitations of users' abilities\nto rate the recommendations of a news curation system. We discuss the\nimplications of this for the user experience of interactive machine learning\nsystems.""}, 'authors': [{'name': 'Hendrik Heuer'}, {'name': 'Andreas Breiter'}], 'author_detail': {'name': 'Andreas Breiter'}, 'author': 'Andreas Breiter', 'arxiv_comment': 'This is a pre-print of an article published in MISDOOM 2020 - 2nd\n  Multidisciplinary International Symposium on Disinformation in Open Online\n  Media', 'arxiv_journal_ref': 'MISDOOM 2020 - 2nd Multidisciplinary International Symposium on\n  Disinformation in Open Online Media', 'links': [{'href': 'http://arxiv.org/abs/2008.01988v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.01988v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
187,http://arxiv.org/abs/2008.01535v2,2020-08-05 01:53:01+00:00,2020-07-30 08:56:51+00:00,Weighted Accuracy Algorithmic Approach In Counteracting Fake News And Disinformation,[arxiv.Result.Author('Kwadwo Osei Bonsu')],"As the world is becoming more dependent on the internet for information
exchange, some overzealous journalists, hackers, bloggers, individuals and
organizations tend to abuse the gift of free information environment by
polluting it with fake news, disinformation and pretentious content for their
own agenda. Hence, there is the need to address the issue of fake news and
disinformation with utmost seriousness. This paper proposes a methodology for
fake news detection and reporting through a constraint mechanism that utilizes
the combined weighted accuracies of four machine learning algorithms.",,,10.2478/ers-2021-0007,cs.CL,"['cs.CL', 'cs.SI', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://dx.doi.org/10.2478/ers-2021-0007', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.01535v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.01535v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.01535v2,"{'id': 'http://arxiv.org/abs/2008.01535v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.01535v2', 'updated': '2020-08-05T01:53:01Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=5, tm_hour=1, tm_min=53, tm_sec=1, tm_wday=2, tm_yday=218, tm_isdst=0), 'published': '2020-07-30T08:56:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=30, tm_hour=8, tm_min=56, tm_sec=51, tm_wday=3, tm_yday=212, tm_isdst=0), 'title': 'Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation'}, 'summary': 'As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.'}, 'authors': [{'name': 'Kwadwo Osei Bonsu'}], 'author_detail': {'name': 'Kwadwo Osei Bonsu'}, 'author': 'Kwadwo Osei Bonsu', 'arxiv_doi': '10.2478/ers-2021-0007', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.2478/ers-2021-0007', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.01535v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.01535v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
188,http://arxiv.org/abs/2007.15121v2,2021-05-17 17:10:02+00:00,2020-07-29 21:40:01+00:00,Exploiting stance hierarchies for cost-sensitive stance detection of Web documents,"[arxiv.Result.Author('Arjun Roy'), arxiv.Result.Author('Pavlos Fafalios'), arxiv.Result.Author('Asif Ekbal'), arxiv.Result.Author('Xiaofei Zhu'), arxiv.Result.Author('Stefan Dietze')]","Fact checking is an essential challenge when combating fake news. Identifying
documents that agree or disagree with a particular statement (claim) is a core
task in this process. In this context, stance detection aims at identifying the
position (stance) of a document towards a claim. Most approaches address this
task through a 4-class classification model where the class distribution is
highly imbalanced. Therefore, they are particularly ineffective in detecting
the minority classes (for instance, 'disagree'), even though such instances are
crucial for tasks such as fact-checking by providing evidence for detecting
false claims. In this paper, we exploit the hierarchical nature of stance
classes, which allows us to propose a modular pipeline of cascading binary
classifiers, enabling performance tuning on a per step and class basis. We
implement our approach through a combination of neural and traditional
classification models that highlight the misclassification costs of minority
classes. Evaluation results demonstrate state-of-the-art performance of our
approach and its ability to significantly improve the classification
performance of the important 'disagree' class.","This is a pre-print version of the Journal paper published in J
  Intell Inf Syst (2021) (Springer). https://rdcu.be/ckLiC",,10.1007/s10844-021-00642-z,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s10844-021-00642-z', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.15121v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.15121v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.15121v2,"{'id': 'http://arxiv.org/abs/2007.15121v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.15121v2', 'updated': '2021-05-17T17:10:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=17, tm_hour=17, tm_min=10, tm_sec=2, tm_wday=0, tm_yday=137, tm_isdst=0), 'published': '2020-07-29T21:40:01Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=29, tm_hour=21, tm_min=40, tm_sec=1, tm_wday=2, tm_yday=211, tm_isdst=0), 'title': 'Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents'}, 'summary': ""Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class.""}, 'authors': [{'name': 'Arjun Roy'}, {'name': 'Pavlos Fafalios'}, {'name': 'Asif Ekbal'}, {'name': 'Xiaofei Zhu'}, {'name': 'Stefan Dietze'}], 'author_detail': {'name': 'Stefan Dietze'}, 'author': 'Stefan Dietze', 'arxiv_doi': '10.1007/s10844-021-00642-z', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s10844-021-00642-z', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.15121v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.15121v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'This is a pre-print version of the Journal paper published in J\n  Intell Inf Syst (2021) (Springer). https://rdcu.be/ckLiC', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
189,http://arxiv.org/abs/2007.14083v1,2020-07-28 09:32:41+00:00,2020-07-28 09:32:41+00:00,Universal Fake News Collection System using Debunking Tweets,"[arxiv.Result.Author('Taichi Murayama'), arxiv.Result.Author('Shoko Wakamiya'), arxiv.Result.Author('Eiji Aramaki')]","Large numbers of people use Social Networking Services (SNS) for easy access
to various news, but they have more opportunities to obtain and share ``fake
news'' carrying false information. Partially to combat fake news, several
fact-checking sites such as Snopes and PolitiFact have been founded.
Nevertheless, these sites rely on time-consuming and labor-intensive tasks.
Moreover, their available languages are not extensive. To address these
difficulties, we propose a new fake news collection system based on rule-based
(unsupervised) frameworks that can be extended easily for various languages.
The system collects news with high probability of being fake by debunking
tweets by users and presents event clusters gathering higher attention. Our
system currently functions in two languages: English and Japanese. It shows
event clusters, 65\% of which are actually fake. In future studies, it will be
applied to other languages and will be published with a large fake news
dataset.","5pages, 2 figures",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2007.14083v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.14083v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.14083v1,"{'id': 'http://arxiv.org/abs/2007.14083v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.14083v1', 'updated': '2020-07-28T09:32:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=28, tm_hour=9, tm_min=32, tm_sec=41, tm_wday=1, tm_yday=210, tm_isdst=0), 'published': '2020-07-28T09:32:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=28, tm_hour=9, tm_min=32, tm_sec=41, tm_wday=1, tm_yday=210, tm_isdst=0), 'title': 'Universal Fake News Collection System using Debunking Tweets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Universal Fake News Collection System using Debunking Tweets'}, 'summary': ""Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset.""}, 'authors': [{'name': 'Taichi Murayama'}, {'name': 'Shoko Wakamiya'}, {'name': 'Eiji Aramaki'}], 'author_detail': {'name': 'Eiji Aramaki'}, 'author': 'Eiji Aramaki', 'arxiv_comment': '5pages, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/2007.14083v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.14083v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
190,http://arxiv.org/abs/2007.14059v2,2021-04-27 05:15:52+00:00,2020-07-28 08:28:16+00:00,Modeling the spread of fake news on Twitter,"[arxiv.Result.Author('Taichi Murayama'), arxiv.Result.Author('Shoko Wakamiya'), arxiv.Result.Author('Eiji Aramaki'), arxiv.Result.Author('Ryota Kobayashi')]","Fake news can have a significant negative impact on society because of the
growing use of mobile devices and the worldwide increase in Internet access. It
is therefore essential to develop a simple mathematical model to understand the
online dissemination of fake news. In this study, we propose a point process
model of the spread of fake news on Twitter. The proposed model describes the
spread of a fake news item as a two-stage process: initially, fake news spreads
as a piece of ordinary news; then, when most users start recognizing the
falsity of the news item, that itself spreads as another news story. We
validate this model using two datasets of fake news items spread on Twitter. We
show that the proposed model is superior to the current state-of-the-art
methods in accurately predicting the evolution of the spread of a fake news
item. Moreover, a text analysis suggests that our model appropriately infers
the correction time, i.e., the moment when Twitter users start realizing the
falsity of the news item. The proposed model contributes to understanding the
dynamics of the spread of fake news on social media. Its ability to extract a
compact representation of the spreading pattern could be useful in the
detection and mitigation of fake news.",Published at PLOS ONE in 2021,Plos one 16.4: e0250419 (2021),10.1371/journal.pone.0250419,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0250419', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.14059v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.14059v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.14059v2,"{'id': 'http://arxiv.org/abs/2007.14059v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.14059v2', 'updated': '2021-04-27T05:15:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=27, tm_hour=5, tm_min=15, tm_sec=52, tm_wday=1, tm_yday=117, tm_isdst=0), 'published': '2020-07-28T08:28:16Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=28, tm_hour=8, tm_min=28, tm_sec=16, tm_wday=1, tm_yday=210, tm_isdst=0), 'title': 'Modeling the spread of fake news on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Modeling the spread of fake news on Twitter'}, 'summary': 'Fake news can have a significant negative impact on society because of the\ngrowing use of mobile devices and the worldwide increase in Internet access. It\nis therefore essential to develop a simple mathematical model to understand the\nonline dissemination of fake news. In this study, we propose a point process\nmodel of the spread of fake news on Twitter. The proposed model describes the\nspread of a fake news item as a two-stage process: initially, fake news spreads\nas a piece of ordinary news; then, when most users start recognizing the\nfalsity of the news item, that itself spreads as another news story. We\nvalidate this model using two datasets of fake news items spread on Twitter. We\nshow that the proposed model is superior to the current state-of-the-art\nmethods in accurately predicting the evolution of the spread of a fake news\nitem. Moreover, a text analysis suggests that our model appropriately infers\nthe correction time, i.e., the moment when Twitter users start realizing the\nfalsity of the news item. The proposed model contributes to understanding the\ndynamics of the spread of fake news on social media. Its ability to extract a\ncompact representation of the spreading pattern could be useful in the\ndetection and mitigation of fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news can have a significant negative impact on society because of the\ngrowing use of mobile devices and the worldwide increase in Internet access. It\nis therefore essential to develop a simple mathematical model to understand the\nonline dissemination of fake news. In this study, we propose a point process\nmodel of the spread of fake news on Twitter. The proposed model describes the\nspread of a fake news item as a two-stage process: initially, fake news spreads\nas a piece of ordinary news; then, when most users start recognizing the\nfalsity of the news item, that itself spreads as another news story. We\nvalidate this model using two datasets of fake news items spread on Twitter. We\nshow that the proposed model is superior to the current state-of-the-art\nmethods in accurately predicting the evolution of the spread of a fake news\nitem. Moreover, a text analysis suggests that our model appropriately infers\nthe correction time, i.e., the moment when Twitter users start realizing the\nfalsity of the news item. The proposed model contributes to understanding the\ndynamics of the spread of fake news on social media. Its ability to extract a\ncompact representation of the spreading pattern could be useful in the\ndetection and mitigation of fake news.'}, 'authors': [{'name': 'Taichi Murayama'}, {'name': 'Shoko Wakamiya'}, {'name': 'Eiji Aramaki'}, {'name': 'Ryota Kobayashi'}], 'author_detail': {'name': 'Ryota Kobayashi'}, 'author': 'Ryota Kobayashi', 'arxiv_doi': '10.1371/journal.pone.0250419', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0250419', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.14059v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.14059v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published at PLOS ONE in 2021', 'arxiv_journal_ref': 'Plos one 16.4: e0250419 (2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
191,http://arxiv.org/abs/2007.14013v1,2020-07-28 06:34:54+00:00,2020-07-28 06:34:54+00:00,Fake News Detection using Temporal Features Extracted via Point Process,"[arxiv.Result.Author('Taichi Murayama'), arxiv.Result.Author('Shoko Wakamiya'), arxiv.Result.Author('Eiji Aramaki')]","Many people use social networking services (SNSs) to easily access various
news. There are numerous ways to obtain and share ``fake news,'' which are news
carrying false information. To address fake news, several studies have been
conducted for detecting fake news by using SNS-extracted features. In this
study, we attempt to use temporal features generated from SNS posts by using a
point process algorithm to identify fake news from real news. Temporal features
in fake news detection have the advantage of robustness over existing features
because it has minimal dependence on fake news propagators. Further, we propose
a novel multi-modal attention-based method, which includes linguistic and user
features alongside temporal features, for detecting fake news from SNS posts.
Results obtained from three public datasets indicate that the proposed model
achieves better performance compared to existing methods and demonstrate the
effectiveness of temporal features for fake news detection.","CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020",,10.36190/2020.13,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.36190/2020.13', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.14013v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.14013v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.14013v1,"{'id': 'http://arxiv.org/abs/2007.14013v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.14013v1', 'updated': '2020-07-28T06:34:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=28, tm_hour=6, tm_min=34, tm_sec=54, tm_wday=1, tm_yday=210, tm_isdst=0), 'published': '2020-07-28T06:34:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=28, tm_hour=6, tm_min=34, tm_sec=54, tm_wday=1, tm_yday=210, tm_isdst=0), 'title': 'Fake News Detection using Temporal Features Extracted via Point Process', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection using Temporal Features Extracted via Point Process'}, 'summary': ""Many people use social networking services (SNSs) to easily access various\nnews. There are numerous ways to obtain and share ``fake news,'' which are news\ncarrying false information. To address fake news, several studies have been\nconducted for detecting fake news by using SNS-extracted features. In this\nstudy, we attempt to use temporal features generated from SNS posts by using a\npoint process algorithm to identify fake news from real news. Temporal features\nin fake news detection have the advantage of robustness over existing features\nbecause it has minimal dependence on fake news propagators. Further, we propose\na novel multi-modal attention-based method, which includes linguistic and user\nfeatures alongside temporal features, for detecting fake news from SNS posts.\nResults obtained from three public datasets indicate that the proposed model\nachieves better performance compared to existing methods and demonstrate the\neffectiveness of temporal features for fake news detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Many people use social networking services (SNSs) to easily access various\nnews. There are numerous ways to obtain and share ``fake news,'' which are news\ncarrying false information. To address fake news, several studies have been\nconducted for detecting fake news by using SNS-extracted features. In this\nstudy, we attempt to use temporal features generated from SNS posts by using a\npoint process algorithm to identify fake news from real news. Temporal features\nin fake news detection have the advantage of robustness over existing features\nbecause it has minimal dependence on fake news propagators. Further, we propose\na novel multi-modal attention-based method, which includes linguistic and user\nfeatures alongside temporal features, for detecting fake news from SNS posts.\nResults obtained from three public datasets indicate that the proposed model\nachieves better performance compared to existing methods and demonstrate the\neffectiveness of temporal features for fake news detection.""}, 'authors': [{'name': 'Taichi Murayama'}, {'name': 'Shoko Wakamiya'}, {'name': 'Eiji Aramaki'}], 'author_detail': {'name': 'Eiji Aramaki'}, 'author': 'Eiji Aramaki', 'arxiv_doi': '10.36190/2020.13', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.36190/2020.13', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.14013v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.14013v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
192,http://arxiv.org/abs/2007.12358v2,2020-07-27 03:59:56+00:00,2020-07-24 05:42:29+00:00,Machine Learning Explanations to Prevent Overtrust in Fake News Detection,"[arxiv.Result.Author('Sina Mohseni'), arxiv.Result.Author('Fan Yang'), arxiv.Result.Author('Shiva Pentyala'), arxiv.Result.Author('Mengnan Du'), arxiv.Result.Author('Yi Liu'), arxiv.Result.Author('Nic Lupfer'), arxiv.Result.Author('Xia Hu'), arxiv.Result.Author('Shuiwang Ji'), arxiv.Result.Author('Eric Ragan')]","Combating fake news and misinformation propagation is a challenging task in
the post-truth era. News feed and search algorithms could potentially lead to
unintentional large-scale propagation of false and fabricated information with
users being exposed to algorithmically selected false content. Our research
investigates the effects of an Explainable AI assistant embedded in news review
platforms for combating the propagation of fake news. We design a news
reviewing and sharing interface, create a dataset of news stories, and train
four interpretable fake news detection algorithms to study the effects of
algorithmic transparency on end-users. We present evaluation results and
analysis from multiple controlled crowdsourced studies. For a deeper
understanding of Explainable AI systems, we discuss interactions between user
engagement, mental model, trust, and performance measures in the process of
explaining. The study results indicate that explanations helped participants to
build appropriate mental models of the intelligent assistants in different
conditions and adjust their trust accordingly for model limitations.",,,,cs.IR,"['cs.IR', 'cs.AI', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2007.12358v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.12358v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.12358v2,"{'id': 'http://arxiv.org/abs/2007.12358v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.12358v2', 'updated': '2020-07-27T03:59:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=27, tm_hour=3, tm_min=59, tm_sec=56, tm_wday=0, tm_yday=209, tm_isdst=0), 'published': '2020-07-24T05:42:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=24, tm_hour=5, tm_min=42, tm_sec=29, tm_wday=4, tm_yday=206, tm_isdst=0), 'title': 'Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection'}, 'summary': 'Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.'}, 'authors': [{'name': 'Sina Mohseni'}, {'name': 'Fan Yang'}, {'name': 'Shiva Pentyala'}, {'name': 'Mengnan Du'}, {'name': 'Yi Liu'}, {'name': 'Nic Lupfer'}, {'name': 'Xia Hu'}, {'name': 'Shuiwang Ji'}, {'name': 'Eric Ragan'}], 'author_detail': {'name': 'Eric Ragan'}, 'author': 'Eric Ragan', 'links': [{'href': 'http://arxiv.org/abs/2007.12358v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.12358v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
193,http://arxiv.org/abs/2007.10534v2,2020-09-20 23:51:37+00:00,2020-07-21 00:07:17+00:00,Check_square at CheckThat! 2020: Claim Detection in Social Media via Fusion of Transformer and Syntactic Features,"[arxiv.Result.Author('Gullal S. Cheema'), arxiv.Result.Author('Sherzod Hakimov'), arxiv.Result.Author('Ralph Ewerth')]","In this digital age of news consumption, a news reader has the ability to
react, express and share opinions with others in a highly interactive and fast
manner. As a consequence, fake news has made its way into our daily life
because of very limited capacity to verify news on the Internet by large
companies as well as individuals. In this paper, we focus on solving two
problems which are part of the fact-checking ecosystem that can help to
automate fact-checking of claims in an ever increasing stream of content on
social media. For the first problem, claim check-worthiness prediction, we
explore the fusion of syntactic features and deep transformer Bidirectional
Encoder Representations from Transformers (BERT) embeddings, to classify
check-worthiness of a tweet, i.e. whether it includes a claim or not. We
conduct a detailed feature analysis and present our best performing models for
English and Arabic tweets. For the second problem, claim retrieval, we explore
the pre-trained embeddings from a Siamese network transformer model
(sentence-transformers) specifically trained for semantic textual similarity,
and perform KD-search to retrieve verified claims with respect to a query
tweet.",CLEF2020-CheckThat!,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2007.10534v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.10534v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.10534v2,"{'id': 'http://arxiv.org/abs/2007.10534v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.10534v2', 'updated': '2020-09-20T23:51:37Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=20, tm_hour=23, tm_min=51, tm_sec=37, tm_wday=6, tm_yday=264, tm_isdst=0), 'published': '2020-07-21T00:07:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=21, tm_hour=0, tm_min=7, tm_sec=17, tm_wday=1, tm_yday=203, tm_isdst=0), 'title': 'Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features'}, 'summary': 'In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.'}, 'authors': [{'name': 'Gullal S. Cheema'}, {'name': 'Sherzod Hakimov'}, {'name': 'Ralph Ewerth'}], 'author_detail': {'name': 'Ralph Ewerth'}, 'author': 'Ralph Ewerth', 'arxiv_comment': 'CLEF2020-CheckThat!', 'links': [{'href': 'http://arxiv.org/abs/2007.10534v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.10534v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
194,http://arxiv.org/abs/2007.09757v1,2020-07-19 19:13:20+00:00,2020-07-19 19:13:20+00:00,Mono vs Multilingual Transformer-based Models: a Comparison across Several Language Tasks,"[arxiv.Result.Author('Diego de Vargas Feijo'), arxiv.Result.Author('Viviane Pereira Moreira')]","BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A
Lite BERT) are methods for pre-training language models which can later be
fine-tuned for a variety of Natural Language Understanding tasks. These methods
have been applied to a number of such tasks (mostly in English), achieving
results that outperform the state-of-the-art. In this paper, our contribution
is twofold. First, we make available our trained BERT and Albert model for
Portuguese. Second, we compare our monolingual and the standard multilingual
models using experiments in semantic textual similarity, recognizing textual
entailment, textual category classification, sentiment analysis, offensive
comment detection, and fake news detection, to assess the effectiveness of the
generated language representations. The results suggest that both monolingual
and multilingual models are able to achieve state-of-the-art and the advantage
of training a single language model, if any, is small.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2007.09757v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.09757v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.09757v1,"{'id': 'http://arxiv.org/abs/2007.09757v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.09757v1', 'updated': '2020-07-19T19:13:20Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=19, tm_min=13, tm_sec=20, tm_wday=6, tm_yday=201, tm_isdst=0), 'published': '2020-07-19T19:13:20Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=19, tm_min=13, tm_sec=20, tm_wday=6, tm_yday=201, tm_isdst=0), 'title': 'Mono vs Multilingual Transformer-based Models: a Comparison across\n  Several Language Tasks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mono vs Multilingual Transformer-based Models: a Comparison across\n  Several Language Tasks'}, 'summary': 'BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A\nLite BERT) are methods for pre-training language models which can later be\nfine-tuned for a variety of Natural Language Understanding tasks. These methods\nhave been applied to a number of such tasks (mostly in English), achieving\nresults that outperform the state-of-the-art. In this paper, our contribution\nis twofold. First, we make available our trained BERT and Albert model for\nPortuguese. Second, we compare our monolingual and the standard multilingual\nmodels using experiments in semantic textual similarity, recognizing textual\nentailment, textual category classification, sentiment analysis, offensive\ncomment detection, and fake news detection, to assess the effectiveness of the\ngenerated language representations. The results suggest that both monolingual\nand multilingual models are able to achieve state-of-the-art and the advantage\nof training a single language model, if any, is small.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A\nLite BERT) are methods for pre-training language models which can later be\nfine-tuned for a variety of Natural Language Understanding tasks. These methods\nhave been applied to a number of such tasks (mostly in English), achieving\nresults that outperform the state-of-the-art. In this paper, our contribution\nis twofold. First, we make available our trained BERT and Albert model for\nPortuguese. Second, we compare our monolingual and the standard multilingual\nmodels using experiments in semantic textual similarity, recognizing textual\nentailment, textual category classification, sentiment analysis, offensive\ncomment detection, and fake news detection, to assess the effectiveness of the\ngenerated language representations. The results suggest that both monolingual\nand multilingual models are able to achieve state-of-the-art and the advantage\nof training a single language model, if any, is small.'}, 'authors': [{'name': 'Diego de Vargas Feijo'}, {'name': 'Viviane Pereira Moreira'}], 'author_detail': {'name': 'Viviane Pereira Moreira'}, 'author': 'Viviane Pereira Moreira', 'links': [{'href': 'http://arxiv.org/abs/2007.09757v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.09757v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
195,http://arxiv.org/abs/2007.09703v1,2020-07-19 16:14:58+00:00,2020-07-19 16:14:58+00:00,A curated collection of COVID-19 online datasets,"[arxiv.Result.Author('Isa Inuwa-Dutse'), arxiv.Result.Author('Ioannis Korkontzelos')]","One of the defining moments of the year 2020 is the outbreak of Coronavirus
Disease (Covid-19), a deadly virus affecting the body's respiratory system to
the point of needing a breathing aid via ventilators. As of June 21, 2020 there
are 12,929,306 confirmed cases and 569,738 confirmed deaths across 216
countries, areas or territories. The scale of spread and impact of the pandemic
left many nations grappling with preventive and curative approaches. The
infamous lockdown measure introduced to mitigate the virus spread has altered
many aspects of our social routines in which demand for online-based services
skyrocketed. As the virus propagate, so does misinformation and fake news
around it via online social media, which seems to favour virality over
veracity. With a majority of the populace confined to their homes for a long
period, vulnerability to the toxic impact of online misinformation is high. A
case in point is the various myths and disinformation associated with the
Covid-19, which, if left unchecked, could lead to a catastrophic outcome and
hamper the fight against the virus.
  While the scientific community is actively engaged in identifying the virus
treatment, there is a growing interest in combating the associated harmful
infodemic. To this end, researchers have been curating and documenting various
datasets about Covid-19. In line with existing studies, we provide an expansive
collection of curated datasets to support the fight against the pandemic,
especially concerning misinformation. The collection consists of 3 categories
of Twitter data, information about standard practices from credible sources and
a chronicle of global situation reports. We describe how to retrieve the
hydrated version of the data and proffer some research problems that could be
addressed using the data.","10 pages, 7 figures",,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2007.09703v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.09703v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.09703v1,"{'id': 'http://arxiv.org/abs/2007.09703v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.09703v1', 'updated': '2020-07-19T16:14:58Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=16, tm_min=14, tm_sec=58, tm_wday=6, tm_yday=201, tm_isdst=0), 'published': '2020-07-19T16:14:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=16, tm_min=14, tm_sec=58, tm_wday=6, tm_yday=201, tm_isdst=0), 'title': 'A curated collection of COVID-19 online datasets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A curated collection of COVID-19 online datasets'}, 'summary': ""One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.""}, 'authors': [{'name': 'Isa Inuwa-Dutse'}, {'name': 'Ioannis Korkontzelos'}], 'author_detail': {'name': 'Ioannis Korkontzelos'}, 'author': 'Ioannis Korkontzelos', 'arxiv_comment': '10 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/2007.09703v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.09703v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
196,http://arxiv.org/abs/2007.07996v2,2021-04-09 08:52:10+00:00,2020-07-15 21:18:30+00:00,Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective and a Call to Arms,"[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Fahim Dalvi'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Nadir Durrani'), arxiv.Result.Author('Hamdy Mubarak'), arxiv.Result.Author('Alex Nikolov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Ahmed Abdelali'), arxiv.Result.Author('Hassan Sajjad'), arxiv.Result.Author('Kareem Darwish'), arxiv.Result.Author('Preslav Nakov')]","With the outbreak of the COVID-19 pandemic, people turned to social media to
read and to share timely information including statistics, warnings, advice,
and inspirational stories. Unfortunately, alongside all this useful
information, there was also a new blending of medical and political
misinformation and disinformation, which gave rise to the first global
infodemic. While fighting this infodemic is typically thought of in terms of
factuality, the problem is much broader as malicious content includes not only
fake news, rumors, and conspiracy theories, but also promotion of fake cures,
panic, racism, xenophobia, and mistrust in the authorities, among others. This
is a complex problem that needs a holistic approach combining the perspectives
of journalists, fact-checkers, policymakers, government entities, social media
platforms, and society as a whole. Taking them into account we define an
annotation schema and detailed annotation instructions, which reflect these
perspectives. We performed initial annotations using this schema, and our
initial experiments demonstrated sizable improvements over the baselines. Now,
we issue a call to arms to the research community and beyond to join the fight
by supporting our crowdsourcing annotation efforts.","COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call
  to Arms, Crowdsourcing Annotations",,,cs.IR,"['cs.IR', 'cs.CL', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2007.07996v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.07996v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.07996v2,"{'id': 'http://arxiv.org/abs/2007.07996v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.07996v2', 'updated': '2021-04-09T08:52:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=8, tm_min=52, tm_sec=10, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2020-07-15T21:18:30Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=15, tm_hour=21, tm_min=18, tm_sec=30, tm_wday=2, tm_yday=197, tm_isdst=0), 'title': 'Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms'}, 'summary': 'With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Fahim Dalvi'}, {'name': 'Shaden Shaar'}, {'name': 'Nadir Durrani'}, {'name': 'Hamdy Mubarak'}, {'name': 'Alex Nikolov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Ahmed Abdelali'}, {'name': 'Hassan Sajjad'}, {'name': 'Kareem Darwish'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations', 'links': [{'href': 'http://arxiv.org/abs/2007.07996v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.07996v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
197,http://arxiv.org/abs/2007.05185v1,2020-07-10 06:08:50+00:00,2020-07-10 06:08:50+00:00,Games of Social Distancing during an Epidemic: Local vs Statistical Information,"[arxiv.Result.Author('A. -R. Lagos'), arxiv.Result.Author('I. Kordonis'), arxiv.Result.Author('G. P. Papavassilopoulos')]","The spontaneous behavioral changes of the agents during an epidemic can have
significant effects on the delay and the prevalence of its spread. In this
work, we study a social distancing game among the agents of a population, who
determine their social interactions during the spread of an epidemic. The
interconnections between the agents are modeled by a network and local
interactions are considered. The payoffs of the agents depend on their benefits
from their social interactions, as well as on the costs to their health due to
their possible contamination. The information available to the agents during
the decision making plays a crucial role in our model. We examine two extreme
cases. In the first case, the agents know exactly the health states of their
neighbors and in the second they have statistical information for the global
prevalence of the epidemic. The Nash equilibria of the games are studied and,
interestingly, in the second case the equilibrium strategies for an agent are
either full isolation or no social distancing at all. Experimental studies are
presented through simulations, where we observe that in the first case of
perfect local information the agents can affect significantly the prevalence of
the epidemic with low cost for their sociability, while in the second case they
have to pay the burden of not being well informed. Moreover, the effects of the
information quality (fake news), the health care system capacity and the
network structure are discussed and relevant simulations are provided, which
indicate that these parameters affect the size, the peak and the start of the
outbreak, as well as the possibility of a second outbreak.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.GT', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2007.05185v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.05185v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.05185v1,"{'id': 'http://arxiv.org/abs/2007.05185v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.05185v1', 'updated': '2020-07-10T06:08:50Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=10, tm_hour=6, tm_min=8, tm_sec=50, tm_wday=4, tm_yday=192, tm_isdst=0), 'published': '2020-07-10T06:08:50Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=10, tm_hour=6, tm_min=8, tm_sec=50, tm_wday=4, tm_yday=192, tm_isdst=0), 'title': 'Games of Social Distancing during an Epidemic: Local vs Statistical\n  Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Games of Social Distancing during an Epidemic: Local vs Statistical\n  Information'}, 'summary': 'The spontaneous behavioral changes of the agents during an epidemic can have\nsignificant effects on the delay and the prevalence of its spread. In this\nwork, we study a social distancing game among the agents of a population, who\ndetermine their social interactions during the spread of an epidemic. The\ninterconnections between the agents are modeled by a network and local\ninteractions are considered. The payoffs of the agents depend on their benefits\nfrom their social interactions, as well as on the costs to their health due to\ntheir possible contamination. The information available to the agents during\nthe decision making plays a crucial role in our model. We examine two extreme\ncases. In the first case, the agents know exactly the health states of their\nneighbors and in the second they have statistical information for the global\nprevalence of the epidemic. The Nash equilibria of the games are studied and,\ninterestingly, in the second case the equilibrium strategies for an agent are\neither full isolation or no social distancing at all. Experimental studies are\npresented through simulations, where we observe that in the first case of\nperfect local information the agents can affect significantly the prevalence of\nthe epidemic with low cost for their sociability, while in the second case they\nhave to pay the burden of not being well informed. Moreover, the effects of the\ninformation quality (fake news), the health care system capacity and the\nnetwork structure are discussed and relevant simulations are provided, which\nindicate that these parameters affect the size, the peak and the start of the\noutbreak, as well as the possibility of a second outbreak.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spontaneous behavioral changes of the agents during an epidemic can have\nsignificant effects on the delay and the prevalence of its spread. In this\nwork, we study a social distancing game among the agents of a population, who\ndetermine their social interactions during the spread of an epidemic. The\ninterconnections between the agents are modeled by a network and local\ninteractions are considered. The payoffs of the agents depend on their benefits\nfrom their social interactions, as well as on the costs to their health due to\ntheir possible contamination. The information available to the agents during\nthe decision making plays a crucial role in our model. We examine two extreme\ncases. In the first case, the agents know exactly the health states of their\nneighbors and in the second they have statistical information for the global\nprevalence of the epidemic. The Nash equilibria of the games are studied and,\ninterestingly, in the second case the equilibrium strategies for an agent are\neither full isolation or no social distancing at all. Experimental studies are\npresented through simulations, where we observe that in the first case of\nperfect local information the agents can affect significantly the prevalence of\nthe epidemic with low cost for their sociability, while in the second case they\nhave to pay the burden of not being well informed. Moreover, the effects of the\ninformation quality (fake news), the health care system capacity and the\nnetwork structure are discussed and relevant simulations are provided, which\nindicate that these parameters affect the size, the peak and the start of the\noutbreak, as well as the possibility of a second outbreak.'}, 'authors': [{'name': 'A. -R. Lagos'}, {'name': 'I. Kordonis'}, {'name': 'G. P. Papavassilopoulos'}], 'author_detail': {'name': 'G. P. Papavassilopoulos'}, 'author': 'G. P. Papavassilopoulos', 'links': [{'href': 'http://arxiv.org/abs/2007.05185v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.05185v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
198,http://arxiv.org/abs/2007.05070v2,2021-02-24 17:35:12+00:00,2020-07-09 21:10:54+00:00,Forecasting Election Polls with Spin Systems,"[arxiv.Result.Author('Ruben Ibarrondo'), arxiv.Result.Author('Mikel Sanz'), arxiv.Result.Author('Roman Orus')]","We show that the problem of political forecasting, i.e, predicting the result
of elections and referendums, can be mapped to finding the ground state
configuration of a classical spin system. Depending on the required prediction,
this spin system can be a combination of $XY$, Ising and vector Potts models,
always with two-spin interactions, magnetic fields, and on arbitrary graphs. By
reduction to the Ising model our result shows that political forecasting is
formally an NP-Hard problem. Moreover, we show that the ground state search can
be recasted as Higher-order and Quadratic Unconstrained Binary Optimization
(HUBO / QUBO) Problems, which are the standard input of classical and quantum
combinatorial optimization techniques. We prove the validity of our approach by
performing a numerical experiment based on data gathered from \emph{Twitter}
for a network of 10 people, finding good agreement between results from a poll
and those predicted by our model. In general terms, our method can also be
understood as a trend detection algorithm, particularly useful in the contexts
of sentiment analysis and identification of fake news.","7 pages, 2 figures, 1 table, minor changes in v2",,,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech', 'quant-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2007.05070v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.05070v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.05070v2,"{'id': 'http://arxiv.org/abs/2007.05070v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.05070v2', 'updated': '2021-02-24T17:35:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=24, tm_hour=17, tm_min=35, tm_sec=12, tm_wday=2, tm_yday=55, tm_isdst=0), 'published': '2020-07-09T21:10:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=9, tm_hour=21, tm_min=10, tm_sec=54, tm_wday=3, tm_yday=191, tm_isdst=0), 'title': 'Forecasting Election Polls with Spin Systems', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Forecasting Election Polls with Spin Systems'}, 'summary': 'We show that the problem of political forecasting, i.e, predicting the result\nof elections and referendums, can be mapped to finding the ground state\nconfiguration of a classical spin system. Depending on the required prediction,\nthis spin system can be a combination of $XY$, Ising and vector Potts models,\nalways with two-spin interactions, magnetic fields, and on arbitrary graphs. By\nreduction to the Ising model our result shows that political forecasting is\nformally an NP-Hard problem. Moreover, we show that the ground state search can\nbe recasted as Higher-order and Quadratic Unconstrained Binary Optimization\n(HUBO / QUBO) Problems, which are the standard input of classical and quantum\ncombinatorial optimization techniques. We prove the validity of our approach by\nperforming a numerical experiment based on data gathered from \\emph{Twitter}\nfor a network of 10 people, finding good agreement between results from a poll\nand those predicted by our model. In general terms, our method can also be\nunderstood as a trend detection algorithm, particularly useful in the contexts\nof sentiment analysis and identification of fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We show that the problem of political forecasting, i.e, predicting the result\nof elections and referendums, can be mapped to finding the ground state\nconfiguration of a classical spin system. Depending on the required prediction,\nthis spin system can be a combination of $XY$, Ising and vector Potts models,\nalways with two-spin interactions, magnetic fields, and on arbitrary graphs. By\nreduction to the Ising model our result shows that political forecasting is\nformally an NP-Hard problem. Moreover, we show that the ground state search can\nbe recasted as Higher-order and Quadratic Unconstrained Binary Optimization\n(HUBO / QUBO) Problems, which are the standard input of classical and quantum\ncombinatorial optimization techniques. We prove the validity of our approach by\nperforming a numerical experiment based on data gathered from \\emph{Twitter}\nfor a network of 10 people, finding good agreement between results from a poll\nand those predicted by our model. In general terms, our method can also be\nunderstood as a trend detection algorithm, particularly useful in the contexts\nof sentiment analysis and identification of fake news.'}, 'authors': [{'name': 'Ruben Ibarrondo'}, {'name': 'Mikel Sanz'}, {'name': 'Roman Orus'}], 'author_detail': {'name': 'Roman Orus'}, 'author': 'Roman Orus', 'arxiv_comment': '7 pages, 2 figures, 1 table, minor changes in v2', 'links': [{'href': 'http://arxiv.org/abs/2007.05070v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.05070v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.stat-mech', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
199,http://arxiv.org/abs/2007.04903v2,2020-10-23 10:22:37+00:00,2020-07-09 16:05:11+00:00,Emergence of polarization in a voter model with personalized information,"[arxiv.Result.Author('Giordano De Marzo'), arxiv.Result.Author('Andrea Zaccaria'), arxiv.Result.Author('Claudio Castellano')]","The flourishing of fake news is favored by recommendation algorithms of
online social networks which, based on previous users activity, provide content
adapted to their preferences and so create filter bubbles. We introduce an
analytically tractable voter model with personalized information, in which an
external field tends to align the agent opinion with the one she held more
frequently in the past. Our model shows a surprisingly rich dynamics despite
its simplicity. An analytical mean-field approach, confirmed by numerical
simulations, allows us to build a phase diagram and to predict if and how
consensus is reached. Remarkably, polarization can be avoided only for weak
interaction with the personalized information and if the number of agents is
below a threshold. We analytically compute this critical size, which depends on
the interaction probability in a strongly non linear way.","15 pages, 9 figures","Phys. Rev. Research 2, 043117 (2020)",10.1103/PhysRevResearch.2.043117,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevResearch.2.043117', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.04903v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.04903v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.04903v2,"{'id': 'http://arxiv.org/abs/2007.04903v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.04903v2', 'updated': '2020-10-23T10:22:37Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=23, tm_hour=10, tm_min=22, tm_sec=37, tm_wday=4, tm_yday=297, tm_isdst=0), 'published': '2020-07-09T16:05:11Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=9, tm_hour=16, tm_min=5, tm_sec=11, tm_wday=3, tm_yday=191, tm_isdst=0), 'title': 'Emergence of polarization in a voter model with personalized information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Emergence of polarization in a voter model with personalized information'}, 'summary': 'The flourishing of fake news is favored by recommendation algorithms of\nonline social networks which, based on previous users activity, provide content\nadapted to their preferences and so create filter bubbles. We introduce an\nanalytically tractable voter model with personalized information, in which an\nexternal field tends to align the agent opinion with the one she held more\nfrequently in the past. Our model shows a surprisingly rich dynamics despite\nits simplicity. An analytical mean-field approach, confirmed by numerical\nsimulations, allows us to build a phase diagram and to predict if and how\nconsensus is reached. Remarkably, polarization can be avoided only for weak\ninteraction with the personalized information and if the number of agents is\nbelow a threshold. We analytically compute this critical size, which depends on\nthe interaction probability in a strongly non linear way.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The flourishing of fake news is favored by recommendation algorithms of\nonline social networks which, based on previous users activity, provide content\nadapted to their preferences and so create filter bubbles. We introduce an\nanalytically tractable voter model with personalized information, in which an\nexternal field tends to align the agent opinion with the one she held more\nfrequently in the past. Our model shows a surprisingly rich dynamics despite\nits simplicity. An analytical mean-field approach, confirmed by numerical\nsimulations, allows us to build a phase diagram and to predict if and how\nconsensus is reached. Remarkably, polarization can be avoided only for weak\ninteraction with the personalized information and if the number of agents is\nbelow a threshold. We analytically compute this critical size, which depends on\nthe interaction probability in a strongly non linear way.'}, 'authors': [{'name': 'Giordano De Marzo'}, {'name': 'Andrea Zaccaria'}, {'name': 'Claudio Castellano'}], 'author_detail': {'name': 'Claudio Castellano'}, 'author': 'Claudio Castellano', 'arxiv_doi': '10.1103/PhysRevResearch.2.043117', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevResearch.2.043117', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.04903v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.04903v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '15 pages, 9 figures', 'arxiv_journal_ref': 'Phys. Rev. Research 2, 043117 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.stat-mech', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
200,http://arxiv.org/abs/2007.03316v2,2020-08-14 07:49:20+00:00,2020-07-07 10:04:50+00:00,Graph Neural Networks with Continual Learning for Fake News Detection from Social Media,"[arxiv.Result.Author('Yi Han'), arxiv.Result.Author('Shanika Karunasekera'), arxiv.Result.Author('Christopher Leckie')]","Although significant effort has been applied to fact-checking, the prevalence
of fake news over social media, which has profound impact on justice, public
trust and our society, remains a serious problem. In this work, we focus on
propagation-based fake news detection, as recent studies have demonstrated that
fake news and real news spread differently online. Specifically, considering
the capability of graph neural networks (GNNs) in dealing with non-Euclidean
data, we use GNNs to differentiate between the propagation patterns of fake and
real news on social media. In particular, we concentrate on two questions: (1)
Without relying on any text information, e.g., tweet content, replies and user
descriptions, how accurately can GNNs identify fake news? Machine learning
models are known to be vulnerable to adversarial attacks, and avoiding the
dependence on text-based features can make the model less susceptible to the
manipulation of advanced fake news fabricators. (2) How to deal with new,
unseen data? In other words, how does a GNN trained on a given dataset perform
on a new and potentially vastly different dataset? If it achieves
unsatisfactory performance, how do we solve the problem without re-training the
model on the entire data from scratch? We study the above questions on two
datasets with thousands of labelled news items, and our results show that: (1)
GNNs can achieve comparable or superior performance without any text
information to state-of-the-art methods. (2) GNNs trained on a given dataset
may perform poorly on new, unseen data, and direct incremental training cannot
solve the problem---this issue has not been addressed in the previous work that
applies GNNs for fake news detection. In order to solve the problem, we propose
a method that achieves balanced performance on both existing and new datasets,
by using techniques from continual learning to train GNNs incrementally.","9 pages, 7 figures, 2 tables",,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2007.03316v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.03316v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.03316v2,"{'id': 'http://arxiv.org/abs/2007.03316v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.03316v2', 'updated': '2020-08-14T07:49:20Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=14, tm_hour=7, tm_min=49, tm_sec=20, tm_wday=4, tm_yday=227, tm_isdst=0), 'published': '2020-07-07T10:04:50Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=7, tm_hour=10, tm_min=4, tm_sec=50, tm_wday=1, tm_yday=189, tm_isdst=0), 'title': 'Graph Neural Networks with Continual Learning for Fake News Detection\n  from Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Graph Neural Networks with Continual Learning for Fake News Detection\n  from Social Media'}, 'summary': 'Although significant effort has been applied to fact-checking, the prevalence\nof fake news over social media, which has profound impact on justice, public\ntrust and our society, remains a serious problem. In this work, we focus on\npropagation-based fake news detection, as recent studies have demonstrated that\nfake news and real news spread differently online. Specifically, considering\nthe capability of graph neural networks (GNNs) in dealing with non-Euclidean\ndata, we use GNNs to differentiate between the propagation patterns of fake and\nreal news on social media. In particular, we concentrate on two questions: (1)\nWithout relying on any text information, e.g., tweet content, replies and user\ndescriptions, how accurately can GNNs identify fake news? Machine learning\nmodels are known to be vulnerable to adversarial attacks, and avoiding the\ndependence on text-based features can make the model less susceptible to the\nmanipulation of advanced fake news fabricators. (2) How to deal with new,\nunseen data? In other words, how does a GNN trained on a given dataset perform\non a new and potentially vastly different dataset? If it achieves\nunsatisfactory performance, how do we solve the problem without re-training the\nmodel on the entire data from scratch? We study the above questions on two\ndatasets with thousands of labelled news items, and our results show that: (1)\nGNNs can achieve comparable or superior performance without any text\ninformation to state-of-the-art methods. (2) GNNs trained on a given dataset\nmay perform poorly on new, unseen data, and direct incremental training cannot\nsolve the problem---this issue has not been addressed in the previous work that\napplies GNNs for fake news detection. In order to solve the problem, we propose\na method that achieves balanced performance on both existing and new datasets,\nby using techniques from continual learning to train GNNs incrementally.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Although significant effort has been applied to fact-checking, the prevalence\nof fake news over social media, which has profound impact on justice, public\ntrust and our society, remains a serious problem. In this work, we focus on\npropagation-based fake news detection, as recent studies have demonstrated that\nfake news and real news spread differently online. Specifically, considering\nthe capability of graph neural networks (GNNs) in dealing with non-Euclidean\ndata, we use GNNs to differentiate between the propagation patterns of fake and\nreal news on social media. In particular, we concentrate on two questions: (1)\nWithout relying on any text information, e.g., tweet content, replies and user\ndescriptions, how accurately can GNNs identify fake news? Machine learning\nmodels are known to be vulnerable to adversarial attacks, and avoiding the\ndependence on text-based features can make the model less susceptible to the\nmanipulation of advanced fake news fabricators. (2) How to deal with new,\nunseen data? In other words, how does a GNN trained on a given dataset perform\non a new and potentially vastly different dataset? If it achieves\nunsatisfactory performance, how do we solve the problem without re-training the\nmodel on the entire data from scratch? We study the above questions on two\ndatasets with thousands of labelled news items, and our results show that: (1)\nGNNs can achieve comparable or superior performance without any text\ninformation to state-of-the-art methods. (2) GNNs trained on a given dataset\nmay perform poorly on new, unseen data, and direct incremental training cannot\nsolve the problem---this issue has not been addressed in the previous work that\napplies GNNs for fake news detection. In order to solve the problem, we propose\na method that achieves balanced performance on both existing and new datasets,\nby using techniques from continual learning to train GNNs incrementally.'}, 'authors': [{'name': 'Yi Han'}, {'name': 'Shanika Karunasekera'}, {'name': 'Christopher Leckie'}], 'author_detail': {'name': 'Christopher Leckie'}, 'author': 'Christopher Leckie', 'arxiv_comment': '9 pages, 7 figures, 2 tables', 'links': [{'href': 'http://arxiv.org/abs/2007.03316v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.03316v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
201,http://arxiv.org/abs/2007.02774v1,2020-06-30 21:07:34+00:00,2020-06-30 21:07:34+00:00,The role of time scale in the spreading of asymmetrically interacting diseases,"[arxiv.Result.Author('Paulo Cesar Ventura'), arxiv.Result.Author('Yamir Moreno'), arxiv.Result.Author('Francisco A. Rodrigues')]","Diseases and other contagion phenomena in nature and society can interact
asymmetrically, such that one can benefit from the other, which in turn impairs
the first, in analogy with predator-prey systems. Here, we consider two models
for interacting disease-like dynamics with asymmetric interactions and
different associated time scales. Using rate equations for homogeneously mixed
populations, we show that the stationary prevalences and phase diagrams of each
model behave differently with respect to variations of the relative time
scales. We also characterize in detail the regime where transient oscillations
are observed, a pattern that is inherent to asymmetrical interactions but often
ignored in the literature. Our results contribute to a better understanding of
disease dynamics in particular, and interacting processes in general, and could
provide interesting insights for real-world applications, most notably, the
interplay between the dynamics of fact-checked and fake news.",11 pages and 8 figures,"Phys. Rev. Research 3, 013146 (2021)",10.1103/PhysRevResearch.3.013146,physics.soc-ph,"['physics.soc-ph', 'q-bio.PE']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevResearch.3.013146', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.02774v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.02774v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.02774v1,"{'id': 'http://arxiv.org/abs/2007.02774v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.02774v1', 'updated': '2020-06-30T21:07:34Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=30, tm_hour=21, tm_min=7, tm_sec=34, tm_wday=1, tm_yday=182, tm_isdst=0), 'published': '2020-06-30T21:07:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=30, tm_hour=21, tm_min=7, tm_sec=34, tm_wday=1, tm_yday=182, tm_isdst=0), 'title': 'The role of time scale in the spreading of asymmetrically interacting\n  diseases', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The role of time scale in the spreading of asymmetrically interacting\n  diseases'}, 'summary': 'Diseases and other contagion phenomena in nature and society can interact\nasymmetrically, such that one can benefit from the other, which in turn impairs\nthe first, in analogy with predator-prey systems. Here, we consider two models\nfor interacting disease-like dynamics with asymmetric interactions and\ndifferent associated time scales. Using rate equations for homogeneously mixed\npopulations, we show that the stationary prevalences and phase diagrams of each\nmodel behave differently with respect to variations of the relative time\nscales. We also characterize in detail the regime where transient oscillations\nare observed, a pattern that is inherent to asymmetrical interactions but often\nignored in the literature. Our results contribute to a better understanding of\ndisease dynamics in particular, and interacting processes in general, and could\nprovide interesting insights for real-world applications, most notably, the\ninterplay between the dynamics of fact-checked and fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Diseases and other contagion phenomena in nature and society can interact\nasymmetrically, such that one can benefit from the other, which in turn impairs\nthe first, in analogy with predator-prey systems. Here, we consider two models\nfor interacting disease-like dynamics with asymmetric interactions and\ndifferent associated time scales. Using rate equations for homogeneously mixed\npopulations, we show that the stationary prevalences and phase diagrams of each\nmodel behave differently with respect to variations of the relative time\nscales. We also characterize in detail the regime where transient oscillations\nare observed, a pattern that is inherent to asymmetrical interactions but often\nignored in the literature. Our results contribute to a better understanding of\ndisease dynamics in particular, and interacting processes in general, and could\nprovide interesting insights for real-world applications, most notably, the\ninterplay between the dynamics of fact-checked and fake news.'}, 'authors': [{'name': 'Paulo Cesar Ventura'}, {'name': 'Yamir Moreno'}, {'name': 'Francisco A. Rodrigues'}], 'author_detail': {'name': 'Francisco A. Rodrigues'}, 'author': 'Francisco A. Rodrigues', 'arxiv_doi': '10.1103/PhysRevResearch.3.013146', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevResearch.3.013146', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.02774v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.02774v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '11 pages and 8 figures', 'arxiv_journal_ref': 'Phys. Rev. Research 3, 013146 (2021)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
202,http://arxiv.org/abs/2006.11343v1,2020-06-19 19:48:00+00:00,2020-06-19 19:48:00+00:00,FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for COVID-19,"[arxiv.Result.Author('Gautam Kishore Shahi'), arxiv.Result.Author('Durgesh Nandini')]","In this paper, we present a first multilingual cross-domain dataset of 5182
fact-checked news articles for COVID-19, collected from 04/01/2020 to
15/05/2020. We have collected the fact-checked articles from 92 different
fact-checking websites after obtaining references from Poynter and Snopes. We
have manually annotated articles into 11 different categories of the
fact-checked news according to their content. The dataset is in 40 languages
from 105 countries. We have built a classifier to detect fake news and present
results for the automatic fake news detection and its class. Our model achieves
an F1 score of 0.76 to detect the false class and other fact check articles.
The FakeCovid dataset is available at Github.","CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020",,10.36190/2020.14,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.36190/2020.14', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.11343v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.11343v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.11343v1,"{'id': 'http://arxiv.org/abs/2006.11343v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.11343v1', 'updated': '2020-06-19T19:48:00Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=19, tm_hour=19, tm_min=48, tm_sec=0, tm_wday=4, tm_yday=171, tm_isdst=0), 'published': '2020-06-19T19:48:00Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=19, tm_hour=19, tm_min=48, tm_sec=0, tm_wday=4, tm_yday=171, tm_isdst=0), 'title': 'FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19'}, 'summary': 'In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.'}, 'authors': [{'name': 'Gautam Kishore Shahi'}, {'name': 'Durgesh Nandini'}], 'author_detail': {'name': 'Durgesh Nandini'}, 'author': 'Durgesh Nandini', 'arxiv_doi': '10.36190/2020.14', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.36190/2020.14', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.11343v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.11343v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
203,http://arxiv.org/abs/2006.05557v2,2020-08-17 20:54:46+00:00,2020-06-09 23:40:51+00:00,ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research,"[arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Apurva Mulay'), arxiv.Result.Author('Emilio Ferrara'), arxiv.Result.Author('Reza Zafarani')]","First identified in Wuhan, China, in December 2019, the outbreak of COVID-19
has been declared as a global emergency in January, and a pandemic in March
2020 by the World Health Organization (WHO). Along with this pandemic, we are
also experiencing an ""infodemic"" of information with low credibility such as
fake news and conspiracies. In this work, we present ReCOVery, a repository
designed and constructed to facilitate research on combating such information
regarding COVID-19. We first broadly search and investigate ~2,000 news
publishers, from which 60 are identified with extreme [high or low] levels of
credibility. By inheriting the credibility of the media on which they were
published, a total of 2,029 news articles on coronavirus, published from
January to May 2020, are collected in the repository, along with 140,820 tweets
that reveal how these news articles have spread on the Twitter social network.
The repository provides multimodal information of news articles on coronavirus,
including textual, visual, temporal, and network information. The way that news
credibility is obtained allows a trade-off between dataset scalability and
label accuracy. Extensive experiments are conducted to present data statistics
and distributions, as well as to provide baseline performances for predicting
news credibility so that future methods can be compared. Our repository is
available at http://coronavirus-fakenews.com.","Proceedings of the 29th ACM International Conference on Information
  and Knowledge Management (CIKM '20)",,10.1145/3340531.3412880,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3340531.3412880', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.05557v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.05557v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.05557v2,"{'id': 'http://arxiv.org/abs/2006.05557v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.05557v2', 'updated': '2020-08-17T20:54:46Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=17, tm_hour=20, tm_min=54, tm_sec=46, tm_wday=0, tm_yday=230, tm_isdst=0), 'published': '2020-06-09T23:40:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=9, tm_hour=23, tm_min=40, tm_sec=51, tm_wday=1, tm_yday=161, tm_isdst=0), 'title': 'ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research'}, 'summary': 'First identified in Wuhan, China, in December 2019, the outbreak of COVID-19\nhas been declared as a global emergency in January, and a pandemic in March\n2020 by the World Health Organization (WHO). Along with this pandemic, we are\nalso experiencing an ""infodemic"" of information with low credibility such as\nfake news and conspiracies. In this work, we present ReCOVery, a repository\ndesigned and constructed to facilitate research on combating such information\nregarding COVID-19. We first broadly search and investigate ~2,000 news\npublishers, from which 60 are identified with extreme [high or low] levels of\ncredibility. By inheriting the credibility of the media on which they were\npublished, a total of 2,029 news articles on coronavirus, published from\nJanuary to May 2020, are collected in the repository, along with 140,820 tweets\nthat reveal how these news articles have spread on the Twitter social network.\nThe repository provides multimodal information of news articles on coronavirus,\nincluding textual, visual, temporal, and network information. The way that news\ncredibility is obtained allows a trade-off between dataset scalability and\nlabel accuracy. Extensive experiments are conducted to present data statistics\nand distributions, as well as to provide baseline performances for predicting\nnews credibility so that future methods can be compared. Our repository is\navailable at http://coronavirus-fakenews.com.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'First identified in Wuhan, China, in December 2019, the outbreak of COVID-19\nhas been declared as a global emergency in January, and a pandemic in March\n2020 by the World Health Organization (WHO). Along with this pandemic, we are\nalso experiencing an ""infodemic"" of information with low credibility such as\nfake news and conspiracies. In this work, we present ReCOVery, a repository\ndesigned and constructed to facilitate research on combating such information\nregarding COVID-19. We first broadly search and investigate ~2,000 news\npublishers, from which 60 are identified with extreme [high or low] levels of\ncredibility. By inheriting the credibility of the media on which they were\npublished, a total of 2,029 news articles on coronavirus, published from\nJanuary to May 2020, are collected in the repository, along with 140,820 tweets\nthat reveal how these news articles have spread on the Twitter social network.\nThe repository provides multimodal information of news articles on coronavirus,\nincluding textual, visual, temporal, and network information. The way that news\ncredibility is obtained allows a trade-off between dataset scalability and\nlabel accuracy. Extensive experiments are conducted to present data statistics\nand distributions, as well as to provide baseline performances for predicting\nnews credibility so that future methods can be compared. Our repository is\navailable at http://coronavirus-fakenews.com.'}, 'authors': [{'name': 'Xinyi Zhou'}, {'name': 'Apurva Mulay'}, {'name': 'Emilio Ferrara'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_doi': '10.1145/3340531.3412880', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3340531.3412880', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.05557v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.05557v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""Proceedings of the 29th ACM International Conference on Information\n  and Knowledge Management (CIKM '20)"", 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
204,http://arxiv.org/abs/2006.04278v1,2020-06-07 22:00:43+00:00,2020-06-07 22:00:43+00:00,Disinformation and Misinformation on Twitter during the Novel Coronavirus Outbreak,"[arxiv.Result.Author('Binxuan Huang'), arxiv.Result.Author('Kathleen M. Carley')]","As the novel coronavirus spread globally, a growing public panic was
expressed over the internet. We examine the public discussion concerning
COVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million
users collected between January 29, 2020 and March 4, 2020. We categorize users
based on their home countries, social identities, and political orientation. We
find that news media, government officials, and individual news reporters
posted a majority of influential tweets, while the most influential ones are
still written by regular users. Tweets mentioning ""fake news"" URLs and
disinformation story-lines are also more likely to be spread by regular users.
Unlike real news and normal tweets, tweets containing URLs pointing to ""fake
news"" sites are most likely to be retweeted within the source country and so
are less likely to spread internationally.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2006.04278v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.04278v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.04278v1,"{'id': 'http://arxiv.org/abs/2006.04278v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.04278v1', 'updated': '2020-06-07T22:00:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=7, tm_hour=22, tm_min=0, tm_sec=43, tm_wday=6, tm_yday=159, tm_isdst=0), 'published': '2020-06-07T22:00:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=7, tm_hour=22, tm_min=0, tm_sec=43, tm_wday=6, tm_yday=159, tm_isdst=0), 'title': 'Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak'}, 'summary': 'As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning ""fake news"" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to ""fake\nnews"" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning ""fake news"" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to ""fake\nnews"" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.'}, 'authors': [{'name': 'Binxuan Huang'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'links': [{'href': 'http://arxiv.org/abs/2006.04278v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.04278v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
205,http://arxiv.org/abs/2006.03526v1,2020-06-05 15:58:54+00:00,2020-06-05 15:58:54+00:00,Ratioing the President: An exploration of public engagement with Obama and Trump on Twitter,"[arxiv.Result.Author('Joshua R. Minot'), arxiv.Result.Author('Michael V. Arnold'), arxiv.Result.Author('Thayer Alshaabi'), arxiv.Result.Author('Christopher M. Danforth'), arxiv.Result.Author('Peter Sheridan Dodds')]","The past decade has witnessed a marked increase in the use of social media by
politicians, most notably exemplified by the 45th President of the United
States (POTUS), Donald Trump. On Twitter, POTUS messages consistently attract
high levels of engagement as measured by likes, retweets, and replies. Here, we
quantify the balance of these activities, also known as ""ratios"", and study
their dynamics as a proxy for collective political engagement in response to
presidential communications. We find that raw activity counts increase during
the period leading up to the 2016 election, accompanied by a regime change in
the ratio of retweets-to-replies connected to the transition between
campaigning and governing. For the Trump account, we find words related to fake
news and the Mueller inquiry are more common in tweets with a high number of
replies relative to retweets. Finally, we find that Barack Obama consistently
received a higher retweet-to-reply ratio than Donald Trump. These results
suggest Trump's Twitter posts are more often controversial and subject to
enduring engagement as a given news cycle unfolds.","17 pages, 10 figures",,10.1371/journal.pone.0248880,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0248880', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.03526v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.03526v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.03526v1,"{'id': 'http://arxiv.org/abs/2006.03526v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.03526v1', 'updated': '2020-06-05T15:58:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=5, tm_hour=15, tm_min=58, tm_sec=54, tm_wday=4, tm_yday=157, tm_isdst=0), 'published': '2020-06-05T15:58:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=5, tm_hour=15, tm_min=58, tm_sec=54, tm_wday=4, tm_yday=157, tm_isdst=0), 'title': 'Ratioing the President: An exploration of public engagement with Obama\n  and Trump on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Ratioing the President: An exploration of public engagement with Obama\n  and Trump on Twitter'}, 'summary': 'The past decade has witnessed a marked increase in the use of social media by\npoliticians, most notably exemplified by the 45th President of the United\nStates (POTUS), Donald Trump. On Twitter, POTUS messages consistently attract\nhigh levels of engagement as measured by likes, retweets, and replies. Here, we\nquantify the balance of these activities, also known as ""ratios"", and study\ntheir dynamics as a proxy for collective political engagement in response to\npresidential communications. We find that raw activity counts increase during\nthe period leading up to the 2016 election, accompanied by a regime change in\nthe ratio of retweets-to-replies connected to the transition between\ncampaigning and governing. For the Trump account, we find words related to fake\nnews and the Mueller inquiry are more common in tweets with a high number of\nreplies relative to retweets. Finally, we find that Barack Obama consistently\nreceived a higher retweet-to-reply ratio than Donald Trump. These results\nsuggest Trump\'s Twitter posts are more often controversial and subject to\nenduring engagement as a given news cycle unfolds.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The past decade has witnessed a marked increase in the use of social media by\npoliticians, most notably exemplified by the 45th President of the United\nStates (POTUS), Donald Trump. On Twitter, POTUS messages consistently attract\nhigh levels of engagement as measured by likes, retweets, and replies. Here, we\nquantify the balance of these activities, also known as ""ratios"", and study\ntheir dynamics as a proxy for collective political engagement in response to\npresidential communications. We find that raw activity counts increase during\nthe period leading up to the 2016 election, accompanied by a regime change in\nthe ratio of retweets-to-replies connected to the transition between\ncampaigning and governing. For the Trump account, we find words related to fake\nnews and the Mueller inquiry are more common in tweets with a high number of\nreplies relative to retweets. Finally, we find that Barack Obama consistently\nreceived a higher retweet-to-reply ratio than Donald Trump. These results\nsuggest Trump\'s Twitter posts are more often controversial and subject to\nenduring engagement as a given news cycle unfolds.'}, 'authors': [{'name': 'Joshua R. Minot'}, {'name': 'Michael V. Arnold'}, {'name': 'Thayer Alshaabi'}, {'name': 'Christopher M. Danforth'}, {'name': 'Peter Sheridan Dodds'}], 'author_detail': {'name': 'Peter Sheridan Dodds'}, 'author': 'Peter Sheridan Dodds', 'arxiv_doi': '10.1371/journal.pone.0248880', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0248880', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.03526v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.03526v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '17 pages, 10 figures', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
206,http://arxiv.org/abs/2005.14627v1,2020-05-29 15:38:54+00:00,2020-05-29 15:38:54+00:00,Detection of Bangla Fake News using MNB and SVM Classifier,"[arxiv.Result.Author('Md Gulzar Hussain'), arxiv.Result.Author('Md Rashidul Hasan'), arxiv.Result.Author('Mahmuda Rahman'), arxiv.Result.Author('Joy Protim'), arxiv.Result.Author('Sakib Al Hasan')]","Fake news has been coming into sight in significant numbers for numerous
business and political reasons and has become frequent in the online world.
People can get contaminated easily by these fake news for its fabricated words
which have enormous effects on the offline community. Thus, interest in
research in this area has risen. Significant research has been conducted on the
detection of fake news from English texts and other languages but a few in
Bangla Language. Our work reflects the experimental analysis on the detection
of Bangla fake news from social media as this field still requires much focus.
In this research work, we have used two supervised machine learning algorithms,
Multinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to
detect Bangla fake news with CountVectorizer and Term Frequency - Inverse
Document Frequency Vectorizer as feature extraction. Our proposed framework
detects fake news depending on the polarity of the corresponding article.
Finally, our analysis shows SVM with the linear kernel with an accuracy of
96.64% outperform MNB with an accuracy of 93.32%.",,,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2005.14627v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.14627v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.14627v1,"{'id': 'http://arxiv.org/abs/2005.14627v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.14627v1', 'updated': '2020-05-29T15:38:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=29, tm_hour=15, tm_min=38, tm_sec=54, tm_wday=4, tm_yday=150, tm_isdst=0), 'published': '2020-05-29T15:38:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=29, tm_hour=15, tm_min=38, tm_sec=54, tm_wday=4, tm_yday=150, tm_isdst=0), 'title': 'Detection of Bangla Fake News using MNB and SVM Classifier', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detection of Bangla Fake News using MNB and SVM Classifier'}, 'summary': 'Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.'}, 'authors': [{'name': 'Md Gulzar Hussain'}, {'name': 'Md Rashidul Hasan'}, {'name': 'Mahmuda Rahman'}, {'name': 'Joy Protim'}, {'name': 'Sakib Al Hasan'}], 'author_detail': {'name': 'Sakib Al Hasan'}, 'author': 'Sakib Al Hasan', 'links': [{'href': 'http://arxiv.org/abs/2005.14627v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.14627v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
207,http://arxiv.org/abs/2005.13290v2,2020-05-28 15:28:13+00:00,2020-05-27 11:39:15+00:00,Pandemic News: Facebook Pages of Mainstream News Media and the Coronavirus Crisis -- A Computational Content Analysis,"[arxiv.Result.Author('Thorsten Quandt'), arxiv.Result.Author('Svenja Boberg'), arxiv.Result.Author('Tim Schatto-Eckrodt'), arxiv.Result.Author('Lena Frischlich')]","The unfolding of the COVID-19 pandemic has been an unprecedented challenge
for news media around the globe. While journalism is meant to process yet
unknown events by design, the dynamically evolving situation affected all
aspects of life in such profound ways that even the routines of crisis
reporting seemed to be insufficient. Critics noted tendencies to horse-race
reporting and uncritical coverage, with journalism being too close to official
statements and too affirmative of political decisions. However, empirical data
on the performance of journalistic news media during the crisis has been
lacking thus far. The current study analyzes the Facebook messages of
journalistic news media during the early Coronavirus crisis, based on a large
German data set from January to March 2020. Using computational content
analysis methods, reach and interactions, topical structure, relevant actors,
negativity of messages, as well as the coverage of fabricated news and
conspiracy theories were examined. The topical structure of the near-time
Facebook coverage changed during various stages of the crisis, with just
partial support for the claims of critics. The initial stages were somewhat
lacking in topical breadth, but later stages offered a broad range of coverage
on Corona-related issues and societal concerns. Further, journalistic media
covered fake news and conspiracy theories during the crisis, but they
consistently contextualized them as what they were and debunked the false
claims circulating in public. While some criticism regarding the performance of
journalism during the crisis received mild empirical support, the analysis did
not find overwhelming signs of systemic dysfunctionalities. Overall,
journalistic media did not default to a uniform reaction nor to sprawling,
information-poor pandemic news, but they responded with a multi-perspective
coverage of the crisis.","Corrected typos, 7 figures, 4 tables, 1 ancillary file",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2005.13290v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.13290v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.13290v2,"{'id': 'http://arxiv.org/abs/2005.13290v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.13290v2', 'updated': '2020-05-28T15:28:13Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=28, tm_hour=15, tm_min=28, tm_sec=13, tm_wday=3, tm_yday=149, tm_isdst=0), 'published': '2020-05-27T11:39:15Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=11, tm_min=39, tm_sec=15, tm_wday=2, tm_yday=148, tm_isdst=0), 'title': 'Pandemic News: Facebook Pages of Mainstream News Media and the\n  Coronavirus Crisis -- A Computational Content Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Pandemic News: Facebook Pages of Mainstream News Media and the\n  Coronavirus Crisis -- A Computational Content Analysis'}, 'summary': 'The unfolding of the COVID-19 pandemic has been an unprecedented challenge\nfor news media around the globe. While journalism is meant to process yet\nunknown events by design, the dynamically evolving situation affected all\naspects of life in such profound ways that even the routines of crisis\nreporting seemed to be insufficient. Critics noted tendencies to horse-race\nreporting and uncritical coverage, with journalism being too close to official\nstatements and too affirmative of political decisions. However, empirical data\non the performance of journalistic news media during the crisis has been\nlacking thus far. The current study analyzes the Facebook messages of\njournalistic news media during the early Coronavirus crisis, based on a large\nGerman data set from January to March 2020. Using computational content\nanalysis methods, reach and interactions, topical structure, relevant actors,\nnegativity of messages, as well as the coverage of fabricated news and\nconspiracy theories were examined. The topical structure of the near-time\nFacebook coverage changed during various stages of the crisis, with just\npartial support for the claims of critics. The initial stages were somewhat\nlacking in topical breadth, but later stages offered a broad range of coverage\non Corona-related issues and societal concerns. Further, journalistic media\ncovered fake news and conspiracy theories during the crisis, but they\nconsistently contextualized them as what they were and debunked the false\nclaims circulating in public. While some criticism regarding the performance of\njournalism during the crisis received mild empirical support, the analysis did\nnot find overwhelming signs of systemic dysfunctionalities. Overall,\njournalistic media did not default to a uniform reaction nor to sprawling,\ninformation-poor pandemic news, but they responded with a multi-perspective\ncoverage of the crisis.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The unfolding of the COVID-19 pandemic has been an unprecedented challenge\nfor news media around the globe. While journalism is meant to process yet\nunknown events by design, the dynamically evolving situation affected all\naspects of life in such profound ways that even the routines of crisis\nreporting seemed to be insufficient. Critics noted tendencies to horse-race\nreporting and uncritical coverage, with journalism being too close to official\nstatements and too affirmative of political decisions. However, empirical data\non the performance of journalistic news media during the crisis has been\nlacking thus far. The current study analyzes the Facebook messages of\njournalistic news media during the early Coronavirus crisis, based on a large\nGerman data set from January to March 2020. Using computational content\nanalysis methods, reach and interactions, topical structure, relevant actors,\nnegativity of messages, as well as the coverage of fabricated news and\nconspiracy theories were examined. The topical structure of the near-time\nFacebook coverage changed during various stages of the crisis, with just\npartial support for the claims of critics. The initial stages were somewhat\nlacking in topical breadth, but later stages offered a broad range of coverage\non Corona-related issues and societal concerns. Further, journalistic media\ncovered fake news and conspiracy theories during the crisis, but they\nconsistently contextualized them as what they were and debunked the false\nclaims circulating in public. While some criticism regarding the performance of\njournalism during the crisis received mild empirical support, the analysis did\nnot find overwhelming signs of systemic dysfunctionalities. Overall,\njournalistic media did not default to a uniform reaction nor to sprawling,\ninformation-poor pandemic news, but they responded with a multi-perspective\ncoverage of the crisis.'}, 'authors': [{'name': 'Thorsten Quandt'}, {'name': 'Svenja Boberg'}, {'name': 'Tim Schatto-Eckrodt'}, {'name': 'Lena Frischlich'}], 'author_detail': {'name': 'Lena Frischlich'}, 'author': 'Lena Frischlich', 'arxiv_comment': 'Corrected typos, 7 figures, 4 tables, 1 ancillary file', 'links': [{'href': 'http://arxiv.org/abs/2005.13290v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.13290v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
208,http://arxiv.org/abs/2005.13270v1,2020-05-27 10:29:14+00:00,2020-05-27 10:29:14+00:00,BRENDA: Browser Extension for Fake News Detection,"[arxiv.Result.Author('Bjarte Botnevik'), arxiv.Result.Author('Eirik Sakariassen'), arxiv.Result.Author('Vinay Setty')]","Misinformation such as fake news has drawn a lot of attention in recent
years. It has serious consequences on society, politics and economy. This has
lead to a rise of manually fact-checking websites such as Snopes and
Politifact. However, the scale of misinformation limits their ability for
verification. In this demonstration, we propose BRENDA a browser extension
which can be used to automate the entire process of credibility assessments of
false claims. Behind the scenes BRENDA uses a tested deep neural network
architecture to automatically identify fact check worthy claims and classifies
as well as presents the result along with evidence to the user. Since BRENDA is
a browser extension, it facilities fast automated fact checking for the end
user without having to leave the Webpage.",Accepted as SIGIR demo,"In Proceedings of the 43rd International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR 2020), July 25 to
  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages",10.1145/3397271.3401396,cs.IR,"['cs.IR', 'cs.AI', 'I.2.7']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3397271.3401396', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.13270v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.13270v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.13270v1,"{'id': 'http://arxiv.org/abs/2005.13270v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.13270v1', 'updated': '2020-05-27T10:29:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=10, tm_min=29, tm_sec=14, tm_wday=2, tm_yday=148, tm_isdst=0), 'published': '2020-05-27T10:29:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=10, tm_min=29, tm_sec=14, tm_wday=2, tm_yday=148, tm_isdst=0), 'title': 'BRENDA: Browser Extension for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BRENDA: Browser Extension for Fake News Detection'}, 'summary': 'Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.'}, 'authors': [{'name': 'Bjarte Botnevik'}, {'name': 'Eirik Sakariassen'}, {'name': 'Vinay Setty'}], 'author_detail': {'name': 'Vinay Setty'}, 'author': 'Vinay Setty', 'arxiv_doi': '10.1145/3397271.3401396', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3397271.3401396', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.13270v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.13270v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted as SIGIR demo', 'arxiv_journal_ref': 'In Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2020), July 25 to\n  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
209,http://arxiv.org/abs/2006.00885v3,2020-11-03 20:37:11+00:00,2020-05-22 19:08:14+00:00,CoAID: COVID-19 Healthcare Misinformation Dataset,"[arxiv.Result.Author('Limeng Cui'), arxiv.Result.Author('Dongwon Lee')]","As the COVID-19 virus quickly spreads around the world, unfortunately,
misinformation related to COVID-19 also gets created and spreads like wild
fire. Such misinformation has caused confusion among people, disruptions in
society, and even deadly consequences in health problems. To be able to
understand, detect, and mitigate such COVID-19 misinformation, therefore, has
not only deep intellectual values but also huge societal impacts. To help
researchers combat COVID-19 health misinformation, therefore, we present CoAID
(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare
misinformation, including fake news on websites and social platforms, along
with users' social engagement about such news. CoAID includes 4,251 news,
296,000 related user engagements, 926 social platform posts about COVID-19, and
ground truth labels. The dataset is available at:
https://github.com/cuilimeng/CoAID.",,,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2006.00885v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.00885v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.00885v3,"{'id': 'http://arxiv.org/abs/2006.00885v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.00885v3', 'updated': '2020-11-03T20:37:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=20, tm_min=37, tm_sec=11, tm_wday=1, tm_yday=308, tm_isdst=0), 'published': '2020-05-22T19:08:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=22, tm_hour=19, tm_min=8, tm_sec=14, tm_wday=4, tm_yday=143, tm_isdst=0), 'title': 'CoAID: COVID-19 Healthcare Misinformation Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CoAID: COVID-19 Healthcare Misinformation Dataset'}, 'summary': ""As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.""}, 'authors': [{'name': 'Limeng Cui'}, {'name': 'Dongwon Lee'}], 'author_detail': {'name': 'Dongwon Lee'}, 'author': 'Dongwon Lee', 'links': [{'href': 'http://arxiv.org/abs/2006.00885v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.00885v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
210,http://arxiv.org/abs/2005.11177v1,2020-05-22 13:30:42+00:00,2020-05-22 13:30:42+00:00,GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19 Tweets with Location Information,"[arxiv.Result.Author('Umair Qazi'), arxiv.Result.Author('Muhammad Imran'), arxiv.Result.Author('Ferda Ofli')]","The past several years have witnessed a huge surge in the use of social media
platforms during mass convergence events such as health emergencies, natural or
human-induced disasters. These non-traditional data sources are becoming vital
for disease forecasts and surveillance when preparing for epidemic and pandemic
outbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset
containing more than 524 million multilingual tweets posted over a period of 90
days since February 1, 2020. Moreover, we employ a gazetteer-based approach to
infer the geolocation of tweets. We postulate that this large-scale,
multilingual, geolocated social media data can empower the research communities
to evaluate how societies are collectively coping with this unprecedented
global crisis as well as to develop computational methods to address challenges
such as identifying fake news, understanding communities' knowledge gaps,
building disease forecast and surveillance models, among others.","10 pages, 5 figures, accepted at ACM SIGSPATIAL Special May 2020",,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2005.11177v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.11177v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.11177v1,"{'id': 'http://arxiv.org/abs/2005.11177v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.11177v1', 'updated': '2020-05-22T13:30:42Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=22, tm_hour=13, tm_min=30, tm_sec=42, tm_wday=4, tm_yday=143, tm_isdst=0), 'published': '2020-05-22T13:30:42Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=22, tm_hour=13, tm_min=30, tm_sec=42, tm_wday=4, tm_yday=143, tm_isdst=0), 'title': 'GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19\n  Tweets with Location Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19\n  Tweets with Location Information'}, 'summary': ""The past several years have witnessed a huge surge in the use of social media\nplatforms during mass convergence events such as health emergencies, natural or\nhuman-induced disasters. These non-traditional data sources are becoming vital\nfor disease forecasts and surveillance when preparing for epidemic and pandemic\noutbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset\ncontaining more than 524 million multilingual tweets posted over a period of 90\ndays since February 1, 2020. Moreover, we employ a gazetteer-based approach to\ninfer the geolocation of tweets. We postulate that this large-scale,\nmultilingual, geolocated social media data can empower the research communities\nto evaluate how societies are collectively coping with this unprecedented\nglobal crisis as well as to develop computational methods to address challenges\nsuch as identifying fake news, understanding communities' knowledge gaps,\nbuilding disease forecast and surveillance models, among others."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The past several years have witnessed a huge surge in the use of social media\nplatforms during mass convergence events such as health emergencies, natural or\nhuman-induced disasters. These non-traditional data sources are becoming vital\nfor disease forecasts and surveillance when preparing for epidemic and pandemic\noutbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset\ncontaining more than 524 million multilingual tweets posted over a period of 90\ndays since February 1, 2020. Moreover, we employ a gazetteer-based approach to\ninfer the geolocation of tweets. We postulate that this large-scale,\nmultilingual, geolocated social media data can empower the research communities\nto evaluate how societies are collectively coping with this unprecedented\nglobal crisis as well as to develop computational methods to address challenges\nsuch as identifying fake news, understanding communities' knowledge gaps,\nbuilding disease forecast and surveillance models, among others.""}, 'authors': [{'name': 'Umair Qazi'}, {'name': 'Muhammad Imran'}, {'name': 'Ferda Ofli'}], 'author_detail': {'name': 'Ferda Ofli'}, 'author': 'Ferda Ofli', 'arxiv_comment': '10 pages, 5 figures, accepted at ACM SIGSPATIAL Special May 2020', 'links': [{'href': 'http://arxiv.org/abs/2005.11177v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.11177v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
211,http://arxiv.org/abs/2005.09199v1,2020-05-19 03:52:21+00:00,2020-05-19 03:52:21+00:00,FrameProv: Towards End-To-End Video Provenance,[arxiv.Result.Author('Mansoor Ahmed-Rengers')],"Video feeds are often deliberately used as evidence, as in the case of CCTV
footage; but more often than not, the existence of footage of a supposed event
is perceived as proof of fact in the eyes of the public at large. This reliance
represents a societal vulnerability given the existence of easy-to-use editing
tools and means to fabricate entire video feeds using machine learning. And, as
the recent barrage of fake news and fake porn videos have shown, this isn't
merely an academic concern, it is actively been exploited. I posit that this
exploitation is only going to get more insidious. In this position paper, I
introduce a long term project that aims to mitigate some of the most egregious
forms of manipulation by embedding trustworthy components in the video
transmission chain. Unlike earlier works, I am not aiming to do tamper
detection or other forms of forensics -- approaches I think are bound to fail
in the face of the reality of necessary editing and compression -- instead, the
aim here is to provide a way for the video publisher to prove the integrity of
the video feed as well as make explicit any edits they may have performed. To
do this, I present a novel data structure, a video-edit specification language
and supporting infrastructure that provides end-to-end video provenance, from
the camera sensor to the viewer. I have implemented a prototype of this system
and am in talks with journalists and video editors to discuss the best ways
forward with introducing this idea to the mainstream.",,"New Security Paradigms Workshop, 2019",10.1145/3368860.3368866,cs.CR,"['cs.CR', 'cs.CY', 'cs.MM']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3368860.3368866', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.09199v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.09199v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.09199v1,"{'id': 'http://arxiv.org/abs/2005.09199v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.09199v1', 'updated': '2020-05-19T03:52:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=19, tm_hour=3, tm_min=52, tm_sec=21, tm_wday=1, tm_yday=140, tm_isdst=0), 'published': '2020-05-19T03:52:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=19, tm_hour=3, tm_min=52, tm_sec=21, tm_wday=1, tm_yday=140, tm_isdst=0), 'title': 'FrameProv: Towards End-To-End Video Provenance', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FrameProv: Towards End-To-End Video Provenance'}, 'summary': ""Video feeds are often deliberately used as evidence, as in the case of CCTV\nfootage; but more often than not, the existence of footage of a supposed event\nis perceived as proof of fact in the eyes of the public at large. This reliance\nrepresents a societal vulnerability given the existence of easy-to-use editing\ntools and means to fabricate entire video feeds using machine learning. And, as\nthe recent barrage of fake news and fake porn videos have shown, this isn't\nmerely an academic concern, it is actively been exploited. I posit that this\nexploitation is only going to get more insidious. In this position paper, I\nintroduce a long term project that aims to mitigate some of the most egregious\nforms of manipulation by embedding trustworthy components in the video\ntransmission chain. Unlike earlier works, I am not aiming to do tamper\ndetection or other forms of forensics -- approaches I think are bound to fail\nin the face of the reality of necessary editing and compression -- instead, the\naim here is to provide a way for the video publisher to prove the integrity of\nthe video feed as well as make explicit any edits they may have performed. To\ndo this, I present a novel data structure, a video-edit specification language\nand supporting infrastructure that provides end-to-end video provenance, from\nthe camera sensor to the viewer. I have implemented a prototype of this system\nand am in talks with journalists and video editors to discuss the best ways\nforward with introducing this idea to the mainstream."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Video feeds are often deliberately used as evidence, as in the case of CCTV\nfootage; but more often than not, the existence of footage of a supposed event\nis perceived as proof of fact in the eyes of the public at large. This reliance\nrepresents a societal vulnerability given the existence of easy-to-use editing\ntools and means to fabricate entire video feeds using machine learning. And, as\nthe recent barrage of fake news and fake porn videos have shown, this isn't\nmerely an academic concern, it is actively been exploited. I posit that this\nexploitation is only going to get more insidious. In this position paper, I\nintroduce a long term project that aims to mitigate some of the most egregious\nforms of manipulation by embedding trustworthy components in the video\ntransmission chain. Unlike earlier works, I am not aiming to do tamper\ndetection or other forms of forensics -- approaches I think are bound to fail\nin the face of the reality of necessary editing and compression -- instead, the\naim here is to provide a way for the video publisher to prove the integrity of\nthe video feed as well as make explicit any edits they may have performed. To\ndo this, I present a novel data structure, a video-edit specification language\nand supporting infrastructure that provides end-to-end video provenance, from\nthe camera sensor to the viewer. I have implemented a prototype of this system\nand am in talks with journalists and video editors to discuss the best ways\nforward with introducing this idea to the mainstream.""}, 'authors': [{'name': 'Mansoor Ahmed-Rengers'}], 'author_detail': {'name': 'Mansoor Ahmed-Rengers'}, 'author': 'Mansoor Ahmed-Rengers', 'arxiv_doi': '10.1145/3368860.3368866', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3368860.3368866', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.09199v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.09199v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'New Security Paradigms Workshop, 2019', 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
212,http://arxiv.org/abs/2005.08794v3,2021-01-13 19:24:59+00:00,2020-05-18 15:15:15+00:00,Inference on the History of a Randomly Growing Tree,"[arxiv.Result.Author('Harry Crane'), arxiv.Result.Author('Min Xu')]","The spread of infectious disease in a human community or the proliferation of
fake news on social media can be modeled as a randomly growing tree-shaped
graph. The history of the random growth process is often unobserved but
contains important information such as the source of the infection. We consider
the problem of statistical inference on aspects of the latent history using
only a single snapshot of the final tree. Our approach is to apply random
labels to the observed unlabeled tree and analyze the resulting distribution of
the growth process, conditional on the final outcome. We show that this
conditional distribution is tractable under a shape-exchangeability condition,
which we introduce here, and that this condition is satisfied for many popular
models for randomly growing trees such as uniform attachment, linear
preferential attachment and uniform attachment on a $D$-regular tree. For
inference of the root under shape-exchangeability, we propose O(n log n) time
algorithms for constructing confidence sets with valid frequentist coverage as
well as bounds on the expected size of the confidence sets. We also provide
efficient sampling algorithms that extend our methods to a wide class of
inference problems.",36 pages; 7 figures; 5 tables,,,math.PR,"['math.PR', 'math.ST', 'stat.CO', 'stat.TH', '90B15, 62M15']","[arxiv.Result.Link('http://arxiv.org/abs/2005.08794v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.08794v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.08794v3,"{'id': 'http://arxiv.org/abs/2005.08794v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.08794v3', 'updated': '2021-01-13T19:24:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=19, tm_min=24, tm_sec=59, tm_wday=2, tm_yday=13, tm_isdst=0), 'published': '2020-05-18T15:15:15Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=18, tm_hour=15, tm_min=15, tm_sec=15, tm_wday=0, tm_yday=139, tm_isdst=0), 'title': 'Inference on the History of a Randomly Growing Tree', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Inference on the History of a Randomly Growing Tree'}, 'summary': 'The spread of infectious disease in a human community or the proliferation of\nfake news on social media can be modeled as a randomly growing tree-shaped\ngraph. The history of the random growth process is often unobserved but\ncontains important information such as the source of the infection. We consider\nthe problem of statistical inference on aspects of the latent history using\nonly a single snapshot of the final tree. Our approach is to apply random\nlabels to the observed unlabeled tree and analyze the resulting distribution of\nthe growth process, conditional on the final outcome. We show that this\nconditional distribution is tractable under a shape-exchangeability condition,\nwhich we introduce here, and that this condition is satisfied for many popular\nmodels for randomly growing trees such as uniform attachment, linear\npreferential attachment and uniform attachment on a $D$-regular tree. For\ninference of the root under shape-exchangeability, we propose O(n log n) time\nalgorithms for constructing confidence sets with valid frequentist coverage as\nwell as bounds on the expected size of the confidence sets. We also provide\nefficient sampling algorithms that extend our methods to a wide class of\ninference problems.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of infectious disease in a human community or the proliferation of\nfake news on social media can be modeled as a randomly growing tree-shaped\ngraph. The history of the random growth process is often unobserved but\ncontains important information such as the source of the infection. We consider\nthe problem of statistical inference on aspects of the latent history using\nonly a single snapshot of the final tree. Our approach is to apply random\nlabels to the observed unlabeled tree and analyze the resulting distribution of\nthe growth process, conditional on the final outcome. We show that this\nconditional distribution is tractable under a shape-exchangeability condition,\nwhich we introduce here, and that this condition is satisfied for many popular\nmodels for randomly growing trees such as uniform attachment, linear\npreferential attachment and uniform attachment on a $D$-regular tree. For\ninference of the root under shape-exchangeability, we propose O(n log n) time\nalgorithms for constructing confidence sets with valid frequentist coverage as\nwell as bounds on the expected size of the confidence sets. We also provide\nefficient sampling algorithms that extend our methods to a wide class of\ninference problems.'}, 'authors': [{'name': 'Harry Crane'}, {'name': 'Min Xu'}], 'author_detail': {'name': 'Min Xu'}, 'author': 'Min Xu', 'arxiv_comment': '36 pages; 7 figures; 5 tables', 'links': [{'href': 'http://arxiv.org/abs/2005.08794v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.08794v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.ST', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '90B15, 62M15', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
213,http://arxiv.org/abs/2005.07688v2,2020-05-18 06:23:56+00:00,2020-05-15 17:56:11+00:00,Keystroke Biometrics in Response to Fake News Propagation in a Global Pandemic,"[arxiv.Result.Author('Aythami Morales'), arxiv.Result.Author('Alejandro Acien'), arxiv.Result.Author('Julian Fierrez'), arxiv.Result.Author('John V. Monaco'), arxiv.Result.Author('Ruben Tolosana'), arxiv.Result.Author('Ruben Vera-Rodriguez'), arxiv.Result.Author('Javier Ortega-Garcia')]","This work proposes and analyzes the use of keystroke biometrics for content
de-anonymization. Fake news have become a powerful tool to manipulate public
opinion, especially during major events. In particular, the massive spread of
fake news during the COVID-19 pandemic has forced governments and companies to
fight against missinformation. In this context, the ability to link multiple
accounts or profiles that spread such malicious content on the Internet while
hiding in anonymity would enable proactive identification and blacklisting.
Behavioral biometrics can be powerful tools in this fight. In this work, we
have analyzed how the latest advances in keystroke biometric recognition can
help to link behavioral typing patterns in experiments involving 100,000 users
and more than 1 million typed sequences. Our proposed system is based on
Recurrent Neural Networks adapted to the context of content de-anonymization.
Assuming the challenge to link the typed content of a target user in a pool of
candidate profiles, our results show that keystroke recognition can be used to
reduce the list of candidate profiles by more than 90%. In addition, when
keystroke is combined with auxiliary data (such as location), our system
achieves a Rank-1 identification performance equal to 52.6% and 10.9% for a
background candidate list composed of 1K and 100K profiles, respectively.",arXiv admin note: text overlap with arXiv:2004.03627,"IEEE International Workshop on Secure Digital Identity Management
  (SDIM) 2020",,cs.CR,"['cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2005.07688v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.07688v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.07688v2,"{'id': 'http://arxiv.org/abs/2005.07688v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.07688v2', 'updated': '2020-05-18T06:23:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=18, tm_hour=6, tm_min=23, tm_sec=56, tm_wday=0, tm_yday=139, tm_isdst=0), 'published': '2020-05-15T17:56:11Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=15, tm_hour=17, tm_min=56, tm_sec=11, tm_wday=4, tm_yday=136, tm_isdst=0), 'title': 'Keystroke Biometrics in Response to Fake News Propagation in a Global\n  Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Keystroke Biometrics in Response to Fake News Propagation in a Global\n  Pandemic'}, 'summary': 'This work proposes and analyzes the use of keystroke biometrics for content\nde-anonymization. Fake news have become a powerful tool to manipulate public\nopinion, especially during major events. In particular, the massive spread of\nfake news during the COVID-19 pandemic has forced governments and companies to\nfight against missinformation. In this context, the ability to link multiple\naccounts or profiles that spread such malicious content on the Internet while\nhiding in anonymity would enable proactive identification and blacklisting.\nBehavioral biometrics can be powerful tools in this fight. In this work, we\nhave analyzed how the latest advances in keystroke biometric recognition can\nhelp to link behavioral typing patterns in experiments involving 100,000 users\nand more than 1 million typed sequences. Our proposed system is based on\nRecurrent Neural Networks adapted to the context of content de-anonymization.\nAssuming the challenge to link the typed content of a target user in a pool of\ncandidate profiles, our results show that keystroke recognition can be used to\nreduce the list of candidate profiles by more than 90%. In addition, when\nkeystroke is combined with auxiliary data (such as location), our system\nachieves a Rank-1 identification performance equal to 52.6% and 10.9% for a\nbackground candidate list composed of 1K and 100K profiles, respectively.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This work proposes and analyzes the use of keystroke biometrics for content\nde-anonymization. Fake news have become a powerful tool to manipulate public\nopinion, especially during major events. In particular, the massive spread of\nfake news during the COVID-19 pandemic has forced governments and companies to\nfight against missinformation. In this context, the ability to link multiple\naccounts or profiles that spread such malicious content on the Internet while\nhiding in anonymity would enable proactive identification and blacklisting.\nBehavioral biometrics can be powerful tools in this fight. In this work, we\nhave analyzed how the latest advances in keystroke biometric recognition can\nhelp to link behavioral typing patterns in experiments involving 100,000 users\nand more than 1 million typed sequences. Our proposed system is based on\nRecurrent Neural Networks adapted to the context of content de-anonymization.\nAssuming the challenge to link the typed content of a target user in a pool of\ncandidate profiles, our results show that keystroke recognition can be used to\nreduce the list of candidate profiles by more than 90%. In addition, when\nkeystroke is combined with auxiliary data (such as location), our system\nachieves a Rank-1 identification performance equal to 52.6% and 10.9% for a\nbackground candidate list composed of 1K and 100K profiles, respectively.'}, 'authors': [{'name': 'Aythami Morales'}, {'name': 'Alejandro Acien'}, {'name': 'Julian Fierrez'}, {'name': 'John V. Monaco'}, {'name': 'Ruben Tolosana'}, {'name': 'Ruben Vera-Rodriguez'}, {'name': 'Javier Ortega-Garcia'}], 'author_detail': {'name': 'Javier Ortega-Garcia'}, 'author': 'Javier Ortega-Garcia', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:2004.03627', 'arxiv_journal_ref': 'IEEE International Workshop on Secure Digital Identity Management\n  (SDIM) 2020', 'links': [{'href': 'http://arxiv.org/abs/2005.07688v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.07688v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
214,http://arxiv.org/abs/2005.06058v1,2020-05-12 21:25:37+00:00,2020-05-12 21:25:37+00:00,That is a Known Lie: Detecting Previously Fact-Checked Claims,"[arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Nikolay Babulkov'), arxiv.Result.Author('Preslav Nakov')]","The recent proliferation of ""fake news"" has triggered a number of responses,
most notably the emergence of several manual fact-checking initiatives. As a
result and over time, a large number of fact-checked claims have been
accumulated, which increases the likelihood that a new claim in social media or
a new statement by a politician might have already been fact-checked by some
trusted fact-checking organization, as viral claims often come back after a
while in social media, and politicians like to repeat their favorite
statements, true or false, over and over again. As manual fact-checking is very
time-consuming (and fully automatic fact-checking has credibility issues), it
is important to try to save this effort and to avoid wasting time on claims
that have already been fact-checked. Interestingly, despite the importance of
the task, it has been largely ignored by the research community so far. Here,
we aim to bridge this gap. In particular, we formulate the task and we discuss
how it relates to, but also differs from, previous work. We further create a
specialized dataset, which we release to the research community. Finally, we
present learning-to-rank experiments that demonstrate sizable improvements over
state-of-the-art retrieval and textual similarity approaches.","detecting previously fact-checked claims, fact-checking,
  disinformation, fake news, social media, political debates",ACL-2020,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2005.06058v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.06058v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.06058v1,"{'id': 'http://arxiv.org/abs/2005.06058v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.06058v1', 'updated': '2020-05-12T21:25:37Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=21, tm_min=25, tm_sec=37, tm_wday=1, tm_yday=133, tm_isdst=0), 'published': '2020-05-12T21:25:37Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=21, tm_min=25, tm_sec=37, tm_wday=1, tm_yday=133, tm_isdst=0), 'title': 'That is a Known Lie: Detecting Previously Fact-Checked Claims', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'That is a Known Lie: Detecting Previously Fact-Checked Claims'}, 'summary': 'The recent proliferation of ""fake news"" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The recent proliferation of ""fake news"" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.'}, 'authors': [{'name': 'Shaden Shaar'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Nikolay Babulkov'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates', 'arxiv_journal_ref': 'ACL-2020', 'links': [{'href': 'http://arxiv.org/abs/2005.06058v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.06058v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
215,http://arxiv.org/abs/2005.05854v1,2020-05-12 15:20:55+00:00,2020-05-12 15:20:55+00:00,Prta: A System to Support the Analysis of Propaganda Techniques in the News,"[arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Yifan Zhang'), arxiv.Result.Author('Seunghak Yu'), arxiv.Result.Author('Alberto Barrón-Cedeño'), arxiv.Result.Author('Preslav Nakov')]","Recent events, such as the 2016 US Presidential Campaign, Brexit and the
COVID-19 ""infodemic"", have brought into the spotlight the dangers of online
disinformation. There has been a lot of research focusing on fact-checking and
disinformation detection. However, little attention has been paid to the
specific rhetorical and psychological techniques used to convey propaganda
messages. Revealing the use of such techniques can help promote media literacy
and critical thinking, and eventually contribute to limiting the impact of
""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion
Techniques Analyzer) allows users to explore the articles crawled on a regular
basis by highlighting the spans in which propaganda techniques occur and to
compare them on the basis of their use of propaganda techniques. The system
further reports statistics about the use of such techniques, overall and over
time, or according to filtering criteria specified by the user based on time
interval, keywords, and/or political orientation of the media. Moreover, it
allows users to analyze any text or URL through a dedicated interface or via an
API. The system is available online: https://www.tanbih.org/prta","propaganda, disinformation, fake news, media bias, COVID-19",ACL-2020,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'cs.NE', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2005.05854v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.05854v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.05854v1,"{'id': 'http://arxiv.org/abs/2005.05854v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.05854v1', 'updated': '2020-05-12T15:20:55Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=15, tm_min=20, tm_sec=55, tm_wday=1, tm_yday=133, tm_isdst=0), 'published': '2020-05-12T15:20:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=15, tm_min=20, tm_sec=55, tm_wday=1, tm_yday=133, tm_isdst=0), 'title': 'Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News'}, 'summary': 'Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 ""infodemic"", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 ""infodemic"", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta'}, 'authors': [{'name': 'Giovanni Da San Martino'}, {'name': 'Shaden Shaar'}, {'name': 'Yifan Zhang'}, {'name': 'Seunghak Yu'}, {'name': 'Alberto Barrón-Cedeño'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'propaganda, disinformation, fake news, media bias, COVID-19', 'arxiv_journal_ref': 'ACL-2020', 'links': [{'href': 'http://arxiv.org/abs/2005.05854v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.05854v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
216,http://arxiv.org/abs/2005.04938v1,2020-05-11 09:07:46+00:00,2020-05-11 09:07:46+00:00,A Deep Learning Approach for Automatic Detection of Fake News,"[arxiv.Result.Author('Tanik Saikh'), arxiv.Result.Author('Arkadipta De'), arxiv.Result.Author('Asif Ekbal'), arxiv.Result.Author('Pushpak Bhattacharyya')]","Fake news detection is a very prominent and essential task in the field of
journalism. This challenging problem is seen so far in the field of politics,
but it could be even more challenging when it is to be determined in the
multi-domain platform. In this paper, we propose two effective models based on
deep learning for solving fake news detection problem in online news contents
of multiple domains. We evaluate our techniques on the two recently released
datasets, namely FakeNews AMT and Celebrity for fake news detection. The
proposed systems yield encouraging performance, outperforming the current
handcrafted feature engineering based state-of-the-art system with a
significant margin of 3.08% and 9.3% by the two models, respectively. In order
to exploit the datasets, available for the related tasks, we perform
cross-domain analysis (i.e. model trained on FakeNews AMT and tested on
Celebrity and vice versa) to explore the applicability of our systems across
the domains.",,"Proceedings of the 16th International Conference on Natural
  Language Processing (ICON 2019)",,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2005.04938v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.04938v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.04938v1,"{'id': 'http://arxiv.org/abs/2005.04938v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.04938v1', 'updated': '2020-05-11T09:07:46Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=11, tm_hour=9, tm_min=7, tm_sec=46, tm_wday=0, tm_yday=132, tm_isdst=0), 'published': '2020-05-11T09:07:46Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=11, tm_hour=9, tm_min=7, tm_sec=46, tm_wday=0, tm_yday=132, tm_isdst=0), 'title': 'A Deep Learning Approach for Automatic Detection of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Deep Learning Approach for Automatic Detection of Fake News'}, 'summary': 'Fake news detection is a very prominent and essential task in the field of\njournalism. This challenging problem is seen so far in the field of politics,\nbut it could be even more challenging when it is to be determined in the\nmulti-domain platform. In this paper, we propose two effective models based on\ndeep learning for solving fake news detection problem in online news contents\nof multiple domains. We evaluate our techniques on the two recently released\ndatasets, namely FakeNews AMT and Celebrity for fake news detection. The\nproposed systems yield encouraging performance, outperforming the current\nhandcrafted feature engineering based state-of-the-art system with a\nsignificant margin of 3.08% and 9.3% by the two models, respectively. In order\nto exploit the datasets, available for the related tasks, we perform\ncross-domain analysis (i.e. model trained on FakeNews AMT and tested on\nCelebrity and vice versa) to explore the applicability of our systems across\nthe domains.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news detection is a very prominent and essential task in the field of\njournalism. This challenging problem is seen so far in the field of politics,\nbut it could be even more challenging when it is to be determined in the\nmulti-domain platform. In this paper, we propose two effective models based on\ndeep learning for solving fake news detection problem in online news contents\nof multiple domains. We evaluate our techniques on the two recently released\ndatasets, namely FakeNews AMT and Celebrity for fake news detection. The\nproposed systems yield encouraging performance, outperforming the current\nhandcrafted feature engineering based state-of-the-art system with a\nsignificant margin of 3.08% and 9.3% by the two models, respectively. In order\nto exploit the datasets, available for the related tasks, we perform\ncross-domain analysis (i.e. model trained on FakeNews AMT and tested on\nCelebrity and vice versa) to explore the applicability of our systems across\nthe domains.'}, 'authors': [{'name': 'Tanik Saikh'}, {'name': 'Arkadipta De'}, {'name': 'Asif Ekbal'}, {'name': 'Pushpak Bhattacharyya'}], 'author_detail': {'name': 'Pushpak Bhattacharyya'}, 'author': 'Pushpak Bhattacharyya', 'arxiv_journal_ref': 'Proceedings of the 16th International Conference on Natural\n  Language Processing (ICON 2019)', 'links': [{'href': 'http://arxiv.org/abs/2005.04938v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.04938v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
217,http://arxiv.org/abs/2005.05883v1,2020-05-10 05:46:51+00:00,2020-05-10 05:46:51+00:00,Networks in a World Unknown: Public WhatsApp Groups in the Venezuelan Refugee Crisis,[arxiv.Result.Author('Adam Chang')],"By early March 2020, five million Venezuelans had fled their home country
after its complete economic and institutional collapse, and over 1.6 million
have migrated to Colombia. Migrants struggle to start their lives over in
Colombia, having arrived with few economic resources, and often no legal
documentation, in cities with little to offer them. Venezuelan migrants,
however, rely heavily on mobile phones and social media networks as lifelines
for information, opportunities, and resources -- making WhatsApp both a
critical tool for migrants' settlement and integration, as well as an
invaluable source of data through which we can better understand migrant
experiences. This thesis explores the dynamics of public WhatsApp groups used
by Venezuelan migrants to Colombia, and what they can tell us about how
migrants use and share information. We center our research on information
spread and trust, especially as they intersect with concentration and
geographic heterogeneity within groups. We analyze messages and memberships
broadly, then explore interaction within groups, fake news and economic scams,
and effects of the coronavirus pandemic. Our results have a range of policy
implications, from reflections on Colombia's decision to shut its borders
amidst the coronavirus pandemic, to understandings of how aid organizations can
effectively share information over social media channels.",,,,cs.SI,"['cs.SI', 'stat.AP']","[arxiv.Result.Link('http://arxiv.org/abs/2005.05883v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.05883v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.05883v1,"{'id': 'http://arxiv.org/abs/2005.05883v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.05883v1', 'updated': '2020-05-10T05:46:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=10, tm_hour=5, tm_min=46, tm_sec=51, tm_wday=6, tm_yday=131, tm_isdst=0), 'published': '2020-05-10T05:46:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=10, tm_hour=5, tm_min=46, tm_sec=51, tm_wday=6, tm_yday=131, tm_isdst=0), 'title': 'Networks in a World Unknown: Public WhatsApp Groups in the Venezuelan\n  Refugee Crisis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Networks in a World Unknown: Public WhatsApp Groups in the Venezuelan\n  Refugee Crisis'}, 'summary': ""By early March 2020, five million Venezuelans had fled their home country\nafter its complete economic and institutional collapse, and over 1.6 million\nhave migrated to Colombia. Migrants struggle to start their lives over in\nColombia, having arrived with few economic resources, and often no legal\ndocumentation, in cities with little to offer them. Venezuelan migrants,\nhowever, rely heavily on mobile phones and social media networks as lifelines\nfor information, opportunities, and resources -- making WhatsApp both a\ncritical tool for migrants' settlement and integration, as well as an\ninvaluable source of data through which we can better understand migrant\nexperiences. This thesis explores the dynamics of public WhatsApp groups used\nby Venezuelan migrants to Colombia, and what they can tell us about how\nmigrants use and share information. We center our research on information\nspread and trust, especially as they intersect with concentration and\ngeographic heterogeneity within groups. We analyze messages and memberships\nbroadly, then explore interaction within groups, fake news and economic scams,\nand effects of the coronavirus pandemic. Our results have a range of policy\nimplications, from reflections on Colombia's decision to shut its borders\namidst the coronavirus pandemic, to understandings of how aid organizations can\neffectively share information over social media channels."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""By early March 2020, five million Venezuelans had fled their home country\nafter its complete economic and institutional collapse, and over 1.6 million\nhave migrated to Colombia. Migrants struggle to start their lives over in\nColombia, having arrived with few economic resources, and often no legal\ndocumentation, in cities with little to offer them. Venezuelan migrants,\nhowever, rely heavily on mobile phones and social media networks as lifelines\nfor information, opportunities, and resources -- making WhatsApp both a\ncritical tool for migrants' settlement and integration, as well as an\ninvaluable source of data through which we can better understand migrant\nexperiences. This thesis explores the dynamics of public WhatsApp groups used\nby Venezuelan migrants to Colombia, and what they can tell us about how\nmigrants use and share information. We center our research on information\nspread and trust, especially as they intersect with concentration and\ngeographic heterogeneity within groups. We analyze messages and memberships\nbroadly, then explore interaction within groups, fake news and economic scams,\nand effects of the coronavirus pandemic. Our results have a range of policy\nimplications, from reflections on Colombia's decision to shut its borders\namidst the coronavirus pandemic, to understandings of how aid organizations can\neffectively share information over social media channels.""}, 'authors': [{'name': 'Adam Chang'}], 'author_detail': {'name': 'Adam Chang'}, 'author': 'Adam Chang', 'links': [{'href': 'http://arxiv.org/abs/2005.05883v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.05883v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
218,http://arxiv.org/abs/2005.04518v1,2020-05-09 22:00:08+00:00,2020-05-09 22:00:08+00:00,What Was Written vs. Who Read It: News Media Profiling Using Text Analysis and Social Media Context,"[arxiv.Result.Author('Ramy Baly'), arxiv.Result.Author('Georgi Karadzhov'), arxiv.Result.Author('Jisun An'), arxiv.Result.Author('Haewoon Kwak'), arxiv.Result.Author('Yoan Dinkov'), arxiv.Result.Author('Ahmed Ali'), arxiv.Result.Author('James Glass'), arxiv.Result.Author('Preslav Nakov')]","Predicting the political bias and the factuality of reporting of entire news
outlets are critical elements of media profiling, which is an understudied but
an increasingly important research direction. The present level of
proliferation of fake, biased, and propagandistic content online, has made it
impossible to fact-check every single suspicious claim, either manually or
automatically. Alternatively, we can profile entire news outlets and look for
those that are likely to publish fake or biased content. This approach makes it
possible to detect likely ""fake news"" the moment they are published, by simply
checking the reliability of their source. From a practical perspective,
political bias and factuality of reporting have a linguistic aspect but also a
social context. Here, we study the impact of both, namely (i) what was written
(i.e., what was published by the target medium, and how it describes itself on
Twitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium
on Facebook, Twitter, and YouTube). We further study (iii) what was written
about the target medium on Wikipedia. The evaluation results show that what was
written matters most, and that putting all information sources together yields
huge improvements over the current state-of-the-art.","Factuality of reporting, fact-checking, political ideology, media
  bias, disinformation, propaganda, social media, news media",ACL-2020,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2005.04518v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.04518v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.04518v1,"{'id': 'http://arxiv.org/abs/2005.04518v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.04518v1', 'updated': '2020-05-09T22:00:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=9, tm_hour=22, tm_min=0, tm_sec=8, tm_wday=5, tm_yday=130, tm_isdst=0), 'published': '2020-05-09T22:00:08Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=9, tm_hour=22, tm_min=0, tm_sec=8, tm_wday=5, tm_yday=130, tm_isdst=0), 'title': 'What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context'}, 'summary': 'Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely ""fake news"" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely ""fake news"" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.'}, 'authors': [{'name': 'Ramy Baly'}, {'name': 'Georgi Karadzhov'}, {'name': 'Jisun An'}, {'name': 'Haewoon Kwak'}, {'name': 'Yoan Dinkov'}, {'name': 'Ahmed Ali'}, {'name': 'James Glass'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media', 'arxiv_journal_ref': 'ACL-2020', 'links': [{'href': 'http://arxiv.org/abs/2005.04518v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.04518v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
219,http://arxiv.org/abs/2005.03550v1,2020-05-07 15:21:56+00:00,2020-05-07 15:21:56+00:00,Credulous Users and Fake News: a Real Case Study on the Propagation in Twitter,"[arxiv.Result.Author('Alessandro Balestrucci'), arxiv.Result.Author('Rocco De Nicola')]","Recent studies have confirmed a growing trend, especially among youngsters,
of using Online Social Media as favourite information platform at the expense
of traditional mass media. Indeed, they can easily reach a wide audience at a
high speed; but exactly because of this they are the preferred medium for
influencing public opinion via so-called fake news. Moreover, there is a
general agreement that the main vehicle of fakes news are malicious software
robots (bots) that automatically interact with human users. In previous work we
have considered the problem of tagging human users in Online Social Networks as
credulous users. Specifically, we have considered credulous those users with
relatively high number of bot friends when compared to total number of their
social friends. We consider this group of users worth of attention because they
might have a higher exposure to malicious activities and they may contribute to
the spreading of fake information by sharing dubious content. In this work,
starting from a dataset of fake news, we investigate the behaviour and the
degree of involvement of credulous users in fake news diffusion. The study aims
to: (i) fight fake news by considering the content diffused by credulous users;
(ii) highlight the relationship between credulous users and fake news
spreading; (iii) target fake news detection by focusing on the analysis of
specific accounts more exposed to malicious activities of bots. Our first
results demonstrate a strong involvement of credulous users in fake news
diffusion. This findings are calling for tools that, by performing data
streaming on credulous' users actions, enables us to perform targeted
fact-checking.","15 pages and 8 tables. Accepted to appear in the Proceedings at IEEE
  Conference on Evolving and Adaptive Intelligent Systems (EAIS2020)",,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2005.03550v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.03550v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.03550v1,"{'id': 'http://arxiv.org/abs/2005.03550v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.03550v1', 'updated': '2020-05-07T15:21:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=7, tm_hour=15, tm_min=21, tm_sec=56, tm_wday=3, tm_yday=128, tm_isdst=0), 'published': '2020-05-07T15:21:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=7, tm_hour=15, tm_min=21, tm_sec=56, tm_wday=3, tm_yday=128, tm_isdst=0), 'title': 'Credulous Users and Fake News: a Real Case Study on the Propagation in\n  Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Credulous Users and Fake News: a Real Case Study on the Propagation in\n  Twitter'}, 'summary': ""Recent studies have confirmed a growing trend, especially among youngsters,\nof using Online Social Media as favourite information platform at the expense\nof traditional mass media. Indeed, they can easily reach a wide audience at a\nhigh speed; but exactly because of this they are the preferred medium for\ninfluencing public opinion via so-called fake news. Moreover, there is a\ngeneral agreement that the main vehicle of fakes news are malicious software\nrobots (bots) that automatically interact with human users. In previous work we\nhave considered the problem of tagging human users in Online Social Networks as\ncredulous users. Specifically, we have considered credulous those users with\nrelatively high number of bot friends when compared to total number of their\nsocial friends. We consider this group of users worth of attention because they\nmight have a higher exposure to malicious activities and they may contribute to\nthe spreading of fake information by sharing dubious content. In this work,\nstarting from a dataset of fake news, we investigate the behaviour and the\ndegree of involvement of credulous users in fake news diffusion. The study aims\nto: (i) fight fake news by considering the content diffused by credulous users;\n(ii) highlight the relationship between credulous users and fake news\nspreading; (iii) target fake news detection by focusing on the analysis of\nspecific accounts more exposed to malicious activities of bots. Our first\nresults demonstrate a strong involvement of credulous users in fake news\ndiffusion. This findings are calling for tools that, by performing data\nstreaming on credulous' users actions, enables us to perform targeted\nfact-checking."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recent studies have confirmed a growing trend, especially among youngsters,\nof using Online Social Media as favourite information platform at the expense\nof traditional mass media. Indeed, they can easily reach a wide audience at a\nhigh speed; but exactly because of this they are the preferred medium for\ninfluencing public opinion via so-called fake news. Moreover, there is a\ngeneral agreement that the main vehicle of fakes news are malicious software\nrobots (bots) that automatically interact with human users. In previous work we\nhave considered the problem of tagging human users in Online Social Networks as\ncredulous users. Specifically, we have considered credulous those users with\nrelatively high number of bot friends when compared to total number of their\nsocial friends. We consider this group of users worth of attention because they\nmight have a higher exposure to malicious activities and they may contribute to\nthe spreading of fake information by sharing dubious content. In this work,\nstarting from a dataset of fake news, we investigate the behaviour and the\ndegree of involvement of credulous users in fake news diffusion. The study aims\nto: (i) fight fake news by considering the content diffused by credulous users;\n(ii) highlight the relationship between credulous users and fake news\nspreading; (iii) target fake news detection by focusing on the analysis of\nspecific accounts more exposed to malicious activities of bots. Our first\nresults demonstrate a strong involvement of credulous users in fake news\ndiffusion. This findings are calling for tools that, by performing data\nstreaming on credulous' users actions, enables us to perform targeted\nfact-checking.""}, 'authors': [{'name': 'Alessandro Balestrucci'}, {'name': 'Rocco De Nicola'}], 'author_detail': {'name': 'Rocco De Nicola'}, 'author': 'Rocco De Nicola', 'arxiv_comment': '15 pages and 8 tables. Accepted to appear in the Proceedings at IEEE\n  Conference on Evolving and Adaptive Intelligent Systems (EAIS2020)', 'links': [{'href': 'http://arxiv.org/abs/2005.03550v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.03550v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
220,http://arxiv.org/abs/2005.02443v1,2020-05-05 19:08:26+00:00,2020-05-05 19:08:26+00:00,A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian and Indian Elections,"[arxiv.Result.Author('Julio C. S. Reis'), arxiv.Result.Author('Philipe de Freitas Melo'), arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Jussara M. Almeida'), arxiv.Result.Author('Dean Eckles'), arxiv.Result.Author('Fabrício Benevenuto')]","Recently, messaging applications, such as WhatsApp, have been reportedly
abused by misinformation campaigns, especially in Brazil and India. A notable
form of abuse in WhatsApp relies on several manipulated images and memes
containing all kinds of fake stories. In this work, we performed an extensive
data collection from a large set of WhatsApp publicly accessible groups and
fact-checking agency websites. This paper opens a novel dataset to the research
community containing fact-checked fake images shared through WhatsApp for two
distinct scenarios known for the spread of fake news on the platform: the 2018
Brazilian elections and the 2019 Indian elections.","7 pages. This is a preprint version of an accepted paper on ICWSM'20.
  Please, consider to cite the conference version instead of this one",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2005.02443v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.02443v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.02443v1,"{'id': 'http://arxiv.org/abs/2005.02443v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.02443v1', 'updated': '2020-05-05T19:08:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=5, tm_hour=19, tm_min=8, tm_sec=26, tm_wday=1, tm_yday=126, tm_isdst=0), 'published': '2020-05-05T19:08:26Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=5, tm_hour=19, tm_min=8, tm_sec=26, tm_wday=1, tm_yday=126, tm_isdst=0), 'title': 'A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections'}, 'summary': 'Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.'}, 'authors': [{'name': 'Julio C. S. Reis'}, {'name': 'Philipe de Freitas Melo'}, {'name': 'Kiran Garimella'}, {'name': 'Jussara M. Almeida'}, {'name': 'Dean Eckles'}, {'name': 'Fabrício Benevenuto'}], 'author_detail': {'name': 'Fabrício Benevenuto'}, 'author': 'Fabrício Benevenuto', 'arxiv_comment': ""7 pages. This is a preprint version of an accepted paper on ICWSM'20.\n  Please, consider to cite the conference version instead of this one"", 'links': [{'href': 'http://arxiv.org/abs/2005.02443v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.02443v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
221,http://arxiv.org/abs/2005.01157v1,2020-05-03 18:02:10+00:00,2020-05-03 18:02:10+00:00,Out of the Echo Chamber: Detecting Countering Debate Speeches,"[arxiv.Result.Author('Matan Orbach'), arxiv.Result.Author('Yonatan Bilu'), arxiv.Result.Author('Assaf Toledo'), arxiv.Result.Author('Dan Lahav'), arxiv.Result.Author('Michal Jacovi'), arxiv.Result.Author('Ranit Aharonov'), arxiv.Result.Author('Noam Slonim')]","An educated and informed consumption of media content has become a challenge
in modern times. With the shift from traditional news outlets to social media
and similar venues, a major concern is that readers are becoming encapsulated
in ""echo chambers"" and may fall prey to fake news and disinformation, lacking
easy access to dissenting views. We suggest a novel task aiming to alleviate
some of these concerns -- that of detecting articles that most effectively
counter the arguments -- and not just the stance -- made in a given text. We
study this problem in the context of debate speeches. Given such a speech, we
aim to identify, from among a set of speeches on the same topic and with an
opposing stance, the ones that directly counter it. We provide a large dataset
of 3,685 such speeches (in English), annotated for this relation, which
hopefully would be of general interest to the NLP community. We explore several
algorithms addressing this task, and while some are successful, all fall short
of expert human performance, suggesting room for further research. All data
collected during this work is freely available for research.","Accepted to ACL 2020 as Long Paper. For the associated debate
  speeches corpus, see
  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2005.01157v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.01157v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.01157v1,"{'id': 'http://arxiv.org/abs/2005.01157v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.01157v1', 'updated': '2020-05-03T18:02:10Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=3, tm_hour=18, tm_min=2, tm_sec=10, tm_wday=6, tm_yday=124, tm_isdst=0), 'published': '2020-05-03T18:02:10Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=3, tm_hour=18, tm_min=2, tm_sec=10, tm_wday=6, tm_yday=124, tm_isdst=0), 'title': 'Out of the Echo Chamber: Detecting Countering Debate Speeches', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Out of the Echo Chamber: Detecting Countering Debate Speeches'}, 'summary': 'An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin ""echo chambers"" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin ""echo chambers"" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.'}, 'authors': [{'name': 'Matan Orbach'}, {'name': 'Yonatan Bilu'}, {'name': 'Assaf Toledo'}, {'name': 'Dan Lahav'}, {'name': 'Michal Jacovi'}, {'name': 'Ranit Aharonov'}, {'name': 'Noam Slonim'}], 'author_detail': {'name': 'Noam Slonim'}, 'author': 'Noam Slonim', 'arxiv_comment': 'Accepted to ACL 2020 as Long Paper. For the associated debate\n  speeches corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis', 'links': [{'href': 'http://arxiv.org/abs/2005.01157v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.01157v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
222,http://arxiv.org/abs/2004.14907v1,2020-04-30 16:06:02+00:00,2020-04-30 16:06:02+00:00,You are right. I am ALARMED -- But by Climate Change Counter Movement,"[arxiv.Result.Author('Shraey Bhatia'), arxiv.Result.Author('Jey Han Lau'), arxiv.Result.Author('Timothy Baldwin')]","The world is facing the challenge of climate crisis. Despite the consensus in
scientific community about anthropogenic global warming, the web is flooded
with articles spreading climate misinformation. These articles are carefully
constructed by climate change counter movement (cccm) organizations to
influence the narrative around climate change. We revisit the literature on
climate misinformation in social sciences and repackage it to introduce in the
community of NLP. Despite considerable work in detection of fake news, there is
no misinformation dataset available that is specific to the domain.of climate
change. We try to bridge this gap by scraping and releasing articles with known
climate change misinformation.",5 pages,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.14907v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.14907v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.14907v1,"{'id': 'http://arxiv.org/abs/2004.14907v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.14907v1', 'updated': '2020-04-30T16:06:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=16, tm_min=6, tm_sec=2, tm_wday=3, tm_yday=121, tm_isdst=0), 'published': '2020-04-30T16:06:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=16, tm_min=6, tm_sec=2, tm_wday=3, tm_yday=121, tm_isdst=0), 'title': 'You are right. I am ALARMED -- But by Climate Change Counter Movement', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'You are right. I am ALARMED -- But by Climate Change Counter Movement'}, 'summary': 'The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.'}, 'authors': [{'name': 'Shraey Bhatia'}, {'name': 'Jey Han Lau'}, {'name': 'Timothy Baldwin'}], 'author_detail': {'name': 'Timothy Baldwin'}, 'author': 'Timothy Baldwin', 'arxiv_comment': '5 pages', 'links': [{'href': 'http://arxiv.org/abs/2004.14907v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.14907v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
223,http://arxiv.org/abs/2005.00485v1,2020-04-30 14:59:25+00:00,2020-04-30 14:59:25+00:00,Getting Insights from a Large Corpus of Scientific Papers on Specialisted Comprehensive Topics -- the Case of COVID-19,"[arxiv.Result.Author('Bernard Dousset'), arxiv.Result.Author('Josiane Mothe')]","COVID-19 is one of the most important topic these days, specifically on
search engines and news. While fake news are easily shared, scientific papers
are reliable sources where information can be extracted. With about 24,000
scientific publications on COVID-19 and related research on PUBMED, automatic
computer-assisted analysis is required. In this paper, we develop two
methodologies to get insights on specific sub-topics of interest and latest
research sub-topics. They rely on natural language processing and graph-based
visualizations. We run these methodologies on two cases: the virus origin and
the uses of existing drugs.",14 pages; 5 figures and 3 tables submitted to KES 2020,,,cs.DL,"['cs.DL', 'cs.IR', 'H.3']","[arxiv.Result.Link('http://arxiv.org/abs/2005.00485v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.00485v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.00485v1,"{'id': 'http://arxiv.org/abs/2005.00485v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.00485v1', 'updated': '2020-04-30T14:59:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=14, tm_min=59, tm_sec=25, tm_wday=3, tm_yday=121, tm_isdst=0), 'published': '2020-04-30T14:59:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=14, tm_min=59, tm_sec=25, tm_wday=3, tm_yday=121, tm_isdst=0), 'title': 'Getting Insights from a Large Corpus of Scientific Papers on\n  Specialisted Comprehensive Topics -- the Case of COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Getting Insights from a Large Corpus of Scientific Papers on\n  Specialisted Comprehensive Topics -- the Case of COVID-19'}, 'summary': 'COVID-19 is one of the most important topic these days, specifically on\nsearch engines and news. While fake news are easily shared, scientific papers\nare reliable sources where information can be extracted. With about 24,000\nscientific publications on COVID-19 and related research on PUBMED, automatic\ncomputer-assisted analysis is required. In this paper, we develop two\nmethodologies to get insights on specific sub-topics of interest and latest\nresearch sub-topics. They rely on natural language processing and graph-based\nvisualizations. We run these methodologies on two cases: the virus origin and\nthe uses of existing drugs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 is one of the most important topic these days, specifically on\nsearch engines and news. While fake news are easily shared, scientific papers\nare reliable sources where information can be extracted. With about 24,000\nscientific publications on COVID-19 and related research on PUBMED, automatic\ncomputer-assisted analysis is required. In this paper, we develop two\nmethodologies to get insights on specific sub-topics of interest and latest\nresearch sub-topics. They rely on natural language processing and graph-based\nvisualizations. We run these methodologies on two cases: the virus origin and\nthe uses of existing drugs.'}, 'authors': [{'name': 'Bernard Dousset'}, {'name': 'Josiane Mothe'}], 'author_detail': {'name': 'Josiane Mothe'}, 'author': 'Josiane Mothe', 'arxiv_comment': '14 pages; 5 figures and 3 tables submitted to KES 2020', 'links': [{'href': 'http://arxiv.org/abs/2005.00485v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.00485v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
224,http://arxiv.org/abs/2004.11648v1,2020-04-24 10:42:49+00:00,2020-04-24 10:42:49+00:00,GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media,"[arxiv.Result.Author('Yi-Ju Lu'), arxiv.Result.Author('Cheng-Te Li')]","This paper solves the fake news detection problem under a more realistic
scenario on social media. Given the source short-text tweet and the
corresponding sequence of retweet users without text comments, we aim at
predicting whether the source tweet is fake or not, and generating explanation
by highlighting the evidences on suspicious retweeters and the words they
concern. We develop a novel neural network-based model, Graph-aware
Co-Attention Networks (GCAN), to achieve the goal. Extensive experiments
conducted on real tweet datasets exhibit that GCAN can significantly outperform
state-of-the-art methods by 16% in accuracy on average. In addition, the case
studies also show that GCAN can produce reasonable explanations.","To appear in Proceedings of The 58th Annual Meeting of the
  Association for Computational Linguistics, ACL 2020. Code is available here
  https://github.com/l852888/GCAN",,,cs.CL,"['cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2004.11648v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.11648v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.11648v1,"{'id': 'http://arxiv.org/abs/2004.11648v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.11648v1', 'updated': '2020-04-24T10:42:49Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=24, tm_hour=10, tm_min=42, tm_sec=49, tm_wday=4, tm_yday=115, tm_isdst=0), 'published': '2020-04-24T10:42:49Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=24, tm_hour=10, tm_min=42, tm_sec=49, tm_wday=4, tm_yday=115, tm_isdst=0), 'title': 'GCAN: Graph-aware Co-Attention Networks for Explainable Fake News\n  Detection on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'GCAN: Graph-aware Co-Attention Networks for Explainable Fake News\n  Detection on Social Media'}, 'summary': 'This paper solves the fake news detection problem under a more realistic\nscenario on social media. Given the source short-text tweet and the\ncorresponding sequence of retweet users without text comments, we aim at\npredicting whether the source tweet is fake or not, and generating explanation\nby highlighting the evidences on suspicious retweeters and the words they\nconcern. We develop a novel neural network-based model, Graph-aware\nCo-Attention Networks (GCAN), to achieve the goal. Extensive experiments\nconducted on real tweet datasets exhibit that GCAN can significantly outperform\nstate-of-the-art methods by 16% in accuracy on average. In addition, the case\nstudies also show that GCAN can produce reasonable explanations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper solves the fake news detection problem under a more realistic\nscenario on social media. Given the source short-text tweet and the\ncorresponding sequence of retweet users without text comments, we aim at\npredicting whether the source tweet is fake or not, and generating explanation\nby highlighting the evidences on suspicious retweeters and the words they\nconcern. We develop a novel neural network-based model, Graph-aware\nCo-Attention Networks (GCAN), to achieve the goal. Extensive experiments\nconducted on real tweet datasets exhibit that GCAN can significantly outperform\nstate-of-the-art methods by 16% in accuracy on average. In addition, the case\nstudies also show that GCAN can produce reasonable explanations.'}, 'authors': [{'name': 'Yi-Ju Lu'}, {'name': 'Cheng-Te Li'}], 'author_detail': {'name': 'Cheng-Te Li'}, 'author': 'Cheng-Te Li', 'arxiv_comment': 'To appear in Proceedings of The 58th Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020. Code is available here\n  https://github.com/l852888/GCAN', 'links': [{'href': 'http://arxiv.org/abs/2004.11648v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.11648v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
225,http://arxiv.org/abs/2004.11480v1,2020-04-23 22:25:48+00:00,2020-04-23 22:25:48+00:00,Characterising User Content on a Multi-lingual Social Network,"[arxiv.Result.Author('Pushkal Agarwal'), arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Sagar Joglekar'), arxiv.Result.Author('Nishanth Sastry'), arxiv.Result.Author('Gareth Tyson')]","Social media has been on the vanguard of political information diffusion in
the 21st century. Most studies that look into disinformation, political
influence and fake-news focus on mainstream social media platforms. This has
inevitably made English an important factor in our current understanding of
political activity on social media. As a result, there has only been a limited
number of studies into a large portion of the world, including the largest,
multilingual and multi-cultural democracy: India. In this paper we present our
characterisation of a multilingual social network in India called ShareChat. We
collect an exhaustive dataset across 72 weeks before and during the Indian
general elections of 2019, across 14 languages. We investigate the cross
lingual dynamics by clustering visually similar images together, and exploring
how they move across language barriers. We find that Telugu, Malayalam, Tamil
and Kannada languages tend to be dominant in soliciting political images (often
referred to as memes), and posts from Hindi have the largest cross-lingual
diffusion across ShareChat (as well as images containing text in English). In
the case of images containing text that cross language barriers, we see that
language translation is used to widen the accessibility. That said, we find
cases where the same image is associated with very different text (and
therefore meanings). This initial characterisation paves the way for more
advanced pipelines to understand the dynamics of fake and political content in
a multi-lingual and non-textual setting.","Accepted at ICWSM 2020, please cite the ICWSM version",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2004.11480v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.11480v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.11480v1,"{'id': 'http://arxiv.org/abs/2004.11480v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.11480v1', 'updated': '2020-04-23T22:25:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=23, tm_hour=22, tm_min=25, tm_sec=48, tm_wday=3, tm_yday=114, tm_isdst=0), 'published': '2020-04-23T22:25:48Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=23, tm_hour=22, tm_min=25, tm_sec=48, tm_wday=3, tm_yday=114, tm_isdst=0), 'title': 'Characterising User Content on a Multi-lingual Social Network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterising User Content on a Multi-lingual Social Network'}, 'summary': 'Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.'}, 'authors': [{'name': 'Pushkal Agarwal'}, {'name': 'Kiran Garimella'}, {'name': 'Sagar Joglekar'}, {'name': 'Nishanth Sastry'}, {'name': 'Gareth Tyson'}], 'author_detail': {'name': 'Gareth Tyson'}, 'author': 'Gareth Tyson', 'arxiv_comment': 'Accepted at ICWSM 2020, please cite the ICWSM version', 'links': [{'href': 'http://arxiv.org/abs/2004.11480v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.11480v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
226,http://arxiv.org/abs/2004.10399v3,2020-08-27 09:07:02+00:00,2020-04-22 05:37:17+00:00,Anger makes fake news viral online,"[arxiv.Result.Author('Yuwei Chuai'), arxiv.Result.Author('Jichang Zhao')]","Fake news that manipulates political elections, strikes financial systems,
and even incites riots is more viral than real news online, resulting in
unstable societies and buffeted democracy. The easier contagion of fake news
online can be causally explained by the greater anger it carries. The same
results in Twitter and Weibo indicate that this mechanism is independent of the
platform. Moreover, mutations in emotions like increasing anger will
progressively speed up the information spread. Specifically, increasing the
occupation of anger by 0.1 and reducing that of joy by 0.1 will produce nearly
6 more retweets in the Weibo dataset. Offline questionnaires reveal that anger
leads to more incentivized audiences in terms of anxiety management and
information sharing and accordingly makes fake news more contagious than real
news online. Cures such as tagging anger in social media could be implemented
to slow or prevent the contagion of fake news at the source.","All data used in this study can be publicly available through
  https://doi.org/10.6084/m9.figshare.12163569.v2",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2004.10399v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.10399v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.10399v3,"{'id': 'http://arxiv.org/abs/2004.10399v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.10399v3', 'updated': '2020-08-27T09:07:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=27, tm_hour=9, tm_min=7, tm_sec=2, tm_wday=3, tm_yday=240, tm_isdst=0), 'published': '2020-04-22T05:37:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=22, tm_hour=5, tm_min=37, tm_sec=17, tm_wday=2, tm_yday=113, tm_isdst=0), 'title': 'Anger makes fake news viral online', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Anger makes fake news viral online'}, 'summary': 'Fake news that manipulates political elections, strikes financial systems,\nand even incites riots is more viral than real news online, resulting in\nunstable societies and buffeted democracy. The easier contagion of fake news\nonline can be causally explained by the greater anger it carries. The same\nresults in Twitter and Weibo indicate that this mechanism is independent of the\nplatform. Moreover, mutations in emotions like increasing anger will\nprogressively speed up the information spread. Specifically, increasing the\noccupation of anger by 0.1 and reducing that of joy by 0.1 will produce nearly\n6 more retweets in the Weibo dataset. Offline questionnaires reveal that anger\nleads to more incentivized audiences in terms of anxiety management and\ninformation sharing and accordingly makes fake news more contagious than real\nnews online. Cures such as tagging anger in social media could be implemented\nto slow or prevent the contagion of fake news at the source.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news that manipulates political elections, strikes financial systems,\nand even incites riots is more viral than real news online, resulting in\nunstable societies and buffeted democracy. The easier contagion of fake news\nonline can be causally explained by the greater anger it carries. The same\nresults in Twitter and Weibo indicate that this mechanism is independent of the\nplatform. Moreover, mutations in emotions like increasing anger will\nprogressively speed up the information spread. Specifically, increasing the\noccupation of anger by 0.1 and reducing that of joy by 0.1 will produce nearly\n6 more retweets in the Weibo dataset. Offline questionnaires reveal that anger\nleads to more incentivized audiences in terms of anxiety management and\ninformation sharing and accordingly makes fake news more contagious than real\nnews online. Cures such as tagging anger in social media could be implemented\nto slow or prevent the contagion of fake news at the source.'}, 'authors': [{'name': 'Yuwei Chuai'}, {'name': 'Jichang Zhao'}], 'author_detail': {'name': 'Jichang Zhao'}, 'author': 'Jichang Zhao', 'arxiv_comment': 'All data used in this study can be publicly available through\n  https://doi.org/10.6084/m9.figshare.12163569.v2', 'links': [{'href': 'http://arxiv.org/abs/2004.10399v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.10399v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
227,http://arxiv.org/abs/2004.10009v1,2020-04-21 13:51:03+00:00,2020-04-21 13:51:03+00:00,Adaptive Interaction Fusion Networks for Fake News Detection,"[arxiv.Result.Author('Lianwei Wu'), arxiv.Result.Author('Yuan Rao')]","The majority of existing methods for fake news detection universally focus on
learning and fusing various features for detection. However, the learning of
various features is independent, which leads to a lack of cross-interaction
fusion between features on social media, especially between posts and comments.
Generally, in fake news, there are emotional associations and semantic
conflicts between posts and comments. How to represent and fuse the
cross-interaction between both is a key challenge. In this paper, we propose
Adaptive Interaction Fusion Networks (AIFN) to fulfill cross-interaction fusion
among features for fake news detection. In AIFN, to discover semantic
conflicts, we design gated adaptive interaction networks (GAIN) to capture
adaptively similar semantics and conflicting semantics between posts and
comments. To establish feature associations, we devise semantic-level fusion
self-attention networks (SFSN) to enhance semantic correlations and fusion
among features. Extensive experiments on two real-world datasets, i.e.,
RumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art
performance and boosts accuracy by more than 2.05% and 1.90%, respectively.","Accepted at the 24th European Conference on Artificial Intelligence
  (ECAI 2020)",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2004.10009v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.10009v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.10009v1,"{'id': 'http://arxiv.org/abs/2004.10009v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.10009v1', 'updated': '2020-04-21T13:51:03Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=21, tm_hour=13, tm_min=51, tm_sec=3, tm_wday=1, tm_yday=112, tm_isdst=0), 'published': '2020-04-21T13:51:03Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=21, tm_hour=13, tm_min=51, tm_sec=3, tm_wday=1, tm_yday=112, tm_isdst=0), 'title': 'Adaptive Interaction Fusion Networks for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adaptive Interaction Fusion Networks for Fake News Detection'}, 'summary': 'The majority of existing methods for fake news detection universally focus on\nlearning and fusing various features for detection. However, the learning of\nvarious features is independent, which leads to a lack of cross-interaction\nfusion between features on social media, especially between posts and comments.\nGenerally, in fake news, there are emotional associations and semantic\nconflicts between posts and comments. How to represent and fuse the\ncross-interaction between both is a key challenge. In this paper, we propose\nAdaptive Interaction Fusion Networks (AIFN) to fulfill cross-interaction fusion\namong features for fake news detection. In AIFN, to discover semantic\nconflicts, we design gated adaptive interaction networks (GAIN) to capture\nadaptively similar semantics and conflicting semantics between posts and\ncomments. To establish feature associations, we devise semantic-level fusion\nself-attention networks (SFSN) to enhance semantic correlations and fusion\namong features. Extensive experiments on two real-world datasets, i.e.,\nRumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art\nperformance and boosts accuracy by more than 2.05% and 1.90%, respectively.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The majority of existing methods for fake news detection universally focus on\nlearning and fusing various features for detection. However, the learning of\nvarious features is independent, which leads to a lack of cross-interaction\nfusion between features on social media, especially between posts and comments.\nGenerally, in fake news, there are emotional associations and semantic\nconflicts between posts and comments. How to represent and fuse the\ncross-interaction between both is a key challenge. In this paper, we propose\nAdaptive Interaction Fusion Networks (AIFN) to fulfill cross-interaction fusion\namong features for fake news detection. In AIFN, to discover semantic\nconflicts, we design gated adaptive interaction networks (GAIN) to capture\nadaptively similar semantics and conflicting semantics between posts and\ncomments. To establish feature associations, we devise semantic-level fusion\nself-attention networks (SFSN) to enhance semantic correlations and fusion\namong features. Extensive experiments on two real-world datasets, i.e.,\nRumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art\nperformance and boosts accuracy by more than 2.05% and 1.90%, respectively.'}, 'authors': [{'name': 'Lianwei Wu'}, {'name': 'Yuan Rao'}], 'author_detail': {'name': 'Yuan Rao'}, 'author': 'Yuan Rao', 'arxiv_comment': 'Accepted at the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)', 'links': [{'href': 'http://arxiv.org/abs/2004.10009v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.10009v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
228,http://arxiv.org/abs/2004.08789v1,2020-04-19 07:42:22+00:00,2020-04-19 07:42:22+00:00,BanFakeNews: A Dataset for Detecting Fake News in Bangla,"[arxiv.Result.Author('Md Zobaer Hossain'), arxiv.Result.Author('Md Ashraful Rahman'), arxiv.Result.Author('Md Saiful Islam'), arxiv.Result.Author('Sudipta Kar')]","Observing the damages that can be done by the rapid propagation of fake news
in various sectors like politics and finance, automatic identification of fake
news using linguistic analysis has drawn the attention of the research
community. However, such methods are largely being developed for English where
low resource languages remain out of the focus. But the risks spawned by fake
and manipulative news are not confined by languages. In this work, we propose
an annotated dataset of ~50K news that can be used for building automated fake
news detection systems for a low resource language like Bangla. Additionally,
we provide an analysis of the dataset and develop a benchmark system with state
of the art NLP techniques to identify Bangla fake news. To create this system,
we explore traditional linguistic features and neural network based methods. We
expect this dataset will be a valuable resource for building technologies to
prevent the spreading of fake news and contribute in research with low resource
languages.",LREC 2020,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.08789v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.08789v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.08789v1,"{'id': 'http://arxiv.org/abs/2004.08789v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.08789v1', 'updated': '2020-04-19T07:42:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=19, tm_hour=7, tm_min=42, tm_sec=22, tm_wday=6, tm_yday=110, tm_isdst=0), 'published': '2020-04-19T07:42:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=19, tm_hour=7, tm_min=42, tm_sec=22, tm_wday=6, tm_yday=110, tm_isdst=0), 'title': 'BanFakeNews: A Dataset for Detecting Fake News in Bangla', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BanFakeNews: A Dataset for Detecting Fake News in Bangla'}, 'summary': 'Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.'}, 'authors': [{'name': 'Md Zobaer Hossain'}, {'name': 'Md Ashraful Rahman'}, {'name': 'Md Saiful Islam'}, {'name': 'Sudipta Kar'}], 'author_detail': {'name': 'Sudipta Kar'}, 'author': 'Sudipta Kar', 'arxiv_comment': 'LREC 2020', 'links': [{'href': 'http://arxiv.org/abs/2004.08789v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.08789v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
229,http://arxiv.org/abs/2004.07682v1,2020-04-16 14:42:14+00:00,2020-04-16 14:42:14+00:00,On the use of Benford's law to detect GAN-generated images,"[arxiv.Result.Author('Nicolò Bonettini'), arxiv.Result.Author('Paolo Bestagini'), arxiv.Result.Author('Simone Milani'), arxiv.Result.Author('Stefano Tubaro')]","The advent of Generative Adversarial Network (GAN) architectures has given
anyone the ability of generating incredibly realistic synthetic imagery. The
malicious diffusion of GAN-generated images may lead to serious social and
political consequences (e.g., fake news spreading, opinion formation, etc.). It
is therefore important to regulate the widespread distribution of synthetic
imagery by developing solutions able to detect them. In this paper, we study
the possibility of using Benford's law to discriminate GAN-generated images
from natural photographs. Benford's law describes the distribution of the most
significant digit for quantized Discrete Cosine Transform (DCT) coefficients.
Extending and generalizing this property, we show that it is possible to
extract a compact feature vector from an image. This feature vector can be fed
to an extremely simple classifier for GAN-generated image detection purpose.",,,,cs.CV,"['cs.CV', 'cs.MM', 'eess.IV']","[arxiv.Result.Link('http://arxiv.org/abs/2004.07682v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.07682v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.07682v1,"{'id': 'http://arxiv.org/abs/2004.07682v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.07682v1', 'updated': '2020-04-16T14:42:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=16, tm_hour=14, tm_min=42, tm_sec=14, tm_wday=3, tm_yday=107, tm_isdst=0), 'published': '2020-04-16T14:42:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=16, tm_hour=14, tm_min=42, tm_sec=14, tm_wday=3, tm_yday=107, tm_isdst=0), 'title': ""On the use of Benford's law to detect GAN-generated images"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""On the use of Benford's law to detect GAN-generated images""}, 'summary': ""The advent of Generative Adversarial Network (GAN) architectures has given\nanyone the ability of generating incredibly realistic synthetic imagery. The\nmalicious diffusion of GAN-generated images may lead to serious social and\npolitical consequences (e.g., fake news spreading, opinion formation, etc.). It\nis therefore important to regulate the widespread distribution of synthetic\nimagery by developing solutions able to detect them. In this paper, we study\nthe possibility of using Benford's law to discriminate GAN-generated images\nfrom natural photographs. Benford's law describes the distribution of the most\nsignificant digit for quantized Discrete Cosine Transform (DCT) coefficients.\nExtending and generalizing this property, we show that it is possible to\nextract a compact feature vector from an image. This feature vector can be fed\nto an extremely simple classifier for GAN-generated image detection purpose."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The advent of Generative Adversarial Network (GAN) architectures has given\nanyone the ability of generating incredibly realistic synthetic imagery. The\nmalicious diffusion of GAN-generated images may lead to serious social and\npolitical consequences (e.g., fake news spreading, opinion formation, etc.). It\nis therefore important to regulate the widespread distribution of synthetic\nimagery by developing solutions able to detect them. In this paper, we study\nthe possibility of using Benford's law to discriminate GAN-generated images\nfrom natural photographs. Benford's law describes the distribution of the most\nsignificant digit for quantized Discrete Cosine Transform (DCT) coefficients.\nExtending and generalizing this property, we show that it is possible to\nextract a compact feature vector from an image. This feature vector can be fed\nto an extremely simple classifier for GAN-generated image detection purpose.""}, 'authors': [{'name': 'Nicolò Bonettini'}, {'name': 'Paolo Bestagini'}, {'name': 'Simone Milani'}, {'name': 'Stefano Tubaro'}], 'author_detail': {'name': 'Stefano Tubaro'}, 'author': 'Stefano Tubaro', 'links': [{'href': 'http://arxiv.org/abs/2004.07682v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.07682v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
230,http://arxiv.org/abs/2004.07676v1,2020-04-16 14:19:40+00:00,2020-04-16 14:19:40+00:00,Video Face Manipulation Detection Through Ensemble of CNNs,"[arxiv.Result.Author('Nicolò Bonettini'), arxiv.Result.Author('Edoardo Daniele Cannas'), arxiv.Result.Author('Sara Mandelli'), arxiv.Result.Author('Luca Bondi'), arxiv.Result.Author('Paolo Bestagini'), arxiv.Result.Author('Stefano Tubaro')]","In the last few years, several techniques for facial manipulation in videos
have been successfully developed and made available to the masses (i.e.,
FaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in
video sequences with incredibly realistic results and a very little effort.
Despite the usefulness of these tools in many fields, if used maliciously, they
can have a significantly bad impact on society (e.g., fake news spreading,
cyber bullying through fake revenge porn). The ability of objectively detecting
whether a face has been manipulated in a video sequence is then a task of
utmost importance. In this paper, we tackle the problem of face manipulation
detection in video sequences targeting modern facial manipulation techniques.
In particular, we study the ensembling of different trained Convolutional
Neural Network (CNN) models. In the proposed solution, different models are
obtained starting from a base network (i.e., EfficientNetB4) making use of two
different concepts: (i) attention layers; (ii) siamese training. We show that
combining these networks leads to promising face manipulation detection results
on two publicly available datasets with more than 119000 videos.",,,,cs.CV,"['cs.CV', 'cs.MM', 'eess.IV']","[arxiv.Result.Link('http://arxiv.org/abs/2004.07676v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.07676v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.07676v1,"{'id': 'http://arxiv.org/abs/2004.07676v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.07676v1', 'updated': '2020-04-16T14:19:40Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=16, tm_hour=14, tm_min=19, tm_sec=40, tm_wday=3, tm_yday=107, tm_isdst=0), 'published': '2020-04-16T14:19:40Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=16, tm_hour=14, tm_min=19, tm_sec=40, tm_wday=3, tm_yday=107, tm_isdst=0), 'title': 'Video Face Manipulation Detection Through Ensemble of CNNs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Video Face Manipulation Detection Through Ensemble of CNNs'}, 'summary': 'In the last few years, several techniques for facial manipulation in videos\nhave been successfully developed and made available to the masses (i.e.,\nFaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in\nvideo sequences with incredibly realistic results and a very little effort.\nDespite the usefulness of these tools in many fields, if used maliciously, they\ncan have a significantly bad impact on society (e.g., fake news spreading,\ncyber bullying through fake revenge porn). The ability of objectively detecting\nwhether a face has been manipulated in a video sequence is then a task of\nutmost importance. In this paper, we tackle the problem of face manipulation\ndetection in video sequences targeting modern facial manipulation techniques.\nIn particular, we study the ensembling of different trained Convolutional\nNeural Network (CNN) models. In the proposed solution, different models are\nobtained starting from a base network (i.e., EfficientNetB4) making use of two\ndifferent concepts: (i) attention layers; (ii) siamese training. We show that\ncombining these networks leads to promising face manipulation detection results\non two publicly available datasets with more than 119000 videos.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the last few years, several techniques for facial manipulation in videos\nhave been successfully developed and made available to the masses (i.e.,\nFaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in\nvideo sequences with incredibly realistic results and a very little effort.\nDespite the usefulness of these tools in many fields, if used maliciously, they\ncan have a significantly bad impact on society (e.g., fake news spreading,\ncyber bullying through fake revenge porn). The ability of objectively detecting\nwhether a face has been manipulated in a video sequence is then a task of\nutmost importance. In this paper, we tackle the problem of face manipulation\ndetection in video sequences targeting modern facial manipulation techniques.\nIn particular, we study the ensembling of different trained Convolutional\nNeural Network (CNN) models. In the proposed solution, different models are\nobtained starting from a base network (i.e., EfficientNetB4) making use of two\ndifferent concepts: (i) attention layers; (ii) siamese training. We show that\ncombining these networks leads to promising face manipulation detection results\non two publicly available datasets with more than 119000 videos.'}, 'authors': [{'name': 'Nicolò Bonettini'}, {'name': 'Edoardo Daniele Cannas'}, {'name': 'Sara Mandelli'}, {'name': 'Luca Bondi'}, {'name': 'Paolo Bestagini'}, {'name': 'Stefano Tubaro'}], 'author_detail': {'name': 'Stefano Tubaro'}, 'author': 'Stefano Tubaro', 'links': [{'href': 'http://arxiv.org/abs/2004.07676v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.07676v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
231,http://arxiv.org/abs/2004.05286v3,2020-07-09 17:17:54+00:00,2020-04-11 02:28:33+00:00,Recent advances in opinion propagation dynamics: A 2020 Survey,[arxiv.Result.Author('Hossein Noorazar')],"Opinion dynamics have attracted the interest of researchers from different
fields. Local interactions among individuals create interesting dynamics for
the system as a whole. Such dynamics are important from a variety of
perspectives. Group decision making, successful marketing, and constructing
networks (in which consensus can be reached or prevented) are a few examples of
existing or potential applications. The invention of the Internet has made the
opinion fusion faster, unilateral, and on a whole different scale. Spread of
fake news, propaganda, and election interferences have made it clear there is
an essential need to know more about these dynamics.
  The emergence of new ideas in the field has accelerated over the last few
years. In the first quarter of 2020, at least 50 research papers have emerged,
either peer-reviewed and published or on pre-print outlets such as arXiv. In
this paper, we summarize these ground-breaking ideas and their fascinating
extensions and introduce newly surfaced concepts.",,,10.1140/epjp/s13360-020-00541-2,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1140/epjp/s13360-020-00541-2', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.05286v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.05286v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.05286v3,"{'id': 'http://arxiv.org/abs/2004.05286v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.05286v3', 'updated': '2020-07-09T17:17:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=9, tm_hour=17, tm_min=17, tm_sec=54, tm_wday=3, tm_yday=191, tm_isdst=0), 'published': '2020-04-11T02:28:33Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=11, tm_hour=2, tm_min=28, tm_sec=33, tm_wday=5, tm_yday=102, tm_isdst=0), 'title': 'Recent advances in opinion propagation dynamics: A 2020 Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent advances in opinion propagation dynamics: A 2020 Survey'}, 'summary': 'Opinion dynamics have attracted the interest of researchers from different\nfields. Local interactions among individuals create interesting dynamics for\nthe system as a whole. Such dynamics are important from a variety of\nperspectives. Group decision making, successful marketing, and constructing\nnetworks (in which consensus can be reached or prevented) are a few examples of\nexisting or potential applications. The invention of the Internet has made the\nopinion fusion faster, unilateral, and on a whole different scale. Spread of\nfake news, propaganda, and election interferences have made it clear there is\nan essential need to know more about these dynamics.\n  The emergence of new ideas in the field has accelerated over the last few\nyears. In the first quarter of 2020, at least 50 research papers have emerged,\neither peer-reviewed and published or on pre-print outlets such as arXiv. In\nthis paper, we summarize these ground-breaking ideas and their fascinating\nextensions and introduce newly surfaced concepts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Opinion dynamics have attracted the interest of researchers from different\nfields. Local interactions among individuals create interesting dynamics for\nthe system as a whole. Such dynamics are important from a variety of\nperspectives. Group decision making, successful marketing, and constructing\nnetworks (in which consensus can be reached or prevented) are a few examples of\nexisting or potential applications. The invention of the Internet has made the\nopinion fusion faster, unilateral, and on a whole different scale. Spread of\nfake news, propaganda, and election interferences have made it clear there is\nan essential need to know more about these dynamics.\n  The emergence of new ideas in the field has accelerated over the last few\nyears. In the first quarter of 2020, at least 50 research papers have emerged,\neither peer-reviewed and published or on pre-print outlets such as arXiv. In\nthis paper, we summarize these ground-breaking ideas and their fascinating\nextensions and introduce newly surfaced concepts.'}, 'authors': [{'name': 'Hossein Noorazar'}], 'author_detail': {'name': 'Hossein Noorazar'}, 'author': 'Hossein Noorazar', 'arxiv_doi': '10.1140/epjp/s13360-020-00541-2', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1140/epjp/s13360-020-00541-2', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.05286v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.05286v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
232,http://arxiv.org/abs/2004.02566v3,2020-04-09 15:41:01+00:00,2020-04-06 11:23:46+00:00,Pandemic Populism: Facebook Pages of Alternative News Media and the Corona Crisis -- A Computational Content Analysis,"[arxiv.Result.Author('Svenja Boberg'), arxiv.Result.Author('Thorsten Quandt'), arxiv.Result.Author('Tim Schatto-Eckrodt'), arxiv.Result.Author('Lena Frischlich')]","The COVID-19 pandemic has not only had severe political, economic, and
societal effects, it has also affected media and communication systems in
unprecedented ways. While traditional journalistic media has tried to adapt to
the rapidly evolving situation, alternative news media on the Internet have
given the events their own ideological spin. Such voices have been criticized
for furthering societal confusion and spreading potentially dangerous ""fake
news"" or conspiracy theories via social media and other online channels. The
current study analyzes the factual basis of such fears in an initial
computational content analysis of alternative news media's output on Facebook
during the early Corona crisis, based on a large German data set from January
to the second half of March 2020. Using computational content analysis,
methods, reach, interactions, actors, and topics of the messages were examined,
as well as the use of fabricated news and conspiracy theories. The analysis
revealed that the alternative news media stay true to message patterns and
ideological foundations identified in prior research. While they do not spread
obvious lies, they are predominantly sharing overly critical, even
anti-systemic messages, opposing the view of the mainstream news media and the
political establishment. With this pandemic populism, they contribute to a
contradictory, menacing, and distrusting worldview, as portrayed in detail in
this analysis.","Muenster Online Research (MOR) Working Paper 1/2020, 4 figures, 4
  tables, corrected typos and references",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.02566v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.02566v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.02566v3,"{'id': 'http://arxiv.org/abs/2004.02566v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.02566v3', 'updated': '2020-04-09T15:41:01Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=9, tm_hour=15, tm_min=41, tm_sec=1, tm_wday=3, tm_yday=100, tm_isdst=0), 'published': '2020-04-06T11:23:46Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=6, tm_hour=11, tm_min=23, tm_sec=46, tm_wday=0, tm_yday=97, tm_isdst=0), 'title': 'Pandemic Populism: Facebook Pages of Alternative News Media and the\n  Corona Crisis -- A Computational Content Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Pandemic Populism: Facebook Pages of Alternative News Media and the\n  Corona Crisis -- A Computational Content Analysis'}, 'summary': 'The COVID-19 pandemic has not only had severe political, economic, and\nsocietal effects, it has also affected media and communication systems in\nunprecedented ways. While traditional journalistic media has tried to adapt to\nthe rapidly evolving situation, alternative news media on the Internet have\ngiven the events their own ideological spin. Such voices have been criticized\nfor furthering societal confusion and spreading potentially dangerous ""fake\nnews"" or conspiracy theories via social media and other online channels. The\ncurrent study analyzes the factual basis of such fears in an initial\ncomputational content analysis of alternative news media\'s output on Facebook\nduring the early Corona crisis, based on a large German data set from January\nto the second half of March 2020. Using computational content analysis,\nmethods, reach, interactions, actors, and topics of the messages were examined,\nas well as the use of fabricated news and conspiracy theories. The analysis\nrevealed that the alternative news media stay true to message patterns and\nideological foundations identified in prior research. While they do not spread\nobvious lies, they are predominantly sharing overly critical, even\nanti-systemic messages, opposing the view of the mainstream news media and the\npolitical establishment. With this pandemic populism, they contribute to a\ncontradictory, menacing, and distrusting worldview, as portrayed in detail in\nthis analysis.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has not only had severe political, economic, and\nsocietal effects, it has also affected media and communication systems in\nunprecedented ways. While traditional journalistic media has tried to adapt to\nthe rapidly evolving situation, alternative news media on the Internet have\ngiven the events their own ideological spin. Such voices have been criticized\nfor furthering societal confusion and spreading potentially dangerous ""fake\nnews"" or conspiracy theories via social media and other online channels. The\ncurrent study analyzes the factual basis of such fears in an initial\ncomputational content analysis of alternative news media\'s output on Facebook\nduring the early Corona crisis, based on a large German data set from January\nto the second half of March 2020. Using computational content analysis,\nmethods, reach, interactions, actors, and topics of the messages were examined,\nas well as the use of fabricated news and conspiracy theories. The analysis\nrevealed that the alternative news media stay true to message patterns and\nideological foundations identified in prior research. While they do not spread\nobvious lies, they are predominantly sharing overly critical, even\nanti-systemic messages, opposing the view of the mainstream news media and the\npolitical establishment. With this pandemic populism, they contribute to a\ncontradictory, menacing, and distrusting worldview, as portrayed in detail in\nthis analysis.'}, 'authors': [{'name': 'Svenja Boberg'}, {'name': 'Thorsten Quandt'}, {'name': 'Tim Schatto-Eckrodt'}, {'name': 'Lena Frischlich'}], 'author_detail': {'name': 'Lena Frischlich'}, 'author': 'Lena Frischlich', 'arxiv_comment': 'Muenster Online Research (MOR) Working Paper 1/2020, 4 figures, 4\n  tables, corrected typos and references', 'links': [{'href': 'http://arxiv.org/abs/2004.02566v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.02566v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
233,http://arxiv.org/abs/2004.01732v1,2020-04-03 18:26:33+00:00,2020-04-03 18:26:33+00:00,Leveraging Multi-Source Weak Social Supervision for Early Detection of Fake News,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Guoqing Zheng'), arxiv.Result.Author('Yichuan Li'), arxiv.Result.Author('Subhabrata Mukherjee'), arxiv.Result.Author('Ahmed Hassan Awadallah'), arxiv.Result.Author('Scott Ruston'), arxiv.Result.Author('Huan Liu')]","Social media has greatly enabled people to participate in online activities
at an unprecedented rate. However, this unrestricted access also exacerbates
the spread of misinformation and fake news online which might cause confusion
and chaos unless being detected early for its mitigation. Given the rapidly
evolving nature of news events and the limited amount of annotated data,
state-of-the-art systems on fake news detection face challenges due to the lack
of large numbers of annotated training instances that are hard to come by for
early detection. In this work, we exploit multiple weak signals from different
sources given by user and content engagements (referred to as weak social
supervision), and their complementary utilities to detect fake news. We jointly
leverage the limited amount of clean data along with weak signals from social
engagements to train deep neural networks in a meta-learning framework to
estimate the quality of different weak instances. Experiments on realworld
datasets demonstrate that the proposed framework outperforms state-of-the-art
baselines for early detection of fake news without using any user engagements
at prediction time.","17 pages, 5 figures, 4 tables",,,cs.LG,"['cs.LG', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2004.01732v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.01732v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.01732v1,"{'id': 'http://arxiv.org/abs/2004.01732v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.01732v1', 'updated': '2020-04-03T18:26:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=3, tm_hour=18, tm_min=26, tm_sec=33, tm_wday=4, tm_yday=94, tm_isdst=0), 'published': '2020-04-03T18:26:33Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=3, tm_hour=18, tm_min=26, tm_sec=33, tm_wday=4, tm_yday=94, tm_isdst=0), 'title': 'Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News'}, 'summary': 'Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Guoqing Zheng'}, {'name': 'Yichuan Li'}, {'name': 'Subhabrata Mukherjee'}, {'name': 'Ahmed Hassan Awadallah'}, {'name': 'Scott Ruston'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '17 pages, 5 figures, 4 tables', 'links': [{'href': 'http://arxiv.org/abs/2004.01732v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.01732v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
234,http://arxiv.org/abs/2004.00777v1,2020-04-02 02:22:45+00:00,2020-04-02 02:22:45+00:00,Skepticism and rumor spreading: the role of spatial correlations,"[arxiv.Result.Author('Marco Antonio Amaral'), arxiv.Result.Author('W. G. Dantas'), arxiv.Result.Author('Jeferson J. Arenzon')]","Critical thinking and skepticism are fundamental mechanisms that one may use
to prevent the spreading of rumors, fake-news and misinformation. We consider a
simple model in which agents without previous contact with the rumor, being
skeptically oriented, may convince spreaders to stop their activity or, once
exposed to the rumor, decide not to propagate it as a consequence, for example,
of fact-checking. We extend a previous, mean-field analysis of the combined
effect of these two mechanisms, active and passive skepticism, to include
spatial correlations. This can be done either analytically, through the pair
approximation, or simulating an agent-based version on diverse networks. Our
results show that while in mean-field there is no coexistence between spreaders
and susceptibles (although, depending on the parameters, there may be
bistability depending on the initial conditions), when spatial correlations are
included, because of the protective effect of the isolation provided by removed
agents, coexistence is possible.","9 pages, 6 figures","Phys. Rev. E 101, 062418 (2020)",10.1103/PhysRevE.101.062418,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech', 'q-bio.PE']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevE.101.062418', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.00777v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00777v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00777v1,"{'id': 'http://arxiv.org/abs/2004.00777v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00777v1', 'updated': '2020-04-02T02:22:45Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=2, tm_min=22, tm_sec=45, tm_wday=3, tm_yday=93, tm_isdst=0), 'published': '2020-04-02T02:22:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=2, tm_min=22, tm_sec=45, tm_wday=3, tm_yday=93, tm_isdst=0), 'title': 'Skepticism and rumor spreading: the role of spatial correlations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Skepticism and rumor spreading: the role of spatial correlations'}, 'summary': 'Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.'}, 'authors': [{'name': 'Marco Antonio Amaral'}, {'name': 'W. G. Dantas'}, {'name': 'Jeferson J. Arenzon'}], 'author_detail': {'name': 'Jeferson J. Arenzon'}, 'author': 'Jeferson J. Arenzon', 'arxiv_doi': '10.1103/PhysRevE.101.062418', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevE.101.062418', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.00777v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00777v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '9 pages, 6 figures', 'arxiv_journal_ref': 'Phys. Rev. E 101, 062418 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.stat-mech', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
235,http://arxiv.org/abs/2003.10421v2,2020-10-23 09:22:53+00:00,2020-03-23 17:49:06+00:00,Multimodal Analytics for Real-world News using Measures of Cross-modal Entity Consistency,"[arxiv.Result.Author('Eric Müller-Budack'), arxiv.Result.Author('Jonas Theiner'), arxiv.Result.Author('Sebastian Diering'), arxiv.Result.Author('Maximilian Idahl'), arxiv.Result.Author('Ralph Ewerth')]","The World Wide Web has become a popular source for gathering information and
news. Multimodal information, e.g., enriching text with photos, is typically
used to convey the news more effectively or to attract attention. Photo content
can range from decorative, depict additional important information, or can even
contain misleading information. Therefore, automatic approaches to quantify
cross-modal consistency of entity representation can support human assessors to
evaluate the overall multimodal message, for instance, with regard to bias or
sentiment. In some cases such measures could give hints to detect fake news,
which is an increasingly important topic in today's society. In this paper, we
introduce a novel task of cross-modal consistency verification in real-world
news and present a multimodal approach to quantify the entity coherence between
image and text. Named entity linking is applied to extract persons, locations,
and events from news texts. Several measures are suggested to calculate
cross-modal similarity for these entities using state of the art approaches. In
contrast to previous work, our system automatically gathers example data from
the Web and is applicable to real-world news. Results on two novel datasets
that cover different languages, topics, and domains demonstrate the feasibility
of our approach. Datasets and code are publicly available to foster research
towards this new direction.","Accepted for publication in: International Conference on Multimedia
  Retrieval (ICMR), Dublin, 2020",,,cs.CL,"['cs.CL', 'cs.IR', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2003.10421v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.10421v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.10421v2,"{'id': 'http://arxiv.org/abs/2003.10421v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.10421v2', 'updated': '2020-10-23T09:22:53Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=23, tm_hour=9, tm_min=22, tm_sec=53, tm_wday=4, tm_yday=297, tm_isdst=0), 'published': '2020-03-23T17:49:06Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=23, tm_hour=17, tm_min=49, tm_sec=6, tm_wday=0, tm_yday=83, tm_isdst=0), 'title': 'Multimodal Analytics for Real-world News using Measures of Cross-modal\n  Entity Consistency', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multimodal Analytics for Real-world News using Measures of Cross-modal\n  Entity Consistency'}, 'summary': ""The World Wide Web has become a popular source for gathering information and\nnews. Multimodal information, e.g., enriching text with photos, is typically\nused to convey the news more effectively or to attract attention. Photo content\ncan range from decorative, depict additional important information, or can even\ncontain misleading information. Therefore, automatic approaches to quantify\ncross-modal consistency of entity representation can support human assessors to\nevaluate the overall multimodal message, for instance, with regard to bias or\nsentiment. In some cases such measures could give hints to detect fake news,\nwhich is an increasingly important topic in today's society. In this paper, we\nintroduce a novel task of cross-modal consistency verification in real-world\nnews and present a multimodal approach to quantify the entity coherence between\nimage and text. Named entity linking is applied to extract persons, locations,\nand events from news texts. Several measures are suggested to calculate\ncross-modal similarity for these entities using state of the art approaches. In\ncontrast to previous work, our system automatically gathers example data from\nthe Web and is applicable to real-world news. Results on two novel datasets\nthat cover different languages, topics, and domains demonstrate the feasibility\nof our approach. Datasets and code are publicly available to foster research\ntowards this new direction."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The World Wide Web has become a popular source for gathering information and\nnews. Multimodal information, e.g., enriching text with photos, is typically\nused to convey the news more effectively or to attract attention. Photo content\ncan range from decorative, depict additional important information, or can even\ncontain misleading information. Therefore, automatic approaches to quantify\ncross-modal consistency of entity representation can support human assessors to\nevaluate the overall multimodal message, for instance, with regard to bias or\nsentiment. In some cases such measures could give hints to detect fake news,\nwhich is an increasingly important topic in today's society. In this paper, we\nintroduce a novel task of cross-modal consistency verification in real-world\nnews and present a multimodal approach to quantify the entity coherence between\nimage and text. Named entity linking is applied to extract persons, locations,\nand events from news texts. Several measures are suggested to calculate\ncross-modal similarity for these entities using state of the art approaches. In\ncontrast to previous work, our system automatically gathers example data from\nthe Web and is applicable to real-world news. Results on two novel datasets\nthat cover different languages, topics, and domains demonstrate the feasibility\nof our approach. Datasets and code are publicly available to foster research\ntowards this new direction.""}, 'authors': [{'name': 'Eric Müller-Budack'}, {'name': 'Jonas Theiner'}, {'name': 'Sebastian Diering'}, {'name': 'Maximilian Idahl'}, {'name': 'Ralph Ewerth'}], 'author_detail': {'name': 'Ralph Ewerth'}, 'author': 'Ralph Ewerth', 'arxiv_comment': 'Accepted for publication in: International Conference on Multimedia\n  Retrieval (ICMR), Dublin, 2020', 'links': [{'href': 'http://arxiv.org/abs/2003.10421v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.10421v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
236,http://arxiv.org/abs/2003.09543v1,2020-03-21 01:00:02+00:00,2020-03-21 01:00:02+00:00,Towards Time-Aware Context-Aware Deep Trust Prediction in Online Social Networks,[arxiv.Result.Author('Seyed Mohssen Ghafari')],"Trust can be defined as a measure to determine which source of information is
reliable and with whom we should share or from whom we should accept
information. There are several applications for trust in Online Social Networks
(OSNs), including social spammer detection, fake news detection, retweet
behaviour detection and recommender systems. Trust prediction is the process of
predicting a new trust relation between two users who are not currently
connected. In applications of trust, trust relations among users need to be
predicted. This process faces many challenges, such as the sparsity of
user-specified trust relations, the context-awareness of trust and changes in
trust values over time. In this dissertation, we analyse the state-of-the-art
in pair-wise trust prediction models in OSNs. We discuss three main challenges
in this domain and present novel trust prediction approaches to address them.
We first focus on proposing a low-rank representation of users that
incorporates users' personality traits as additional information. Then, we
propose a set of context-aware trust prediction models. Finally, by considering
the time-dependency of trust relations, we propose a dynamic deep trust
prediction approach. We design and implement five pair-wise trust prediction
approaches and evaluate them with real-world datasets collected from OSNs. The
experimental results demonstrate the effectiveness of our approaches compared
to other state-of-the-art pair-wise trust prediction models.","158 pages, 20 figures, and 19 tables. This is my PhD thesis in
  Macquarie University, Sydney, Australia",,,cs.SI,"['cs.SI', 'cs.LG', 'cs.NE', '68-02', 'E.0']","[arxiv.Result.Link('http://arxiv.org/abs/2003.09543v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.09543v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.09543v1,"{'id': 'http://arxiv.org/abs/2003.09543v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.09543v1', 'updated': '2020-03-21T01:00:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=21, tm_hour=1, tm_min=0, tm_sec=2, tm_wday=5, tm_yday=81, tm_isdst=0), 'published': '2020-03-21T01:00:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=21, tm_hour=1, tm_min=0, tm_sec=2, tm_wday=5, tm_yday=81, tm_isdst=0), 'title': 'Towards Time-Aware Context-Aware Deep Trust Prediction in Online Social\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Time-Aware Context-Aware Deep Trust Prediction in Online Social\n  Networks'}, 'summary': ""Trust can be defined as a measure to determine which source of information is\nreliable and with whom we should share or from whom we should accept\ninformation. There are several applications for trust in Online Social Networks\n(OSNs), including social spammer detection, fake news detection, retweet\nbehaviour detection and recommender systems. Trust prediction is the process of\npredicting a new trust relation between two users who are not currently\nconnected. In applications of trust, trust relations among users need to be\npredicted. This process faces many challenges, such as the sparsity of\nuser-specified trust relations, the context-awareness of trust and changes in\ntrust values over time. In this dissertation, we analyse the state-of-the-art\nin pair-wise trust prediction models in OSNs. We discuss three main challenges\nin this domain and present novel trust prediction approaches to address them.\nWe first focus on proposing a low-rank representation of users that\nincorporates users' personality traits as additional information. Then, we\npropose a set of context-aware trust prediction models. Finally, by considering\nthe time-dependency of trust relations, we propose a dynamic deep trust\nprediction approach. We design and implement five pair-wise trust prediction\napproaches and evaluate them with real-world datasets collected from OSNs. The\nexperimental results demonstrate the effectiveness of our approaches compared\nto other state-of-the-art pair-wise trust prediction models."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Trust can be defined as a measure to determine which source of information is\nreliable and with whom we should share or from whom we should accept\ninformation. There are several applications for trust in Online Social Networks\n(OSNs), including social spammer detection, fake news detection, retweet\nbehaviour detection and recommender systems. Trust prediction is the process of\npredicting a new trust relation between two users who are not currently\nconnected. In applications of trust, trust relations among users need to be\npredicted. This process faces many challenges, such as the sparsity of\nuser-specified trust relations, the context-awareness of trust and changes in\ntrust values over time. In this dissertation, we analyse the state-of-the-art\nin pair-wise trust prediction models in OSNs. We discuss three main challenges\nin this domain and present novel trust prediction approaches to address them.\nWe first focus on proposing a low-rank representation of users that\nincorporates users' personality traits as additional information. Then, we\npropose a set of context-aware trust prediction models. Finally, by considering\nthe time-dependency of trust relations, we propose a dynamic deep trust\nprediction approach. We design and implement five pair-wise trust prediction\napproaches and evaluate them with real-world datasets collected from OSNs. The\nexperimental results demonstrate the effectiveness of our approaches compared\nto other state-of-the-art pair-wise trust prediction models.""}, 'authors': [{'name': 'Seyed Mohssen Ghafari'}], 'author_detail': {'name': 'Seyed Mohssen Ghafari'}, 'author': 'Seyed Mohssen Ghafari', 'arxiv_comment': '158 pages, 20 figures, and 19 tables. This is my PhD thesis in\n  Macquarie University, Sydney, Australia', 'links': [{'href': 'http://arxiv.org/abs/2003.09543v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.09543v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68-02', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'E.0', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
237,http://arxiv.org/abs/2003.07595v1,2020-03-17 09:24:22+00:00,2020-03-17 09:24:22+00:00,FakeYou! -- A Gamified Approach for Building and Evaluating Resilience Against Fake News,"[arxiv.Result.Author('Lena Clever'), arxiv.Result.Author('Dennis Assenmacher'), arxiv.Result.Author('Kilian Müller'), arxiv.Result.Author('Moritz Vinzent Seiler'), arxiv.Result.Author('Dennis M. Riehle'), arxiv.Result.Author('Mike Preuss'), arxiv.Result.Author('Christian Grimme')]","Nowadays fake news are heavily discussed in public and political debates.
Even though the phenomenon of intended false information is rather old,
misinformation reaches a new level with the rise of the internet and
participatory platforms. Due to Facebook and Co., purposeful false information
- often called fake news - can be easily spread by everyone. Because of a high
data volatility and variety in content types (text, images,...) debunking of
fake news is a complex challenge. This is especially true for automated
approaches, which are prone to fail validating the veracity of the information.
This work focuses on an a gamified approach to strengthen the resilience of
consumers towards fake news. The game FakeYou motivates its players to
critically analyze headlines regarding their trustworthiness. Further, the game
follows a ""learning by doing strategy"": by generating own fake headlines, users
should experience the concepts of convincing fake headline formulations. We
introduce the game itself, as well as the underlying technical infrastructure.
A first evaluation study shows, that users tend to use specific stylistic
devices to generate fake news. Further, the results indicate, that creating
good fakes and identifying correct headlines are challenging and hard to learn.","accepted for Disinformation in Open Online Media - 2nd
  Multidisciplinary International Symposium, MISDOOM 2020",,,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2003.07595v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07595v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07595v1,"{'id': 'http://arxiv.org/abs/2003.07595v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07595v1', 'updated': '2020-03-17T09:24:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=17, tm_hour=9, tm_min=24, tm_sec=22, tm_wday=1, tm_yday=77, tm_isdst=0), 'published': '2020-03-17T09:24:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=17, tm_hour=9, tm_min=24, tm_sec=22, tm_wday=1, tm_yday=77, tm_isdst=0), 'title': 'FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News'}, 'summary': 'Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a ""learning by doing strategy"": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a ""learning by doing strategy"": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.'}, 'authors': [{'name': 'Lena Clever'}, {'name': 'Dennis Assenmacher'}, {'name': 'Kilian Müller'}, {'name': 'Moritz Vinzent Seiler'}, {'name': 'Dennis M. Riehle'}, {'name': 'Mike Preuss'}, {'name': 'Christian Grimme'}], 'author_detail': {'name': 'Christian Grimme'}, 'author': 'Christian Grimme', 'arxiv_comment': 'accepted for Disinformation in Open Online Media - 2nd\n  Multidisciplinary International Symposium, MISDOOM 2020', 'links': [{'href': 'http://arxiv.org/abs/2003.07595v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07595v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
238,http://arxiv.org/abs/2003.07010v2,2020-07-13 17:00:58+00:00,2020-03-16 04:01:09+00:00,Adversarial Perturbations of Opinion Dynamics in Networks,"[arxiv.Result.Author('Jason Gaitonde'), arxiv.Result.Author('Jon Kleinberg'), arxiv.Result.Author('Eva Tardos')]","We study the connections between network structure, opinion dynamics, and an
adversary's power to artificially induce disagreements. We approach these
questions by extending models of opinion formation in the social sciences to
represent scenarios, familiar from recent events, in which external actors seek
to destabilize communities through sophisticated information warfare tactics
via fake news and bots. In many instances, the intrinsic goals of these efforts
are not necessarily to shift the overall sentiment of the network, but rather
to induce discord. These perturbations diffuse via opinion dynamics on the
underlying network, through mechanisms that have been analyzed and abstracted
through work in computer science and the social sciences. We investigate the
properties of such attacks, considering optimal strategies both for the
adversary seeking to create disagreement and for the entities tasked with
defending the network from attack. We show that for different formulations of
these types of objectives, different regimes of the spectral structure of the
network will limit the adversary's capacity to sow discord; this enables us to
qualitatively describe which networks are most vulnerable against these
perturbations. We then consider the algorithmic task of a network defender to
mitigate these sorts of adversarial attacks by insulating nodes
heterogeneously; we show that, by considering the geometry of this problem,
this optimization task can be efficiently solved via convex programming.
Finally, we generalize these results to allow for two network structures, where
the opinion dynamics process and the measurement of disagreement become
uncoupled, and determine how the adversary's power changes; for instance, this
may arise when opinion dynamics are controlled an online community via social
media, while disagreement is measured along ""real-world"" connections.","28 pages; added new related work, fixed typos",,,cs.DS,"['cs.DS', 'cs.GT', 'cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2003.07010v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07010v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07010v2,"{'id': 'http://arxiv.org/abs/2003.07010v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07010v2', 'updated': '2020-07-13T17:00:58Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=13, tm_hour=17, tm_min=0, tm_sec=58, tm_wday=0, tm_yday=195, tm_isdst=0), 'published': '2020-03-16T04:01:09Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=16, tm_hour=4, tm_min=1, tm_sec=9, tm_wday=0, tm_yday=76, tm_isdst=0), 'title': 'Adversarial Perturbations of Opinion Dynamics in Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversarial Perturbations of Opinion Dynamics in Networks'}, 'summary': 'We study the connections between network structure, opinion dynamics, and an\nadversary\'s power to artificially induce disagreements. We approach these\nquestions by extending models of opinion formation in the social sciences to\nrepresent scenarios, familiar from recent events, in which external actors seek\nto destabilize communities through sophisticated information warfare tactics\nvia fake news and bots. In many instances, the intrinsic goals of these efforts\nare not necessarily to shift the overall sentiment of the network, but rather\nto induce discord. These perturbations diffuse via opinion dynamics on the\nunderlying network, through mechanisms that have been analyzed and abstracted\nthrough work in computer science and the social sciences. We investigate the\nproperties of such attacks, considering optimal strategies both for the\nadversary seeking to create disagreement and for the entities tasked with\ndefending the network from attack. We show that for different formulations of\nthese types of objectives, different regimes of the spectral structure of the\nnetwork will limit the adversary\'s capacity to sow discord; this enables us to\nqualitatively describe which networks are most vulnerable against these\nperturbations. We then consider the algorithmic task of a network defender to\nmitigate these sorts of adversarial attacks by insulating nodes\nheterogeneously; we show that, by considering the geometry of this problem,\nthis optimization task can be efficiently solved via convex programming.\nFinally, we generalize these results to allow for two network structures, where\nthe opinion dynamics process and the measurement of disagreement become\nuncoupled, and determine how the adversary\'s power changes; for instance, this\nmay arise when opinion dynamics are controlled an online community via social\nmedia, while disagreement is measured along ""real-world"" connections.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We study the connections between network structure, opinion dynamics, and an\nadversary\'s power to artificially induce disagreements. We approach these\nquestions by extending models of opinion formation in the social sciences to\nrepresent scenarios, familiar from recent events, in which external actors seek\nto destabilize communities through sophisticated information warfare tactics\nvia fake news and bots. In many instances, the intrinsic goals of these efforts\nare not necessarily to shift the overall sentiment of the network, but rather\nto induce discord. These perturbations diffuse via opinion dynamics on the\nunderlying network, through mechanisms that have been analyzed and abstracted\nthrough work in computer science and the social sciences. We investigate the\nproperties of such attacks, considering optimal strategies both for the\nadversary seeking to create disagreement and for the entities tasked with\ndefending the network from attack. We show that for different formulations of\nthese types of objectives, different regimes of the spectral structure of the\nnetwork will limit the adversary\'s capacity to sow discord; this enables us to\nqualitatively describe which networks are most vulnerable against these\nperturbations. We then consider the algorithmic task of a network defender to\nmitigate these sorts of adversarial attacks by insulating nodes\nheterogeneously; we show that, by considering the geometry of this problem,\nthis optimization task can be efficiently solved via convex programming.\nFinally, we generalize these results to allow for two network structures, where\nthe opinion dynamics process and the measurement of disagreement become\nuncoupled, and determine how the adversary\'s power changes; for instance, this\nmay arise when opinion dynamics are controlled an online community via social\nmedia, while disagreement is measured along ""real-world"" connections.'}, 'authors': [{'name': 'Jason Gaitonde'}, {'name': 'Jon Kleinberg'}, {'name': 'Eva Tardos'}], 'author_detail': {'name': 'Eva Tardos'}, 'author': 'Eva Tardos', 'arxiv_comment': '28 pages; added new related work, fixed typos', 'links': [{'href': 'http://arxiv.org/abs/2003.07010v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07010v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
239,http://arxiv.org/abs/2003.06634v1,2020-03-14 14:02:27+00:00,2020-03-14 14:02:27+00:00,Text Similarity Using Word Embeddings to Classify Misinformation,"[arxiv.Result.Author('Caio Almeida'), arxiv.Result.Author('Débora Santos')]","Fake news is a growing problem in the last years, especially during
elections. It's hard work to identify what is true and what is false among all
the user generated content that circulates every day. Technology can help with
that work and optimize the fact-checking process. In this work, we address the
challenge of finding similar content in order to be able to suggest to a
fact-checker articles that could have been verified before and thus avoid that
the same information is verified more than once. This is especially important
in collaborative approaches to fact-checking where members of large teams will
not know what content others have already fact-checked.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2003.06634v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.06634v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.06634v1,"{'id': 'http://arxiv.org/abs/2003.06634v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.06634v1', 'updated': '2020-03-14T14:02:27Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=14, tm_hour=14, tm_min=2, tm_sec=27, tm_wday=5, tm_yday=74, tm_isdst=0), 'published': '2020-03-14T14:02:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=14, tm_hour=14, tm_min=2, tm_sec=27, tm_wday=5, tm_yday=74, tm_isdst=0), 'title': 'Text Similarity Using Word Embeddings to Classify Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Text Similarity Using Word Embeddings to Classify Misinformation'}, 'summary': ""Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.""}, 'authors': [{'name': 'Caio Almeida'}, {'name': 'Débora Santos'}], 'author_detail': {'name': 'Débora Santos'}, 'author': 'Débora Santos', 'links': [{'href': 'http://arxiv.org/abs/2003.06634v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.06634v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
240,http://arxiv.org/abs/2003.07192v4,2021-01-08 03:43:46+00:00,2020-03-12 18:37:19+00:00,Social Media and Misleading Information in a Democracy: A Mechanism Design Approach,"[arxiv.Result.Author('Aditya Dave'), arxiv.Result.Author('Ioannis Vasileios Chremos'), arxiv.Result.Author('Andreas A. Malikopoulos')]","In this paper, we present a resource allocation mechanism for the problem of
incentivizing filtering among a finite number of strategic social media
platforms. We consider the presence of a strategic government and private
knowledge of how misinformation affects the users of the social media
platforms. Our proposed mechanism incentivizes social media platforms to filter
misleading information efficiently, and thus indirectly prevents the spread of
fake news. In particular, we design an economically inspired mechanism that
strongly implements all generalized Nash equilibria for efficient filtering of
misleading information in the induced game. We show that our mechanism is
individually rational, budget balanced, while it has at least one equilibrium.
Finally, we show that for quasi-concave utilities and constraints, our
mechanism admits a generalized Nash equilibrium and implements a Pareto
efficient solution.",,,,cs.GT,"['cs.GT', 'cs.SY', 'eess.SY']","[arxiv.Result.Link('http://arxiv.org/abs/2003.07192v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07192v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07192v4,"{'id': 'http://arxiv.org/abs/2003.07192v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07192v4', 'updated': '2021-01-08T03:43:46Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=8, tm_hour=3, tm_min=43, tm_sec=46, tm_wday=4, tm_yday=8, tm_isdst=0), 'published': '2020-03-12T18:37:19Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=12, tm_hour=18, tm_min=37, tm_sec=19, tm_wday=3, tm_yday=72, tm_isdst=0), 'title': 'Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach'}, 'summary': 'In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.'}, 'authors': [{'name': 'Aditya Dave'}, {'name': 'Ioannis Vasileios Chremos'}, {'name': 'Andreas A. Malikopoulos'}], 'author_detail': {'name': 'Andreas A. Malikopoulos'}, 'author': 'Andreas A. Malikopoulos', 'links': [{'href': 'http://arxiv.org/abs/2003.07192v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07192v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
241,http://arxiv.org/abs/2003.05096v1,2020-03-11 03:16:04+00:00,2020-03-11 03:16:04+00:00,Exploring the Role of Visual Content in Fake News Detection,"[arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('Peng Qi'), arxiv.Result.Author('Qiang Sheng'), arxiv.Result.Author('Tianyun Yang'), arxiv.Result.Author('Junbo Guo'), arxiv.Result.Author('Jintao Li')]","The increasing popularity of social media promotes the proliferation of fake
news, which has caused significant negative societal effects. Therefore, fake
news detection on social media has recently become an emerging research area of
great concern. With the development of multimedia technology, fake news
attempts to utilize multimedia content with images or videos to attract and
mislead consumers for rapid dissemination, which makes visual content an
important part of fake news. Despite the importance of visual content, our
understanding of the role of visual content in fake news detection is still
limited. This chapter presents a comprehensive review of the visual content in
fake news, including the basic concepts, effective visual features,
representative detection methods and challenging issues of multimedia fake news
detection. This chapter can help readers to understand the role of visual
content in fake news detection, and effectively utilize visual content to
assist in detecting multimedia fake news.","This is a preprint of a chapter published in Disinformation,
  Misinformation, and Fake News in Social Media: Emerging Research Challenges
  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,
  Springer reproduced with permission of Springer Nature Switzerland AG. The
  final authenticated version is available online at:
  https://www.springer.com/gp/book/9783030426989. arXiv admin note: text
  overlap with arXiv:2001.00623, arXiv:1808.06686, arXiv:1903.00788 by other
  authors","Disinformation, Misinformation, and Fake News in Social Media.
  2020",10.1007/978-3-030-42699-6,cs.MM,"['cs.MM', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-42699-6', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2003.05096v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.05096v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.05096v1,"{'id': 'http://arxiv.org/abs/2003.05096v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.05096v1', 'updated': '2020-03-11T03:16:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=11, tm_hour=3, tm_min=16, tm_sec=4, tm_wday=2, tm_yday=71, tm_isdst=0), 'published': '2020-03-11T03:16:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=11, tm_hour=3, tm_min=16, tm_sec=4, tm_wday=2, tm_yday=71, tm_isdst=0), 'title': 'Exploring the Role of Visual Content in Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring the Role of Visual Content in Fake News Detection'}, 'summary': 'The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.'}, 'authors': [{'name': 'Juan Cao'}, {'name': 'Peng Qi'}, {'name': 'Qiang Sheng'}, {'name': 'Tianyun Yang'}, {'name': 'Junbo Guo'}, {'name': 'Jintao Li'}], 'author_detail': {'name': 'Jintao Li'}, 'author': 'Jintao Li', 'arxiv_doi': '10.1007/978-3-030-42699-6', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-42699-6', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2003.05096v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.05096v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  https://www.springer.com/gp/book/9783030426989. arXiv admin note: text\n  overlap with arXiv:2001.00623, arXiv:1808.06686, arXiv:1903.00788 by other\n  authors', 'arxiv_journal_ref': 'Disinformation, Misinformation, and Fake News in Social Media.\n  2020', 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
242,http://arxiv.org/abs/2003.00923v1,2020-03-02 14:07:56+00:00,2020-03-02 14:07:56+00:00,"Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business","[arxiv.Result.Author('Yelena Mejova'), arxiv.Result.Author('Kyriaki Kalimeri')]","In the age of social media, disasters and epidemics usher not only a
devastation and affliction in the physical world, but also prompt a deluge of
information, opinions, prognoses and advice to billions of internet users. The
coronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World
Health Organization warning of a possible ""infodemic"" of fake news. In this
study, we examine the alternative narratives around the coronavirus outbreak
through advertisements promoted on Facebook, the largest social media platform
in the US. Using the new Facebook Ads Library, we discover advertisers from
public health and non-profit sectors, alongside those from news media,
politics, and business, incorporating coronavirus into their messaging and
agenda. We find the virus used in political attacks, donation solicitations,
business promotion, stock market advice, and animal rights campaigning. Among
these, we find several instances of possible misinformation, ranging from
bioweapons conspiracy theories to unverifiable claims by politicians. As we
make the dataset available to the community, we hope the advertising domain
will become an important part of quality control for public health
communication and public discourse in general.",Preprint. Under Review,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2003.00923v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.00923v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.00923v1,"{'id': 'http://arxiv.org/abs/2003.00923v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.00923v1', 'updated': '2020-03-02T14:07:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=2, tm_hour=14, tm_min=7, tm_sec=56, tm_wday=0, tm_yday=62, tm_isdst=0), 'published': '2020-03-02T14:07:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=2, tm_hour=14, tm_min=7, tm_sec=56, tm_wday=0, tm_yday=62, tm_isdst=0), 'title': 'Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business'}, 'summary': 'In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible ""infodemic"" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible ""infodemic"" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.'}, 'authors': [{'name': 'Yelena Mejova'}, {'name': 'Kyriaki Kalimeri'}], 'author_detail': {'name': 'Kyriaki Kalimeri'}, 'author': 'Kyriaki Kalimeri', 'arxiv_comment': 'Preprint. Under Review', 'links': [{'href': 'http://arxiv.org/abs/2003.00923v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.00923v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
243,http://arxiv.org/abs/2003.00627v2,2020-03-23 18:46:08+00:00,2020-03-02 01:55:05+00:00,Cluster-Based Social Reinforcement Learning,"[arxiv.Result.Author('Mahak Goindani'), arxiv.Result.Author('Jennifer Neville')]","Social Reinforcement Learning methods, which model agents in large networks,
are useful for fake news mitigation, personalized teaching/healthcare, and
viral marketing, but it is challenging to incorporate inter-agent dependencies
into the models effectively due to network size and sparse interaction data.
Previous social RL approaches either ignore agents dependencies or model them
in a computationally intensive manner. In this work, we incorporate agent
dependencies efficiently in a compact model by clustering users (based on their
payoff and contribution to the goal) and combine this with a method to easily
derive personalized agent-level policies from cluster-level policies. We also
propose a dynamic clustering approach that captures changing user behavior.
Experiments on real-world datasets illustrate that our proposed approach learns
more accurate policy estimates and converges more quickly, compared to several
baselines that do not use agent correlations or only use static clusters.",,,,cs.LG,"['cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2003.00627v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.00627v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.00627v2,"{'id': 'http://arxiv.org/abs/2003.00627v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.00627v2', 'updated': '2020-03-23T18:46:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=23, tm_hour=18, tm_min=46, tm_sec=8, tm_wday=0, tm_yday=83, tm_isdst=0), 'published': '2020-03-02T01:55:05Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=2, tm_hour=1, tm_min=55, tm_sec=5, tm_wday=0, tm_yday=62, tm_isdst=0), 'title': 'Cluster-Based Social Reinforcement Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cluster-Based Social Reinforcement Learning'}, 'summary': 'Social Reinforcement Learning methods, which model agents in large networks,\nare useful for fake news mitigation, personalized teaching/healthcare, and\nviral marketing, but it is challenging to incorporate inter-agent dependencies\ninto the models effectively due to network size and sparse interaction data.\nPrevious social RL approaches either ignore agents dependencies or model them\nin a computationally intensive manner. In this work, we incorporate agent\ndependencies efficiently in a compact model by clustering users (based on their\npayoff and contribution to the goal) and combine this with a method to easily\nderive personalized agent-level policies from cluster-level policies. We also\npropose a dynamic clustering approach that captures changing user behavior.\nExperiments on real-world datasets illustrate that our proposed approach learns\nmore accurate policy estimates and converges more quickly, compared to several\nbaselines that do not use agent correlations or only use static clusters.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Reinforcement Learning methods, which model agents in large networks,\nare useful for fake news mitigation, personalized teaching/healthcare, and\nviral marketing, but it is challenging to incorporate inter-agent dependencies\ninto the models effectively due to network size and sparse interaction data.\nPrevious social RL approaches either ignore agents dependencies or model them\nin a computationally intensive manner. In this work, we incorporate agent\ndependencies efficiently in a compact model by clustering users (based on their\npayoff and contribution to the goal) and combine this with a method to easily\nderive personalized agent-level policies from cluster-level policies. We also\npropose a dynamic clustering approach that captures changing user behavior.\nExperiments on real-world datasets illustrate that our proposed approach learns\nmore accurate policy estimates and converges more quickly, compared to several\nbaselines that do not use agent correlations or only use static clusters.'}, 'authors': [{'name': 'Mahak Goindani'}, {'name': 'Jennifer Neville'}], 'author_detail': {'name': 'Jennifer Neville'}, 'author': 'Jennifer Neville', 'links': [{'href': 'http://arxiv.org/abs/2003.00627v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.00627v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
244,http://arxiv.org/abs/2003.04981v1,2020-02-19 02:51:04+00:00,2020-02-19 02:51:04+00:00,SAFE: Similarity-Aware Multi-Modal Fake News Detection,"[arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Jindi Wu'), arxiv.Result.Author('Reza Zafarani')]","Effective detection of fake news has recently attracted significant
attention. Current studies have made significant contributions to predicting
fake news with less focus on exploiting the relationship (similarity) between
the textual and visual information in news articles. Attaching importance to
such similarity helps identify fake news stories that, for example, attempt to
use irrelevant images to attract readers' attention. In this work, we propose a
$\mathsf{S}$imilarity-$\mathsf{A}$ware $\mathsf{F}$ak$\mathsf{E}$ news
detection method ($\mathsf{SAFE}$) which investigates multi-modal (textual and
visual) information of news articles. First, neural networks are adopted to
separately extract textual and visual features for news representation. We
further investigate the relationship between the extracted features across
modalities. Such representations of news textual and visual information along
with their relationship are jointly learned and used to predict fake news. The
proposed method facilitates recognizing the falsity of news articles based on
their text, images, or their ""mismatches."" We conduct extensive experiments on
large-scale real-world data, which demonstrate the effectiveness of the
proposed method.","To be published in The 24th Pacific-Asia Conference on Knowledge
  Discovery and Data Mining (PAKDD 2020)",,,cs.CL,"['cs.CL', 'cs.CV', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2003.04981v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.04981v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.04981v1,"{'id': 'http://arxiv.org/abs/2003.04981v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.04981v1', 'updated': '2020-02-19T02:51:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=51, tm_sec=4, tm_wday=2, tm_yday=50, tm_isdst=0), 'published': '2020-02-19T02:51:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=51, tm_sec=4, tm_wday=2, tm_yday=50, tm_isdst=0), 'title': 'SAFE: Similarity-Aware Multi-Modal Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SAFE: Similarity-Aware Multi-Modal Fake News Detection'}, 'summary': 'Effective detection of fake news has recently attracted significant\nattention. Current studies have made significant contributions to predicting\nfake news with less focus on exploiting the relationship (similarity) between\nthe textual and visual information in news articles. Attaching importance to\nsuch similarity helps identify fake news stories that, for example, attempt to\nuse irrelevant images to attract readers\' attention. In this work, we propose a\n$\\mathsf{S}$imilarity-$\\mathsf{A}$ware $\\mathsf{F}$ak$\\mathsf{E}$ news\ndetection method ($\\mathsf{SAFE}$) which investigates multi-modal (textual and\nvisual) information of news articles. First, neural networks are adopted to\nseparately extract textual and visual features for news representation. We\nfurther investigate the relationship between the extracted features across\nmodalities. Such representations of news textual and visual information along\nwith their relationship are jointly learned and used to predict fake news. The\nproposed method facilitates recognizing the falsity of news articles based on\ntheir text, images, or their ""mismatches."" We conduct extensive experiments on\nlarge-scale real-world data, which demonstrate the effectiveness of the\nproposed method.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Effective detection of fake news has recently attracted significant\nattention. Current studies have made significant contributions to predicting\nfake news with less focus on exploiting the relationship (similarity) between\nthe textual and visual information in news articles. Attaching importance to\nsuch similarity helps identify fake news stories that, for example, attempt to\nuse irrelevant images to attract readers\' attention. In this work, we propose a\n$\\mathsf{S}$imilarity-$\\mathsf{A}$ware $\\mathsf{F}$ak$\\mathsf{E}$ news\ndetection method ($\\mathsf{SAFE}$) which investigates multi-modal (textual and\nvisual) information of news articles. First, neural networks are adopted to\nseparately extract textual and visual features for news representation. We\nfurther investigate the relationship between the extracted features across\nmodalities. Such representations of news textual and visual information along\nwith their relationship are jointly learned and used to predict fake news. The\nproposed method facilitates recognizing the falsity of news articles based on\ntheir text, images, or their ""mismatches."" We conduct extensive experiments on\nlarge-scale real-world data, which demonstrate the effectiveness of the\nproposed method.'}, 'authors': [{'name': 'Xinyi Zhou'}, {'name': 'Jindi Wu'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_comment': 'To be published in The 24th Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD 2020)', 'links': [{'href': 'http://arxiv.org/abs/2003.04981v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.04981v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
245,http://arxiv.org/abs/2003.04978v1,2020-02-15 06:15:17+00:00,2020-02-15 06:15:17+00:00,Fake News Detection with Different Models,"[arxiv.Result.Author('Sairamvinay Vijayaraghavan'), arxiv.Result.Author('Ye Wang'), arxiv.Result.Author('Zhiyuan Guo'), arxiv.Result.Author('John Voong'), arxiv.Result.Author('Wenda Xu'), arxiv.Result.Author('Armand Nasseri'), arxiv.Result.Author('Jiaru Cai'), arxiv.Result.Author('Linda Li'), arxiv.Result.Author('Kevin Vuong'), arxiv.Result.Author('Eshan Wadhwa')]","This is a paper for exploring various different models aiming at developing
fake news detection models and we had used certain machine learning algorithms
and we had used pretrained algorithms such as TFIDF and CV and W2V as features
for processing textual data.",,,,cs.CL,"['cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2003.04978v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.04978v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.04978v1,"{'id': 'http://arxiv.org/abs/2003.04978v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.04978v1', 'updated': '2020-02-15T06:15:17Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=15, tm_hour=6, tm_min=15, tm_sec=17, tm_wday=5, tm_yday=46, tm_isdst=0), 'published': '2020-02-15T06:15:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=15, tm_hour=6, tm_min=15, tm_sec=17, tm_wday=5, tm_yday=46, tm_isdst=0), 'title': 'Fake News Detection with Different Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection with Different Models'}, 'summary': 'This is a paper for exploring various different models aiming at developing\nfake news detection models and we had used certain machine learning algorithms\nand we had used pretrained algorithms such as TFIDF and CV and W2V as features\nfor processing textual data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This is a paper for exploring various different models aiming at developing\nfake news detection models and we had used certain machine learning algorithms\nand we had used pretrained algorithms such as TFIDF and CV and W2V as features\nfor processing textual data.'}, 'authors': [{'name': 'Sairamvinay Vijayaraghavan'}, {'name': 'Ye Wang'}, {'name': 'Zhiyuan Guo'}, {'name': 'John Voong'}, {'name': 'Wenda Xu'}, {'name': 'Armand Nasseri'}, {'name': 'Jiaru Cai'}, {'name': 'Linda Li'}, {'name': 'Kevin Vuong'}, {'name': 'Eshan Wadhwa'}], 'author_detail': {'name': 'Eshan Wadhwa'}, 'author': 'Eshan Wadhwa', 'links': [{'href': 'http://arxiv.org/abs/2003.04978v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.04978v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
246,http://arxiv.org/abs/2002.04397v2,2021-02-13 03:16:22+00:00,2020-02-05 19:09:13+00:00,Fake News Detection on News-Oriented Heterogeneous Information Networks through Hierarchical Graph Attention,"[arxiv.Result.Author('Yuxiang Ren'), arxiv.Result.Author('Jiawei Zhang')]","The viral spread of fake news has caused great social harm, making fake news
detection an urgent task. Current fake news detection methods rely heavily on
text information by learning the extracted news content or writing style of
internal knowledge. However, deliberate rumors can mask writing style,
bypassing language models and invalidating simple text-based models. In fact,
news articles and other related components (such as news creators and news
topics) can be modeled as a heterogeneous information network (HIN for short).
In this paper, we propose a novel fake news detection framework, namely
Hierarchical Graph Attention Network(HGAT), which uses a novel hierarchical
attention mechanism to perform node representation learning in HIN, and then
detects fake news by classifying news article nodes. Experiments on two
real-world fake news datasets show that HGAT can outperform text-based models
and other network-based models. In addition, the experiment proved the
expandability and generalizability of our for graph representation learning and
other node classification related applications in heterogeneous graphs.",,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2002.04397v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.04397v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.04397v2,"{'id': 'http://arxiv.org/abs/2002.04397v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.04397v2', 'updated': '2021-02-13T03:16:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=13, tm_hour=3, tm_min=16, tm_sec=22, tm_wday=5, tm_yday=44, tm_isdst=0), 'published': '2020-02-05T19:09:13Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=5, tm_hour=19, tm_min=9, tm_sec=13, tm_wday=2, tm_yday=36, tm_isdst=0), 'title': 'Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention'}, 'summary': 'The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.'}, 'authors': [{'name': 'Yuxiang Ren'}, {'name': 'Jiawei Zhang'}], 'author_detail': {'name': 'Jiawei Zhang'}, 'author': 'Jiawei Zhang', 'links': [{'href': 'http://arxiv.org/abs/2002.04397v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.04397v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
247,http://arxiv.org/abs/2002.01065v2,2020-04-02 05:12:35+00:00,2020-02-04 00:28:38+00:00,Fake News Detection by means of Uncertainty Weighted Causal Graphs,"[arxiv.Result.Author('Eduardo C. Garrido-Merchán'), arxiv.Result.Author('Cristina Puente'), arxiv.Result.Author('Rafael Palacios')]","Society is experimenting changes in information consumption, as new
information channels such as social networks let people share news that do not
necessarily be trust worthy. Sometimes, these sources of information produce
fake news deliberately with doubtful purposes and the consumers of that
information share it to other users thinking that the information is accurate.
This transmission of information represents an issue in our society, as can
influence negatively the opinion of people about certain figures, groups or
ideas. Hence, it is desirable to design a system that is able to detect and
classify information as fake and categorize a source of information as trust
worthy or not. Current systems experiment difficulties performing this task, as
it is complicated to design an automatic procedure that can classify this
information independent on the context. In this work, we propose a mechanism to
detect fake news through a classifier based on weighted causal graphs. These
graphs are specific hybrid models that are built through causal relations
retrieved from texts and consider the uncertainty of causal relations. We take
advantage of this representation to use the probability distributions of this
graph and built a fake news classifier based on the entropy and KL divergence
of learned and new information. We believe that the problem of fake news is
accurately tackled by this model due to its hybrid nature between a symbolic
and quantitative methodology. We describe the methodology of this classifier
and add empirical evidence of the usefulness of our proposed approach in the
form of synthetic experiments and a real experiment involving lung cancer.",,,,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2002.01065v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.01065v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.01065v2,"{'id': 'http://arxiv.org/abs/2002.01065v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.01065v2', 'updated': '2020-04-02T05:12:35Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=5, tm_min=12, tm_sec=35, tm_wday=3, tm_yday=93, tm_isdst=0), 'published': '2020-02-04T00:28:38Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=4, tm_hour=0, tm_min=28, tm_sec=38, tm_wday=1, tm_yday=35, tm_isdst=0), 'title': 'Fake News Detection by means of Uncertainty Weighted Causal Graphs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection by means of Uncertainty Weighted Causal Graphs'}, 'summary': 'Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.'}, 'authors': [{'name': 'Eduardo C. Garrido-Merchán'}, {'name': 'Cristina Puente'}, {'name': 'Rafael Palacios'}], 'author_detail': {'name': 'Rafael Palacios'}, 'author': 'Rafael Palacios', 'links': [{'href': 'http://arxiv.org/abs/2002.01065v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.01065v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
248,http://arxiv.org/abs/2002.01030v1,2020-02-03 22:13:07+00:00,2020-02-03 22:13:07+00:00,Detecting Fake News with Capsule Neural Networks,"[arxiv.Result.Author('Mohammad Hadi Goldani'), arxiv.Result.Author('Saeedeh Momtazi'), arxiv.Result.Author('Reza Safabakhsh')]","Fake news is dramatically increased in social media in recent years. This has
prompted the need for effective fake news detection algorithms. Capsule neural
networks have been successful in computer vision and are receiving attention
for use in Natural Language Processing (NLP). This paper aims to use capsule
neural networks in the fake news detection task. We use different embedding
models for news items of different lengths. Static word embedding is used for
short news items, whereas non-static word embeddings that allow incremental
up-training and updating in the training phase are used for medium length or
large news statements. Moreover, we apply different levels of n-grams for
feature extraction. Our proposed architectures are evaluated on two recent
well-known datasets in the field, namely ISOT and LIAR. The results show
encouraging performance, outperforming the state-of-the-art methods by 7.8% on
ISOT and 3.1% on the validation set, and 1% on the test set of the LIAR
dataset.","25 pages, 4 figures",,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2002.01030v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.01030v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.01030v1,"{'id': 'http://arxiv.org/abs/2002.01030v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.01030v1', 'updated': '2020-02-03T22:13:07Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=3, tm_hour=22, tm_min=13, tm_sec=7, tm_wday=0, tm_yday=34, tm_isdst=0), 'published': '2020-02-03T22:13:07Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=3, tm_hour=22, tm_min=13, tm_sec=7, tm_wday=0, tm_yday=34, tm_isdst=0), 'title': 'Detecting Fake News with Capsule Neural Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Fake News with Capsule Neural Networks'}, 'summary': 'Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.'}, 'authors': [{'name': 'Mohammad Hadi Goldani'}, {'name': 'Saeedeh Momtazi'}, {'name': 'Reza Safabakhsh'}], 'author_detail': {'name': 'Reza Safabakhsh'}, 'author': 'Reza Safabakhsh', 'arxiv_comment': '25 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2002.01030v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.01030v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
249,http://arxiv.org/abs/2002.00763v1,2020-01-31 02:28:35+00:00,2020-01-31 02:28:35+00:00,Two-path Deep Semi-supervised Learning for Timely Fake News Detection,"[arxiv.Result.Author('Xishuang Dong'), arxiv.Result.Author('Uboho Victor'), arxiv.Result.Author('Lijun Qian')]","News in social media such as Twitter has been generated in high volume and
speed. However, very few of them are labeled (as fake or true news) by
professionals in near real time. In order to achieve timely detection of fake
news in social media, a novel framework of two-path deep semi-supervised
learning is proposed where one path is for supervised learning and the other is
for unsupervised learning. The supervised learning path learns on the limited
amount of labeled data while the unsupervised learning path is able to learn on
a huge amount of unlabeled data. Furthermore, these two paths implemented with
convolutional neural networks (CNN) are jointly optimized to complete
semi-supervised learning. In addition, we build a shared CNN to extract the low
level features on both labeled data and unlabeled data to feed them into these
two paths. To verify this framework, we implement a Word CNN based
semi-supervised learning model and test it on two datasets, namely, LIAR and
PHEME. Experimental results demonstrate that the model built on the proposed
framework can recognize fake news effectively with very few labeled data.",,,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2002.00763v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.00763v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.00763v1,"{'id': 'http://arxiv.org/abs/2002.00763v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.00763v1', 'updated': '2020-01-31T02:28:35Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=31, tm_hour=2, tm_min=28, tm_sec=35, tm_wday=4, tm_yday=31, tm_isdst=0), 'published': '2020-01-31T02:28:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=31, tm_hour=2, tm_min=28, tm_sec=35, tm_wday=4, tm_yday=31, tm_isdst=0), 'title': 'Two-path Deep Semi-supervised Learning for Timely Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Two-path Deep Semi-supervised Learning for Timely Fake News Detection'}, 'summary': 'News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them are labeled (as fake or true news) by\nprofessionals in near real time. In order to achieve timely detection of fake\nnews in social media, a novel framework of two-path deep semi-supervised\nlearning is proposed where one path is for supervised learning and the other is\nfor unsupervised learning. The supervised learning path learns on the limited\namount of labeled data while the unsupervised learning path is able to learn on\na huge amount of unlabeled data. Furthermore, these two paths implemented with\nconvolutional neural networks (CNN) are jointly optimized to complete\nsemi-supervised learning. In addition, we build a shared CNN to extract the low\nlevel features on both labeled data and unlabeled data to feed them into these\ntwo paths. To verify this framework, we implement a Word CNN based\nsemi-supervised learning model and test it on two datasets, namely, LIAR and\nPHEME. Experimental results demonstrate that the model built on the proposed\nframework can recognize fake news effectively with very few labeled data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them are labeled (as fake or true news) by\nprofessionals in near real time. In order to achieve timely detection of fake\nnews in social media, a novel framework of two-path deep semi-supervised\nlearning is proposed where one path is for supervised learning and the other is\nfor unsupervised learning. The supervised learning path learns on the limited\namount of labeled data while the unsupervised learning path is able to learn on\na huge amount of unlabeled data. Furthermore, these two paths implemented with\nconvolutional neural networks (CNN) are jointly optimized to complete\nsemi-supervised learning. In addition, we build a shared CNN to extract the low\nlevel features on both labeled data and unlabeled data to feed them into these\ntwo paths. To verify this framework, we implement a Word CNN based\nsemi-supervised learning model and test it on two datasets, namely, LIAR and\nPHEME. Experimental results demonstrate that the model built on the proposed\nframework can recognize fake news effectively with very few labeled data.'}, 'authors': [{'name': 'Xishuang Dong'}, {'name': 'Uboho Victor'}, {'name': 'Lijun Qian'}], 'author_detail': {'name': 'Lijun Qian'}, 'author': 'Lijun Qian', 'links': [{'href': 'http://arxiv.org/abs/2002.00763v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.00763v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
250,http://arxiv.org/abs/2002.00838v1,2020-01-28 00:44:59+00:00,2020-01-28 00:44:59+00:00,Improving Generalizability of Fake News Detection Methods using Propensity Score Matching,"[arxiv.Result.Author('Bo Ni'), arxiv.Result.Author('Zhichun Guo'), arxiv.Result.Author('Jianing Li'), arxiv.Result.Author('Meng Jiang')]","Recently, due to the booming influence of online social networks, detecting
fake news is drawing significant attention from both academic communities and
general public. In this paper, we consider the existence of confounding
variables in the features of fake news and use Propensity Score Matching (PSM)
to select generalizable features in order to reduce the effects of the
confounding variables. Experimental results show that the generalizability of
fake news method is significantly better by using PSM than using raw frequency
to select features. We investigate multiple types of fake news methods
(classifiers) such as logistic regression, random forests, and support vector
machines. We have consistent observations of performance improvement.",,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2002.00838v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.00838v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.00838v1,"{'id': 'http://arxiv.org/abs/2002.00838v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.00838v1', 'updated': '2020-01-28T00:44:59Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=28, tm_hour=0, tm_min=44, tm_sec=59, tm_wday=1, tm_yday=28, tm_isdst=0), 'published': '2020-01-28T00:44:59Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=28, tm_hour=0, tm_min=44, tm_sec=59, tm_wday=1, tm_yday=28, tm_isdst=0), 'title': 'Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching'}, 'summary': 'Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.'}, 'authors': [{'name': 'Bo Ni'}, {'name': 'Zhichun Guo'}, {'name': 'Jianing Li'}, {'name': 'Meng Jiang'}], 'author_detail': {'name': 'Meng Jiang'}, 'author': 'Meng Jiang', 'links': [{'href': 'http://arxiv.org/abs/2002.00838v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.00838v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
251,http://arxiv.org/abs/2002.00837v2,2020-03-30 06:08:08+00:00,2020-01-27 17:27:58+00:00,Ginger Cannot Cure Cancer: Battling Fake Health News with a Comprehensive Data Repository,"[arxiv.Result.Author('Enyan Dai'), arxiv.Result.Author('Yiwei Sun'), arxiv.Result.Author('Suhang Wang')]","Nowadays, Internet is a primary source of attaining health information.
Massive fake health news which is spreading over the Internet, has become a
severe threat to public health. Numerous studies and research works have been
done in fake news detection domain, however, few of them are designed to cope
with the challenges in health news. For instance, the development of
explainable is required for fake health news detection. To mitigate these
problems, we construct a comprehensive repository, FakeHealth, which includes
news contents with rich features, news reviews with detailed explanations,
social engagements and a user-user social network. Moreover, exploratory
analyses are conducted to understand the characteristics of the datasets,
analyze useful patterns and validate the quality of the datasets for health
fake news detection. We also discuss the novel and potential future research
directions for the health fake news detection.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2002.00837v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.00837v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.00837v2,"{'id': 'http://arxiv.org/abs/2002.00837v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.00837v2', 'updated': '2020-03-30T06:08:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=30, tm_hour=6, tm_min=8, tm_sec=8, tm_wday=0, tm_yday=90, tm_isdst=0), 'published': '2020-01-27T17:27:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=27, tm_hour=17, tm_min=27, tm_sec=58, tm_wday=0, tm_yday=27, tm_isdst=0), 'title': 'Ginger Cannot Cure Cancer: Battling Fake Health News with a\n  Comprehensive Data Repository', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Ginger Cannot Cure Cancer: Battling Fake Health News with a\n  Comprehensive Data Repository'}, 'summary': 'Nowadays, Internet is a primary source of attaining health information.\nMassive fake health news which is spreading over the Internet, has become a\nsevere threat to public health. Numerous studies and research works have been\ndone in fake news detection domain, however, few of them are designed to cope\nwith the challenges in health news. For instance, the development of\nexplainable is required for fake health news detection. To mitigate these\nproblems, we construct a comprehensive repository, FakeHealth, which includes\nnews contents with rich features, news reviews with detailed explanations,\nsocial engagements and a user-user social network. Moreover, exploratory\nanalyses are conducted to understand the characteristics of the datasets,\nanalyze useful patterns and validate the quality of the datasets for health\nfake news detection. We also discuss the novel and potential future research\ndirections for the health fake news detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Nowadays, Internet is a primary source of attaining health information.\nMassive fake health news which is spreading over the Internet, has become a\nsevere threat to public health. Numerous studies and research works have been\ndone in fake news detection domain, however, few of them are designed to cope\nwith the challenges in health news. For instance, the development of\nexplainable is required for fake health news detection. To mitigate these\nproblems, we construct a comprehensive repository, FakeHealth, which includes\nnews contents with rich features, news reviews with detailed explanations,\nsocial engagements and a user-user social network. Moreover, exploratory\nanalyses are conducted to understand the characteristics of the datasets,\nanalyze useful patterns and validate the quality of the datasets for health\nfake news detection. We also discuss the novel and potential future research\ndirections for the health fake news detection.'}, 'authors': [{'name': 'Enyan Dai'}, {'name': 'Yiwei Sun'}, {'name': 'Suhang Wang'}], 'author_detail': {'name': 'Suhang Wang'}, 'author': 'Suhang Wang', 'links': [{'href': 'http://arxiv.org/abs/2002.00837v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.00837v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
252,http://arxiv.org/abs/2001.09473v1,2020-01-26 15:42:43+00:00,2020-01-26 15:42:43+00:00,"Information Credibility in the Social Web: Contexts, Approaches, and Open Issues","[arxiv.Result.Author('Gabriella Pasi'), arxiv.Result.Author('Marco Viviani')]","In the Social Web scenario, large amounts of User-Generated Content (UGC) are
diffused through social media often without almost any form of traditional
trusted intermediaries. Therefore, the risk of running into misinformation is
not negligible. For this reason, assessing and mining the credibility of online
information constitutes nowadays a fundamental research issue. Credibility,
also referred as believability, is a quality perceived by individuals, who are
not always able to discern, with their own cognitive capacities, genuine
information from fake one. Hence, in the last years, several approaches have
been proposed to automatically assess credibility in social media. Many of them
are based on data-driven models, i.e., they employ machine learning techniques
to identify misinformation, but recently also model-driven approaches are
emerging, as well as graph-based approaches focusing on credibility
propagation, and knowledge-based ones exploiting Semantic Web technologies.
Three of the main contexts in which the assessment of information credibility
has been investigated concern: (i) the detection of opinion spam in review
sites, (ii) the detection of fake news in microblogging, and (iii) the
credibility assessment of online health-related information. In this article,
the main issues connected to the evaluation of information credibility in the
Social Web, which are shared by the above-mentioned contexts, are discussed. A
concise survey of the approaches and methodologies that have been proposed in
recent years to address these issues is also presented.","Article accepted and presented at ITASEC 2020: Italian Conference on
  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2001.09473v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.09473v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.09473v1,"{'id': 'http://arxiv.org/abs/2001.09473v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.09473v1', 'updated': '2020-01-26T15:42:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=26, tm_hour=15, tm_min=42, tm_sec=43, tm_wday=6, tm_yday=26, tm_isdst=0), 'published': '2020-01-26T15:42:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=26, tm_hour=15, tm_min=42, tm_sec=43, tm_wday=6, tm_yday=26, tm_isdst=0), 'title': 'Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues'}, 'summary': 'In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.'}, 'authors': [{'name': 'Gabriella Pasi'}, {'name': 'Marco Viviani'}], 'author_detail': {'name': 'Marco Viviani'}, 'author': 'Marco Viviani', 'arxiv_comment': 'Article accepted and presented at ITASEC 2020: Italian Conference on\n  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/', 'links': [{'href': 'http://arxiv.org/abs/2001.09473v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.09473v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
253,http://arxiv.org/abs/2001.02438v1,2020-01-08 10:26:55+00:00,2020-01-08 10:26:55+00:00,To Transfer or Not to Transfer: Misclassification Attacks Against Transfer Learned Text Classifiers,"[arxiv.Result.Author('Bijeeta Pal'), arxiv.Result.Author('Shruti Tople')]","Transfer learning --- transferring learned knowledge --- has brought a
paradigm shift in the way models are trained. The lucrative benefits of
improved accuracy and reduced training time have shown promise in training
models with constrained computational resources and fewer training samples.
Specifically, publicly available text-based models such as GloVe and BERT that
are trained on large corpus of datasets have seen ubiquitous adoption in
practice. In this paper, we ask, ""can transfer learning in text prediction
models be exploited to perform misclassification attacks?"" As our main
contribution, we present novel attack techniques that utilize unintended
features learnt in the teacher (public) model to generate adversarial examples
for student (downstream) models. To the best of our knowledge, ours is the
first work to show that transfer learning from state-of-the-art word-based and
sentence-based teacher models increase the susceptibility of student models to
misclassification attacks. First, we propose a novel word-score based attack
algorithm for generating adversarial examples against student models trained
using context-free word-level embedding model. On binary classification tasks
trained using the GloVe teacher model, we achieve an average attack accuracy of
97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For
multi-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and
achieve an average attack accuracy of 75% and 41% respectively. Next, we
present length-based and sentence-based misclassification attacks for the Fake
News Detection task trained using a context-aware BERT model and achieve 78%
and 39% attack accuracy respectively. Thus, our results motivate the need for
designing training techniques that are robust to unintended feature learning,
specifically for transfer learned models.",,,,cs.LG,"['cs.LG', 'cs.CR', 'cs.IR', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2001.02438v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.02438v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.02438v1,"{'id': 'http://arxiv.org/abs/2001.02438v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.02438v1', 'updated': '2020-01-08T10:26:55Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=8, tm_hour=10, tm_min=26, tm_sec=55, tm_wday=2, tm_yday=8, tm_isdst=0), 'published': '2020-01-08T10:26:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=8, tm_hour=10, tm_min=26, tm_sec=55, tm_wday=2, tm_yday=8, tm_isdst=0), 'title': 'To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers'}, 'summary': 'Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, ""can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?"" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, ""can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?"" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.'}, 'authors': [{'name': 'Bijeeta Pal'}, {'name': 'Shruti Tople'}], 'author_detail': {'name': 'Shruti Tople'}, 'author': 'Shruti Tople', 'links': [{'href': 'http://arxiv.org/abs/2001.02438v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.02438v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
254,http://arxiv.org/abs/2001.02214v1,2020-01-07 18:26:38+00:00,2020-01-07 18:26:38+00:00,Attributed Multi-Relational Attention Network for Fact-checking URL Recommendation,"[arxiv.Result.Author('Di You'), arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee'), arxiv.Result.Author('Qiang Liu')]","To combat fake news, researchers mostly focused on detecting fake news and
journalists built and maintained fact-checking sites (e.g., Snopes.com and
Politifact.com). However, fake news dissemination has been greatly promoted via
social media sites, and these fact-checking sites have not been fully utilized.
To overcome these problems and complement existing methods against fake news,
in this paper we propose a deep-learning based fact-checking URL recommender
system to mitigate impact of fake news in social media sites such as Twitter
and Facebook. In particular, our proposed framework consists of a
multi-relational attentive module and a heterogeneous graph attention network
to learn complex/semantic relationship between user-URL pairs, user-user pairs,
and URL-URL pairs. Extensive experiments on a real-world dataset show that our
proposed framework outperforms eight state-of-the-art recommendation models,
achieving at least 3~5.3% improvement.",CIKM2019,,,cs.IR,"['cs.IR', 'cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2001.02214v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.02214v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.02214v1,"{'id': 'http://arxiv.org/abs/2001.02214v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.02214v1', 'updated': '2020-01-07T18:26:38Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=7, tm_hour=18, tm_min=26, tm_sec=38, tm_wday=1, tm_yday=7, tm_isdst=0), 'published': '2020-01-07T18:26:38Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=7, tm_hour=18, tm_min=26, tm_sec=38, tm_wday=1, tm_yday=7, tm_isdst=0), 'title': 'Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation'}, 'summary': 'To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.'}, 'authors': [{'name': 'Di You'}, {'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}, {'name': 'Qiang Liu'}], 'author_detail': {'name': 'Qiang Liu'}, 'author': 'Qiang Liu', 'arxiv_comment': 'CIKM2019', 'links': [{'href': 'http://arxiv.org/abs/2001.02214v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.02214v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
255,http://arxiv.org/abs/2001.01565v1,2020-01-06 13:37:51+00:00,2020-01-06 13:37:51+00:00,Stance Detection Benchmark: How Robust Is Your Stance Detection?,"[arxiv.Result.Author('Benjamin Schiller'), arxiv.Result.Author('Johannes Daxenberger'), arxiv.Result.Author('Iryna Gurevych')]","Stance Detection (StD) aims to detect an author's stance towards a certain
topic or claim and has become a key component in applications like fake news
detection, claim validation, and argument search. However, while stance is
easily detected by humans, machine learning models are clearly falling short of
this task. Given the major differences in dataset sizes and framing of StD
(e.g. number of classes and inputs), we introduce a StD benchmark that learns
from ten StD datasets of various domains in a multi-dataset learning (MDL)
setting, as well as from related tasks via transfer learning. Within this
benchmark setup, we are able to present new state-of-the-art results on five of
the datasets. Yet, the models still perform well below human capabilities and
even simple adversarial attacks severely hurt the performance of MDL models.
Deeper investigation into this phenomenon suggests the existence of biases
inherited from multiple datasets by design. Our analysis emphasizes the need of
focus on robustness and de-biasing strategies in multi-task learning
approaches. The benchmark dataset and code is made available.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2001.01565v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.01565v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.01565v1,"{'id': 'http://arxiv.org/abs/2001.01565v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.01565v1', 'updated': '2020-01-06T13:37:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=6, tm_hour=13, tm_min=37, tm_sec=51, tm_wday=0, tm_yday=6, tm_isdst=0), 'published': '2020-01-06T13:37:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=6, tm_hour=13, tm_min=37, tm_sec=51, tm_wday=0, tm_yday=6, tm_isdst=0), 'title': 'Stance Detection Benchmark: How Robust Is Your Stance Detection?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance Detection Benchmark: How Robust Is Your Stance Detection?'}, 'summary': ""Stance Detection (StD) aims to detect an author's stance towards a certain\ntopic or claim and has become a key component in applications like fake news\ndetection, claim validation, and argument search. However, while stance is\neasily detected by humans, machine learning models are clearly falling short of\nthis task. Given the major differences in dataset sizes and framing of StD\n(e.g. number of classes and inputs), we introduce a StD benchmark that learns\nfrom ten StD datasets of various domains in a multi-dataset learning (MDL)\nsetting, as well as from related tasks via transfer learning. Within this\nbenchmark setup, we are able to present new state-of-the-art results on five of\nthe datasets. Yet, the models still perform well below human capabilities and\neven simple adversarial attacks severely hurt the performance of MDL models.\nDeeper investigation into this phenomenon suggests the existence of biases\ninherited from multiple datasets by design. Our analysis emphasizes the need of\nfocus on robustness and de-biasing strategies in multi-task learning\napproaches. The benchmark dataset and code is made available."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Stance Detection (StD) aims to detect an author's stance towards a certain\ntopic or claim and has become a key component in applications like fake news\ndetection, claim validation, and argument search. However, while stance is\neasily detected by humans, machine learning models are clearly falling short of\nthis task. Given the major differences in dataset sizes and framing of StD\n(e.g. number of classes and inputs), we introduce a StD benchmark that learns\nfrom ten StD datasets of various domains in a multi-dataset learning (MDL)\nsetting, as well as from related tasks via transfer learning. Within this\nbenchmark setup, we are able to present new state-of-the-art results on five of\nthe datasets. Yet, the models still perform well below human capabilities and\neven simple adversarial attacks severely hurt the performance of MDL models.\nDeeper investigation into this phenomenon suggests the existence of biases\ninherited from multiple datasets by design. Our analysis emphasizes the need of\nfocus on robustness and de-biasing strategies in multi-task learning\napproaches. The benchmark dataset and code is made available.""}, 'authors': [{'name': 'Benjamin Schiller'}, {'name': 'Johannes Daxenberger'}, {'name': 'Iryna Gurevych'}], 'author_detail': {'name': 'Iryna Gurevych'}, 'author': 'Iryna Gurevych', 'links': [{'href': 'http://arxiv.org/abs/2001.01565v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.01565v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
256,http://arxiv.org/abs/2001.00623v1,2020-01-02 21:01:02+00:00,2020-01-02 21:01:02+00:00,"Mining Disinformation and Fake News: Concepts, Methods, and Recent Advancements","[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Dongwon Lee'), arxiv.Result.Author('Huan Liu')]","In recent years, disinformation including fake news, has became a global
phenomenon due to its explosive growth, particularly on social media. The wide
spread of disinformation and fake news can cause detrimental societal effects.
Despite the recent progress in detecting disinformation and fake news, it is
still non-trivial due to its complexity, diversity, multi-modality, and costs
of fact-checking or annotation. The goal of this chapter is to pave the way for
appreciating the challenges and advancements via: (1) introducing the types of
information disorder on social media and examine their differences and
connections; (2) describing important and emerging tasks to combat
disinformation for characterization, detection and attribution; and (3)
discussing a weak supervision approach to detect disinformation with limited
labeled data. We then provide an overview of the chapters in this book that
represent the recent advancements in three related parts: (1) user engagements
in the dissemination of information disorder; (2) techniques on detecting and
mitigating disinformation; and (3) trending issues such as ethics, blockchain,
clickbaits, etc. We hope this book to be a convenient entry point for
researchers, practitioners, and students to understand the problems and
challenges, learn state-of-the-art solutions for their specific needs, and
quickly identify new research problems in their domains.","Submitted as an introductory chapter for the edited book on ""Fake
  News, Disinformation, and Misinformation in Social Media- Emerging Research
  Challenges and Opportunities"", Springer Press",,,cs.SI,"['cs.SI', 'cs.CL', 'H.2.8']","[arxiv.Result.Link('http://arxiv.org/abs/2001.00623v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.00623v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.00623v1,"{'id': 'http://arxiv.org/abs/2001.00623v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.00623v1', 'updated': '2020-01-02T21:01:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=2, tm_hour=21, tm_min=1, tm_sec=2, tm_wday=3, tm_yday=2, tm_isdst=0), 'published': '2020-01-02T21:01:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=2, tm_hour=21, tm_min=1, tm_sec=2, tm_wday=3, tm_yday=2, tm_isdst=0), 'title': 'Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements'}, 'summary': 'In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Suhang Wang'}, {'name': 'Dongwon Lee'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'Submitted as an introductory chapter for the edited book on ""Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities"", Springer Press', 'links': [{'href': 'http://arxiv.org/abs/2001.00623v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.00623v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.2.8', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
257,http://arxiv.org/abs/2001.00179v3,2020-06-18 18:17:43+00:00,2020-01-01 09:54:34+00:00,DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection,"[arxiv.Result.Author('Ruben Tolosana'), arxiv.Result.Author('Ruben Vera-Rodriguez'), arxiv.Result.Author('Julian Fierrez'), arxiv.Result.Author('Aythami Morales'), arxiv.Result.Author('Javier Ortega-Garcia')]","The free access to large-scale public databases, together with the fast
progress of deep learning techniques, in particular Generative Adversarial
Networks, have led to the generation of very realistic fake content with its
corresponding implications towards society in this era of fake news. This
survey provides a thorough review of techniques for manipulating face images
including DeepFake methods, and methods to detect such manipulations. In
particular, four types of facial manipulation are reviewed: i) entire face
synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv)
expression swap. For each manipulation group, we provide details regarding
manipulation techniques, existing public databases, and key benchmarks for
technology evaluation of fake detection methods, including a summary of results
from those evaluations. Among all the aspects discussed in the survey, we pay
special attention to the latest generation of DeepFakes, highlighting its
improvements and challenges for fake detection.
  In addition to the survey information, we also discuss open issues and future
trends that should be considered to advance in the field.",,"Information Fusion, 2020",,cs.CV,"['cs.CV', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2001.00179v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.00179v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.00179v3,"{'id': 'http://arxiv.org/abs/2001.00179v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.00179v3', 'updated': '2020-06-18T18:17:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=18, tm_hour=18, tm_min=17, tm_sec=43, tm_wday=3, tm_yday=170, tm_isdst=0), 'published': '2020-01-01T09:54:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=1, tm_hour=9, tm_min=54, tm_sec=34, tm_wday=2, tm_yday=1, tm_isdst=0), 'title': 'DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection'}, 'summary': 'The free access to large-scale public databases, together with the fast\nprogress of deep learning techniques, in particular Generative Adversarial\nNetworks, have led to the generation of very realistic fake content with its\ncorresponding implications towards society in this era of fake news. This\nsurvey provides a thorough review of techniques for manipulating face images\nincluding DeepFake methods, and methods to detect such manipulations. In\nparticular, four types of facial manipulation are reviewed: i) entire face\nsynthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv)\nexpression swap. For each manipulation group, we provide details regarding\nmanipulation techniques, existing public databases, and key benchmarks for\ntechnology evaluation of fake detection methods, including a summary of results\nfrom those evaluations. Among all the aspects discussed in the survey, we pay\nspecial attention to the latest generation of DeepFakes, highlighting its\nimprovements and challenges for fake detection.\n  In addition to the survey information, we also discuss open issues and future\ntrends that should be considered to advance in the field.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The free access to large-scale public databases, together with the fast\nprogress of deep learning techniques, in particular Generative Adversarial\nNetworks, have led to the generation of very realistic fake content with its\ncorresponding implications towards society in this era of fake news. This\nsurvey provides a thorough review of techniques for manipulating face images\nincluding DeepFake methods, and methods to detect such manipulations. In\nparticular, four types of facial manipulation are reviewed: i) entire face\nsynthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv)\nexpression swap. For each manipulation group, we provide details regarding\nmanipulation techniques, existing public databases, and key benchmarks for\ntechnology evaluation of fake detection methods, including a summary of results\nfrom those evaluations. Among all the aspects discussed in the survey, we pay\nspecial attention to the latest generation of DeepFakes, highlighting its\nimprovements and challenges for fake detection.\n  In addition to the survey information, we also discuss open issues and future\ntrends that should be considered to advance in the field.'}, 'authors': [{'name': 'Ruben Tolosana'}, {'name': 'Ruben Vera-Rodriguez'}, {'name': 'Julian Fierrez'}, {'name': 'Aythami Morales'}, {'name': 'Javier Ortega-Garcia'}], 'author_detail': {'name': 'Javier Ortega-Garcia'}, 'author': 'Javier Ortega-Garcia', 'arxiv_journal_ref': 'Information Fusion, 2020', 'links': [{'href': 'http://arxiv.org/abs/2001.00179v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.00179v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
258,http://arxiv.org/abs/1912.12520v2,2020-01-20 03:03:09+00:00,2019-12-28 21:20:25+00:00,Weak Supervision for Fake News Detection via Reinforcement Learning,"[arxiv.Result.Author('Yaqing Wang'), arxiv.Result.Author('Weifeng Yang'), arxiv.Result.Author('Fenglong Ma'), arxiv.Result.Author('Jin Xu'), arxiv.Result.Author('Bin Zhong'), arxiv.Result.Author('Qiang Deng'), arxiv.Result.Author('Jing Gao')]","Today social media has become the primary source for news. Via social media
platforms, fake news travel at unprecedented speeds, reach global audiences and
put users and communities at great risk. Therefore, it is extremely important
to detect fake news as early as possible. Recently, deep learning based
approaches have shown improved performance in fake news detection. However, the
training of such models requires a large amount of labeled data, but manual
annotation is time-consuming and expensive. Moreover, due to the dynamic nature
of news, annotated samples may become outdated quickly and cannot represent the
news articles on newly emerged events. Therefore, how to obtain fresh and
high-quality labeled samples is the major challenge in employing deep learning
models for fake news detection. In order to tackle this challenge, we propose a
reinforced weakly-supervised fake news detection framework, i.e., WeFEND, which
can leverage users' reports as weak supervision to enlarge the amount of
training data for fake news detection. The proposed framework consists of three
main components: the annotator, the reinforced selector and the fake news
detector. The annotator can automatically assign weak labels for unlabeled news
based on users' reports. The reinforced selector using reinforcement learning
techniques chooses high-quality samples from the weakly labeled data and
filters out those low-quality ones that may degrade the detector's prediction
performance. The fake news detector aims to identify fake news based on the
news content. We tested the proposed framework on a large collection of news
articles published via WeChat official accounts and associated user reports.
Extensive experiments on this dataset show that the proposed WeFEND model
achieves the best performance compared with the state-of-the-art methods.",AAAI 2020,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1912.12520v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.12520v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.12520v2,"{'id': 'http://arxiv.org/abs/1912.12520v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.12520v2', 'updated': '2020-01-20T03:03:09Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=20, tm_hour=3, tm_min=3, tm_sec=9, tm_wday=0, tm_yday=20, tm_isdst=0), 'published': '2019-12-28T21:20:25Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=28, tm_hour=21, tm_min=20, tm_sec=25, tm_wday=5, tm_yday=362, tm_isdst=0), 'title': 'Weak Supervision for Fake News Detection via Reinforcement Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Weak Supervision for Fake News Detection via Reinforcement Learning'}, 'summary': ""Today social media has become the primary source for news. Via social media\nplatforms, fake news travel at unprecedented speeds, reach global audiences and\nput users and communities at great risk. Therefore, it is extremely important\nto detect fake news as early as possible. Recently, deep learning based\napproaches have shown improved performance in fake news detection. However, the\ntraining of such models requires a large amount of labeled data, but manual\nannotation is time-consuming and expensive. Moreover, due to the dynamic nature\nof news, annotated samples may become outdated quickly and cannot represent the\nnews articles on newly emerged events. Therefore, how to obtain fresh and\nhigh-quality labeled samples is the major challenge in employing deep learning\nmodels for fake news detection. In order to tackle this challenge, we propose a\nreinforced weakly-supervised fake news detection framework, i.e., WeFEND, which\ncan leverage users' reports as weak supervision to enlarge the amount of\ntraining data for fake news detection. The proposed framework consists of three\nmain components: the annotator, the reinforced selector and the fake news\ndetector. The annotator can automatically assign weak labels for unlabeled news\nbased on users' reports. The reinforced selector using reinforcement learning\ntechniques chooses high-quality samples from the weakly labeled data and\nfilters out those low-quality ones that may degrade the detector's prediction\nperformance. The fake news detector aims to identify fake news based on the\nnews content. We tested the proposed framework on a large collection of news\narticles published via WeChat official accounts and associated user reports.\nExtensive experiments on this dataset show that the proposed WeFEND model\nachieves the best performance compared with the state-of-the-art methods."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Today social media has become the primary source for news. Via social media\nplatforms, fake news travel at unprecedented speeds, reach global audiences and\nput users and communities at great risk. Therefore, it is extremely important\nto detect fake news as early as possible. Recently, deep learning based\napproaches have shown improved performance in fake news detection. However, the\ntraining of such models requires a large amount of labeled data, but manual\nannotation is time-consuming and expensive. Moreover, due to the dynamic nature\nof news, annotated samples may become outdated quickly and cannot represent the\nnews articles on newly emerged events. Therefore, how to obtain fresh and\nhigh-quality labeled samples is the major challenge in employing deep learning\nmodels for fake news detection. In order to tackle this challenge, we propose a\nreinforced weakly-supervised fake news detection framework, i.e., WeFEND, which\ncan leverage users' reports as weak supervision to enlarge the amount of\ntraining data for fake news detection. The proposed framework consists of three\nmain components: the annotator, the reinforced selector and the fake news\ndetector. The annotator can automatically assign weak labels for unlabeled news\nbased on users' reports. The reinforced selector using reinforcement learning\ntechniques chooses high-quality samples from the weakly labeled data and\nfilters out those low-quality ones that may degrade the detector's prediction\nperformance. The fake news detector aims to identify fake news based on the\nnews content. We tested the proposed framework on a large collection of news\narticles published via WeChat official accounts and associated user reports.\nExtensive experiments on this dataset show that the proposed WeFEND model\nachieves the best performance compared with the state-of-the-art methods.""}, 'authors': [{'name': 'Yaqing Wang'}, {'name': 'Weifeng Yang'}, {'name': 'Fenglong Ma'}, {'name': 'Jin Xu'}, {'name': 'Bin Zhong'}, {'name': 'Qiang Deng'}, {'name': 'Jing Gao'}], 'author_detail': {'name': 'Jing Gao'}, 'author': 'Jing Gao', 'arxiv_comment': 'AAAI 2020', 'links': [{'href': 'http://arxiv.org/abs/1912.12520v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.12520v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
259,http://arxiv.org/abs/1912.03211v1,2019-12-06 16:25:29+00:00,2019-12-06 16:25:29+00:00,Transitivity and degree assortativity explained: The bipartite structure of social networks,"[arxiv.Result.Author('Demival Vasques Filho'), arxiv.Result.Author(""Dion R. J. O'Neale"")]","Dynamical processes, such as the diffusion of knowledge, opinions, pathogens,
""fake news"", innovation, and others, are highly dependent on the structure of
the social network on which they occur. However, questions on why most social
networks present some particular structural features, namely high levels of
transitivity and degree assortativity, when compared to other types of networks
remain open. First, we argue that every one-mode network can be regarded as a
projection of a bipartite network, and show that this is the case using two
simple examples solved with the generating functions formalism. Second, using
synthetic and empirical data, we reveal how the combination of the degree
distribution of both sets of nodes of the bipartite network --- together with
the presence of cycles of length four and six --- explains the observed levels
of transitivity and degree assortativity in the one-mode projected network.
Bipartite networks with top node degrees that display a more right-skewed
distribution than the bottom nodes result in highly transitive and degree
assortative projections, especially if a large number of small cycles are
present in the bipartite structure.","9 pages, 6 figures","Phys. Rev. E 101, 052305 (2020)",10.1103/PhysRevE.101.052305,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevE.101.052305', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1912.03211v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.03211v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.03211v1,"{'id': 'http://arxiv.org/abs/1912.03211v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.03211v1', 'updated': '2019-12-06T16:25:29Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=6, tm_hour=16, tm_min=25, tm_sec=29, tm_wday=4, tm_yday=340, tm_isdst=0), 'published': '2019-12-06T16:25:29Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=6, tm_hour=16, tm_min=25, tm_sec=29, tm_wday=4, tm_yday=340, tm_isdst=0), 'title': 'Transitivity and degree assortativity explained: The bipartite structure\n  of social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transitivity and degree assortativity explained: The bipartite structure\n  of social networks'}, 'summary': 'Dynamical processes, such as the diffusion of knowledge, opinions, pathogens,\n""fake news"", innovation, and others, are highly dependent on the structure of\nthe social network on which they occur. However, questions on why most social\nnetworks present some particular structural features, namely high levels of\ntransitivity and degree assortativity, when compared to other types of networks\nremain open. First, we argue that every one-mode network can be regarded as a\nprojection of a bipartite network, and show that this is the case using two\nsimple examples solved with the generating functions formalism. Second, using\nsynthetic and empirical data, we reveal how the combination of the degree\ndistribution of both sets of nodes of the bipartite network --- together with\nthe presence of cycles of length four and six --- explains the observed levels\nof transitivity and degree assortativity in the one-mode projected network.\nBipartite networks with top node degrees that display a more right-skewed\ndistribution than the bottom nodes result in highly transitive and degree\nassortative projections, especially if a large number of small cycles are\npresent in the bipartite structure.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Dynamical processes, such as the diffusion of knowledge, opinions, pathogens,\n""fake news"", innovation, and others, are highly dependent on the structure of\nthe social network on which they occur. However, questions on why most social\nnetworks present some particular structural features, namely high levels of\ntransitivity and degree assortativity, when compared to other types of networks\nremain open. First, we argue that every one-mode network can be regarded as a\nprojection of a bipartite network, and show that this is the case using two\nsimple examples solved with the generating functions formalism. Second, using\nsynthetic and empirical data, we reveal how the combination of the degree\ndistribution of both sets of nodes of the bipartite network --- together with\nthe presence of cycles of length four and six --- explains the observed levels\nof transitivity and degree assortativity in the one-mode projected network.\nBipartite networks with top node degrees that display a more right-skewed\ndistribution than the bottom nodes result in highly transitive and degree\nassortative projections, especially if a large number of small cycles are\npresent in the bipartite structure.'}, 'authors': [{'name': 'Demival Vasques Filho'}, {'name': ""Dion R. J. O'Neale""}], 'author_detail': {'name': ""Dion R. J. O'Neale""}, 'author': ""Dion R. J. O'Neale"", 'arxiv_doi': '10.1103/PhysRevE.101.052305', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevE.101.052305', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1912.03211v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.03211v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '9 pages, 6 figures', 'arxiv_journal_ref': 'Phys. Rev. E 101, 052305 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
260,http://arxiv.org/abs/1911.12069v2,2021-04-22 09:51:53+00:00,2019-11-27 10:41:19+00:00,SpoC: Spoofing Camera Fingerprints,"[arxiv.Result.Author('Davide Cozzolino'), arxiv.Result.Author('Justus Thies'), arxiv.Result.Author('Andreas Rössler'), arxiv.Result.Author('Matthias Nießner'), arxiv.Result.Author('Luisa Verdoliva')]","Thanks to the fast progress in synthetic media generation, creating realistic
false images has become very easy. Such images can be used to wrap ""rich"" fake
news with enhanced credibility, spawning a new wave of high-impact, high-risk
misinformation campaigns. Therefore, there is a fast-growing interest in
reliable detectors of manipulated media. The most powerful detectors, to date,
rely on the subtle traces left by any device on all images acquired by it. In
particular, due to proprietary in-camera processes, like demosaicing or
compression, each camera model leaves trademark traces that can be exploited
for forensic analyses. The absence or distortion of such traces in the target
image is a strong hint of manipulation. In this paper, we challenge such
detectors to gain better insight into their vulnerabilities. This is an
important study in order to build better forgery detectors able to face
malicious attacks. Our proposal consists of a GAN-based approach that injects
camera traces into synthetic images. Given a GAN-generated image, we insert the
traces of a specific camera model into it and deceive state-of-the-art
detectors into believing the image was acquired by that model. Likewise, we
deceive independent detectors of synthetic GAN images into believing the image
is real. Experiments prove the effectiveness of the proposed method in a wide
array of conditions. Moreover, no prior information on the attacked detectors
is needed, but only sample images from the target camera.",,,,cs.CV,"['cs.CV', 'cs.CR', 'cs.LG', 'eess.IV']","[arxiv.Result.Link('http://arxiv.org/abs/1911.12069v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.12069v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.12069v2,"{'id': 'http://arxiv.org/abs/1911.12069v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.12069v2', 'updated': '2021-04-22T09:51:53Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=22, tm_hour=9, tm_min=51, tm_sec=53, tm_wday=3, tm_yday=112, tm_isdst=0), 'published': '2019-11-27T10:41:19Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=10, tm_min=41, tm_sec=19, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'SpoC: Spoofing Camera Fingerprints', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SpoC: Spoofing Camera Fingerprints'}, 'summary': 'Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap ""rich"" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap ""rich"" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.'}, 'authors': [{'name': 'Davide Cozzolino'}, {'name': 'Justus Thies'}, {'name': 'Andreas Rössler'}, {'name': 'Matthias Nießner'}, {'name': 'Luisa Verdoliva'}], 'author_detail': {'name': 'Luisa Verdoliva'}, 'author': 'Luisa Verdoliva', 'links': [{'href': 'http://arxiv.org/abs/1911.12069v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.12069v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
261,http://arxiv.org/abs/1911.12039v1,2019-11-27 09:22:51+00:00,2019-11-27 09:22:51+00:00,The Limited Reach of Fake News on Twitter during 2019 European Elections,"[arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Stefano Cresci'), arxiv.Result.Author('Alessandro Galeazzi'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Maurizio Tesconi')]","The advent of social media changed the way we consume content favoring a
disintermediated access and production. This scenario has been matter of
critical discussion about its impact on society. Magnified in the case of Arab
Spring or heavily criticized in the Brexit and 2016 U.S. elections. In this
work we explore information consumption on Twitter during the last European
electoral campaign by analyzing the interaction patterns of official news
sources, fake news sources, politicians, people from the showbiz and many
others. We extensively explore interactions among different classes of accounts
in the months preceding the last European elections, held between 23rd and 26th
of May, 2019. We collected almost 400,000 tweets posted by 863 accounts having
different roles in the public society. Through a thorough quantitative analysis
we investigate the information flow among them, also exploiting geolocalized
information. Accounts show the tendency to confine their interaction within the
same class and the debate rarely crosses national borders. Moreover, we do not
find any evidence of an organized network of accounts aimed at spreading
disinformation. Instead, disinformation outlets are largely ignored by the
other actors and hence play a peripheral role in online political discussions.",,"PLoS ONE 15(6): e0234689, 2020",10.1371/journal.pone.0234689,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0234689', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1911.12039v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.12039v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.12039v1,"{'id': 'http://arxiv.org/abs/1911.12039v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.12039v1', 'updated': '2019-11-27T09:22:51Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=9, tm_min=22, tm_sec=51, tm_wday=2, tm_yday=331, tm_isdst=0), 'published': '2019-11-27T09:22:51Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=9, tm_min=22, tm_sec=51, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'The Limited Reach of Fake News on Twitter during 2019 European Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Limited Reach of Fake News on Twitter during 2019 European Elections'}, 'summary': 'The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.'}, 'authors': [{'name': 'Matteo Cinelli'}, {'name': 'Stefano Cresci'}, {'name': 'Alessandro Galeazzi'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Maurizio Tesconi'}], 'author_detail': {'name': 'Maurizio Tesconi'}, 'author': 'Maurizio Tesconi', 'arxiv_doi': '10.1371/journal.pone.0234689', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0234689', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1911.12039v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.12039v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'PLoS ONE 15(6): e0234689, 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
262,http://arxiv.org/abs/1911.11951v1,2019-11-27 04:52:53+00:00,2019-11-27 04:52:53+00:00,Taking a Stance on Fake News: Towards Automatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance Detection,"[arxiv.Result.Author('Chris Dulhanty'), arxiv.Result.Author('Jason L. Deglint'), arxiv.Result.Author('Ibrahim Ben Daya'), arxiv.Result.Author('Alexander Wong')]","The exponential rise of social media and digital news in the past decade has
had the unfortunate consequence of escalating what the United Nations has
called a global topic of concern: the growing prevalence of disinformation.
Given the complexity and time-consuming nature of combating disinformation
through human assessment, one is motivated to explore harnessing AI solutions
to automatically assess news articles for the presence of disinformation. A
valuable first step towards automatic identification of disinformation is
stance detection, where given a claim and a news article, the aim is to predict
if the article agrees, disagrees, takes no position, or is unrelated to the
claim. Existing approaches in literature have largely relied on hand-engineered
features or shallow learned representations (e.g., word embeddings) to encode
the claim-article pairs, which can limit the level of representational
expressiveness needed to tackle the high complexity of disinformation
identification. In this work, we explore the notion of harnessing large-scale
deep bidirectional transformer language models for encoding claim-article pairs
in an effort to construct state-of-the-art stance detection geared for
identifying disinformation. Taking advantage of bidirectional cross-attention
between claim-article pairs via pair encoding with self-attention, we construct
a large-scale language model for stance detection by performing transfer
learning on a RoBERTa deep bidirectional transformer language model, and were
able to achieve state-of-the-art performance (weighted accuracy of 90.01%) on
the Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results
serve as motivation for harnessing such large-scale language models as powerful
building blocks for creating effective AI solutions to combat disinformation.",Accepted to the AI for Social Good Workshop at NeurIPS 2019,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1911.11951v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.11951v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.11951v1,"{'id': 'http://arxiv.org/abs/1911.11951v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.11951v1', 'updated': '2019-11-27T04:52:53Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=4, tm_min=52, tm_sec=53, tm_wday=2, tm_yday=331, tm_isdst=0), 'published': '2019-11-27T04:52:53Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=4, tm_min=52, tm_sec=53, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection'}, 'summary': 'The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.'}, 'authors': [{'name': 'Chris Dulhanty'}, {'name': 'Jason L. Deglint'}, {'name': 'Ibrahim Ben Daya'}, {'name': 'Alexander Wong'}], 'author_detail': {'name': 'Alexander Wong'}, 'author': 'Alexander Wong', 'arxiv_comment': 'Accepted to the AI for Social Good Workshop at NeurIPS 2019', 'links': [{'href': 'http://arxiv.org/abs/1911.11951v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.11951v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
263,http://arxiv.org/abs/1911.11920v1,2019-11-27 02:33:24+00:00,2019-11-27 02:33:24+00:00,Warning Signs in Communicating the Machine Learning Detection Results of Misinformation with Individuals,[arxiv.Result.Author('Limeng Cui')],"With the prevalence of misinformation online, researchers have focused on
developing various machine learning algorithms to detect fake news. However,
users' perception of machine learning outcomes and related behaviors have been
widely ignored. Hence, this paper proposed to bridge this gap by studying how
to pass the detection results of machine learning to the users, and aid their
decisions in handling misinformation. An online experiment was conducted, to
evaluate the effect of the proposed machine learning warning sign against a
control condition. We examined participants' detection and sharing of news. The
data showed that warning sign's effects on participants' trust toward the fake
news were not significant. However, we found that people's uncertainty about
the authenticity of the news dropped with the presence of the machine learning
warning sign. We also found that social media experience had effects on users'
trust toward the fake news, and age and social media experience had effects on
users' sharing decision. Therefore, the results indicate that there are many
factors worth studying that affect people's trust in the news. Moreover, the
warning sign in communicating machine learning detection results is different
from ordinary warnings and needs more detailed research and design. These
findings hold important implications for the design of machine learning
warnings.",,,,cs.HC,"['cs.HC', 'H.5.2']","[arxiv.Result.Link('http://arxiv.org/abs/1911.11920v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.11920v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.11920v1,"{'id': 'http://arxiv.org/abs/1911.11920v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.11920v1', 'updated': '2019-11-27T02:33:24Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=2, tm_min=33, tm_sec=24, tm_wday=2, tm_yday=331, tm_isdst=0), 'published': '2019-11-27T02:33:24Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=2, tm_min=33, tm_sec=24, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals'}, 'summary': ""With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.""}, 'authors': [{'name': 'Limeng Cui'}], 'author_detail': {'name': 'Limeng Cui'}, 'author': 'Limeng Cui', 'links': [{'href': 'http://arxiv.org/abs/1911.11920v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.11920v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
264,http://arxiv.org/abs/1911.10130v1,2019-11-22 16:35:37+00:00,2019-11-22 16:35:37+00:00,A Data Set of Internet Claims and Comparison of their Sentiments with Credibility,"[arxiv.Result.Author('Amey Parundekar'), arxiv.Result.Author('Susan Elias'), arxiv.Result.Author('Ashwin Ashok')]","In this modern era, communication has become faster and easier. This means
fallacious information can spread as fast as reality. Considering the damage
that fake news kindles on the psychology of people and the fact that such news
proliferates faster than truth, we need to study the phenomenon that helps
spread fake news. An unbiased data set that depends on reality for rating news
is necessary to construct predictive models for its classification. This paper
describes the methodology to create such a data set. We collect our data from
snopes.com which is a fact-checking organization. Furthermore, we intend to
create this data set not only for classification of the news but also to find
patterns that reason the intent behind misinformation. We also formally define
an Internet Claim, its credibility, and the sentiment behind such a claim. We
try to realize the relationship between the sentiment of a claim with its
credibility. This relationship pours light on the bigger picture behind the
propagation of misinformation. We pave the way for further research based on
the methodology described in this paper to create the data set and usage of
predictive modeling along with research-based on psychology/mentality of people
to understand why fake news spreads much faster than reality.","8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact
  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,
  Alaska",,,cs.IR,"['cs.IR', 'cs.CL', 'H.3.3, I.2.7', 'H.3.3; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1911.10130v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.10130v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.10130v1,"{'id': 'http://arxiv.org/abs/1911.10130v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.10130v1', 'updated': '2019-11-22T16:35:37Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=22, tm_hour=16, tm_min=35, tm_sec=37, tm_wday=4, tm_yday=326, tm_isdst=0), 'published': '2019-11-22T16:35:37Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=22, tm_hour=16, tm_min=35, tm_sec=37, tm_wday=4, tm_yday=326, tm_isdst=0), 'title': 'A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility'}, 'summary': 'In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.'}, 'authors': [{'name': 'Amey Parundekar'}, {'name': 'Susan Elias'}, {'name': 'Ashwin Ashok'}], 'author_detail': {'name': 'Ashwin Ashok'}, 'author': 'Ashwin Ashok', 'arxiv_comment': '8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact\n  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,\n  Alaska', 'links': [{'href': 'http://arxiv.org/abs/1911.10130v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.10130v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.3, I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.3; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
265,http://arxiv.org/abs/1911.08516v1,2019-11-19 19:24:07+00:00,2019-11-19 19:24:07+00:00,Sieving Fake News From Genuine: A Synopsis,"[arxiv.Result.Author('Shahid Alam'), arxiv.Result.Author('Abdulaziz Ravshanbekov')]","With the rise of social media, it has become easier to disseminate fake news
faster and cheaper, compared to traditional news media, such as television and
newspapers. Recently this phenomenon has attracted lot of public attention,
because it is causing significant social and financial impacts on their lives
and businesses. Fake news are responsible for creating false, deceptive,
misleading, and suspicious information that can greatly effect the outcome of
an event. This paper presents a synopsis that explains what are fake news with
examples and also discusses some of the current machine learning techniques,
specifically natural language processing (NLP) and deep learning, for
automatically predicting and detecting fake news. Based on this synopsis, we
recommend that there is a potential of using NLP and deep learning to improve
automatic detection of fake news, but with the right set of data and features.","Published in the Proceedings of the International Conference on All
  Aspects of Cyber Security 2019, pp: 67-71",,,cs.CR,"['cs.CR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1911.08516v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.08516v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.08516v1,"{'id': 'http://arxiv.org/abs/1911.08516v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.08516v1', 'updated': '2019-11-19T19:24:07Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=19, tm_hour=19, tm_min=24, tm_sec=7, tm_wday=1, tm_yday=323, tm_isdst=0), 'published': '2019-11-19T19:24:07Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=19, tm_hour=19, tm_min=24, tm_sec=7, tm_wday=1, tm_yday=323, tm_isdst=0), 'title': 'Sieving Fake News From Genuine: A Synopsis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sieving Fake News From Genuine: A Synopsis'}, 'summary': 'With the rise of social media, it has become easier to disseminate fake news\nfaster and cheaper, compared to traditional news media, such as television and\nnewspapers. Recently this phenomenon has attracted lot of public attention,\nbecause it is causing significant social and financial impacts on their lives\nand businesses. Fake news are responsible for creating false, deceptive,\nmisleading, and suspicious information that can greatly effect the outcome of\nan event. This paper presents a synopsis that explains what are fake news with\nexamples and also discusses some of the current machine learning techniques,\nspecifically natural language processing (NLP) and deep learning, for\nautomatically predicting and detecting fake news. Based on this synopsis, we\nrecommend that there is a potential of using NLP and deep learning to improve\nautomatic detection of fake news, but with the right set of data and features.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the rise of social media, it has become easier to disseminate fake news\nfaster and cheaper, compared to traditional news media, such as television and\nnewspapers. Recently this phenomenon has attracted lot of public attention,\nbecause it is causing significant social and financial impacts on their lives\nand businesses. Fake news are responsible for creating false, deceptive,\nmisleading, and suspicious information that can greatly effect the outcome of\nan event. This paper presents a synopsis that explains what are fake news with\nexamples and also discusses some of the current machine learning techniques,\nspecifically natural language processing (NLP) and deep learning, for\nautomatically predicting and detecting fake news. Based on this synopsis, we\nrecommend that there is a potential of using NLP and deep learning to improve\nautomatic detection of fake news, but with the right set of data and features.'}, 'authors': [{'name': 'Shahid Alam'}, {'name': 'Abdulaziz Ravshanbekov'}], 'author_detail': {'name': 'Abdulaziz Ravshanbekov'}, 'author': 'Abdulaziz Ravshanbekov', 'arxiv_comment': 'Published in the Proceedings of the International Conference on All\n  Aspects of Cyber Security 2019, pp: 67-71', 'links': [{'href': 'http://arxiv.org/abs/1911.08516v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.08516v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
266,http://arxiv.org/abs/1911.08125v1,2019-11-19 07:06:22+00:00,2019-11-19 07:06:22+00:00,In Search of Credible News,"[arxiv.Result.Author('Momchil Hardalov'), arxiv.Result.Author('Ivan Koychev'), arxiv.Result.Author('Preslav Nakov')]","We study the problem of finding fake online news. This is an important
problem as news of questionable credibility have recently been proliferating in
social media at an alarming scale. As this is an understudied problem,
especially for languages other than English, we first collect and release to
the research community three new balanced credible vs. fake news datasets
derived from four online sources. We then propose a language-independent
approach for automatically distinguishing credible from fake news, based on a
rich feature set. In particular, we use linguistic (n-gram),
credibility-related (capitalization, punctuation, pronoun use, sentiment
polarity), and semantic (embeddings and DBPedia data) features. Our experiments
on three different testsets show that our model can distinguish credible from
fake news with very high accuracy.","Credibility, veracity, fact checking, humor detection",AIMSA-2016,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1911.08125v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.08125v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.08125v1,"{'id': 'http://arxiv.org/abs/1911.08125v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.08125v1', 'updated': '2019-11-19T07:06:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=19, tm_hour=7, tm_min=6, tm_sec=22, tm_wday=1, tm_yday=323, tm_isdst=0), 'published': '2019-11-19T07:06:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=19, tm_hour=7, tm_min=6, tm_sec=22, tm_wday=1, tm_yday=323, tm_isdst=0), 'title': 'In Search of Credible News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In Search of Credible News'}, 'summary': 'We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.'}, 'authors': [{'name': 'Momchil Hardalov'}, {'name': 'Ivan Koychev'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Credibility, veracity, fact checking, humor detection', 'arxiv_journal_ref': 'AIMSA-2016', 'links': [{'href': 'http://arxiv.org/abs/1911.08125v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.08125v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
267,http://arxiv.org/abs/1911.07199v1,2019-11-17 09:40:24+00:00,2019-11-17 09:40:24+00:00,"Rumor Detection on Social Media: Datasets, Methods and Opportunities","[arxiv.Result.Author('Quanzhi Li'), arxiv.Result.Author('Qiong Zhang'), arxiv.Result.Author('Luo Si'), arxiv.Result.Author('Yingchi Liu')]","Social media platforms have been used for information and news gathering, and
they are very valuable in many applications. However, they also lead to the
spreading of rumors and fake news. Many efforts have been taken to detect and
debunk rumors on social media by analyzing their content and social context
using machine learning techniques. This paper gives an overview of the recent
studies in the rumor detection field. It provides a comprehensive list of
datasets used for rumor detection, and reviews the important studies based on
what types of information they exploit and the approaches they take. And more
importantly, we also present several new directions for future research.",10 pages,EMNLP 2019,,cs.IR,"['cs.IR', 'cs.CL', 'cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1911.07199v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.07199v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.07199v1,"{'id': 'http://arxiv.org/abs/1911.07199v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.07199v1', 'updated': '2019-11-17T09:40:24Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=17, tm_hour=9, tm_min=40, tm_sec=24, tm_wday=6, tm_yday=321, tm_isdst=0), 'published': '2019-11-17T09:40:24Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=17, tm_hour=9, tm_min=40, tm_sec=24, tm_wday=6, tm_yday=321, tm_isdst=0), 'title': 'Rumor Detection on Social Media: Datasets, Methods and Opportunities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Rumor Detection on Social Media: Datasets, Methods and Opportunities'}, 'summary': 'Social media platforms have been used for information and news gathering, and\nthey are very valuable in many applications. However, they also lead to the\nspreading of rumors and fake news. Many efforts have been taken to detect and\ndebunk rumors on social media by analyzing their content and social context\nusing machine learning techniques. This paper gives an overview of the recent\nstudies in the rumor detection field. It provides a comprehensive list of\ndatasets used for rumor detection, and reviews the important studies based on\nwhat types of information they exploit and the approaches they take. And more\nimportantly, we also present several new directions for future research.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media platforms have been used for information and news gathering, and\nthey are very valuable in many applications. However, they also lead to the\nspreading of rumors and fake news. Many efforts have been taken to detect and\ndebunk rumors on social media by analyzing their content and social context\nusing machine learning techniques. This paper gives an overview of the recent\nstudies in the rumor detection field. It provides a comprehensive list of\ndatasets used for rumor detection, and reviews the important studies based on\nwhat types of information they exploit and the approaches they take. And more\nimportantly, we also present several new directions for future research.'}, 'authors': [{'name': 'Quanzhi Li'}, {'name': 'Qiong Zhang'}, {'name': 'Luo Si'}, {'name': 'Yingchi Liu'}], 'author_detail': {'name': 'Yingchi Liu'}, 'author': 'Yingchi Liu', 'arxiv_comment': '10 pages', 'arxiv_journal_ref': 'EMNLP 2019', 'links': [{'href': 'http://arxiv.org/abs/1911.07199v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.07199v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
268,http://arxiv.org/abs/1911.05885v1,2019-11-14 01:36:05+00:00,2019-11-14 01:36:05+00:00,Deception through Half-Truths,"[arxiv.Result.Author('Andrew Estornell'), arxiv.Result.Author('Sanmay Das'), arxiv.Result.Author('Yevgeniy Vorobeychik')]","Deception is a fundamental issue across a diverse array of settings, from
cybersecurity, where decoys (e.g., honeypots) are an important tool, to
politics that can feature politically motivated ""leaks"" and fake news about
candidates.Typical considerations of deception view it as providing false
information.However, just as important but less frequently studied is a more
tacit form where information is strategically hidden or leaked.We consider the
problem of how much an adversary can affect a principal's decision by
""half-truths"", that is, by masking or hiding bits of information, when the
principal is oblivious to the presence of the adversary. The principal's
problem can be modeled as one of predicting future states of variables in a
dynamic Bayes network, and we show that, while theoretically the principal's
decisions can be made arbitrarily bad, the optimal attack is NP-hard to
approximate, even under strong assumptions favoring the attacker. However, we
also describe an important special case where the dependency of future states
on past states is additive, in which we can efficiently compute an
approximately optimal attack. Moreover, in networks with a linear transition
function we can solve the problem optimally in polynomial time.",,,,cs.AI,"['cs.AI', 'cs.MA']","[arxiv.Result.Link('http://arxiv.org/abs/1911.05885v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.05885v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.05885v1,"{'id': 'http://arxiv.org/abs/1911.05885v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.05885v1', 'updated': '2019-11-14T01:36:05Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=14, tm_hour=1, tm_min=36, tm_sec=5, tm_wday=3, tm_yday=318, tm_isdst=0), 'published': '2019-11-14T01:36:05Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=14, tm_hour=1, tm_min=36, tm_sec=5, tm_wday=3, tm_yday=318, tm_isdst=0), 'title': 'Deception through Half-Truths', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deception through Half-Truths'}, 'summary': 'Deception is a fundamental issue across a diverse array of settings, from\ncybersecurity, where decoys (e.g., honeypots) are an important tool, to\npolitics that can feature politically motivated ""leaks"" and fake news about\ncandidates.Typical considerations of deception view it as providing false\ninformation.However, just as important but less frequently studied is a more\ntacit form where information is strategically hidden or leaked.We consider the\nproblem of how much an adversary can affect a principal\'s decision by\n""half-truths"", that is, by masking or hiding bits of information, when the\nprincipal is oblivious to the presence of the adversary. The principal\'s\nproblem can be modeled as one of predicting future states of variables in a\ndynamic Bayes network, and we show that, while theoretically the principal\'s\ndecisions can be made arbitrarily bad, the optimal attack is NP-hard to\napproximate, even under strong assumptions favoring the attacker. However, we\nalso describe an important special case where the dependency of future states\non past states is additive, in which we can efficiently compute an\napproximately optimal attack. Moreover, in networks with a linear transition\nfunction we can solve the problem optimally in polynomial time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deception is a fundamental issue across a diverse array of settings, from\ncybersecurity, where decoys (e.g., honeypots) are an important tool, to\npolitics that can feature politically motivated ""leaks"" and fake news about\ncandidates.Typical considerations of deception view it as providing false\ninformation.However, just as important but less frequently studied is a more\ntacit form where information is strategically hidden or leaked.We consider the\nproblem of how much an adversary can affect a principal\'s decision by\n""half-truths"", that is, by masking or hiding bits of information, when the\nprincipal is oblivious to the presence of the adversary. The principal\'s\nproblem can be modeled as one of predicting future states of variables in a\ndynamic Bayes network, and we show that, while theoretically the principal\'s\ndecisions can be made arbitrarily bad, the optimal attack is NP-hard to\napproximate, even under strong assumptions favoring the attacker. However, we\nalso describe an important special case where the dependency of future states\non past states is additive, in which we can efficiently compute an\napproximately optimal attack. Moreover, in networks with a linear transition\nfunction we can solve the problem optimally in polynomial time.'}, 'authors': [{'name': 'Andrew Estornell'}, {'name': 'Sanmay Das'}, {'name': 'Yevgeniy Vorobeychik'}], 'author_detail': {'name': 'Yevgeniy Vorobeychik'}, 'author': 'Yevgeniy Vorobeychik', 'links': [{'href': 'http://arxiv.org/abs/1911.05885v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.05885v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
269,http://arxiv.org/abs/1911.11067v1,2019-11-11 08:30:54+00:00,2019-11-11 08:30:54+00:00,Analysing Russian Trolls via NLP tools,[arxiv.Result.Author('Bokun Kong')],"The fifty-eighth American presidential election in 2016 still arouse fierce
controversyat present. A portion of politicians as well as medium and voters
believe that theRussian government interfered with the election of 2016 by
controlling malicioussocial media accounts on twitter, such as trolls and bots
accounts. Both of them willbroadcast fake news, derail the conversations about
election, and mislead people.Therefore, this paper will focus on analysing some
of the twitter dataset about theelection of 2016 by using NLP methods and
looking for some interesting patterns ofwhether the Russian government
interfered with the election or not. We apply topicmodel on the given twitter
dataset to extract some interesting topics and analysethe meaning, then we
implement supervised topic model to retrieve the relationshipbetween topics to
category which is left troll or right troll, and analyse the
pattern.Additionally, we will do sentiment analysis to analyse the attitude of
the tweet. Afterextracting typical tweets from interesting topic, sentiment
analysis offers the ability toknow whether the tweet supports this topic or
not. Based on comprehensive analysisand evaluation, we find interesting
patterns of the dataset as well as some meaningfultopics.","53 pages, 8 figures, 16 tables",,,cs.IR,"['cs.IR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1911.11067v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.11067v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.11067v1,"{'id': 'http://arxiv.org/abs/1911.11067v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.11067v1', 'updated': '2019-11-11T08:30:54Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=11, tm_hour=8, tm_min=30, tm_sec=54, tm_wday=0, tm_yday=315, tm_isdst=0), 'published': '2019-11-11T08:30:54Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=11, tm_hour=8, tm_min=30, tm_sec=54, tm_wday=0, tm_yday=315, tm_isdst=0), 'title': 'Analysing Russian Trolls via NLP tools', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysing Russian Trolls via NLP tools'}, 'summary': 'The fifty-eighth American presidential election in 2016 still arouse fierce\ncontroversyat present. A portion of politicians as well as medium and voters\nbelieve that theRussian government interfered with the election of 2016 by\ncontrolling malicioussocial media accounts on twitter, such as trolls and bots\naccounts. Both of them willbroadcast fake news, derail the conversations about\nelection, and mislead people.Therefore, this paper will focus on analysing some\nof the twitter dataset about theelection of 2016 by using NLP methods and\nlooking for some interesting patterns ofwhether the Russian government\ninterfered with the election or not. We apply topicmodel on the given twitter\ndataset to extract some interesting topics and analysethe meaning, then we\nimplement supervised topic model to retrieve the relationshipbetween topics to\ncategory which is left troll or right troll, and analyse the\npattern.Additionally, we will do sentiment analysis to analyse the attitude of\nthe tweet. Afterextracting typical tweets from interesting topic, sentiment\nanalysis offers the ability toknow whether the tweet supports this topic or\nnot. Based on comprehensive analysisand evaluation, we find interesting\npatterns of the dataset as well as some meaningfultopics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The fifty-eighth American presidential election in 2016 still arouse fierce\ncontroversyat present. A portion of politicians as well as medium and voters\nbelieve that theRussian government interfered with the election of 2016 by\ncontrolling malicioussocial media accounts on twitter, such as trolls and bots\naccounts. Both of them willbroadcast fake news, derail the conversations about\nelection, and mislead people.Therefore, this paper will focus on analysing some\nof the twitter dataset about theelection of 2016 by using NLP methods and\nlooking for some interesting patterns ofwhether the Russian government\ninterfered with the election or not. We apply topicmodel on the given twitter\ndataset to extract some interesting topics and analysethe meaning, then we\nimplement supervised topic model to retrieve the relationshipbetween topics to\ncategory which is left troll or right troll, and analyse the\npattern.Additionally, we will do sentiment analysis to analyse the attitude of\nthe tweet. Afterextracting typical tweets from interesting topic, sentiment\nanalysis offers the ability toknow whether the tweet supports this topic or\nnot. Based on comprehensive analysisand evaluation, we find interesting\npatterns of the dataset as well as some meaningfultopics.'}, 'authors': [{'name': 'Bokun Kong'}], 'author_detail': {'name': 'Bokun Kong'}, 'author': 'Bokun Kong', 'arxiv_comment': '53 pages, 8 figures, 16 tables', 'links': [{'href': 'http://arxiv.org/abs/1911.11067v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.11067v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
270,http://arxiv.org/abs/1911.03854v2,2020-03-12 17:55:57+00:00,2019-11-10 05:06:38+00:00,r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection,"[arxiv.Result.Author('Kai Nakamura'), arxiv.Result.Author('Sharon Levy'), arxiv.Result.Author('William Yang Wang')]","Fake news has altered society in negative ways in politics and culture. It
has adversely affected both online social network systems as well as offline
communities and conversations. Using automatic machine learning classification
models is an efficient way to combat the widespread dissemination of fake news.
However, a lack of effective, comprehensive datasets has been a problem for
fake news research and detection model development. Prior fake news datasets do
not provide multimodal text and image data, metadata, comment data, and
fine-grained fake news categorization at the scale and breadth of our dataset.
We present Fakeddit, a novel multimodal dataset consisting of over 1 million
samples from multiple categories of fake news. After being processed through
several stages of review, the samples are labeled according to 2-way, 3-way,
and 6-way classification categories through distant supervision. We construct
hybrid text+image models and perform extensive experiments for multiple
variations of classification, demonstrating the importance of the novel aspect
of multimodality and fine-grained classification unique to Fakeddit.",Accepted LREC 2020,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1911.03854v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.03854v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.03854v2,"{'id': 'http://arxiv.org/abs/1911.03854v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.03854v2', 'updated': '2020-03-12T17:55:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=12, tm_hour=17, tm_min=55, tm_sec=57, tm_wday=3, tm_yday=72, tm_isdst=0), 'published': '2019-11-10T05:06:38Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=10, tm_hour=5, tm_min=6, tm_sec=38, tm_wday=6, tm_yday=314, tm_isdst=0), 'title': 'r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake\n  News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake\n  News Detection'}, 'summary': 'Fake news has altered society in negative ways in politics and culture. It\nhas adversely affected both online social network systems as well as offline\ncommunities and conversations. Using automatic machine learning classification\nmodels is an efficient way to combat the widespread dissemination of fake news.\nHowever, a lack of effective, comprehensive datasets has been a problem for\nfake news research and detection model development. Prior fake news datasets do\nnot provide multimodal text and image data, metadata, comment data, and\nfine-grained fake news categorization at the scale and breadth of our dataset.\nWe present Fakeddit, a novel multimodal dataset consisting of over 1 million\nsamples from multiple categories of fake news. After being processed through\nseveral stages of review, the samples are labeled according to 2-way, 3-way,\nand 6-way classification categories through distant supervision. We construct\nhybrid text+image models and perform extensive experiments for multiple\nvariations of classification, demonstrating the importance of the novel aspect\nof multimodality and fine-grained classification unique to Fakeddit.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news has altered society in negative ways in politics and culture. It\nhas adversely affected both online social network systems as well as offline\ncommunities and conversations. Using automatic machine learning classification\nmodels is an efficient way to combat the widespread dissemination of fake news.\nHowever, a lack of effective, comprehensive datasets has been a problem for\nfake news research and detection model development. Prior fake news datasets do\nnot provide multimodal text and image data, metadata, comment data, and\nfine-grained fake news categorization at the scale and breadth of our dataset.\nWe present Fakeddit, a novel multimodal dataset consisting of over 1 million\nsamples from multiple categories of fake news. After being processed through\nseveral stages of review, the samples are labeled according to 2-way, 3-way,\nand 6-way classification categories through distant supervision. We construct\nhybrid text+image models and perform extensive experiments for multiple\nvariations of classification, demonstrating the importance of the novel aspect\nof multimodality and fine-grained classification unique to Fakeddit.'}, 'authors': [{'name': 'Kai Nakamura'}, {'name': 'Sharon Levy'}, {'name': 'William Yang Wang'}], 'author_detail': {'name': 'William Yang Wang'}, 'author': 'William Yang Wang', 'arxiv_comment': 'Accepted LREC 2020', 'links': [{'href': 'http://arxiv.org/abs/1911.03854v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.03854v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
271,http://arxiv.org/abs/1911.00643v1,2019-11-02 04:06:30+00:00,2019-11-02 04:06:30+00:00,Credibility-based Fake News Detection,"[arxiv.Result.Author('Niraj Sitaula'), arxiv.Result.Author('Chilukuri K. Mohan'), arxiv.Result.Author('Jennifer Grygiel'), arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Reza Zafarani')]","Fake news can significantly misinform people who often rely on online sources
and social media for their information. Current research on fake news detection
has mostly focused on analyzing fake news content and how it propagates on a
network of users. In this paper, we emphasize the detection of fake news by
assessing its credibility. By analyzing public fake news data, we show that
information on news sources (and authors) can be a strong indicator of
credibility. Our findings suggest that an author's history of association with
fake news, and the number of authors of a news article, can play a significant
role in detecting fake news. Our approach can help improve traditional fake
news detection methods, wherein content features are often used to detect fake
news.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1911.00643v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.00643v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.00643v1,"{'id': 'http://arxiv.org/abs/1911.00643v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.00643v1', 'updated': '2019-11-02T04:06:30Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=2, tm_hour=4, tm_min=6, tm_sec=30, tm_wday=5, tm_yday=306, tm_isdst=0), 'published': '2019-11-02T04:06:30Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=2, tm_hour=4, tm_min=6, tm_sec=30, tm_wday=5, tm_yday=306, tm_isdst=0), 'title': 'Credibility-based Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Credibility-based Fake News Detection'}, 'summary': ""Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.""}, 'authors': [{'name': 'Niraj Sitaula'}, {'name': 'Chilukuri K. Mohan'}, {'name': 'Jennifer Grygiel'}, {'name': 'Xinyi Zhou'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'links': [{'href': 'http://arxiv.org/abs/1911.00643v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.00643v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
272,http://arxiv.org/abs/1910.14353v1,2019-10-31 10:32:43+00:00,2019-10-31 10:32:43+00:00,Transfer Learning from Transformers to Fake News Challenge Stance Detection (FNC-1) Task,[arxiv.Result.Author('Valeriya Slovikovskaya')],"In this paper, we report improved results of the Fake News Challenge Stage 1
(FNC-1) stance detection task. This gain in performance is due to the
generalization power of large language models based on Transformer
architecture, invented, trained and publicly released over the last two years.
Specifically (1) we improved the FNC-1 best performing model adding BERT
sentence embedding of input sequences as a model feature, (2) we fine-tuned
BERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained
state-of-the-art results on FNC-1 task.","12 pages, 9 tables",,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1910.14353v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.14353v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.14353v1,"{'id': 'http://arxiv.org/abs/1910.14353v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.14353v1', 'updated': '2019-10-31T10:32:43Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=31, tm_hour=10, tm_min=32, tm_sec=43, tm_wday=3, tm_yday=304, tm_isdst=0), 'published': '2019-10-31T10:32:43Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=31, tm_hour=10, tm_min=32, tm_sec=43, tm_wday=3, tm_yday=304, tm_isdst=0), 'title': 'Transfer Learning from Transformers to Fake News Challenge Stance\n  Detection (FNC-1) Task', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transfer Learning from Transformers to Fake News Challenge Stance\n  Detection (FNC-1) Task'}, 'summary': 'In this paper, we report improved results of the Fake News Challenge Stage 1\n(FNC-1) stance detection task. This gain in performance is due to the\ngeneralization power of large language models based on Transformer\narchitecture, invented, trained and publicly released over the last two years.\nSpecifically (1) we improved the FNC-1 best performing model adding BERT\nsentence embedding of input sequences as a model feature, (2) we fine-tuned\nBERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained\nstate-of-the-art results on FNC-1 task.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we report improved results of the Fake News Challenge Stage 1\n(FNC-1) stance detection task. This gain in performance is due to the\ngeneralization power of large language models based on Transformer\narchitecture, invented, trained and publicly released over the last two years.\nSpecifically (1) we improved the FNC-1 best performing model adding BERT\nsentence embedding of input sequences as a model feature, (2) we fine-tuned\nBERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained\nstate-of-the-art results on FNC-1 task.'}, 'authors': [{'name': 'Valeriya Slovikovskaya'}], 'author_detail': {'name': 'Valeriya Slovikovskaya'}, 'author': 'Valeriya Slovikovskaya', 'arxiv_comment': '12 pages, 9 tables', 'links': [{'href': 'http://arxiv.org/abs/1910.14353v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.14353v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
273,http://arxiv.org/abs/1910.12203v1,2019-10-27 07:44:33+00:00,2019-10-27 07:44:33+00:00,Do Sentence Interactions Matter? Leveraging Sentence Level Representations for Fake News Classification,"[arxiv.Result.Author('Vaibhav Vaibhav'), arxiv.Result.Author('Raghuram Mandyam Annasamy'), arxiv.Result.Author('Eduard Hovy')]","The rising growth of fake news and misleading information through online
media outlets demands an automatic method for detecting such news articles. Of
the few limited works which differentiate between trusted vs other types of
news article (satire, propaganda, hoax), none of them model sentence
interactions within a document. We observe an interesting pattern in the way
sentences interact with each other across different kind of news articles. To
capture this kind of information for long news articles, we propose a graph
neural network-based model which does away with the need of feature engineering
for fine grained fake news classification. Through experiments, we show that
our proposed method beats strong neural baselines and achieves state-of-the-art
accuracy on existing datasets. Moreover, we establish the generalizability of
our model by evaluating its performance in out-of-domain scenarios. Code is
available at https://github.com/MysteryVaibhav/fake_news_semantics",Accepted at TextGraphs - EMNLP 2019,,,cs.CL,"['cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1910.12203v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.12203v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.12203v1,"{'id': 'http://arxiv.org/abs/1910.12203v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.12203v1', 'updated': '2019-10-27T07:44:33Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=27, tm_hour=7, tm_min=44, tm_sec=33, tm_wday=6, tm_yday=300, tm_isdst=0), 'published': '2019-10-27T07:44:33Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=27, tm_hour=7, tm_min=44, tm_sec=33, tm_wday=6, tm_yday=300, tm_isdst=0), 'title': 'Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification'}, 'summary': 'The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics'}, 'authors': [{'name': 'Vaibhav Vaibhav'}, {'name': 'Raghuram Mandyam Annasamy'}, {'name': 'Eduard Hovy'}], 'author_detail': {'name': 'Eduard Hovy'}, 'author': 'Eduard Hovy', 'arxiv_comment': 'Accepted at TextGraphs - EMNLP 2019', 'links': [{'href': 'http://arxiv.org/abs/1910.12203v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.12203v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
274,http://arxiv.org/abs/1910.12073v1,2019-10-26 14:29:37+00:00,2019-10-26 14:29:37+00:00,Disinformation Detection: A review of linguistic feature selection and classification models in news veracity assessments,[arxiv.Result.Author('Jillian Tompkins')],"Over the past couple of years, the topic of ""fake news"" and its influence
over people's opinions has become a growing cause for concern. Although the
spread of disinformation on the Internet is not a new phenomenon, the
widespread use of social media has exacerbated its effects, providing more
channels for dissemination and the potential to ""go viral."" Nowhere was this
more evident than during the 2016 United States Presidential Election. Although
the current of disinformation spread via trolls, bots, and hyperpartisan media
outlets likely reinforced existing biases rather than sway undecided voters,
the effects of this deluge of disinformation are by no means trivial. The
consequences range in severity from an overall distrust in news media, to an
ill-informed citizenry, and in extreme cases, provocation of violent action. It
is clear that human ability to discern lies from truth is flawed at best. As
such, greater attention has been given towards applying machine learning
approaches to detect deliberately deceptive news articles. This paper looks at
the work that has already been done in this area.",,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1910.12073v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.12073v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.12073v1,"{'id': 'http://arxiv.org/abs/1910.12073v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.12073v1', 'updated': '2019-10-26T14:29:37Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=26, tm_hour=14, tm_min=29, tm_sec=37, tm_wday=5, tm_yday=299, tm_isdst=0), 'published': '2019-10-26T14:29:37Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=26, tm_hour=14, tm_min=29, tm_sec=37, tm_wday=5, tm_yday=299, tm_isdst=0), 'title': 'Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments'}, 'summary': 'Over the past couple of years, the topic of ""fake news"" and its influence\nover people\'s opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to ""go viral."" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past couple of years, the topic of ""fake news"" and its influence\nover people\'s opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to ""go viral."" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.'}, 'authors': [{'name': 'Jillian Tompkins'}], 'author_detail': {'name': 'Jillian Tompkins'}, 'author': 'Jillian Tompkins', 'links': [{'href': 'http://arxiv.org/abs/1910.12073v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.12073v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
275,http://arxiv.org/abs/1910.11430v2,2020-05-26 23:13:25+00:00,2019-10-24 21:27:31+00:00,Detecting Fake News with Weak Social Supervision,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Ahmed Hassan Awadallah'), arxiv.Result.Author('Susan Dumais'), arxiv.Result.Author('Huan Liu')]","Limited labeled data is becoming the largest bottleneck for supervised
learning systems. This is especially the case for many real-world tasks where
large scale annotated examples are either too expensive to acquire or
unavailable due to privacy or data access constraints. Weak supervision has
shown to be a good means to mitigate the scarcity of annotated data by
leveraging weak labels or injecting constraints from heuristic rules and/or
external knowledge sources. Social media has little labeled data but possesses
unique characteristics that make it suitable for generating weak supervision,
resulting in a new type of weak supervision, i.e., weak social supervision. In
this article, we illustrate how various aspects of social media can be used to
generate weak social supervision. Specifically, we use the recent research on
fake news detection as the use case, where social engagements are abundant but
annotated examples are scarce, to show that weak social supervision is
effective when facing the little labeled data problem. This article opens the
door for learning with weak social supervision for other emerging tasks.","9 pages, 4 figures",IEEE Intelligent Systems 2020,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1910.11430v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.11430v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.11430v2,"{'id': 'http://arxiv.org/abs/1910.11430v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.11430v2', 'updated': '2020-05-26T23:13:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=26, tm_hour=23, tm_min=13, tm_sec=25, tm_wday=1, tm_yday=147, tm_isdst=0), 'published': '2019-10-24T21:27:31Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=24, tm_hour=21, tm_min=27, tm_sec=31, tm_wday=3, tm_yday=297, tm_isdst=0), 'title': 'Detecting Fake News with Weak Social Supervision', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Fake News with Weak Social Supervision'}, 'summary': 'Limited labeled data is becoming the largest bottleneck for supervised\nlearning systems. This is especially the case for many real-world tasks where\nlarge scale annotated examples are either too expensive to acquire or\nunavailable due to privacy or data access constraints. Weak supervision has\nshown to be a good means to mitigate the scarcity of annotated data by\nleveraging weak labels or injecting constraints from heuristic rules and/or\nexternal knowledge sources. Social media has little labeled data but possesses\nunique characteristics that make it suitable for generating weak supervision,\nresulting in a new type of weak supervision, i.e., weak social supervision. In\nthis article, we illustrate how various aspects of social media can be used to\ngenerate weak social supervision. Specifically, we use the recent research on\nfake news detection as the use case, where social engagements are abundant but\nannotated examples are scarce, to show that weak social supervision is\neffective when facing the little labeled data problem. This article opens the\ndoor for learning with weak social supervision for other emerging tasks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Limited labeled data is becoming the largest bottleneck for supervised\nlearning systems. This is especially the case for many real-world tasks where\nlarge scale annotated examples are either too expensive to acquire or\nunavailable due to privacy or data access constraints. Weak supervision has\nshown to be a good means to mitigate the scarcity of annotated data by\nleveraging weak labels or injecting constraints from heuristic rules and/or\nexternal knowledge sources. Social media has little labeled data but possesses\nunique characteristics that make it suitable for generating weak supervision,\nresulting in a new type of weak supervision, i.e., weak social supervision. In\nthis article, we illustrate how various aspects of social media can be used to\ngenerate weak social supervision. Specifically, we use the recent research on\nfake news detection as the use case, where social engagements are abundant but\nannotated examples are scarce, to show that weak social supervision is\neffective when facing the little labeled data problem. This article opens the\ndoor for learning with weak social supervision for other emerging tasks.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Ahmed Hassan Awadallah'}, {'name': 'Susan Dumais'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '9 pages, 4 figures', 'arxiv_journal_ref': 'IEEE Intelligent Systems 2020', 'links': [{'href': 'http://arxiv.org/abs/1910.11430v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.11430v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
276,http://arxiv.org/abs/1910.09516v3,2020-05-06 13:25:07+00:00,2019-10-21 17:14:52+00:00,Reversible bootstrap percolation: Fake news and fact checking,"[arxiv.Result.Author('M. A. Di Muro'), arxiv.Result.Author('S. V. Buldyrev'), arxiv.Result.Author('L. A. Braunstein')]","Bootstrap percolation has been used to describe opinion formation in society
and other social and natural phenomena. The formal equation of the bootstrap
percolation may have more than one solution, corresponding to several stable
fixed points of the corresponding iteration process. We construct a reversible
bootstrap percolation process, which converges to these extra solutions
displaying a hysteresis typical of discontinuous phase transitions. This
process provides a reasonable model for fake news spreading and the
effectiveness of fact checking. We show that sometimes it is not sufficient to
discard all the sources of fake news in order to reverse the belief of a
population that formed under the influence of these sources.",,"Phys. Rev. E 101, 042307 (2020)",10.1103/PhysRevE.101.042307,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevE.101.042307', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1910.09516v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.09516v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.09516v3,"{'id': 'http://arxiv.org/abs/1910.09516v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.09516v3', 'updated': '2020-05-06T13:25:07Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=6, tm_hour=13, tm_min=25, tm_sec=7, tm_wday=2, tm_yday=127, tm_isdst=0), 'published': '2019-10-21T17:14:52Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=21, tm_hour=17, tm_min=14, tm_sec=52, tm_wday=0, tm_yday=294, tm_isdst=0), 'title': 'Reversible bootstrap percolation: Fake news and fact checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Reversible bootstrap percolation: Fake news and fact checking'}, 'summary': 'Bootstrap percolation has been used to describe opinion formation in society\nand other social and natural phenomena. The formal equation of the bootstrap\npercolation may have more than one solution, corresponding to several stable\nfixed points of the corresponding iteration process. We construct a reversible\nbootstrap percolation process, which converges to these extra solutions\ndisplaying a hysteresis typical of discontinuous phase transitions. This\nprocess provides a reasonable model for fake news spreading and the\neffectiveness of fact checking. We show that sometimes it is not sufficient to\ndiscard all the sources of fake news in order to reverse the belief of a\npopulation that formed under the influence of these sources.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Bootstrap percolation has been used to describe opinion formation in society\nand other social and natural phenomena. The formal equation of the bootstrap\npercolation may have more than one solution, corresponding to several stable\nfixed points of the corresponding iteration process. We construct a reversible\nbootstrap percolation process, which converges to these extra solutions\ndisplaying a hysteresis typical of discontinuous phase transitions. This\nprocess provides a reasonable model for fake news spreading and the\neffectiveness of fact checking. We show that sometimes it is not sufficient to\ndiscard all the sources of fake news in order to reverse the belief of a\npopulation that formed under the influence of these sources.'}, 'authors': [{'name': 'M. A. Di Muro'}, {'name': 'S. V. Buldyrev'}, {'name': 'L. A. Braunstein'}], 'author_detail': {'name': 'L. A. Braunstein'}, 'author': 'L. A. Braunstein', 'arxiv_doi': '10.1103/PhysRevE.101.042307', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevE.101.042307', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1910.09516v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.09516v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Phys. Rev. E 101, 042307 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
277,http://arxiv.org/abs/1910.09295v3,2020-05-15 17:54:09+00:00,2019-10-21 12:28:00+00:00,Localization of Fake News Detection via Multitask Transfer Learning,"[arxiv.Result.Author('Jan Christian Blaise Cruz'), arxiv.Result.Author('Julianne Agatha Tan'), arxiv.Result.Author('Charibeth Cheng')]","The use of the internet as a fast medium of spreading fake news reinforces
the need for computational tools that combat it. Techniques that train fake
news classifiers exist, but they all assume an abundance of resources including
large labeled datasets and expert-curated corpora, which low-resource languages
may not have. In this work, we make two main contributions: First, we alleviate
resource scarcity by constructing the first expertly-curated benchmark dataset
for fake news detection in Filipino, which we call ""Fake News Filipino.""
Second, we benchmark Transfer Learning (TL) techniques and show that they can
be used to train robust fake news classifiers from little data, achieving 91%
accuracy on our fake news dataset, reducing the error by 14% compared to
established few-shot baselines. Furthermore, lifting ideas from multitask
learning, we show that augmenting transformer-based transfer techniques with
auxiliary language modeling losses improves their performance by adapting to
writing style. Using this, we improve TL performance by 4-6%, achieving an
accuracy of 96% on our best model. Lastly, we show that our method generalizes
well to different types of news articles, including political news,
entertainment news, and opinion articles.","Published in the LREC 2020 Proceedings. Models and data available at
  https://github.com/jcblaisecruz02/Tagalog-fake-news","In Proceedings of The 12th Language Resources and Evaluation
  Conference, pp.2589-2597 (2020)",10.13140/RG.2.2.23028.40322,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://dx.doi.org/10.13140/RG.2.2.23028.40322', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1910.09295v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.09295v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.09295v3,"{'id': 'http://arxiv.org/abs/1910.09295v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.09295v3', 'updated': '2020-05-15T17:54:09Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=15, tm_hour=17, tm_min=54, tm_sec=9, tm_wday=4, tm_yday=136, tm_isdst=0), 'published': '2019-10-21T12:28:00Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=21, tm_hour=12, tm_min=28, tm_sec=0, tm_wday=0, tm_yday=294, tm_isdst=0), 'title': 'Localization of Fake News Detection via Multitask Transfer Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Localization of Fake News Detection via Multitask Transfer Learning'}, 'summary': 'The use of the internet as a fast medium of spreading fake news reinforces\nthe need for computational tools that combat it. Techniques that train fake\nnews classifiers exist, but they all assume an abundance of resources including\nlarge labeled datasets and expert-curated corpora, which low-resource languages\nmay not have. In this work, we make two main contributions: First, we alleviate\nresource scarcity by constructing the first expertly-curated benchmark dataset\nfor fake news detection in Filipino, which we call ""Fake News Filipino.""\nSecond, we benchmark Transfer Learning (TL) techniques and show that they can\nbe used to train robust fake news classifiers from little data, achieving 91%\naccuracy on our fake news dataset, reducing the error by 14% compared to\nestablished few-shot baselines. Furthermore, lifting ideas from multitask\nlearning, we show that augmenting transformer-based transfer techniques with\nauxiliary language modeling losses improves their performance by adapting to\nwriting style. Using this, we improve TL performance by 4-6%, achieving an\naccuracy of 96% on our best model. Lastly, we show that our method generalizes\nwell to different types of news articles, including political news,\nentertainment news, and opinion articles.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The use of the internet as a fast medium of spreading fake news reinforces\nthe need for computational tools that combat it. Techniques that train fake\nnews classifiers exist, but they all assume an abundance of resources including\nlarge labeled datasets and expert-curated corpora, which low-resource languages\nmay not have. In this work, we make two main contributions: First, we alleviate\nresource scarcity by constructing the first expertly-curated benchmark dataset\nfor fake news detection in Filipino, which we call ""Fake News Filipino.""\nSecond, we benchmark Transfer Learning (TL) techniques and show that they can\nbe used to train robust fake news classifiers from little data, achieving 91%\naccuracy on our fake news dataset, reducing the error by 14% compared to\nestablished few-shot baselines. Furthermore, lifting ideas from multitask\nlearning, we show that augmenting transformer-based transfer techniques with\nauxiliary language modeling losses improves their performance by adapting to\nwriting style. Using this, we improve TL performance by 4-6%, achieving an\naccuracy of 96% on our best model. Lastly, we show that our method generalizes\nwell to different types of news articles, including political news,\nentertainment news, and opinion articles.'}, 'authors': [{'name': 'Jan Christian Blaise Cruz'}, {'name': 'Julianne Agatha Tan'}, {'name': 'Charibeth Cheng'}], 'author_detail': {'name': 'Charibeth Cheng'}, 'author': 'Charibeth Cheng', 'arxiv_doi': '10.13140/RG.2.2.23028.40322', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.13140/RG.2.2.23028.40322', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1910.09295v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.09295v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published in the LREC 2020 Proceedings. Models and data available at\n  https://github.com/jcblaisecruz02/Tagalog-fake-news', 'arxiv_journal_ref': 'In Proceedings of The 12th Language Resources and Evaluation\n  Conference, pp.2589-2597 (2020)', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
278,http://arxiv.org/abs/1910.08010v1,2019-10-17 16:30:08+00:00,2019-10-17 16:30:08+00:00,Uncritical polarized groups: The impact of spreading fake news as fact in social networks,"[arxiv.Result.Author('Jesus San Martin'), arxiv.Result.Author('Fatima Drubi'), arxiv.Result.Author('Daniel Rodriguez-Perez')]","The spread of ideas in online social networks is a crucial phenomenon to
understand nowadays the proliferation of fake news and their impact in
democracies. This makes necessary to use models that mimic the circulation of
rumors. The law of large numbers as well as the probability distribution of
contact groups allow us to construct a model with a minimum number of
hypotheses. Moreover, we can analyze with this model the presence of very
polarized groups of individuals (humans or bots) who spread a rumor as soon as
they know about it. Given only the initial number of individuals who know any
news, in a population connected by an instant messaging application, we first
deduce from our model a simple function of time to study the rumor propagation.
We then prove that the polarized groups can be detected and quantified from
empirical data. Finally, we also predict the time required by any rumor to
reach a fixed percentage of the population.","31 pages, 6 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1910.08010v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.08010v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.08010v1,"{'id': 'http://arxiv.org/abs/1910.08010v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.08010v1', 'updated': '2019-10-17T16:30:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=16, tm_min=30, tm_sec=8, tm_wday=3, tm_yday=290, tm_isdst=0), 'published': '2019-10-17T16:30:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=16, tm_min=30, tm_sec=8, tm_wday=3, tm_yday=290, tm_isdst=0), 'title': 'Uncritical polarized groups: The impact of spreading fake news as fact\n  in social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Uncritical polarized groups: The impact of spreading fake news as fact\n  in social networks'}, 'summary': 'The spread of ideas in online social networks is a crucial phenomenon to\nunderstand nowadays the proliferation of fake news and their impact in\ndemocracies. This makes necessary to use models that mimic the circulation of\nrumors. The law of large numbers as well as the probability distribution of\ncontact groups allow us to construct a model with a minimum number of\nhypotheses. Moreover, we can analyze with this model the presence of very\npolarized groups of individuals (humans or bots) who spread a rumor as soon as\nthey know about it. Given only the initial number of individuals who know any\nnews, in a population connected by an instant messaging application, we first\ndeduce from our model a simple function of time to study the rumor propagation.\nWe then prove that the polarized groups can be detected and quantified from\nempirical data. Finally, we also predict the time required by any rumor to\nreach a fixed percentage of the population.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of ideas in online social networks is a crucial phenomenon to\nunderstand nowadays the proliferation of fake news and their impact in\ndemocracies. This makes necessary to use models that mimic the circulation of\nrumors. The law of large numbers as well as the probability distribution of\ncontact groups allow us to construct a model with a minimum number of\nhypotheses. Moreover, we can analyze with this model the presence of very\npolarized groups of individuals (humans or bots) who spread a rumor as soon as\nthey know about it. Given only the initial number of individuals who know any\nnews, in a population connected by an instant messaging application, we first\ndeduce from our model a simple function of time to study the rumor propagation.\nWe then prove that the polarized groups can be detected and quantified from\nempirical data. Finally, we also predict the time required by any rumor to\nreach a fixed percentage of the population.'}, 'authors': [{'name': 'Jesus San Martin'}, {'name': 'Fatima Drubi'}, {'name': 'Daniel Rodriguez-Perez'}], 'author_detail': {'name': 'Daniel Rodriguez-Perez'}, 'author': 'Daniel Rodriguez-Perez', 'arxiv_comment': '31 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/1910.08010v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.08010v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
279,http://arxiv.org/abs/1910.07130v5,2020-09-02 02:01:28+00:00,2019-10-16 02:05:26+00:00,SCG: Spotting Coordinated Groups in Social Media,"[arxiv.Result.Author('Junhao Wang'), arxiv.Result.Author('Sacha Levy'), arxiv.Result.Author('Ren Wang'), arxiv.Result.Author('Aayushi Kulshrestha'), arxiv.Result.Author('Reihaneh Rabbany')]","Recent events have led to a burgeoning awareness on the misuse of social
media sites to affect political events, sway public opinion, and confuse the
voters. Such serious, hostile mass manipulation has motivated a large body of
works on bots/troll detection and fake news detection, which mostly focus on
classifying at the user level based on the content generated by the users. In
this study, we jointly analyze the connections among the users, as well as the
content generated by them to Spot Coordinated Groups (SCG), sets of users that
are likely to be organized towards impacting the general discourse. Given their
tiny size (relative to the whole data), detecting these groups is
computationally hard. Our proposed method detects these tiny-clusters
effectively and efficiently. We deploy our SCG method to summarize and explain
the coordinated groups on Twitter around the 2019 Canadian Federal Elections,
by analyzing over 60 thousand user accounts with 3.4 million followership
connections, and 1.3 million unique hashtags in the content of their tweets.
The users in the detected coordinated groups are over 4x more likely to get
suspended, whereas the hashtags which characterize their creed are linked to
misinformation campaigns.",,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1910.07130v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.07130v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.07130v5,"{'id': 'http://arxiv.org/abs/1910.07130v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.07130v5', 'updated': '2020-09-02T02:01:28Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=2, tm_hour=2, tm_min=1, tm_sec=28, tm_wday=2, tm_yday=246, tm_isdst=0), 'published': '2019-10-16T02:05:26Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=16, tm_hour=2, tm_min=5, tm_sec=26, tm_wday=2, tm_yday=289, tm_isdst=0), 'title': 'SCG: Spotting Coordinated Groups in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SCG: Spotting Coordinated Groups in Social Media'}, 'summary': 'Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.'}, 'authors': [{'name': 'Junhao Wang'}, {'name': 'Sacha Levy'}, {'name': 'Ren Wang'}, {'name': 'Aayushi Kulshrestha'}, {'name': 'Reihaneh Rabbany'}], 'author_detail': {'name': 'Reihaneh Rabbany'}, 'author': 'Reihaneh Rabbany', 'links': [{'href': 'http://arxiv.org/abs/1910.07130v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.07130v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
280,http://arxiv.org/abs/1910.06592v1,2019-10-15 08:43:47+00:00,2019-10-15 08:43:47+00:00,FacTweet: Profiling Fake News Twitter Accounts,"[arxiv.Result.Author('Bilal Ghanem'), arxiv.Result.Author('Simone Paolo Ponzetto'), arxiv.Result.Author('Paolo Rosso')]","We present an approach to detect fake news in Twitter at the account level
using a neural recurrent model and a variety of different semantic and
stylistic features. Our method extracts a set of features from the timelines of
news Twitter accounts by reading their posts as chunks, rather than dealing
with each tweet independently. We show the experimental benefits of modeling
latent stylistic signatures of mixed fake and real news with a sequential model
over a wide range of strong baselines.",6 pages,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1910.06592v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.06592v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.06592v1,"{'id': 'http://arxiv.org/abs/1910.06592v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.06592v1', 'updated': '2019-10-15T08:43:47Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=15, tm_hour=8, tm_min=43, tm_sec=47, tm_wday=1, tm_yday=288, tm_isdst=0), 'published': '2019-10-15T08:43:47Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=15, tm_hour=8, tm_min=43, tm_sec=47, tm_wday=1, tm_yday=288, tm_isdst=0), 'title': 'FacTweet: Profiling Fake News Twitter Accounts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FacTweet: Profiling Fake News Twitter Accounts'}, 'summary': 'We present an approach to detect fake news in Twitter at the account level\nusing a neural recurrent model and a variety of different semantic and\nstylistic features. Our method extracts a set of features from the timelines of\nnews Twitter accounts by reading their posts as chunks, rather than dealing\nwith each tweet independently. We show the experimental benefits of modeling\nlatent stylistic signatures of mixed fake and real news with a sequential model\nover a wide range of strong baselines.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We present an approach to detect fake news in Twitter at the account level\nusing a neural recurrent model and a variety of different semantic and\nstylistic features. Our method extracts a set of features from the timelines of\nnews Twitter accounts by reading their posts as chunks, rather than dealing\nwith each tweet independently. We show the experimental benefits of modeling\nlatent stylistic signatures of mixed fake and real news with a sequential model\nover a wide range of strong baselines.'}, 'authors': [{'name': 'Bilal Ghanem'}, {'name': 'Simone Paolo Ponzetto'}, {'name': 'Paolo Rosso'}], 'author_detail': {'name': 'Paolo Rosso'}, 'author': 'Paolo Rosso', 'arxiv_comment': '6 pages', 'links': [{'href': 'http://arxiv.org/abs/1910.06592v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.06592v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
281,http://arxiv.org/abs/1911.05496v2,2021-08-20 09:14:43+00:00,2019-10-14 06:19:58+00:00,Temporal Graph Kernels for Classifying Dissemination Processes,"[arxiv.Result.Author('Lutz Oettershagen'), arxiv.Result.Author('Nils M. Kriege'), arxiv.Result.Author('Christopher Morris'), arxiv.Result.Author('Petra Mutzel')]","Many real-world graphs or networks are temporal, e.g., in a social network
persons only interact at specific points in time. This information directs
dissemination processes on the network, such as the spread of rumors, fake
news, or diseases. However, the current state-of-the-art methods for supervised
graph classification are designed mainly for static graphs and may not be able
to capture temporal information. Hence, they are not powerful enough to
distinguish between graphs modeling different dissemination processes. To
address this, we introduce a framework to lift standard graph kernels to the
temporal domain. Specifically, we explore three different approaches and
investigate the trade-offs between loss of temporal information and efficiency.
Moreover, to handle large-scale graphs, we propose stochastic variants of our
kernels with provable approximation guarantees. We evaluate our methods on a
wide range of real-world social networks. Our methods beat static kernels by a
large margin in terms of accuracy while still being scalable to large graphs
and data sets. Hence, we confirm that taking temporal information into account
is crucial for the successful classification of dissemination processes.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1911.05496v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.05496v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.05496v2,"{'id': 'http://arxiv.org/abs/1911.05496v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.05496v2', 'updated': '2021-08-20T09:14:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=20, tm_hour=9, tm_min=14, tm_sec=43, tm_wday=4, tm_yday=232, tm_isdst=0), 'published': '2019-10-14T06:19:58Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=14, tm_hour=6, tm_min=19, tm_sec=58, tm_wday=0, tm_yday=287, tm_isdst=0), 'title': 'Temporal Graph Kernels for Classifying Dissemination Processes', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Temporal Graph Kernels for Classifying Dissemination Processes'}, 'summary': 'Many real-world graphs or networks are temporal, e.g., in a social network\npersons only interact at specific points in time. This information directs\ndissemination processes on the network, such as the spread of rumors, fake\nnews, or diseases. However, the current state-of-the-art methods for supervised\ngraph classification are designed mainly for static graphs and may not be able\nto capture temporal information. Hence, they are not powerful enough to\ndistinguish between graphs modeling different dissemination processes. To\naddress this, we introduce a framework to lift standard graph kernels to the\ntemporal domain. Specifically, we explore three different approaches and\ninvestigate the trade-offs between loss of temporal information and efficiency.\nMoreover, to handle large-scale graphs, we propose stochastic variants of our\nkernels with provable approximation guarantees. We evaluate our methods on a\nwide range of real-world social networks. Our methods beat static kernels by a\nlarge margin in terms of accuracy while still being scalable to large graphs\nand data sets. Hence, we confirm that taking temporal information into account\nis crucial for the successful classification of dissemination processes.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Many real-world graphs or networks are temporal, e.g., in a social network\npersons only interact at specific points in time. This information directs\ndissemination processes on the network, such as the spread of rumors, fake\nnews, or diseases. However, the current state-of-the-art methods for supervised\ngraph classification are designed mainly for static graphs and may not be able\nto capture temporal information. Hence, they are not powerful enough to\ndistinguish between graphs modeling different dissemination processes. To\naddress this, we introduce a framework to lift standard graph kernels to the\ntemporal domain. Specifically, we explore three different approaches and\ninvestigate the trade-offs between loss of temporal information and efficiency.\nMoreover, to handle large-scale graphs, we propose stochastic variants of our\nkernels with provable approximation guarantees. We evaluate our methods on a\nwide range of real-world social networks. Our methods beat static kernels by a\nlarge margin in terms of accuracy while still being scalable to large graphs\nand data sets. Hence, we confirm that taking temporal information into account\nis crucial for the successful classification of dissemination processes.'}, 'authors': [{'name': 'Lutz Oettershagen'}, {'name': 'Nils M. Kriege'}, {'name': 'Christopher Morris'}, {'name': 'Petra Mutzel'}], 'author_detail': {'name': 'Petra Mutzel'}, 'author': 'Petra Mutzel', 'links': [{'href': 'http://arxiv.org/abs/1911.05496v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.05496v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
282,http://arxiv.org/abs/1910.02223v1,2019-10-05 06:48:23+00:00,2019-10-05 06:48:23+00:00,A Machine Learning Analysis of the Features in Deceptive and Credible News,[arxiv.Result.Author('Qi Jia Sun')],"Fake news is a type of pervasive propaganda that spreads misinformation
online, taking advantage of social media's extensive reach to manipulate public
perception. Over the past three years, fake news has become a focal discussion
point in the media due to its impact on the 2016 U.S. presidential election.
Fake news can have severe real-world implications: in 2016, a man walked into a
pizzeria carrying a rifle because he read that Hillary Clinton was harboring
children as sex slaves. This project presents a high accuracy (87%) machine
learning classifier that determines the validity of news based on the word
distributions and specific linguistic and stylistic differences in the first
few sentences of an article. This can help readers identify the validity of an
article by looking for specific features in the opening lines aiding them in
making informed decisions. Using a dataset of 2,107 articles from 30 different
websites, this project establishes an understanding of the variations between
fake and credible news by examining the model, dataset, and features. This
classifier appears to use the differences in word distribution, levels of tone
authenticity, and frequency of adverbs, adjectives, and nouns. The
differentiation in the features of these articles can be used to improve future
classifiers. This classifier can also be further applied directly to browsers
as a Google Chrome extension or as a filter for social media outlets or news
websites to reduce the spread of misinformation.",,,,cs.CL,"['cs.CL', 'J.5.5']","[arxiv.Result.Link('http://arxiv.org/abs/1910.02223v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.02223v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.02223v1,"{'id': 'http://arxiv.org/abs/1910.02223v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.02223v1', 'updated': '2019-10-05T06:48:23Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=6, tm_min=48, tm_sec=23, tm_wday=5, tm_yday=278, tm_isdst=0), 'published': '2019-10-05T06:48:23Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=6, tm_min=48, tm_sec=23, tm_wday=5, tm_yday=278, tm_isdst=0), 'title': 'A Machine Learning Analysis of the Features in Deceptive and Credible\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Machine Learning Analysis of the Features in Deceptive and Credible\n  News'}, 'summary': ""Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.""}, 'authors': [{'name': 'Qi Jia Sun'}], 'author_detail': {'name': 'Qi Jia Sun'}, 'author': 'Qi Jia Sun', 'links': [{'href': 'http://arxiv.org/abs/1910.02223v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.02223v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.5.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
283,http://arxiv.org/abs/1910.02202v1,2019-10-05 03:23:45+00:00,2019-10-05 03:23:45+00:00,Learning from Fact-checkers: Analysis and Generation of Fact-checking Language,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","In fighting against fake news, many fact-checking systems comprised of
human-based fact-checking sites (e.g., snopes.com and politifact.com) and
automatic detection systems have been developed in recent years. However,
online users still keep sharing fake news even when it has been debunked. It
means that early fake news detection may be insufficient and we need another
complementary approach to mitigate the spread of misinformation. In this paper,
we introduce a novel application of text generation for combating fake news. In
particular, we (1) leverage online users named \emph{fact-checkers}, who cite
fact-checking sites as credible evidences to fact-check information in public
discourse; (2) analyze linguistic characteristics of fact-checking tweets; and
(3) propose and build a deep learning framework to generate responses with
fact-checking intention to increase the fact-checkers' engagement in
fact-checking activities. Our analysis reveals that the fact-checkers tend to
refute misinformation and use formal language (e.g. few swear words and
Internet slangs). Our framework successfully generates relevant responses, and
outperforms competing models by achieving up to 30\% improvements. Our
qualitative study also confirms that the superiority of our generated responses
compared with responses generated from the existing models.",SIGIR 2019,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1910.02202v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.02202v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.02202v1,"{'id': 'http://arxiv.org/abs/1910.02202v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.02202v1', 'updated': '2019-10-05T03:23:45Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=3, tm_min=23, tm_sec=45, tm_wday=5, tm_yday=278, tm_isdst=0), 'published': '2019-10-05T03:23:45Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=3, tm_min=23, tm_sec=45, tm_wday=5, tm_yday=278, tm_isdst=0), 'title': 'Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language'}, 'summary': ""In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.""}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'SIGIR 2019', 'links': [{'href': 'http://arxiv.org/abs/1910.02202v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.02202v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
284,http://arxiv.org/abs/1910.01722v2,2020-04-10 19:25:59+00:00,2019-10-03 21:12:57+00:00,Constant State of Change: Engagement Inequality in Temporal Dynamic Networks,"[arxiv.Result.Author('Hadar Miller'), arxiv.Result.Author('Osnat Mokryn')]","The temporal changes in complex systems of interactions have excited the
research community in recent years as they encompass understandings on their
dynamics and evolution. From the collective dynamics of organizations and
online communities to the spreading of information and fake news, to name a
few, temporal dynamics are fundamental in the understanding of complex systems.
In this work, we quantify the level of engagement in dynamic complex systems of
interactions, modeled as networks. We focus on interaction networks for which
the dynamics of the interactions are coupled with that of the topology, such as
online messaging, forums, and emails. We define two indices to capture the
temporal level of engagement: the Temporal Network (edge) Intensity index, and
the Temporal Dominance Inequality index. Our surprising results are that these
measures are stationary for most measured networks, regardless of vast
fluctuations in the size of the networks in time. Moreover, more than 80% of
weekly changes in the indices values are bounded by less than 10%. The indices
are stable between the temporal evolution of a network but are different
between networks, and a classifier can determine the network the temporal
indices belong to with high success. We find an exception in the Enron
management email exchange during the year before its disintegration, in which
both indices show high volatility throughout the inspected period.",arXiv admin note: substantial text overlap with arXiv:1809.09613,PLOS ONE 15(4): e0231035 (2020),10.1371/journal.pone.0231035,cs.SI,"['cs.SI', 'physics.data-an', 'stat.AP']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0231035', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1910.01722v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.01722v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.01722v2,"{'id': 'http://arxiv.org/abs/1910.01722v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.01722v2', 'updated': '2020-04-10T19:25:59Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=10, tm_hour=19, tm_min=25, tm_sec=59, tm_wday=4, tm_yday=101, tm_isdst=0), 'published': '2019-10-03T21:12:57Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=3, tm_hour=21, tm_min=12, tm_sec=57, tm_wday=3, tm_yday=276, tm_isdst=0), 'title': 'Constant State of Change: Engagement Inequality in Temporal Dynamic\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Constant State of Change: Engagement Inequality in Temporal Dynamic\n  Networks'}, 'summary': 'The temporal changes in complex systems of interactions have excited the\nresearch community in recent years as they encompass understandings on their\ndynamics and evolution. From the collective dynamics of organizations and\nonline communities to the spreading of information and fake news, to name a\nfew, temporal dynamics are fundamental in the understanding of complex systems.\nIn this work, we quantify the level of engagement in dynamic complex systems of\ninteractions, modeled as networks. We focus on interaction networks for which\nthe dynamics of the interactions are coupled with that of the topology, such as\nonline messaging, forums, and emails. We define two indices to capture the\ntemporal level of engagement: the Temporal Network (edge) Intensity index, and\nthe Temporal Dominance Inequality index. Our surprising results are that these\nmeasures are stationary for most measured networks, regardless of vast\nfluctuations in the size of the networks in time. Moreover, more than 80% of\nweekly changes in the indices values are bounded by less than 10%. The indices\nare stable between the temporal evolution of a network but are different\nbetween networks, and a classifier can determine the network the temporal\nindices belong to with high success. We find an exception in the Enron\nmanagement email exchange during the year before its disintegration, in which\nboth indices show high volatility throughout the inspected period.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The temporal changes in complex systems of interactions have excited the\nresearch community in recent years as they encompass understandings on their\ndynamics and evolution. From the collective dynamics of organizations and\nonline communities to the spreading of information and fake news, to name a\nfew, temporal dynamics are fundamental in the understanding of complex systems.\nIn this work, we quantify the level of engagement in dynamic complex systems of\ninteractions, modeled as networks. We focus on interaction networks for which\nthe dynamics of the interactions are coupled with that of the topology, such as\nonline messaging, forums, and emails. We define two indices to capture the\ntemporal level of engagement: the Temporal Network (edge) Intensity index, and\nthe Temporal Dominance Inequality index. Our surprising results are that these\nmeasures are stationary for most measured networks, regardless of vast\nfluctuations in the size of the networks in time. Moreover, more than 80% of\nweekly changes in the indices values are bounded by less than 10%. The indices\nare stable between the temporal evolution of a network but are different\nbetween networks, and a classifier can determine the network the temporal\nindices belong to with high success. We find an exception in the Enron\nmanagement email exchange during the year before its disintegration, in which\nboth indices show high volatility throughout the inspected period.'}, 'authors': [{'name': 'Hadar Miller'}, {'name': 'Osnat Mokryn'}], 'author_detail': {'name': 'Osnat Mokryn'}, 'author': 'Osnat Mokryn', 'arxiv_doi': '10.1371/journal.pone.0231035', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0231035', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1910.01722v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.01722v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'arXiv admin note: substantial text overlap with arXiv:1809.09613', 'arxiv_journal_ref': 'PLOS ONE 15(4): e0231035 (2020)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
285,http://arxiv.org/abs/1910.01160v2,2019-11-05 20:45:25+00:00,2019-10-02 18:47:17+00:00,Identifying Nuances in Fake News vs. Satire: Using Semantic and Linguistic Cues,"[arxiv.Result.Author('Or Levi'), arxiv.Result.Author('Pedram Hosseini'), arxiv.Result.Author('Mona Diab'), arxiv.Result.Author('David A. Broniatowski')]","The blurry line between nefarious fake news and protected-speech satire has
been a notorious struggle for social media platforms. Further to the efforts of
reducing exposure to misinformation on social media, purveyors of fake news
have begun to masquerade as satire sites to avoid being demoted. In this work,
we address the challenge of automatically classifying fake news versus satire.
Previous work have studied whether fake news and satire can be distinguished
based on language differences. Contrary to fake news, satire stories are
usually humorous and carry some political or social message. We hypothesize
that these nuances could be identified using semantic and linguistic cues.
Consequently, we train a machine learning method using semantic representation,
with a state-of-the-art contextual language model, and with linguistic features
based on textual coherence metrics. Empirical evaluation attests to the merits
of our approach compared to the language-based baseline and sheds light on the
nuances between fake news and satire. As avenues for future work, we consider
studying additional linguistic features related to the humor aspect, and
enriching the data with current news events, to help identify a political or
social message.","Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):
  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019",,10.18653/v1/D19-5004,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.18653/v1/D19-5004', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1910.01160v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.01160v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.01160v2,"{'id': 'http://arxiv.org/abs/1910.01160v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.01160v2', 'updated': '2019-11-05T20:45:25Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=5, tm_hour=20, tm_min=45, tm_sec=25, tm_wday=1, tm_yday=309, tm_isdst=0), 'published': '2019-10-02T18:47:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=2, tm_hour=18, tm_min=47, tm_sec=17, tm_wday=2, tm_yday=275, tm_isdst=0), 'title': 'Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues'}, 'summary': 'The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.'}, 'authors': [{'name': 'Or Levi'}, {'name': 'Pedram Hosseini'}, {'name': 'Mona Diab'}, {'name': 'David A. Broniatowski'}], 'author_detail': {'name': 'David A. Broniatowski'}, 'author': 'David A. Broniatowski', 'arxiv_doi': '10.18653/v1/D19-5004', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.18653/v1/D19-5004', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1910.01160v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.01160v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
286,http://arxiv.org/abs/1910.03496v2,2019-10-11 05:36:23+00:00,2019-09-29 17:45:48+00:00,Fake news detection using Deep Learning,"[arxiv.Result.Author('Álvaro Ibrain Rodríguez'), arxiv.Result.Author('Lara Lloret Iglesias')]","The evolution of the information and communication technologies has
dramatically increased the number of people with access to the Internet, which
has changed the way the information is consumed. As a consequence of the above,
fake news have become one of the major concerns because its potential to
destabilize governments, which makes them a potential danger to modern society.
An example of this can be found in the US. electoral campaign, where the term
""fake news"" gained great notoriety due to the influence of the hoaxes in the
final result of these. In this work the feasibility of applying deep learning
techniques to discriminate fake news on the Internet using only their text is
studied. In order to accomplish that, three different neural network
architectures are proposed, one of them based on BERT, a modern language model
created by Google which achieves state-of-the-art results.",,,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1910.03496v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.03496v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.03496v2,"{'id': 'http://arxiv.org/abs/1910.03496v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.03496v2', 'updated': '2019-10-11T05:36:23Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=11, tm_hour=5, tm_min=36, tm_sec=23, tm_wday=4, tm_yday=284, tm_isdst=0), 'published': '2019-09-29T17:45:48Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=29, tm_hour=17, tm_min=45, tm_sec=48, tm_wday=6, tm_yday=272, tm_isdst=0), 'title': 'Fake news detection using Deep Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news detection using Deep Learning'}, 'summary': 'The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n""fake news"" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n""fake news"" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.'}, 'authors': [{'name': 'Álvaro Ibrain Rodríguez'}, {'name': 'Lara Lloret Iglesias'}], 'author_detail': {'name': 'Lara Lloret Iglesias'}, 'author': 'Lara Lloret Iglesias', 'links': [{'href': 'http://arxiv.org/abs/1910.03496v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.03496v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
287,http://arxiv.org/abs/1909.12089v2,2019-12-20 01:12:42+00:00,2019-09-26 13:36:02+00:00,From classical to modern opinion dynamics,"[arxiv.Result.Author('Hossein Noorazar'), arxiv.Result.Author('Kevin R. Vixie'), arxiv.Result.Author('Arghavan Talebanpour'), arxiv.Result.Author('Yunfeng Hu')]","In this age of Facebook, Instagram and Twitter, there is rapidly growing
interest in understanding network-enabled opinion dynamics in large groups of
autonomous agents. The phenomena of opinion polarization, the spread of
propaganda and fake news, and the manipulation of sentiment are of interest to
large numbers of organizations and people, some of whom are resource rich.
Whether it is the more nefarious players such as foreign governments that are
attempting to sway elections or large corporations that are trying to bend
sentiment -- often quite surreptitiously, or it is more open and above board,
like researchers that want to spread the news of some finding or some business
interest that wants to make a large group of people aware of genuinely helpful
innovations that they are marketing, what is at stake is often significant. In
this paper we review many of the classical, and some of the new, social
interaction models aimed at understanding opinion dynamics. While the first
papers studying opinion dynamics appeared over 60 years ago, there is still a
great deal of room for innovation and exploration. We believe that the
political climate and the extraordinary (even unprecedented) events in the
sphere of politics in the last few years will inspire new interest and new
ideas. It is our aim to help those interested researchers understand what has
already been explored in a significant portion of the field of opinion
dynamics. We believe that in doing this, it will become clear that there is
still much to be done.",,,10.1142/S0129183120501016,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1142/S0129183120501016', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1909.12089v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.12089v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.12089v2,"{'id': 'http://arxiv.org/abs/1909.12089v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.12089v2', 'updated': '2019-12-20T01:12:42Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=20, tm_hour=1, tm_min=12, tm_sec=42, tm_wday=4, tm_yday=354, tm_isdst=0), 'published': '2019-09-26T13:36:02Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=26, tm_hour=13, tm_min=36, tm_sec=2, tm_wday=3, tm_yday=269, tm_isdst=0), 'title': 'From classical to modern opinion dynamics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'From classical to modern opinion dynamics'}, 'summary': 'In this age of Facebook, Instagram and Twitter, there is rapidly growing\ninterest in understanding network-enabled opinion dynamics in large groups of\nautonomous agents. The phenomena of opinion polarization, the spread of\npropaganda and fake news, and the manipulation of sentiment are of interest to\nlarge numbers of organizations and people, some of whom are resource rich.\nWhether it is the more nefarious players such as foreign governments that are\nattempting to sway elections or large corporations that are trying to bend\nsentiment -- often quite surreptitiously, or it is more open and above board,\nlike researchers that want to spread the news of some finding or some business\ninterest that wants to make a large group of people aware of genuinely helpful\ninnovations that they are marketing, what is at stake is often significant. In\nthis paper we review many of the classical, and some of the new, social\ninteraction models aimed at understanding opinion dynamics. While the first\npapers studying opinion dynamics appeared over 60 years ago, there is still a\ngreat deal of room for innovation and exploration. We believe that the\npolitical climate and the extraordinary (even unprecedented) events in the\nsphere of politics in the last few years will inspire new interest and new\nideas. It is our aim to help those interested researchers understand what has\nalready been explored in a significant portion of the field of opinion\ndynamics. We believe that in doing this, it will become clear that there is\nstill much to be done.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this age of Facebook, Instagram and Twitter, there is rapidly growing\ninterest in understanding network-enabled opinion dynamics in large groups of\nautonomous agents. The phenomena of opinion polarization, the spread of\npropaganda and fake news, and the manipulation of sentiment are of interest to\nlarge numbers of organizations and people, some of whom are resource rich.\nWhether it is the more nefarious players such as foreign governments that are\nattempting to sway elections or large corporations that are trying to bend\nsentiment -- often quite surreptitiously, or it is more open and above board,\nlike researchers that want to spread the news of some finding or some business\ninterest that wants to make a large group of people aware of genuinely helpful\ninnovations that they are marketing, what is at stake is often significant. In\nthis paper we review many of the classical, and some of the new, social\ninteraction models aimed at understanding opinion dynamics. While the first\npapers studying opinion dynamics appeared over 60 years ago, there is still a\ngreat deal of room for innovation and exploration. We believe that the\npolitical climate and the extraordinary (even unprecedented) events in the\nsphere of politics in the last few years will inspire new interest and new\nideas. It is our aim to help those interested researchers understand what has\nalready been explored in a significant portion of the field of opinion\ndynamics. We believe that in doing this, it will become clear that there is\nstill much to be done.'}, 'authors': [{'name': 'Hossein Noorazar'}, {'name': 'Kevin R. Vixie'}, {'name': 'Arghavan Talebanpour'}, {'name': 'Yunfeng Hu'}], 'author_detail': {'name': 'Yunfeng Hu'}, 'author': 'Yunfeng Hu', 'arxiv_doi': '10.1142/S0129183120501016', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1142/S0129183120501016', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1909.12089v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.12089v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
288,http://arxiv.org/abs/1909.09868v2,2020-04-24 01:44:57+00:00,2019-09-21 18:47:34+00:00,On the Importance of Delexicalization for Fact Verification,"[arxiv.Result.Author('Sandeep Suntwal'), arxiv.Result.Author('Mithun Paul'), arxiv.Result.Author('Rebecca Sharp'), arxiv.Result.Author('Mihai Surdeanu')]","In this work we aim to understand and estimate the importance that a neural
network assigns to various aspects of the data while learning and making
predictions. Here we focus on the recognizing textual entailment (RTE) task and
its application to fact verification. In this context, the contributions of
this work are as follows. We investigate the attention weights a state of the
art RTE method assigns to input tokens in the RTE component of fact
verification systems, and confirm that most of the weight is assigned to POS
tags of nouns (e.g., NN, NNP etc.) or their phrases. To verify that these
lexicalized models transfer poorly, we implement a domain transfer experiment
where a RTE component is trained on the FEVER data, and tested on the Fake News
Challenge (FNC) dataset. As expected, even though this method achieves high
accuracy when evaluated in the same domain, the performance in the target
domain is poor, marginally above chance.To mitigate this dependence on
lexicalized information, we experiment with several strategies for masking out
names by replacing them with their semantic category, coupled with a unique
identifier to mark that the same or new entities are referenced between claim
and evidence. The results show that, while the performance on the FEVER dataset
remains at par with that of the model trained on lexicalized data, it improves
significantly when tested in the FNC dataset. Thus our experiments demonstrate
that our strategy is successful in mitigating the dependency on lexical
information.",published in the proceedings at EMNLP2019,,10.18653/v1/D19-1340,cs.LG,"['cs.LG', 'cs.AI']","[arxiv.Result.Link('http://dx.doi.org/10.18653/v1/D19-1340', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1909.09868v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.09868v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.09868v2,"{'id': 'http://arxiv.org/abs/1909.09868v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.09868v2', 'updated': '2020-04-24T01:44:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=24, tm_hour=1, tm_min=44, tm_sec=57, tm_wday=4, tm_yday=115, tm_isdst=0), 'published': '2019-09-21T18:47:34Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=21, tm_hour=18, tm_min=47, tm_sec=34, tm_wday=5, tm_yday=264, tm_isdst=0), 'title': 'On the Importance of Delexicalization for Fact Verification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the Importance of Delexicalization for Fact Verification'}, 'summary': 'In this work we aim to understand and estimate the importance that a neural\nnetwork assigns to various aspects of the data while learning and making\npredictions. Here we focus on the recognizing textual entailment (RTE) task and\nits application to fact verification. In this context, the contributions of\nthis work are as follows. We investigate the attention weights a state of the\nart RTE method assigns to input tokens in the RTE component of fact\nverification systems, and confirm that most of the weight is assigned to POS\ntags of nouns (e.g., NN, NNP etc.) or their phrases. To verify that these\nlexicalized models transfer poorly, we implement a domain transfer experiment\nwhere a RTE component is trained on the FEVER data, and tested on the Fake News\nChallenge (FNC) dataset. As expected, even though this method achieves high\naccuracy when evaluated in the same domain, the performance in the target\ndomain is poor, marginally above chance.To mitigate this dependence on\nlexicalized information, we experiment with several strategies for masking out\nnames by replacing them with their semantic category, coupled with a unique\nidentifier to mark that the same or new entities are referenced between claim\nand evidence. The results show that, while the performance on the FEVER dataset\nremains at par with that of the model trained on lexicalized data, it improves\nsignificantly when tested in the FNC dataset. Thus our experiments demonstrate\nthat our strategy is successful in mitigating the dependency on lexical\ninformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work we aim to understand and estimate the importance that a neural\nnetwork assigns to various aspects of the data while learning and making\npredictions. Here we focus on the recognizing textual entailment (RTE) task and\nits application to fact verification. In this context, the contributions of\nthis work are as follows. We investigate the attention weights a state of the\nart RTE method assigns to input tokens in the RTE component of fact\nverification systems, and confirm that most of the weight is assigned to POS\ntags of nouns (e.g., NN, NNP etc.) or their phrases. To verify that these\nlexicalized models transfer poorly, we implement a domain transfer experiment\nwhere a RTE component is trained on the FEVER data, and tested on the Fake News\nChallenge (FNC) dataset. As expected, even though this method achieves high\naccuracy when evaluated in the same domain, the performance in the target\ndomain is poor, marginally above chance.To mitigate this dependence on\nlexicalized information, we experiment with several strategies for masking out\nnames by replacing them with their semantic category, coupled with a unique\nidentifier to mark that the same or new entities are referenced between claim\nand evidence. The results show that, while the performance on the FEVER dataset\nremains at par with that of the model trained on lexicalized data, it improves\nsignificantly when tested in the FNC dataset. Thus our experiments demonstrate\nthat our strategy is successful in mitigating the dependency on lexical\ninformation.'}, 'authors': [{'name': 'Sandeep Suntwal'}, {'name': 'Mithun Paul'}, {'name': 'Rebecca Sharp'}, {'name': 'Mihai Surdeanu'}], 'author_detail': {'name': 'Mihai Surdeanu'}, 'author': 'Mihai Surdeanu', 'arxiv_doi': '10.18653/v1/D19-1340', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.18653/v1/D19-1340', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1909.09868v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.09868v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'published in the proceedings at EMNLP2019', 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
289,http://arxiv.org/abs/1909.07523v1,2019-09-16 23:53:59+00:00,2019-09-16 23:53:59+00:00,Discovering Differential Features: Adversarial Learning for Information Credibility Evaluation,"[arxiv.Result.Author('Lianwei Wu'), arxiv.Result.Author('Yuan Rao'), arxiv.Result.Author('Ambreen Nazir'), arxiv.Result.Author('Haolin Jin')]","A series of deep learning approaches extract a large number of credibility
features to detect fake news on the Internet. However, these extracted features
still suffer from many irrelevant and noisy features that restrict severely the
performance of the approaches. In this paper, we propose a novel model based on
Adversarial Networks and inspirited by the Shared-Private model (ANSP), which
aims at reducing common, irrelevant features from the extracted features for
information credibility evaluation. Specifically, ANSP involves two tasks: one
is to prevent the binary classification of true and false information for
capturing common features relying on adversarial networks guided by
reinforcement learning. Another extracts credibility features (henceforth,
private features) from multiple types of credibility information and compares
with the common features through two strategies, i.e., orthogonality
constraints and KL-divergence for making the private features more
differential. Experiments first on two six-label LIAR and Weibo datasets
demonstrate that ANSP achieves the state-of-the-art performance, boosting the
accuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate
the robustness of the model with 1.8% performance improvements.",Information Sciences,,,cs.CY,"['cs.CY', 'cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1909.07523v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.07523v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.07523v1,"{'id': 'http://arxiv.org/abs/1909.07523v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.07523v1', 'updated': '2019-09-16T23:53:59Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=16, tm_hour=23, tm_min=53, tm_sec=59, tm_wday=0, tm_yday=259, tm_isdst=0), 'published': '2019-09-16T23:53:59Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=16, tm_hour=23, tm_min=53, tm_sec=59, tm_wday=0, tm_yday=259, tm_isdst=0), 'title': 'Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation'}, 'summary': 'A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.'}, 'authors': [{'name': 'Lianwei Wu'}, {'name': 'Yuan Rao'}, {'name': 'Ambreen Nazir'}, {'name': 'Haolin Jin'}], 'author_detail': {'name': 'Haolin Jin'}, 'author': 'Haolin Jin', 'arxiv_comment': 'Information Sciences', 'links': [{'href': 'http://arxiv.org/abs/1909.07523v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.07523v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
290,http://arxiv.org/abs/1909.12233v1,2019-09-13 13:39:59+00:00,2019-09-13 13:39:59+00:00,Deep Ensemble Learning for News Stance Detection,"[arxiv.Result.Author('Wenjun Liao'), arxiv.Result.Author('Chenghua Lin')]","Stance detection in fake news is an important component in news veracity
assessment because this process helps fact-checking by understanding stance to
a central claim from different information sources. The Fake News Challenge
Stage 1 (FNC-1) held in 2017 was setup for this purpose, which involves
estimating the stance of a news article body relative to a given headline. This
thesis starts from the error analysis for the three top-performing systems in
FNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron
system is chosen as the baseline. Afterwards, three approaches are explored to
improve baseline.The first approach explores the possibility of improving the
prediction accuracy by adding extra keywords features when training a model,
where keywords are converted to an indicator vector and then concatenated to
the baseline features. A list of keywords is manually selected based on the
error analysis, which may best reflect some characteristics of fake news titles
and bodies. To make this selection process automatically, three algorithms are
created based on Mutual Information (MI) theory: keywords generator based on MI
stance class, MI customised class, and Pointwise MI algorithm. The second
approach is based on word embedding, where word2vec model is introduced and two
document similarities calculation algorithms are implemented: wor2vec cosine
similarity and WMD distance. The third approach is ensemble learning. Different
models are configured together with two continuous outputs combining
algorithms. The 10-fold cross validation reveals that the ensemble of three
neural network models trained from simple bag-of-words features gives the best
performance. It is therefore selected to compete in FNC-1. After
hyperparameters fine tuning, the selected deep ensemble model beats the FNC-1
winner team by a remarkable 34.25 marks under FNC-1's evaluation metric.",Poster presenataion of 5th IC2S2 in University of Amsterdam,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1909.12233v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.12233v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.12233v1,"{'id': 'http://arxiv.org/abs/1909.12233v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.12233v1', 'updated': '2019-09-13T13:39:59Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=13, tm_hour=13, tm_min=39, tm_sec=59, tm_wday=4, tm_yday=256, tm_isdst=0), 'published': '2019-09-13T13:39:59Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=13, tm_hour=13, tm_min=39, tm_sec=59, tm_wday=4, tm_yday=256, tm_isdst=0), 'title': 'Deep Ensemble Learning for News Stance Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deep Ensemble Learning for News Stance Detection'}, 'summary': ""Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric.""}, 'authors': [{'name': 'Wenjun Liao'}, {'name': 'Chenghua Lin'}], 'author_detail': {'name': 'Chenghua Lin'}, 'author': 'Chenghua Lin', 'arxiv_comment': 'Poster presenataion of 5th IC2S2 in University of Amsterdam', 'links': [{'href': 'http://arxiv.org/abs/1909.12233v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.12233v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
291,http://arxiv.org/abs/1909.01720v1,2019-09-04 12:15:02+00:00,2019-09-04 12:15:02+00:00,Different Absorption from the Same Sharing: Sifted Multi-task Learning for Fake News Detection,"[arxiv.Result.Author('Lianwei Wu'), arxiv.Result.Author('Yuan Rao'), arxiv.Result.Author('Haolin Jin'), arxiv.Result.Author('Ambreen Nazir'), arxiv.Result.Author('Ling Sun')]","Recently, neural networks based on multi-task learning have achieved
promising performance on fake news detection, which focus on learning shared
features among tasks as complementary features to serve different tasks.
However, in most of the existing approaches, the shared features are completely
assigned to different tasks without selection, which may lead to some useless
and even adverse features integrated into specific tasks. In this paper, we
design a sifted multi-task learning method with a selected sharing layer for
fake news detection. The selected sharing layer adopts gate mechanism and
attention mechanism to filter and select shared feature flows between tasks.
Experiments on two public and widely used competition datasets, i.e. RumourEval
and PHEME, demonstrate that our proposed method achieves the state-of-the-art
performance and boosts the F1-score by more than 0.87%, 1.31%, respectively.","10 pages, 5 figures, EMNLP 2019",,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1909.01720v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.01720v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.01720v1,"{'id': 'http://arxiv.org/abs/1909.01720v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.01720v1', 'updated': '2019-09-04T12:15:02Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=12, tm_min=15, tm_sec=2, tm_wday=2, tm_yday=247, tm_isdst=0), 'published': '2019-09-04T12:15:02Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=12, tm_min=15, tm_sec=2, tm_wday=2, tm_yday=247, tm_isdst=0), 'title': 'Different Absorption from the Same Sharing: Sifted Multi-task Learning\n  for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Different Absorption from the Same Sharing: Sifted Multi-task Learning\n  for Fake News Detection'}, 'summary': 'Recently, neural networks based on multi-task learning have achieved\npromising performance on fake news detection, which focus on learning shared\nfeatures among tasks as complementary features to serve different tasks.\nHowever, in most of the existing approaches, the shared features are completely\nassigned to different tasks without selection, which may lead to some useless\nand even adverse features integrated into specific tasks. In this paper, we\ndesign a sifted multi-task learning method with a selected sharing layer for\nfake news detection. The selected sharing layer adopts gate mechanism and\nattention mechanism to filter and select shared feature flows between tasks.\nExperiments on two public and widely used competition datasets, i.e. RumourEval\nand PHEME, demonstrate that our proposed method achieves the state-of-the-art\nperformance and boosts the F1-score by more than 0.87%, 1.31%, respectively.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, neural networks based on multi-task learning have achieved\npromising performance on fake news detection, which focus on learning shared\nfeatures among tasks as complementary features to serve different tasks.\nHowever, in most of the existing approaches, the shared features are completely\nassigned to different tasks without selection, which may lead to some useless\nand even adverse features integrated into specific tasks. In this paper, we\ndesign a sifted multi-task learning method with a selected sharing layer for\nfake news detection. The selected sharing layer adopts gate mechanism and\nattention mechanism to filter and select shared feature flows between tasks.\nExperiments on two public and widely used competition datasets, i.e. RumourEval\nand PHEME, demonstrate that our proposed method achieves the state-of-the-art\nperformance and boosts the F1-score by more than 0.87%, 1.31%, respectively.'}, 'authors': [{'name': 'Lianwei Wu'}, {'name': 'Yuan Rao'}, {'name': 'Haolin Jin'}, {'name': 'Ambreen Nazir'}, {'name': 'Ling Sun'}], 'author_detail': {'name': 'Ling Sun'}, 'author': 'Ling Sun', 'arxiv_comment': '10 pages, 5 figures, EMNLP 2019', 'links': [{'href': 'http://arxiv.org/abs/1909.01720v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.01720v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
292,http://arxiv.org/abs/1909.01681v1,2019-09-04 10:30:03+00:00,2019-09-04 10:30:03+00:00,Under the Conditions of Non-Agenda Ownership: Social Media Users in the 2019 Ukrainian Presidential Elections Campaign,"[arxiv.Result.Author('Artem Zakharchenko'), arxiv.Result.Author('Yuliia Maksimtsova'), arxiv.Result.Author('Valentyn Iurchenko'), arxiv.Result.Author('Viktoriya Shevchenko'), arxiv.Result.Author('Solomiia Fedushko')]","Owing to its history and challenging circumstances, social networks community
in Ukraine is a very interesting polygon for the study of communications in the
constantly changing environment, especially in the political discourse. This
unique environment requires three dimensions to ascertain the political
position of its participant. But 2019 presidential elections made this object
even more spectacular. The winner of elections comedian Volodymyr Zelenskyi
reached 73% of votes without any issue ownership, with empty agenda, and this
influenced the electoral content of social networks and their authors behavior.
We saw, that the issue ownership by other candidates succeeds in making their
issues more salient in social networks. But the new phenomena, the non-agenda
ownership, overcome any ideological influence, especially under the conditions
of punishment mechanism applied to old politicians. Analyzing social media
content and users behavior in the period between two rounds of elections, we
found considerable overlaps between this campaign and the 2016 Trump campaign.
We approved the widespread of filter bubbles, negative campaign messages, fake
news and conspiracy theories. Active and powerful core of Ukrainian Facebook
that was responsible for the Revolution of dignity now became less significant
and even turns into the huge filter bubble of active people. We also proved
that manipulations and fake news in the environment of private groups may be as
much powerful as in a case of classical communication based around the opinion
leaders.","21 pages, 8 figures","CEUR Workshop Proceedings. Vol 2392: Proceedings of the 1st
  International Workshop on Control, Optimisation and Analytical Processing of
  Social Networks, COAPSN-2019, 2019",,cs.CY,"['cs.CY', 'cs.CR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1909.01681v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.01681v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.01681v1,"{'id': 'http://arxiv.org/abs/1909.01681v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.01681v1', 'updated': '2019-09-04T10:30:03Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=10, tm_min=30, tm_sec=3, tm_wday=2, tm_yday=247, tm_isdst=0), 'published': '2019-09-04T10:30:03Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=10, tm_min=30, tm_sec=3, tm_wday=2, tm_yday=247, tm_isdst=0), 'title': 'Under the Conditions of Non-Agenda Ownership: Social Media Users in the\n  2019 Ukrainian Presidential Elections Campaign', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Under the Conditions of Non-Agenda Ownership: Social Media Users in the\n  2019 Ukrainian Presidential Elections Campaign'}, 'summary': 'Owing to its history and challenging circumstances, social networks community\nin Ukraine is a very interesting polygon for the study of communications in the\nconstantly changing environment, especially in the political discourse. This\nunique environment requires three dimensions to ascertain the political\nposition of its participant. But 2019 presidential elections made this object\neven more spectacular. The winner of elections comedian Volodymyr Zelenskyi\nreached 73% of votes without any issue ownership, with empty agenda, and this\ninfluenced the electoral content of social networks and their authors behavior.\nWe saw, that the issue ownership by other candidates succeeds in making their\nissues more salient in social networks. But the new phenomena, the non-agenda\nownership, overcome any ideological influence, especially under the conditions\nof punishment mechanism applied to old politicians. Analyzing social media\ncontent and users behavior in the period between two rounds of elections, we\nfound considerable overlaps between this campaign and the 2016 Trump campaign.\nWe approved the widespread of filter bubbles, negative campaign messages, fake\nnews and conspiracy theories. Active and powerful core of Ukrainian Facebook\nthat was responsible for the Revolution of dignity now became less significant\nand even turns into the huge filter bubble of active people. We also proved\nthat manipulations and fake news in the environment of private groups may be as\nmuch powerful as in a case of classical communication based around the opinion\nleaders.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Owing to its history and challenging circumstances, social networks community\nin Ukraine is a very interesting polygon for the study of communications in the\nconstantly changing environment, especially in the political discourse. This\nunique environment requires three dimensions to ascertain the political\nposition of its participant. But 2019 presidential elections made this object\neven more spectacular. The winner of elections comedian Volodymyr Zelenskyi\nreached 73% of votes without any issue ownership, with empty agenda, and this\ninfluenced the electoral content of social networks and their authors behavior.\nWe saw, that the issue ownership by other candidates succeeds in making their\nissues more salient in social networks. But the new phenomena, the non-agenda\nownership, overcome any ideological influence, especially under the conditions\nof punishment mechanism applied to old politicians. Analyzing social media\ncontent and users behavior in the period between two rounds of elections, we\nfound considerable overlaps between this campaign and the 2016 Trump campaign.\nWe approved the widespread of filter bubbles, negative campaign messages, fake\nnews and conspiracy theories. Active and powerful core of Ukrainian Facebook\nthat was responsible for the Revolution of dignity now became less significant\nand even turns into the huge filter bubble of active people. We also proved\nthat manipulations and fake news in the environment of private groups may be as\nmuch powerful as in a case of classical communication based around the opinion\nleaders.'}, 'authors': [{'name': 'Artem Zakharchenko'}, {'name': 'Yuliia Maksimtsova'}, {'name': 'Valentyn Iurchenko'}, {'name': 'Viktoriya Shevchenko'}, {'name': 'Solomiia Fedushko'}], 'author_detail': {'name': 'Solomiia Fedushko'}, 'author': 'Solomiia Fedushko', 'arxiv_comment': '21 pages, 8 figures', 'arxiv_journal_ref': 'CEUR Workshop Proceedings. Vol 2392: Proceedings of the 1st\n  International Workshop on Control, Optimisation and Analytical Processing of\n  Social Networks, COAPSN-2019, 2019', 'links': [{'href': 'http://arxiv.org/abs/1909.01681v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.01681v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
293,http://arxiv.org/abs/1909.00530v2,2019-09-04 02:50:01+00:00,2019-09-02 03:47:57+00:00,Burning Two Worlds: Algorithms for Burning Dense and Tree-like Graphs,"[arxiv.Result.Author('Shahin Kamali'), arxiv.Result.Author('Avery Miller'), arxiv.Result.Author('Kenny Zhang')]","Graph burning is a simple model for the spread of social influence in
networks. The objective is to measure how quickly a fire (e.g., a piece of fake
news) can be spread in a network. The burning process takes place in discrete
rounds. In each round, a new fire breaks out at a selected vertex and burns it.
Meanwhile, the old fires extend to their neighbours and burn them. A burning
schedule selects where the new fire breaks out in each round, and the burning
problem asks for a schedule that burns all vertices in a minimum number of
rounds, termed the burning number of the graph. The burning problem is known to
be NP-hard even when the graph is a tree or a disjoint set of paths. For
connected graphs, it has been conjectured that burning takes at most $\lceil
\sqrt{n} \rceil$ rounds.
  We approach the algorithmic study of graph burning from two directions.
First, we consider graphs with minimum degree $\delta$. We present an algorithm
that burns any graph of size $n$ in at most $\sqrt{\frac{24n}{\delta+1}}$
rounds. In particular, for dense graphs with $\delta \in \Theta(n)$, all
vertices are burned in a constant number of rounds. More interestingly, even
when $\delta$ is a constant that is independent of the graph size, our
algorithm answers the graph-burning conjecture in the affirmative by burning
the graph in at most $\lceil \sqrt{n} \rceil$ rounds. Next, we consider burning
graphs with bounded path-length or tree-length. These include many graph
families including connected interval graphs and connected chordal graphs. We
show that any graph with path-length $pl$ and diameter $d$ can be burned in
$\lceil \sqrt{d-1} \rceil + pl$ rounds. Our algorithm ensures an approximation
ratio of $1+o(1)$ for graphs of bounded path-length. We introduce another
algorithm that achieves an approximation ratio of $2+o(1)$ for burning graphs
of bounded tree-length.",,,,math.CO,"['math.CO', 'cs.DS']","[arxiv.Result.Link('http://arxiv.org/abs/1909.00530v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.00530v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.00530v2,"{'id': 'http://arxiv.org/abs/1909.00530v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.00530v2', 'updated': '2019-09-04T02:50:01Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=2, tm_min=50, tm_sec=1, tm_wday=2, tm_yday=247, tm_isdst=0), 'published': '2019-09-02T03:47:57Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=2, tm_hour=3, tm_min=47, tm_sec=57, tm_wday=0, tm_yday=245, tm_isdst=0), 'title': 'Burning Two Worlds: Algorithms for Burning Dense and Tree-like Graphs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Burning Two Worlds: Algorithms for Burning Dense and Tree-like Graphs'}, 'summary': 'Graph burning is a simple model for the spread of social influence in\nnetworks. The objective is to measure how quickly a fire (e.g., a piece of fake\nnews) can be spread in a network. The burning process takes place in discrete\nrounds. In each round, a new fire breaks out at a selected vertex and burns it.\nMeanwhile, the old fires extend to their neighbours and burn them. A burning\nschedule selects where the new fire breaks out in each round, and the burning\nproblem asks for a schedule that burns all vertices in a minimum number of\nrounds, termed the burning number of the graph. The burning problem is known to\nbe NP-hard even when the graph is a tree or a disjoint set of paths. For\nconnected graphs, it has been conjectured that burning takes at most $\\lceil\n\\sqrt{n} \\rceil$ rounds.\n  We approach the algorithmic study of graph burning from two directions.\nFirst, we consider graphs with minimum degree $\\delta$. We present an algorithm\nthat burns any graph of size $n$ in at most $\\sqrt{\\frac{24n}{\\delta+1}}$\nrounds. In particular, for dense graphs with $\\delta \\in \\Theta(n)$, all\nvertices are burned in a constant number of rounds. More interestingly, even\nwhen $\\delta$ is a constant that is independent of the graph size, our\nalgorithm answers the graph-burning conjecture in the affirmative by burning\nthe graph in at most $\\lceil \\sqrt{n} \\rceil$ rounds. Next, we consider burning\ngraphs with bounded path-length or tree-length. These include many graph\nfamilies including connected interval graphs and connected chordal graphs. We\nshow that any graph with path-length $pl$ and diameter $d$ can be burned in\n$\\lceil \\sqrt{d-1} \\rceil + pl$ rounds. Our algorithm ensures an approximation\nratio of $1+o(1)$ for graphs of bounded path-length. We introduce another\nalgorithm that achieves an approximation ratio of $2+o(1)$ for burning graphs\nof bounded tree-length.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Graph burning is a simple model for the spread of social influence in\nnetworks. The objective is to measure how quickly a fire (e.g., a piece of fake\nnews) can be spread in a network. The burning process takes place in discrete\nrounds. In each round, a new fire breaks out at a selected vertex and burns it.\nMeanwhile, the old fires extend to their neighbours and burn them. A burning\nschedule selects where the new fire breaks out in each round, and the burning\nproblem asks for a schedule that burns all vertices in a minimum number of\nrounds, termed the burning number of the graph. The burning problem is known to\nbe NP-hard even when the graph is a tree or a disjoint set of paths. For\nconnected graphs, it has been conjectured that burning takes at most $\\lceil\n\\sqrt{n} \\rceil$ rounds.\n  We approach the algorithmic study of graph burning from two directions.\nFirst, we consider graphs with minimum degree $\\delta$. We present an algorithm\nthat burns any graph of size $n$ in at most $\\sqrt{\\frac{24n}{\\delta+1}}$\nrounds. In particular, for dense graphs with $\\delta \\in \\Theta(n)$, all\nvertices are burned in a constant number of rounds. More interestingly, even\nwhen $\\delta$ is a constant that is independent of the graph size, our\nalgorithm answers the graph-burning conjecture in the affirmative by burning\nthe graph in at most $\\lceil \\sqrt{n} \\rceil$ rounds. Next, we consider burning\ngraphs with bounded path-length or tree-length. These include many graph\nfamilies including connected interval graphs and connected chordal graphs. We\nshow that any graph with path-length $pl$ and diameter $d$ can be burned in\n$\\lceil \\sqrt{d-1} \\rceil + pl$ rounds. Our algorithm ensures an approximation\nratio of $1+o(1)$ for graphs of bounded path-length. We introduce another\nalgorithm that achieves an approximation ratio of $2+o(1)$ for burning graphs\nof bounded tree-length.'}, 'authors': [{'name': 'Shahin Kamali'}, {'name': 'Avery Miller'}, {'name': 'Kenny Zhang'}], 'author_detail': {'name': 'Kenny Zhang'}, 'author': 'Kenny Zhang', 'links': [{'href': 'http://arxiv.org/abs/1909.00530v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.00530v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'math.CO', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
294,http://arxiv.org/abs/1908.11722v1,2019-08-30 13:12:21+00:00,2019-08-30 13:12:21+00:00,Fact-Checking Meets Fauxtography: Verifying Claims About Images,"[arxiv.Result.Author('Dimitrina Zlatkova'), arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Ivan Koychev')]","The recent explosion of false claims in social media and on the Web in
general has given rise to a lot of manual fact-checking initiatives.
Unfortunately, the number of claims that need to be fact-checked is several
orders of magnitude larger than what humans can handle manually. Thus, there
has been a lot of research aiming at automating the process. Interestingly,
previous work has largely ignored the growing number of claims about images.
This is despite the fact that visual imagery is more influential than text and
naturally appears alongside fake news. Here we aim at bridging this gap. In
particular, we create a new dataset for this problem, and we explore a variety
of features modeling the claim, the image, and the relationship between the
claim and the image. The evaluation results show sizable improvements over the
baseline. We release our dataset, hoping to enable further research on
fact-checking claims about images.",Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News,EMNLP-2019,,cs.CL,"['cs.CL', 'cs.AI', 'cs.CV', 'cs.IR', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1908.11722v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.11722v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.11722v1,"{'id': 'http://arxiv.org/abs/1908.11722v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.11722v1', 'updated': '2019-08-30T13:12:21Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=30, tm_hour=13, tm_min=12, tm_sec=21, tm_wday=4, tm_yday=242, tm_isdst=0), 'published': '2019-08-30T13:12:21Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=30, tm_hour=13, tm_min=12, tm_sec=21, tm_wday=4, tm_yday=242, tm_isdst=0), 'title': 'Fact-Checking Meets Fauxtography: Verifying Claims About Images', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact-Checking Meets Fauxtography: Verifying Claims About Images'}, 'summary': 'The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.'}, 'authors': [{'name': 'Dimitrina Zlatkova'}, {'name': 'Preslav Nakov'}, {'name': 'Ivan Koychev'}], 'author_detail': {'name': 'Ivan Koychev'}, 'author': 'Ivan Koychev', 'arxiv_comment': 'Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News', 'arxiv_journal_ref': 'EMNLP-2019', 'links': [{'href': 'http://arxiv.org/abs/1908.11722v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.11722v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
295,http://arxiv.org/abs/1908.09951v1,2019-08-26 22:49:35+00:00,2019-08-26 22:49:35+00:00,An Emotional Analysis of False Information in Social Media and News Articles,"[arxiv.Result.Author('Bilal Ghanem'), arxiv.Result.Author('Paolo Rosso'), arxiv.Result.Author('Francisco Rangel')]","Fake news is risky since it has been created to manipulate the readers'
opinions and beliefs. In this work, we compared the language of false news to
the real one of real news from an emotional perspective, considering a set of
false information types (propaganda, hoax, clickbait, and satire) from social
media and online news articles sources. Our experiments showed that false
information has different emotional patterns in each of its types, and emotions
play a key role in deceiving the reader. Based on that, we proposed a LSTM
neural network model that is emotionally-infused to detect false news.",,,,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1908.09951v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.09951v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.09951v1,"{'id': 'http://arxiv.org/abs/1908.09951v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.09951v1', 'updated': '2019-08-26T22:49:35Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=26, tm_hour=22, tm_min=49, tm_sec=35, tm_wday=0, tm_yday=238, tm_isdst=0), 'published': '2019-08-26T22:49:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=26, tm_hour=22, tm_min=49, tm_sec=35, tm_wday=0, tm_yday=238, tm_isdst=0), 'title': 'An Emotional Analysis of False Information in Social Media and News\n  Articles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Emotional Analysis of False Information in Social Media and News\n  Articles'}, 'summary': ""Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.""}, 'authors': [{'name': 'Bilal Ghanem'}, {'name': 'Paolo Rosso'}, {'name': 'Francisco Rangel'}], 'author_detail': {'name': 'Francisco Rangel'}, 'author': 'Francisco Rangel', 'links': [{'href': 'http://arxiv.org/abs/1908.09951v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.09951v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
296,http://arxiv.org/abs/1908.09805v2,2020-02-20 18:32:33+00:00,2019-08-26 17:23:22+00:00,The Limitations of Stylometry for Detecting Machine-Generated Fake News,"[arxiv.Result.Author('Tal Schuster'), arxiv.Result.Author('Roei Schuster'), arxiv.Result.Author('Darsh J Shah'), arxiv.Result.Author('Regina Barzilay')]","Recent developments in neural language models (LMs) have raised concerns
about their potential misuse for automatically spreading misinformation. In
light of these concerns, several studies have proposed to detect
machine-generated fake news by capturing their stylistic differences from
human-written text. These approaches, broadly termed stylometry, have found
success in source attribution and misinformation detection in human-written
texts. However, in this work, we show that stylometry is limited against
machine-generated misinformation. While humans speak differently when trying to
deceive, LMs generate stylistically consistent text, regardless of underlying
motive. Thus, though stylometry can successfully prevent impersonation by
identifying text provenance, it fails to distinguish legitimate LM applications
from those that introduce false information. We create two benchmarks
demonstrating the stylistic similarity between malicious and legitimate uses of
LMs, employed in auto-completion and editing-assistance settings. Our findings
highlight the need for non-stylometry approaches in detecting machine-generated
misinformation, and open up the discussion on the desired evaluation
benchmarks.","Accepted for Computational Linguistics journal (squib). Previously
  posted with title ""Are We Safe Yet? The Limitations of Distributional
  Features for Fake News Detection""",,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1908.09805v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.09805v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.09805v2,"{'id': 'http://arxiv.org/abs/1908.09805v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.09805v2', 'updated': '2020-02-20T18:32:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=32, tm_sec=33, tm_wday=3, tm_yday=51, tm_isdst=0), 'published': '2019-08-26T17:23:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=26, tm_hour=17, tm_min=23, tm_sec=22, tm_wday=0, tm_yday=238, tm_isdst=0), 'title': 'The Limitations of Stylometry for Detecting Machine-Generated Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Limitations of Stylometry for Detecting Machine-Generated Fake News'}, 'summary': 'Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.'}, 'authors': [{'name': 'Tal Schuster'}, {'name': 'Roei Schuster'}, {'name': 'Darsh J Shah'}, {'name': 'Regina Barzilay'}], 'author_detail': {'name': 'Regina Barzilay'}, 'author': 'Regina Barzilay', 'arxiv_comment': 'Accepted for Computational Linguistics journal (squib). Previously\n  posted with title ""Are We Safe Yet? The Limitations of Distributional\n  Features for Fake News Detection""', 'links': [{'href': 'http://arxiv.org/abs/1908.09805v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.09805v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
297,http://arxiv.org/abs/1908.04472v1,2019-08-13 03:19:46+00:00,2019-08-13 03:19:46+00:00,Exploiting Multi-domain Visual Information for Fake News Detection,"[arxiv.Result.Author('Peng Qi'), arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('Tianyun Yang'), arxiv.Result.Author('Junbo Guo'), arxiv.Result.Author('Jintao Li')]","The increasing popularity of social media promotes the proliferation of fake
news. With the development of multimedia technology, fake news attempts to
utilize multimedia contents with images or videos to attract and mislead
readers for rapid dissemination, which makes visual contents an important part
of fake news. Fake-news images, images attached in fake news posts,include not
only fake images which are maliciously tampered but also real images which are
wrongly used to represent irrelevant events. Hence, how to fully exploit the
inherent characteristics of fake-news images is an important but challenging
problem for fake news detection. In the real world, fake-news images may have
significantly different characteristics from real-news images at both physical
and semantic levels, which can be clearly reflected in the frequency and pixel
domain, respectively. Therefore, we propose a novel framework Multi-domain
Visual Neural Network (MVNN) to fuse the visual information of frequency and
pixel domains for detecting fake news. Specifically, we design a CNN-based
network to automatically capture the complex patterns of fake-news images in
the frequency domain; and utilize a multi-branch CNN-RNN model to extract
visual features from different semantic levels in the pixel domain. An
attention mechanism is utilized to fuse the feature representations of
frequency and pixel domains dynamically. Extensive experiments conducted on a
real-world dataset demonstrate that MVNN outperforms existing methods with at
least 9.2% in accuracy, and can help improve the performance of multimodal fake
news detection by over 5.2%.","10 pages, 9 figures, conference",,,cs.MM,"['cs.MM', 'cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1908.04472v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.04472v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.04472v1,"{'id': 'http://arxiv.org/abs/1908.04472v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.04472v1', 'updated': '2019-08-13T03:19:46Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=13, tm_hour=3, tm_min=19, tm_sec=46, tm_wday=1, tm_yday=225, tm_isdst=0), 'published': '2019-08-13T03:19:46Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=13, tm_hour=3, tm_min=19, tm_sec=46, tm_wday=1, tm_yday=225, tm_isdst=0), 'title': 'Exploiting Multi-domain Visual Information for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploiting Multi-domain Visual Information for Fake News Detection'}, 'summary': 'The increasing popularity of social media promotes the proliferation of fake\nnews. With the development of multimedia technology, fake news attempts to\nutilize multimedia contents with images or videos to attract and mislead\nreaders for rapid dissemination, which makes visual contents an important part\nof fake news. Fake-news images, images attached in fake news posts,include not\nonly fake images which are maliciously tampered but also real images which are\nwrongly used to represent irrelevant events. Hence, how to fully exploit the\ninherent characteristics of fake-news images is an important but challenging\nproblem for fake news detection. In the real world, fake-news images may have\nsignificantly different characteristics from real-news images at both physical\nand semantic levels, which can be clearly reflected in the frequency and pixel\ndomain, respectively. Therefore, we propose a novel framework Multi-domain\nVisual Neural Network (MVNN) to fuse the visual information of frequency and\npixel domains for detecting fake news. Specifically, we design a CNN-based\nnetwork to automatically capture the complex patterns of fake-news images in\nthe frequency domain; and utilize a multi-branch CNN-RNN model to extract\nvisual features from different semantic levels in the pixel domain. An\nattention mechanism is utilized to fuse the feature representations of\nfrequency and pixel domains dynamically. Extensive experiments conducted on a\nreal-world dataset demonstrate that MVNN outperforms existing methods with at\nleast 9.2% in accuracy, and can help improve the performance of multimodal fake\nnews detection by over 5.2%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The increasing popularity of social media promotes the proliferation of fake\nnews. With the development of multimedia technology, fake news attempts to\nutilize multimedia contents with images or videos to attract and mislead\nreaders for rapid dissemination, which makes visual contents an important part\nof fake news. Fake-news images, images attached in fake news posts,include not\nonly fake images which are maliciously tampered but also real images which are\nwrongly used to represent irrelevant events. Hence, how to fully exploit the\ninherent characteristics of fake-news images is an important but challenging\nproblem for fake news detection. In the real world, fake-news images may have\nsignificantly different characteristics from real-news images at both physical\nand semantic levels, which can be clearly reflected in the frequency and pixel\ndomain, respectively. Therefore, we propose a novel framework Multi-domain\nVisual Neural Network (MVNN) to fuse the visual information of frequency and\npixel domains for detecting fake news. Specifically, we design a CNN-based\nnetwork to automatically capture the complex patterns of fake-news images in\nthe frequency domain; and utilize a multi-branch CNN-RNN model to extract\nvisual features from different semantic levels in the pixel domain. An\nattention mechanism is utilized to fuse the feature representations of\nfrequency and pixel domains dynamically. Extensive experiments conducted on a\nreal-world dataset demonstrate that MVNN outperforms existing methods with at\nleast 9.2% in accuracy, and can help improve the performance of multimodal fake\nnews detection by over 5.2%.'}, 'authors': [{'name': 'Peng Qi'}, {'name': 'Juan Cao'}, {'name': 'Tianyun Yang'}, {'name': 'Junbo Guo'}, {'name': 'Jintao Li'}], 'author_detail': {'name': 'Jintao Li'}, 'author': 'Jintao Li', 'arxiv_comment': '10 pages, 9 figures, conference', 'links': [{'href': 'http://arxiv.org/abs/1908.04472v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.04472v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
298,http://arxiv.org/abs/1908.03957v1,2019-08-11 19:51:48+00:00,2019-08-11 19:51:48+00:00,Tensor Factorization with Label Information for Fake News Detection,"[arxiv.Result.Author('Frosso Papanastasiou'), arxiv.Result.Author('Georgios Katsimpras'), arxiv.Result.Author('Georgios Paliouras')]","The buzz over the so-called ""fake news"" has created concerns about a
degenerated media environment and led to the need for technological solutions.
As the detection of fake news is increasingly considered a technological
problem, it has attracted considerable research. Most of these studies
primarily focus on utilizing information extracted from textual news content.
In contrast, we focus on detecting fake news solely based on structural
information of social networks. We suggest that the underlying network
connections of users that share fake news are discriminative enough to support
the detection of fake news. Thereupon, we model each post as a network of
friendship interactions and represent a collection of posts as a
multidimensional tensor. Taking into account the available labeled data, we
propose a tensor factorization method which associates the class labels of data
samples with their latent representations. Specifically, we combine a
classification error term with the standard factorization in a unified
optimization process. Results on real-world datasets demonstrate that our
proposed method is competitive against state-of-the-art methods by implementing
an arguably simpler approach.","Presented at the Workshop on Reducing Online Misinformation Exposure
  ROME 2019",,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1908.03957v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.03957v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.03957v1,"{'id': 'http://arxiv.org/abs/1908.03957v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.03957v1', 'updated': '2019-08-11T19:51:48Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=11, tm_hour=19, tm_min=51, tm_sec=48, tm_wday=6, tm_yday=223, tm_isdst=0), 'published': '2019-08-11T19:51:48Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=11, tm_hour=19, tm_min=51, tm_sec=48, tm_wday=6, tm_yday=223, tm_isdst=0), 'title': 'Tensor Factorization with Label Information for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tensor Factorization with Label Information for Fake News Detection'}, 'summary': 'The buzz over the so-called ""fake news"" has created concerns about a\ndegenerated media environment and led to the need for technological solutions.\nAs the detection of fake news is increasingly considered a technological\nproblem, it has attracted considerable research. Most of these studies\nprimarily focus on utilizing information extracted from textual news content.\nIn contrast, we focus on detecting fake news solely based on structural\ninformation of social networks. We suggest that the underlying network\nconnections of users that share fake news are discriminative enough to support\nthe detection of fake news. Thereupon, we model each post as a network of\nfriendship interactions and represent a collection of posts as a\nmultidimensional tensor. Taking into account the available labeled data, we\npropose a tensor factorization method which associates the class labels of data\nsamples with their latent representations. Specifically, we combine a\nclassification error term with the standard factorization in a unified\noptimization process. Results on real-world datasets demonstrate that our\nproposed method is competitive against state-of-the-art methods by implementing\nan arguably simpler approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The buzz over the so-called ""fake news"" has created concerns about a\ndegenerated media environment and led to the need for technological solutions.\nAs the detection of fake news is increasingly considered a technological\nproblem, it has attracted considerable research. Most of these studies\nprimarily focus on utilizing information extracted from textual news content.\nIn contrast, we focus on detecting fake news solely based on structural\ninformation of social networks. We suggest that the underlying network\nconnections of users that share fake news are discriminative enough to support\nthe detection of fake news. Thereupon, we model each post as a network of\nfriendship interactions and represent a collection of posts as a\nmultidimensional tensor. Taking into account the available labeled data, we\npropose a tensor factorization method which associates the class labels of data\nsamples with their latent representations. Specifically, we combine a\nclassification error term with the standard factorization in a unified\noptimization process. Results on real-world datasets demonstrate that our\nproposed method is competitive against state-of-the-art methods by implementing\nan arguably simpler approach.'}, 'authors': [{'name': 'Frosso Papanastasiou'}, {'name': 'Georgios Katsimpras'}, {'name': 'Georgios Paliouras'}], 'author_detail': {'name': 'Georgios Paliouras'}, 'author': 'Georgios Paliouras', 'arxiv_comment': 'Presented at the Workshop on Reducing Online Misinformation Exposure\n  ROME 2019', 'links': [{'href': 'http://arxiv.org/abs/1908.03957v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.03957v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
299,http://arxiv.org/abs/1908.01760v1,2019-08-05 17:59:44+00:00,2019-08-05 17:59:44+00:00,The Myths of Our Time: Fake News,"[arxiv.Result.Author('Vít Růžička'), arxiv.Result.Author('Eunsu Kang'), arxiv.Result.Author('David Gordon'), arxiv.Result.Author('Ankita Patel'), arxiv.Result.Author('Jacqui Fashimpaur'), arxiv.Result.Author('Manzil Zaheer')]","While the purpose of most fake news is misinformation and political
propaganda, our team sees it as a new type of myth that is created by people in
the age of internet identities and artificial intelligence. Seeking insights on
the fear and desire hidden underneath these modified or generated stories, we
use machine learning methods to generate fake articles and present them in the
form of an online news blog. This paper aims to share the details of our
pipeline and the techniques used for full generation of fake news, from dataset
collection to presentation as a media art project on the internet.","5 pages, 5 figures, in proceedings of International Symposium on
  Electronic Art 2019 (ISEA)","Proceedings of International Symposium on Electronic Art 2019
  (ISEA), pages 494-498",,cs.LG,"['cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1908.01760v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.01760v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.01760v1,"{'id': 'http://arxiv.org/abs/1908.01760v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.01760v1', 'updated': '2019-08-05T17:59:44Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=5, tm_hour=17, tm_min=59, tm_sec=44, tm_wday=0, tm_yday=217, tm_isdst=0), 'published': '2019-08-05T17:59:44Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=5, tm_hour=17, tm_min=59, tm_sec=44, tm_wday=0, tm_yday=217, tm_isdst=0), 'title': 'The Myths of Our Time: Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Myths of Our Time: Fake News'}, 'summary': 'While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.'}, 'authors': [{'name': 'Vít Růžička'}, {'name': 'Eunsu Kang'}, {'name': 'David Gordon'}, {'name': 'Ankita Patel'}, {'name': 'Jacqui Fashimpaur'}, {'name': 'Manzil Zaheer'}], 'author_detail': {'name': 'Manzil Zaheer'}, 'author': 'Manzil Zaheer', 'arxiv_comment': '5 pages, 5 figures, in proceedings of International Symposium on\n  Electronic Art 2019 (ISEA)', 'arxiv_journal_ref': 'Proceedings of International Symposium on Electronic Art 2019\n  (ISEA), pages 494-498', 'links': [{'href': 'http://arxiv.org/abs/1908.01760v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.01760v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
300,http://arxiv.org/abs/1907.07347v1,2019-07-17 06:03:17+00:00,2019-07-17 06:03:17+00:00,Fake News Detection as Natural Language Inference,"[arxiv.Result.Author('Kai-Chou Yang'), arxiv.Result.Author('Timothy Niven'), arxiv.Result.Author('Hung-Yu Kao')]","This report describes the entry by the Intelligent Knowledge Management (IKM)
Lab in the WSDM 2019 Fake News Classification challenge. We treat the task as
natural language inference (NLI). We individually train a number of the
strongest NLI models as well as BERT. We ensemble these results and retrain
with noisy labels in two stages. We analyze transitivity relations in the train
and test sets and determine a set of test cases that can be reliably classified
on this basis. The remainder of test cases are classified by our ensemble. Our
entry achieves test set accuracy of 88.063% for 3rd place in the competition.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1907.07347v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.07347v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.07347v1,"{'id': 'http://arxiv.org/abs/1907.07347v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.07347v1', 'updated': '2019-07-17T06:03:17Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=17, tm_hour=6, tm_min=3, tm_sec=17, tm_wday=2, tm_yday=198, tm_isdst=0), 'published': '2019-07-17T06:03:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=17, tm_hour=6, tm_min=3, tm_sec=17, tm_wday=2, tm_yday=198, tm_isdst=0), 'title': 'Fake News Detection as Natural Language Inference', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection as Natural Language Inference'}, 'summary': 'This report describes the entry by the Intelligent Knowledge Management (IKM)\nLab in the WSDM 2019 Fake News Classification challenge. We treat the task as\nnatural language inference (NLI). We individually train a number of the\nstrongest NLI models as well as BERT. We ensemble these results and retrain\nwith noisy labels in two stages. We analyze transitivity relations in the train\nand test sets and determine a set of test cases that can be reliably classified\non this basis. The remainder of test cases are classified by our ensemble. Our\nentry achieves test set accuracy of 88.063% for 3rd place in the competition.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This report describes the entry by the Intelligent Knowledge Management (IKM)\nLab in the WSDM 2019 Fake News Classification challenge. We treat the task as\nnatural language inference (NLI). We individually train a number of the\nstrongest NLI models as well as BERT. We ensemble these results and retrain\nwith noisy labels in two stages. We analyze transitivity relations in the train\nand test sets and determine a set of test cases that can be reliably classified\non this basis. The remainder of test cases are classified by our ensemble. Our\nentry achieves test set accuracy of 88.063% for 3rd place in the competition.'}, 'authors': [{'name': 'Kai-Chou Yang'}, {'name': 'Timothy Niven'}, {'name': 'Hung-Yu Kao'}], 'author_detail': {'name': 'Hung-Yu Kao'}, 'author': 'Hung-Yu Kao', 'links': [{'href': 'http://arxiv.org/abs/1907.07347v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.07347v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
301,http://arxiv.org/abs/1907.07759v1,2019-07-09 22:40:35+00:00,2019-07-09 22:40:35+00:00,"The Mass, Fake News, and Cognition Security","[arxiv.Result.Author('Bin Guo'), arxiv.Result.Author('Yasan Ding'), arxiv.Result.Author('Yueheng Sun'), arxiv.Result.Author('Shuai Ma'), arxiv.Result.Author('Ke Li')]","The wide spread of fake news in social networks is posing threats to social
stability, economic development and political democracy etc. Numerous studies
have explored the effective detection approaches of online fake news, while few
works study the intrinsic propagation and cognition mechanisms of fake news.
Since the development of cognitive science paves a promising way for the
prevention of fake news, we present a new research area called Cognition
Security (CogSec), which studies the potential impacts of fake news to human
cognition, ranging from misperception, untrusted knowledge acquisition,
targeted opinion/attitude formation, to biased decision making, and
investigates the effective ways for fake news debunking. CogSec is a
multidisciplinary research field that leverages knowledge from social science,
psychology, cognition science, neuroscience, AI and computer science. We first
propose related definitions to characterize CogSec and review the literature
history. We further investigate the key research challenges and techniques of
CogSec, including human-content cognition mechanism, social influence and
opinion diffusion, fake news detection and malicious bot detection. Finally, we
summarize the open issues and future research directions, such as early
detection of fake news, explainable fake news debunking, social contagion and
diffusion models of fake news, and so on.",,,,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/1907.07759v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.07759v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.07759v1,"{'id': 'http://arxiv.org/abs/1907.07759v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.07759v1', 'updated': '2019-07-09T22:40:35Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=9, tm_hour=22, tm_min=40, tm_sec=35, tm_wday=1, tm_yday=190, tm_isdst=0), 'published': '2019-07-09T22:40:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=9, tm_hour=22, tm_min=40, tm_sec=35, tm_wday=1, tm_yday=190, tm_isdst=0), 'title': 'The Mass, Fake News, and Cognition Security', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Mass, Fake News, and Cognition Security'}, 'summary': 'The wide spread of fake news in social networks is posing threats to social\nstability, economic development and political democracy etc. Numerous studies\nhave explored the effective detection approaches of online fake news, while few\nworks study the intrinsic propagation and cognition mechanisms of fake news.\nSince the development of cognitive science paves a promising way for the\nprevention of fake news, we present a new research area called Cognition\nSecurity (CogSec), which studies the potential impacts of fake news to human\ncognition, ranging from misperception, untrusted knowledge acquisition,\ntargeted opinion/attitude formation, to biased decision making, and\ninvestigates the effective ways for fake news debunking. CogSec is a\nmultidisciplinary research field that leverages knowledge from social science,\npsychology, cognition science, neuroscience, AI and computer science. We first\npropose related definitions to characterize CogSec and review the literature\nhistory. We further investigate the key research challenges and techniques of\nCogSec, including human-content cognition mechanism, social influence and\nopinion diffusion, fake news detection and malicious bot detection. Finally, we\nsummarize the open issues and future research directions, such as early\ndetection of fake news, explainable fake news debunking, social contagion and\ndiffusion models of fake news, and so on.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The wide spread of fake news in social networks is posing threats to social\nstability, economic development and political democracy etc. Numerous studies\nhave explored the effective detection approaches of online fake news, while few\nworks study the intrinsic propagation and cognition mechanisms of fake news.\nSince the development of cognitive science paves a promising way for the\nprevention of fake news, we present a new research area called Cognition\nSecurity (CogSec), which studies the potential impacts of fake news to human\ncognition, ranging from misperception, untrusted knowledge acquisition,\ntargeted opinion/attitude formation, to biased decision making, and\ninvestigates the effective ways for fake news debunking. CogSec is a\nmultidisciplinary research field that leverages knowledge from social science,\npsychology, cognition science, neuroscience, AI and computer science. We first\npropose related definitions to characterize CogSec and review the literature\nhistory. We further investigate the key research challenges and techniques of\nCogSec, including human-content cognition mechanism, social influence and\nopinion diffusion, fake news detection and malicious bot detection. Finally, we\nsummarize the open issues and future research directions, such as early\ndetection of fake news, explainable fake news debunking, social contagion and\ndiffusion models of fake news, and so on.'}, 'authors': [{'name': 'Bin Guo'}, {'name': 'Yasan Ding'}, {'name': 'Yueheng Sun'}, {'name': 'Shuai Ma'}, {'name': 'Ke Li'}], 'author_detail': {'name': 'Ke Li'}, 'author': 'Ke Li', 'links': [{'href': 'http://arxiv.org/abs/1907.07759v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.07759v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
302,http://arxiv.org/abs/1907.07757v1,2019-07-08 18:29:58+00:00,2019-07-08 18:29:58+00:00,XFake: Explainable Fake News Detector with Visualizations,"[arxiv.Result.Author('Fan Yang'), arxiv.Result.Author('Shiva K. Pentyala'), arxiv.Result.Author('Sina Mohseni'), arxiv.Result.Author('Mengnan Du'), arxiv.Result.Author('Hao Yuan'), arxiv.Result.Author('Rhema Linder'), arxiv.Result.Author('Eric D. Ragan'), arxiv.Result.Author('Shuiwang Ji'), arxiv.Result.Author('Xia Hu')]","In this demo paper, we present the XFake system, an explainable fake news
detector that assists end-users to identify news credibility. To effectively
detect and interpret the fakeness of news items, we jointly consider both
attributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT
frameworks are designed, where MIMIC is built for attribute analysis, ATTN is
for statement semantic analysis and PERT is for statement linguistic analysis.
Beyond the explanations extracted from the designed frameworks, relevant
supporting examples as well as visualization are further provided to facilitate
the interpretation. Our implemented system is demonstrated on a real-world
dataset crawled from PolitiFact, where thousands of verified political news
have been collected.","4 pages, WebConf'2019 Demo",,10.1145/3308558.3314119,cs.CY,"['cs.CY', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3308558.3314119', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1907.07757v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.07757v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.07757v1,"{'id': 'http://arxiv.org/abs/1907.07757v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.07757v1', 'updated': '2019-07-08T18:29:58Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=8, tm_hour=18, tm_min=29, tm_sec=58, tm_wday=0, tm_yday=189, tm_isdst=0), 'published': '2019-07-08T18:29:58Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=8, tm_hour=18, tm_min=29, tm_sec=58, tm_wday=0, tm_yday=189, tm_isdst=0), 'title': 'XFake: Explainable Fake News Detector with Visualizations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'XFake: Explainable Fake News Detector with Visualizations'}, 'summary': 'In this demo paper, we present the XFake system, an explainable fake news\ndetector that assists end-users to identify news credibility. To effectively\ndetect and interpret the fakeness of news items, we jointly consider both\nattributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT\nframeworks are designed, where MIMIC is built for attribute analysis, ATTN is\nfor statement semantic analysis and PERT is for statement linguistic analysis.\nBeyond the explanations extracted from the designed frameworks, relevant\nsupporting examples as well as visualization are further provided to facilitate\nthe interpretation. Our implemented system is demonstrated on a real-world\ndataset crawled from PolitiFact, where thousands of verified political news\nhave been collected.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this demo paper, we present the XFake system, an explainable fake news\ndetector that assists end-users to identify news credibility. To effectively\ndetect and interpret the fakeness of news items, we jointly consider both\nattributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT\nframeworks are designed, where MIMIC is built for attribute analysis, ATTN is\nfor statement semantic analysis and PERT is for statement linguistic analysis.\nBeyond the explanations extracted from the designed frameworks, relevant\nsupporting examples as well as visualization are further provided to facilitate\nthe interpretation. Our implemented system is demonstrated on a real-world\ndataset crawled from PolitiFact, where thousands of verified political news\nhave been collected.'}, 'authors': [{'name': 'Fan Yang'}, {'name': 'Shiva K. Pentyala'}, {'name': 'Sina Mohseni'}, {'name': 'Mengnan Du'}, {'name': 'Hao Yuan'}, {'name': 'Rhema Linder'}, {'name': 'Eric D. Ragan'}, {'name': 'Shuiwang Ji'}, {'name': 'Xia Hu'}], 'author_detail': {'name': 'Xia Hu'}, 'author': 'Xia Hu', 'arxiv_doi': '10.1145/3308558.3314119', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3308558.3314119', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1907.07757v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.07757v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""4 pages, WebConf'2019 Demo"", 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
303,http://arxiv.org/abs/1907.00498v4,2020-07-08 22:48:11+00:00,2019-06-30 23:46:30+00:00,Proof of Witness Presence: Blockchain Consensus for Augmented Democracy in Smart Cities,[arxiv.Result.Author('Evangelos Pournaras')],"Smart Cities evolve into complex and pervasive urban environments with a
citizens' mandate to meet sustainable development goals. Repositioning
democratic values of citizens' choices in these complex ecosystems has turned
out to be imperative in an era of social media filter bubbles, fake news and
opportunities for manipulating electoral results with such means. This paper
introduces a new paradigm of augmented democracy that promises actively
engaging citizens in a more informed decision-making augmented into public
urban space. The proposed concept is inspired by a digital revive of the
Ancient Agora of Athens, an arena of public discourse, a Polis where citizens
assemble to actively deliberate and collectively decide about public matters.
The core contribution of the proposed paradigm is the concept of proving
witness presence: making decision-making subject of providing secure evidence
and testifying for choices made in the physical space. This paper shows how the
challenge of proving witness presence can be tackled with blockchain consensus
to empower citizens' trust and overcome security vulnerabilities of GPS
localization. Moreover, a novel platform for collective decision-making and
crowd-sensing in urban space is introduced: Smart Agora. It is shown how
real-time collective measurements over citizens' choices can be made in a fully
decentralized and privacy-preserving way. Witness presence is tested by
deploying a decentralized system for crowd-sensing the sustainable use of
transport means. Furthermore, witness presence of cycling risk is validated
using official accident data from public authorities, which are compared
against wisdom of the crowd. The paramount role of dynamic consensus,
self-governance and ethically aligned artificial intelligence in the augmented
democracy paradigm is outlined.",,,,cs.CY,"['cs.CY', 'cs.DC']","[arxiv.Result.Link('http://arxiv.org/abs/1907.00498v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.00498v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.00498v4,"{'id': 'http://arxiv.org/abs/1907.00498v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.00498v4', 'updated': '2020-07-08T22:48:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=8, tm_hour=22, tm_min=48, tm_sec=11, tm_wday=2, tm_yday=190, tm_isdst=0), 'published': '2019-06-30T23:46:30Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=30, tm_hour=23, tm_min=46, tm_sec=30, tm_wday=6, tm_yday=181, tm_isdst=0), 'title': 'Proof of Witness Presence: Blockchain Consensus for Augmented Democracy\n  in Smart Cities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Proof of Witness Presence: Blockchain Consensus for Augmented Democracy\n  in Smart Cities'}, 'summary': ""Smart Cities evolve into complex and pervasive urban environments with a\ncitizens' mandate to meet sustainable development goals. Repositioning\ndemocratic values of citizens' choices in these complex ecosystems has turned\nout to be imperative in an era of social media filter bubbles, fake news and\nopportunities for manipulating electoral results with such means. This paper\nintroduces a new paradigm of augmented democracy that promises actively\nengaging citizens in a more informed decision-making augmented into public\nurban space. The proposed concept is inspired by a digital revive of the\nAncient Agora of Athens, an arena of public discourse, a Polis where citizens\nassemble to actively deliberate and collectively decide about public matters.\nThe core contribution of the proposed paradigm is the concept of proving\nwitness presence: making decision-making subject of providing secure evidence\nand testifying for choices made in the physical space. This paper shows how the\nchallenge of proving witness presence can be tackled with blockchain consensus\nto empower citizens' trust and overcome security vulnerabilities of GPS\nlocalization. Moreover, a novel platform for collective decision-making and\ncrowd-sensing in urban space is introduced: Smart Agora. It is shown how\nreal-time collective measurements over citizens' choices can be made in a fully\ndecentralized and privacy-preserving way. Witness presence is tested by\ndeploying a decentralized system for crowd-sensing the sustainable use of\ntransport means. Furthermore, witness presence of cycling risk is validated\nusing official accident data from public authorities, which are compared\nagainst wisdom of the crowd. The paramount role of dynamic consensus,\nself-governance and ethically aligned artificial intelligence in the augmented\ndemocracy paradigm is outlined."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Smart Cities evolve into complex and pervasive urban environments with a\ncitizens' mandate to meet sustainable development goals. Repositioning\ndemocratic values of citizens' choices in these complex ecosystems has turned\nout to be imperative in an era of social media filter bubbles, fake news and\nopportunities for manipulating electoral results with such means. This paper\nintroduces a new paradigm of augmented democracy that promises actively\nengaging citizens in a more informed decision-making augmented into public\nurban space. The proposed concept is inspired by a digital revive of the\nAncient Agora of Athens, an arena of public discourse, a Polis where citizens\nassemble to actively deliberate and collectively decide about public matters.\nThe core contribution of the proposed paradigm is the concept of proving\nwitness presence: making decision-making subject of providing secure evidence\nand testifying for choices made in the physical space. This paper shows how the\nchallenge of proving witness presence can be tackled with blockchain consensus\nto empower citizens' trust and overcome security vulnerabilities of GPS\nlocalization. Moreover, a novel platform for collective decision-making and\ncrowd-sensing in urban space is introduced: Smart Agora. It is shown how\nreal-time collective measurements over citizens' choices can be made in a fully\ndecentralized and privacy-preserving way. Witness presence is tested by\ndeploying a decentralized system for crowd-sensing the sustainable use of\ntransport means. Furthermore, witness presence of cycling risk is validated\nusing official accident data from public authorities, which are compared\nagainst wisdom of the crowd. The paramount role of dynamic consensus,\nself-governance and ethically aligned artificial intelligence in the augmented\ndemocracy paradigm is outlined.""}, 'authors': [{'name': 'Evangelos Pournaras'}], 'author_detail': {'name': 'Evangelos Pournaras'}, 'author': 'Evangelos Pournaras', 'links': [{'href': 'http://arxiv.org/abs/1907.00498v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.00498v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
304,http://arxiv.org/abs/1907.00181v1,2019-06-29 11:00:22+00:00,2019-06-29 11:00:22+00:00,Fake News Detection using Stance Classification: A Survey,"[arxiv.Result.Author('Anders Edelbo Lillie'), arxiv.Result.Author('Emil Refsgaard Middelboe')]","This paper surveys and presents recent academic work carried out within the
field of stance classification and fake news detection. Echo chambers and the
model organism problem are examples that pose challenges to acquire data with
high quality, due to opinions being polarised in microblogs. Nevertheless it is
shown that several machine learning approaches achieve promising results in
classifying stance. Some use crowd stance for fake news detection, such as the
approach in [Dungs et al., 2018] using Hidden Markov Models. Furthermore
feature engineering have significant importance in several approaches, which is
shown in [Aker et al., 2017]. This paper additionally includes a proposal of a
system implementation based on the presented survey.","19 pages, 1 figure",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.SI', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1907.00181v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.00181v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.00181v1,"{'id': 'http://arxiv.org/abs/1907.00181v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.00181v1', 'updated': '2019-06-29T11:00:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=29, tm_hour=11, tm_min=0, tm_sec=22, tm_wday=5, tm_yday=180, tm_isdst=0), 'published': '2019-06-29T11:00:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=29, tm_hour=11, tm_min=0, tm_sec=22, tm_wday=5, tm_yday=180, tm_isdst=0), 'title': 'Fake News Detection using Stance Classification: A Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection using Stance Classification: A Survey'}, 'summary': 'This paper surveys and presents recent academic work carried out within the\nfield of stance classification and fake news detection. Echo chambers and the\nmodel organism problem are examples that pose challenges to acquire data with\nhigh quality, due to opinions being polarised in microblogs. Nevertheless it is\nshown that several machine learning approaches achieve promising results in\nclassifying stance. Some use crowd stance for fake news detection, such as the\napproach in [Dungs et al., 2018] using Hidden Markov Models. Furthermore\nfeature engineering have significant importance in several approaches, which is\nshown in [Aker et al., 2017]. This paper additionally includes a proposal of a\nsystem implementation based on the presented survey.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper surveys and presents recent academic work carried out within the\nfield of stance classification and fake news detection. Echo chambers and the\nmodel organism problem are examples that pose challenges to acquire data with\nhigh quality, due to opinions being polarised in microblogs. Nevertheless it is\nshown that several machine learning approaches achieve promising results in\nclassifying stance. Some use crowd stance for fake news detection, such as the\napproach in [Dungs et al., 2018] using Hidden Markov Models. Furthermore\nfeature engineering have significant importance in several approaches, which is\nshown in [Aker et al., 2017]. This paper additionally includes a proposal of a\nsystem implementation based on the presented survey.'}, 'authors': [{'name': 'Anders Edelbo Lillie'}, {'name': 'Emil Refsgaard Middelboe'}], 'author_detail': {'name': 'Emil Refsgaard Middelboe'}, 'author': 'Emil Refsgaard Middelboe', 'arxiv_comment': '19 pages, 1 figure', 'links': [{'href': 'http://arxiv.org/abs/1907.00181v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.00181v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
305,http://arxiv.org/abs/1906.11126v2,2020-08-15 08:45:35+00:00,2019-06-26 14:33:18+00:00,On the Coherence of Fake News Articles,"[arxiv.Result.Author('Iknoor Singh'), arxiv.Result.Author('Deepak P'), arxiv.Result.Author('Anoop K')]","The generation and spread of fake news within new and online media sources is
emerging as a phenomenon of high societal significance. Combating them using
data-driven analytics has been attracting much recent scholarly interest. In
this study, we analyze the textual coherence of fake news articles vis-a-vis
legitimate ones. We develop three computational formulations of textual
coherence drawing upon the state-of-the-art methods in natural language
processing and data science. Two real-world datasets from widely different
domains which have fake/legitimate article labellings are then analyzed with
respect to textual coherence. We observe apparent differences in textual
coherence across fake and legitimate news articles, with fake news articles
consistently scoring lower on coherence as compared to legitimate news ones.
While the relative coherence shortfall of fake news articles as compared to
legitimate ones form the main observation from our study, we analyze several
aspects of the differences and outline potential avenues of further inquiry.","8th International Workshop on News Recommendation and Analytics (INRA
  2020) held in conjunction with ECML PKDD 2020 Conference",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/1906.11126v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.11126v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.11126v2,"{'id': 'http://arxiv.org/abs/1906.11126v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.11126v2', 'updated': '2020-08-15T08:45:35Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=15, tm_hour=8, tm_min=45, tm_sec=35, tm_wday=5, tm_yday=228, tm_isdst=0), 'published': '2019-06-26T14:33:18Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=26, tm_hour=14, tm_min=33, tm_sec=18, tm_wday=2, tm_yday=177, tm_isdst=0), 'title': 'On the Coherence of Fake News Articles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the Coherence of Fake News Articles'}, 'summary': 'The generation and spread of fake news within new and online media sources is\nemerging as a phenomenon of high societal significance. Combating them using\ndata-driven analytics has been attracting much recent scholarly interest. In\nthis study, we analyze the textual coherence of fake news articles vis-a-vis\nlegitimate ones. We develop three computational formulations of textual\ncoherence drawing upon the state-of-the-art methods in natural language\nprocessing and data science. Two real-world datasets from widely different\ndomains which have fake/legitimate article labellings are then analyzed with\nrespect to textual coherence. We observe apparent differences in textual\ncoherence across fake and legitimate news articles, with fake news articles\nconsistently scoring lower on coherence as compared to legitimate news ones.\nWhile the relative coherence shortfall of fake news articles as compared to\nlegitimate ones form the main observation from our study, we analyze several\naspects of the differences and outline potential avenues of further inquiry.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The generation and spread of fake news within new and online media sources is\nemerging as a phenomenon of high societal significance. Combating them using\ndata-driven analytics has been attracting much recent scholarly interest. In\nthis study, we analyze the textual coherence of fake news articles vis-a-vis\nlegitimate ones. We develop three computational formulations of textual\ncoherence drawing upon the state-of-the-art methods in natural language\nprocessing and data science. Two real-world datasets from widely different\ndomains which have fake/legitimate article labellings are then analyzed with\nrespect to textual coherence. We observe apparent differences in textual\ncoherence across fake and legitimate news articles, with fake news articles\nconsistently scoring lower on coherence as compared to legitimate news ones.\nWhile the relative coherence shortfall of fake news articles as compared to\nlegitimate ones form the main observation from our study, we analyze several\naspects of the differences and outline potential avenues of further inquiry.'}, 'authors': [{'name': 'Iknoor Singh'}, {'name': 'Deepak P'}, {'name': 'Anoop K'}], 'author_detail': {'name': 'Anoop K'}, 'author': 'Anoop K', 'arxiv_comment': '8th International Workshop on News Recommendation and Analytics (INRA\n  2020) held in conjunction with ECML PKDD 2020 Conference', 'links': [{'href': 'http://arxiv.org/abs/1906.11126v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.11126v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
306,http://arxiv.org/abs/1906.10365v4,2020-08-04 20:26:08+00:00,2019-06-25 07:47:00+00:00,Emotion Cognizance Improves Health Fake News Identification,"[arxiv.Result.Author('Anoop K'), arxiv.Result.Author('Deepak P'), arxiv.Result.Author('Lajish V L')]","Identifying misinformation is increasingly being recognized as an important
computational task with high potential social impact. Misinformation and fake
contents are injected into almost every domain of news including politics,
health, science, business, etc., among which, the fakeness in health domain
pose serious adverse effects to scare or harm the society. Misinformation
contains scientific claims or content from social media exaggerated with strong
emotion content to attract eyeballs. In this paper, we consider the utility of
the affective character of news articles for fake news identification in the
health domain and present evidence that emotion cognizant representations are
significantly more suited for the task. We outline a technique to leverage
emotion intensity lexicons to develop emotionized text representations, and
evaluate the utility of such a representation for identifying fake news
relating to health in various supervised and unsupervised scenarios. The
consistent and significant empirical gains that we observe over a range of
technique types and parameter settings establish the utility of the emotional
information in news articles, an often overlooked aspect, for the task of
misinformation identification in the health domain.","In Proceedings of 24th International Database Engineering &
  Applications Symposium (IDEAS 2020), Incheon, Korea",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1906.10365v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.10365v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.10365v4,"{'id': 'http://arxiv.org/abs/1906.10365v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.10365v4', 'updated': '2020-08-04T20:26:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=4, tm_hour=20, tm_min=26, tm_sec=8, tm_wday=1, tm_yday=217, tm_isdst=0), 'published': '2019-06-25T07:47:00Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=25, tm_hour=7, tm_min=47, tm_sec=0, tm_wday=1, tm_yday=176, tm_isdst=0), 'title': 'Emotion Cognizance Improves Health Fake News Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Emotion Cognizance Improves Health Fake News Identification'}, 'summary': 'Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.'}, 'authors': [{'name': 'Anoop K'}, {'name': 'Deepak P'}, {'name': 'Lajish V L'}], 'author_detail': {'name': 'Lajish V L'}, 'author': 'Lajish V L', 'arxiv_comment': 'In Proceedings of 24th International Database Engineering &\n  Applications Symposium (IDEAS 2020), Incheon, Korea', 'links': [{'href': 'http://arxiv.org/abs/1906.10365v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.10365v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
307,http://arxiv.org/abs/1906.08875v2,2020-06-15 22:58:41+00:00,2019-06-20 21:38:36+00:00,Measuring the engagement level in encrypted group conversations by using temporal networks,"[arxiv.Result.Author('Moshe Cotacallapa'), arxiv.Result.Author('Lilian Berton'), arxiv.Result.Author('Leonardo N. Ferreira'), arxiv.Result.Author('Marcos G. Quiles'), arxiv.Result.Author('Liang Zhao'), arxiv.Result.Author('Elbert E. N. Macau'), arxiv.Result.Author('Didier A. Vega-Oliveros')]","Chat groups are well-known for their capacity to promote viral political and
marketing campaigns, spread fake news, and create rallies by hundreds of
thousands on the streets. Also, with the increasing public awareness regarding
privacy and surveillance, many platforms have started to deploy end-to-end
encrypted protocols. In this context, the group's conversations are not
accessible in plain text or readable format by third-party organizations or
even the platform owner. Then, the main challenge that emerges is related to
getting insights from users' activity of those groups, but without accessing
the messages. Previous approaches evaluated the user engagement by assessing
user's activity, however, on limited conditions where the data is encrypted,
they cannot be applied. In this work, we present a framework for measuring the
level of engagement of group conversations and users, without reading the
messages. Our framework creates an ensemble of interaction networks that
represent the temporal evolution of the conversation, then, we apply the
proposed Engagement Index (EI) for each interval of conversations to assess
users' participation. Our results in five datasets from real-world WhatsApp
Groups indicate that, based on the EI, it is possible to identify the most
engaged users within a time interval, create rankings, and group users
according to their engagement and monitor their performance over time.","8 pages, 9 figures, IJCNN",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1906.08875v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.08875v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.08875v2,"{'id': 'http://arxiv.org/abs/1906.08875v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.08875v2', 'updated': '2020-06-15T22:58:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=15, tm_hour=22, tm_min=58, tm_sec=41, tm_wday=0, tm_yday=167, tm_isdst=0), 'published': '2019-06-20T21:38:36Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=20, tm_hour=21, tm_min=38, tm_sec=36, tm_wday=3, tm_yday=171, tm_isdst=0), 'title': 'Measuring the engagement level in encrypted group conversations by using\n  temporal networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Measuring the engagement level in encrypted group conversations by using\n  temporal networks'}, 'summary': ""Chat groups are well-known for their capacity to promote viral political and\nmarketing campaigns, spread fake news, and create rallies by hundreds of\nthousands on the streets. Also, with the increasing public awareness regarding\nprivacy and surveillance, many platforms have started to deploy end-to-end\nencrypted protocols. In this context, the group's conversations are not\naccessible in plain text or readable format by third-party organizations or\neven the platform owner. Then, the main challenge that emerges is related to\ngetting insights from users' activity of those groups, but without accessing\nthe messages. Previous approaches evaluated the user engagement by assessing\nuser's activity, however, on limited conditions where the data is encrypted,\nthey cannot be applied. In this work, we present a framework for measuring the\nlevel of engagement of group conversations and users, without reading the\nmessages. Our framework creates an ensemble of interaction networks that\nrepresent the temporal evolution of the conversation, then, we apply the\nproposed Engagement Index (EI) for each interval of conversations to assess\nusers' participation. Our results in five datasets from real-world WhatsApp\nGroups indicate that, based on the EI, it is possible to identify the most\nengaged users within a time interval, create rankings, and group users\naccording to their engagement and monitor their performance over time."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Chat groups are well-known for their capacity to promote viral political and\nmarketing campaigns, spread fake news, and create rallies by hundreds of\nthousands on the streets. Also, with the increasing public awareness regarding\nprivacy and surveillance, many platforms have started to deploy end-to-end\nencrypted protocols. In this context, the group's conversations are not\naccessible in plain text or readable format by third-party organizations or\neven the platform owner. Then, the main challenge that emerges is related to\ngetting insights from users' activity of those groups, but without accessing\nthe messages. Previous approaches evaluated the user engagement by assessing\nuser's activity, however, on limited conditions where the data is encrypted,\nthey cannot be applied. In this work, we present a framework for measuring the\nlevel of engagement of group conversations and users, without reading the\nmessages. Our framework creates an ensemble of interaction networks that\nrepresent the temporal evolution of the conversation, then, we apply the\nproposed Engagement Index (EI) for each interval of conversations to assess\nusers' participation. Our results in five datasets from real-world WhatsApp\nGroups indicate that, based on the EI, it is possible to identify the most\nengaged users within a time interval, create rankings, and group users\naccording to their engagement and monitor their performance over time.""}, 'authors': [{'name': 'Moshe Cotacallapa'}, {'name': 'Lilian Berton'}, {'name': 'Leonardo N. Ferreira'}, {'name': 'Marcos G. Quiles'}, {'name': 'Liang Zhao'}, {'name': 'Elbert E. N. Macau'}, {'name': 'Didier A. Vega-Oliveros'}], 'author_detail': {'name': 'Didier A. Vega-Oliveros'}, 'author': 'Didier A. Vega-Oliveros', 'arxiv_comment': '8 pages, 9 figures, IJCNN', 'links': [{'href': 'http://arxiv.org/abs/1906.08875v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.08875v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
308,http://arxiv.org/abs/1906.08021v1,2019-06-19 11:11:31+00:00,2019-06-19 11:11:31+00:00,Subtle Censorship via Adversarial Fakeness in Kyrgyzstan,"[arxiv.Result.Author('Christopher Schwartz'), arxiv.Result.Author('Rebekah Overdorf')]","With the shift of public discourse to social media, we see simultaneously an
expansion of civic engagement as the bar to enter the conversation is lowered,
and the reaction by both state and non-state adversaries of free speech to
silence these voices. Traditional forms of censorship struggle in this new
situation to enforce the preferred narrative of those in power. Consequently,
they have developed new methods for controlling the conversation that use the
social media platform itself.
  Using the Central Asian republic of Kyrgyzstan as a main case study, this
talk explores how this new form of ""subtle"" censorship relies on pretence and
imitation, and why interdisciplinary methods of research are needed to grapple
with it. We examine how ""fakeness"" in the form of fake news and profiles is
used as methods of subtle censorship.","Accepted HotPETs talk, 2019",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1906.08021v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.08021v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.08021v1,"{'id': 'http://arxiv.org/abs/1906.08021v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.08021v1', 'updated': '2019-06-19T11:11:31Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=19, tm_hour=11, tm_min=11, tm_sec=31, tm_wday=2, tm_yday=170, tm_isdst=0), 'published': '2019-06-19T11:11:31Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=19, tm_hour=11, tm_min=11, tm_sec=31, tm_wday=2, tm_yday=170, tm_isdst=0), 'title': 'Subtle Censorship via Adversarial Fakeness in Kyrgyzstan', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Subtle Censorship via Adversarial Fakeness in Kyrgyzstan'}, 'summary': 'With the shift of public discourse to social media, we see simultaneously an\nexpansion of civic engagement as the bar to enter the conversation is lowered,\nand the reaction by both state and non-state adversaries of free speech to\nsilence these voices. Traditional forms of censorship struggle in this new\nsituation to enforce the preferred narrative of those in power. Consequently,\nthey have developed new methods for controlling the conversation that use the\nsocial media platform itself.\n  Using the Central Asian republic of Kyrgyzstan as a main case study, this\ntalk explores how this new form of ""subtle"" censorship relies on pretence and\nimitation, and why interdisciplinary methods of research are needed to grapple\nwith it. We examine how ""fakeness"" in the form of fake news and profiles is\nused as methods of subtle censorship.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the shift of public discourse to social media, we see simultaneously an\nexpansion of civic engagement as the bar to enter the conversation is lowered,\nand the reaction by both state and non-state adversaries of free speech to\nsilence these voices. Traditional forms of censorship struggle in this new\nsituation to enforce the preferred narrative of those in power. Consequently,\nthey have developed new methods for controlling the conversation that use the\nsocial media platform itself.\n  Using the Central Asian republic of Kyrgyzstan as a main case study, this\ntalk explores how this new form of ""subtle"" censorship relies on pretence and\nimitation, and why interdisciplinary methods of research are needed to grapple\nwith it. We examine how ""fakeness"" in the form of fake news and profiles is\nused as methods of subtle censorship.'}, 'authors': [{'name': 'Christopher Schwartz'}, {'name': 'Rebekah Overdorf'}], 'author_detail': {'name': 'Rebekah Overdorf'}, 'author': 'Rebekah Overdorf', 'arxiv_comment': 'Accepted HotPETs talk, 2019', 'links': [{'href': 'http://arxiv.org/abs/1906.08021v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.08021v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
309,http://arxiv.org/abs/1906.05659v1,2019-06-10 21:19:41+00:00,2019-06-10 21:19:41+00:00,Deep Two-path Semi-supervised Learning for Fake News Detection,"[arxiv.Result.Author('Xishuang Dong'), arxiv.Result.Author('Uboho Victor'), arxiv.Result.Author('Shanta Chowdhury'), arxiv.Result.Author('Lijun Qian')]","News in social media such as Twitter has been generated in high volume and
speed. However, very few of them can be labeled (as fake or true news) in a
short time. In order to achieve timely detection of fake news in social media,
a novel deep two-path semi-supervised learning model is proposed, where one
path is for supervised learning and the other is for unsupervised learning.
These two paths implemented with convolutional neural networks are jointly
optimized to enhance detection performance. In addition, we build a shared
convolutional neural networks between these two paths to share the low level
features. Experimental results using Twitter datasets show that the proposed
model can recognize fake news effectively with very few labeled data.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1906.05659v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.05659v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.05659v1,"{'id': 'http://arxiv.org/abs/1906.05659v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.05659v1', 'updated': '2019-06-10T21:19:41Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=10, tm_hour=21, tm_min=19, tm_sec=41, tm_wday=0, tm_yday=161, tm_isdst=0), 'published': '2019-06-10T21:19:41Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=10, tm_hour=21, tm_min=19, tm_sec=41, tm_wday=0, tm_yday=161, tm_isdst=0), 'title': 'Deep Two-path Semi-supervised Learning for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deep Two-path Semi-supervised Learning for Fake News Detection'}, 'summary': 'News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them can be labeled (as fake or true news) in a\nshort time. In order to achieve timely detection of fake news in social media,\na novel deep two-path semi-supervised learning model is proposed, where one\npath is for supervised learning and the other is for unsupervised learning.\nThese two paths implemented with convolutional neural networks are jointly\noptimized to enhance detection performance. In addition, we build a shared\nconvolutional neural networks between these two paths to share the low level\nfeatures. Experimental results using Twitter datasets show that the proposed\nmodel can recognize fake news effectively with very few labeled data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them can be labeled (as fake or true news) in a\nshort time. In order to achieve timely detection of fake news in social media,\na novel deep two-path semi-supervised learning model is proposed, where one\npath is for supervised learning and the other is for unsupervised learning.\nThese two paths implemented with convolutional neural networks are jointly\noptimized to enhance detection performance. In addition, we build a shared\nconvolutional neural networks between these two paths to share the low level\nfeatures. Experimental results using Twitter datasets show that the proposed\nmodel can recognize fake news effectively with very few labeled data.'}, 'authors': [{'name': 'Xishuang Dong'}, {'name': 'Uboho Victor'}, {'name': 'Shanta Chowdhury'}, {'name': 'Lijun Qian'}], 'author_detail': {'name': 'Lijun Qian'}, 'author': 'Lijun Qian', 'links': [{'href': 'http://arxiv.org/abs/1906.05659v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.05659v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
310,http://arxiv.org/abs/1906.04210v1,2019-06-10 18:10:27+00:00,2019-06-10 18:10:27+00:00,Network-based Fake News Detection: A Pattern-driven Approach,"[arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Reza Zafarani')]","Fake news gains has gained significant momentum, strongly motivating the need
for fake news research. Many fake news detection approaches have thus been
proposed, where most of them heavily rely on news content. However,
network-based clues revealed when analyzing news propagation on social networks
is an information that has hardly been comprehensively explored or used for
fake news detection. We bridge this gap by proposing a network-based
pattern-driven fake news detection approach. We aim to study the patterns of
fake news in social networks, which refer to the news being spread, spreaders
of the news and relationships among the spreaders. Empirical evidence and
interpretations on the existence of such patterns are provided based on social
psychological theories. These patterns are then represented at various network
levels (i.e., node-level, ego-level, triad-level, community-level and the
overall network) for being further utilized to detect fake news. The proposed
approach enhances the explainability in fake news feature engineering.
Experiments conducted on real-world data demonstrate that the proposed approach
can outperform the state of the arts.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1906.04210v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.04210v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.04210v1,"{'id': 'http://arxiv.org/abs/1906.04210v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.04210v1', 'updated': '2019-06-10T18:10:27Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=10, tm_hour=18, tm_min=10, tm_sec=27, tm_wday=0, tm_yday=161, tm_isdst=0), 'published': '2019-06-10T18:10:27Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=10, tm_hour=18, tm_min=10, tm_sec=27, tm_wday=0, tm_yday=161, tm_isdst=0), 'title': 'Network-based Fake News Detection: A Pattern-driven Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Network-based Fake News Detection: A Pattern-driven Approach'}, 'summary': 'Fake news gains has gained significant momentum, strongly motivating the need\nfor fake news research. Many fake news detection approaches have thus been\nproposed, where most of them heavily rely on news content. However,\nnetwork-based clues revealed when analyzing news propagation on social networks\nis an information that has hardly been comprehensively explored or used for\nfake news detection. We bridge this gap by proposing a network-based\npattern-driven fake news detection approach. We aim to study the patterns of\nfake news in social networks, which refer to the news being spread, spreaders\nof the news and relationships among the spreaders. Empirical evidence and\ninterpretations on the existence of such patterns are provided based on social\npsychological theories. These patterns are then represented at various network\nlevels (i.e., node-level, ego-level, triad-level, community-level and the\noverall network) for being further utilized to detect fake news. The proposed\napproach enhances the explainability in fake news feature engineering.\nExperiments conducted on real-world data demonstrate that the proposed approach\ncan outperform the state of the arts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news gains has gained significant momentum, strongly motivating the need\nfor fake news research. Many fake news detection approaches have thus been\nproposed, where most of them heavily rely on news content. However,\nnetwork-based clues revealed when analyzing news propagation on social networks\nis an information that has hardly been comprehensively explored or used for\nfake news detection. We bridge this gap by proposing a network-based\npattern-driven fake news detection approach. We aim to study the patterns of\nfake news in social networks, which refer to the news being spread, spreaders\nof the news and relationships among the spreaders. Empirical evidence and\ninterpretations on the existence of such patterns are provided based on social\npsychological theories. These patterns are then represented at various network\nlevels (i.e., node-level, ego-level, triad-level, community-level and the\noverall network) for being further utilized to detect fake news. The proposed\napproach enhances the explainability in fake news feature engineering.\nExperiments conducted on real-world data demonstrate that the proposed approach\ncan outperform the state of the arts.'}, 'authors': [{'name': 'Xinyi Zhou'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'links': [{'href': 'http://arxiv.org/abs/1906.04210v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.04210v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
311,http://arxiv.org/abs/1906.03423v1,2019-06-08 08:56:02+00:00,2019-06-08 08:56:02+00:00,News Labeling as Early as Possible: Real or Fake?,"[arxiv.Result.Author('Maryam Ramezani'), arxiv.Result.Author('Mina Rafiei'), arxiv.Result.Author('Soroush Omranpour'), arxiv.Result.Author('Hamid R. Rabiee')]","Making disguise between real and fake news propagation through online social
networks is an important issue in many applications. The time gap between the
news release time and detection of its label is a significant step towards
broadcasting the real information and avoiding the fake. Therefore, one of the
challenging tasks in this area is to identify fake and real news in early
stages of propagation. However, there is a trade-off between minimizing the
time gap and maximizing accuracy. Despite recent efforts in detection of fake
news, there has been no significant work that explicitly incorporates early
detection in its model. In this paper, we focus on accurate early labeling of
news, and propose a model by considering earliness both in modeling and
prediction. The proposed method utilizes recurrent neural networks with a novel
loss function, and a new stopping rule. Given the context of news, we first
embed it with a class-specific text representation. Then, we utilize the
available public profile of users, and speed of news diffusion, for early
labeling of the news. Experiments on real datasets demonstrate the
effectiveness of our model both in terms of early labelling and accuracy,
compared to the state of the art baseline and models.",,,10.1145/3341161.3342957,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3341161.3342957', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1906.03423v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.03423v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.03423v1,"{'id': 'http://arxiv.org/abs/1906.03423v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.03423v1', 'updated': '2019-06-08T08:56:02Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=8, tm_hour=8, tm_min=56, tm_sec=2, tm_wday=5, tm_yday=159, tm_isdst=0), 'published': '2019-06-08T08:56:02Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=8, tm_hour=8, tm_min=56, tm_sec=2, tm_wday=5, tm_yday=159, tm_isdst=0), 'title': 'News Labeling as Early as Possible: Real or Fake?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'News Labeling as Early as Possible: Real or Fake?'}, 'summary': 'Making disguise between real and fake news propagation through online social\nnetworks is an important issue in many applications. The time gap between the\nnews release time and detection of its label is a significant step towards\nbroadcasting the real information and avoiding the fake. Therefore, one of the\nchallenging tasks in this area is to identify fake and real news in early\nstages of propagation. However, there is a trade-off between minimizing the\ntime gap and maximizing accuracy. Despite recent efforts in detection of fake\nnews, there has been no significant work that explicitly incorporates early\ndetection in its model. In this paper, we focus on accurate early labeling of\nnews, and propose a model by considering earliness both in modeling and\nprediction. The proposed method utilizes recurrent neural networks with a novel\nloss function, and a new stopping rule. Given the context of news, we first\nembed it with a class-specific text representation. Then, we utilize the\navailable public profile of users, and speed of news diffusion, for early\nlabeling of the news. Experiments on real datasets demonstrate the\neffectiveness of our model both in terms of early labelling and accuracy,\ncompared to the state of the art baseline and models.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Making disguise between real and fake news propagation through online social\nnetworks is an important issue in many applications. The time gap between the\nnews release time and detection of its label is a significant step towards\nbroadcasting the real information and avoiding the fake. Therefore, one of the\nchallenging tasks in this area is to identify fake and real news in early\nstages of propagation. However, there is a trade-off between minimizing the\ntime gap and maximizing accuracy. Despite recent efforts in detection of fake\nnews, there has been no significant work that explicitly incorporates early\ndetection in its model. In this paper, we focus on accurate early labeling of\nnews, and propose a model by considering earliness both in modeling and\nprediction. The proposed method utilizes recurrent neural networks with a novel\nloss function, and a new stopping rule. Given the context of news, we first\nembed it with a class-specific text representation. Then, we utilize the\navailable public profile of users, and speed of news diffusion, for early\nlabeling of the news. Experiments on real datasets demonstrate the\neffectiveness of our model both in terms of early labelling and accuracy,\ncompared to the state of the art baseline and models.'}, 'authors': [{'name': 'Maryam Ramezani'}, {'name': 'Mina Rafiei'}, {'name': 'Soroush Omranpour'}, {'name': 'Hamid R. Rabiee'}], 'author_detail': {'name': 'Hamid R. Rabiee'}, 'author': 'Hamid R. Rabiee', 'arxiv_doi': '10.1145/3341161.3342957', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3341161.3342957', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1906.03423v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.03423v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
312,http://arxiv.org/abs/1906.01147v1,2019-06-04 01:05:08+00:00,2019-06-04 01:05:08+00:00,Interacting contagions are indistinguishable from social reinforcement,"[arxiv.Result.Author('Laurent Hébert-Dufresne'), arxiv.Result.Author('Samuel V. Scarpino'), arxiv.Result.Author('Jean-Gabriel Young')]","From fake news to innovative technologies, many contagions spread via a
process of social reinforcement, where multiple exposures are distinct from
prolonged exposure to a single source. Contrarily, biological agents such as
Ebola or measles are typically thought to spread as simple contagions. Here, we
demonstrate that interacting simple contagions are indistinguishable from
complex contagions. In the social context, our results highlight the challenge
of identifying and quantifying mechanisms, such as social reinforcement, in a
world where an innumerable amount of ideas, memes and behaviors interact. In
the biological context, this parallel allows the use of complex contagions to
effectively quantify the non-trivial interactions of infectious diseases.","Supplementary Material containing details of our simulation and
  inference procedures is available as an ancillary file",,10.1038/s41567-020-0791-2,physics.soc-ph,"['physics.soc-ph', 'math.DS', 'q-bio.PE']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41567-020-0791-2', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1906.01147v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.01147v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.01147v1,"{'id': 'http://arxiv.org/abs/1906.01147v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.01147v1', 'updated': '2019-06-04T01:05:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=4, tm_hour=1, tm_min=5, tm_sec=8, tm_wday=1, tm_yday=155, tm_isdst=0), 'published': '2019-06-04T01:05:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=4, tm_hour=1, tm_min=5, tm_sec=8, tm_wday=1, tm_yday=155, tm_isdst=0), 'title': 'Interacting contagions are indistinguishable from social reinforcement', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Interacting contagions are indistinguishable from social reinforcement'}, 'summary': 'From fake news to innovative technologies, many contagions spread via a\nprocess of social reinforcement, where multiple exposures are distinct from\nprolonged exposure to a single source. Contrarily, biological agents such as\nEbola or measles are typically thought to spread as simple contagions. Here, we\ndemonstrate that interacting simple contagions are indistinguishable from\ncomplex contagions. In the social context, our results highlight the challenge\nof identifying and quantifying mechanisms, such as social reinforcement, in a\nworld where an innumerable amount of ideas, memes and behaviors interact. In\nthe biological context, this parallel allows the use of complex contagions to\neffectively quantify the non-trivial interactions of infectious diseases.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'From fake news to innovative technologies, many contagions spread via a\nprocess of social reinforcement, where multiple exposures are distinct from\nprolonged exposure to a single source. Contrarily, biological agents such as\nEbola or measles are typically thought to spread as simple contagions. Here, we\ndemonstrate that interacting simple contagions are indistinguishable from\ncomplex contagions. In the social context, our results highlight the challenge\nof identifying and quantifying mechanisms, such as social reinforcement, in a\nworld where an innumerable amount of ideas, memes and behaviors interact. In\nthe biological context, this parallel allows the use of complex contagions to\neffectively quantify the non-trivial interactions of infectious diseases.'}, 'authors': [{'name': 'Laurent Hébert-Dufresne'}, {'name': 'Samuel V. Scarpino'}, {'name': 'Jean-Gabriel Young'}], 'author_detail': {'name': 'Jean-Gabriel Young'}, 'author': 'Jean-Gabriel Young', 'arxiv_doi': '10.1038/s41567-020-0791-2', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41567-020-0791-2', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1906.01147v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.01147v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Supplementary Material containing details of our simulation and\n  inference procedures is available as an ancillary file', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
313,http://arxiv.org/abs/1905.12616v3,2020-12-11 16:17:17+00:00,2019-05-29 17:58:52+00:00,Defending Against Neural Fake News,"[arxiv.Result.Author('Rowan Zellers'), arxiv.Result.Author('Ari Holtzman'), arxiv.Result.Author('Hannah Rashkin'), arxiv.Result.Author('Yonatan Bisk'), arxiv.Result.Author('Ali Farhadi'), arxiv.Result.Author('Franziska Roesner'), arxiv.Result.Author('Yejin Choi')]","Recent progress in natural language generation has raised dual-use concerns.
While applications like summarization and translation are positive, the
underlying technology also might enable adversaries to generate neural fake
news: targeted propaganda that closely mimics the style of real news.
  Modern computer security relies on careful threat modeling: identifying
potential threats and vulnerabilities from an adversary's point of view, and
exploring potential mitigations to these threats. Likewise, developing robust
defenses against neural fake news requires us first to carefully investigate
and characterize the risks of these models. We thus present a model for
controllable text generation called Grover. Given a headline like `Link Found
Between Vaccines and Autism,' Grover can generate the rest of the article;
humans find these generations to be more trustworthy than human-written
disinformation.
  Developing robust verification techniques against generators like Grover is
critical. We find that best current discriminators can classify neural fake
news from real, human-written, news with 73% accuracy, assuming access to a
moderate level of training data. Counterintuitively, the best defense against
Grover turns out to be Grover itself, with 92% accuracy, demonstrating the
importance of public release of strong generators. We investigate these results
further, showing that exposure bias -- and sampling strategies that alleviate
its effects -- both leave artifacts that similar discriminators can pick up on.
We conclude by discussing ethical issues regarding the technology, and plan to
release Grover publicly, helping pave the way for better detection of neural
fake news.","NeurIPS 2019 camera ready version. Project page/code/demo at
  https://rowanzellers.com/grover",,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1905.12616v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.12616v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.12616v3,"{'id': 'http://arxiv.org/abs/1905.12616v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.12616v3', 'updated': '2020-12-11T16:17:17Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=11, tm_hour=16, tm_min=17, tm_sec=17, tm_wday=4, tm_yday=346, tm_isdst=0), 'published': '2019-05-29T17:58:52Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=29, tm_hour=17, tm_min=58, tm_sec=52, tm_wday=2, tm_yday=149, tm_isdst=0), 'title': 'Defending Against Neural Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Defending Against Neural Fake News'}, 'summary': ""Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.""}, 'authors': [{'name': 'Rowan Zellers'}, {'name': 'Ari Holtzman'}, {'name': 'Hannah Rashkin'}, {'name': 'Yonatan Bisk'}, {'name': 'Ali Farhadi'}, {'name': 'Franziska Roesner'}, {'name': 'Yejin Choi'}], 'author_detail': {'name': 'Yejin Choi'}, 'author': 'Yejin Choi', 'arxiv_comment': 'NeurIPS 2019 camera ready version. Project page/code/demo at\n  https://rowanzellers.com/grover', 'links': [{'href': 'http://arxiv.org/abs/1905.12616v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.12616v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
314,http://arxiv.org/abs/1905.11204v1,2019-05-23 17:41:32+00:00,2019-05-23 17:41:32+00:00,A trust model for spreading gossip in social networks,"[arxiv.Result.Author('Rinni Bhansali'), arxiv.Result.Author('Laura P. Schaposnik')]","We introduce here a multi-type bootstrap percolation model, which we call
T-Bootstrap Percolation (T-BP), and apply it to study information propagation
in social networks. In this model, a social network is represented by a graph G
whose vertices have different labels corresponding to the type of role the
person plays in the network (e.g. a student, an educator, etc.). Once an
initial set of vertices of G is randomly selected to be carrying a gossip (e.g.
to be infected), the gossip propagates to a new vertex provided it is
transmitted by a minimum threshold of vertices with different labels. By
considering random graphs, which have been shown to closely represent social
networks, we study different properties of the T-BP model through numerical
simulations, and describe its implications when applied to rumour spread, fake
news, and marketing strategies.","9 pages, 9 figures",,,physics.soc-ph,"['physics.soc-ph', 'math.CO', 'nlin.CG', 'q-bio.PE', '60C05, 82B20, 60K35']","[arxiv.Result.Link('http://arxiv.org/abs/1905.11204v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.11204v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.11204v1,"{'id': 'http://arxiv.org/abs/1905.11204v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.11204v1', 'updated': '2019-05-23T17:41:32Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=41, tm_sec=32, tm_wday=3, tm_yday=143, tm_isdst=0), 'published': '2019-05-23T17:41:32Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=41, tm_sec=32, tm_wday=3, tm_yday=143, tm_isdst=0), 'title': 'A trust model for spreading gossip in social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A trust model for spreading gossip in social networks'}, 'summary': 'We introduce here a multi-type bootstrap percolation model, which we call\nT-Bootstrap Percolation (T-BP), and apply it to study information propagation\nin social networks. In this model, a social network is represented by a graph G\nwhose vertices have different labels corresponding to the type of role the\nperson plays in the network (e.g. a student, an educator, etc.). Once an\ninitial set of vertices of G is randomly selected to be carrying a gossip (e.g.\nto be infected), the gossip propagates to a new vertex provided it is\ntransmitted by a minimum threshold of vertices with different labels. By\nconsidering random graphs, which have been shown to closely represent social\nnetworks, we study different properties of the T-BP model through numerical\nsimulations, and describe its implications when applied to rumour spread, fake\nnews, and marketing strategies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We introduce here a multi-type bootstrap percolation model, which we call\nT-Bootstrap Percolation (T-BP), and apply it to study information propagation\nin social networks. In this model, a social network is represented by a graph G\nwhose vertices have different labels corresponding to the type of role the\nperson plays in the network (e.g. a student, an educator, etc.). Once an\ninitial set of vertices of G is randomly selected to be carrying a gossip (e.g.\nto be infected), the gossip propagates to a new vertex provided it is\ntransmitted by a minimum threshold of vertices with different labels. By\nconsidering random graphs, which have been shown to closely represent social\nnetworks, we study different properties of the T-BP model through numerical\nsimulations, and describe its implications when applied to rumour spread, fake\nnews, and marketing strategies.'}, 'authors': [{'name': 'Rinni Bhansali'}, {'name': 'Laura P. Schaposnik'}], 'author_detail': {'name': 'Laura P. Schaposnik'}, 'author': 'Laura P. Schaposnik', 'arxiv_comment': '9 pages, 9 figures', 'links': [{'href': 'http://arxiv.org/abs/1905.11204v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.11204v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.CG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '60C05, 82B20, 60K35', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
315,http://arxiv.org/abs/1905.08831v2,2019-05-30 15:02:54+00:00,2019-05-21 19:03:46+00:00,IdeoTrace: A Framework for Ideology Tracing with a Case Study on the 2016 U.S. Presidential Election,"[arxiv.Result.Author('Indu Manickam'), arxiv.Result.Author('Andrew S. Lan'), arxiv.Result.Author('Gautam Dasarathy'), arxiv.Result.Author('Richard G. Baraniuk')]","The 2016 United States presidential election has been characterized as a
period of extreme divisiveness that was exacerbated on social media by the
influence of fake news, trolls, and social bots. However, the extent to which
the public became more polarized in response to these influences over the
course of the election is not well understood. In this paper we propose
IdeoTrace, a framework for (i) jointly estimating the ideology of social media
users and news websites and (ii) tracing changes in user ideology over time. We
apply this framework to the last two months of the election period for a group
of 47508 Twitter users and demonstrate that both liberal and conservative users
became more polarized over time.","9 pages, 4 figures, submitted to ASONAM 2019",,,cs.SI,"['cs.SI', 'cs.LG', 'eess.SP', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1905.08831v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.08831v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.08831v2,"{'id': 'http://arxiv.org/abs/1905.08831v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.08831v2', 'updated': '2019-05-30T15:02:54Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=30, tm_hour=15, tm_min=2, tm_sec=54, tm_wday=3, tm_yday=150, tm_isdst=0), 'published': '2019-05-21T19:03:46Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=21, tm_hour=19, tm_min=3, tm_sec=46, tm_wday=1, tm_yday=141, tm_isdst=0), 'title': 'IdeoTrace: A Framework for Ideology Tracing with a Case Study on the\n  2016 U.S. Presidential Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'IdeoTrace: A Framework for Ideology Tracing with a Case Study on the\n  2016 U.S. Presidential Election'}, 'summary': 'The 2016 United States presidential election has been characterized as a\nperiod of extreme divisiveness that was exacerbated on social media by the\ninfluence of fake news, trolls, and social bots. However, the extent to which\nthe public became more polarized in response to these influences over the\ncourse of the election is not well understood. In this paper we propose\nIdeoTrace, a framework for (i) jointly estimating the ideology of social media\nusers and news websites and (ii) tracing changes in user ideology over time. We\napply this framework to the last two months of the election period for a group\nof 47508 Twitter users and demonstrate that both liberal and conservative users\nbecame more polarized over time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The 2016 United States presidential election has been characterized as a\nperiod of extreme divisiveness that was exacerbated on social media by the\ninfluence of fake news, trolls, and social bots. However, the extent to which\nthe public became more polarized in response to these influences over the\ncourse of the election is not well understood. In this paper we propose\nIdeoTrace, a framework for (i) jointly estimating the ideology of social media\nusers and news websites and (ii) tracing changes in user ideology over time. We\napply this framework to the last two months of the election period for a group\nof 47508 Twitter users and demonstrate that both liberal and conservative users\nbecame more polarized over time.'}, 'authors': [{'name': 'Indu Manickam'}, {'name': 'Andrew S. Lan'}, {'name': 'Gautam Dasarathy'}, {'name': 'Richard G. Baraniuk'}], 'author_detail': {'name': 'Richard G. Baraniuk'}, 'author': 'Richard G. Baraniuk', 'arxiv_comment': '9 pages, 4 figures, submitted to ASONAM 2019', 'links': [{'href': 'http://arxiv.org/abs/1905.08831v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.08831v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
316,http://arxiv.org/abs/1905.04749v2,2021-03-26 05:30:08+00:00,2019-05-12 17:15:11+00:00,A Benchmark Study of Machine Learning Models for Online Fake News Detection,"[arxiv.Result.Author('Junaed Younus Khan'), arxiv.Result.Author('Md. Tawkat Islam Khondaker'), arxiv.Result.Author('Sadia Afroz'), arxiv.Result.Author('Gias Uddin'), arxiv.Result.Author('Anindya Iqbal')]","The proliferation of fake news and its propagation on social media has become
a major concern due to its ability to create devastating impacts. Different
machine learning approaches have been suggested to detect fake news. However,
most of those focused on a specific type of news (such as political) which
leads us to the question of dataset-bias of the models used. In this research,
we conducted a benchmark study to assess the performance of different
applicable machine learning approaches on three different datasets where we
accumulated the largest and most diversified one. We explored a number of
advanced pre-trained language models for fake news detection along with the
traditional and deep learning ones and compared their performances from
different aspects for the first time to the best of our knowledge. We find that
BERT and similar pre-trained models perform the best for fake news detection,
especially with very small dataset. Hence, these models are significantly
better option for languages with limited electronic contents, i.e., training
data. We also carried out several analysis based on the models' performance,
article's topic, article's length, and discussed different lessons learned from
them. We believe that this benchmark study will help the research community to
explore further and news sites/blogs to select the most appropriate fake news
detection method.","22 pages, 5 figures, to be published in Machine Learning with
  Applications journal",Machine Learning with Applications: 4(2021).100032,10.1016/j.mlwa.2021.100032,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.mlwa.2021.100032', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1905.04749v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.04749v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.04749v2,"{'id': 'http://arxiv.org/abs/1905.04749v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.04749v2', 'updated': '2021-03-26T05:30:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=26, tm_hour=5, tm_min=30, tm_sec=8, tm_wday=4, tm_yday=85, tm_isdst=0), 'published': '2019-05-12T17:15:11Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=12, tm_hour=17, tm_min=15, tm_sec=11, tm_wday=6, tm_yday=132, tm_isdst=0), 'title': 'A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection'}, 'summary': ""The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method.""}, 'authors': [{'name': 'Junaed Younus Khan'}, {'name': 'Md. Tawkat Islam Khondaker'}, {'name': 'Sadia Afroz'}, {'name': 'Gias Uddin'}, {'name': 'Anindya Iqbal'}], 'author_detail': {'name': 'Anindya Iqbal'}, 'author': 'Anindya Iqbal', 'arxiv_doi': '10.1016/j.mlwa.2021.100032', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.mlwa.2021.100032', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1905.04749v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.04749v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '22 pages, 5 figures, to be published in Machine Learning with\n  Applications journal', 'arxiv_journal_ref': 'Machine Learning with Applications: 4(2021).100032', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
317,http://arxiv.org/abs/1905.04260v1,2019-05-10 17:00:40+00:00,2019-05-10 17:00:40+00:00,Check-It: A Plugin for Detecting and Reducing the Spread of Fake News and Misinformation on the Web,"[arxiv.Result.Author('Demetris Paschalides'), arxiv.Result.Author('Alexandros Kornilakis'), arxiv.Result.Author('Chrysovalantis Christodoulou'), arxiv.Result.Author('Rafael Andreou'), arxiv.Result.Author('George Pallis'), arxiv.Result.Author('Marios D. Dikaiakos'), arxiv.Result.Author('Evangelos Markatos')]","Over the past few years, we have been witnessing the rise of misinformation
on the Web. People fall victims of fake news during their daily lives and
assist their further propagation knowingly and inadvertently. There have been
many initiatives that are trying to mitigate the damage caused by fake news,
focusing on signals from either domain flag-lists, online social networks or
artificial intelligence. In this work, we present Check-It, a system that
combines, in an intelligent way, a variety of signals into a pipeline for fake
news identification. Check-It is developed as a web browser plugin with the
objective of efficient and timely fake news detection, respecting the user's
privacy. Experimental results show that Check-It is able to outperform the
state-of-the-art methods. On a dataset, consisting of 9 millions of articles
labeled as fake and real, Check-It obtains classification accuracies that
exceed 99%.","8 pages, 6 figures,",,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1905.04260v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.04260v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.04260v1,"{'id': 'http://arxiv.org/abs/1905.04260v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.04260v1', 'updated': '2019-05-10T17:00:40Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=10, tm_hour=17, tm_min=0, tm_sec=40, tm_wday=4, tm_yday=130, tm_isdst=0), 'published': '2019-05-10T17:00:40Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=10, tm_hour=17, tm_min=0, tm_sec=40, tm_wday=4, tm_yday=130, tm_isdst=0), 'title': 'Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web'}, 'summary': ""Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.""}, 'authors': [{'name': 'Demetris Paschalides'}, {'name': 'Alexandros Kornilakis'}, {'name': 'Chrysovalantis Christodoulou'}, {'name': 'Rafael Andreou'}, {'name': 'George Pallis'}, {'name': 'Marios D. Dikaiakos'}, {'name': 'Evangelos Markatos'}], 'author_detail': {'name': 'Evangelos Markatos'}, 'author': 'Evangelos Markatos', 'arxiv_comment': '8 pages, 6 figures,', 'links': [{'href': 'http://arxiv.org/abs/1905.04260v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.04260v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
318,http://arxiv.org/abs/1905.01556v1,2019-05-04 20:51:06+00:00,2019-05-04 20:51:06+00:00,Detecting Pathogenic Social Media Accounts without Content or Network Structure,"[arxiv.Result.Author('Elham Shaabani'), arxiv.Result.Author('Ruocheng Guo'), arxiv.Result.Author('Paulo Shakarian')]","The spread of harmful mis-information in social media is a pressing problem.
We refer accounts that have the capability of spreading such information to
viral proportions as ""Pathogenic Social Media"" accounts. These accounts include
terrorist supporters accounts, water armies, and fake news writers. We
introduce an unsupervised causality-based framework that also leverages label
propagation. This approach identifies these users without using network
structure, cascade path information, content and user's information. We show
our approach obtains higher precision (0.75) in identifying Pathogenic Social
Media accounts in comparison with random (precision of 0.11) and existing bot
detection (precision of 0.16) methods.","8 pages, 5 figures, International Conference on Data Intelligence and
  Security. arXiv admin note: text overlap with arXiv:1905.01553",,,cs.SI,"['cs.SI', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1905.01556v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.01556v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.01556v1,"{'id': 'http://arxiv.org/abs/1905.01556v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.01556v1', 'updated': '2019-05-04T20:51:06Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=4, tm_hour=20, tm_min=51, tm_sec=6, tm_wday=5, tm_yday=124, tm_isdst=0), 'published': '2019-05-04T20:51:06Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=4, tm_hour=20, tm_min=51, tm_sec=6, tm_wday=5, tm_yday=124, tm_isdst=0), 'title': 'Detecting Pathogenic Social Media Accounts without Content or Network\n  Structure', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Pathogenic Social Media Accounts without Content or Network\n  Structure'}, 'summary': 'The spread of harmful mis-information in social media is a pressing problem.\nWe refer accounts that have the capability of spreading such information to\nviral proportions as ""Pathogenic Social Media"" accounts. These accounts include\nterrorist supporters accounts, water armies, and fake news writers. We\nintroduce an unsupervised causality-based framework that also leverages label\npropagation. This approach identifies these users without using network\nstructure, cascade path information, content and user\'s information. We show\nour approach obtains higher precision (0.75) in identifying Pathogenic Social\nMedia accounts in comparison with random (precision of 0.11) and existing bot\ndetection (precision of 0.16) methods.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of harmful mis-information in social media is a pressing problem.\nWe refer accounts that have the capability of spreading such information to\nviral proportions as ""Pathogenic Social Media"" accounts. These accounts include\nterrorist supporters accounts, water armies, and fake news writers. We\nintroduce an unsupervised causality-based framework that also leverages label\npropagation. This approach identifies these users without using network\nstructure, cascade path information, content and user\'s information. We show\nour approach obtains higher precision (0.75) in identifying Pathogenic Social\nMedia accounts in comparison with random (precision of 0.11) and existing bot\ndetection (precision of 0.16) methods.'}, 'authors': [{'name': 'Elham Shaabani'}, {'name': 'Ruocheng Guo'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'arxiv_comment': '8 pages, 5 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01553', 'links': [{'href': 'http://arxiv.org/abs/1905.01556v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.01556v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
319,http://arxiv.org/abs/1905.01553v1,2019-05-04 20:19:08+00:00,2019-05-04 20:19:08+00:00,An End-to-End Framework to Identify Pathogenic Social Media Accounts on Twitter,"[arxiv.Result.Author('Elham Shaabani'), arxiv.Result.Author('Ashkan Sadeghi-Mobarakeh'), arxiv.Result.Author('Hamidreza Alvari'), arxiv.Result.Author('Paulo Shakarian')]","Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts
and fake news writers have the capability of spreading disinformation to viral
proportions. Early detection of PSM accounts is crucial as they are likely to
be key users to make malicious information ""viral"". In this paper, we adopt the
causal inference framework along with graph-based metrics in order to
distinguish PSMs from normal users within a short time of their activities. We
propose both supervised and semi-supervised approaches without taking the
network information and content into account. Results on a real-world dataset
from Twitter accentuates the advantage of our proposed frameworks. We show our
approach achieves 0.28 improvement in F1 score over existing approaches with
the precision of 0.90 and F1 score of 0.63.","9 pages, 8 figures, International Conference on Data Intelligence and
  Security. arXiv admin note: text overlap with arXiv:1905.01556",,,cs.SI,"['cs.SI', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1905.01553v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.01553v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.01553v1,"{'id': 'http://arxiv.org/abs/1905.01553v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.01553v1', 'updated': '2019-05-04T20:19:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=4, tm_hour=20, tm_min=19, tm_sec=8, tm_wday=5, tm_yday=124, tm_isdst=0), 'published': '2019-05-04T20:19:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=4, tm_hour=20, tm_min=19, tm_sec=8, tm_wday=5, tm_yday=124, tm_isdst=0), 'title': 'An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter'}, 'summary': 'Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information ""viral"". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information ""viral"". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.'}, 'authors': [{'name': 'Elham Shaabani'}, {'name': 'Ashkan Sadeghi-Mobarakeh'}, {'name': 'Hamidreza Alvari'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'arxiv_comment': '9 pages, 8 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01556', 'links': [{'href': 'http://arxiv.org/abs/1905.01553v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.01553v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
320,http://arxiv.org/abs/1905.00957v1,2019-05-02 20:50:22+00:00,2019-05-02 20:50:22+00:00,A Topic-Agnostic Approach for Identifying Fake News Pages,"[arxiv.Result.Author('Sonia Castelo'), arxiv.Result.Author('Thais Almeida'), arxiv.Result.Author('Anas Elghafari'), arxiv.Result.Author('Aécio Santos'), arxiv.Result.Author('Kien Pham'), arxiv.Result.Author('Eduardo Nakamura'), arxiv.Result.Author('Juliana Freire')]","Fake news and misinformation have been increasingly used to manipulate
popular opinion and influence political processes. To better understand fake
news, how they are propagated, and how to counter their effect, it is necessary
to first identify them. Recently, approaches have been proposed to
automatically classify articles as fake based on their content. An important
challenge for these approaches comes from the dynamic nature of news: as new
political events are covered, topics and discourse constantly change and thus,
a classifier trained using content from articles published at a given time is
likely to become ineffective in the future. To address this challenge, we
propose a topic-agnostic (TAG) classification strategy that uses linguistic and
web-markup features to identify fake news pages. We report experimental results
using multiple data sets which show that our approach attains high accuracy in
the identification of fake news, even as topics evolve over time.","Accepted for publication in the Companion Proceedings of the 2019
  World Wide Web Conference (WWW'19 Companion). Presented in the 2019
  International Workshop on Misinformation, Computational Fact-Checking and
  Credible Web (MisinfoWorkshop2019). 6 pages",,10.1145/3308560.3316739,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3308560.3316739', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1905.00957v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.00957v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.00957v1,"{'id': 'http://arxiv.org/abs/1905.00957v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.00957v1', 'updated': '2019-05-02T20:50:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=20, tm_min=50, tm_sec=22, tm_wday=3, tm_yday=122, tm_isdst=0), 'published': '2019-05-02T20:50:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=20, tm_min=50, tm_sec=22, tm_wday=3, tm_yday=122, tm_isdst=0), 'title': 'A Topic-Agnostic Approach for Identifying Fake News Pages', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Topic-Agnostic Approach for Identifying Fake News Pages'}, 'summary': 'Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.'}, 'authors': [{'name': 'Sonia Castelo'}, {'name': 'Thais Almeida'}, {'name': 'Anas Elghafari'}, {'name': 'Aécio Santos'}, {'name': 'Kien Pham'}, {'name': 'Eduardo Nakamura'}, {'name': 'Juliana Freire'}], 'author_detail': {'name': 'Juliana Freire'}, 'author': 'Juliana Freire', 'arxiv_doi': '10.1145/3308560.3316739', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3308560.3316739', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1905.00957v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.00957v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""Accepted for publication in the Companion Proceedings of the 2019\n  World Wide Web Conference (WWW'19 Companion). Presented in the 2019\n  International Workshop on Misinformation, Computational Fact-Checking and\n  Credible Web (MisinfoWorkshop2019). 6 pages"", 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
321,http://arxiv.org/abs/1905.06894v1,2019-05-02 15:49:21+00:00,2019-05-02 15:49:21+00:00,Fake news and rumors: a trigger for proliferation or fading away,"[arxiv.Result.Author('Ahad N. Zehmakan'), arxiv.Result.Author('Serge Galam')]","The dynamics of fake news and rumor spreading is investigated using a model
with three kinds of agents who are respectively the Seeds, the Agnostics and
the Others. While Seeds are the ones who start spreading the rumor being
adamantly convinced of its truth, Agnostics reject any kind of rumor and do not
believe in conspiracy theories. In between, the Others constitute the main part
of the community. While Seeds are always Believers and Agnostics are always
Indifferents, Others can switch between being Believer and Indifferent
depending on who they are discussing with. The underlying driving dynamics is
implemented via local updates of randomly formed groups of agents. In each
group, an Other turns into a Believer as soon as $m$ or more Believers are
present in the group. However, since some Believers may lose interest in the
rumor as time passes by, we add a flipping fixed rate $0<d<1$ from Believers
into Indifferents. Rigorous analysis of the associated dynamics reveals that
switching from $m=1$ to $m\ge2$ triggers a drastic qualitative change in the
spreading process. When $m=1$ even a small group of Believers may manage to
convince a large part of the community very quickly. In contrast, for $m\ge 2$,
even a substantial fraction of Believers does not prevent the rumor dying out
after a few update rounds. Our results provide an explanation on why a given
rumor spreads within a social group and not in another, and also why some
rumors will not spread in neither groups.",,,10.1063/5.0006984,cs.DM,"['cs.DM', 'cs.DS', 'cs.SI', 'math.DS', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1063/5.0006984', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1905.06894v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.06894v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.06894v1,"{'id': 'http://arxiv.org/abs/1905.06894v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.06894v1', 'updated': '2019-05-02T15:49:21Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=15, tm_min=49, tm_sec=21, tm_wday=3, tm_yday=122, tm_isdst=0), 'published': '2019-05-02T15:49:21Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=15, tm_min=49, tm_sec=21, tm_wday=3, tm_yday=122, tm_isdst=0), 'title': 'Fake news and rumors: a trigger for proliferation or fading away', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and rumors: a trigger for proliferation or fading away'}, 'summary': 'The dynamics of fake news and rumor spreading is investigated using a model\nwith three kinds of agents who are respectively the Seeds, the Agnostics and\nthe Others. While Seeds are the ones who start spreading the rumor being\nadamantly convinced of its truth, Agnostics reject any kind of rumor and do not\nbelieve in conspiracy theories. In between, the Others constitute the main part\nof the community. While Seeds are always Believers and Agnostics are always\nIndifferents, Others can switch between being Believer and Indifferent\ndepending on who they are discussing with. The underlying driving dynamics is\nimplemented via local updates of randomly formed groups of agents. In each\ngroup, an Other turns into a Believer as soon as $m$ or more Believers are\npresent in the group. However, since some Believers may lose interest in the\nrumor as time passes by, we add a flipping fixed rate $0<d<1$ from Believers\ninto Indifferents. Rigorous analysis of the associated dynamics reveals that\nswitching from $m=1$ to $m\\ge2$ triggers a drastic qualitative change in the\nspreading process. When $m=1$ even a small group of Believers may manage to\nconvince a large part of the community very quickly. In contrast, for $m\\ge 2$,\neven a substantial fraction of Believers does not prevent the rumor dying out\nafter a few update rounds. Our results provide an explanation on why a given\nrumor spreads within a social group and not in another, and also why some\nrumors will not spread in neither groups.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The dynamics of fake news and rumor spreading is investigated using a model\nwith three kinds of agents who are respectively the Seeds, the Agnostics and\nthe Others. While Seeds are the ones who start spreading the rumor being\nadamantly convinced of its truth, Agnostics reject any kind of rumor and do not\nbelieve in conspiracy theories. In between, the Others constitute the main part\nof the community. While Seeds are always Believers and Agnostics are always\nIndifferents, Others can switch between being Believer and Indifferent\ndepending on who they are discussing with. The underlying driving dynamics is\nimplemented via local updates of randomly formed groups of agents. In each\ngroup, an Other turns into a Believer as soon as $m$ or more Believers are\npresent in the group. However, since some Believers may lose interest in the\nrumor as time passes by, we add a flipping fixed rate $0<d<1$ from Believers\ninto Indifferents. Rigorous analysis of the associated dynamics reveals that\nswitching from $m=1$ to $m\\ge2$ triggers a drastic qualitative change in the\nspreading process. When $m=1$ even a small group of Believers may manage to\nconvince a large part of the community very quickly. In contrast, for $m\\ge 2$,\neven a substantial fraction of Believers does not prevent the rumor dying out\nafter a few update rounds. Our results provide an explanation on why a given\nrumor spreads within a social group and not in another, and also why some\nrumors will not spread in neither groups.'}, 'authors': [{'name': 'Ahad N. Zehmakan'}, {'name': 'Serge Galam'}], 'author_detail': {'name': 'Serge Galam'}, 'author': 'Serge Galam', 'arxiv_doi': '10.1063/5.0006984', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1063/5.0006984', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1905.06894v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.06894v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.DM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
322,http://arxiv.org/abs/1905.00672v4,2020-08-06 18:29:54+00:00,2019-05-02 11:36:11+00:00,Temporal Ordered Clustering in Dynamic Networks: Unsupervised and Semi-supervised Learning Algorithms,"[arxiv.Result.Author('Krzysztof Turowski'), arxiv.Result.Author('Jithin K. Sreedharan'), arxiv.Result.Author('Wojciech Szpankowski')]","In temporal ordered clustering, given a single snapshot of a dynamic network
in which nodes arrive at distinct time instants, we aim at partitioning its
nodes into $K$ ordered clusters $\mathcal{C}_1 \prec \cdots \prec
\mathcal{C}_K$ such that for $i<j$, nodes in cluster $\mathcal{C}_i$ arrived
before nodes in cluster $\mathcal{C}_j$, with $K$ being a data-driven parameter
and not known upfront. Such a problem is of considerable significance in many
applications ranging from tracking the expansion of fake news to mapping the
spread of information. We first formulate our problem for a general dynamic
graph, and propose an integer programming framework that finds the optimal
clustering, represented as a strict partial order set, achieving the best
precision (i.e., fraction of successfully ordered node pairs) for a fixed
density (i.e., fraction of comparable node pairs). We then develop a sequential
importance procedure and design unsupervised and semi-supervised algorithms to
find temporal ordered clusters that efficiently approximate the optimal
solution. To illustrate the techniques, we apply our methods to the vertex
copying (duplication-divergence) model which exhibits some edge-case challenges
in inferring the clusters as compared to other network models. Finally, we
validate the performance of the proposed algorithms on synthetic and real-world
networks.","14 pages, 9 figures, and 3 tables. This version is submitted to a
  journal. A shorter version of this work is published in the proceedings of
  IEEE International Symposium on Information Theory (ISIT), 2020. The first
  two authors contributed equally",,,cs.SI,"['cs.SI', 'cs.LG', 'stat.AP']","[arxiv.Result.Link('http://arxiv.org/abs/1905.00672v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.00672v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.00672v4,"{'id': 'http://arxiv.org/abs/1905.00672v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.00672v4', 'updated': '2020-08-06T18:29:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=6, tm_hour=18, tm_min=29, tm_sec=54, tm_wday=3, tm_yday=219, tm_isdst=0), 'published': '2019-05-02T11:36:11Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=11, tm_min=36, tm_sec=11, tm_wday=3, tm_yday=122, tm_isdst=0), 'title': 'Temporal Ordered Clustering in Dynamic Networks: Unsupervised and\n  Semi-supervised Learning Algorithms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Temporal Ordered Clustering in Dynamic Networks: Unsupervised and\n  Semi-supervised Learning Algorithms'}, 'summary': 'In temporal ordered clustering, given a single snapshot of a dynamic network\nin which nodes arrive at distinct time instants, we aim at partitioning its\nnodes into $K$ ordered clusters $\\mathcal{C}_1 \\prec \\cdots \\prec\n\\mathcal{C}_K$ such that for $i<j$, nodes in cluster $\\mathcal{C}_i$ arrived\nbefore nodes in cluster $\\mathcal{C}_j$, with $K$ being a data-driven parameter\nand not known upfront. Such a problem is of considerable significance in many\napplications ranging from tracking the expansion of fake news to mapping the\nspread of information. We first formulate our problem for a general dynamic\ngraph, and propose an integer programming framework that finds the optimal\nclustering, represented as a strict partial order set, achieving the best\nprecision (i.e., fraction of successfully ordered node pairs) for a fixed\ndensity (i.e., fraction of comparable node pairs). We then develop a sequential\nimportance procedure and design unsupervised and semi-supervised algorithms to\nfind temporal ordered clusters that efficiently approximate the optimal\nsolution. To illustrate the techniques, we apply our methods to the vertex\ncopying (duplication-divergence) model which exhibits some edge-case challenges\nin inferring the clusters as compared to other network models. Finally, we\nvalidate the performance of the proposed algorithms on synthetic and real-world\nnetworks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In temporal ordered clustering, given a single snapshot of a dynamic network\nin which nodes arrive at distinct time instants, we aim at partitioning its\nnodes into $K$ ordered clusters $\\mathcal{C}_1 \\prec \\cdots \\prec\n\\mathcal{C}_K$ such that for $i<j$, nodes in cluster $\\mathcal{C}_i$ arrived\nbefore nodes in cluster $\\mathcal{C}_j$, with $K$ being a data-driven parameter\nand not known upfront. Such a problem is of considerable significance in many\napplications ranging from tracking the expansion of fake news to mapping the\nspread of information. We first formulate our problem for a general dynamic\ngraph, and propose an integer programming framework that finds the optimal\nclustering, represented as a strict partial order set, achieving the best\nprecision (i.e., fraction of successfully ordered node pairs) for a fixed\ndensity (i.e., fraction of comparable node pairs). We then develop a sequential\nimportance procedure and design unsupervised and semi-supervised algorithms to\nfind temporal ordered clusters that efficiently approximate the optimal\nsolution. To illustrate the techniques, we apply our methods to the vertex\ncopying (duplication-divergence) model which exhibits some edge-case challenges\nin inferring the clusters as compared to other network models. Finally, we\nvalidate the performance of the proposed algorithms on synthetic and real-world\nnetworks.'}, 'authors': [{'name': 'Krzysztof Turowski'}, {'name': 'Jithin K. Sreedharan'}, {'name': 'Wojciech Szpankowski'}], 'author_detail': {'name': 'Wojciech Szpankowski'}, 'author': 'Wojciech Szpankowski', 'arxiv_comment': '14 pages, 9 figures, and 3 tables. This version is submitted to a\n  journal. A shorter version of this work is published in the proceedings of\n  IEEE International Symposium on Information Theory (ISIT), 2020. The first\n  two authors contributed equally', 'links': [{'href': 'http://arxiv.org/abs/1905.00672v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.00672v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
323,http://arxiv.org/abs/1905.03035v1,2019-05-01 16:48:19+00:00,2019-05-01 16:48:19+00:00,Applications of Social Media in Hydroinformatics: A Survey,"[arxiv.Result.Author('Yufeng Yu'), arxiv.Result.Author('Yuelong Zhu'), arxiv.Result.Author('Dingsheng Wan'), arxiv.Result.Author('Qun Zhao'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Huan Liu')]","Floods of research and practical applications employ social media data for a
wide range of public applications, including environmental monitoring, water
resource managing, disaster and emergency response.Hydroinformatics can benefit
from the social media technologies with newly emerged data, techniques and
analytical tools to handle large datasets, from which creative ideas and new
values could be mined.This paper first proposes a 4W (What, Why, When, hoW)
model and a methodological structure to better understand and represent the
application of social media to hydroinformatics, then provides an overview of
academic research of applying social media to hydroinformatics such as water
environment, water resources, flood, drought and water Scarcity management. At
last,some advanced topics and suggestions of water related social media
applications from data collection, data quality management, fake news
detection, privacy issues, algorithms and platforms was present to
hydroinformatics managers and researchers based on previous discussion.",37pages,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1905.03035v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.03035v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.03035v1,"{'id': 'http://arxiv.org/abs/1905.03035v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.03035v1', 'updated': '2019-05-01T16:48:19Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=1, tm_hour=16, tm_min=48, tm_sec=19, tm_wday=2, tm_yday=121, tm_isdst=0), 'published': '2019-05-01T16:48:19Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=1, tm_hour=16, tm_min=48, tm_sec=19, tm_wday=2, tm_yday=121, tm_isdst=0), 'title': 'Applications of Social Media in Hydroinformatics: A Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Applications of Social Media in Hydroinformatics: A Survey'}, 'summary': 'Floods of research and practical applications employ social media data for a\nwide range of public applications, including environmental monitoring, water\nresource managing, disaster and emergency response.Hydroinformatics can benefit\nfrom the social media technologies with newly emerged data, techniques and\nanalytical tools to handle large datasets, from which creative ideas and new\nvalues could be mined.This paper first proposes a 4W (What, Why, When, hoW)\nmodel and a methodological structure to better understand and represent the\napplication of social media to hydroinformatics, then provides an overview of\nacademic research of applying social media to hydroinformatics such as water\nenvironment, water resources, flood, drought and water Scarcity management. At\nlast,some advanced topics and suggestions of water related social media\napplications from data collection, data quality management, fake news\ndetection, privacy issues, algorithms and platforms was present to\nhydroinformatics managers and researchers based on previous discussion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Floods of research and practical applications employ social media data for a\nwide range of public applications, including environmental monitoring, water\nresource managing, disaster and emergency response.Hydroinformatics can benefit\nfrom the social media technologies with newly emerged data, techniques and\nanalytical tools to handle large datasets, from which creative ideas and new\nvalues could be mined.This paper first proposes a 4W (What, Why, When, hoW)\nmodel and a methodological structure to better understand and represent the\napplication of social media to hydroinformatics, then provides an overview of\nacademic research of applying social media to hydroinformatics such as water\nenvironment, water resources, flood, drought and water Scarcity management. At\nlast,some advanced topics and suggestions of water related social media\napplications from data collection, data quality management, fake news\ndetection, privacy issues, algorithms and platforms was present to\nhydroinformatics managers and researchers based on previous discussion.'}, 'authors': [{'name': 'Yufeng Yu'}, {'name': 'Yuelong Zhu'}, {'name': 'Dingsheng Wan'}, {'name': 'Qun Zhao'}, {'name': 'Kai Shu'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '37pages', 'links': [{'href': 'http://arxiv.org/abs/1905.03035v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.03035v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
324,http://arxiv.org/abs/1904.13355v1,2019-04-30 16:35:28+00:00,2019-04-30 16:35:28+00:00,The Role of User Profile for Fake News Detection,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Reza Zafarani'), arxiv.Result.Author('Huan Liu')]","Consuming news from social media is becoming increasingly popular. Social
media appeals to users due to its fast dissemination of information, low cost,
and easy access. However, social media also enables the widespread of fake
news. Because of the detrimental societal effects of fake news, detecting fake
news has attracted increasing attention. However, the detection performance
only using news contents is generally not satisfactory as fake news is written
to mimic true news. Thus, there is a need for an in-depth understanding on the
relationship between user profiles on social media and fake news. In this
paper, we study the challenging problem of understanding and exploiting user
profiles on social media for fake news detection. In an attempt to understand
connections between user profiles and fake news, first, we measure users'
sharing behaviors on social media and group representative users who are more
likely to share fake and real news; then, we perform a comparative analysis of
explicit and implicit profile features between these user groups, which reveals
their potential to help differentiate fake news from real news. To exploit user
profile features, we demonstrate the usefulness of these user profile features
in a fake news classification task. We further validate the effectiveness of
these features through feature importance analysis. The findings of this work
lay the foundation for deeper exploration of user profile features of social
media and enhance the capabilities for fake news detection.",,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1904.13355v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.13355v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.13355v1,"{'id': 'http://arxiv.org/abs/1904.13355v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.13355v1', 'updated': '2019-04-30T16:35:28Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=30, tm_hour=16, tm_min=35, tm_sec=28, tm_wday=1, tm_yday=120, tm_isdst=0), 'published': '2019-04-30T16:35:28Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=30, tm_hour=16, tm_min=35, tm_sec=28, tm_wday=1, tm_yday=120, tm_isdst=0), 'title': 'The Role of User Profile for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Role of User Profile for Fake News Detection'}, 'summary': ""Consuming news from social media is becoming increasingly popular. Social\nmedia appeals to users due to its fast dissemination of information, low cost,\nand easy access. However, social media also enables the widespread of fake\nnews. Because of the detrimental societal effects of fake news, detecting fake\nnews has attracted increasing attention. However, the detection performance\nonly using news contents is generally not satisfactory as fake news is written\nto mimic true news. Thus, there is a need for an in-depth understanding on the\nrelationship between user profiles on social media and fake news. In this\npaper, we study the challenging problem of understanding and exploiting user\nprofiles on social media for fake news detection. In an attempt to understand\nconnections between user profiles and fake news, first, we measure users'\nsharing behaviors on social media and group representative users who are more\nlikely to share fake and real news; then, we perform a comparative analysis of\nexplicit and implicit profile features between these user groups, which reveals\ntheir potential to help differentiate fake news from real news. To exploit user\nprofile features, we demonstrate the usefulness of these user profile features\nin a fake news classification task. We further validate the effectiveness of\nthese features through feature importance analysis. The findings of this work\nlay the foundation for deeper exploration of user profile features of social\nmedia and enhance the capabilities for fake news detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Consuming news from social media is becoming increasingly popular. Social\nmedia appeals to users due to its fast dissemination of information, low cost,\nand easy access. However, social media also enables the widespread of fake\nnews. Because of the detrimental societal effects of fake news, detecting fake\nnews has attracted increasing attention. However, the detection performance\nonly using news contents is generally not satisfactory as fake news is written\nto mimic true news. Thus, there is a need for an in-depth understanding on the\nrelationship between user profiles on social media and fake news. In this\npaper, we study the challenging problem of understanding and exploiting user\nprofiles on social media for fake news detection. In an attempt to understand\nconnections between user profiles and fake news, first, we measure users'\nsharing behaviors on social media and group representative users who are more\nlikely to share fake and real news; then, we perform a comparative analysis of\nexplicit and implicit profile features between these user groups, which reveals\ntheir potential to help differentiate fake news from real news. To exploit user\nprofile features, we demonstrate the usefulness of these user profile features\nin a fake news classification task. We further validate the effectiveness of\nthese features through feature importance analysis. The findings of this work\nlay the foundation for deeper exploration of user profile features of social\nmedia and enhance the capabilities for fake news detection.""}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Xinyi Zhou'}, {'name': 'Suhang Wang'}, {'name': 'Reza Zafarani'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'links': [{'href': 'http://arxiv.org/abs/1904.13355v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.13355v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
325,http://arxiv.org/abs/1904.12767v4,2021-06-11 00:11:09+00:00,2019-04-29 15:25:01+00:00,Local non-Bayesian social learning with stubborn agents,"[arxiv.Result.Author('Daniel Vial'), arxiv.Result.Author('Vijay Subramanian')]","We study a social learning model in which agents iteratively update their
beliefs about the true state of the world using private signals and the beliefs
of other agents in a non-Bayesian manner. Some agents are stubborn, meaning
they attempt to convince others of an erroneous true state (modeling fake
news). We show that while agents learn the true state on short timescales, they
""forget"" it and believe the erroneous state to be true on longer timescales.
Using these results, we devise strategies for seeding stubborn agents so as to
disrupt learning, which outperform intuitive heuristics and give novel insights
regarding vulnerabilities in social learning.",,,,cs.SI,"['cs.SI', 'cs.MA']","[arxiv.Result.Link('http://arxiv.org/abs/1904.12767v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.12767v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.12767v4,"{'id': 'http://arxiv.org/abs/1904.12767v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.12767v4', 'updated': '2021-06-11T00:11:09Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=11, tm_hour=0, tm_min=11, tm_sec=9, tm_wday=4, tm_yday=162, tm_isdst=0), 'published': '2019-04-29T15:25:01Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=29, tm_hour=15, tm_min=25, tm_sec=1, tm_wday=0, tm_yday=119, tm_isdst=0), 'title': 'Local non-Bayesian social learning with stubborn agents', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Local non-Bayesian social learning with stubborn agents'}, 'summary': 'We study a social learning model in which agents iteratively update their\nbeliefs about the true state of the world using private signals and the beliefs\nof other agents in a non-Bayesian manner. Some agents are stubborn, meaning\nthey attempt to convince others of an erroneous true state (modeling fake\nnews). We show that while agents learn the true state on short timescales, they\n""forget"" it and believe the erroneous state to be true on longer timescales.\nUsing these results, we devise strategies for seeding stubborn agents so as to\ndisrupt learning, which outperform intuitive heuristics and give novel insights\nregarding vulnerabilities in social learning.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We study a social learning model in which agents iteratively update their\nbeliefs about the true state of the world using private signals and the beliefs\nof other agents in a non-Bayesian manner. Some agents are stubborn, meaning\nthey attempt to convince others of an erroneous true state (modeling fake\nnews). We show that while agents learn the true state on short timescales, they\n""forget"" it and believe the erroneous state to be true on longer timescales.\nUsing these results, we devise strategies for seeding stubborn agents so as to\ndisrupt learning, which outperform intuitive heuristics and give novel insights\nregarding vulnerabilities in social learning.'}, 'authors': [{'name': 'Daniel Vial'}, {'name': 'Vijay Subramanian'}], 'author_detail': {'name': 'Vijay Subramanian'}, 'author': 'Vijay Subramanian', 'links': [{'href': 'http://arxiv.org/abs/1904.12767v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.12767v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
326,http://arxiv.org/abs/1904.11679v2,2020-09-16 18:42:11+00:00,2019-04-26 05:52:05+00:00,Fake News Early Detection: An Interdisciplinary Study,"[arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Atishay Jain'), arxiv.Result.Author('Vir V. Phoha'), arxiv.Result.Author('Reza Zafarani')]","Massive dissemination of fake news and its potential to erode democracy has
increased the demand for accurate fake news detection. Recent advancements in
this area have proposed novel techniques that aim to detect fake news by
exploring how it propagates on social networks. Nevertheless, to detect fake
news at an early stage, i.e., when it is published on a news outlet but not yet
spread on social media, one cannot rely on news propagation information as it
does not exist. Hence, there is a strong need to develop approaches that can
detect fake news by focusing on news content. In this paper, a theory-driven
model is proposed for fake news detection. The method investigates news content
at various levels: lexicon-level, syntax-level, semantic-level and
discourse-level. We represent news at each level, relying on well-established
theories in social and forensic psychology. Fake news detection is then
conducted within a supervised machine learning framework. As an
interdisciplinary research, our work explores potential fake news patterns,
enhances the interpretability in fake news feature engineering, and studies the
relationships among fake news, deception/disinformation, and clickbaits.
Experiments conducted on two real-world datasets indicate the proposed method
can outperform the state-of-the-art and enable fake news early detection when
there is limited content information.",25 pages,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1904.11679v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.11679v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.11679v2,"{'id': 'http://arxiv.org/abs/1904.11679v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.11679v2', 'updated': '2020-09-16T18:42:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=16, tm_hour=18, tm_min=42, tm_sec=11, tm_wday=2, tm_yday=260, tm_isdst=0), 'published': '2019-04-26T05:52:05Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=26, tm_hour=5, tm_min=52, tm_sec=5, tm_wday=4, tm_yday=116, tm_isdst=0), 'title': 'Fake News Early Detection: An Interdisciplinary Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Early Detection: An Interdisciplinary Study'}, 'summary': 'Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.'}, 'authors': [{'name': 'Xinyi Zhou'}, {'name': 'Atishay Jain'}, {'name': 'Vir V. Phoha'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_comment': '25 pages', 'links': [{'href': 'http://arxiv.org/abs/1904.11679v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.11679v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
327,http://arxiv.org/abs/1904.05386v2,2019-10-20 19:30:09+00:00,2019-04-10 18:42:45+00:00,"Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger Technologies and Blockchain to Combat Digital Deception and Counterfeit Reality","[arxiv.Result.Author('Paula Fraga-Lamas'), arxiv.Result.Author('Tiago M. Fernández-Caramés')]","The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda
and post-truth, often referred to as fake news, raises concerns over the role
of Internet and social media in modern democratic societies. Due to its rapid
and widespread diffusion, digital deception has not only an individual or
societal cost (e.g., to hamper the integrity of elections), but it can lead to
significant economic losses (e.g., to affect stock market performance) or to
risks to national security. Blockchain and other Distributed Ledger
Technologies (DLTs) guarantee the provenance, authenticity and traceability of
data by providing a transparent, immutable and verifiable record of
transactions while creating a peer-to-peer secure platform for storing and
exchanging information. This overview aims to explore the potential of DLTs and
blockchain to combat digital deception, reviewing initiatives that are
currently under development and identifying their main current challenges.
Moreover, some recommendations are enumerated to guide future researchers on
issues that will have to be tackled to face fake news, disinformation and
deepfakes, as an integral part of strengthening the resilience against
cyber-threats on today's online media.",Updated version,,,cs.CY,"['cs.CY', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/1904.05386v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.05386v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.05386v2,"{'id': 'http://arxiv.org/abs/1904.05386v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.05386v2', 'updated': '2019-10-20T19:30:09Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=20, tm_hour=19, tm_min=30, tm_sec=9, tm_wday=6, tm_yday=293, tm_isdst=0), 'published': '2019-04-10T18:42:45Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=10, tm_hour=18, tm_min=42, tm_sec=45, tm_wday=2, tm_yday=100, tm_isdst=0), 'title': 'Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality'}, 'summary': ""The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.""}, 'authors': [{'name': 'Paula Fraga-Lamas'}, {'name': 'Tiago M. Fernández-Caramés'}], 'author_detail': {'name': 'Tiago M. Fernández-Caramés'}, 'author': 'Tiago M. Fernández-Caramés', 'arxiv_comment': 'Updated version', 'links': [{'href': 'http://arxiv.org/abs/1904.05386v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.05386v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
328,http://arxiv.org/abs/1904.05305v1,2019-04-10 17:14:22+00:00,2019-04-10 17:14:22+00:00,A Classification Algorithm to Recognize Fake News Websites,"[arxiv.Result.Author('Davide Bennato'), arxiv.Result.Author('Giuseppe Pernagallo'), arxiv.Result.Author('Benedetto Torrisi')]","'Fake news' is information that generally spreads on the web, which only
mimics the form of reliable news media content. The phenomenon has assumed
uncontrolled proportions in recent years rising the concern of authorities and
citizens. In this paper we present a classifier able to distinguish a reliable
source from a fake news website. We have prepared a dataset made of 200 fake
news websites and 200 reliable websites from all over the world and used as
predictors information potentially available on websites, such as the presence
of a 'contact us' section or a secured connection. The algorithm is based on
logistic regression, whereas further analyses were carried out using
tetrachoric correlation coefficients for dichotomous variables and chi-square
tests. This framework offers a concrete solution to attribute a 'reliability
score' to news website, defined as the probability that a source is reliable or
not, and on this probability a user can decide if the news is worth sharing or
not.","11 pages, 3 figures, 4 tables","International Conference on Data Science and Social Research, 2020",10.1007/978-3-030-51222-4_25,cs.SI,"['cs.SI', 'cs.CY', 'stat.AP']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-51222-4_25', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1904.05305v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.05305v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.05305v1,"{'id': 'http://arxiv.org/abs/1904.05305v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.05305v1', 'updated': '2019-04-10T17:14:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=10, tm_hour=17, tm_min=14, tm_sec=22, tm_wday=2, tm_yday=100, tm_isdst=0), 'published': '2019-04-10T17:14:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=10, tm_hour=17, tm_min=14, tm_sec=22, tm_wday=2, tm_yday=100, tm_isdst=0), 'title': 'A Classification Algorithm to Recognize Fake News Websites', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Classification Algorithm to Recognize Fake News Websites'}, 'summary': ""'Fake news' is information that generally spreads on the web, which only\nmimics the form of reliable news media content. The phenomenon has assumed\nuncontrolled proportions in recent years rising the concern of authorities and\ncitizens. In this paper we present a classifier able to distinguish a reliable\nsource from a fake news website. We have prepared a dataset made of 200 fake\nnews websites and 200 reliable websites from all over the world and used as\npredictors information potentially available on websites, such as the presence\nof a 'contact us' section or a secured connection. The algorithm is based on\nlogistic regression, whereas further analyses were carried out using\ntetrachoric correlation coefficients for dichotomous variables and chi-square\ntests. This framework offers a concrete solution to attribute a 'reliability\nscore' to news website, defined as the probability that a source is reliable or\nnot, and on this probability a user can decide if the news is worth sharing or\nnot."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""'Fake news' is information that generally spreads on the web, which only\nmimics the form of reliable news media content. The phenomenon has assumed\nuncontrolled proportions in recent years rising the concern of authorities and\ncitizens. In this paper we present a classifier able to distinguish a reliable\nsource from a fake news website. We have prepared a dataset made of 200 fake\nnews websites and 200 reliable websites from all over the world and used as\npredictors information potentially available on websites, such as the presence\nof a 'contact us' section or a secured connection. The algorithm is based on\nlogistic regression, whereas further analyses were carried out using\ntetrachoric correlation coefficients for dichotomous variables and chi-square\ntests. This framework offers a concrete solution to attribute a 'reliability\nscore' to news website, defined as the probability that a source is reliable or\nnot, and on this probability a user can decide if the news is worth sharing or\nnot.""}, 'authors': [{'name': 'Davide Bennato'}, {'name': 'Giuseppe Pernagallo'}, {'name': 'Benedetto Torrisi'}], 'author_detail': {'name': 'Benedetto Torrisi'}, 'author': 'Benedetto Torrisi', 'arxiv_doi': '10.1007/978-3-030-51222-4_25', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-51222-4_25', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1904.05305v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.05305v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '11 pages, 3 figures, 4 tables', 'arxiv_journal_ref': 'International Conference on Data Science and Social Research, 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
329,http://arxiv.org/abs/1904.02934v5,2021-03-03 03:57:00+00:00,2019-04-05 08:32:27+00:00,Second-order Inductive Inference: an axiomatic approach,"[arxiv.Result.Author(""Patrick H. O'Callaghan"")]","Consider a predictor who ranks eventualities on the basis of past cases: for
instance a search engine ranking webpages given past searches. Resampling past
cases leads to different rankings and the extraction of deeper information. Yet
a rich database, with sufficiently diverse rankings, is often beyond reach.
Inexperience demands either ""on the fly"" learning-by-doing or prudence: the
arrival of a novel case does not force (i) a revision of current rankings, (ii)
dogmatism towards new rankings, or (iii) intransitivity. For this higher-order
framework of inductive inference, we derive a suitably unique numerical
representation of these rankings via a matrix on eventualities x cases and
describe a robust test of prudence. Applications include: the success/failure
of startups; the veracity of fake news; and novel conditions for the existence
of a yield curve that is robustly arbitrage-free.",,,,econ.TH,"['econ.TH', 'econ.EM']","[arxiv.Result.Link('http://arxiv.org/abs/1904.02934v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.02934v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.02934v5,"{'id': 'http://arxiv.org/abs/1904.02934v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.02934v5', 'updated': '2021-03-03T03:57:00Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=3, tm_hour=3, tm_min=57, tm_sec=0, tm_wday=2, tm_yday=62, tm_isdst=0), 'published': '2019-04-05T08:32:27Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=5, tm_hour=8, tm_min=32, tm_sec=27, tm_wday=4, tm_yday=95, tm_isdst=0), 'title': 'Second-order Inductive Inference: an axiomatic approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Second-order Inductive Inference: an axiomatic approach'}, 'summary': 'Consider a predictor who ranks eventualities on the basis of past cases: for\ninstance a search engine ranking webpages given past searches. Resampling past\ncases leads to different rankings and the extraction of deeper information. Yet\na rich database, with sufficiently diverse rankings, is often beyond reach.\nInexperience demands either ""on the fly"" learning-by-doing or prudence: the\narrival of a novel case does not force (i) a revision of current rankings, (ii)\ndogmatism towards new rankings, or (iii) intransitivity. For this higher-order\nframework of inductive inference, we derive a suitably unique numerical\nrepresentation of these rankings via a matrix on eventualities x cases and\ndescribe a robust test of prudence. Applications include: the success/failure\nof startups; the veracity of fake news; and novel conditions for the existence\nof a yield curve that is robustly arbitrage-free.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Consider a predictor who ranks eventualities on the basis of past cases: for\ninstance a search engine ranking webpages given past searches. Resampling past\ncases leads to different rankings and the extraction of deeper information. Yet\na rich database, with sufficiently diverse rankings, is often beyond reach.\nInexperience demands either ""on the fly"" learning-by-doing or prudence: the\narrival of a novel case does not force (i) a revision of current rankings, (ii)\ndogmatism towards new rankings, or (iii) intransitivity. For this higher-order\nframework of inductive inference, we derive a suitably unique numerical\nrepresentation of these rankings via a matrix on eventualities x cases and\ndescribe a robust test of prudence. Applications include: the success/failure\nof startups; the veracity of fake news; and novel conditions for the existence\nof a yield curve that is robustly arbitrage-free.'}, 'authors': [{'name': ""Patrick H. O'Callaghan""}], 'author_detail': {'name': ""Patrick H. O'Callaghan""}, 'author': ""Patrick H. O'Callaghan"", 'links': [{'href': 'http://arxiv.org/abs/1904.02934v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.02934v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.EM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
330,http://arxiv.org/abs/1904.03016v1,2019-04-04 06:23:25+00:00,2019-04-04 06:23:25+00:00,Open Issues in Combating Fake News: Interpretability as an Opportunity,"[arxiv.Result.Author('Sina Mohseni'), arxiv.Result.Author('Eric Ragan'), arxiv.Result.Author('Xia Hu')]","Combating fake news needs a variety of defense methods. Although rumor
detection and various linguistic analysis techniques are common methods to
detect false content in social media, there are other feasible mitigation
approaches that could be explored in the machine learning community. In this
paper, we present open issues and opportunities in fake news research that need
further attention. We first review different stages of the news life cycle in
social media and discuss core vulnerability issues for news feed algorithms in
propagating fake news content with three examples. We then discuss how
complexity and unclarity of the fake news problem limit the advancements in
this field. Lastly, we present research opportunities from interpretable
machine learning to mitigate fake news problems with 1) interpretable fake news
detection and 2) transparent news feed algorithms. We propose three dimensions
of interpretability consisting of algorithmic interpretability, human
interpretability, and the inclusion of supporting evidence that can benefit
fake news mitigation methods in different ways.",arXiv admin note: text overlap with arXiv:1811.12349,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1904.03016v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.03016v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.03016v1,"{'id': 'http://arxiv.org/abs/1904.03016v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.03016v1', 'updated': '2019-04-04T06:23:25Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=4, tm_hour=6, tm_min=23, tm_sec=25, tm_wday=3, tm_yday=94, tm_isdst=0), 'published': '2019-04-04T06:23:25Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=4, tm_hour=6, tm_min=23, tm_sec=25, tm_wday=3, tm_yday=94, tm_isdst=0), 'title': 'Open Issues in Combating Fake News: Interpretability as an Opportunity', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Open Issues in Combating Fake News: Interpretability as an Opportunity'}, 'summary': 'Combating fake news needs a variety of defense methods. Although rumor\ndetection and various linguistic analysis techniques are common methods to\ndetect false content in social media, there are other feasible mitigation\napproaches that could be explored in the machine learning community. In this\npaper, we present open issues and opportunities in fake news research that need\nfurther attention. We first review different stages of the news life cycle in\nsocial media and discuss core vulnerability issues for news feed algorithms in\npropagating fake news content with three examples. We then discuss how\ncomplexity and unclarity of the fake news problem limit the advancements in\nthis field. Lastly, we present research opportunities from interpretable\nmachine learning to mitigate fake news problems with 1) interpretable fake news\ndetection and 2) transparent news feed algorithms. We propose three dimensions\nof interpretability consisting of algorithmic interpretability, human\ninterpretability, and the inclusion of supporting evidence that can benefit\nfake news mitigation methods in different ways.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating fake news needs a variety of defense methods. Although rumor\ndetection and various linguistic analysis techniques are common methods to\ndetect false content in social media, there are other feasible mitigation\napproaches that could be explored in the machine learning community. In this\npaper, we present open issues and opportunities in fake news research that need\nfurther attention. We first review different stages of the news life cycle in\nsocial media and discuss core vulnerability issues for news feed algorithms in\npropagating fake news content with three examples. We then discuss how\ncomplexity and unclarity of the fake news problem limit the advancements in\nthis field. Lastly, we present research opportunities from interpretable\nmachine learning to mitigate fake news problems with 1) interpretable fake news\ndetection and 2) transparent news feed algorithms. We propose three dimensions\nof interpretability consisting of algorithmic interpretability, human\ninterpretability, and the inclusion of supporting evidence that can benefit\nfake news mitigation methods in different ways.'}, 'authors': [{'name': 'Sina Mohseni'}, {'name': 'Eric Ragan'}, {'name': 'Xia Hu'}], 'author_detail': {'name': 'Xia Hu'}, 'author': 'Xia Hu', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1811.12349', 'links': [{'href': 'http://arxiv.org/abs/1904.03016v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.03016v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
331,http://arxiv.org/abs/1904.00712v2,2019-04-09 07:34:04+00:00,2019-04-01 11:59:50+00:00,NewsCompare - a novel application for detecting news influence in a country,"[arxiv.Result.Author('Cristian Pop'), arxiv.Result.Author('Alexandru Popa')]","The concept of `fake news' has been referenced and thrown around in news
reports so much in recent years that it has become a news topic in its own
right. At its core, it poses a chilling question -- what do we do if our
worldview is fundamentally wrong? Even if internally consistent, what if it
does not match the real world? Are our beliefs justified, or could we become
indoctrinated from living in a `bubble'? If the latter is true, how could we
even test the limits of said bubble from within its confines? We propose a new
method to augment the process of identifying fake news, by speeding up and
automating the more cumbersome and time-consuming tasks involved. Our
application, NewsCompare takes any list of target websites as input
(news-related in our use case, but otherwise not restricted), visits them in
parallel and retrieves any text content found within. Web pages are
subsequently compared to each other, and similarities are tentatively pointed
out. These results can be manually verified in order to determine which
websites tend to draw inspiration from one another. The data gathered on every
intermediate step can be queried and analyzed separately, and most notably we
already use the set of hyperlinks to and from the various websites we encounter
to paint a sort of `map' of that particular slice of the web. This map can then
be cross-referenced and further strengthen the conclusion that a particular
grouping of sites with strong links to each other, and posting similar content,
are likely to share the same allegiance. We run our application on the Romanian
news websites and we draw several interesting observations.","25 pages, 4 figures;",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1904.00712v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.00712v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.00712v2,"{'id': 'http://arxiv.org/abs/1904.00712v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.00712v2', 'updated': '2019-04-09T07:34:04Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=9, tm_hour=7, tm_min=34, tm_sec=4, tm_wday=1, tm_yday=99, tm_isdst=0), 'published': '2019-04-01T11:59:50Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=1, tm_hour=11, tm_min=59, tm_sec=50, tm_wday=0, tm_yday=91, tm_isdst=0), 'title': 'NewsCompare - a novel application for detecting news influence in a\n  country', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'NewsCompare - a novel application for detecting news influence in a\n  country'}, 'summary': ""The concept of `fake news' has been referenced and thrown around in news\nreports so much in recent years that it has become a news topic in its own\nright. At its core, it poses a chilling question -- what do we do if our\nworldview is fundamentally wrong? Even if internally consistent, what if it\ndoes not match the real world? Are our beliefs justified, or could we become\nindoctrinated from living in a `bubble'? If the latter is true, how could we\neven test the limits of said bubble from within its confines? We propose a new\nmethod to augment the process of identifying fake news, by speeding up and\nautomating the more cumbersome and time-consuming tasks involved. Our\napplication, NewsCompare takes any list of target websites as input\n(news-related in our use case, but otherwise not restricted), visits them in\nparallel and retrieves any text content found within. Web pages are\nsubsequently compared to each other, and similarities are tentatively pointed\nout. These results can be manually verified in order to determine which\nwebsites tend to draw inspiration from one another. The data gathered on every\nintermediate step can be queried and analyzed separately, and most notably we\nalready use the set of hyperlinks to and from the various websites we encounter\nto paint a sort of `map' of that particular slice of the web. This map can then\nbe cross-referenced and further strengthen the conclusion that a particular\ngrouping of sites with strong links to each other, and posting similar content,\nare likely to share the same allegiance. We run our application on the Romanian\nnews websites and we draw several interesting observations."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The concept of `fake news' has been referenced and thrown around in news\nreports so much in recent years that it has become a news topic in its own\nright. At its core, it poses a chilling question -- what do we do if our\nworldview is fundamentally wrong? Even if internally consistent, what if it\ndoes not match the real world? Are our beliefs justified, or could we become\nindoctrinated from living in a `bubble'? If the latter is true, how could we\neven test the limits of said bubble from within its confines? We propose a new\nmethod to augment the process of identifying fake news, by speeding up and\nautomating the more cumbersome and time-consuming tasks involved. Our\napplication, NewsCompare takes any list of target websites as input\n(news-related in our use case, but otherwise not restricted), visits them in\nparallel and retrieves any text content found within. Web pages are\nsubsequently compared to each other, and similarities are tentatively pointed\nout. These results can be manually verified in order to determine which\nwebsites tend to draw inspiration from one another. The data gathered on every\nintermediate step can be queried and analyzed separately, and most notably we\nalready use the set of hyperlinks to and from the various websites we encounter\nto paint a sort of `map' of that particular slice of the web. This map can then\nbe cross-referenced and further strengthen the conclusion that a particular\ngrouping of sites with strong links to each other, and posting similar content,\nare likely to share the same allegiance. We run our application on the Romanian\nnews websites and we draw several interesting observations.""}, 'authors': [{'name': 'Cristian Pop'}, {'name': 'Alexandru Popa'}], 'author_detail': {'name': 'Alexandru Popa'}, 'author': 'Alexandru Popa', 'arxiv_comment': '25 pages, 4 figures;', 'links': [{'href': 'http://arxiv.org/abs/1904.00712v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.00712v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
332,http://arxiv.org/abs/1904.00542v1,2019-04-01 02:54:54+00:00,2019-04-01 02:54:54+00:00,Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness and the Leading Political Ideology of News Media,"[arxiv.Result.Author('Ramy Baly'), arxiv.Result.Author('Georgi Karadzhov'), arxiv.Result.Author('Abdelrhman Saleh'), arxiv.Result.Author('James Glass'), arxiv.Result.Author('Preslav Nakov')]","In the context of fake news, bias, and propaganda, we study two important but
relatively under-explored problems: (i) trustworthiness estimation (on a
3-point scale) and (ii) political ideology detection (left/right bias on a
7-point scale) of entire news outlets, as opposed to evaluating individual
articles. In particular, we propose a multi-task ordinal regression framework
that models the two problems jointly. This is motivated by the observation that
hyper-partisanship is often linked to low trustworthiness, e.g., appealing to
emotions rather than sticking to the facts, while center media tend to be
generally more impartial and trustworthy. We further use several auxiliary
tasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias
on a coarse-grained scale. The evaluation results show sizable performance
gains by the joint models over models that target the problems in isolation.","Fact-checking, political ideology, news media, NAACL-2019",,,cs.IR,"['cs.IR', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1904.00542v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.00542v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.00542v1,"{'id': 'http://arxiv.org/abs/1904.00542v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.00542v1', 'updated': '2019-04-01T02:54:54Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=1, tm_hour=2, tm_min=54, tm_sec=54, tm_wday=0, tm_yday=91, tm_isdst=0), 'published': '2019-04-01T02:54:54Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=1, tm_hour=2, tm_min=54, tm_sec=54, tm_wday=0, tm_yday=91, tm_isdst=0), 'title': 'Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media'}, 'summary': 'In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.'}, 'authors': [{'name': 'Ramy Baly'}, {'name': 'Georgi Karadzhov'}, {'name': 'Abdelrhman Saleh'}, {'name': 'James Glass'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'arxiv_affiliation': 'Qatar Computing Research Institute, HBKU, Qatar', 'author': 'Preslav Nakov', 'arxiv_comment': 'Fact-checking, political ideology, news media, NAACL-2019', 'links': [{'href': 'http://arxiv.org/abs/1904.00542v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.00542v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
333,http://arxiv.org/abs/1903.11899v1,2019-03-28 11:24:30+00:00,2019-03-28 11:24:30+00:00,Using Blockchain to Rein in The New Post-Truth World and Check The Spread of Fake News,"[arxiv.Result.Author('Adnan Qayyum'), arxiv.Result.Author('Junaid Qadir'), arxiv.Result.Author('Muhammad Umar Janjua'), arxiv.Result.Author('Falak Sher')]","In recent years, `fake news' has become a global issue that raises
unprecedented challenges for human society and democracy. This problem has
arisen due to the emergence of various concomitant phenomena such as (1) the
digitization of human life and the ease of disseminating news through social
networking applications (such as Facebook and WhatsApp); (2) the availability
of `big data' that allows customization of news feeds and the creation of
polarized so-called `filter-bubbles'; and (3) the rapid progress made by
generative machine learning (ML) and deep learning (DL) algorithms in creating
realistic-looking yet fake digital content (such as text, images, and videos).
There is a crucial need to combat the rampant rise of fake news and
disinformation. In this paper, we propose a high-level overview of a
blockchain-based framework for fake news prevention and highlight the various
design issues and consideration of such a blockchain-based framework for
tackling fake news.","This paper has been accepted at IEEE IT Professional magazine.
  Personal use of this material is permitted, permission from IEEE must be
  obtained for all other uses",,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/1903.11899v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.11899v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.11899v1,"{'id': 'http://arxiv.org/abs/1903.11899v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.11899v1', 'updated': '2019-03-28T11:24:30Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=28, tm_hour=11, tm_min=24, tm_sec=30, tm_wday=3, tm_yday=87, tm_isdst=0), 'published': '2019-03-28T11:24:30Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=28, tm_hour=11, tm_min=24, tm_sec=30, tm_wday=3, tm_yday=87, tm_isdst=0), 'title': 'Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News'}, 'summary': ""In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news.""}, 'authors': [{'name': 'Adnan Qayyum'}, {'name': 'Junaid Qadir'}, {'name': 'Muhammad Umar Janjua'}, {'name': 'Falak Sher'}], 'author_detail': {'name': 'Falak Sher'}, 'author': 'Falak Sher', 'arxiv_comment': 'This paper has been accepted at IEEE IT Professional magazine.\n  Personal use of this material is permitted, permission from IEEE must be\n  obtained for all other uses', 'links': [{'href': 'http://arxiv.org/abs/1903.11899v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.11899v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
334,http://arxiv.org/abs/1903.11452v3,2020-08-20 20:19:03+00:00,2019-03-27 14:28:17+00:00,Lexical convergence and collective identities on Facebook,"[arxiv.Result.Author('Emanuele Brugnoli'), arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Fabiana Zollo'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Antonio Scala')]","Recent studies, targeting Facebook, showed the tendency of users to interact
with information adhering to their preferred narrative and to ignore dissenting
information. Primarily driven by confirmation bias, users tend to join
polarized clusters where they cooperate to reinforce a like-minded system of
beliefs, thus facilitating fake news and misinformation cascades. To gain a
deeper understanding of these phenomena, in this work we analyze the lexicons
used by the communities of users emerging on Facebook around verified and
unverified contents. We show how the lexical approach provides important
insights about the kind of information processed by the two communities of
users and about their overall sentiment. Furthermore, by focusing on comment
threads, we observe a strong positive correlation between the lexical
convergence of co-commenters and their number of interactions, which in turns
suggests that such a trend could be a proxy for the emergence of collective
identities and polarization in opinion dynamics.","11 pages, 9 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph', '91F20']","[arxiv.Result.Link('http://arxiv.org/abs/1903.11452v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.11452v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.11452v3,"{'id': 'http://arxiv.org/abs/1903.11452v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.11452v3', 'updated': '2020-08-20T20:19:03Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=20, tm_hour=20, tm_min=19, tm_sec=3, tm_wday=3, tm_yday=233, tm_isdst=0), 'published': '2019-03-27T14:28:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=27, tm_hour=14, tm_min=28, tm_sec=17, tm_wday=2, tm_yday=86, tm_isdst=0), 'title': 'Lexical convergence and collective identities on Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Lexical convergence and collective identities on Facebook'}, 'summary': 'Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.'}, 'authors': [{'name': 'Emanuele Brugnoli'}, {'name': 'Matteo Cinelli'}, {'name': 'Fabiana Zollo'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Antonio Scala'}], 'author_detail': {'name': 'Antonio Scala'}, 'author': 'Antonio Scala', 'arxiv_comment': '11 pages, 9 figures', 'links': [{'href': 'http://arxiv.org/abs/1903.11452v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.11452v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '91F20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
335,http://arxiv.org/abs/1904.00788v2,2019-12-12 07:46:43+00:00,2019-03-24 07:27:51+00:00,Neural Abstractive Text Summarization and Fake News Detection,"[arxiv.Result.Author('Soheil Esmaeilzadeh'), arxiv.Result.Author('Gao Xian Peh'), arxiv.Result.Author('Angela Xu')]","In this work, we study abstractive text summarization by exploring different
models such as LSTM-encoder-decoder with attention, pointer-generator networks,
coverage mechanisms, and transformers. Upon extensive and careful
hyperparameter tuning we compare the proposed architectures against each other
for the abstractive text summarization task. Finally, as an extension of our
work, we apply our text summarization model as a feature extractor for a fake
news detection task where the news articles prior to classification will be
summarized and the results are compared against the classification using only
the original news text.
  keywords: LSTM, encoder-deconder, abstractive text summarization,
pointer-generator, coverage mechanism, transformers, fake news detection",,,,cs.CL,"['cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1904.00788v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.00788v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.00788v2,"{'id': 'http://arxiv.org/abs/1904.00788v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.00788v2', 'updated': '2019-12-12T07:46:43Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=12, tm_hour=7, tm_min=46, tm_sec=43, tm_wday=3, tm_yday=346, tm_isdst=0), 'published': '2019-03-24T07:27:51Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=24, tm_hour=7, tm_min=27, tm_sec=51, tm_wday=6, tm_yday=83, tm_isdst=0), 'title': 'Neural Abstractive Text Summarization and Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Neural Abstractive Text Summarization and Fake News Detection'}, 'summary': 'In this work, we study abstractive text summarization by exploring different\nmodels such as LSTM-encoder-decoder with attention, pointer-generator networks,\ncoverage mechanisms, and transformers. Upon extensive and careful\nhyperparameter tuning we compare the proposed architectures against each other\nfor the abstractive text summarization task. Finally, as an extension of our\nwork, we apply our text summarization model as a feature extractor for a fake\nnews detection task where the news articles prior to classification will be\nsummarized and the results are compared against the classification using only\nthe original news text.\n  keywords: LSTM, encoder-deconder, abstractive text summarization,\npointer-generator, coverage mechanism, transformers, fake news detection', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work, we study abstractive text summarization by exploring different\nmodels such as LSTM-encoder-decoder with attention, pointer-generator networks,\ncoverage mechanisms, and transformers. Upon extensive and careful\nhyperparameter tuning we compare the proposed architectures against each other\nfor the abstractive text summarization task. Finally, as an extension of our\nwork, we apply our text summarization model as a feature extractor for a fake\nnews detection task where the news articles prior to classification will be\nsummarized and the results are compared against the classification using only\nthe original news text.\n  keywords: LSTM, encoder-deconder, abstractive text summarization,\npointer-generator, coverage mechanism, transformers, fake news detection'}, 'authors': [{'name': 'Soheil Esmaeilzadeh'}, {'name': 'Gao Xian Peh'}, {'name': 'Angela Xu'}], 'author_detail': {'name': 'Angela Xu'}, 'author': 'Angela Xu', 'links': [{'href': 'http://arxiv.org/abs/1904.00788v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.00788v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
336,http://arxiv.org/abs/1903.09196v1,2019-03-21 18:57:35+00:00,2019-03-21 18:57:35+00:00,Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Deepak Mahudeswaran'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Huan Liu')]","Consuming news from social media is becoming increasingly popular. However,
social media also enables the widespread of fake news. Because of its
detrimental effects brought by social media, fake news detection has attracted
increasing attention. However, the performance of detecting fake news only from
news content is generally limited as fake news pieces are written to mimic true
news. In the real world, news pieces spread through propagation networks on
social media. The news propagation networks usually involve multi-levels. In
this paper, we study the challenging problem of investigating and exploiting
news hierarchical propagation network on social media for fake news detection.
  In an attempt to understand the correlations between news propagation
networks and fake news, first, we build a hierarchical propagation network from
macro-level and micro-level of fake news and true news; second, we perform a
comparative analysis of the propagation network features of linguistic,
structural and temporal perspectives between fake and real news, which
demonstrates the potential of utilizing these features to detect fake news;
third, we show the effectiveness of these propagation network features for fake
news detection. We further validate the effectiveness of these features from
feature important analysis. Altogether, this work presents a data-driven view
of hierarchical propagation network and fake news and paves the way towards a
healthier online news ecosystem.",10 pages,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1903.09196v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.09196v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.09196v1,"{'id': 'http://arxiv.org/abs/1903.09196v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.09196v1', 'updated': '2019-03-21T18:57:35Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=21, tm_hour=18, tm_min=57, tm_sec=35, tm_wday=3, tm_yday=80, tm_isdst=0), 'published': '2019-03-21T18:57:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=21, tm_hour=18, tm_min=57, tm_sec=35, tm_wday=3, tm_yday=80, tm_isdst=0), 'title': 'Hierarchical Propagation Networks for Fake News Detection: Investigation\n  and Exploitation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hierarchical Propagation Networks for Fake News Detection: Investigation\n  and Exploitation'}, 'summary': 'Consuming news from social media is becoming increasingly popular. However,\nsocial media also enables the widespread of fake news. Because of its\ndetrimental effects brought by social media, fake news detection has attracted\nincreasing attention. However, the performance of detecting fake news only from\nnews content is generally limited as fake news pieces are written to mimic true\nnews. In the real world, news pieces spread through propagation networks on\nsocial media. The news propagation networks usually involve multi-levels. In\nthis paper, we study the challenging problem of investigating and exploiting\nnews hierarchical propagation network on social media for fake news detection.\n  In an attempt to understand the correlations between news propagation\nnetworks and fake news, first, we build a hierarchical propagation network from\nmacro-level and micro-level of fake news and true news; second, we perform a\ncomparative analysis of the propagation network features of linguistic,\nstructural and temporal perspectives between fake and real news, which\ndemonstrates the potential of utilizing these features to detect fake news;\nthird, we show the effectiveness of these propagation network features for fake\nnews detection. We further validate the effectiveness of these features from\nfeature important analysis. Altogether, this work presents a data-driven view\nof hierarchical propagation network and fake news and paves the way towards a\nhealthier online news ecosystem.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Consuming news from social media is becoming increasingly popular. However,\nsocial media also enables the widespread of fake news. Because of its\ndetrimental effects brought by social media, fake news detection has attracted\nincreasing attention. However, the performance of detecting fake news only from\nnews content is generally limited as fake news pieces are written to mimic true\nnews. In the real world, news pieces spread through propagation networks on\nsocial media. The news propagation networks usually involve multi-levels. In\nthis paper, we study the challenging problem of investigating and exploiting\nnews hierarchical propagation network on social media for fake news detection.\n  In an attempt to understand the correlations between news propagation\nnetworks and fake news, first, we build a hierarchical propagation network from\nmacro-level and micro-level of fake news and true news; second, we perform a\ncomparative analysis of the propagation network features of linguistic,\nstructural and temporal perspectives between fake and real news, which\ndemonstrates the potential of utilizing these features to detect fake news;\nthird, we show the effectiveness of these propagation network features for fake\nnews detection. We further validate the effectiveness of these features from\nfeature important analysis. Altogether, this work presents a data-driven view\nof hierarchical propagation network and fake news and paves the way towards a\nhealthier online news ecosystem.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Deepak Mahudeswaran'}, {'name': 'Suhang Wang'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '10 pages', 'links': [{'href': 'http://arxiv.org/abs/1903.09196v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.09196v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
337,http://arxiv.org/abs/1903.08404v1,2019-03-20 09:40:19+00:00,2019-03-20 09:40:19+00:00,Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences for Fact-Checking,"[arxiv.Result.Author('Casper Hansen'), arxiv.Result.Author('Christian Hansen'), arxiv.Result.Author('Stephen Alstrup'), arxiv.Result.Author('Jakob Grue Simonsen'), arxiv.Result.Author('Christina Lioma')]","Automatic fact-checking systems detect misinformation, such as fake news, by
(i) selecting check-worthy sentences for fact-checking, (ii) gathering related
information to the sentences, and (iii) inferring the factuality of the
sentences. Most prior research on (i) uses hand-crafted features to select
check-worthy sentences, and does not explicitly account for the recent finding
that the top weighted terms in both check-worthy and non-check-worthy sentences
are actually overlapping [15]. Motivated by this, we present a neural
check-worthiness sentence ranking model that represents each word in a sentence
by \textit{both} its embedding (aiming to capture its semantics) and its
syntactic dependencies (aiming to capture its role in modifying the semantics
of other terms in the sentence). Our model is an end-to-end trainable neural
network for check-worthiness ranking, which is trained on large amounts of
unlabelled data through weak supervision. Thorough experimental evaluation
against state of the art baselines, with and without weak supervision, shows
our model to be superior at all times (+13% in MAP and +28% at various
Precision cut-offs from the best baseline with statistical significance).
Empirical analysis of the use of weak supervision, word embedding pretraining
on domain-specific data, and the use of syntactic dependencies of our model
reveals that check-worthy sentences contain notably more identical syntactic
dependencies than non-check-worthy sentences.",6 pages,In Companion Proceedings of the 2019 World Wide Web Conference,,cs.IR,"['cs.IR', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1903.08404v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.08404v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.08404v1,"{'id': 'http://arxiv.org/abs/1903.08404v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.08404v1', 'updated': '2019-03-20T09:40:19Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=20, tm_hour=9, tm_min=40, tm_sec=19, tm_wday=2, tm_yday=79, tm_isdst=0), 'published': '2019-03-20T09:40:19Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=20, tm_hour=9, tm_min=40, tm_sec=19, tm_wday=2, tm_yday=79, tm_isdst=0), 'title': 'Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking'}, 'summary': 'Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.'}, 'authors': [{'name': 'Casper Hansen'}, {'name': 'Christian Hansen'}, {'name': 'Stephen Alstrup'}, {'name': 'Jakob Grue Simonsen'}, {'name': 'Christina Lioma'}], 'author_detail': {'name': 'Christina Lioma'}, 'author': 'Christina Lioma', 'arxiv_comment': '6 pages', 'arxiv_journal_ref': 'In Companion Proceedings of the 2019 World Wide Web Conference', 'links': [{'href': 'http://arxiv.org/abs/1903.08404v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.08404v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
338,http://arxiv.org/abs/1903.01780v1,2019-03-05 12:10:11+00:00,2019-03-05 12:10:11+00:00,Trust and Trustworthiness in Social Recommender Systems,"[arxiv.Result.Author('Taha Hassan'), arxiv.Result.Author('D. Scott McCrickard')]","The prevalence of misinformation on online social media has tangible
empirical connections to increasing political polarization and partisan
antipathy in the United States. Ranking algorithms for social recommendation
often encode broad assumptions about network structure (like homophily) and
group cognition (like, social action is largely imitative). Assumptions like
these can be na\""ive and exclusionary in the era of fake news and ideological
uniformity towards the political poles. We examine these assumptions with aid
from the user-centric framework of trustworthiness in social recommendation.
The constituent dimensions of trustworthiness (diversity, transparency,
explainability, disruption) highlight new opportunities for discouraging
dogmatization and building decision-aware, transparent news recommender
systems.",WWW '19 FATES,,,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/1903.01780v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.01780v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.01780v1,"{'id': 'http://arxiv.org/abs/1903.01780v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.01780v1', 'updated': '2019-03-05T12:10:11Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=12, tm_min=10, tm_sec=11, tm_wday=1, tm_yday=64, tm_isdst=0), 'published': '2019-03-05T12:10:11Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=12, tm_min=10, tm_sec=11, tm_wday=1, tm_yday=64, tm_isdst=0), 'title': 'Trust and Trustworthiness in Social Recommender Systems', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trust and Trustworthiness in Social Recommender Systems'}, 'summary': 'The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\""ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\""ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.'}, 'authors': [{'name': 'Taha Hassan'}, {'name': 'D. Scott McCrickard'}], 'author_detail': {'name': 'D. Scott McCrickard'}, 'author': 'D. Scott McCrickard', 'arxiv_comment': ""WWW '19 FATES"", 'links': [{'href': 'http://arxiv.org/abs/1903.01780v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.01780v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
339,http://arxiv.org/abs/1903.01728v4,2021-02-14 08:23:51+00:00,2019-03-05 08:52:33+00:00,Mining Dual Emotion for Fake News Detection,"[arxiv.Result.Author('Xueyao Zhang'), arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('Xirong Li'), arxiv.Result.Author('Qiang Sheng'), arxiv.Result.Author('Lei Zhong'), arxiv.Result.Author('Kai Shu')]","Emotion plays an important role in detecting fake news online. When
leveraging emotional signals, the existing methods focus on exploiting the
emotions of news contents that conveyed by the publishers (i.e., publisher
emotion). However, fake news often evokes high-arousal or activating emotions
of people, so the emotions of news comments aroused in the crowd (i.e., social
emotion) should not be ignored. Furthermore, it remains to be explored whether
there exists a relationship between publisher emotion and social emotion (i.e.,
dual emotion), and how the dual emotion appears in fake news. In this paper, we
verify that dual emotion is distinctive between fake and real news and propose
Dual Emotion Features to represent dual emotion and the relationship between
them for fake news detection. Further, we exhibit that our proposed features
can be easily plugged into existing fake news detectors as an enhancement.
Extensive experiments on three real-world datasets (one in English and the
others in Chinese) show that our proposed feature set: 1) outperforms the
state-of-the-art task-related emotional features; 2) can be well compatible
with existing fake news detectors and effectively improve the performance of
detecting fake news.",Accepted by WWW 2021,,10.1145/3442381.3450004,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3442381.3450004', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1903.01728v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.01728v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.01728v4,"{'id': 'http://arxiv.org/abs/1903.01728v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.01728v4', 'updated': '2021-02-14T08:23:51Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=14, tm_hour=8, tm_min=23, tm_sec=51, tm_wday=6, tm_yday=45, tm_isdst=0), 'published': '2019-03-05T08:52:33Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=8, tm_min=52, tm_sec=33, tm_wday=1, tm_yday=64, tm_isdst=0), 'title': 'Mining Dual Emotion for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mining Dual Emotion for Fake News Detection'}, 'summary': 'Emotion plays an important role in detecting fake news online. When\nleveraging emotional signals, the existing methods focus on exploiting the\nemotions of news contents that conveyed by the publishers (i.e., publisher\nemotion). However, fake news often evokes high-arousal or activating emotions\nof people, so the emotions of news comments aroused in the crowd (i.e., social\nemotion) should not be ignored. Furthermore, it remains to be explored whether\nthere exists a relationship between publisher emotion and social emotion (i.e.,\ndual emotion), and how the dual emotion appears in fake news. In this paper, we\nverify that dual emotion is distinctive between fake and real news and propose\nDual Emotion Features to represent dual emotion and the relationship between\nthem for fake news detection. Further, we exhibit that our proposed features\ncan be easily plugged into existing fake news detectors as an enhancement.\nExtensive experiments on three real-world datasets (one in English and the\nothers in Chinese) show that our proposed feature set: 1) outperforms the\nstate-of-the-art task-related emotional features; 2) can be well compatible\nwith existing fake news detectors and effectively improve the performance of\ndetecting fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Emotion plays an important role in detecting fake news online. When\nleveraging emotional signals, the existing methods focus on exploiting the\nemotions of news contents that conveyed by the publishers (i.e., publisher\nemotion). However, fake news often evokes high-arousal or activating emotions\nof people, so the emotions of news comments aroused in the crowd (i.e., social\nemotion) should not be ignored. Furthermore, it remains to be explored whether\nthere exists a relationship between publisher emotion and social emotion (i.e.,\ndual emotion), and how the dual emotion appears in fake news. In this paper, we\nverify that dual emotion is distinctive between fake and real news and propose\nDual Emotion Features to represent dual emotion and the relationship between\nthem for fake news detection. Further, we exhibit that our proposed features\ncan be easily plugged into existing fake news detectors as an enhancement.\nExtensive experiments on three real-world datasets (one in English and the\nothers in Chinese) show that our proposed feature set: 1) outperforms the\nstate-of-the-art task-related emotional features; 2) can be well compatible\nwith existing fake news detectors and effectively improve the performance of\ndetecting fake news.'}, 'authors': [{'name': 'Xueyao Zhang'}, {'name': 'Juan Cao'}, {'name': 'Xirong Li'}, {'name': 'Qiang Sheng'}, {'name': 'Lei Zhong'}, {'name': 'Kai Shu'}], 'author_detail': {'name': 'Kai Shu'}, 'author': 'Kai Shu', 'arxiv_doi': '10.1145/3442381.3450004', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3442381.3450004', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1903.01728v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.01728v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted by WWW 2021', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
340,http://arxiv.org/abs/1903.00449v2,2019-05-09 12:19:03+00:00,2019-03-01 18:20:24+00:00,TEEvil: Identity Lease via Trusted Execution Environments,"[arxiv.Result.Author('Ivan Puddu'), arxiv.Result.Author('Daniele Lain'), arxiv.Result.Author('Moritz Schneider'), arxiv.Result.Author('Elizaveta Tretiakova'), arxiv.Result.Author('Sinisa Matetic'), arxiv.Result.Author('Srdjan Capkun')]","We investigate identity lease, a new type of service in which users lease
their identities to third parties by providing them with full or restricted
access to their online accounts or credentials. We discuss how identity lease
could be abused to subvert the digital society, facilitating the spread of fake
news and subverting electronic voting by enabling the sale of votes. We show
that the emergence of Trusted Execution Environments and anonymous
cryptocurrencies, for the first time, allows the implementation of such a lease
service while guaranteeing fairness, plausible deniability and anonymity,
therefore shielding the users and account renters from prosecution. To show
that such a service can be practically implemented, we build an example service
that we call TEEvil leveraging Intel SGX and ZCash. Finally, we discuss defense
mechanisms and challenges in the mitigation of identity lease services.","21 pages, 5 figures",,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/1903.00449v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.00449v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.00449v2,"{'id': 'http://arxiv.org/abs/1903.00449v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.00449v2', 'updated': '2019-05-09T12:19:03Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=9, tm_hour=12, tm_min=19, tm_sec=3, tm_wday=3, tm_yday=129, tm_isdst=0), 'published': '2019-03-01T18:20:24Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=18, tm_min=20, tm_sec=24, tm_wday=4, tm_yday=60, tm_isdst=0), 'title': 'TEEvil: Identity Lease via Trusted Execution Environments', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TEEvil: Identity Lease via Trusted Execution Environments'}, 'summary': 'We investigate identity lease, a new type of service in which users lease\ntheir identities to third parties by providing them with full or restricted\naccess to their online accounts or credentials. We discuss how identity lease\ncould be abused to subvert the digital society, facilitating the spread of fake\nnews and subverting electronic voting by enabling the sale of votes. We show\nthat the emergence of Trusted Execution Environments and anonymous\ncryptocurrencies, for the first time, allows the implementation of such a lease\nservice while guaranteeing fairness, plausible deniability and anonymity,\ntherefore shielding the users and account renters from prosecution. To show\nthat such a service can be practically implemented, we build an example service\nthat we call TEEvil leveraging Intel SGX and ZCash. Finally, we discuss defense\nmechanisms and challenges in the mitigation of identity lease services.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We investigate identity lease, a new type of service in which users lease\ntheir identities to third parties by providing them with full or restricted\naccess to their online accounts or credentials. We discuss how identity lease\ncould be abused to subvert the digital society, facilitating the spread of fake\nnews and subverting electronic voting by enabling the sale of votes. We show\nthat the emergence of Trusted Execution Environments and anonymous\ncryptocurrencies, for the first time, allows the implementation of such a lease\nservice while guaranteeing fairness, plausible deniability and anonymity,\ntherefore shielding the users and account renters from prosecution. To show\nthat such a service can be practically implemented, we build an example service\nthat we call TEEvil leveraging Intel SGX and ZCash. Finally, we discuss defense\nmechanisms and challenges in the mitigation of identity lease services.'}, 'authors': [{'name': 'Ivan Puddu'}, {'name': 'Daniele Lain'}, {'name': 'Moritz Schneider'}, {'name': 'Elizaveta Tretiakova'}, {'name': 'Sinisa Matetic'}, {'name': 'Srdjan Capkun'}], 'author_detail': {'name': 'Srdjan Capkun'}, 'author': 'Srdjan Capkun', 'arxiv_comment': '21 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/1903.00449v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.00449v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
341,http://arxiv.org/abs/1903.07389v6,2019-04-10 14:20:53+00:00,2019-02-27 00:03:17+00:00,Learning Hierarchical Discourse-level Structure for Fake News Detection,"[arxiv.Result.Author('Hamid Karimi'), arxiv.Result.Author('Jiliang Tang')]","On the one hand, nowadays, fake news articles are easily propagated through
various online media platforms and have become a grand threat to the
trustworthiness of information. On the other hand, our understanding of the
language of fake news is still minimal. Incorporating hierarchical
discourse-level structure of fake and real news articles is one crucial step
toward a better understanding of how these articles are structured.
Nevertheless, this has rarely been investigated in the fake news detection
domain and faces tremendous challenges. First, existing methods for capturing
discourse-level structure rely on annotated corpora which are not available for
fake news datasets. Second, how to extract out useful information from such
discovered structures is another challenge. To address these challenges, we
propose Hierarchical Discourse-level Structure for Fake news detection. HDSF
learns and constructs a discourse-level structure for fake/real news articles
in an automated and data-driven manner. Moreover, we identify insightful
structure-related properties, which can explain the discovered structures and
boost our understating of fake news. Conducted experiments show the
effectiveness of the proposed approach. Further structural analysis suggests
that real and fake news present substantial differences in the hierarchical
discourse-level structures.","Accepted to 2019 Annual Conference of the North American Chapter of
  the Association for Computational Linguistics June 2-7, 2019 Minneapolis, USA",,,cs.CL,"['cs.CL', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1903.07389v6', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.07389v6', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.07389v6,"{'id': 'http://arxiv.org/abs/1903.07389v6', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.07389v6', 'updated': '2019-04-10T14:20:53Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=10, tm_hour=14, tm_min=20, tm_sec=53, tm_wday=2, tm_yday=100, tm_isdst=0), 'published': '2019-02-27T00:03:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=27, tm_hour=0, tm_min=3, tm_sec=17, tm_wday=2, tm_yday=58, tm_isdst=0), 'title': 'Learning Hierarchical Discourse-level Structure for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Learning Hierarchical Discourse-level Structure for Fake News Detection'}, 'summary': 'On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.'}, 'authors': [{'name': 'Hamid Karimi'}, {'name': 'Jiliang Tang'}], 'author_detail': {'name': 'Jiliang Tang'}, 'author': 'Jiliang Tang', 'arxiv_comment': 'Accepted to 2019 Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics June 2-7, 2019 Minneapolis, USA', 'links': [{'href': 'http://arxiv.org/abs/1903.07389v6', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.07389v6', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
342,http://arxiv.org/abs/1902.07636v1,2019-02-20 16:47:04+00:00,2019-02-20 16:47:04+00:00,Contributive Social Capital Extraction From Different Types of Online Data Sources,"[arxiv.Result.Author('Sebastian Schams'), arxiv.Result.Author('Georg Groh')]","It is a recurring problem of online communication that the properties of
unknown people are hard to assess. This may lead to various issues such as the
spread of `fake news' from untrustworthy sources. In sociology the sum of
(social) resources available to a person through their social network is often
described as social capital. In this article, we look at social capital from a
different angle. Instead of evaluating the advantage that people have because
of their membership in a certain group, we investigate various ways to infer
the social capital a person adds or may add to the network, their contributive
social capital (CSC). As there is no consensus in the literature on what the
social capital of a person exactly consists of, we look at various related
properties: expertise, reputation, trustworthiness, and influence. The analysis
of these features is investigated for five different sources of online data:
microblogging (e.g., Twitter), social networking platforms (e.g., Facebook),
direct communication (e.g., email), scientometrics, and threaded discussion
boards (e.g., Reddit). In each field we discuss recent publications and put a
focus on the data sources used, the algorithms implemented, and the performance
evaluation. The findings are compared and set in context to contributive social
capital extraction. The analysis algorithms are based on individual features
(e.g., followers on Twitter), ratios thereof, or a person's centrality measures
(e.g., PageRank). The machine learning approaches, such as straightforward
classifiers (e.g., support vector machines) use ground truths that are
connected to social capital. The discussion of these methods is intended to
facilitate research on the topic by identifying relevant data sources and the
best suited algorithms, and by providing tested methods for the evaluation of
findings.",44 pages,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1902.07636v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.07636v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.07636v1,"{'id': 'http://arxiv.org/abs/1902.07636v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.07636v1', 'updated': '2019-02-20T16:47:04Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=47, tm_sec=4, tm_wday=2, tm_yday=51, tm_isdst=0), 'published': '2019-02-20T16:47:04Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=47, tm_sec=4, tm_wday=2, tm_yday=51, tm_isdst=0), 'title': 'Contributive Social Capital Extraction From Different Types of Online\n  Data Sources', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Contributive Social Capital Extraction From Different Types of Online\n  Data Sources'}, 'summary': ""It is a recurring problem of online communication that the properties of\nunknown people are hard to assess. This may lead to various issues such as the\nspread of `fake news' from untrustworthy sources. In sociology the sum of\n(social) resources available to a person through their social network is often\ndescribed as social capital. In this article, we look at social capital from a\ndifferent angle. Instead of evaluating the advantage that people have because\nof their membership in a certain group, we investigate various ways to infer\nthe social capital a person adds or may add to the network, their contributive\nsocial capital (CSC). As there is no consensus in the literature on what the\nsocial capital of a person exactly consists of, we look at various related\nproperties: expertise, reputation, trustworthiness, and influence. The analysis\nof these features is investigated for five different sources of online data:\nmicroblogging (e.g., Twitter), social networking platforms (e.g., Facebook),\ndirect communication (e.g., email), scientometrics, and threaded discussion\nboards (e.g., Reddit). In each field we discuss recent publications and put a\nfocus on the data sources used, the algorithms implemented, and the performance\nevaluation. The findings are compared and set in context to contributive social\ncapital extraction. The analysis algorithms are based on individual features\n(e.g., followers on Twitter), ratios thereof, or a person's centrality measures\n(e.g., PageRank). The machine learning approaches, such as straightforward\nclassifiers (e.g., support vector machines) use ground truths that are\nconnected to social capital. The discussion of these methods is intended to\nfacilitate research on the topic by identifying relevant data sources and the\nbest suited algorithms, and by providing tested methods for the evaluation of\nfindings."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""It is a recurring problem of online communication that the properties of\nunknown people are hard to assess. This may lead to various issues such as the\nspread of `fake news' from untrustworthy sources. In sociology the sum of\n(social) resources available to a person through their social network is often\ndescribed as social capital. In this article, we look at social capital from a\ndifferent angle. Instead of evaluating the advantage that people have because\nof their membership in a certain group, we investigate various ways to infer\nthe social capital a person adds or may add to the network, their contributive\nsocial capital (CSC). As there is no consensus in the literature on what the\nsocial capital of a person exactly consists of, we look at various related\nproperties: expertise, reputation, trustworthiness, and influence. The analysis\nof these features is investigated for five different sources of online data:\nmicroblogging (e.g., Twitter), social networking platforms (e.g., Facebook),\ndirect communication (e.g., email), scientometrics, and threaded discussion\nboards (e.g., Reddit). In each field we discuss recent publications and put a\nfocus on the data sources used, the algorithms implemented, and the performance\nevaluation. The findings are compared and set in context to contributive social\ncapital extraction. The analysis algorithms are based on individual features\n(e.g., followers on Twitter), ratios thereof, or a person's centrality measures\n(e.g., PageRank). The machine learning approaches, such as straightforward\nclassifiers (e.g., support vector machines) use ground truths that are\nconnected to social capital. The discussion of these methods is intended to\nfacilitate research on the topic by identifying relevant data sources and the\nbest suited algorithms, and by providing tested methods for the evaluation of\nfindings.""}, 'authors': [{'name': 'Sebastian Schams'}, {'name': 'Georg Groh'}], 'author_detail': {'name': 'Georg Groh'}, 'author': 'Georg Groh', 'arxiv_comment': '44 pages', 'links': [{'href': 'http://arxiv.org/abs/1902.07636v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.07636v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
343,http://arxiv.org/abs/1902.06673v1,2019-02-10 15:21:45+00:00,2019-02-10 15:21:45+00:00,Fake News Detection on Social Media using Geometric Deep Learning,"[arxiv.Result.Author('Federico Monti'), arxiv.Result.Author('Fabrizio Frasca'), arxiv.Result.Author('Davide Eynard'), arxiv.Result.Author('Damon Mannion'), arxiv.Result.Author('Michael M. Bronstein')]","Social media are nowadays one of the main news sources for millions of people
around the globe due to their low cost, easy access and rapid dissemination.
This however comes at the cost of dubious trustworthiness and significant risk
of exposure to 'fake news', intentionally written to mislead the readers.
Automatically detecting fake news poses challenges that defy existing
content-based analysis approaches. One of the main reasons is that often the
interpretation of the news requires the knowledge of political or social
context or 'common sense', which current NLP algorithms are still missing.
Recent studies have shown that fake and real news spread differently on social
media, forming propagation patterns that could be harnessed for the automatic
fake news detection. Propagation-based approaches have multiple advantages
compared to their content-based counterparts, among which is language
independence and better resilience to adversarial attacks. In this paper we
show a novel automatic fake news detection model based on geometric deep
learning. The underlying core algorithms are a generalization of classical CNNs
to graphs, allowing the fusion of heterogeneous data such as content, user
profile and activity, social graph, and news propagation. Our model was trained
and tested on news stories, verified by professional fact-checking
organizations, that were spread on Twitter. Our experiments indicate that
social network structure and propagation are important features allowing highly
accurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news
can be reliably detected at an early stage, after just a few hours of
propagation. Third, we test the aging of our model on training and testing data
separated in time. Our results point to the promise of propagation-based
approaches for fake news detection as an alternative or complementary strategy
to content-based approaches.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1902.06673v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.06673v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.06673v1,"{'id': 'http://arxiv.org/abs/1902.06673v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.06673v1', 'updated': '2019-02-10T15:21:45Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=10, tm_hour=15, tm_min=21, tm_sec=45, tm_wday=6, tm_yday=41, tm_isdst=0), 'published': '2019-02-10T15:21:45Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=10, tm_hour=15, tm_min=21, tm_sec=45, tm_wday=6, tm_yday=41, tm_isdst=0), 'title': 'Fake News Detection on Social Media using Geometric Deep Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection on Social Media using Geometric Deep Learning'}, 'summary': ""Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches.""}, 'authors': [{'name': 'Federico Monti'}, {'name': 'Fabrizio Frasca'}, {'name': 'Davide Eynard'}, {'name': 'Damon Mannion'}, {'name': 'Michael M. Bronstein'}], 'author_detail': {'name': 'Michael M. Bronstein'}, 'author': 'Michael M. Bronstein', 'links': [{'href': 'http://arxiv.org/abs/1902.06673v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.06673v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
344,http://arxiv.org/abs/1902.01970v1,2019-02-05 23:19:48+00:00,2019-02-05 23:19:48+00:00,Hawkes Process for Understanding the Influence of Pathogenic Social Media Accounts,"[arxiv.Result.Author('Hamidreza Alvari'), arxiv.Result.Author('Paulo Shakarian')]","Over the past years, political events and public opinion on the Web have been
allegedly manipulated by accounts dedicated to spreading disinformation and
performing malicious activities on social media. These accounts hereafter
referred to as ""Pathogenic Social Media (PSM)"" accounts, are often controlled
by terrorist supporters, water armies or fake news writers and hence can pose
threats to social media and general public. Understanding and analyzing PSMs
could help social media firms devise sophisticated and automated techniques
that could be deployed to stop them from reaching their audience and
consequently reduce their threat. In this paper, we leverage the well-known
statistical technique ""Hawkes Process"" to quantify the influence of PSM
accounts on the dissemination of malicious information on social media
platforms. Our findings on a real-world ISIS-related dataset from Twitter
indicate that PSMs are significantly different from regular users in making a
message viral. Specifically, we observed that PSMs do not usually post URLs
from mainstream news sources. Instead, their tweets usually receive large
impact on audience, if contained URLs from Facebook and alternative news
outlets. In contrary, tweets posted by regular users receive nearly equal
impression regardless of the posted URLs and their sources. Our findings can
further shed light on understanding and detecting PSM accounts.",IEEE Conference on Data Intelligence and Security (ICDIS) 2019,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1902.01970v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.01970v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.01970v1,"{'id': 'http://arxiv.org/abs/1902.01970v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.01970v1', 'updated': '2019-02-05T23:19:48Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=23, tm_min=19, tm_sec=48, tm_wday=1, tm_yday=36, tm_isdst=0), 'published': '2019-02-05T23:19:48Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=5, tm_hour=23, tm_min=19, tm_sec=48, tm_wday=1, tm_yday=36, tm_isdst=0), 'title': 'Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts'}, 'summary': 'Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as ""Pathogenic Social Media (PSM)"" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique ""Hawkes Process"" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as ""Pathogenic Social Media (PSM)"" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique ""Hawkes Process"" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.'}, 'authors': [{'name': 'Hamidreza Alvari'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'arxiv_comment': 'IEEE Conference on Data Intelligence and Security (ICDIS) 2019', 'links': [{'href': 'http://arxiv.org/abs/1902.01970v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.01970v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
345,http://arxiv.org/abs/1902.01443v1,2019-02-04 19:56:06+00:00,2019-02-04 19:56:06+00:00,Identification and Estimation of Causal Effects from Dependent Data,"[arxiv.Result.Author('Eli Sherman'), arxiv.Result.Author('Ilya Shpitser')]","The assumption that data samples are independent and identically distributed
(iid) is standard in many areas of statistics and machine learning.
Nevertheless, in some settings, such as social networks, infectious disease
modeling, and reasoning with spatial and temporal data, this assumption is
false. An extensive literature exists on making causal inferences under the iid
assumption [18, 12, 28, 22], even when unobserved confounding bias may be
present. But, as pointed out in [20], causal inference in non-iid contexts is
challenging due to the presence of both unobserved confounding and data
dependence. In this paper we develop a general theory describing when causal
inferences are possible in such scenarios. We use segregated graphs [21], a
generalization of latent projection mixed graphs [30], to represent causal
models of this type and provide a complete algorithm for non-parametric
identification in these models. We then demonstrate how statistical inference
may be performed on causal parameters identified by this algorithm. In
particular, we consider cases where only a single sample is available for parts
of the model due to full interference, i.e., all units are pathwise dependent
and neighbors' treatments affect each others' outcomes [26]. We apply these
techniques to a synthetic data set which considers users sharing fake news
articles given the structure of their social network, user activity levels, and
baseline demographics and socioeconomic covariates.",Advances in neural information processing systems. 2018,,,stat.ME,['stat.ME'],"[arxiv.Result.Link('http://arxiv.org/abs/1902.01443v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.01443v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.01443v1,"{'id': 'http://arxiv.org/abs/1902.01443v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.01443v1', 'updated': '2019-02-04T19:56:06Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=19, tm_min=56, tm_sec=6, tm_wday=0, tm_yday=35, tm_isdst=0), 'published': '2019-02-04T19:56:06Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=4, tm_hour=19, tm_min=56, tm_sec=6, tm_wday=0, tm_yday=35, tm_isdst=0), 'title': 'Identification and Estimation of Causal Effects from Dependent Data', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identification and Estimation of Causal Effects from Dependent Data'}, 'summary': ""The assumption that data samples are independent and identically distributed\n(iid) is standard in many areas of statistics and machine learning.\nNevertheless, in some settings, such as social networks, infectious disease\nmodeling, and reasoning with spatial and temporal data, this assumption is\nfalse. An extensive literature exists on making causal inferences under the iid\nassumption [18, 12, 28, 22], even when unobserved confounding bias may be\npresent. But, as pointed out in [20], causal inference in non-iid contexts is\nchallenging due to the presence of both unobserved confounding and data\ndependence. In this paper we develop a general theory describing when causal\ninferences are possible in such scenarios. We use segregated graphs [21], a\ngeneralization of latent projection mixed graphs [30], to represent causal\nmodels of this type and provide a complete algorithm for non-parametric\nidentification in these models. We then demonstrate how statistical inference\nmay be performed on causal parameters identified by this algorithm. In\nparticular, we consider cases where only a single sample is available for parts\nof the model due to full interference, i.e., all units are pathwise dependent\nand neighbors' treatments affect each others' outcomes [26]. We apply these\ntechniques to a synthetic data set which considers users sharing fake news\narticles given the structure of their social network, user activity levels, and\nbaseline demographics and socioeconomic covariates."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The assumption that data samples are independent and identically distributed\n(iid) is standard in many areas of statistics and machine learning.\nNevertheless, in some settings, such as social networks, infectious disease\nmodeling, and reasoning with spatial and temporal data, this assumption is\nfalse. An extensive literature exists on making causal inferences under the iid\nassumption [18, 12, 28, 22], even when unobserved confounding bias may be\npresent. But, as pointed out in [20], causal inference in non-iid contexts is\nchallenging due to the presence of both unobserved confounding and data\ndependence. In this paper we develop a general theory describing when causal\ninferences are possible in such scenarios. We use segregated graphs [21], a\ngeneralization of latent projection mixed graphs [30], to represent causal\nmodels of this type and provide a complete algorithm for non-parametric\nidentification in these models. We then demonstrate how statistical inference\nmay be performed on causal parameters identified by this algorithm. In\nparticular, we consider cases where only a single sample is available for parts\nof the model due to full interference, i.e., all units are pathwise dependent\nand neighbors' treatments affect each others' outcomes [26]. We apply these\ntechniques to a synthetic data set which considers users sharing fake news\narticles given the structure of their social network, user activity levels, and\nbaseline demographics and socioeconomic covariates.""}, 'authors': [{'name': 'Eli Sherman'}, {'name': 'Ilya Shpitser'}], 'author_detail': {'name': 'Ilya Shpitser'}, 'author': 'Ilya Shpitser', 'arxiv_comment': 'Advances in neural information processing systems. 2018', 'links': [{'href': 'http://arxiv.org/abs/1902.01443v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.01443v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
346,http://arxiv.org/abs/1901.08971v3,2019-08-26 17:59:54+00:00,2019-01-25 16:38:21+00:00,FaceForensics++: Learning to Detect Manipulated Facial Images,"[arxiv.Result.Author('Andreas Rössler'), arxiv.Result.Author('Davide Cozzolino'), arxiv.Result.Author('Luisa Verdoliva'), arxiv.Result.Author('Christian Riess'), arxiv.Result.Author('Justus Thies'), arxiv.Result.Author('Matthias Nießner')]","The rapid progress in synthetic image generation and manipulation has now
come to a point where it raises significant concerns for the implications
towards society. At best, this leads to a loss of trust in digital content, but
could potentially cause further harm by spreading false information or fake
news. This paper examines the realism of state-of-the-art image manipulations,
and how difficult it is to detect them, either automatically or by humans. To
standardize the evaluation of detection methods, we propose an automated
benchmark for facial manipulation detection. In particular, the benchmark is
based on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent
representatives for facial manipulations at random compression level and size.
The benchmark is publicly available and contains a hidden test set as well as a
database of over 1.8 million manipulated images. This dataset is over an order
of magnitude larger than comparable, publicly available, forgery datasets.
Based on this data, we performed a thorough analysis of data-driven forgery
detectors. We show that the use of additional domainspecific knowledge improves
forgery detection to unprecedented accuracy, even in the presence of strong
compression, and clearly outperforms human observers.",Video: https://youtu.be/x2g48Q2I2ZQ,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.08971v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.08971v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.08971v3,"{'id': 'http://arxiv.org/abs/1901.08971v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.08971v3', 'updated': '2019-08-26T17:59:54Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=26, tm_hour=17, tm_min=59, tm_sec=54, tm_wday=0, tm_yday=238, tm_isdst=0), 'published': '2019-01-25T16:38:21Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=25, tm_hour=16, tm_min=38, tm_sec=21, tm_wday=4, tm_yday=25, tm_isdst=0), 'title': 'FaceForensics++: Learning to Detect Manipulated Facial Images', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FaceForensics++: Learning to Detect Manipulated Facial Images'}, 'summary': 'The rapid progress in synthetic image generation and manipulation has now\ncome to a point where it raises significant concerns for the implications\ntowards society. At best, this leads to a loss of trust in digital content, but\ncould potentially cause further harm by spreading false information or fake\nnews. This paper examines the realism of state-of-the-art image manipulations,\nand how difficult it is to detect them, either automatically or by humans. To\nstandardize the evaluation of detection methods, we propose an automated\nbenchmark for facial manipulation detection. In particular, the benchmark is\nbased on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent\nrepresentatives for facial manipulations at random compression level and size.\nThe benchmark is publicly available and contains a hidden test set as well as a\ndatabase of over 1.8 million manipulated images. This dataset is over an order\nof magnitude larger than comparable, publicly available, forgery datasets.\nBased on this data, we performed a thorough analysis of data-driven forgery\ndetectors. We show that the use of additional domainspecific knowledge improves\nforgery detection to unprecedented accuracy, even in the presence of strong\ncompression, and clearly outperforms human observers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid progress in synthetic image generation and manipulation has now\ncome to a point where it raises significant concerns for the implications\ntowards society. At best, this leads to a loss of trust in digital content, but\ncould potentially cause further harm by spreading false information or fake\nnews. This paper examines the realism of state-of-the-art image manipulations,\nand how difficult it is to detect them, either automatically or by humans. To\nstandardize the evaluation of detection methods, we propose an automated\nbenchmark for facial manipulation detection. In particular, the benchmark is\nbased on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent\nrepresentatives for facial manipulations at random compression level and size.\nThe benchmark is publicly available and contains a hidden test set as well as a\ndatabase of over 1.8 million manipulated images. This dataset is over an order\nof magnitude larger than comparable, publicly available, forgery datasets.\nBased on this data, we performed a thorough analysis of data-driven forgery\ndetectors. We show that the use of additional domainspecific knowledge improves\nforgery detection to unprecedented accuracy, even in the presence of strong\ncompression, and clearly outperforms human observers.'}, 'authors': [{'name': 'Andreas Rössler'}, {'name': 'Davide Cozzolino'}, {'name': 'Luisa Verdoliva'}, {'name': 'Christian Riess'}, {'name': 'Justus Thies'}, {'name': 'Matthias Nießner'}], 'author_detail': {'name': 'Matthias Nießner'}, 'author': 'Matthias Nießner', 'arxiv_comment': 'Video: https://youtu.be/x2g48Q2I2ZQ', 'links': [{'href': 'http://arxiv.org/abs/1901.08971v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.08971v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
347,http://arxiv.org/abs/1901.06437v1,2019-01-18 22:57:09+00:00,2019-01-18 22:57:09+00:00,Combating Fake News: A Survey on Identification and Mitigation Techniques,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Feng Qian'), arxiv.Result.Author('He Jiang'), arxiv.Result.Author('Natali Ruchansky'), arxiv.Result.Author('Ming Zhang'), arxiv.Result.Author('Yan Liu')]","The proliferation of fake news on social media has opened up new directions
of research for timely identification and containment of fake news, and
mitigation of its widespread impact on public opinion. While much of the
earlier research was focused on identification of fake news based on its
contents or by exploiting users' engagements with the news on social media,
there has been a rising interest in proactive intervention strategies to
counter the spread of misinformation and its impact on society. In this survey,
we describe the modern-day problem of fake news and, in particular, highlight
the technical challenges associated with it. We discuss existing methods and
techniques applicable to both identification and mitigation, with a focus on
the significant advances in each method and their advantages and limitations.
In addition, research has often been limited by the quality of existing
datasets and their specific application contexts. To alleviate this problem, we
comprehensively compile and summarize characteristic features of available
datasets. Furthermore, we outline new directions of research to facilitate
future development of effective and interdisciplinary solutions.",,"ACM Transactions on Intelligent Systems and Technology, 2019",,cs.LG,"['cs.LG', 'cs.AI', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1901.06437v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.06437v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.06437v1,"{'id': 'http://arxiv.org/abs/1901.06437v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.06437v1', 'updated': '2019-01-18T22:57:09Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=18, tm_hour=22, tm_min=57, tm_sec=9, tm_wday=4, tm_yday=18, tm_isdst=0), 'published': '2019-01-18T22:57:09Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=18, tm_hour=22, tm_min=57, tm_sec=9, tm_wday=4, tm_yday=18, tm_isdst=0), 'title': 'Combating Fake News: A Survey on Identification and Mitigation\n  Techniques', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Fake News: A Survey on Identification and Mitigation\n  Techniques'}, 'summary': ""The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.""}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Feng Qian'}, {'name': 'He Jiang'}, {'name': 'Natali Ruchansky'}, {'name': 'Ming Zhang'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_journal_ref': 'ACM Transactions on Intelligent Systems and Technology, 2019', 'links': [{'href': 'http://arxiv.org/abs/1901.06437v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.06437v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
348,http://arxiv.org/abs/1901.02156v1,2019-01-08 05:11:17+00:00,2019-01-08 05:11:17+00:00,Influence Minimization Under Budget and Matroid Constraints: Extended Version,"[arxiv.Result.Author('Sourav Medya'), arxiv.Result.Author('Arlei Silva'), arxiv.Result.Author('Ambuj Singh')]","Recently, online social networks have become major battlegrounds for
political campaigns, viral marketing, and the dissemination of news. As a
consequence, ''bad actors'' are increasingly exploiting these platforms,
becoming a key challenge for their administrators, businesses and the society
in general. The spread of fake news is a classical example of the abuse of
social networks by these actors. While some have advocated for stricter
policies to control the spread of misinformation in social networks, this often
happens in detriment of their democratic and organic structure. In this paper
we study how to limit the influence of a target set of users in a network via
the removal of a few edges. The idea is to control the diffusion processes
while minimizing the amount of disturbance in the network structure.
  We formulate the influence limitation problem in a data-driven fashion, by
taking into account past propagation traces. Moreover, we consider two types of
constraints over the set of edge removals, a budget constraint and also a, more
general, set of matroid constraints. These problems lead to interesting
challenges in terms of algorithm design. For instance, we are able to show that
influence limitation is APX-hard and propose deterministic and probabilistic
approximation algorithms for the budgeted and matroid version of the problem,
respectively. Our experiments show that the proposed solutions outperform the
baselines by up to 40%.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.02156v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.02156v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.02156v1,"{'id': 'http://arxiv.org/abs/1901.02156v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.02156v1', 'updated': '2019-01-08T05:11:17Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=8, tm_hour=5, tm_min=11, tm_sec=17, tm_wday=1, tm_yday=8, tm_isdst=0), 'published': '2019-01-08T05:11:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=8, tm_hour=5, tm_min=11, tm_sec=17, tm_wday=1, tm_yday=8, tm_isdst=0), 'title': 'Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version'}, 'summary': ""Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%.""}, 'authors': [{'name': 'Sourav Medya'}, {'name': 'Arlei Silva'}, {'name': 'Ambuj Singh'}], 'author_detail': {'name': 'Ambuj Singh'}, 'author': 'Ambuj Singh', 'links': [{'href': 'http://arxiv.org/abs/1901.02156v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.02156v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
349,http://arxiv.org/abs/1901.09657v1,2019-01-05 11:56:13+00:00,2019-01-05 11:56:13+00:00,Fake News Detection via NLP is Vulnerable to Adversarial Attacks,"[arxiv.Result.Author('Zhixuan Zhou'), arxiv.Result.Author('Huankang Guan'), arxiv.Result.Author('Meghana Moorthy Bhat'), arxiv.Result.Author('Justin Hsu')]","News plays a significant role in shaping people's beliefs and opinions. Fake
news has always been a problem, which wasn't exposed to the mass public until
the past election cycle for the 45th President of the United States. While
quite a few detection methods have been proposed to combat fake news since
2015, they focus mainly on linguistic aspects of an article without any fact
checking. In this paper, we argue that these models have the potential to
misclassify fact-tampering fake news as well as under-written real news.
Through experiments on Fakebox, a state-of-the-art fake news detector, we show
that fact tampering attacks can be effective. To address these weaknesses, we
argue that fact checking should be adopted in conjunction with linguistic
characteristics analysis, so as to truly separate fake news from real news. A
crowdsourced knowledge graph is proposed as a straw man solution to collecting
timely facts about news events.","11th International Conference on Agents and Artificial Intelligence
  (ICAART 2019)",,10.5220/0007566307940800,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.5220/0007566307940800', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1901.09657v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.09657v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.09657v1,"{'id': 'http://arxiv.org/abs/1901.09657v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.09657v1', 'updated': '2019-01-05T11:56:13Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=5, tm_hour=11, tm_min=56, tm_sec=13, tm_wday=5, tm_yday=5, tm_isdst=0), 'published': '2019-01-05T11:56:13Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=5, tm_hour=11, tm_min=56, tm_sec=13, tm_wday=5, tm_yday=5, tm_isdst=0), 'title': 'Fake News Detection via NLP is Vulnerable to Adversarial Attacks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection via NLP is Vulnerable to Adversarial Attacks'}, 'summary': ""News plays a significant role in shaping people's beliefs and opinions. Fake\nnews has always been a problem, which wasn't exposed to the mass public until\nthe past election cycle for the 45th President of the United States. While\nquite a few detection methods have been proposed to combat fake news since\n2015, they focus mainly on linguistic aspects of an article without any fact\nchecking. In this paper, we argue that these models have the potential to\nmisclassify fact-tampering fake news as well as under-written real news.\nThrough experiments on Fakebox, a state-of-the-art fake news detector, we show\nthat fact tampering attacks can be effective. To address these weaknesses, we\nargue that fact checking should be adopted in conjunction with linguistic\ncharacteristics analysis, so as to truly separate fake news from real news. A\ncrowdsourced knowledge graph is proposed as a straw man solution to collecting\ntimely facts about news events."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""News plays a significant role in shaping people's beliefs and opinions. Fake\nnews has always been a problem, which wasn't exposed to the mass public until\nthe past election cycle for the 45th President of the United States. While\nquite a few detection methods have been proposed to combat fake news since\n2015, they focus mainly on linguistic aspects of an article without any fact\nchecking. In this paper, we argue that these models have the potential to\nmisclassify fact-tampering fake news as well as under-written real news.\nThrough experiments on Fakebox, a state-of-the-art fake news detector, we show\nthat fact tampering attacks can be effective. To address these weaknesses, we\nargue that fact checking should be adopted in conjunction with linguistic\ncharacteristics analysis, so as to truly separate fake news from real news. A\ncrowdsourced knowledge graph is proposed as a straw man solution to collecting\ntimely facts about news events.""}, 'authors': [{'name': 'Zhixuan Zhou'}, {'name': 'Huankang Guan'}, {'name': 'Meghana Moorthy Bhat'}, {'name': 'Justin Hsu'}], 'author_detail': {'name': 'Justin Hsu'}, 'author': 'Justin Hsu', 'arxiv_doi': '10.5220/0007566307940800', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.5220/0007566307940800', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1901.09657v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.09657v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '11th International Conference on Agents and Artificial Intelligence\n  (ICAART 2019)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
350,http://arxiv.org/abs/1812.04478v4,2020-03-17 13:02:14+00:00,2018-12-11 15:45:10+00:00,Socratrees: Exploring the Design of Argument Technology for Layman Users,[arxiv.Result.Author('Steven Jeuris')],"Terms like 'misinformation', 'fake news', and 'echo chambers' permeate
current discussions on the state of the Internet. We believe a lack of
technological support to evaluate, contest, and reason about information
online---as opposed to merely disseminating it---lies at the root of these
problems. Several argument technologies support such functionality, but have
seen limited use outside of niche communities. Most research systems
overemphasize argument analysis and structure, standing in stark contrast with
the informal dialectical nature of everyday argumentation. Conversely,
non-academic systems overlook important implications for design which can be
derived from theory. In this paper, we present the design of a system aiming to
strike a balance between structured argumentation and ease of use. Socratrees
is a website for collaborative argumentative discussion targeting layman users,
but includes sophisticated community guidelines and novel features inspired by
informal logic. During an exploratory study, we evaluate the usefulness of our
imposed structure on argumentation and investigate how users perceive it.
Contributing to arguments remains a complex task, but most users learned to do
so effectively with minimal guidance and all recognized that the structure of
Socratrees may improve online discussion and results in a clearer overview of
arguments.","Rejected several times, primarily on the basis of needing a larger
  study. While trying to obtain funding for this (this project has received no
  funding so far), leaving this out here for now",,,cs.HC,"['cs.HC', 'cs.CY', 'H.5.4']","[arxiv.Result.Link('http://arxiv.org/abs/1812.04478v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.04478v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.04478v4,"{'id': 'http://arxiv.org/abs/1812.04478v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.04478v4', 'updated': '2020-03-17T13:02:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=17, tm_hour=13, tm_min=2, tm_sec=14, tm_wday=1, tm_yday=77, tm_isdst=0), 'published': '2018-12-11T15:45:10Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=11, tm_hour=15, tm_min=45, tm_sec=10, tm_wday=1, tm_yday=345, tm_isdst=0), 'title': 'Socratrees: Exploring the Design of Argument Technology for Layman Users', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Socratrees: Exploring the Design of Argument Technology for Layman Users'}, 'summary': ""Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments.""}, 'authors': [{'name': 'Steven Jeuris'}], 'author_detail': {'name': 'Steven Jeuris'}, 'author': 'Steven Jeuris', 'arxiv_comment': 'Rejected several times, primarily on the basis of needing a larger\n  study. While trying to obtain funding for this (this project has received no\n  funding so far), leaving this out here for now', 'links': [{'href': 'http://arxiv.org/abs/1812.04478v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.04478v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
351,http://arxiv.org/abs/1812.02978v1,2018-12-07 10:59:09+00:00,2018-12-07 10:59:09+00:00,More or Less? Predict the Social Influence of Malicious URLs on Social Media,"[arxiv.Result.Author('Chun-Ming Lai'), arxiv.Result.Author('Xiaoyun Wang'), arxiv.Result.Author('Jon W. Chapman'), arxiv.Result.Author('Yu-Cheng Lin'), arxiv.Result.Author('Yu-Chang Ho'), arxiv.Result.Author('S. Felix Wu'), arxiv.Result.Author('Patrick McDaniel'), arxiv.Result.Author('Hasan Cam')]","Users of Online Social Networks (OSNs) interact with each other more than
ever. In the context of a public discussion group, people receive, read, and
write comments in response to articles and postings. In the absence of access
control mechanisms, OSNs are a great environment for attackers to influence
others, from spreading phishing URLs, to posting fake news. Moreover, OSN user
behavior can be predicted by social science concepts which include conformity
and the bandwagon effect. In this paper, we show how social recommendation
systems affect the occurrence of malicious URLs on Facebook. We exploit
temporal features to build a prediction framework, having greater than 75%
accuracy, to predict whether the following group users' behavior will increase
or not. Included in this work, we demarcate classes of URLs, including those
malicious URLs classified as creating critical damage, as well as those of a
lesser nature which only inflict light damage such as aggressive commercial
advertisements and spam content. It is our hope that the data and analyses in
this paper provide a better understanding of OSN user reactions to different
categories of malicious URLs, thereby providing a way to mitigate the influence
of these malicious URL attacks.","10 pages, 6 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1812.02978v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.02978v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.02978v1,"{'id': 'http://arxiv.org/abs/1812.02978v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.02978v1', 'updated': '2018-12-07T10:59:09Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=7, tm_hour=10, tm_min=59, tm_sec=9, tm_wday=4, tm_yday=341, tm_isdst=0), 'published': '2018-12-07T10:59:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=7, tm_hour=10, tm_min=59, tm_sec=9, tm_wday=4, tm_yday=341, tm_isdst=0), 'title': 'More or Less? Predict the Social Influence of Malicious URLs on Social\n  Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'More or Less? Predict the Social Influence of Malicious URLs on Social\n  Media'}, 'summary': ""Users of Online Social Networks (OSNs) interact with each other more than\never. In the context of a public discussion group, people receive, read, and\nwrite comments in response to articles and postings. In the absence of access\ncontrol mechanisms, OSNs are a great environment for attackers to influence\nothers, from spreading phishing URLs, to posting fake news. Moreover, OSN user\nbehavior can be predicted by social science concepts which include conformity\nand the bandwagon effect. In this paper, we show how social recommendation\nsystems affect the occurrence of malicious URLs on Facebook. We exploit\ntemporal features to build a prediction framework, having greater than 75%\naccuracy, to predict whether the following group users' behavior will increase\nor not. Included in this work, we demarcate classes of URLs, including those\nmalicious URLs classified as creating critical damage, as well as those of a\nlesser nature which only inflict light damage such as aggressive commercial\nadvertisements and spam content. It is our hope that the data and analyses in\nthis paper provide a better understanding of OSN user reactions to different\ncategories of malicious URLs, thereby providing a way to mitigate the influence\nof these malicious URL attacks."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Users of Online Social Networks (OSNs) interact with each other more than\never. In the context of a public discussion group, people receive, read, and\nwrite comments in response to articles and postings. In the absence of access\ncontrol mechanisms, OSNs are a great environment for attackers to influence\nothers, from spreading phishing URLs, to posting fake news. Moreover, OSN user\nbehavior can be predicted by social science concepts which include conformity\nand the bandwagon effect. In this paper, we show how social recommendation\nsystems affect the occurrence of malicious URLs on Facebook. We exploit\ntemporal features to build a prediction framework, having greater than 75%\naccuracy, to predict whether the following group users' behavior will increase\nor not. Included in this work, we demarcate classes of URLs, including those\nmalicious URLs classified as creating critical damage, as well as those of a\nlesser nature which only inflict light damage such as aggressive commercial\nadvertisements and spam content. It is our hope that the data and analyses in\nthis paper provide a better understanding of OSN user reactions to different\ncategories of malicious URLs, thereby providing a way to mitigate the influence\nof these malicious URL attacks.""}, 'authors': [{'name': 'Chun-Ming Lai'}, {'name': 'Xiaoyun Wang'}, {'name': 'Jon W. Chapman'}, {'name': 'Yu-Cheng Lin'}, {'name': 'Yu-Chang Ho'}, {'name': 'S. Felix Wu'}, {'name': 'Patrick McDaniel'}, {'name': 'Hasan Cam'}], 'author_detail': {'name': 'Hasan Cam'}, 'author': 'Hasan Cam', 'arxiv_comment': '10 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/1812.02978v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.02978v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
352,http://arxiv.org/abs/1812.00315v2,2020-07-17 21:08:10+00:00,2018-12-02 03:27:15+00:00,"A Survey of Fake News: Fundamental Theories, Detection Methods, and Opportunities","[arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Reza Zafarani')]","The explosive growth in fake news and its erosion to democracy, justice, and
public trust has increased the demand for fake news detection and intervention.
This survey reviews and evaluates methods that can detect fake news from four
perspectives: (1) the false knowledge it carries, (2) its writing style, (3)
its propagation patterns, and (4) the credibility of its source. The survey
also highlights some potential research tasks based on the review. In
particular, we identify and detail related fundamental theories across various
disciplines to encourage interdisciplinary research on fake news. We hope this
survey can facilitate collaborative efforts among experts in computer and
information sciences, social sciences, political science, and journalism to
research fake news, where such efforts can lead to fake news detection that is
not only efficient but more importantly, explainable.","ACM Computing Surveys (CSUR), 37 pages",,10.1145/3395046,cs.CL,"['cs.CL', 'cs.AI', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3395046', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1812.00315v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.00315v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.00315v2,"{'id': 'http://arxiv.org/abs/1812.00315v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.00315v2', 'updated': '2020-07-17T21:08:10Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=17, tm_hour=21, tm_min=8, tm_sec=10, tm_wday=4, tm_yday=199, tm_isdst=0), 'published': '2018-12-02T03:27:15Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=2, tm_hour=3, tm_min=27, tm_sec=15, tm_wday=6, tm_yday=336, tm_isdst=0), 'title': 'A Survey of Fake News: Fundamental Theories, Detection Methods, and\n  Opportunities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey of Fake News: Fundamental Theories, Detection Methods, and\n  Opportunities'}, 'summary': 'The explosive growth in fake news and its erosion to democracy, justice, and\npublic trust has increased the demand for fake news detection and intervention.\nThis survey reviews and evaluates methods that can detect fake news from four\nperspectives: (1) the false knowledge it carries, (2) its writing style, (3)\nits propagation patterns, and (4) the credibility of its source. The survey\nalso highlights some potential research tasks based on the review. In\nparticular, we identify and detail related fundamental theories across various\ndisciplines to encourage interdisciplinary research on fake news. We hope this\nsurvey can facilitate collaborative efforts among experts in computer and\ninformation sciences, social sciences, political science, and journalism to\nresearch fake news, where such efforts can lead to fake news detection that is\nnot only efficient but more importantly, explainable.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The explosive growth in fake news and its erosion to democracy, justice, and\npublic trust has increased the demand for fake news detection and intervention.\nThis survey reviews and evaluates methods that can detect fake news from four\nperspectives: (1) the false knowledge it carries, (2) its writing style, (3)\nits propagation patterns, and (4) the credibility of its source. The survey\nalso highlights some potential research tasks based on the review. In\nparticular, we identify and detail related fundamental theories across various\ndisciplines to encourage interdisciplinary research on fake news. We hope this\nsurvey can facilitate collaborative efforts among experts in computer and\ninformation sciences, social sciences, political science, and journalism to\nresearch fake news, where such efforts can lead to fake news detection that is\nnot only efficient but more importantly, explainable.'}, 'authors': [{'name': 'Xinyi Zhou'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_doi': '10.1145/3395046', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3395046', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1812.00315v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.00315v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'ACM Computing Surveys (CSUR), 37 pages', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
353,http://arxiv.org/abs/1811.12349v2,2018-12-04 16:15:25+00:00,2018-11-29 17:54:49+00:00,Combating Fake News with Interpretable News Feed Algorithms,"[arxiv.Result.Author('Sina Mohseni'), arxiv.Result.Author('Eric Ragan')]","Nowadays, artificial intelligence algorithms are used for targeted and
personalized content distribution in the large scale as part of the intense
competition for attention in the digital media environment. Unfortunately,
targeted information dissemination may result in intellectual isolation and
discrimination. Further, as demonstrated in recent political events in the US
and EU, malicious bots and social media users can create and propagate targeted
`fake news' content in different forms for political gains. From the other
direction, fake news detection algorithms attempt to combat such problems by
identifying misinformation and fraudulent user profiles. This paper reviews
common news feed algorithms as well as methods for fake news detection, and we
discuss how news feed algorithms could be misused to promote falsified content,
affect news diversity, or impact credibility. We review how news feed
algorithms and recommender engines can enable confirmation bias to isolate
users to certain news sources and affecting the perception of reality. As a
potential solution for increasing user awareness of how content is selected or
sorted, we argue for the use of interpretable and explainable news feed
algorithms. We discuss how improved user awareness and system transparency
could mitigate unwanted outcomes of echo chambers and bubble filters in social
media.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1811.12349v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.12349v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.12349v2,"{'id': 'http://arxiv.org/abs/1811.12349v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.12349v2', 'updated': '2018-12-04T16:15:25Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=4, tm_hour=16, tm_min=15, tm_sec=25, tm_wday=1, tm_yday=338, tm_isdst=0), 'published': '2018-11-29T17:54:49Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=29, tm_hour=17, tm_min=54, tm_sec=49, tm_wday=3, tm_yday=333, tm_isdst=0), 'title': 'Combating Fake News with Interpretable News Feed Algorithms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Fake News with Interpretable News Feed Algorithms'}, 'summary': ""Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.""}, 'authors': [{'name': 'Sina Mohseni'}, {'name': 'Eric Ragan'}], 'author_detail': {'name': 'Eric Ragan'}, 'author': 'Eric Ragan', 'links': [{'href': 'http://arxiv.org/abs/1811.12349v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.12349v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
354,http://arxiv.org/abs/1811.09729v3,2019-09-11 18:29:06+00:00,2018-11-24 00:06:10+00:00,"Generate, Segment and Refine: Towards Generic Manipulation Segmentation","[arxiv.Result.Author('Peng Zhou'), arxiv.Result.Author('Bor-Chun Chen'), arxiv.Result.Author('Xintong Han'), arxiv.Result.Author('Mahyar Najibi'), arxiv.Result.Author('Abhinav Shrivastava'), arxiv.Result.Author('Ser Nam Lim'), arxiv.Result.Author('Larry S. Davis')]","Detecting manipulated images has become a significant emerging challenge. The
advent of image sharing platforms and the easy availability of advanced photo
editing software have resulted in a large quantities of manipulated images
being shared on the internet. While the intent behind such manipulations varies
widely, concerns on the spread of fake news and misinformation is growing.
Current state of the art methods for detecting these manipulated images suffers
from the lack of training data due to the laborious labeling process. We
address this problem in this paper, for which we introduce a manipulated image
generation process that creates true positives using currently available
datasets. Drawing from traditional work on image blending, we propose a novel
generator for creating such examples. In addition, we also propose to further
create examples that force the algorithm to focus on boundary artifacts during
training. Strong experimental results validate our proposal.",,AAAI-2020,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.09729v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.09729v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.09729v3,"{'id': 'http://arxiv.org/abs/1811.09729v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.09729v3', 'updated': '2019-09-11T18:29:06Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=11, tm_hour=18, tm_min=29, tm_sec=6, tm_wday=2, tm_yday=254, tm_isdst=0), 'published': '2018-11-24T00:06:10Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=24, tm_hour=0, tm_min=6, tm_sec=10, tm_wday=5, tm_yday=328, tm_isdst=0), 'title': 'Generate, Segment and Refine: Towards Generic Manipulation Segmentation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Generate, Segment and Refine: Towards Generic Manipulation Segmentation'}, 'summary': 'Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.'}, 'authors': [{'name': 'Peng Zhou'}, {'name': 'Bor-Chun Chen'}, {'name': 'Xintong Han'}, {'name': 'Mahyar Najibi'}, {'name': 'Abhinav Shrivastava'}, {'name': 'Ser Nam Lim'}, {'name': 'Larry S. Davis'}], 'author_detail': {'name': 'Larry S. Davis'}, 'author': 'Larry S. Davis', 'arxiv_journal_ref': 'AAAI-2020', 'links': [{'href': 'http://arxiv.org/abs/1811.09729v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.09729v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
355,http://arxiv.org/abs/1811.07901v4,2019-01-08 21:15:07+00:00,2018-11-19 19:00:01+00:00,On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection,"[arxiv.Result.Author('Vivian Lai'), arxiv.Result.Author('Chenhao Tan')]","Humans are the final decision makers in critical tasks that involve ethical
and legal concerns, ranging from recidivism prediction, to medical diagnosis,
to fighting against fake news. Although machine learning models can sometimes
achieve impressive performance in these tasks, these tasks are not amenable to
full automation. To realize the potential of machine learning for improving
human decisions, it is important to understand how assistance from machine
learning models affects human performance and human agency.
  In this paper, we use deception detection as a testbed and investigate how we
can harness explanations and predictions of machine learning models to improve
human performance while retaining human agency. We propose a spectrum between
full human agency and full automation, and develop varying levels of machine
assistance along the spectrum that gradually increase the influence of machine
predictions. We find that without showing predicted labels, explanations alone
slightly improve human performance in the end task. In comparison, human
performance is greatly improved by showing predicted labels (>20% relative
improvement) and can be further improved by explicitly suggesting strong
machine performance. Interestingly, when predicted labels are shown,
explanations of machine predictions induce a similar level of accuracy as an
explicit statement of strong machine performance. Our results demonstrate a
tradeoff between human performance and human agency and show that explanations
of machine predictions can moderate this tradeoff.","17 pages, 19 figures, in Proceedings of ACM FAT* 2019, dataset & demo
  available at https://deception.machineintheloop.com",,10.1145/3287560.3287590,cs.AI,"['cs.AI', 'cs.CL', 'cs.CY', 'physics.soc-ph', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3287560.3287590', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1811.07901v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.07901v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.07901v4,"{'id': 'http://arxiv.org/abs/1811.07901v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.07901v4', 'updated': '2019-01-08T21:15:07Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=8, tm_hour=21, tm_min=15, tm_sec=7, tm_wday=1, tm_yday=8, tm_isdst=0), 'published': '2018-11-19T19:00:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=19, tm_hour=19, tm_min=0, tm_sec=1, tm_wday=0, tm_yday=323, tm_isdst=0), 'title': 'On Human Predictions with Explanations and Predictions of Machine\n  Learning Models: A Case Study on Deception Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On Human Predictions with Explanations and Predictions of Machine\n  Learning Models: A Case Study on Deception Detection'}, 'summary': 'Humans are the final decision makers in critical tasks that involve ethical\nand legal concerns, ranging from recidivism prediction, to medical diagnosis,\nto fighting against fake news. Although machine learning models can sometimes\nachieve impressive performance in these tasks, these tasks are not amenable to\nfull automation. To realize the potential of machine learning for improving\nhuman decisions, it is important to understand how assistance from machine\nlearning models affects human performance and human agency.\n  In this paper, we use deception detection as a testbed and investigate how we\ncan harness explanations and predictions of machine learning models to improve\nhuman performance while retaining human agency. We propose a spectrum between\nfull human agency and full automation, and develop varying levels of machine\nassistance along the spectrum that gradually increase the influence of machine\npredictions. We find that without showing predicted labels, explanations alone\nslightly improve human performance in the end task. In comparison, human\nperformance is greatly improved by showing predicted labels (>20% relative\nimprovement) and can be further improved by explicitly suggesting strong\nmachine performance. Interestingly, when predicted labels are shown,\nexplanations of machine predictions induce a similar level of accuracy as an\nexplicit statement of strong machine performance. Our results demonstrate a\ntradeoff between human performance and human agency and show that explanations\nof machine predictions can moderate this tradeoff.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Humans are the final decision makers in critical tasks that involve ethical\nand legal concerns, ranging from recidivism prediction, to medical diagnosis,\nto fighting against fake news. Although machine learning models can sometimes\nachieve impressive performance in these tasks, these tasks are not amenable to\nfull automation. To realize the potential of machine learning for improving\nhuman decisions, it is important to understand how assistance from machine\nlearning models affects human performance and human agency.\n  In this paper, we use deception detection as a testbed and investigate how we\ncan harness explanations and predictions of machine learning models to improve\nhuman performance while retaining human agency. We propose a spectrum between\nfull human agency and full automation, and develop varying levels of machine\nassistance along the spectrum that gradually increase the influence of machine\npredictions. We find that without showing predicted labels, explanations alone\nslightly improve human performance in the end task. In comparison, human\nperformance is greatly improved by showing predicted labels (>20% relative\nimprovement) and can be further improved by explicitly suggesting strong\nmachine performance. Interestingly, when predicted labels are shown,\nexplanations of machine predictions induce a similar level of accuracy as an\nexplicit statement of strong machine performance. Our results demonstrate a\ntradeoff between human performance and human agency and show that explanations\nof machine predictions can moderate this tradeoff.'}, 'authors': [{'name': 'Vivian Lai'}, {'name': 'Chenhao Tan'}], 'author_detail': {'name': 'Chenhao Tan'}, 'author': 'Chenhao Tan', 'arxiv_doi': '10.1145/3287560.3287590', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3287560.3287590', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1811.07901v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.07901v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '17 pages, 19 figures, in Proceedings of ACM FAT* 2019, dataset & demo\n  available at https://deception.machineintheloop.com', 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
356,http://arxiv.org/abs/1811.05900v2,2020-10-28 15:05:51+00:00,2018-11-14 16:44:59+00:00,A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections,[arxiv.Result.Author('Michael Bossetta')],"State-sponsored ""bad actors"" increasingly weaponize social media platforms to
launch cyberattacks and disinformation campaigns during elections. Social media
companies, due to their rapid growth and scale, struggle to prevent the
weaponization of their platforms. This study conducts an automated spear
phishing and disinformation campaign on Twitter ahead of the 2018 United States
Midterm Elections. A fake news bot account - the @DCNewsReport - was created
and programmed to automatically send customized tweets with a ""breaking news""
link to 138 Twitter users, before being restricted by Twitter.
  Overall, one in five users clicked the link, which could have potentially led
to the downloading of ransomware or the theft of private information. However,
the link in this experiment was non-malicious and redirected users to a Google
Forms survey. In predicting users' likelihood to click the link on Twitter, no
statistically significant differences were observed between right-wing and
left-wing partisans, or between Web users and mobile users. The findings signal
that politically expressive Americans on Twitter, regardless of their party
preferences or the devices they use to access the platform, are at risk of
being spear phishing on social media.",,"First Monday, 23(12) (2018)",10.5210/fm.v23i12.9540,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.5210/fm.v23i12.9540', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1811.05900v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.05900v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.05900v2,"{'id': 'http://arxiv.org/abs/1811.05900v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.05900v2', 'updated': '2020-10-28T15:05:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=28, tm_hour=15, tm_min=5, tm_sec=51, tm_wday=2, tm_yday=302, tm_isdst=0), 'published': '2018-11-14T16:44:59Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=14, tm_hour=16, tm_min=44, tm_sec=59, tm_wday=2, tm_yday=318, tm_isdst=0), 'title': 'A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections'}, 'summary': 'State-sponsored ""bad actors"" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a ""breaking news""\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users\' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'State-sponsored ""bad actors"" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a ""breaking news""\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users\' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.'}, 'authors': [{'name': 'Michael Bossetta'}], 'author_detail': {'name': 'Michael Bossetta'}, 'author': 'Michael Bossetta', 'arxiv_doi': '10.5210/fm.v23i12.9540', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.5210/fm.v23i12.9540', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1811.05900v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.05900v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'First Monday, 23(12) (2018)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
357,http://arxiv.org/abs/1811.04670v1,2018-11-12 11:40:09+00:00,2018-11-12 11:40:09+00:00,A Deep Ensemble Framework for Fake News Detection and Classification,"[arxiv.Result.Author('Arjun Roy'), arxiv.Result.Author('Kingshuk Basak'), arxiv.Result.Author('Asif Ekbal'), arxiv.Result.Author('Pushpak Bhattacharyya')]","Fake news, rumor, incorrect information, and misinformation detection are
nowadays crucial issues as these might have serious consequences for our social
fabrics. The rate of such information is increasing rapidly due to the
availability of enormous web information sources including social media feeds,
news blogs, online newspapers etc.
  In this paper, we develop various deep learning models for detecting fake
news and classifying them into the pre-defined fine-grained categories.
  At first, we develop models based on Convolutional Neural Network (CNN) and
Bi-directional Long Short Term Memory (Bi-LSTM) networks. The representations
obtained from these two models are fed into a Multi-layer Perceptron Model
(MLP) for the final classification. Our experiments on a benchmark dataset show
promising results with an overall accuracy of 44.87\%, which outperforms the
current state of the art.","6 pages, 1 figure, accepted as a short paper in Web Intelligence 2018
  (https://webintelligence2018.com/accepted-papers.html), title changed from
  {""Going Deep to Detect Liars"" Detecting Fake News using Deep Learning} to {A
  Deep Ensemble Framework for Fake News Detection and Classification} as per
  reviewers suggestion",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.04670v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.04670v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.04670v1,"{'id': 'http://arxiv.org/abs/1811.04670v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.04670v1', 'updated': '2018-11-12T11:40:09Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=12, tm_hour=11, tm_min=40, tm_sec=9, tm_wday=0, tm_yday=316, tm_isdst=0), 'published': '2018-11-12T11:40:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=12, tm_hour=11, tm_min=40, tm_sec=9, tm_wday=0, tm_yday=316, tm_isdst=0), 'title': 'A Deep Ensemble Framework for Fake News Detection and Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Deep Ensemble Framework for Fake News Detection and Classification'}, 'summary': 'Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.'}, 'authors': [{'name': 'Arjun Roy'}, {'name': 'Kingshuk Basak'}, {'name': 'Asif Ekbal'}, {'name': 'Pushpak Bhattacharyya'}], 'author_detail': {'name': 'Pushpak Bhattacharyya'}, 'author': 'Pushpak Bhattacharyya', 'arxiv_comment': '6 pages, 1 figure, accepted as a short paper in Web Intelligence 2018\n  (https://webintelligence2018.com/accepted-papers.html), title changed from\n  {""Going Deep to Detect Liars"" Detecting Fake News using Deep Learning} to {A\n  Deep Ensemble Framework for Fake News Detection and Classification} as per\n  reviewers suggestion', 'links': [{'href': 'http://arxiv.org/abs/1811.04670v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.04670v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
358,http://arxiv.org/abs/1811.01806v1,2018-11-05 15:43:45+00:00,2018-11-05 15:43:45+00:00,"Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of User Engagement and Challenges","[arxiv.Result.Author('Md Mahfuzul Haque'), arxiv.Result.Author('Mohammad Yousuf'), arxiv.Result.Author('Zahedur Arman'), arxiv.Result.Author('Md Main Uddin Rony'), arxiv.Result.Author('Ahmed Shatil Alam'), arxiv.Result.Author('Kazi Mehedi Hasan'), arxiv.Result.Author('Md Khadimul Islam'), arxiv.Result.Author('Naeemul Hassan')]","Fake news and misinformation spread in developing countries as fast as they
do in developed countries with increasing penetration of the internet and
social media. However, fighting misinformation is more difficult in developing
countries where resources and necessary technologies are scarce. This study
provides an understanding of the challenges various fact-checking initiatives
face in three South Asian countries--Bangladesh, India, and Nepal. In-depth
interviews were conducted with senior editors of six fact-checking initiatives.
Challenges identified include lack of resources, technologies, and political
pressure. An analysis of Facebook pages of these initiatives shows increasing
user engagement with their posts.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.01806v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.01806v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.01806v1,"{'id': 'http://arxiv.org/abs/1811.01806v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.01806v1', 'updated': '2018-11-05T15:43:45Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=5, tm_hour=15, tm_min=43, tm_sec=45, tm_wday=0, tm_yday=309, tm_isdst=0), 'published': '2018-11-05T15:43:45Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=5, tm_hour=15, tm_min=43, tm_sec=45, tm_wday=0, tm_yday=309, tm_isdst=0), 'title': 'Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges'}, 'summary': 'Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.'}, 'authors': [{'name': 'Md Mahfuzul Haque'}, {'name': 'Mohammad Yousuf'}, {'name': 'Zahedur Arman'}, {'name': 'Md Main Uddin Rony'}, {'name': 'Ahmed Shatil Alam'}, {'name': 'Kazi Mehedi Hasan'}, {'name': 'Md Khadimul Islam'}, {'name': 'Naeemul Hassan'}], 'author_detail': {'name': 'Naeemul Hassan'}, 'author': 'Naeemul Hassan', 'links': [{'href': 'http://arxiv.org/abs/1811.01806v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.01806v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
359,http://arxiv.org/abs/1811.00770v2,2020-03-05 01:40:56+00:00,2018-11-02 08:10:21+00:00,A Survey on Natural Language Processing for Fake News Detection,"[arxiv.Result.Author('Ray Oshikawa'), arxiv.Result.Author('Jing Qian'), arxiv.Result.Author('William Yang Wang')]","Fake news detection is a critical yet challenging problem in Natural Language
Processing (NLP). The rapid rise of social networking platforms has not only
yielded a vast increase in information accessibility but has also accelerated
the spread of fake news. Thus, the effect of fake news has been growing,
sometimes extending to the offline world and threatening public safety. Given
the massive amount of Web content, automatic fake news detection is a practical
NLP problem useful to all online content providers, in order to reduce the
human time and effort to detect and prevent the spread of fake news. In this
paper, we describe the challenges involved in fake news detection and also
describe related tasks. We systematically review and compare the task
formulations, datasets and NLP solutions that have been developed for this
task, and also discuss the potentials and limitations of them. Based on our
insights, we outline promising research directions, including more
fine-grained, detailed, fair, and practical detection models. We also highlight
the difference between fake news detection and other related tasks, and the
importance of NLP solutions for fake news detection.","11 pages, no figure, Accepted to LREC 2020","Proceedings of the 12th Language Resources and Evaluation
  Conference (LREC 2020) pp. 6086-6093",,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/1811.00770v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.00770v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.00770v2,"{'id': 'http://arxiv.org/abs/1811.00770v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.00770v2', 'updated': '2020-03-05T01:40:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=5, tm_hour=1, tm_min=40, tm_sec=56, tm_wday=3, tm_yday=65, tm_isdst=0), 'published': '2018-11-02T08:10:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=2, tm_hour=8, tm_min=10, tm_sec=21, tm_wday=4, tm_yday=306, tm_isdst=0), 'title': 'A Survey on Natural Language Processing for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Natural Language Processing for Fake News Detection'}, 'summary': 'Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.'}, 'authors': [{'name': 'Ray Oshikawa'}, {'name': 'Jing Qian'}, {'name': 'William Yang Wang'}], 'author_detail': {'name': 'William Yang Wang'}, 'author': 'William Yang Wang', 'arxiv_comment': '11 pages, no figure, Accepted to LREC 2020', 'arxiv_journal_ref': 'Proceedings of the 12th Language Resources and Evaluation\n  Conference (LREC 2020) pp. 6086-6093', 'links': [{'href': 'http://arxiv.org/abs/1811.00770v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.00770v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
360,http://arxiv.org/abs/1811.00706v1,2018-11-02 02:13:52+00:00,2018-11-02 02:13:52+00:00,Combining Similarity Features and Deep Representation Learning for Stance Detection in the Context of Checking Fake News,"[arxiv.Result.Author('Luís Borges'), arxiv.Result.Author('Bruno Martins'), arxiv.Result.Author('Pável Calado')]","Fake news are nowadays an issue of pressing concern, given their recent rise
as a potential threat to high-quality journalism and well-informed public
discourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage
the development of machine learning-based classification systems for stance
detection (i.e., for identifying whether a particular news article agrees,
disagrees, discusses, or is unrelated to a particular news headline), thus
helping in the detection and analysis of possible instances of fake news. This
article presents a new approach to tackle this stance detection problem, based
on the combination of string similarity features with a deep neural
architecture that leverages ideas previously advanced in the context of
learning efficient text representations, document classification, and natural
language inference. Specifically, we use bi-directional Recurrent Neural
Networks, together with max-pooling over the temporal/sequential dimension and
neural attention, for representing (i) the headline, (ii) the first two
sentences of the news article, and (iii) the entire news article. These
representations are then combined/compared, complemented with similarity
features inspired on other FNC-1 approaches, and passed to a final layer that
predicts the stance of the article towards the headline. We also explore the
use of external sources of information, specifically large datasets of sentence
pairs originally proposed for training and evaluating natural language
inference methods, in order to pre-train specific components of the neural
network architecture (e.g., the RNNs used for encoding sentences). The obtained
results attest to the effectiveness of the proposed ideas and show that our
model, particularly when considering pre-training and the combination of neural
representations together with similarity features, slightly outperforms the
previous state-of-the-art.","Accepted for publication in the special issue of the ACM Journal of
  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation
  and Disinformation","Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019",,cs.LG,"['cs.LG', 'cs.IR', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1811.00706v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.00706v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.00706v1,"{'id': 'http://arxiv.org/abs/1811.00706v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.00706v1', 'updated': '2018-11-02T02:13:52Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=2, tm_hour=2, tm_min=13, tm_sec=52, tm_wday=4, tm_yday=306, tm_isdst=0), 'published': '2018-11-02T02:13:52Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=2, tm_hour=2, tm_min=13, tm_sec=52, tm_wday=4, tm_yday=306, tm_isdst=0), 'title': 'Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News'}, 'summary': 'Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.'}, 'authors': [{'name': 'Luís Borges'}, {'name': 'Bruno Martins'}, {'name': 'Pável Calado'}], 'author_detail': {'name': 'Pável Calado'}, 'author': 'Pável Calado', 'arxiv_comment': 'Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation', 'arxiv_journal_ref': 'Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019', 'links': [{'href': 'http://arxiv.org/abs/1811.00706v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.00706v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
361,http://arxiv.org/abs/1810.11449v3,2019-01-20 19:00:45+00:00,2018-10-26 17:59:56+00:00,The Politics of Attention,"[arxiv.Result.Author('Li Hu'), arxiv.Result.Author('Anqi Li')]","We develop an equilibrium theory of attention and politics. In a spatial
model of electoral competition where candidates have varying policy
preferences, we examine what kinds of political behaviors capture voters'
limited attention and how this concern affects the overall political outcomes.
Following the seminal works of Downs (1957) and Sims (1998), we assume that
voters are rationally inattentive and can process information about the
policies at a cost proportional to entropy reduction. The main finding is an
equilibrium phenomenon called attention- and media-driven extremism, namely as
we increase the attention cost or garble the news technology, a truncated set
of the equilibria captures voters' attention through enlarging the policy
differentials between the varying types of the candidates. We supplement our
analysis with historical accounts, and discuss its relevance in the new era
featured with greater media choices and distractions, as well as the rise of
partisan media and fake news.",,,,econ.GN,"['econ.GN', 'econ.TH', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/1810.11449v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1810.11449v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1810.11449v3,"{'id': 'http://arxiv.org/abs/1810.11449v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1810.11449v3', 'updated': '2019-01-20T19:00:45Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=20, tm_hour=19, tm_min=0, tm_sec=45, tm_wday=6, tm_yday=20, tm_isdst=0), 'published': '2018-10-26T17:59:56Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=26, tm_hour=17, tm_min=59, tm_sec=56, tm_wday=4, tm_yday=299, tm_isdst=0), 'title': 'The Politics of Attention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Politics of Attention'}, 'summary': ""We develop an equilibrium theory of attention and politics. In a spatial\nmodel of electoral competition where candidates have varying policy\npreferences, we examine what kinds of political behaviors capture voters'\nlimited attention and how this concern affects the overall political outcomes.\nFollowing the seminal works of Downs (1957) and Sims (1998), we assume that\nvoters are rationally inattentive and can process information about the\npolicies at a cost proportional to entropy reduction. The main finding is an\nequilibrium phenomenon called attention- and media-driven extremism, namely as\nwe increase the attention cost or garble the news technology, a truncated set\nof the equilibria captures voters' attention through enlarging the policy\ndifferentials between the varying types of the candidates. We supplement our\nanalysis with historical accounts, and discuss its relevance in the new era\nfeatured with greater media choices and distractions, as well as the rise of\npartisan media and fake news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We develop an equilibrium theory of attention and politics. In a spatial\nmodel of electoral competition where candidates have varying policy\npreferences, we examine what kinds of political behaviors capture voters'\nlimited attention and how this concern affects the overall political outcomes.\nFollowing the seminal works of Downs (1957) and Sims (1998), we assume that\nvoters are rationally inattentive and can process information about the\npolicies at a cost proportional to entropy reduction. The main finding is an\nequilibrium phenomenon called attention- and media-driven extremism, namely as\nwe increase the attention cost or garble the news technology, a truncated set\nof the equilibria captures voters' attention through enlarging the policy\ndifferentials between the varying types of the candidates. We supplement our\nanalysis with historical accounts, and discuss its relevance in the new era\nfeatured with greater media choices and distractions, as well as the rise of\npartisan media and fake news.""}, 'authors': [{'name': 'Li Hu'}, {'name': 'Anqi Li'}], 'author_detail': {'name': 'Anqi Li'}, 'author': 'Anqi Li', 'links': [{'href': 'http://arxiv.org/abs/1810.11449v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1810.11449v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
362,http://arxiv.org/abs/1809.09076v3,2021-02-22 20:26:19+00:00,2018-09-24 17:43:54+00:00,Subleading BMS charges and fake news near null infinity,"[arxiv.Result.Author('Hadi Godazgar'), arxiv.Result.Author('Mahdi Godazgar'), arxiv.Result.Author('C. N. Pope')]","In this paper we establish a relation between the non-linearly conserved
Newman-Penrose charges and certain subleading terms in a large-$r$ expansion of
the BMS charges in an asymptotically-flat spacetime. We define the subleading
BMS charges by considering a $1/r$-expansion of the Barnich-Brandt prescription
for defining asymptotic charges in an asymptotically-flat spacetime. At the
leading order, i.e. $1/r^0$, one obtains the standard BMS charges, which would
be integrable and conserved in the absence of a flux term at null infinity,
corresponding to gravitational radiation, or Bondi news. At subleading orders,
analogous terms in general provide obstructions to the integrability of the
corresponding charges. Since the subleading terms are defined close to null
infinity, but vanish actually at infinity, the analogous obstructions are not
associated with genuine Bondi news. One may instead describe them as
corresponding to ""fake news."" At order $r^{-3}$, we find that a set of
integrable charges can be defined and that these are related to the ten
non-linearly conserved Newman-Penrose charges.",34 pages;few minor typos corrected,JHEP01(2019)143,10.1007/JHEP01(2019)143,hep-th,"['hep-th', 'gr-qc']","[arxiv.Result.Link('http://dx.doi.org/10.1007/JHEP01(2019)143', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1809.09076v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.09076v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.09076v3,"{'id': 'http://arxiv.org/abs/1809.09076v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.09076v3', 'updated': '2021-02-22T20:26:19Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=22, tm_hour=20, tm_min=26, tm_sec=19, tm_wday=0, tm_yday=53, tm_isdst=0), 'published': '2018-09-24T17:43:54Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=24, tm_hour=17, tm_min=43, tm_sec=54, tm_wday=0, tm_yday=267, tm_isdst=0), 'title': 'Subleading BMS charges and fake news near null infinity', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Subleading BMS charges and fake news near null infinity'}, 'summary': 'In this paper we establish a relation between the non-linearly conserved\nNewman-Penrose charges and certain subleading terms in a large-$r$ expansion of\nthe BMS charges in an asymptotically-flat spacetime. We define the subleading\nBMS charges by considering a $1/r$-expansion of the Barnich-Brandt prescription\nfor defining asymptotic charges in an asymptotically-flat spacetime. At the\nleading order, i.e. $1/r^0$, one obtains the standard BMS charges, which would\nbe integrable and conserved in the absence of a flux term at null infinity,\ncorresponding to gravitational radiation, or Bondi news. At subleading orders,\nanalogous terms in general provide obstructions to the integrability of the\ncorresponding charges. Since the subleading terms are defined close to null\ninfinity, but vanish actually at infinity, the analogous obstructions are not\nassociated with genuine Bondi news. One may instead describe them as\ncorresponding to ""fake news."" At order $r^{-3}$, we find that a set of\nintegrable charges can be defined and that these are related to the ten\nnon-linearly conserved Newman-Penrose charges.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper we establish a relation between the non-linearly conserved\nNewman-Penrose charges and certain subleading terms in a large-$r$ expansion of\nthe BMS charges in an asymptotically-flat spacetime. We define the subleading\nBMS charges by considering a $1/r$-expansion of the Barnich-Brandt prescription\nfor defining asymptotic charges in an asymptotically-flat spacetime. At the\nleading order, i.e. $1/r^0$, one obtains the standard BMS charges, which would\nbe integrable and conserved in the absence of a flux term at null infinity,\ncorresponding to gravitational radiation, or Bondi news. At subleading orders,\nanalogous terms in general provide obstructions to the integrability of the\ncorresponding charges. Since the subleading terms are defined close to null\ninfinity, but vanish actually at infinity, the analogous obstructions are not\nassociated with genuine Bondi news. One may instead describe them as\ncorresponding to ""fake news."" At order $r^{-3}$, we find that a set of\nintegrable charges can be defined and that these are related to the ten\nnon-linearly conserved Newman-Penrose charges.'}, 'authors': [{'name': 'Hadi Godazgar'}, {'name': 'Mahdi Godazgar'}, {'name': 'C. N. Pope'}], 'author_detail': {'name': 'C. N. Pope'}, 'author': 'C. N. Pope', 'arxiv_doi': '10.1007/JHEP01(2019)143', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/JHEP01(2019)143', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1809.09076v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.09076v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '34 pages;few minor typos corrected', 'arxiv_journal_ref': 'JHEP01(2019)143', 'arxiv_primary_category': {'term': 'hep-th', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'hep-th', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'gr-qc', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
363,http://arxiv.org/abs/1809.06683v1,2018-09-18 13:12:21+00:00,2018-09-18 13:12:21+00:00,RumourEval 2019: Determining Rumour Veracity and Support for Rumours,"[arxiv.Result.Author('Genevieve Gorrell'), arxiv.Result.Author('Kalina Bontcheva'), arxiv.Result.Author('Leon Derczynski'), arxiv.Result.Author('Elena Kochkina'), arxiv.Result.Author('Maria Liakata'), arxiv.Result.Author('Arkaitz Zubiaga')]","This is the proposal for RumourEval-2019, which will run in early 2019 as
part of that year's SemEval event. Since the first RumourEval shared task in
2017, interest in automated claim validation has greatly increased, as the
dangers of ""fake news"" have become a mainstream concern. Yet automated support
for rumour checking remains in its infancy. For this reason, it is important
that a shared task in this area continues to provide a focus for effort, which
is likely to increase. We therefore propose a continuation in which the
veracity of further rumours is determined, and as previously, supportive of
this goal, tweets discussing them are classified according to the stance they
take regarding the rumour. Scope is extended compared with the first
RumourEval, in that the dataset is substantially expanded to include Reddit as
well as Twitter data, and additional languages are also included.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1809.06683v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.06683v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.06683v1,"{'id': 'http://arxiv.org/abs/1809.06683v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.06683v1', 'updated': '2018-09-18T13:12:21Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=18, tm_hour=13, tm_min=12, tm_sec=21, tm_wday=1, tm_yday=261, tm_isdst=0), 'published': '2018-09-18T13:12:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=18, tm_hour=13, tm_min=12, tm_sec=21, tm_wday=1, tm_yday=261, tm_isdst=0), 'title': 'RumourEval 2019: Determining Rumour Veracity and Support for Rumours', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'RumourEval 2019: Determining Rumour Veracity and Support for Rumours'}, 'summary': 'This is the proposal for RumourEval-2019, which will run in early 2019 as\npart of that year\'s SemEval event. Since the first RumourEval shared task in\n2017, interest in automated claim validation has greatly increased, as the\ndangers of ""fake news"" have become a mainstream concern. Yet automated support\nfor rumour checking remains in its infancy. For this reason, it is important\nthat a shared task in this area continues to provide a focus for effort, which\nis likely to increase. We therefore propose a continuation in which the\nveracity of further rumours is determined, and as previously, supportive of\nthis goal, tweets discussing them are classified according to the stance they\ntake regarding the rumour. Scope is extended compared with the first\nRumourEval, in that the dataset is substantially expanded to include Reddit as\nwell as Twitter data, and additional languages are also included.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This is the proposal for RumourEval-2019, which will run in early 2019 as\npart of that year\'s SemEval event. Since the first RumourEval shared task in\n2017, interest in automated claim validation has greatly increased, as the\ndangers of ""fake news"" have become a mainstream concern. Yet automated support\nfor rumour checking remains in its infancy. For this reason, it is important\nthat a shared task in this area continues to provide a focus for effort, which\nis likely to increase. We therefore propose a continuation in which the\nveracity of further rumours is determined, and as previously, supportive of\nthis goal, tweets discussing them are classified according to the stance they\ntake regarding the rumour. Scope is extended compared with the first\nRumourEval, in that the dataset is substantially expanded to include Reddit as\nwell as Twitter data, and additional languages are also included.'}, 'authors': [{'name': 'Genevieve Gorrell'}, {'name': 'Kalina Bontcheva'}, {'name': 'Leon Derczynski'}, {'name': 'Elena Kochkina'}, {'name': 'Maria Liakata'}, {'name': 'Arkaitz Zubiaga'}], 'author_detail': {'name': 'Arkaitz Zubiaga'}, 'author': 'Arkaitz Zubiaga', 'links': [{'href': 'http://arxiv.org/abs/1809.06683v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.06683v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
364,http://arxiv.org/abs/1809.06416v1,2018-09-17 19:51:18+00:00,2018-09-17 19:51:18+00:00,DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning,"[arxiv.Result.Author('Kashyap Popat'), arxiv.Result.Author('Subhabrata Mukherjee'), arxiv.Result.Author('Andrew Yates'), arxiv.Result.Author('Gerhard Weikum')]","Misinformation such as fake news is one of the big challenges of our society.
Research on automated fact-checking has proposed methods based on supervised
learning, but these approaches do not consider external evidence apart from
labeled training instances. Recent approaches counter this deficit by
considering external sources related to a claim. However, these methods require
substantial feature modeling and rich lexicons. This paper overcomes these
limitations of prior work with an end-to-end model for evidence-aware
credibility assessment of arbitrary textual claims, without any human
intervention. It presents a neural network model that judiciously aggregates
signals from external evidence articles, the language of these articles and the
trustworthiness of their sources. It also derives informative features for
generating user-comprehensible explanations that makes the neural network
predictions transparent to the end-user. Experiments with four datasets and
ablation studies show the strength of our method.",EMNLP 2018,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1809.06416v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.06416v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.06416v1,"{'id': 'http://arxiv.org/abs/1809.06416v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.06416v1', 'updated': '2018-09-17T19:51:18Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=17, tm_hour=19, tm_min=51, tm_sec=18, tm_wday=0, tm_yday=260, tm_isdst=0), 'published': '2018-09-17T19:51:18Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=17, tm_hour=19, tm_min=51, tm_sec=18, tm_wday=0, tm_yday=260, tm_isdst=0), 'title': 'DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning'}, 'summary': 'Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.'}, 'authors': [{'name': 'Kashyap Popat'}, {'name': 'Subhabrata Mukherjee'}, {'name': 'Andrew Yates'}, {'name': 'Gerhard Weikum'}], 'author_detail': {'name': 'Gerhard Weikum'}, 'author': 'Gerhard Weikum', 'arxiv_comment': 'EMNLP 2018', 'links': [{'href': 'http://arxiv.org/abs/1809.06416v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.06416v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
365,http://arxiv.org/abs/1809.05521v2,2018-11-21 00:22:24+00:00,2018-09-14 17:46:58+00:00,Defending Elections Against Malicious Spread of Misinformation,"[arxiv.Result.Author('Bryan Wilder'), arxiv.Result.Author('Yevgeniy Vorobeychik')]","The integrity of democratic elections depends on voters' access to accurate
information. However, modern media environments, which are dominated by social
media, provide malicious actors with unprecedented ability to manipulate
elections via misinformation, such as fake news. We study a zero-sum game
between an attacker, who attempts to subvert an election by propagating a fake
new story or other misinformation over a set of advertising channels, and a
defender who attempts to limit the attacker's impact. Computing an equilibrium
in this game is challenging as even the pure strategy sets of players are
exponential. Nevertheless, we give provable polynomial-time approximation
algorithms for computing the defender's minimax optimal strategy across a range
of settings, encompassing different population structures as well as models of
the information available to each player. Experimental results confirm that our
algorithms provide near-optimal defender strategies and showcase variations in
the difficulty of defending elections depending on the resources and knowledge
available to the defender.",Full version of paper accepted to AAAI 2019,,,cs.GT,"['cs.GT', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1809.05521v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.05521v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.05521v2,"{'id': 'http://arxiv.org/abs/1809.05521v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.05521v2', 'updated': '2018-11-21T00:22:24Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=21, tm_hour=0, tm_min=22, tm_sec=24, tm_wday=2, tm_yday=325, tm_isdst=0), 'published': '2018-09-14T17:46:58Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=14, tm_hour=17, tm_min=46, tm_sec=58, tm_wday=4, tm_yday=257, tm_isdst=0), 'title': 'Defending Elections Against Malicious Spread of Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Defending Elections Against Malicious Spread of Misinformation'}, 'summary': ""The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender.""}, 'authors': [{'name': 'Bryan Wilder'}, {'name': 'Yevgeniy Vorobeychik'}], 'author_detail': {'name': 'Yevgeniy Vorobeychik'}, 'author': 'Yevgeniy Vorobeychik', 'arxiv_comment': 'Full version of paper accepted to AAAI 2019', 'links': [{'href': 'http://arxiv.org/abs/1809.05521v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.05521v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
366,http://arxiv.org/abs/1809.05252v1,2018-09-14 04:52:33+00:00,2018-09-14 04:52:33+00:00,CIMTDetect: A Community Infused Matrix-Tensor Coupled Factorization Based Method for Fake News Detection,"[arxiv.Result.Author('Shashank Gupta'), arxiv.Result.Author('Raghuveer Thirukovalluru'), arxiv.Result.Author('Manjira Sinha'), arxiv.Result.Author('Sandya Mannarswamy')]","Detecting whether a news article is fake or genuine is a crucial task in
today's digital world where it's easy to create and spread a misleading news
article. This is especially true of news stories shared on social media since
they don't undergo any stringent journalistic checking associated with main
stream media. Given the inherent human tendency to share information with their
social connections at a mouse-click, fake news articles masquerading as real
ones, tend to spread widely and virally. The presence of echo chambers (people
sharing same beliefs) in social networks, only adds to this problem of
wide-spread existence of fake news on social media. In this paper, we tackle
the problem of fake news detection from social media by exploiting the very
presence of echo chambers that exist within the social network of users to
obtain an efficient and informative latent representation of the news article.
By modeling the echo-chambers as closely-connected communities within the
social network, we represent a news article as a 3-mode tensor of the structure
- <News, User, Community> and propose a tensor factorization based method to
encode the news article in a latent embedding space preserving the community
structure. We also propose an extension of the above method, which jointly
models the community and content information of the news article through a
coupled matrix-tensor factorization framework. We empirically demonstrate the
efficacy of our method for the task of Fake News Detection over two real-world
datasets. Further, we validate the generalization of the resulting embeddings
over two other auxiliary tasks, namely: \textbf{1)} News Cohort Analysis and
\textbf{2)} Collaborative News Recommendation. Our proposed method outperforms
appropriate baselines for both the tasks, establishing its generalization.",Presented at ASONAM'18,,,cs.IR,"['cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1809.05252v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.05252v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.05252v1,"{'id': 'http://arxiv.org/abs/1809.05252v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.05252v1', 'updated': '2018-09-14T04:52:33Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=14, tm_hour=4, tm_min=52, tm_sec=33, tm_wday=4, tm_yday=257, tm_isdst=0), 'published': '2018-09-14T04:52:33Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=14, tm_hour=4, tm_min=52, tm_sec=33, tm_wday=4, tm_yday=257, tm_isdst=0), 'title': 'CIMTDetect: A Community Infused Matrix-Tensor Coupled Factorization\n  Based Method for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CIMTDetect: A Community Infused Matrix-Tensor Coupled Factorization\n  Based Method for Fake News Detection'}, 'summary': ""Detecting whether a news article is fake or genuine is a crucial task in\ntoday's digital world where it's easy to create and spread a misleading news\narticle. This is especially true of news stories shared on social media since\nthey don't undergo any stringent journalistic checking associated with main\nstream media. Given the inherent human tendency to share information with their\nsocial connections at a mouse-click, fake news articles masquerading as real\nones, tend to spread widely and virally. The presence of echo chambers (people\nsharing same beliefs) in social networks, only adds to this problem of\nwide-spread existence of fake news on social media. In this paper, we tackle\nthe problem of fake news detection from social media by exploiting the very\npresence of echo chambers that exist within the social network of users to\nobtain an efficient and informative latent representation of the news article.\nBy modeling the echo-chambers as closely-connected communities within the\nsocial network, we represent a news article as a 3-mode tensor of the structure\n- <News, User, Community> and propose a tensor factorization based method to\nencode the news article in a latent embedding space preserving the community\nstructure. We also propose an extension of the above method, which jointly\nmodels the community and content information of the news article through a\ncoupled matrix-tensor factorization framework. We empirically demonstrate the\nefficacy of our method for the task of Fake News Detection over two real-world\ndatasets. Further, we validate the generalization of the resulting embeddings\nover two other auxiliary tasks, namely: \\textbf{1)} News Cohort Analysis and\n\\textbf{2)} Collaborative News Recommendation. Our proposed method outperforms\nappropriate baselines for both the tasks, establishing its generalization."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Detecting whether a news article is fake or genuine is a crucial task in\ntoday's digital world where it's easy to create and spread a misleading news\narticle. This is especially true of news stories shared on social media since\nthey don't undergo any stringent journalistic checking associated with main\nstream media. Given the inherent human tendency to share information with their\nsocial connections at a mouse-click, fake news articles masquerading as real\nones, tend to spread widely and virally. The presence of echo chambers (people\nsharing same beliefs) in social networks, only adds to this problem of\nwide-spread existence of fake news on social media. In this paper, we tackle\nthe problem of fake news detection from social media by exploiting the very\npresence of echo chambers that exist within the social network of users to\nobtain an efficient and informative latent representation of the news article.\nBy modeling the echo-chambers as closely-connected communities within the\nsocial network, we represent a news article as a 3-mode tensor of the structure\n- <News, User, Community> and propose a tensor factorization based method to\nencode the news article in a latent embedding space preserving the community\nstructure. We also propose an extension of the above method, which jointly\nmodels the community and content information of the news article through a\ncoupled matrix-tensor factorization framework. We empirically demonstrate the\nefficacy of our method for the task of Fake News Detection over two real-world\ndatasets. Further, we validate the generalization of the resulting embeddings\nover two other auxiliary tasks, namely: \\textbf{1)} News Cohort Analysis and\n\\textbf{2)} Collaborative News Recommendation. Our proposed method outperforms\nappropriate baselines for both the tasks, establishing its generalization.""}, 'authors': [{'name': 'Shashank Gupta'}, {'name': 'Raghuveer Thirukovalluru'}, {'name': 'Manjira Sinha'}, {'name': 'Sandya Mannarswamy'}], 'author_detail': {'name': 'Sandya Mannarswamy'}, 'author': 'Sandya Mannarswamy', 'arxiv_comment': ""Presented at ASONAM'18"", 'links': [{'href': 'http://arxiv.org/abs/1809.05252v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.05252v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
367,http://arxiv.org/abs/1809.01574v2,2018-10-03 12:44:14+00:00,2018-09-05 15:20:41+00:00,Stance Prediction for Russian: Data and Analysis,"[arxiv.Result.Author('Nikita Lozhnikov'), arxiv.Result.Author('Leon Derczynski'), arxiv.Result.Author('Manuel Mazzara')]","Stance detection is a critical component of rumour and fake news
identification. It involves the extraction of the stance a particular author
takes related to a given claim, both expressed in text. This paper investigates
stance classification for Russian. It introduces a new dataset, RuStance, of
Russian tweets and news comments from multiple sources, covering multiple
stories, as well as text classification approaches to stance detection as
benchmarks over this data in this language. As well as presenting this
openly-available dataset, the first of its kind for Russian, the paper presents
a baseline for stance prediction in the language.",,,10.13140/RG.2.2.15252.76161/1,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://dx.doi.org/10.13140/RG.2.2.15252.76161/1', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1809.01574v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.01574v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.01574v2,"{'id': 'http://arxiv.org/abs/1809.01574v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.01574v2', 'updated': '2018-10-03T12:44:14Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=3, tm_hour=12, tm_min=44, tm_sec=14, tm_wday=2, tm_yday=276, tm_isdst=0), 'published': '2018-09-05T15:20:41Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=5, tm_hour=15, tm_min=20, tm_sec=41, tm_wday=2, tm_yday=248, tm_isdst=0), 'title': 'Stance Prediction for Russian: Data and Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance Prediction for Russian: Data and Analysis'}, 'summary': 'Stance detection is a critical component of rumour and fake news\nidentification. It involves the extraction of the stance a particular author\ntakes related to a given claim, both expressed in text. This paper investigates\nstance classification for Russian. It introduces a new dataset, RuStance, of\nRussian tweets and news comments from multiple sources, covering multiple\nstories, as well as text classification approaches to stance detection as\nbenchmarks over this data in this language. As well as presenting this\nopenly-available dataset, the first of its kind for Russian, the paper presents\na baseline for stance prediction in the language.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance detection is a critical component of rumour and fake news\nidentification. It involves the extraction of the stance a particular author\ntakes related to a given claim, both expressed in text. This paper investigates\nstance classification for Russian. It introduces a new dataset, RuStance, of\nRussian tweets and news comments from multiple sources, covering multiple\nstories, as well as text classification approaches to stance detection as\nbenchmarks over this data in this language. As well as presenting this\nopenly-available dataset, the first of its kind for Russian, the paper presents\na baseline for stance prediction in the language.'}, 'authors': [{'name': 'Nikita Lozhnikov'}, {'name': 'Leon Derczynski'}, {'name': 'Manuel Mazzara'}], 'author_detail': {'name': 'Manuel Mazzara'}, 'author': 'Manuel Mazzara', 'arxiv_doi': '10.13140/RG.2.2.15252.76161/1', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.13140/RG.2.2.15252.76161/1', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1809.01574v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.01574v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
368,http://arxiv.org/abs/1809.01286v3,2019-03-27 16:54:50+00:00,2018-09-05 01:14:11+00:00,"FakeNewsNet: A Data Repository with News Content, Social Context and Spatialtemporal Information for Studying Fake News on Social Media","[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Deepak Mahudeswaran'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Dongwon Lee'), arxiv.Result.Author('Huan Liu')]","Social media has become a popular means for people to consume news.
Meanwhile, it also enables the wide dissemination of fake news, i.e., news with
intentionally false information, which brings significant negative effects to
the society. Thus, fake news detection is attracting increasing attention.
However, fake news detection is a non-trivial task, which requires multi-source
information such as news content, social context, and dynamic information.
First, fake news is written to fool people, which makes it difficult to detect
fake news simply based on news contents. In addition to news contents, we need
to explore social contexts such as user engagements and social behaviors. For
example, a credible user's comment that ""this is a fake news"" is a strong
signal for detecting fake news. Second, dynamic information such as how fake
news and true news propagate and how users' opinions toward news pieces are
very important for extracting useful patterns for (early) fake news detection
and intervention. Thus, comprehensive datasets which contain news content,
social context, and dynamic information could facilitate fake news propagation,
detection, and mitigation; while to the best of our knowledge, existing
datasets only contains one or two aspects. Therefore, in this paper, to
facilitate fake news related researches, we provide a fake news data repository
FakeNewsNet, which contains two comprehensive datasets that includes news
content, social context, and dynamic information. We present a comprehensive
description of datasets collection, demonstrate an exploratory analysis of this
data repository from different perspectives, and discuss the benefits of
FakeNewsNet for potential applications on fake news study on social media.",11 pages; the dataset structure and API function are updated,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1809.01286v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.01286v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.01286v3,"{'id': 'http://arxiv.org/abs/1809.01286v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.01286v3', 'updated': '2019-03-27T16:54:50Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=27, tm_hour=16, tm_min=54, tm_sec=50, tm_wday=2, tm_yday=86, tm_isdst=0), 'published': '2018-09-05T01:14:11Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=5, tm_hour=1, tm_min=14, tm_sec=11, tm_wday=2, tm_yday=248, tm_isdst=0), 'title': 'FakeNewsNet: A Data Repository with News Content, Social Context and\n  Spatialtemporal Information for Studying Fake News on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeNewsNet: A Data Repository with News Content, Social Context and\n  Spatialtemporal Information for Studying Fake News on Social Media'}, 'summary': 'Social media has become a popular means for people to consume news.\nMeanwhile, it also enables the wide dissemination of fake news, i.e., news with\nintentionally false information, which brings significant negative effects to\nthe society. Thus, fake news detection is attracting increasing attention.\nHowever, fake news detection is a non-trivial task, which requires multi-source\ninformation such as news content, social context, and dynamic information.\nFirst, fake news is written to fool people, which makes it difficult to detect\nfake news simply based on news contents. In addition to news contents, we need\nto explore social contexts such as user engagements and social behaviors. For\nexample, a credible user\'s comment that ""this is a fake news"" is a strong\nsignal for detecting fake news. Second, dynamic information such as how fake\nnews and true news propagate and how users\' opinions toward news pieces are\nvery important for extracting useful patterns for (early) fake news detection\nand intervention. Thus, comprehensive datasets which contain news content,\nsocial context, and dynamic information could facilitate fake news propagation,\ndetection, and mitigation; while to the best of our knowledge, existing\ndatasets only contains one or two aspects. Therefore, in this paper, to\nfacilitate fake news related researches, we provide a fake news data repository\nFakeNewsNet, which contains two comprehensive datasets that includes news\ncontent, social context, and dynamic information. We present a comprehensive\ndescription of datasets collection, demonstrate an exploratory analysis of this\ndata repository from different perspectives, and discuss the benefits of\nFakeNewsNet for potential applications on fake news study on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media has become a popular means for people to consume news.\nMeanwhile, it also enables the wide dissemination of fake news, i.e., news with\nintentionally false information, which brings significant negative effects to\nthe society. Thus, fake news detection is attracting increasing attention.\nHowever, fake news detection is a non-trivial task, which requires multi-source\ninformation such as news content, social context, and dynamic information.\nFirst, fake news is written to fool people, which makes it difficult to detect\nfake news simply based on news contents. In addition to news contents, we need\nto explore social contexts such as user engagements and social behaviors. For\nexample, a credible user\'s comment that ""this is a fake news"" is a strong\nsignal for detecting fake news. Second, dynamic information such as how fake\nnews and true news propagate and how users\' opinions toward news pieces are\nvery important for extracting useful patterns for (early) fake news detection\nand intervention. Thus, comprehensive datasets which contain news content,\nsocial context, and dynamic information could facilitate fake news propagation,\ndetection, and mitigation; while to the best of our knowledge, existing\ndatasets only contains one or two aspects. Therefore, in this paper, to\nfacilitate fake news related researches, we provide a fake news data repository\nFakeNewsNet, which contains two comprehensive datasets that includes news\ncontent, social context, and dynamic information. We present a comprehensive\ndescription of datasets collection, demonstrate an exploratory analysis of this\ndata repository from different perspectives, and discuss the benefits of\nFakeNewsNet for potential applications on fake news study on social media.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Deepak Mahudeswaran'}, {'name': 'Suhang Wang'}, {'name': 'Dongwon Lee'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '11 pages; the dataset structure and API function are updated', 'links': [{'href': 'http://arxiv.org/abs/1809.01286v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.01286v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
369,http://arxiv.org/abs/1809.00964v2,2018-10-26 10:39:34+00:00,2018-09-04 13:50:49+00:00,How to model fake news,"[arxiv.Result.Author('Dorje C. Brody'), arxiv.Result.Author('David M. Meier')]","Over the past three years it has become evident that fake news is a danger to
democracy. However, until now there has been no clear understanding of how to
define fake news, much less how to model it. This paper addresses both these
issues. A definition of fake news is given, and two approaches for the
modelling of fake news and its impact in elections and referendums are
introduced. The first approach, based on the idea of a representative voter, is
shown to be suitable to obtain a qualitative understanding of phenomena
associated with fake news at a macroscopic level. The second approach, based on
the idea of an election microstructure, describes the collective behaviour of
the electorate by modelling the preferences of individual voters. It is shown
through a simulation study that the mere knowledge that pieces of fake news may
be in circulation goes a long way towards mitigating the impact of fake news.","17 pages, 3 figures",,,stat.AP,"['stat.AP', 'cs.IT', 'cs.SI', 'econ.GN', 'math.IT', 'math.PR', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/1809.00964v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.00964v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.00964v2,"{'id': 'http://arxiv.org/abs/1809.00964v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.00964v2', 'updated': '2018-10-26T10:39:34Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=26, tm_hour=10, tm_min=39, tm_sec=34, tm_wday=4, tm_yday=299, tm_isdst=0), 'published': '2018-09-04T13:50:49Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=4, tm_hour=13, tm_min=50, tm_sec=49, tm_wday=1, tm_yday=247, tm_isdst=0), 'title': 'How to model fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How to model fake news'}, 'summary': 'Over the past three years it has become evident that fake news is a danger to\ndemocracy. However, until now there has been no clear understanding of how to\ndefine fake news, much less how to model it. This paper addresses both these\nissues. A definition of fake news is given, and two approaches for the\nmodelling of fake news and its impact in elections and referendums are\nintroduced. The first approach, based on the idea of a representative voter, is\nshown to be suitable to obtain a qualitative understanding of phenomena\nassociated with fake news at a macroscopic level. The second approach, based on\nthe idea of an election microstructure, describes the collective behaviour of\nthe electorate by modelling the preferences of individual voters. It is shown\nthrough a simulation study that the mere knowledge that pieces of fake news may\nbe in circulation goes a long way towards mitigating the impact of fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past three years it has become evident that fake news is a danger to\ndemocracy. However, until now there has been no clear understanding of how to\ndefine fake news, much less how to model it. This paper addresses both these\nissues. A definition of fake news is given, and two approaches for the\nmodelling of fake news and its impact in elections and referendums are\nintroduced. The first approach, based on the idea of a representative voter, is\nshown to be suitable to obtain a qualitative understanding of phenomena\nassociated with fake news at a macroscopic level. The second approach, based on\nthe idea of an election microstructure, describes the collective behaviour of\nthe electorate by modelling the preferences of individual voters. It is shown\nthrough a simulation study that the mere knowledge that pieces of fake news may\nbe in circulation goes a long way towards mitigating the impact of fake news.'}, 'authors': [{'name': 'Dorje C. Brody'}, {'name': 'David M. Meier'}], 'author_detail': {'name': 'David M. Meier'}, 'author': 'David M. Meier', 'arxiv_comment': '17 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/1809.00964v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.00964v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
370,http://arxiv.org/abs/1809.00494v1,2018-09-03 08:37:33+00:00,2018-09-03 08:37:33+00:00,Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News on the Web,"[arxiv.Result.Author('Diego Esteves'), arxiv.Result.Author('Aniketh Janardhan Reddy'), arxiv.Result.Author('Piyush Chawla'), arxiv.Result.Author('Jens Lehmann')]","With the growth of the internet, the number of fake-news online has been
proliferating every year. The consequences of such phenomena are manifold,
ranging from lousy decision-making process to bullying and violence episodes.
Therefore, fact-checking algorithms became a valuable asset. To this aim, an
important step to detect fake-news is to have access to a credibility score for
a given information source. However, most of the widely used Web indicators
have either been shut-down to the public (e.g., Google PageRank) or are not
free for use (Alexa Rank). Further existing databases are short-manually
curated lists of online sources, which do not scale. Finally, most of the
research on the topic is theoretical-based or explore confidential data in a
restricted simulation environment. In this paper we explore current research,
highlight the challenges and propose solutions to tackle the problem of
classifying websites into a credibility scale. The proposed model automatically
extracts source reputation cues and computes a credibility factor, providing
valuable insights which can help in belittling dubious and confirming trustful
unknown websites. Experimental results outperform state of the art in the
2-classes and 5-classes setting.",,"EMNLP 2018: Conference on Empirical Methods in Natural Language
  Processing (The First Workshop on Fact Extraction and Verification)",,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1809.00494v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.00494v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.00494v1,"{'id': 'http://arxiv.org/abs/1809.00494v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.00494v1', 'updated': '2018-09-03T08:37:33Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=3, tm_hour=8, tm_min=37, tm_sec=33, tm_wday=0, tm_yday=246, tm_isdst=0), 'published': '2018-09-03T08:37:33Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=3, tm_hour=8, tm_min=37, tm_sec=33, tm_wday=0, tm_yday=246, tm_isdst=0), 'title': 'Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web'}, 'summary': 'With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.'}, 'authors': [{'name': 'Diego Esteves'}, {'name': 'Aniketh Janardhan Reddy'}, {'name': 'Piyush Chawla'}, {'name': 'Jens Lehmann'}], 'author_detail': {'name': 'Jens Lehmann'}, 'author': 'Jens Lehmann', 'arxiv_journal_ref': 'EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)', 'links': [{'href': 'http://arxiv.org/abs/1809.00494v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.00494v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
371,http://arxiv.org/abs/1808.09922v1,2018-08-29 16:50:16+00:00,2018-08-29 16:50:16+00:00,Limiting the Spread of Fake News on Social Media Platforms by Evaluating Users' Trustworthiness,"[arxiv.Result.Author('Oana Balmau'), arxiv.Result.Author('Rachid Guerraoui'), arxiv.Result.Author('Anne-Marie Kermarrec'), arxiv.Result.Author('Alexandre Maurer'), arxiv.Result.Author('Matej Pavlovic'), arxiv.Result.Author('Willy Zwaenepoel')]","Today's social media platforms enable to spread both authentic and fake news
very quickly. Some approaches have been proposed to automatically detect such
""fake"" news based on their content, but it is difficult to agree on universal
criteria of authenticity (which can be bypassed by adversaries once known).
Besides, it is obviously impossible to have each news item checked by a human.
  In this paper, we a mechanism to limit the spread of fake news which is not
based on content. It can be implemented as a plugin on a social media platform.
The principle is as follows: a team of fact-checkers reviews a small number of
news items (the most popular ones), which enables to have an estimation of each
user's inclination to share fake news items. Then, using a Bayesian approach,
we estimate the trustworthiness of future news items, and treat accordingly
those of them that pass a certain ""untrustworthiness"" threshold.
  We then evaluate the effectiveness and overhead of this technique on a large
Twitter graph. We show that having a few thousands users exposed to one given
news item enables to reach a very precise estimation of its reliability. We
thus identify more than 99% of fake news items with no false positives. The
performance impact is very small: the induced overhead on the 90th percentile
latency is less than 3%, and less than 8% on the throughput of user operations.","10 pages, 9 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1808.09922v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.09922v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.09922v1,"{'id': 'http://arxiv.org/abs/1808.09922v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.09922v1', 'updated': '2018-08-29T16:50:16Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=29, tm_hour=16, tm_min=50, tm_sec=16, tm_wday=2, tm_yday=241, tm_isdst=0), 'published': '2018-08-29T16:50:16Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=29, tm_hour=16, tm_min=50, tm_sec=16, tm_wday=2, tm_yday=241, tm_isdst=0), 'title': ""Limiting the Spread of Fake News on Social Media Platforms by Evaluating\n  Users' Trustworthiness"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Limiting the Spread of Fake News on Social Media Platforms by Evaluating\n  Users' Trustworthiness""}, 'summary': 'Today\'s social media platforms enable to spread both authentic and fake news\nvery quickly. Some approaches have been proposed to automatically detect such\n""fake"" news based on their content, but it is difficult to agree on universal\ncriteria of authenticity (which can be bypassed by adversaries once known).\nBesides, it is obviously impossible to have each news item checked by a human.\n  In this paper, we a mechanism to limit the spread of fake news which is not\nbased on content. It can be implemented as a plugin on a social media platform.\nThe principle is as follows: a team of fact-checkers reviews a small number of\nnews items (the most popular ones), which enables to have an estimation of each\nuser\'s inclination to share fake news items. Then, using a Bayesian approach,\nwe estimate the trustworthiness of future news items, and treat accordingly\nthose of them that pass a certain ""untrustworthiness"" threshold.\n  We then evaluate the effectiveness and overhead of this technique on a large\nTwitter graph. We show that having a few thousands users exposed to one given\nnews item enables to reach a very precise estimation of its reliability. We\nthus identify more than 99% of fake news items with no false positives. The\nperformance impact is very small: the induced overhead on the 90th percentile\nlatency is less than 3%, and less than 8% on the throughput of user operations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Today\'s social media platforms enable to spread both authentic and fake news\nvery quickly. Some approaches have been proposed to automatically detect such\n""fake"" news based on their content, but it is difficult to agree on universal\ncriteria of authenticity (which can be bypassed by adversaries once known).\nBesides, it is obviously impossible to have each news item checked by a human.\n  In this paper, we a mechanism to limit the spread of fake news which is not\nbased on content. It can be implemented as a plugin on a social media platform.\nThe principle is as follows: a team of fact-checkers reviews a small number of\nnews items (the most popular ones), which enables to have an estimation of each\nuser\'s inclination to share fake news items. Then, using a Bayesian approach,\nwe estimate the trustworthiness of future news items, and treat accordingly\nthose of them that pass a certain ""untrustworthiness"" threshold.\n  We then evaluate the effectiveness and overhead of this technique on a large\nTwitter graph. We show that having a few thousands users exposed to one given\nnews item enables to reach a very precise estimation of its reliability. We\nthus identify more than 99% of fake news items with no false positives. The\nperformance impact is very small: the induced overhead on the 90th percentile\nlatency is less than 3%, and less than 8% on the throughput of user operations.'}, 'authors': [{'name': 'Oana Balmau'}, {'name': 'Rachid Guerraoui'}, {'name': 'Anne-Marie Kermarrec'}, {'name': 'Alexandre Maurer'}, {'name': 'Matej Pavlovic'}, {'name': 'Willy Zwaenepoel'}], 'author_detail': {'name': 'Willy Zwaenepoel'}, 'author': 'Willy Zwaenepoel', 'arxiv_comment': '10 pages, 9 figures', 'links': [{'href': 'http://arxiv.org/abs/1808.09922v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.09922v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
372,http://arxiv.org/abs/1808.09386v2,2018-10-29 16:40:45+00:00,2018-08-28 16:20:20+00:00,Framing and Agenda-setting in Russian News: a Computational Analysis of Intricate Political Strategies,"[arxiv.Result.Author('Anjalie Field'), arxiv.Result.Author('Doron Kliger'), arxiv.Result.Author('Shuly Wintner'), arxiv.Result.Author('Jennifer Pan'), arxiv.Result.Author('Dan Jurafsky'), arxiv.Result.Author('Yulia Tsvetkov')]","Amidst growing concern over media manipulation, NLP attention has focused on
overt strategies like censorship and ""fake news'"". Here, we draw on two
concepts from the political science literature to explore subtler strategies
for government media manipulation: agenda-setting (selecting what topics to
cover) and framing (deciding how topics are covered). We analyze 13 years (100K
articles) of the Russian newspaper Izvestia and identify a strategy of
distraction: articles mention the U.S. more frequently in the month directly
following an economic downturn in Russia. We introduce embedding-based methods
for cross-lingually projecting English frames to Russian, and discover that
these articles emphasize U.S. moral failings and threats to the U.S. Our work
offers new ways to identify subtle media manipulation strategies at the
intersection of agenda-setting and framing.",Accepted as a full paper at EMNLP 2018,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1808.09386v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.09386v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.09386v2,"{'id': 'http://arxiv.org/abs/1808.09386v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.09386v2', 'updated': '2018-10-29T16:40:45Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=29, tm_hour=16, tm_min=40, tm_sec=45, tm_wday=0, tm_yday=302, tm_isdst=0), 'published': '2018-08-28T16:20:20Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=20, tm_sec=20, tm_wday=1, tm_yday=240, tm_isdst=0), 'title': 'Framing and Agenda-setting in Russian News: a Computational Analysis of\n  Intricate Political Strategies', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Framing and Agenda-setting in Russian News: a Computational Analysis of\n  Intricate Political Strategies'}, 'summary': 'Amidst growing concern over media manipulation, NLP attention has focused on\novert strategies like censorship and ""fake news\'"". Here, we draw on two\nconcepts from the political science literature to explore subtler strategies\nfor government media manipulation: agenda-setting (selecting what topics to\ncover) and framing (deciding how topics are covered). We analyze 13 years (100K\narticles) of the Russian newspaper Izvestia and identify a strategy of\ndistraction: articles mention the U.S. more frequently in the month directly\nfollowing an economic downturn in Russia. We introduce embedding-based methods\nfor cross-lingually projecting English frames to Russian, and discover that\nthese articles emphasize U.S. moral failings and threats to the U.S. Our work\noffers new ways to identify subtle media manipulation strategies at the\nintersection of agenda-setting and framing.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Amidst growing concern over media manipulation, NLP attention has focused on\novert strategies like censorship and ""fake news\'"". Here, we draw on two\nconcepts from the political science literature to explore subtler strategies\nfor government media manipulation: agenda-setting (selecting what topics to\ncover) and framing (deciding how topics are covered). We analyze 13 years (100K\narticles) of the Russian newspaper Izvestia and identify a strategy of\ndistraction: articles mention the U.S. more frequently in the month directly\nfollowing an economic downturn in Russia. We introduce embedding-based methods\nfor cross-lingually projecting English frames to Russian, and discover that\nthese articles emphasize U.S. moral failings and threats to the U.S. Our work\noffers new ways to identify subtle media manipulation strategies at the\nintersection of agenda-setting and framing.'}, 'authors': [{'name': 'Anjalie Field'}, {'name': 'Doron Kliger'}, {'name': 'Shuly Wintner'}, {'name': 'Jennifer Pan'}, {'name': 'Dan Jurafsky'}, {'name': 'Yulia Tsvetkov'}], 'author_detail': {'name': 'Yulia Tsvetkov'}, 'author': 'Yulia Tsvetkov', 'arxiv_comment': 'Accepted as a full paper at EMNLP 2018', 'links': [{'href': 'http://arxiv.org/abs/1808.09386v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.09386v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
373,http://arxiv.org/abs/1808.08426v1,2018-08-25 13:40:36+00:00,2018-08-25 13:40:36+00:00,Analysis of adversarial attacks against CNN-based image forgery detectors,"[arxiv.Result.Author('Diego Gragnaniello'), arxiv.Result.Author('Francesco Marra'), arxiv.Result.Author('Giovanni Poggi'), arxiv.Result.Author('Luisa Verdoliva')]","With the ubiquitous diffusion of social networks, images are becoming a
dominant and powerful communication channel. Not surprisingly, they are also
increasingly subject to manipulations aimed at distorting information and
spreading fake news. In recent years, the scientific community has devoted
major efforts to contrast this menace, and many image forgery detectors have
been proposed. Currently, due to the success of deep learning in many
multimedia processing tasks, there is high interest towards CNN-based
detectors, and early results are already very promising. Recent studies in
computer vision, however, have shown CNNs to be highly vulnerable to
adversarial attacks, small perturbations of the input data which drive the
network towards erroneous classification. In this paper we analyze the
vulnerability of CNN-based image forensics methods to adversarial attacks,
considering several detectors and several types of attack, and testing
performance on a wide range of common manipulations, both easily and hardly
detectable.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1808.08426v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.08426v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.08426v1,"{'id': 'http://arxiv.org/abs/1808.08426v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.08426v1', 'updated': '2018-08-25T13:40:36Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=25, tm_hour=13, tm_min=40, tm_sec=36, tm_wday=5, tm_yday=237, tm_isdst=0), 'published': '2018-08-25T13:40:36Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=25, tm_hour=13, tm_min=40, tm_sec=36, tm_wday=5, tm_yday=237, tm_isdst=0), 'title': 'Analysis of adversarial attacks against CNN-based image forgery\n  detectors', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysis of adversarial attacks against CNN-based image forgery\n  detectors'}, 'summary': 'With the ubiquitous diffusion of social networks, images are becoming a\ndominant and powerful communication channel. Not surprisingly, they are also\nincreasingly subject to manipulations aimed at distorting information and\nspreading fake news. In recent years, the scientific community has devoted\nmajor efforts to contrast this menace, and many image forgery detectors have\nbeen proposed. Currently, due to the success of deep learning in many\nmultimedia processing tasks, there is high interest towards CNN-based\ndetectors, and early results are already very promising. Recent studies in\ncomputer vision, however, have shown CNNs to be highly vulnerable to\nadversarial attacks, small perturbations of the input data which drive the\nnetwork towards erroneous classification. In this paper we analyze the\nvulnerability of CNN-based image forensics methods to adversarial attacks,\nconsidering several detectors and several types of attack, and testing\nperformance on a wide range of common manipulations, both easily and hardly\ndetectable.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the ubiquitous diffusion of social networks, images are becoming a\ndominant and powerful communication channel. Not surprisingly, they are also\nincreasingly subject to manipulations aimed at distorting information and\nspreading fake news. In recent years, the scientific community has devoted\nmajor efforts to contrast this menace, and many image forgery detectors have\nbeen proposed. Currently, due to the success of deep learning in many\nmultimedia processing tasks, there is high interest towards CNN-based\ndetectors, and early results are already very promising. Recent studies in\ncomputer vision, however, have shown CNNs to be highly vulnerable to\nadversarial attacks, small perturbations of the input data which drive the\nnetwork towards erroneous classification. In this paper we analyze the\nvulnerability of CNN-based image forensics methods to adversarial attacks,\nconsidering several detectors and several types of attack, and testing\nperformance on a wide range of common manipulations, both easily and hardly\ndetectable.'}, 'authors': [{'name': 'Diego Gragnaniello'}, {'name': 'Francesco Marra'}, {'name': 'Giovanni Poggi'}, {'name': 'Luisa Verdoliva'}], 'author_detail': {'name': 'Luisa Verdoliva'}, 'author': 'Luisa Verdoliva', 'links': [{'href': 'http://arxiv.org/abs/1808.08426v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.08426v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
374,http://arxiv.org/abs/1808.05359v1,2018-08-16 06:55:25+00:00,2018-08-16 06:55:25+00:00,Neural Networks Assist Crowd Predictions in Discerning the Veracity of Emotional Expressions,"[arxiv.Result.Author('Zhenyue Qin'), arxiv.Result.Author('Tom Gedeon'), arxiv.Result.Author('Sabrina Caldwell')]","Crowd predictions have demonstrated powerful performance in predicting future
events. We aim to understand crowd prediction efficacy in ascertaining the
veracity of human emotional expressions. We discover that collective
discernment can increase the accuracy of detecting emotion veracity from 63%,
which is the average individual performance, to 80%. Constraining data to best
performers can further increase the result up to 92%. Neural networks can
achieve an accuracy to 99.69% by aggregating participants' answers. That is,
assigning positive and negative weights to high and low human predictors,
respectively. Furthermore, neural networks that are trained with one emotion
data can also produce high accuracies on discerning the veracity of other
emotion types: our crowdsourced transfer of emotion learning is novel. We find
that our neural networks do not require a large number of participants,
particularly, 30 randomly selected, to achieve high accuracy predictions,
better than any individual participant. Our proposed method of assembling
peoples' predictions with neural networks can provide insights for applications
such as fake news prevention and lie detection.",,,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/1808.05359v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.05359v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.05359v1,"{'id': 'http://arxiv.org/abs/1808.05359v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.05359v1', 'updated': '2018-08-16T06:55:25Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=16, tm_hour=6, tm_min=55, tm_sec=25, tm_wday=3, tm_yday=228, tm_isdst=0), 'published': '2018-08-16T06:55:25Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=16, tm_hour=6, tm_min=55, tm_sec=25, tm_wday=3, tm_yday=228, tm_isdst=0), 'title': 'Neural Networks Assist Crowd Predictions in Discerning the Veracity of\n  Emotional Expressions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Neural Networks Assist Crowd Predictions in Discerning the Veracity of\n  Emotional Expressions'}, 'summary': ""Crowd predictions have demonstrated powerful performance in predicting future\nevents. We aim to understand crowd prediction efficacy in ascertaining the\nveracity of human emotional expressions. We discover that collective\ndiscernment can increase the accuracy of detecting emotion veracity from 63%,\nwhich is the average individual performance, to 80%. Constraining data to best\nperformers can further increase the result up to 92%. Neural networks can\nachieve an accuracy to 99.69% by aggregating participants' answers. That is,\nassigning positive and negative weights to high and low human predictors,\nrespectively. Furthermore, neural networks that are trained with one emotion\ndata can also produce high accuracies on discerning the veracity of other\nemotion types: our crowdsourced transfer of emotion learning is novel. We find\nthat our neural networks do not require a large number of participants,\nparticularly, 30 randomly selected, to achieve high accuracy predictions,\nbetter than any individual participant. Our proposed method of assembling\npeoples' predictions with neural networks can provide insights for applications\nsuch as fake news prevention and lie detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Crowd predictions have demonstrated powerful performance in predicting future\nevents. We aim to understand crowd prediction efficacy in ascertaining the\nveracity of human emotional expressions. We discover that collective\ndiscernment can increase the accuracy of detecting emotion veracity from 63%,\nwhich is the average individual performance, to 80%. Constraining data to best\nperformers can further increase the result up to 92%. Neural networks can\nachieve an accuracy to 99.69% by aggregating participants' answers. That is,\nassigning positive and negative weights to high and low human predictors,\nrespectively. Furthermore, neural networks that are trained with one emotion\ndata can also produce high accuracies on discerning the veracity of other\nemotion types: our crowdsourced transfer of emotion learning is novel. We find\nthat our neural networks do not require a large number of participants,\nparticularly, 30 randomly selected, to achieve high accuracy predictions,\nbetter than any individual participant. Our proposed method of assembling\npeoples' predictions with neural networks can provide insights for applications\nsuch as fake news prevention and lie detection.""}, 'authors': [{'name': 'Zhenyue Qin'}, {'name': 'Tom Gedeon'}, {'name': 'Sabrina Caldwell'}], 'author_detail': {'name': 'Sabrina Caldwell'}, 'author': 'Sabrina Caldwell', 'links': [{'href': 'http://arxiv.org/abs/1808.05359v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.05359v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
375,http://arxiv.org/abs/1808.02831v1,2018-08-08 15:45:06+00:00,2018-08-08 15:45:06+00:00,Debunking Fake News One Feature at a Time,"[arxiv.Result.Author('Melanie Tosik'), arxiv.Result.Author('Antonio Mallia'), arxiv.Result.Author('Kedar Gangopadhyay')]","Identifying the stance of a news article body with respect to a certain
headline is the first step to automated fake news detection. In this paper, we
introduce a 2-stage ensemble model to solve the stance detection task. By using
only hand-crafted features as input to a gradient boosting classifier, we are
able to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake
News Challenge (Stage 1) dataset. We identify the most useful features for
detecting fake news and discuss how sampling techniques can be used to improve
recall accuracy on a highly imbalanced dataset.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1808.02831v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.02831v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.02831v1,"{'id': 'http://arxiv.org/abs/1808.02831v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.02831v1', 'updated': '2018-08-08T15:45:06Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=8, tm_hour=15, tm_min=45, tm_sec=6, tm_wday=2, tm_yday=220, tm_isdst=0), 'published': '2018-08-08T15:45:06Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=8, tm_hour=15, tm_min=45, tm_sec=6, tm_wday=2, tm_yday=220, tm_isdst=0), 'title': 'Debunking Fake News One Feature at a Time', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Debunking Fake News One Feature at a Time'}, 'summary': 'Identifying the stance of a news article body with respect to a certain\nheadline is the first step to automated fake news detection. In this paper, we\nintroduce a 2-stage ensemble model to solve the stance detection task. By using\nonly hand-crafted features as input to a gradient boosting classifier, we are\nable to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake\nNews Challenge (Stage 1) dataset. We identify the most useful features for\ndetecting fake news and discuss how sampling techniques can be used to improve\nrecall accuracy on a highly imbalanced dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying the stance of a news article body with respect to a certain\nheadline is the first step to automated fake news detection. In this paper, we\nintroduce a 2-stage ensemble model to solve the stance detection task. By using\nonly hand-crafted features as input to a gradient boosting classifier, we are\nable to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake\nNews Challenge (Stage 1) dataset. We identify the most useful features for\ndetecting fake news and discuss how sampling techniques can be used to improve\nrecall accuracy on a highly imbalanced dataset.'}, 'authors': [{'name': 'Melanie Tosik'}, {'name': 'Antonio Mallia'}, {'name': 'Kedar Gangopadhyay'}], 'author_detail': {'name': 'Kedar Gangopadhyay'}, 'author': 'Kedar Gangopadhyay', 'links': [{'href': 'http://arxiv.org/abs/1808.02831v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.02831v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
376,http://arxiv.org/abs/1807.06926v1,2018-07-18 13:41:57+00:00,2018-07-18 13:41:57+00:00,"Fake news as we feel it: perception and conceptualization of the term ""fake news"" in the media","[arxiv.Result.Author('Evandro Cunha'), arxiv.Result.Author('Gabriel Magno'), arxiv.Result.Author('Josemar Caetano'), arxiv.Result.Author('Douglas Teixeira'), arxiv.Result.Author('Virgilio Almeida')]","In this article, we quantitatively analyze how the term ""fake news"" is being
shaped in news media in recent years. We study the perception and the
conceptualization of this term in the traditional media using eight years of
data collected from news outlets based in 20 countries. Our results not only
corroborate previous indications of a high increase in the usage of the
expression ""fake news"", but also show contextual changes around this expression
after the United States presidential election of 2016. Among other results, we
found changes in the related vocabulary, in the mentioned entities, in the
surrounding topics and in the contextual polarity around the term ""fake news"",
suggesting that this expression underwent a change in perception and
conceptualization after 2016. These outcomes expand the understandings on the
usage of the term ""fake news"", helping to comprehend and more accurately
characterize this relevant social phenomenon linked to misinformation and
manipulation.","Accepted as a full paper at the 10th International Conference on
  Social Informatics (SocInfo 2018). Please cite the SocInfo version",,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1807.06926v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.06926v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.06926v1,"{'id': 'http://arxiv.org/abs/1807.06926v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.06926v1', 'updated': '2018-07-18T13:41:57Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=41, tm_sec=57, tm_wday=2, tm_yday=199, tm_isdst=0), 'published': '2018-07-18T13:41:57Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=41, tm_sec=57, tm_wday=2, tm_yday=199, tm_isdst=0), 'title': 'Fake news as we feel it: perception and conceptualization of the term\n  ""fake news"" in the media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news as we feel it: perception and conceptualization of the term\n  ""fake news"" in the media'}, 'summary': 'In this article, we quantitatively analyze how the term ""fake news"" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression ""fake news"", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term ""fake news"",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term ""fake news"", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this article, we quantitatively analyze how the term ""fake news"" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression ""fake news"", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term ""fake news"",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term ""fake news"", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.'}, 'authors': [{'name': 'Evandro Cunha'}, {'name': 'Gabriel Magno'}, {'name': 'Josemar Caetano'}, {'name': 'Douglas Teixeira'}, {'name': 'Virgilio Almeida'}], 'author_detail': {'name': 'Virgilio Almeida'}, 'author': 'Virgilio Almeida', 'arxiv_comment': 'Accepted as a full paper at the 10th International Conference on\n  Social Informatics (SocInfo 2018). Please cite the SocInfo version', 'links': [{'href': 'http://arxiv.org/abs/1807.06926v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.06926v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
377,http://arxiv.org/abs/1807.06147v1,2018-07-16 23:08:44+00:00,2018-07-16 23:08:44+00:00,Tracking Elections: our experience during the presidential elections in Ecuador,"[arxiv.Result.Author('Daniel Riofrio'), arxiv.Result.Author('Anacaren Ruiz'), arxiv.Result.Author('Erin Sosebee'), arxiv.Result.Author('Qasim Raza'), arxiv.Result.Author('Adnan Bashir'), arxiv.Result.Author('Jed Crandall')]","The world's digital transformation has influenced not only the way we do
business, but also the way we perform daily activities. In fact, the past
Presidential elections in the United States as well as those in Great Britain
(Brexit) and in Colombia (peace agreement referendum) are proof that social
media play an important part in modern politics. In fact, this digital
political field is filled by political movements and political candidates
looking for popular support (number of followers), regular citizens' messages
discussing social issues (trending topics flooding social media), or even
political propaganda in favor or against politicians or political movements
(advertisement). One of the issues with social media in this era is the
presence of automatic accounts (bots) that artificially fill accounts with fake
followers, create false trending topics, and share fake news or simply flood
the net with propaganda. All this artificial information may influence people
and sometimes may even censor people's real opinions undermining their freedom
of speech. In this paper, we propose a methodology to track elections and a set
of tools used to collect and analyze election data. In particular, this paper
discusses our experiences during the Presidential Elections in Ecuador held in
2017. In fact, we show how all candidates prepared an online campaign in social
media (Twitter) and how the political campaign altered a common follower rate
subscription. We discuss that the high presence of followers during the period
between the first and second round of elections may be altered by automatic
accounts. Finally, we use bot detection systems and gathered more than 30,000
political motivated bots. In our data analysis, we show that these bots were
mainly used for propaganda purposes in favor or against a particular candidate.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1807.06147v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.06147v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.06147v1,"{'id': 'http://arxiv.org/abs/1807.06147v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.06147v1', 'updated': '2018-07-16T23:08:44Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=16, tm_hour=23, tm_min=8, tm_sec=44, tm_wday=0, tm_yday=197, tm_isdst=0), 'published': '2018-07-16T23:08:44Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=16, tm_hour=23, tm_min=8, tm_sec=44, tm_wday=0, tm_yday=197, tm_isdst=0), 'title': 'Tracking Elections: our experience during the presidential elections in\n  Ecuador', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tracking Elections: our experience during the presidential elections in\n  Ecuador'}, 'summary': ""The world's digital transformation has influenced not only the way we do\nbusiness, but also the way we perform daily activities. In fact, the past\nPresidential elections in the United States as well as those in Great Britain\n(Brexit) and in Colombia (peace agreement referendum) are proof that social\nmedia play an important part in modern politics. In fact, this digital\npolitical field is filled by political movements and political candidates\nlooking for popular support (number of followers), regular citizens' messages\ndiscussing social issues (trending topics flooding social media), or even\npolitical propaganda in favor or against politicians or political movements\n(advertisement). One of the issues with social media in this era is the\npresence of automatic accounts (bots) that artificially fill accounts with fake\nfollowers, create false trending topics, and share fake news or simply flood\nthe net with propaganda. All this artificial information may influence people\nand sometimes may even censor people's real opinions undermining their freedom\nof speech. In this paper, we propose a methodology to track elections and a set\nof tools used to collect and analyze election data. In particular, this paper\ndiscusses our experiences during the Presidential Elections in Ecuador held in\n2017. In fact, we show how all candidates prepared an online campaign in social\nmedia (Twitter) and how the political campaign altered a common follower rate\nsubscription. We discuss that the high presence of followers during the period\nbetween the first and second round of elections may be altered by automatic\naccounts. Finally, we use bot detection systems and gathered more than 30,000\npolitical motivated bots. In our data analysis, we show that these bots were\nmainly used for propaganda purposes in favor or against a particular candidate."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The world's digital transformation has influenced not only the way we do\nbusiness, but also the way we perform daily activities. In fact, the past\nPresidential elections in the United States as well as those in Great Britain\n(Brexit) and in Colombia (peace agreement referendum) are proof that social\nmedia play an important part in modern politics. In fact, this digital\npolitical field is filled by political movements and political candidates\nlooking for popular support (number of followers), regular citizens' messages\ndiscussing social issues (trending topics flooding social media), or even\npolitical propaganda in favor or against politicians or political movements\n(advertisement). One of the issues with social media in this era is the\npresence of automatic accounts (bots) that artificially fill accounts with fake\nfollowers, create false trending topics, and share fake news or simply flood\nthe net with propaganda. All this artificial information may influence people\nand sometimes may even censor people's real opinions undermining their freedom\nof speech. In this paper, we propose a methodology to track elections and a set\nof tools used to collect and analyze election data. In particular, this paper\ndiscusses our experiences during the Presidential Elections in Ecuador held in\n2017. In fact, we show how all candidates prepared an online campaign in social\nmedia (Twitter) and how the political campaign altered a common follower rate\nsubscription. We discuss that the high presence of followers during the period\nbetween the first and second round of elections may be altered by automatic\naccounts. Finally, we use bot detection systems and gathered more than 30,000\npolitical motivated bots. In our data analysis, we show that these bots were\nmainly used for propaganda purposes in favor or against a particular candidate.""}, 'authors': [{'name': 'Daniel Riofrio'}, {'name': 'Anacaren Ruiz'}, {'name': 'Erin Sosebee'}, {'name': 'Qasim Raza'}, {'name': 'Adnan Bashir'}, {'name': 'Jed Crandall'}], 'author_detail': {'name': 'Jed Crandall'}, 'author': 'Jed Crandall', 'links': [{'href': 'http://arxiv.org/abs/1807.06147v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.06147v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
378,http://arxiv.org/abs/1806.11316v1,2018-06-29 09:36:46+00:00,2018-06-29 09:36:46+00:00,Fake News Identification on Twitter with Hybrid CNN and RNN Models,"[arxiv.Result.Author('Oluwaseun Ajao'), arxiv.Result.Author('Deepayan Bhowmik'), arxiv.Result.Author('Shahrzad Zargari')]","The problem associated with the propagation of fake news continues to grow at
an alarming scale. This trend has generated much interest from politics to
academia and industry alike. We propose a framework that detects and classifies
fake news messages from Twitter posts using hybrid of convolutional neural
networks and long-short term recurrent neural network models. The proposed work
using this deep learning approach achieves 82% accuracy. Our approach
intuitively identifies relevant features associated with fake news stories
without previous knowledge of the domain.",5 Pages,"Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad Zargari. 2018. Fake
  News Identification on Twitter with Hybrid CNN and RNN Models. In Proceedings
  of the International Conference on Social Media & Society, Copenhagen,
  Denmark (SMSociety)",10.1145/3217804.3217917,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3217804.3217917', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1806.11316v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.11316v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.11316v1,"{'id': 'http://arxiv.org/abs/1806.11316v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.11316v1', 'updated': '2018-06-29T09:36:46Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=29, tm_hour=9, tm_min=36, tm_sec=46, tm_wday=4, tm_yday=180, tm_isdst=0), 'published': '2018-06-29T09:36:46Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=29, tm_hour=9, tm_min=36, tm_sec=46, tm_wday=4, tm_yday=180, tm_isdst=0), 'title': 'Fake News Identification on Twitter with Hybrid CNN and RNN Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Identification on Twitter with Hybrid CNN and RNN Models'}, 'summary': 'The problem associated with the propagation of fake news continues to grow at\nan alarming scale. This trend has generated much interest from politics to\nacademia and industry alike. We propose a framework that detects and classifies\nfake news messages from Twitter posts using hybrid of convolutional neural\nnetworks and long-short term recurrent neural network models. The proposed work\nusing this deep learning approach achieves 82% accuracy. Our approach\nintuitively identifies relevant features associated with fake news stories\nwithout previous knowledge of the domain.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The problem associated with the propagation of fake news continues to grow at\nan alarming scale. This trend has generated much interest from politics to\nacademia and industry alike. We propose a framework that detects and classifies\nfake news messages from Twitter posts using hybrid of convolutional neural\nnetworks and long-short term recurrent neural network models. The proposed work\nusing this deep learning approach achieves 82% accuracy. Our approach\nintuitively identifies relevant features associated with fake news stories\nwithout previous knowledge of the domain.'}, 'authors': [{'name': 'Oluwaseun Ajao'}, {'name': 'Deepayan Bhowmik'}, {'name': 'Shahrzad Zargari'}], 'author_detail': {'name': 'Shahrzad Zargari'}, 'author': 'Shahrzad Zargari', 'arxiv_doi': '10.1145/3217804.3217917', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3217804.3217917', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1806.11316v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.11316v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '5 Pages', 'arxiv_journal_ref': 'Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad Zargari. 2018. Fake\n  News Identification on Twitter with Hybrid CNN and RNN Models. In Proceedings\n  of the International Conference on Social Media & Society, Copenhagen,\n  Denmark (SMSociety)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
379,http://arxiv.org/abs/1806.07516v2,2019-10-09 22:04:46+00:00,2018-06-20 01:26:21+00:00,The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake News,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","A large body of research work and efforts have been focused on detecting fake
news and building online fact-check systems in order to debunk fake news as
soon as possible. Despite the existence of these systems, fake news is still
wildly shared by online users. It indicates that these systems may not be fully
utilized. After detecting fake news, what is the next step to stop people from
sharing it? How can we improve the utilization of these fact-check systems? To
fill this gap, in this paper, we (i) collect and analyze online users called
guardians, who correct misinformation and fake news in online discussions by
referring fact-checking URLs; and (ii) propose a novel fact-checking URL
recommendation model to encourage the guardians to engage more in fact-checking
activities. We found that the guardians usually took less than one day to reply
to claims in online conversations and took another day to spread verified
information to hundreds of millions of followers. Our proposed recommendation
model outperformed four state-of-the-art models by 11%~33%. Our source code and
dataset are available at https://github.com/nguyenvo09/CombatingFakeNews.",SIGIR 2018,,,cs.IR,"['cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1806.07516v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.07516v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.07516v2,"{'id': 'http://arxiv.org/abs/1806.07516v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.07516v2', 'updated': '2019-10-09T22:04:46Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=9, tm_hour=22, tm_min=4, tm_sec=46, tm_wday=2, tm_yday=282, tm_isdst=0), 'published': '2018-06-20T01:26:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=20, tm_hour=1, tm_min=26, tm_sec=21, tm_wday=2, tm_yday=171, tm_isdst=0), 'title': 'The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News'}, 'summary': 'A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.'}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'SIGIR 2018', 'links': [{'href': 'http://arxiv.org/abs/1806.07516v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.07516v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
380,http://arxiv.org/abs/1806.05180v1,2018-06-13 15:38:09+00:00,2018-06-13 15:38:09+00:00,A Retrospective Analysis of the Fake News Challenge Stance Detection Task,"[arxiv.Result.Author('Andreas Hanselowski'), arxiv.Result.Author('Avinesh PVS'), arxiv.Result.Author('Benjamin Schiller'), arxiv.Result.Author('Felix Caspelherr'), arxiv.Result.Author('Debanjan Chaudhuri'), arxiv.Result.Author('Christian M. Meyer'), arxiv.Result.Author('Iryna Gurevych')]","The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance
classification task as a crucial first step towards detecting fake news. To
date, there is no in-depth analysis paper to critically discuss FNC-1's
experimental setup, reproduce the results, and draw conclusions for
next-generation stance classification methods. In this paper, we provide such
an in-depth analysis for the three top-performing systems. We first find that
FNC-1's proposed evaluation metric favors the majority class, which can be
easily classified, and thus overestimates the true discriminative power of the
methods. Therefore, we propose a new F1-based metric yielding a changed system
ranking. Next, we compare the features and architectures used, which leads to a
novel feature-rich stacked LSTM model that performs on par with the best
systems, but is superior in predicting minority classes. To understand the
methods' ability to generalize, we derive a new dataset and perform both
in-domain and cross-domain experiments. Our qualitative and quantitative study
helps interpreting the original FNC-1 scores and understand which features help
improving performance and why. Our new dataset and all source code used during
the reproduction study are publicly available for future research.",,,,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1806.05180v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.05180v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.05180v1,"{'id': 'http://arxiv.org/abs/1806.05180v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.05180v1', 'updated': '2018-06-13T15:38:09Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=13, tm_hour=15, tm_min=38, tm_sec=9, tm_wday=2, tm_yday=164, tm_isdst=0), 'published': '2018-06-13T15:38:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=13, tm_hour=15, tm_min=38, tm_sec=9, tm_wday=2, tm_yday=164, tm_isdst=0), 'title': 'A Retrospective Analysis of the Fake News Challenge Stance Detection\n  Task', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Retrospective Analysis of the Fake News Challenge Stance Detection\n  Task'}, 'summary': ""The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance\nclassification task as a crucial first step towards detecting fake news. To\ndate, there is no in-depth analysis paper to critically discuss FNC-1's\nexperimental setup, reproduce the results, and draw conclusions for\nnext-generation stance classification methods. In this paper, we provide such\nan in-depth analysis for the three top-performing systems. We first find that\nFNC-1's proposed evaluation metric favors the majority class, which can be\neasily classified, and thus overestimates the true discriminative power of the\nmethods. Therefore, we propose a new F1-based metric yielding a changed system\nranking. Next, we compare the features and architectures used, which leads to a\nnovel feature-rich stacked LSTM model that performs on par with the best\nsystems, but is superior in predicting minority classes. To understand the\nmethods' ability to generalize, we derive a new dataset and perform both\nin-domain and cross-domain experiments. Our qualitative and quantitative study\nhelps interpreting the original FNC-1 scores and understand which features help\nimproving performance and why. Our new dataset and all source code used during\nthe reproduction study are publicly available for future research."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance\nclassification task as a crucial first step towards detecting fake news. To\ndate, there is no in-depth analysis paper to critically discuss FNC-1's\nexperimental setup, reproduce the results, and draw conclusions for\nnext-generation stance classification methods. In this paper, we provide such\nan in-depth analysis for the three top-performing systems. We first find that\nFNC-1's proposed evaluation metric favors the majority class, which can be\neasily classified, and thus overestimates the true discriminative power of the\nmethods. Therefore, we propose a new F1-based metric yielding a changed system\nranking. Next, we compare the features and architectures used, which leads to a\nnovel feature-rich stacked LSTM model that performs on par with the best\nsystems, but is superior in predicting minority classes. To understand the\nmethods' ability to generalize, we derive a new dataset and perform both\nin-domain and cross-domain experiments. Our qualitative and quantitative study\nhelps interpreting the original FNC-1 scores and understand which features help\nimproving performance and why. Our new dataset and all source code used during\nthe reproduction study are publicly available for future research.""}, 'authors': [{'name': 'Andreas Hanselowski'}, {'name': 'Avinesh PVS'}, {'name': 'Benjamin Schiller'}, {'name': 'Felix Caspelherr'}, {'name': 'Debanjan Chaudhuri'}, {'name': 'Christian M. Meyer'}, {'name': 'Iryna Gurevych'}], 'author_detail': {'name': 'Iryna Gurevych'}, 'author': 'Iryna Gurevych', 'links': [{'href': 'http://arxiv.org/abs/1806.05180v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.05180v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
381,http://arxiv.org/abs/1806.09541v1,2018-06-06 10:47:20+00:00,2018-06-06 10:47:20+00:00,"Technology, Propaganda, and the Limits of Human Intellect",[arxiv.Result.Author('Panagiotis Metaxas')],"""Fake news"" is a recent phenomenon, but misinformation and propaganda are
not. Our new communication technologies make it easy for us to be exposed to
high volumes of true, false, irrelevant, and unprovable information. Future AI
is expected to amplify the problem even more. At the same time, our brains are
reaching their limits in handling information. How should we respond to
propaganda? Technology can help, but relying on it alone will not suffice in
the long term. We also need ethical policies, laws, regulations, and trusted
authorities, including fact-checkers. However, we will not solve the problem
without the active engagement of the educated citizen. Epistemological
education, recognition of self biases and protection of our channels of
communication and trusted networks are all needed to overcome the problem and
continue our progress as democratic societies.",12 pages,,,cs.GL,"['cs.GL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1806.09541v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.09541v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.09541v1,"{'id': 'http://arxiv.org/abs/1806.09541v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.09541v1', 'updated': '2018-06-06T10:47:20Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=6, tm_hour=10, tm_min=47, tm_sec=20, tm_wday=2, tm_yday=157, tm_isdst=0), 'published': '2018-06-06T10:47:20Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=6, tm_hour=10, tm_min=47, tm_sec=20, tm_wday=2, tm_yday=157, tm_isdst=0), 'title': 'Technology, Propaganda, and the Limits of Human Intellect', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Technology, Propaganda, and the Limits of Human Intellect'}, 'summary': '""Fake news"" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Fake news"" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.'}, 'authors': [{'name': 'Panagiotis Metaxas'}], 'author_detail': {'name': 'Panagiotis Metaxas'}, 'author': 'Panagiotis Metaxas', 'arxiv_comment': '12 pages', 'links': [{'href': 'http://arxiv.org/abs/1806.09541v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.09541v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
382,http://arxiv.org/abs/1806.00749v1,2018-06-03 08:09:58+00:00,2018-06-03 08:09:58+00:00,TI-CNN: Convolutional Neural Networks for Fake News Detection,"[arxiv.Result.Author('Yang Yang'), arxiv.Result.Author('Lei Zheng'), arxiv.Result.Author('Jiawei Zhang'), arxiv.Result.Author('Qingcai Cui'), arxiv.Result.Author('Zhoujun Li'), arxiv.Result.Author('Philip S. Yu')]","With the development of social networks, fake news for various commercial and
political purposes has been appearing in large numbers and gotten widespread in
the online world. With deceptive words, people can get infected by the fake
news very easily and will share them without any fact-checking. For instance,
during the 2016 US president election, various kinds of fake news about the
candidates widely spread through both official news media and the online social
networks. These fake news is usually released to either smear the opponents or
support the candidate on their side. The erroneous information in the fake news
is usually written to motivate the voters' irrational emotion and enthusiasm.
Such kinds of fake news sometimes can bring about devastating effects, and an
important goal in improving the credibility of online social networks is to
identify the fake news timely. In this paper, we propose to study the fake news
detection problem. Automatic fake news identification is extremely hard, since
pure model based fact-checking for news is still an open problem, and few
existing models can be applied to solve the problem. With a thorough
investigation of a fake news data, lots of useful explicit features are
identified from both the text words and images used in the fake news. Besides
the explicit features, there also exist some hidden patterns in the words and
images used in fake news, which can be captured with a set of latent features
extracted via the multiple convolutional layers in our model. A model named as
TI-CNN (Text and Image information based Convolutinal Neural Network) is
proposed in this paper. By projecting the explicit and latent features into a
unified feature space, TI-CNN is trained with both the text and image
information simultaneously. Extensive experiments carried on the real-world
fake news datasets have demonstrate the effectiveness of TI-CNN.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1806.00749v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.00749v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.00749v1,"{'id': 'http://arxiv.org/abs/1806.00749v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.00749v1', 'updated': '2018-06-03T08:09:58Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=3, tm_hour=8, tm_min=9, tm_sec=58, tm_wday=6, tm_yday=154, tm_isdst=0), 'published': '2018-06-03T08:09:58Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=3, tm_hour=8, tm_min=9, tm_sec=58, tm_wday=6, tm_yday=154, tm_isdst=0), 'title': 'TI-CNN: Convolutional Neural Networks for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TI-CNN: Convolutional Neural Networks for Fake News Detection'}, 'summary': ""With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.""}, 'authors': [{'name': 'Yang Yang'}, {'name': 'Lei Zheng'}, {'name': 'Jiawei Zhang'}, {'name': 'Qingcai Cui'}, {'name': 'Zhoujun Li'}, {'name': 'Philip S. Yu'}], 'author_detail': {'name': 'Philip S. Yu'}, 'author': 'Philip S. Yu', 'links': [{'href': 'http://arxiv.org/abs/1806.00749v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.00749v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
383,http://arxiv.org/abs/1805.08751v2,2019-08-10 11:40:16+00:00,2018-05-22 17:23:32+00:00,FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural Network,"[arxiv.Result.Author('Jiawei Zhang'), arxiv.Result.Author('Bowen Dong'), arxiv.Result.Author('Philip S. Yu')]","In recent years, due to the booming development of online social networks,
fake news for various commercial and political purposes has been appearing in
large numbers and widespread in the online world. With deceptive words, online
social network users can get infected by these online fake news easily, which
has brought about tremendous effects on the offline society already. An
important goal in improving the trustworthiness of information in online social
networks is to identify the fake news timely. This paper aims at investigating
the principles, methodologies and algorithms for detecting fake news articles,
creators and subjects from online social networks and evaluating the
corresponding performance. This paper addresses the challenges introduced by
the unknown characteristics of fake news and diverse connections among news
articles, creators and subjects. This paper introduces a novel automatic fake
news credibility inference model, namely FAKEDETECTOR. Based on a set of
explicit and latent features extracted from the textual information,
FAKEDETECTOR builds a deep diffusive network model to learn the representations
of news articles, creators and subjects simultaneously. Extensive experiments
have been done on a real-world fake news dataset to compare FAKEDETECTOR with
several state-of-the-art models, and the experimental results have demonstrated
the effectiveness of the proposed model.",12 pages,,,cs.SI,"['cs.SI', 'cs.AI', 'cs.NE', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1805.08751v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1805.08751v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1805.08751v2,"{'id': 'http://arxiv.org/abs/1805.08751v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.08751v2', 'updated': '2019-08-10T11:40:16Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=10, tm_hour=11, tm_min=40, tm_sec=16, tm_wday=5, tm_yday=222, tm_isdst=0), 'published': '2018-05-22T17:23:32Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=22, tm_hour=17, tm_min=23, tm_sec=32, tm_wday=1, tm_yday=142, tm_isdst=0), 'title': 'FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural\n  Network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural\n  Network'}, 'summary': 'In recent years, due to the booming development of online social networks,\nfake news for various commercial and political purposes has been appearing in\nlarge numbers and widespread in the online world. With deceptive words, online\nsocial network users can get infected by these online fake news easily, which\nhas brought about tremendous effects on the offline society already. An\nimportant goal in improving the trustworthiness of information in online social\nnetworks is to identify the fake news timely. This paper aims at investigating\nthe principles, methodologies and algorithms for detecting fake news articles,\ncreators and subjects from online social networks and evaluating the\ncorresponding performance. This paper addresses the challenges introduced by\nthe unknown characteristics of fake news and diverse connections among news\narticles, creators and subjects. This paper introduces a novel automatic fake\nnews credibility inference model, namely FAKEDETECTOR. Based on a set of\nexplicit and latent features extracted from the textual information,\nFAKEDETECTOR builds a deep diffusive network model to learn the representations\nof news articles, creators and subjects simultaneously. Extensive experiments\nhave been done on a real-world fake news dataset to compare FAKEDETECTOR with\nseveral state-of-the-art models, and the experimental results have demonstrated\nthe effectiveness of the proposed model.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, due to the booming development of online social networks,\nfake news for various commercial and political purposes has been appearing in\nlarge numbers and widespread in the online world. With deceptive words, online\nsocial network users can get infected by these online fake news easily, which\nhas brought about tremendous effects on the offline society already. An\nimportant goal in improving the trustworthiness of information in online social\nnetworks is to identify the fake news timely. This paper aims at investigating\nthe principles, methodologies and algorithms for detecting fake news articles,\ncreators and subjects from online social networks and evaluating the\ncorresponding performance. This paper addresses the challenges introduced by\nthe unknown characteristics of fake news and diverse connections among news\narticles, creators and subjects. This paper introduces a novel automatic fake\nnews credibility inference model, namely FAKEDETECTOR. Based on a set of\nexplicit and latent features extracted from the textual information,\nFAKEDETECTOR builds a deep diffusive network model to learn the representations\nof news articles, creators and subjects simultaneously. Extensive experiments\nhave been done on a real-world fake news dataset to compare FAKEDETECTOR with\nseveral state-of-the-art models, and the experimental results have demonstrated\nthe effectiveness of the proposed model.'}, 'authors': [{'name': 'Jiawei Zhang'}, {'name': 'Bowen Dong'}, {'name': 'Philip S. Yu'}], 'author_detail': {'name': 'Philip S. Yu'}, 'author': 'Philip S. Yu', 'arxiv_comment': '12 pages', 'links': [{'href': 'http://arxiv.org/abs/1805.08751v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.08751v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
384,http://arxiv.org/abs/1805.01392v1,2018-05-03 16:03:47+00:00,2018-05-03 16:03:47+00:00,Prevalence of web trackers on hospital websites in Illinois,[arxiv.Result.Author('Robert Robinson')],"Web tracking technologies are pervasive and operated by a few large
technology companies. This technology, and the use of the collected data has
been implicated in influencing elections, fake news, discrimination, and even
health decisions. Little is known about how this technology is deployed on
hospital or other health related websites. The websites of the 210 public
hospitals in the state of Illinois, USA were evaluated with a web tracker
identification tool. Web trackers were identified on 94% of hospital webs
sites, with an average of 3.5 trackers on the websites of general hospitals.
The websites of smaller critical access hospitals used an average of 2 web
trackers. The most common web tracker identified was Google Analytics, found on
74% of Illinois hospital websites. Of the web trackers discovered, 88% were
operated by Google and 26% by Facebook. In light of revelations about how web
browsing profiles have been used and misused, search bubbles, and the potential
for algorithmic discrimination hospital leadership and policy makers must
carefully consider if it is appropriate to use third party tracking technology
on hospital web sites.","7 pages, 1 table, 2 figures",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1805.01392v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1805.01392v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1805.01392v1,"{'id': 'http://arxiv.org/abs/1805.01392v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.01392v1', 'updated': '2018-05-03T16:03:47Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=3, tm_hour=16, tm_min=3, tm_sec=47, tm_wday=3, tm_yday=123, tm_isdst=0), 'published': '2018-05-03T16:03:47Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=3, tm_hour=16, tm_min=3, tm_sec=47, tm_wday=3, tm_yday=123, tm_isdst=0), 'title': 'Prevalence of web trackers on hospital websites in Illinois', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Prevalence of web trackers on hospital websites in Illinois'}, 'summary': 'Web tracking technologies are pervasive and operated by a few large\ntechnology companies. This technology, and the use of the collected data has\nbeen implicated in influencing elections, fake news, discrimination, and even\nhealth decisions. Little is known about how this technology is deployed on\nhospital or other health related websites. The websites of the 210 public\nhospitals in the state of Illinois, USA were evaluated with a web tracker\nidentification tool. Web trackers were identified on 94% of hospital webs\nsites, with an average of 3.5 trackers on the websites of general hospitals.\nThe websites of smaller critical access hospitals used an average of 2 web\ntrackers. The most common web tracker identified was Google Analytics, found on\n74% of Illinois hospital websites. Of the web trackers discovered, 88% were\noperated by Google and 26% by Facebook. In light of revelations about how web\nbrowsing profiles have been used and misused, search bubbles, and the potential\nfor algorithmic discrimination hospital leadership and policy makers must\ncarefully consider if it is appropriate to use third party tracking technology\non hospital web sites.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Web tracking technologies are pervasive and operated by a few large\ntechnology companies. This technology, and the use of the collected data has\nbeen implicated in influencing elections, fake news, discrimination, and even\nhealth decisions. Little is known about how this technology is deployed on\nhospital or other health related websites. The websites of the 210 public\nhospitals in the state of Illinois, USA were evaluated with a web tracker\nidentification tool. Web trackers were identified on 94% of hospital webs\nsites, with an average of 3.5 trackers on the websites of general hospitals.\nThe websites of smaller critical access hospitals used an average of 2 web\ntrackers. The most common web tracker identified was Google Analytics, found on\n74% of Illinois hospital websites. Of the web trackers discovered, 88% were\noperated by Google and 26% by Facebook. In light of revelations about how web\nbrowsing profiles have been used and misused, search bubbles, and the potential\nfor algorithmic discrimination hospital leadership and policy makers must\ncarefully consider if it is appropriate to use third party tracking technology\non hospital web sites.'}, 'authors': [{'name': 'Robert Robinson'}], 'author_detail': {'name': 'Robert Robinson'}, 'author': 'Robert Robinson', 'arxiv_comment': '7 pages, 1 table, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/1805.01392v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.01392v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
385,http://arxiv.org/abs/1804.10233v1,2018-04-26 18:30:56+00:00,2018-04-26 18:30:56+00:00,Studying Fake News via Network Analysis: Detection and Mitigation,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('H. Russell Bernard'), arxiv.Result.Author('Huan Liu')]","Social media for news consumption is becoming increasingly popular due to its
easy access, fast dissemination, and low cost. However, social media also
enable the wide propagation of ""fake news"", i.e., news with intentionally false
information. Fake news on social media poses significant negative societal
effects, and also presents unique challenges. To tackle the challenges, many
existing works exploit various features, from a network perspective, to detect
and mitigate fake news. In essence, news dissemination ecosystem involves three
dimensions on social media, i.e., a content dimension, a social dimension, and
a temporal dimension. In this chapter, we will review network properties for
studying fake news, introduce popular network types and how these networks can
be used to detect and mitigation fake news on social media.","Submitted as a invited book chapter in Lecture Notes in Social
  Networks, Springer Press",,,cs.SI,"['cs.SI', 'H.2.8']","[arxiv.Result.Link('http://arxiv.org/abs/1804.10233v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.10233v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.10233v1,"{'id': 'http://arxiv.org/abs/1804.10233v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.10233v1', 'updated': '2018-04-26T18:30:56Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=26, tm_hour=18, tm_min=30, tm_sec=56, tm_wday=3, tm_yday=116, tm_isdst=0), 'published': '2018-04-26T18:30:56Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=26, tm_hour=18, tm_min=30, tm_sec=56, tm_wday=3, tm_yday=116, tm_isdst=0), 'title': 'Studying Fake News via Network Analysis: Detection and Mitigation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Studying Fake News via Network Analysis: Detection and Mitigation'}, 'summary': 'Social media for news consumption is becoming increasingly popular due to its\neasy access, fast dissemination, and low cost. However, social media also\nenable the wide propagation of ""fake news"", i.e., news with intentionally false\ninformation. Fake news on social media poses significant negative societal\neffects, and also presents unique challenges. To tackle the challenges, many\nexisting works exploit various features, from a network perspective, to detect\nand mitigate fake news. In essence, news dissemination ecosystem involves three\ndimensions on social media, i.e., a content dimension, a social dimension, and\na temporal dimension. In this chapter, we will review network properties for\nstudying fake news, introduce popular network types and how these networks can\nbe used to detect and mitigation fake news on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media for news consumption is becoming increasingly popular due to its\neasy access, fast dissemination, and low cost. However, social media also\nenable the wide propagation of ""fake news"", i.e., news with intentionally false\ninformation. Fake news on social media poses significant negative societal\neffects, and also presents unique challenges. To tackle the challenges, many\nexisting works exploit various features, from a network perspective, to detect\nand mitigate fake news. In essence, news dissemination ecosystem involves three\ndimensions on social media, i.e., a content dimension, a social dimension, and\na temporal dimension. In this chapter, we will review network properties for\nstudying fake news, introduce popular network types and how these networks can\nbe used to detect and mitigation fake news on social media.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'H. Russell Bernard'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'Submitted as a invited book chapter in Lecture Notes in Social\n  Networks, Springer Press', 'links': [{'href': 'http://arxiv.org/abs/1804.10233v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.10233v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.2.8', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
386,http://arxiv.org/abs/1804.10159v1,2018-04-26 16:34:48+00:00,2018-04-26 16:34:48+00:00,AbuSniff: Automatic Detection and Defenses Against Abusive Facebook Friends,"[arxiv.Result.Author('Sajedul Talukder'), arxiv.Result.Author('Bogdan Carbunar')]","Adversaries leverage social network friend relationships to collect sensitive
data from users and target them with abuse that includes fake news,
cyberbullying, malware, and propaganda. Case in point, 71 out of 80 user study
participants had at least 1 Facebook friend with whom they never interact,
either in Facebook or in real life, or whom they believe is likely to abuse
their posted photos or status updates, or post offensive, false or malicious
content. We introduce AbuSniff, a system that identifies Facebook friends
perceived as strangers or abusive, and protects the user by unfriending,
unfollowing, or restricting the access to information for such friends. We
develop a questionnaire to detect perceived strangers and friend abuse.We
introduce mutual Facebook activity features and show that they can train
supervised learning algorithms to predict questionnaire responses. We have
evaluated AbuSniff through several user studies with a total of 263
participants from 25 countries. After answering the questionnaire, participants
agreed to unfollow and restrict abusers in 91.6% and 90.9% of the cases
respectively, and sandbox or unfriend non-abusive strangers in 92.45% of the
cases. Without answering the questionnaire, participants agreed to take the
AbuSniff suggested action against friends predicted to be strangers or abusive,
in 78.2% of the cases. AbuSniff increased the participant self-reported
willingness to reject invitations from strangers and abusers, their awareness
of friend abuse implications and their perceived protection from friend abuse.","12TH INTERNATIONAL AAAI CONFERENCE ON WEB AND SOCIAL MEDIA
  (ICWSM-18), 10 pages",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1804.10159v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.10159v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.10159v1,"{'id': 'http://arxiv.org/abs/1804.10159v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.10159v1', 'updated': '2018-04-26T16:34:48Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=26, tm_hour=16, tm_min=34, tm_sec=48, tm_wday=3, tm_yday=116, tm_isdst=0), 'published': '2018-04-26T16:34:48Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=26, tm_hour=16, tm_min=34, tm_sec=48, tm_wday=3, tm_yday=116, tm_isdst=0), 'title': 'AbuSniff: Automatic Detection and Defenses Against Abusive Facebook\n  Friends', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AbuSniff: Automatic Detection and Defenses Against Abusive Facebook\n  Friends'}, 'summary': 'Adversaries leverage social network friend relationships to collect sensitive\ndata from users and target them with abuse that includes fake news,\ncyberbullying, malware, and propaganda. Case in point, 71 out of 80 user study\nparticipants had at least 1 Facebook friend with whom they never interact,\neither in Facebook or in real life, or whom they believe is likely to abuse\ntheir posted photos or status updates, or post offensive, false or malicious\ncontent. We introduce AbuSniff, a system that identifies Facebook friends\nperceived as strangers or abusive, and protects the user by unfriending,\nunfollowing, or restricting the access to information for such friends. We\ndevelop a questionnaire to detect perceived strangers and friend abuse.We\nintroduce mutual Facebook activity features and show that they can train\nsupervised learning algorithms to predict questionnaire responses. We have\nevaluated AbuSniff through several user studies with a total of 263\nparticipants from 25 countries. After answering the questionnaire, participants\nagreed to unfollow and restrict abusers in 91.6% and 90.9% of the cases\nrespectively, and sandbox or unfriend non-abusive strangers in 92.45% of the\ncases. Without answering the questionnaire, participants agreed to take the\nAbuSniff suggested action against friends predicted to be strangers or abusive,\nin 78.2% of the cases. AbuSniff increased the participant self-reported\nwillingness to reject invitations from strangers and abusers, their awareness\nof friend abuse implications and their perceived protection from friend abuse.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversaries leverage social network friend relationships to collect sensitive\ndata from users and target them with abuse that includes fake news,\ncyberbullying, malware, and propaganda. Case in point, 71 out of 80 user study\nparticipants had at least 1 Facebook friend with whom they never interact,\neither in Facebook or in real life, or whom they believe is likely to abuse\ntheir posted photos or status updates, or post offensive, false or malicious\ncontent. We introduce AbuSniff, a system that identifies Facebook friends\nperceived as strangers or abusive, and protects the user by unfriending,\nunfollowing, or restricting the access to information for such friends. We\ndevelop a questionnaire to detect perceived strangers and friend abuse.We\nintroduce mutual Facebook activity features and show that they can train\nsupervised learning algorithms to predict questionnaire responses. We have\nevaluated AbuSniff through several user studies with a total of 263\nparticipants from 25 countries. After answering the questionnaire, participants\nagreed to unfollow and restrict abusers in 91.6% and 90.9% of the cases\nrespectively, and sandbox or unfriend non-abusive strangers in 92.45% of the\ncases. Without answering the questionnaire, participants agreed to take the\nAbuSniff suggested action against friends predicted to be strangers or abusive,\nin 78.2% of the cases. AbuSniff increased the participant self-reported\nwillingness to reject invitations from strangers and abusers, their awareness\nof friend abuse implications and their perceived protection from friend abuse.'}, 'authors': [{'name': 'Sajedul Talukder'}, {'name': 'Bogdan Carbunar'}], 'author_detail': {'name': 'Bogdan Carbunar'}, 'author': 'Bogdan Carbunar', 'arxiv_comment': '12TH INTERNATIONAL AAAI CONFERENCE ON WEB AND SOCIAL MEDIA\n  (ICWSM-18), 10 pages', 'links': [{'href': 'http://arxiv.org/abs/1804.10159v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.10159v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
387,http://arxiv.org/abs/1804.09088v1,2018-04-24 15:13:51+00:00,2018-04-24 15:13:51+00:00,Semi-supervised Content-based Detection of Misinformation via Tensor Embeddings,"[arxiv.Result.Author('Gisel Bastidas Guacho'), arxiv.Result.Author('Sara Abdali'), arxiv.Result.Author('Neil Shah'), arxiv.Result.Author('Evangelos E. Papalexakis')]","Fake news may be intentionally created to promote economic, political and
social interests, and can lead to negative impacts on humans beliefs and
decisions. Hence, detection of fake news is an emerging problem that has become
extremely prevalent during the last few years. Most existing works on this
topic focus on manual feature extraction and supervised classification models
leveraging a large number of labeled (fake or real) articles. In contrast, we
focus on content-based detection of fake news articles, while assuming that we
have a small amount of labels, made available by manual fact-checkers or
automated sources. We argue this is a more realistic setting in the presence of
massive amounts of content, most of which cannot be easily factchecked. To that
end, we represent collections of news articles as multi-dimensional tensors,
leverage tensor decomposition to derive concise article embeddings that capture
spatial/contextual information about each news article, and use those
embeddings to create an article-by-article graph on which we propagate limited
labels. Results on three real-world datasets show that our method performs on
par or better than existing models that are fully supervised, in that we
achieve better detection accuracy using fewer labels. In particular, our
proposed method achieves 75.43% of accuracy using only 30% of labels of a
public dataset while an SVM-based classifier achieved 67.43%. Furthermore, our
method achieves 70.92% of accuracy in a large dataset using only 2% of labels.",,,,cs.LG,"['cs.LG', 'cs.SI', 'stat.AP', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1804.09088v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.09088v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.09088v1,"{'id': 'http://arxiv.org/abs/1804.09088v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.09088v1', 'updated': '2018-04-24T15:13:51Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=24, tm_hour=15, tm_min=13, tm_sec=51, tm_wday=1, tm_yday=114, tm_isdst=0), 'published': '2018-04-24T15:13:51Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=24, tm_hour=15, tm_min=13, tm_sec=51, tm_wday=1, tm_yday=114, tm_isdst=0), 'title': 'Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings'}, 'summary': 'Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.'}, 'authors': [{'name': 'Gisel Bastidas Guacho'}, {'name': 'Sara Abdali'}, {'name': 'Neil Shah'}, {'name': 'Evangelos E. Papalexakis'}], 'author_detail': {'name': 'Evangelos E. Papalexakis'}, 'author': 'Evangelos E. Papalexakis', 'links': [{'href': 'http://arxiv.org/abs/1804.09088v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.09088v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
388,http://arxiv.org/abs/1804.07581v1,2018-04-20 12:48:10+00:00,2018-04-20 12:48:10+00:00,Automatic Stance Detection Using End-to-End Memory Networks,"[arxiv.Result.Author('Mitra Mohtarami'), arxiv.Result.Author('Ramy Baly'), arxiv.Result.Author('James Glass'), arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Lluis Marquez'), arxiv.Result.Author('Alessandro Moschitti')]","We present a novel end-to-end memory network for stance detection, which
jointly (i) predicts whether a document agrees, disagrees, discusses or is
unrelated with respect to a given target claim, and also (ii) extracts snippets
of evidence for that prediction. The network operates at the paragraph level
and integrates convolutional and recurrent neural networks, as well as a
similarity matrix as part of the overall architecture. The experimental
evaluation on the Fake News Challenge dataset shows state-of-the-art
performance.","NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory
  networks; Neural Networks; Distributed Representations",,,cs.CL,"['cs.CL', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1804.07581v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.07581v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.07581v1,"{'id': 'http://arxiv.org/abs/1804.07581v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.07581v1', 'updated': '2018-04-20T12:48:10Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=20, tm_hour=12, tm_min=48, tm_sec=10, tm_wday=4, tm_yday=110, tm_isdst=0), 'published': '2018-04-20T12:48:10Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=20, tm_hour=12, tm_min=48, tm_sec=10, tm_wday=4, tm_yday=110, tm_isdst=0), 'title': 'Automatic Stance Detection Using End-to-End Memory Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic Stance Detection Using End-to-End Memory Networks'}, 'summary': 'We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.'}, 'authors': [{'name': 'Mitra Mohtarami'}, {'name': 'Ramy Baly'}, {'name': 'James Glass'}, {'name': 'Preslav Nakov'}, {'name': 'Lluis Marquez'}, {'name': 'Alessandro Moschitti'}], 'author_detail': {'name': 'Alessandro Moschitti'}, 'author': 'Alessandro Moschitti', 'arxiv_comment': 'NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory\n  networks; Neural Networks; Distributed Representations', 'links': [{'href': 'http://arxiv.org/abs/1804.07581v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.07581v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
389,http://arxiv.org/abs/1804.02509v1,2018-04-07 04:46:31+00:00,2018-04-07 04:46:31+00:00,Incentivizing the Dissemination of Truth Versus Fake News in Social Networks,"[arxiv.Result.Author('Abbas Ehsanfar'), arxiv.Result.Author('Mo Mansouri')]","The concept of truth, as a public good is the production of a collective
understanding, which emerges from a complex network of social interactions. The
recent impact of social networks on shaping the perception of truth in
political arena shows how such perception is corroborated and established by
the online users, collectively. However, investigative journalism for
discovering truth is a costly option, given the vast spectrum of online
information. In some cases, both journalist and online users choose not to
investigate the authenticity of the news they receive, because they assume
other actors of the network had carried the cost of validation. Therefore, the
new phenomenon of ""fake news"" has emerged within the context of social
networks. The online social networks, similarly to System of Systems, cause
emergent properties, which makes authentication processes difficult, given
availability of multiple sources. In this study, we show how this conflict can
be modeled as a volunteer's dilemma. We also show how the public contribution
through news subscription (shared rewards) can impact the dominance of truth
over fake news in the network.","System of Systems Engineering Conference (SoSE), 2017 12th. IEEE,
  2017",,,cs.SI,"['cs.SI', 'cs.SY']","[arxiv.Result.Link('http://arxiv.org/abs/1804.02509v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.02509v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.02509v1,"{'id': 'http://arxiv.org/abs/1804.02509v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.02509v1', 'updated': '2018-04-07T04:46:31Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=7, tm_hour=4, tm_min=46, tm_sec=31, tm_wday=5, tm_yday=97, tm_isdst=0), 'published': '2018-04-07T04:46:31Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=7, tm_hour=4, tm_min=46, tm_sec=31, tm_wday=5, tm_yday=97, tm_isdst=0), 'title': 'Incentivizing the Dissemination of Truth Versus Fake News in Social\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Incentivizing the Dissemination of Truth Versus Fake News in Social\n  Networks'}, 'summary': 'The concept of truth, as a public good is the production of a collective\nunderstanding, which emerges from a complex network of social interactions. The\nrecent impact of social networks on shaping the perception of truth in\npolitical arena shows how such perception is corroborated and established by\nthe online users, collectively. However, investigative journalism for\ndiscovering truth is a costly option, given the vast spectrum of online\ninformation. In some cases, both journalist and online users choose not to\ninvestigate the authenticity of the news they receive, because they assume\nother actors of the network had carried the cost of validation. Therefore, the\nnew phenomenon of ""fake news"" has emerged within the context of social\nnetworks. The online social networks, similarly to System of Systems, cause\nemergent properties, which makes authentication processes difficult, given\navailability of multiple sources. In this study, we show how this conflict can\nbe modeled as a volunteer\'s dilemma. We also show how the public contribution\nthrough news subscription (shared rewards) can impact the dominance of truth\nover fake news in the network.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The concept of truth, as a public good is the production of a collective\nunderstanding, which emerges from a complex network of social interactions. The\nrecent impact of social networks on shaping the perception of truth in\npolitical arena shows how such perception is corroborated and established by\nthe online users, collectively. However, investigative journalism for\ndiscovering truth is a costly option, given the vast spectrum of online\ninformation. In some cases, both journalist and online users choose not to\ninvestigate the authenticity of the news they receive, because they assume\nother actors of the network had carried the cost of validation. Therefore, the\nnew phenomenon of ""fake news"" has emerged within the context of social\nnetworks. The online social networks, similarly to System of Systems, cause\nemergent properties, which makes authentication processes difficult, given\navailability of multiple sources. In this study, we show how this conflict can\nbe modeled as a volunteer\'s dilemma. We also show how the public contribution\nthrough news subscription (shared rewards) can impact the dominance of truth\nover fake news in the network.'}, 'authors': [{'name': 'Abbas Ehsanfar'}, {'name': 'Mo Mansouri'}], 'author_detail': {'name': 'Mo Mansouri'}, 'author': 'Mo Mansouri', 'arxiv_comment': 'System of Systems Engineering Conference (SoSE), 2017 12th. IEEE,\n  2017', 'links': [{'href': 'http://arxiv.org/abs/1804.02509v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.02509v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
390,http://arxiv.org/abs/1804.01235v2,2018-04-17 12:58:41+00:00,2018-04-04 04:38:36+00:00,Real-time Detection of Content Polluters in Partially Observable Twitter Networks,"[arxiv.Result.Author('Mehwish Nasim'), arxiv.Result.Author('Andrew Nguyen'), arxiv.Result.Author('Nick Lothian'), arxiv.Result.Author('Robert Cope'), arxiv.Result.Author('Lewis Mitchell')]","Content polluters, or bots that hijack a conversation for political or
advertising purposes are a known problem for event prediction, election
forecasting and when distinguishing real news from fake news in social media
data. Identifying this type of bot is particularly challenging, with
state-of-the-art methods utilising large volumes of network data as features
for machine learning models. Such datasets are generally not readily available
in typical applications which stream social media data for real-time event
prediction. In this work we develop a methodology to detect content polluters
in social media datasets that are streamed in real-time. Applying our method to
the problem of civil unrest event prediction in Australia, we identify content
polluters from individual tweets, without collecting social network or
historical data from individual accounts. We identify some peculiar
characteristics of these bots in our dataset and propose metrics for
identification of such accounts. We then pose some research questions around
this type of bot detection, including: how good Twitter is at detecting content
polluters and how well state-of-the-art methods perform in detecting bots in
our dataset.","Accepted for publication in WWW '18 Companion: The 2018 Web
  Conference Companion, April 23-27, 2018, Lyon, France",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1804.01235v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.01235v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.01235v2,"{'id': 'http://arxiv.org/abs/1804.01235v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.01235v2', 'updated': '2018-04-17T12:58:41Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=17, tm_hour=12, tm_min=58, tm_sec=41, tm_wday=1, tm_yday=107, tm_isdst=0), 'published': '2018-04-04T04:38:36Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=4, tm_hour=4, tm_min=38, tm_sec=36, tm_wday=2, tm_yday=94, tm_isdst=0), 'title': 'Real-time Detection of Content Polluters in Partially Observable Twitter\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Real-time Detection of Content Polluters in Partially Observable Twitter\n  Networks'}, 'summary': 'Content polluters, or bots that hijack a conversation for political or\nadvertising purposes are a known problem for event prediction, election\nforecasting and when distinguishing real news from fake news in social media\ndata. Identifying this type of bot is particularly challenging, with\nstate-of-the-art methods utilising large volumes of network data as features\nfor machine learning models. Such datasets are generally not readily available\nin typical applications which stream social media data for real-time event\nprediction. In this work we develop a methodology to detect content polluters\nin social media datasets that are streamed in real-time. Applying our method to\nthe problem of civil unrest event prediction in Australia, we identify content\npolluters from individual tweets, without collecting social network or\nhistorical data from individual accounts. We identify some peculiar\ncharacteristics of these bots in our dataset and propose metrics for\nidentification of such accounts. We then pose some research questions around\nthis type of bot detection, including: how good Twitter is at detecting content\npolluters and how well state-of-the-art methods perform in detecting bots in\nour dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Content polluters, or bots that hijack a conversation for political or\nadvertising purposes are a known problem for event prediction, election\nforecasting and when distinguishing real news from fake news in social media\ndata. Identifying this type of bot is particularly challenging, with\nstate-of-the-art methods utilising large volumes of network data as features\nfor machine learning models. Such datasets are generally not readily available\nin typical applications which stream social media data for real-time event\nprediction. In this work we develop a methodology to detect content polluters\nin social media datasets that are streamed in real-time. Applying our method to\nthe problem of civil unrest event prediction in Australia, we identify content\npolluters from individual tweets, without collecting social network or\nhistorical data from individual accounts. We identify some peculiar\ncharacteristics of these bots in our dataset and propose metrics for\nidentification of such accounts. We then pose some research questions around\nthis type of bot detection, including: how good Twitter is at detecting content\npolluters and how well state-of-the-art methods perform in detecting bots in\nour dataset.'}, 'authors': [{'name': 'Mehwish Nasim'}, {'name': 'Andrew Nguyen'}, {'name': 'Nick Lothian'}, {'name': 'Robert Cope'}, {'name': 'Lewis Mitchell'}], 'author_detail': {'name': 'Lewis Mitchell'}, 'author': 'Lewis Mitchell', 'arxiv_comment': ""Accepted for publication in WWW '18 Companion: The 2018 Web\n  Conference Companion, April 23-27, 2018, Lyon, France"", 'links': [{'href': 'http://arxiv.org/abs/1804.01235v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.01235v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
391,http://arxiv.org/abs/1804.00982v1,2018-04-03 14:17:09+00:00,2018-04-03 14:17:09+00:00,360° Stance Detection,"[arxiv.Result.Author('Sebastian Ruder'), arxiv.Result.Author('John Glover'), arxiv.Result.Author('Afshin Mehrabani'), arxiv.Result.Author('Parsa Ghaffari')]","The proliferation of fake news and filter bubbles makes it increasingly
difficult to form an unbiased, balanced opinion towards a topic. To ameliorate
this, we propose 360{\deg} Stance Detection, a tool that aggregates news with
multiple perspectives on a topic. It presents them on a spectrum ranging from
support to opposition, enabling the user to base their opinion on multiple
pieces of diverse evidence.",Proceedings of NAACL-HLT 2018: System Demonstrations,,,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1804.00982v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.00982v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.00982v1,"{'id': 'http://arxiv.org/abs/1804.00982v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.00982v1', 'updated': '2018-04-03T14:17:09Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=3, tm_hour=14, tm_min=17, tm_sec=9, tm_wday=1, tm_yday=93, tm_isdst=0), 'published': '2018-04-03T14:17:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=3, tm_hour=14, tm_min=17, tm_sec=9, tm_wday=1, tm_yday=93, tm_isdst=0), 'title': '360° Stance Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '360° Stance Detection'}, 'summary': 'The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.'}, 'authors': [{'name': 'Sebastian Ruder'}, {'name': 'John Glover'}, {'name': 'Afshin Mehrabani'}, {'name': 'Parsa Ghaffari'}], 'author_detail': {'name': 'Parsa Ghaffari'}, 'author': 'Parsa Ghaffari', 'arxiv_comment': 'Proceedings of NAACL-HLT 2018: System Demonstrations', 'links': [{'href': 'http://arxiv.org/abs/1804.00982v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.00982v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
392,http://arxiv.org/abs/1804.00482v1,2018-04-02 13:31:11+00:00,2018-04-02 13:31:11+00:00,Real Time Sentiment Change Detection of Twitter Data Streams,"[arxiv.Result.Author('Sotiris K. Tasoulis'), arxiv.Result.Author('Aristidis G. Vrahatis'), arxiv.Result.Author('Spiros V. Georgakopoulos'), arxiv.Result.Author('Vassilis P. Plagianakos')]","In the past few years, there has been a huge growth in Twitter sentiment
analysis having already provided a fair amount of research on sentiment
detection of public opinion among Twitter users. Given the fact that Twitter
messages are generated constantly with dizzying rates, a huge volume of
streaming data is created, thus there is an imperative need for accurate
methods for knowledge discovery and mining of this information. Although there
exists a plethora of twitter sentiment analysis methods in the recent
literature, the researchers have shifted to real-time sentiment identification
on twitter streaming data, as expected. A major challenge is to deal with the
Big Data challenges arising in Twitter streaming applications concerning both
Volume and Velocity. Under this perspective, in this paper, a methodological
approach based on open source tools is provided for real-time detection of
changes in sentiment that is ultra efficient with respect to both memory
consumption and computational cost. This is achieved by iteratively collecting
tweets in real time and discarding them immediately after their process. For
this purpose, we employ the Lexicon approach for sentiment characterizations,
while change detection is achieved through appropriate control charts that do
not require historical information. We believe that the proposed methodology
provides the trigger for a potential large-scale monitoring of threads in an
attempt to discover fake news spread or propaganda efforts in their early
stages. Our experimental real-time analysis based on a recent hashtag provides
evidence that the proposed approach can detect meaningful sentiment changes
across a hashtags lifetime.",,,10.1109/INISTA.2018.8466326,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/INISTA.2018.8466326', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1804.00482v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.00482v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.00482v1,"{'id': 'http://arxiv.org/abs/1804.00482v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.00482v1', 'updated': '2018-04-02T13:31:11Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=2, tm_hour=13, tm_min=31, tm_sec=11, tm_wday=0, tm_yday=92, tm_isdst=0), 'published': '2018-04-02T13:31:11Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=2, tm_hour=13, tm_min=31, tm_sec=11, tm_wday=0, tm_yday=92, tm_isdst=0), 'title': 'Real Time Sentiment Change Detection of Twitter Data Streams', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Real Time Sentiment Change Detection of Twitter Data Streams'}, 'summary': 'In the past few years, there has been a huge growth in Twitter sentiment\nanalysis having already provided a fair amount of research on sentiment\ndetection of public opinion among Twitter users. Given the fact that Twitter\nmessages are generated constantly with dizzying rates, a huge volume of\nstreaming data is created, thus there is an imperative need for accurate\nmethods for knowledge discovery and mining of this information. Although there\nexists a plethora of twitter sentiment analysis methods in the recent\nliterature, the researchers have shifted to real-time sentiment identification\non twitter streaming data, as expected. A major challenge is to deal with the\nBig Data challenges arising in Twitter streaming applications concerning both\nVolume and Velocity. Under this perspective, in this paper, a methodological\napproach based on open source tools is provided for real-time detection of\nchanges in sentiment that is ultra efficient with respect to both memory\nconsumption and computational cost. This is achieved by iteratively collecting\ntweets in real time and discarding them immediately after their process. For\nthis purpose, we employ the Lexicon approach for sentiment characterizations,\nwhile change detection is achieved through appropriate control charts that do\nnot require historical information. We believe that the proposed methodology\nprovides the trigger for a potential large-scale monitoring of threads in an\nattempt to discover fake news spread or propaganda efforts in their early\nstages. Our experimental real-time analysis based on a recent hashtag provides\nevidence that the proposed approach can detect meaningful sentiment changes\nacross a hashtags lifetime.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the past few years, there has been a huge growth in Twitter sentiment\nanalysis having already provided a fair amount of research on sentiment\ndetection of public opinion among Twitter users. Given the fact that Twitter\nmessages are generated constantly with dizzying rates, a huge volume of\nstreaming data is created, thus there is an imperative need for accurate\nmethods for knowledge discovery and mining of this information. Although there\nexists a plethora of twitter sentiment analysis methods in the recent\nliterature, the researchers have shifted to real-time sentiment identification\non twitter streaming data, as expected. A major challenge is to deal with the\nBig Data challenges arising in Twitter streaming applications concerning both\nVolume and Velocity. Under this perspective, in this paper, a methodological\napproach based on open source tools is provided for real-time detection of\nchanges in sentiment that is ultra efficient with respect to both memory\nconsumption and computational cost. This is achieved by iteratively collecting\ntweets in real time and discarding them immediately after their process. For\nthis purpose, we employ the Lexicon approach for sentiment characterizations,\nwhile change detection is achieved through appropriate control charts that do\nnot require historical information. We believe that the proposed methodology\nprovides the trigger for a potential large-scale monitoring of threads in an\nattempt to discover fake news spread or propaganda efforts in their early\nstages. Our experimental real-time analysis based on a recent hashtag provides\nevidence that the proposed approach can detect meaningful sentiment changes\nacross a hashtags lifetime.'}, 'authors': [{'name': 'Sotiris K. Tasoulis'}, {'name': 'Aristidis G. Vrahatis'}, {'name': 'Spiros V. Georgakopoulos'}, {'name': 'Vassilis P. Plagianakos'}], 'author_detail': {'name': 'Vassilis P. Plagianakos'}, 'author': 'Vassilis P. Plagianakos', 'arxiv_doi': '10.1109/INISTA.2018.8466326', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/INISTA.2018.8466326', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1804.00482v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.00482v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
393,http://arxiv.org/abs/1804.03508v1,2018-03-31 09:48:20+00:00,2018-03-31 09:48:20+00:00,Seeing Through Misinformation: A Framework for Identifying Fake Online News,"[arxiv.Result.Author('Murphy Choy'), arxiv.Result.Author('Mark Chong')]","The fake news epidemic makes it imperative to develop a diagnostic framework
that is both parsimonious and valid to guide present and future efforts in fake
news detection. This paper represents one of the very first attempts to fill a
void in the research on this topic. The LeSiE (Lexical Structure, Simplicity,
Emotion) framework we created and validated allows lay people to identify
potential fake news without the use of calculators or complex statistics by
looking out for three simple cues.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1804.03508v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.03508v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.03508v1,"{'id': 'http://arxiv.org/abs/1804.03508v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.03508v1', 'updated': '2018-03-31T09:48:20Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=31, tm_hour=9, tm_min=48, tm_sec=20, tm_wday=5, tm_yday=90, tm_isdst=0), 'published': '2018-03-31T09:48:20Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=31, tm_hour=9, tm_min=48, tm_sec=20, tm_wday=5, tm_yday=90, tm_isdst=0), 'title': 'Seeing Through Misinformation: A Framework for Identifying Fake Online\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Seeing Through Misinformation: A Framework for Identifying Fake Online\n  News'}, 'summary': 'The fake news epidemic makes it imperative to develop a diagnostic framework\nthat is both parsimonious and valid to guide present and future efforts in fake\nnews detection. This paper represents one of the very first attempts to fill a\nvoid in the research on this topic. The LeSiE (Lexical Structure, Simplicity,\nEmotion) framework we created and validated allows lay people to identify\npotential fake news without the use of calculators or complex statistics by\nlooking out for three simple cues.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The fake news epidemic makes it imperative to develop a diagnostic framework\nthat is both parsimonious and valid to guide present and future efforts in fake\nnews detection. This paper represents one of the very first attempts to fill a\nvoid in the research on this topic. The LeSiE (Lexical Structure, Simplicity,\nEmotion) framework we created and validated allows lay people to identify\npotential fake news without the use of calculators or complex statistics by\nlooking out for three simple cues.'}, 'authors': [{'name': 'Murphy Choy'}, {'name': 'Mark Chong'}], 'author_detail': {'name': 'Mark Chong'}, 'author': 'Mark Chong', 'links': [{'href': 'http://arxiv.org/abs/1804.03508v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.03508v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
394,http://arxiv.org/abs/1803.08491v2,2019-03-20 14:53:31+00:00,2018-03-22 17:53:09+00:00,Influence of fake news in Twitter during the 2016 US presidential election,"[arxiv.Result.Author('Alexandre Bovet'), arxiv.Result.Author('Hernan A. Makse')]","The dynamics and influence of fake news on Twitter during the 2016 US
presidential election remains to be clarified. Here, we use a dataset of 171
million tweets in the five months preceding the election day to identify 30
million tweets, from 2.2 million users, which contain a link to news outlets.
Based on a classification of news outlets curated by www.opensources.co, we
find that 25% of these tweets spread either fake or extremely biased news. We
characterize the networks of information flow to find the most influential
spreaders of fake and traditional news and use causal modeling to uncover how
fake news influenced the presidential election. We find that, while top
influencers spreading traditional center and left leaning news largely
influence the activity of Clinton supporters, this causality is reversed for
the fake news: the activity of Trump supporters influences the dynamics of the
top fake news spreaders.",Updated to latest revised version,"Nat. Commun. 10, 7 (2019)",10.1038/s41467-018-07761-2,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41467-018-07761-2', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1803.08491v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1803.08491v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1803.08491v2,"{'id': 'http://arxiv.org/abs/1803.08491v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1803.08491v2', 'updated': '2019-03-20T14:53:31Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=20, tm_hour=14, tm_min=53, tm_sec=31, tm_wday=2, tm_yday=79, tm_isdst=0), 'published': '2018-03-22T17:53:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=22, tm_hour=17, tm_min=53, tm_sec=9, tm_wday=3, tm_yday=81, tm_isdst=0), 'title': 'Influence of fake news in Twitter during the 2016 US presidential\n  election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Influence of fake news in Twitter during the 2016 US presidential\n  election'}, 'summary': 'The dynamics and influence of fake news on Twitter during the 2016 US\npresidential election remains to be clarified. Here, we use a dataset of 171\nmillion tweets in the five months preceding the election day to identify 30\nmillion tweets, from 2.2 million users, which contain a link to news outlets.\nBased on a classification of news outlets curated by www.opensources.co, we\nfind that 25% of these tweets spread either fake or extremely biased news. We\ncharacterize the networks of information flow to find the most influential\nspreaders of fake and traditional news and use causal modeling to uncover how\nfake news influenced the presidential election. We find that, while top\ninfluencers spreading traditional center and left leaning news largely\ninfluence the activity of Clinton supporters, this causality is reversed for\nthe fake news: the activity of Trump supporters influences the dynamics of the\ntop fake news spreaders.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The dynamics and influence of fake news on Twitter during the 2016 US\npresidential election remains to be clarified. Here, we use a dataset of 171\nmillion tweets in the five months preceding the election day to identify 30\nmillion tweets, from 2.2 million users, which contain a link to news outlets.\nBased on a classification of news outlets curated by www.opensources.co, we\nfind that 25% of these tweets spread either fake or extremely biased news. We\ncharacterize the networks of information flow to find the most influential\nspreaders of fake and traditional news and use causal modeling to uncover how\nfake news influenced the presidential election. We find that, while top\ninfluencers spreading traditional center and left leaning news largely\ninfluence the activity of Clinton supporters, this causality is reversed for\nthe fake news: the activity of Trump supporters influences the dynamics of the\ntop fake news spreaders.'}, 'authors': [{'name': 'Alexandre Bovet'}, {'name': 'Hernan A. Makse'}], 'author_detail': {'name': 'Hernan A. Makse'}, 'author': 'Hernan A. Makse', 'arxiv_doi': '10.1038/s41467-018-07761-2', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41467-018-07761-2', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1803.08491v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1803.08491v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Updated to latest revised version', 'arxiv_journal_ref': 'Nat. Commun. 10, 7 (2019)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
395,http://arxiv.org/abs/1803.03786v1,2018-03-10 10:09:13+00:00,2018-03-10 10:09:13+00:00,We Built a Fake News & Click-bait Filter: What Happened Next Will Blow Your Mind!,"[arxiv.Result.Author('Georgi Karadzhov'), arxiv.Result.Author('Pepa Gencheva'), arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Ivan Koychev')]","It is completely amazing! Fake news and click-baits have totally invaded the
cyber space. Let us face it: everybody hates them for three simple reasons.
Reason #2 will absolutely amaze you. What these can achieve at the time of
election will completely blow your mind! Now, we all agree, this cannot go on,
you know, somebody has to stop it. So, we did this research on fake
news/click-bait detection and trust us, it is totally great research, it really
is! Make no mistake. This is the best research ever! Seriously, come have a
look, we have it all: neural networks, attention mechanism, sentiment lexicons,
author profiling, you name it. Lexical features, semantic features, we
absolutely have it all. And we have totally tested it, trust us! We have
results, and numbers, really big numbers. The best numbers ever! Oh, and
analysis, absolutely top notch analysis. Interested? Come read the shocking
truth about fake news and click-bait in the Bulgarian cyber space. You won't
believe what we have found!","RANLP'2017, 7 pages, 1 figure",,10.26615/978-954-452-049-6_045,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://dx.doi.org/10.26615/978-954-452-049-6_045', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1803.03786v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1803.03786v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1803.03786v1,"{'id': 'http://arxiv.org/abs/1803.03786v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1803.03786v1', 'updated': '2018-03-10T10:09:13Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=10, tm_hour=10, tm_min=9, tm_sec=13, tm_wday=5, tm_yday=69, tm_isdst=0), 'published': '2018-03-10T10:09:13Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=10, tm_hour=10, tm_min=9, tm_sec=13, tm_wday=5, tm_yday=69, tm_isdst=0), 'title': 'We Built a Fake News & Click-bait Filter: What Happened Next Will Blow\n  Your Mind!', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We Built a Fake News & Click-bait Filter: What Happened Next Will Blow\n  Your Mind!'}, 'summary': ""It is completely amazing! Fake news and click-baits have totally invaded the\ncyber space. Let us face it: everybody hates them for three simple reasons.\nReason #2 will absolutely amaze you. What these can achieve at the time of\nelection will completely blow your mind! Now, we all agree, this cannot go on,\nyou know, somebody has to stop it. So, we did this research on fake\nnews/click-bait detection and trust us, it is totally great research, it really\nis! Make no mistake. This is the best research ever! Seriously, come have a\nlook, we have it all: neural networks, attention mechanism, sentiment lexicons,\nauthor profiling, you name it. Lexical features, semantic features, we\nabsolutely have it all. And we have totally tested it, trust us! We have\nresults, and numbers, really big numbers. The best numbers ever! Oh, and\nanalysis, absolutely top notch analysis. Interested? Come read the shocking\ntruth about fake news and click-bait in the Bulgarian cyber space. You won't\nbelieve what we have found!"", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""It is completely amazing! Fake news and click-baits have totally invaded the\ncyber space. Let us face it: everybody hates them for three simple reasons.\nReason #2 will absolutely amaze you. What these can achieve at the time of\nelection will completely blow your mind! Now, we all agree, this cannot go on,\nyou know, somebody has to stop it. So, we did this research on fake\nnews/click-bait detection and trust us, it is totally great research, it really\nis! Make no mistake. This is the best research ever! Seriously, come have a\nlook, we have it all: neural networks, attention mechanism, sentiment lexicons,\nauthor profiling, you name it. Lexical features, semantic features, we\nabsolutely have it all. And we have totally tested it, trust us! We have\nresults, and numbers, really big numbers. The best numbers ever! Oh, and\nanalysis, absolutely top notch analysis. Interested? Come read the shocking\ntruth about fake news and click-bait in the Bulgarian cyber space. You won't\nbelieve what we have found!""}, 'authors': [{'name': 'Georgi Karadzhov'}, {'name': 'Pepa Gencheva'}, {'name': 'Preslav Nakov'}, {'name': 'Ivan Koychev'}], 'author_detail': {'name': 'Ivan Koychev'}, 'author': 'Ivan Koychev', 'arxiv_doi': '10.26615/978-954-452-049-6_045', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.26615/978-954-452-049-6_045', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1803.03786v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1803.03786v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""RANLP'2017, 7 pages, 1 figure"", 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
396,http://arxiv.org/abs/1803.03443v3,2019-04-16 02:11:50+00:00,2018-03-09 10:04:00+00:00,Fake news propagate differently from real news even at early stages of spreading,"[arxiv.Result.Author('Zilong Zhao'), arxiv.Result.Author('Jichang Zhao'), arxiv.Result.Author('Yukie Sano'), arxiv.Result.Author('Orr levy'), arxiv.Result.Author('Hideki Takayasu'), arxiv.Result.Author('Misako Takayasu'), arxiv.Result.Author('Daqing Li'), arxiv.Result.Author('Junjie Wu'), arxiv.Result.Author('Shlomo Havlin')]","Social media can be a double-edged sword for society, either as a convenient
channel exchanging ideas or as an unexpected conduit circulating fake news
through a large population. While existing studies of fake news focus on
theoretical modeling of propagation or identification methods based on machine
learning, it is important to understand the realistic mechanisms between
theoretical models and black-box methods. Here we track large databases of fake
news and real news in both, Weibo in China and Twitter in Japan from different
culture, which include their complete traces of re-postings. We find in both
online social networks that fake news spreads distinctively from real news even
at early stages of propagation, e.g. five hours after the first re-postings.
Our finding demonstrates collective structural signals that help to understand
the different propagation evolution of fake news and real news. Different from
earlier studies, identifying the topological properties of the information
propagation at early stages may offer novel features for early detection of
fake news in social media.","35pages, 6 groups of figures",,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1803.03443v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1803.03443v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1803.03443v3,"{'id': 'http://arxiv.org/abs/1803.03443v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1803.03443v3', 'updated': '2019-04-16T02:11:50Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=16, tm_hour=2, tm_min=11, tm_sec=50, tm_wday=1, tm_yday=106, tm_isdst=0), 'published': '2018-03-09T10:04:00Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=9, tm_hour=10, tm_min=4, tm_sec=0, tm_wday=4, tm_yday=68, tm_isdst=0), 'title': 'Fake news propagate differently from real news even at early stages of\n  spreading', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news propagate differently from real news even at early stages of\n  spreading'}, 'summary': 'Social media can be a double-edged sword for society, either as a convenient\nchannel exchanging ideas or as an unexpected conduit circulating fake news\nthrough a large population. While existing studies of fake news focus on\ntheoretical modeling of propagation or identification methods based on machine\nlearning, it is important to understand the realistic mechanisms between\ntheoretical models and black-box methods. Here we track large databases of fake\nnews and real news in both, Weibo in China and Twitter in Japan from different\nculture, which include their complete traces of re-postings. We find in both\nonline social networks that fake news spreads distinctively from real news even\nat early stages of propagation, e.g. five hours after the first re-postings.\nOur finding demonstrates collective structural signals that help to understand\nthe different propagation evolution of fake news and real news. Different from\nearlier studies, identifying the topological properties of the information\npropagation at early stages may offer novel features for early detection of\nfake news in social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media can be a double-edged sword for society, either as a convenient\nchannel exchanging ideas or as an unexpected conduit circulating fake news\nthrough a large population. While existing studies of fake news focus on\ntheoretical modeling of propagation or identification methods based on machine\nlearning, it is important to understand the realistic mechanisms between\ntheoretical models and black-box methods. Here we track large databases of fake\nnews and real news in both, Weibo in China and Twitter in Japan from different\nculture, which include their complete traces of re-postings. We find in both\nonline social networks that fake news spreads distinctively from real news even\nat early stages of propagation, e.g. five hours after the first re-postings.\nOur finding demonstrates collective structural signals that help to understand\nthe different propagation evolution of fake news and real news. Different from\nearlier studies, identifying the topological properties of the information\npropagation at early stages may offer novel features for early detection of\nfake news in social media.'}, 'authors': [{'name': 'Zilong Zhao'}, {'name': 'Jichang Zhao'}, {'name': 'Yukie Sano'}, {'name': 'Orr levy'}, {'name': 'Hideki Takayasu'}, {'name': 'Misako Takayasu'}, {'name': 'Daqing Li'}, {'name': 'Junjie Wu'}, {'name': 'Shlomo Havlin'}], 'author_detail': {'name': 'Shlomo Havlin'}, 'author': 'Shlomo Havlin', 'arxiv_comment': '35pages, 6 groups of figures', 'links': [{'href': 'http://arxiv.org/abs/1803.03443v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1803.03443v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
397,http://arxiv.org/abs/1803.03428v1,2018-03-09 09:19:16+00:00,2018-03-09 09:19:16+00:00,A Bias Aware News Recommendation System,"[arxiv.Result.Author('Anish Anil Patankar'), arxiv.Result.Author('Joy Bose'), arxiv.Result.Author('Harshit Khanna')]","In this era of fake news and political polarization, it is desirable to have
a system to enable users to access balanced news content. Current solutions
focus on top down, server based approaches to decide whether a news article is
fake or biased, and display only trusted news to the end users. In this paper,
we follow a different approach to help the users make informed choices about
which news they want to read, making users aware in real time of the bias in
news articles they were browsing and recommending news articles from other
sources on the same topic with different levels of bias. We use a recent Pew
research report to collect news sources that readers with varying political
inclinations prefer to read. We then scrape news articles on a variety of
topics from these varied news sources. After this, we perform clustering to
find similar topics of the articles, as well as calculate a bias score for each
article. For a news article the user is currently reading, we display the bias
score and also display other articles on the same topic, out of the previously
collected articles, from different news sources. This we present to the user.
This approach, we hope, would make it possible for users to access more
balanced articles on given news topics. We present the implementation details
of the system along with some preliminary results on news articles.","11 pages, 7 figures",,,cs.IR,"['cs.IR', 'cs.HC', 'H.5.2']","[arxiv.Result.Link('http://arxiv.org/abs/1803.03428v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1803.03428v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1803.03428v1,"{'id': 'http://arxiv.org/abs/1803.03428v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1803.03428v1', 'updated': '2018-03-09T09:19:16Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=9, tm_hour=9, tm_min=19, tm_sec=16, tm_wday=4, tm_yday=68, tm_isdst=0), 'published': '2018-03-09T09:19:16Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=9, tm_hour=9, tm_min=19, tm_sec=16, tm_wday=4, tm_yday=68, tm_isdst=0), 'title': 'A Bias Aware News Recommendation System', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Bias Aware News Recommendation System'}, 'summary': 'In this era of fake news and political polarization, it is desirable to have\na system to enable users to access balanced news content. Current solutions\nfocus on top down, server based approaches to decide whether a news article is\nfake or biased, and display only trusted news to the end users. In this paper,\nwe follow a different approach to help the users make informed choices about\nwhich news they want to read, making users aware in real time of the bias in\nnews articles they were browsing and recommending news articles from other\nsources on the same topic with different levels of bias. We use a recent Pew\nresearch report to collect news sources that readers with varying political\ninclinations prefer to read. We then scrape news articles on a variety of\ntopics from these varied news sources. After this, we perform clustering to\nfind similar topics of the articles, as well as calculate a bias score for each\narticle. For a news article the user is currently reading, we display the bias\nscore and also display other articles on the same topic, out of the previously\ncollected articles, from different news sources. This we present to the user.\nThis approach, we hope, would make it possible for users to access more\nbalanced articles on given news topics. We present the implementation details\nof the system along with some preliminary results on news articles.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this era of fake news and political polarization, it is desirable to have\na system to enable users to access balanced news content. Current solutions\nfocus on top down, server based approaches to decide whether a news article is\nfake or biased, and display only trusted news to the end users. In this paper,\nwe follow a different approach to help the users make informed choices about\nwhich news they want to read, making users aware in real time of the bias in\nnews articles they were browsing and recommending news articles from other\nsources on the same topic with different levels of bias. We use a recent Pew\nresearch report to collect news sources that readers with varying political\ninclinations prefer to read. We then scrape news articles on a variety of\ntopics from these varied news sources. After this, we perform clustering to\nfind similar topics of the articles, as well as calculate a bias score for each\narticle. For a news article the user is currently reading, we display the bias\nscore and also display other articles on the same topic, out of the previously\ncollected articles, from different news sources. This we present to the user.\nThis approach, we hope, would make it possible for users to access more\nbalanced articles on given news topics. We present the implementation details\nof the system along with some preliminary results on news articles.'}, 'authors': [{'name': 'Anish Anil Patankar'}, {'name': 'Joy Bose'}, {'name': 'Harshit Khanna'}], 'author_detail': {'name': 'Harshit Khanna'}, 'author': 'Harshit Khanna', 'arxiv_comment': '11 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/1803.03428v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1803.03428v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
398,http://arxiv.org/abs/1803.01845v1,2018-03-04 20:54:33+00:00,2018-03-04 20:54:33+00:00,"Polarization, Partisanship and Junk News Consumption over Social Media in the US","[arxiv.Result.Author('Vidya Narayanan'), arxiv.Result.Author('Vlad Barash'), arxiv.Result.Author('John Kelly'), arxiv.Result.Author('Bence Kollanyi'), arxiv.Result.Author('Lisa-Maria Neudert'), arxiv.Result.Author('Philip N. Howard')]","What kinds of social media users read junk news? We examine the distribution
of the most significant sources of junk news in the three months before
President Donald Trump first State of the Union Address. Drawing on a list of
sources that consistently publish political news and information that is
extremist, sensationalist, conspiratorial, masked commentary, fake news and
other forms of junk news, we find that the distribution of such content is
unevenly spread across the ideological spectrum. We demonstrate that (1) on
Twitter, a network of Trump supporters shares the widest range of known junk
news sources and circulates more junk news than all the other groups put
together; (2) on Facebook, extreme hard right pages, distinct from Republican
pages, share the widest range of known junk news sources and circulate more
junk news than all the other audiences put together; (3) on average, the
audiences for junk news on Twitter share a wider range of known junk news
sources than audiences on Facebook public pages.",arXiv admin note: text overlap with arXiv:1802.03572,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1803.01845v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1803.01845v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1803.01845v1,"{'id': 'http://arxiv.org/abs/1803.01845v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1803.01845v1', 'updated': '2018-03-04T20:54:33Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=4, tm_hour=20, tm_min=54, tm_sec=33, tm_wday=6, tm_yday=63, tm_isdst=0), 'published': '2018-03-04T20:54:33Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=4, tm_hour=20, tm_min=54, tm_sec=33, tm_wday=6, tm_yday=63, tm_isdst=0), 'title': 'Polarization, Partisanship and Junk News Consumption over Social Media\n  in the US', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Polarization, Partisanship and Junk News Consumption over Social Media\n  in the US'}, 'summary': 'What kinds of social media users read junk news? We examine the distribution\nof the most significant sources of junk news in the three months before\nPresident Donald Trump first State of the Union Address. Drawing on a list of\nsources that consistently publish political news and information that is\nextremist, sensationalist, conspiratorial, masked commentary, fake news and\nother forms of junk news, we find that the distribution of such content is\nunevenly spread across the ideological spectrum. We demonstrate that (1) on\nTwitter, a network of Trump supporters shares the widest range of known junk\nnews sources and circulates more junk news than all the other groups put\ntogether; (2) on Facebook, extreme hard right pages, distinct from Republican\npages, share the widest range of known junk news sources and circulate more\njunk news than all the other audiences put together; (3) on average, the\naudiences for junk news on Twitter share a wider range of known junk news\nsources than audiences on Facebook public pages.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What kinds of social media users read junk news? We examine the distribution\nof the most significant sources of junk news in the three months before\nPresident Donald Trump first State of the Union Address. Drawing on a list of\nsources that consistently publish political news and information that is\nextremist, sensationalist, conspiratorial, masked commentary, fake news and\nother forms of junk news, we find that the distribution of such content is\nunevenly spread across the ideological spectrum. We demonstrate that (1) on\nTwitter, a network of Trump supporters shares the widest range of known junk\nnews sources and circulates more junk news than all the other groups put\ntogether; (2) on Facebook, extreme hard right pages, distinct from Republican\npages, share the widest range of known junk news sources and circulate more\njunk news than all the other audiences put together; (3) on average, the\naudiences for junk news on Twitter share a wider range of known junk news\nsources than audiences on Facebook public pages.'}, 'authors': [{'name': 'Vidya Narayanan'}, {'name': 'Vlad Barash'}, {'name': 'John Kelly'}, {'name': 'Bence Kollanyi'}, {'name': 'Lisa-Maria Neudert'}, {'name': 'Philip N. Howard'}], 'author_detail': {'name': 'Philip N. Howard'}, 'author': 'Philip N. Howard', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1802.03572', 'links': [{'href': 'http://arxiv.org/abs/1803.01845v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1803.01845v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
399,http://arxiv.org/abs/1802.07398v2,2018-09-16 23:33:45+00:00,2018-02-21 01:52:01+00:00,Investigating Rumor News Using Agreement-Aware Search,"[arxiv.Result.Author('Jingbo Shang'), arxiv.Result.Author('Tianhang Sun'), arxiv.Result.Author('Jiaming Shen'), arxiv.Result.Author('Xingbang Liu'), arxiv.Result.Author('Anja Gruenheid'), arxiv.Result.Author('Flip Korn'), arxiv.Result.Author('Adam Lelkes'), arxiv.Result.Author('Cong Yu'), arxiv.Result.Author('Jiawei Han')]","Recent years have witnessed a widespread increase of rumor news generated by
humans and machines. Therefore, tools for investigating rumor news have become
an urgent necessity. One useful function of such tools is to see ways a
specific topic or event is represented by presenting different points of view
from multiple sources.
  In this paper, we propose Maester, a novel agreement-aware search framework
for investigating rumor news. Given an investigative question, Maester will
retrieve related articles to that question, assign and display top articles
from agree, disagree, and discuss categories to users. Splitting the results
into these three categories provides the user a holistic view towards the
investigative question. We build Maester based on the following two key
observations: (1) relatedness can commonly be determined by keywords and
entities occurring in both questions and articles, and (2) the level of
agreement between the investigative question and the related news article can
often be decided by a few key sentences. Accordingly, we use gradient boosting
tree models with keyword/entity matching features for relatedness detection,
and leverage recurrent neural network to infer the level of agreement. Our
experiments on the Fake News Challenge (FNC) dataset demonstrate up to an order
of magnitude improvement of Maester over the original FNC winning solution, for
agreement-aware search.",,,10.1145/3269206.3272020,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3269206.3272020', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1802.07398v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.07398v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.07398v2,"{'id': 'http://arxiv.org/abs/1802.07398v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.07398v2', 'updated': '2018-09-16T23:33:45Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=16, tm_hour=23, tm_min=33, tm_sec=45, tm_wday=6, tm_yday=259, tm_isdst=0), 'published': '2018-02-21T01:52:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=21, tm_hour=1, tm_min=52, tm_sec=1, tm_wday=2, tm_yday=52, tm_isdst=0), 'title': 'Investigating Rumor News Using Agreement-Aware Search', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Rumor News Using Agreement-Aware Search'}, 'summary': 'Recent years have witnessed a widespread increase of rumor news generated by\nhumans and machines. Therefore, tools for investigating rumor news have become\nan urgent necessity. One useful function of such tools is to see ways a\nspecific topic or event is represented by presenting different points of view\nfrom multiple sources.\n  In this paper, we propose Maester, a novel agreement-aware search framework\nfor investigating rumor news. Given an investigative question, Maester will\nretrieve related articles to that question, assign and display top articles\nfrom agree, disagree, and discuss categories to users. Splitting the results\ninto these three categories provides the user a holistic view towards the\ninvestigative question. We build Maester based on the following two key\nobservations: (1) relatedness can commonly be determined by keywords and\nentities occurring in both questions and articles, and (2) the level of\nagreement between the investigative question and the related news article can\noften be decided by a few key sentences. Accordingly, we use gradient boosting\ntree models with keyword/entity matching features for relatedness detection,\nand leverage recurrent neural network to infer the level of agreement. Our\nexperiments on the Fake News Challenge (FNC) dataset demonstrate up to an order\nof magnitude improvement of Maester over the original FNC winning solution, for\nagreement-aware search.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed a widespread increase of rumor news generated by\nhumans and machines. Therefore, tools for investigating rumor news have become\nan urgent necessity. One useful function of such tools is to see ways a\nspecific topic or event is represented by presenting different points of view\nfrom multiple sources.\n  In this paper, we propose Maester, a novel agreement-aware search framework\nfor investigating rumor news. Given an investigative question, Maester will\nretrieve related articles to that question, assign and display top articles\nfrom agree, disagree, and discuss categories to users. Splitting the results\ninto these three categories provides the user a holistic view towards the\ninvestigative question. We build Maester based on the following two key\nobservations: (1) relatedness can commonly be determined by keywords and\nentities occurring in both questions and articles, and (2) the level of\nagreement between the investigative question and the related news article can\noften be decided by a few key sentences. Accordingly, we use gradient boosting\ntree models with keyword/entity matching features for relatedness detection,\nand leverage recurrent neural network to infer the level of agreement. Our\nexperiments on the Fake News Challenge (FNC) dataset demonstrate up to an order\nof magnitude improvement of Maester over the original FNC winning solution, for\nagreement-aware search.'}, 'authors': [{'name': 'Jingbo Shang'}, {'name': 'Tianhang Sun'}, {'name': 'Jiaming Shen'}, {'name': 'Xingbang Liu'}, {'name': 'Anja Gruenheid'}, {'name': 'Flip Korn'}, {'name': 'Adam Lelkes'}, {'name': 'Cong Yu'}, {'name': 'Jiawei Han'}], 'author_detail': {'name': 'Jiawei Han'}, 'author': 'Jiawei Han', 'arxiv_doi': '10.1145/3269206.3272020', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3269206.3272020', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1802.07398v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.07398v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
400,http://arxiv.org/abs/1802.01400v1,2018-02-05 14:17:21+00:00,2018-02-05 14:17:21+00:00,Polarization and Fake News: Early Warning of Potential Misinformation Targets,"[arxiv.Result.Author('Michela Del Vicario'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Antonio Scala'), arxiv.Result.Author('Fabiana Zollo')]","Users polarization and confirmation bias play a key role in misinformation
spreading on online social media. Our aim is to use this information to
determine in advance potential targets for hoaxes and fake news. In this paper,
we introduce a general framework for promptly identifying polarizing content on
social media and, thus, ""predicting"" future fake news topics. We validate the
performances of the proposed methodology on a massive Italian Facebook dataset,
showing that we are able to identify topics that are susceptible to
misinformation with 77% accuracy. Moreover, such information may be embedded as
a new feature in an additional classifier able to recognize fake news with 91%
accuracy. The novelty of our approach consists in taking into account a series
of characteristics related to users behavior on online social media, making a
first, important step towards the smoothing of polarization and the mitigation
of misinformation phenomena.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1802.01400v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.01400v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.01400v1,"{'id': 'http://arxiv.org/abs/1802.01400v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.01400v1', 'updated': '2018-02-05T14:17:21Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=5, tm_hour=14, tm_min=17, tm_sec=21, tm_wday=0, tm_yday=36, tm_isdst=0), 'published': '2018-02-05T14:17:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=5, tm_hour=14, tm_min=17, tm_sec=21, tm_wday=0, tm_yday=36, tm_isdst=0), 'title': 'Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets'}, 'summary': 'Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, ""predicting"" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, ""predicting"" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.'}, 'authors': [{'name': 'Michela Del Vicario'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Antonio Scala'}, {'name': 'Fabiana Zollo'}], 'author_detail': {'name': 'Fabiana Zollo'}, 'author': 'Fabiana Zollo', 'links': [{'href': 'http://arxiv.org/abs/1802.01400v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.01400v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
401,http://arxiv.org/abs/1802.00156v1,2018-02-01 05:11:09+00:00,2018-02-01 05:11:09+00:00,The Great Division,"[arxiv.Result.Author('Yu Wang'), arxiv.Result.Author('Jiebo Luo')]","When information flow fails, when Democrats and Republicans do not talk to
each other, when Israelis and Palestinians do not talk to each other, and when
North Koreans and South Koreans do not talk to each other, mis-perceptions,
biases and fake news arise. In this paper we present an in-depth study of
political polarization and social division using Twitter data and Monte Carlo
simulations. First, we study at the aggregate level people's inclination to
retweet within their own ideological circle. Introducing the concept of cocoon
ratio, we show that Donald Trump's followers are 2.56 more likely to retweet a
fellow Trump follower than to retweet a Hillary Clinton follower. Second, going
down to the individual level, we show that the tendency of retweeting
exclusively within one's ideological circle is stronger for women than for men
and that such tendency weakens as one's social capital grows. Third, we use a
one-dimensional Ising model to simulate how a society with high cocoon ratios
could end up becoming completely divided. We conclude with a discussion of our
findings with respect to fake news.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1802.00156v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.00156v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.00156v1,"{'id': 'http://arxiv.org/abs/1802.00156v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.00156v1', 'updated': '2018-02-01T05:11:09Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=1, tm_hour=5, tm_min=11, tm_sec=9, tm_wday=3, tm_yday=32, tm_isdst=0), 'published': '2018-02-01T05:11:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=1, tm_hour=5, tm_min=11, tm_sec=9, tm_wday=3, tm_yday=32, tm_isdst=0), 'title': 'The Great Division', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Great Division'}, 'summary': ""When information flow fails, when Democrats and Republicans do not talk to\neach other, when Israelis and Palestinians do not talk to each other, and when\nNorth Koreans and South Koreans do not talk to each other, mis-perceptions,\nbiases and fake news arise. In this paper we present an in-depth study of\npolitical polarization and social division using Twitter data and Monte Carlo\nsimulations. First, we study at the aggregate level people's inclination to\nretweet within their own ideological circle. Introducing the concept of cocoon\nratio, we show that Donald Trump's followers are 2.56 more likely to retweet a\nfellow Trump follower than to retweet a Hillary Clinton follower. Second, going\ndown to the individual level, we show that the tendency of retweeting\nexclusively within one's ideological circle is stronger for women than for men\nand that such tendency weakens as one's social capital grows. Third, we use a\none-dimensional Ising model to simulate how a society with high cocoon ratios\ncould end up becoming completely divided. We conclude with a discussion of our\nfindings with respect to fake news."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""When information flow fails, when Democrats and Republicans do not talk to\neach other, when Israelis and Palestinians do not talk to each other, and when\nNorth Koreans and South Koreans do not talk to each other, mis-perceptions,\nbiases and fake news arise. In this paper we present an in-depth study of\npolitical polarization and social division using Twitter data and Monte Carlo\nsimulations. First, we study at the aggregate level people's inclination to\nretweet within their own ideological circle. Introducing the concept of cocoon\nratio, we show that Donald Trump's followers are 2.56 more likely to retweet a\nfellow Trump follower than to retweet a Hillary Clinton follower. Second, going\ndown to the individual level, we show that the tendency of retweeting\nexclusively within one's ideological circle is stronger for women than for men\nand that such tendency weakens as one's social capital grows. Third, we use a\none-dimensional Ising model to simulate how a society with high cocoon ratios\ncould end up becoming completely divided. We conclude with a discussion of our\nfindings with respect to fake news.""}, 'authors': [{'name': 'Yu Wang'}, {'name': 'Jiebo Luo'}], 'author_detail': {'name': 'Jiebo Luo'}, 'author': 'Jiebo Luo', 'links': [{'href': 'http://arxiv.org/abs/1802.00156v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.00156v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
402,http://arxiv.org/abs/1801.08159v1,2018-01-24 19:38:00+00:00,2018-01-24 19:38:00+00:00,Adversarial Classification on Social Networks,"[arxiv.Result.Author('Sixie Yu'), arxiv.Result.Author('Yevgeniy Vorobeychik'), arxiv.Result.Author('Scott Alfeld')]","The spread of unwanted or malicious content through social media has become a
major challenge. Traditional examples of this include social network spam, but
an important new concern is the propagation of fake news through social media.
A common approach for mitigating this problem is by using standard statistical
classification to distinguish malicious (e.g., fake news) instances from benign
(e.g., actual news stories). However, such an approach ignores the fact that
malicious instances propagate through the network, which is consequential both
in quantifying consequences (e.g., fake news diffusing through the network),
and capturing detection redundancy (bad content can be detected at different
nodes). An additional concern is evasion attacks, whereby the generators of
malicious instances modify the nature of these to escape detection. We model
this problem as a Stackelberg game between the defender who is choosing
parameters of the detection model, and an attacker, who is choosing both the
node at which to initiate malicious spread, and the nature of malicious
entities. We develop a novel bi-level programming approach for this problem, as
well as a novel solution approach based on implicit function gradients, and
experimentally demonstrate the advantage of our approach over alternatives
which ignore network structure.",,,,cs.MA,"['cs.MA', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1801.08159v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1801.08159v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1801.08159v1,"{'id': 'http://arxiv.org/abs/1801.08159v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1801.08159v1', 'updated': '2018-01-24T19:38:00Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=38, tm_sec=0, tm_wday=2, tm_yday=24, tm_isdst=0), 'published': '2018-01-24T19:38:00Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=38, tm_sec=0, tm_wday=2, tm_yday=24, tm_isdst=0), 'title': 'Adversarial Classification on Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversarial Classification on Social Networks'}, 'summary': 'The spread of unwanted or malicious content through social media has become a\nmajor challenge. Traditional examples of this include social network spam, but\nan important new concern is the propagation of fake news through social media.\nA common approach for mitigating this problem is by using standard statistical\nclassification to distinguish malicious (e.g., fake news) instances from benign\n(e.g., actual news stories). However, such an approach ignores the fact that\nmalicious instances propagate through the network, which is consequential both\nin quantifying consequences (e.g., fake news diffusing through the network),\nand capturing detection redundancy (bad content can be detected at different\nnodes). An additional concern is evasion attacks, whereby the generators of\nmalicious instances modify the nature of these to escape detection. We model\nthis problem as a Stackelberg game between the defender who is choosing\nparameters of the detection model, and an attacker, who is choosing both the\nnode at which to initiate malicious spread, and the nature of malicious\nentities. We develop a novel bi-level programming approach for this problem, as\nwell as a novel solution approach based on implicit function gradients, and\nexperimentally demonstrate the advantage of our approach over alternatives\nwhich ignore network structure.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of unwanted or malicious content through social media has become a\nmajor challenge. Traditional examples of this include social network spam, but\nan important new concern is the propagation of fake news through social media.\nA common approach for mitigating this problem is by using standard statistical\nclassification to distinguish malicious (e.g., fake news) instances from benign\n(e.g., actual news stories). However, such an approach ignores the fact that\nmalicious instances propagate through the network, which is consequential both\nin quantifying consequences (e.g., fake news diffusing through the network),\nand capturing detection redundancy (bad content can be detected at different\nnodes). An additional concern is evasion attacks, whereby the generators of\nmalicious instances modify the nature of these to escape detection. We model\nthis problem as a Stackelberg game between the defender who is choosing\nparameters of the detection model, and an attacker, who is choosing both the\nnode at which to initiate malicious spread, and the nature of malicious\nentities. We develop a novel bi-level programming approach for this problem, as\nwell as a novel solution approach based on implicit function gradients, and\nexperimentally demonstrate the advantage of our approach over alternatives\nwhich ignore network structure.'}, 'authors': [{'name': 'Sixie Yu'}, {'name': 'Yevgeniy Vorobeychik'}, {'name': 'Scott Alfeld'}], 'author_detail': {'name': 'Scott Alfeld'}, 'author': 'Scott Alfeld', 'links': [{'href': 'http://arxiv.org/abs/1801.08159v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1801.08159v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
403,http://arxiv.org/abs/1801.06510v2,2018-01-23 14:41:34+00:00,2018-01-19 17:54:22+00:00,Image Provenance Analysis at Scale,"[arxiv.Result.Author('Daniel Moreira'), arxiv.Result.Author('Aparna Bharati'), arxiv.Result.Author('Joel Brogan'), arxiv.Result.Author('Allan Pinto'), arxiv.Result.Author('Michael Parowski'), arxiv.Result.Author('Kevin W. Bowyer'), arxiv.Result.Author('Patrick J. Flynn'), arxiv.Result.Author('Anderson Rocha'), arxiv.Result.Author('Walter J. Scheirer')]","Prior art has shown it is possible to estimate, through image processing and
computer vision techniques, the types and parameters of transformations that
have been applied to the content of individual images to obtain new images.
Given a large corpus of images and a query image, an interesting further step
is to retrieve the set of original images whose content is present in the query
image, as well as the detailed sequences of transformations that yield the
query image given the original images. This is a problem that recently has
received the name of image provenance analysis. In these times of public media
manipulation ( e.g., fake news and meme sharing), obtaining the history of
image transformations is relevant for fact checking and authorship
verification, among many other applications. This article presents an
end-to-end processing pipeline for image provenance analysis, which works at
real-world scale. It employs a cutting-edge image filtering solution that is
custom-tailored for the problem at hand, as well as novel techniques for
obtaining the provenance graph that expresses how the images, as nodes, are
ancestrally connected. A comprehensive set of experiments for each stage of the
pipeline is provided, comparing the proposed solution with state-of-the-art
results, employing previously published datasets. In addition, this work
introduces a new dataset of real-world provenance cases from the social media
site Reddit, along with baseline results.","13 pages, 6 figures",,,cs.CV,"['cs.CV', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1801.06510v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1801.06510v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1801.06510v2,"{'id': 'http://arxiv.org/abs/1801.06510v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1801.06510v2', 'updated': '2018-01-23T14:41:34Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=23, tm_hour=14, tm_min=41, tm_sec=34, tm_wday=1, tm_yday=23, tm_isdst=0), 'published': '2018-01-19T17:54:22Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=19, tm_hour=17, tm_min=54, tm_sec=22, tm_wday=4, tm_yday=19, tm_isdst=0), 'title': 'Image Provenance Analysis at Scale', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Image Provenance Analysis at Scale'}, 'summary': 'Prior art has shown it is possible to estimate, through image processing and\ncomputer vision techniques, the types and parameters of transformations that\nhave been applied to the content of individual images to obtain new images.\nGiven a large corpus of images and a query image, an interesting further step\nis to retrieve the set of original images whose content is present in the query\nimage, as well as the detailed sequences of transformations that yield the\nquery image given the original images. This is a problem that recently has\nreceived the name of image provenance analysis. In these times of public media\nmanipulation ( e.g., fake news and meme sharing), obtaining the history of\nimage transformations is relevant for fact checking and authorship\nverification, among many other applications. This article presents an\nend-to-end processing pipeline for image provenance analysis, which works at\nreal-world scale. It employs a cutting-edge image filtering solution that is\ncustom-tailored for the problem at hand, as well as novel techniques for\nobtaining the provenance graph that expresses how the images, as nodes, are\nancestrally connected. A comprehensive set of experiments for each stage of the\npipeline is provided, comparing the proposed solution with state-of-the-art\nresults, employing previously published datasets. In addition, this work\nintroduces a new dataset of real-world provenance cases from the social media\nsite Reddit, along with baseline results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Prior art has shown it is possible to estimate, through image processing and\ncomputer vision techniques, the types and parameters of transformations that\nhave been applied to the content of individual images to obtain new images.\nGiven a large corpus of images and a query image, an interesting further step\nis to retrieve the set of original images whose content is present in the query\nimage, as well as the detailed sequences of transformations that yield the\nquery image given the original images. This is a problem that recently has\nreceived the name of image provenance analysis. In these times of public media\nmanipulation ( e.g., fake news and meme sharing), obtaining the history of\nimage transformations is relevant for fact checking and authorship\nverification, among many other applications. This article presents an\nend-to-end processing pipeline for image provenance analysis, which works at\nreal-world scale. It employs a cutting-edge image filtering solution that is\ncustom-tailored for the problem at hand, as well as novel techniques for\nobtaining the provenance graph that expresses how the images, as nodes, are\nancestrally connected. A comprehensive set of experiments for each stage of the\npipeline is provided, comparing the proposed solution with state-of-the-art\nresults, employing previously published datasets. In addition, this work\nintroduces a new dataset of real-world provenance cases from the social media\nsite Reddit, along with baseline results.'}, 'authors': [{'name': 'Daniel Moreira'}, {'name': 'Aparna Bharati'}, {'name': 'Joel Brogan'}, {'name': 'Allan Pinto'}, {'name': 'Michael Parowski'}, {'name': 'Kevin W. Bowyer'}, {'name': 'Patrick J. Flynn'}, {'name': 'Anderson Rocha'}, {'name': 'Walter J. Scheirer'}], 'author_detail': {'name': 'Walter J. Scheirer'}, 'author': 'Walter J. Scheirer', 'arxiv_comment': '13 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/1801.06510v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1801.06510v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
404,http://arxiv.org/abs/1801.06122v1,2018-01-18 16:54:01+00:00,2018-01-18 16:54:01+00:00,Anatomy of an online misinformation network,"[arxiv.Result.Author('Chengcheng Shao'), arxiv.Result.Author('Pik-Mai Hui'), arxiv.Result.Author('Lei Wang'), arxiv.Result.Author('Xinwen Jiang'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Giovanni Luca Ciampaglia')]","Massive amounts of fake news and conspiratorial content have spread over
social media before and after the 2016 US Presidential Elections despite
intense fact-checking efforts. How do the spread of misinformation and
fact-checking compete? What are the structural and dynamic characteristics of
the core of the misinformation diffusion network, and who are its main
purveyors? How to reduce the overall amount of misinformation? To explore these
questions we built Hoaxy, an open platform that enables large-scale, systematic
studies of how misinformation and fact-checking spread and compete on Twitter.
Hoaxy filters public tweets that include links to unverified claims or
fact-checking articles. We perform k-core decomposition on a diffusion network
obtained from two million retweets produced by several hundred thousand
accounts over the six months before the election. As we move from the periphery
to the core of the network, fact-checking nearly disappears, while social bots
proliferate. The number of users in the main core reaches equilibrium around
the time of the election, with limited churn and increasingly dense
connections. We conclude by quantifying how effectively the network can be
disrupted by penalizing the most central nodes. These findings provide a first
look at the anatomy of a massive online misinformation diffusion network.","28 pages, 11 figures, submitted to PLOS ONE","PLoS ONE, 13(4): e0196087. 2018",10.1371/journal.pone.0196087,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0196087', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1801.06122v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1801.06122v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1801.06122v1,"{'id': 'http://arxiv.org/abs/1801.06122v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1801.06122v1', 'updated': '2018-01-18T16:54:01Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=18, tm_hour=16, tm_min=54, tm_sec=1, tm_wday=3, tm_yday=18, tm_isdst=0), 'published': '2018-01-18T16:54:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=18, tm_hour=16, tm_min=54, tm_sec=1, tm_wday=3, tm_yday=18, tm_isdst=0), 'title': 'Anatomy of an online misinformation network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Anatomy of an online misinformation network'}, 'summary': 'Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.'}, 'authors': [{'name': 'Chengcheng Shao'}, {'name': 'Pik-Mai Hui'}, {'name': 'Lei Wang'}, {'name': 'Xinwen Jiang'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}, {'name': 'Giovanni Luca Ciampaglia'}], 'author_detail': {'name': 'Giovanni Luca Ciampaglia'}, 'author': 'Giovanni Luca Ciampaglia', 'arxiv_doi': '10.1371/journal.pone.0196087', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0196087', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1801.06122v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1801.06122v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '28 pages, 11 figures, submitted to PLOS ONE', 'arxiv_journal_ref': 'PLoS ONE, 13(4): e0196087. 2018', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
405,http://arxiv.org/abs/1712.07709v2,2018-12-10 00:02:16+00:00,2017-12-20 21:03:54+00:00,Beyond News Contents: The Role of Social Context for Fake News Detection,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Huan Liu')]","Social media is becoming popular for news consumption due to its fast
dissemination, easy access, and low cost. However, it also enables the wide
propagation of fake news, i.e., news with intentionally false information.
Detecting fake news is an important task, which not only ensures users to
receive authentic information but also help maintain a trustworthy news
ecosystem. The majority of existing detection algorithms focus on finding clues
from news contents, which are generally not effective because fake news is
often intentionally written to mislead users by mimicking true news. Therefore,
we need to explore auxiliary information to improve detection. The social
context during news dissemination process on social media forms the inherent
tri-relationship, the relationship among publishers, news pieces, and users,
which has potential to improve fake news detection. For example,
partisan-biased publishers are more likely to publish fake news, and
low-credible users are more likely to share fake news. In this paper, we study
the novel problem of exploiting social context for fake news detection. We
propose a tri-relationship embedding framework TriFN, which models
publisher-news relations and user-news interactions simultaneously for fake
news classification. We conduct experiments on two real-world datasets, which
demonstrate that the proposed approach significantly outperforms other baseline
methods for fake news detection.","In Proceedings of 12th ACM International Conference on Web Search and
  Data Mining (WSDM 2019)",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1712.07709v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1712.07709v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1712.07709v2,"{'id': 'http://arxiv.org/abs/1712.07709v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1712.07709v2', 'updated': '2018-12-10T00:02:16Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=10, tm_hour=0, tm_min=2, tm_sec=16, tm_wday=0, tm_yday=344, tm_isdst=0), 'published': '2017-12-20T21:03:54Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=20, tm_hour=21, tm_min=3, tm_sec=54, tm_wday=2, tm_yday=354, tm_isdst=0), 'title': 'Beyond News Contents: The Role of Social Context for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Beyond News Contents: The Role of Social Context for Fake News Detection'}, 'summary': 'Social media is becoming popular for news consumption due to its fast\ndissemination, easy access, and low cost. However, it also enables the wide\npropagation of fake news, i.e., news with intentionally false information.\nDetecting fake news is an important task, which not only ensures users to\nreceive authentic information but also help maintain a trustworthy news\necosystem. The majority of existing detection algorithms focus on finding clues\nfrom news contents, which are generally not effective because fake news is\noften intentionally written to mislead users by mimicking true news. Therefore,\nwe need to explore auxiliary information to improve detection. The social\ncontext during news dissemination process on social media forms the inherent\ntri-relationship, the relationship among publishers, news pieces, and users,\nwhich has potential to improve fake news detection. For example,\npartisan-biased publishers are more likely to publish fake news, and\nlow-credible users are more likely to share fake news. In this paper, we study\nthe novel problem of exploiting social context for fake news detection. We\npropose a tri-relationship embedding framework TriFN, which models\npublisher-news relations and user-news interactions simultaneously for fake\nnews classification. We conduct experiments on two real-world datasets, which\ndemonstrate that the proposed approach significantly outperforms other baseline\nmethods for fake news detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media is becoming popular for news consumption due to its fast\ndissemination, easy access, and low cost. However, it also enables the wide\npropagation of fake news, i.e., news with intentionally false information.\nDetecting fake news is an important task, which not only ensures users to\nreceive authentic information but also help maintain a trustworthy news\necosystem. The majority of existing detection algorithms focus on finding clues\nfrom news contents, which are generally not effective because fake news is\noften intentionally written to mislead users by mimicking true news. Therefore,\nwe need to explore auxiliary information to improve detection. The social\ncontext during news dissemination process on social media forms the inherent\ntri-relationship, the relationship among publishers, news pieces, and users,\nwhich has potential to improve fake news detection. For example,\npartisan-biased publishers are more likely to publish fake news, and\nlow-credible users are more likely to share fake news. In this paper, we study\nthe novel problem of exploiting social context for fake news detection. We\npropose a tri-relationship embedding framework TriFN, which models\npublisher-news relations and user-news interactions simultaneously for fake\nnews classification. We conduct experiments on two real-world datasets, which\ndemonstrate that the proposed approach significantly outperforms other baseline\nmethods for fake news detection.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Suhang Wang'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'In Proceedings of 12th ACM International Conference on Web Search and\n  Data Mining (WSDM 2019)', 'links': [{'href': 'http://arxiv.org/abs/1712.07709v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1712.07709v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
406,http://arxiv.org/abs/1712.05999v1,2017-12-16 18:07:58+00:00,2017-12-16 18:07:58+00:00,Characterizing Political Fake News in Twitter by its Meta-Data,"[arxiv.Result.Author('Julio Amador'), arxiv.Result.Author('Axel Oehmichen'), arxiv.Result.Author('Miguel Molina-Solana')]","This article presents a preliminary approach towards characterizing political
fake news on Twitter through the analysis of their meta-data. In particular, we
focus on more than 1.5M tweets collected on the day of the election of Donald
Trump as 45th president of the United States of America. We use the meta-data
embedded within those tweets in order to look for differences between tweets
containing fake news and tweets not containing them. Specifically, we perform
our analysis only on tweets that went viral, by studying proxies for users'
exposure to the tweets, by characterizing accounts spreading fake news, and by
looking at their polarization. We found significant differences on the
distribution of followers, the number of URLs on tweets, and the verification
of the users.",,,,cs.CL,"['cs.CL', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1712.05999v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1712.05999v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1712.05999v1,"{'id': 'http://arxiv.org/abs/1712.05999v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1712.05999v1', 'updated': '2017-12-16T18:07:58Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=16, tm_hour=18, tm_min=7, tm_sec=58, tm_wday=5, tm_yday=350, tm_isdst=0), 'published': '2017-12-16T18:07:58Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=16, tm_hour=18, tm_min=7, tm_sec=58, tm_wday=5, tm_yday=350, tm_isdst=0), 'title': 'Characterizing Political Fake News in Twitter by its Meta-Data', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing Political Fake News in Twitter by its Meta-Data'}, 'summary': ""This article presents a preliminary approach towards characterizing political\nfake news on Twitter through the analysis of their meta-data. In particular, we\nfocus on more than 1.5M tweets collected on the day of the election of Donald\nTrump as 45th president of the United States of America. We use the meta-data\nembedded within those tweets in order to look for differences between tweets\ncontaining fake news and tweets not containing them. Specifically, we perform\nour analysis only on tweets that went viral, by studying proxies for users'\nexposure to the tweets, by characterizing accounts spreading fake news, and by\nlooking at their polarization. We found significant differences on the\ndistribution of followers, the number of URLs on tweets, and the verification\nof the users."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This article presents a preliminary approach towards characterizing political\nfake news on Twitter through the analysis of their meta-data. In particular, we\nfocus on more than 1.5M tweets collected on the day of the election of Donald\nTrump as 45th president of the United States of America. We use the meta-data\nembedded within those tweets in order to look for differences between tweets\ncontaining fake news and tweets not containing them. Specifically, we perform\nour analysis only on tweets that went viral, by studying proxies for users'\nexposure to the tweets, by characterizing accounts spreading fake news, and by\nlooking at their polarization. We found significant differences on the\ndistribution of followers, the number of URLs on tweets, and the verification\nof the users.""}, 'authors': [{'name': 'Julio Amador'}, {'name': 'Axel Oehmichen'}, {'name': 'Miguel Molina-Solana'}], 'author_detail': {'name': 'Miguel Molina-Solana'}, 'author': 'Miguel Molina-Solana', 'links': [{'href': 'http://arxiv.org/abs/1712.05999v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1712.05999v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
407,http://arxiv.org/abs/1712.03935v1,2017-12-11 18:32:11+00:00,2017-12-11 18:32:11+00:00,"On the Benefit of Combining Neural, Statistical and External Features for Fake News Identification","[arxiv.Result.Author('Gaurav Bhatt'), arxiv.Result.Author('Aman Sharma'), arxiv.Result.Author('Shivam Sharma'), arxiv.Result.Author('Ankush Nagpal'), arxiv.Result.Author('Balasubramanian Raman'), arxiv.Result.Author('Ankush Mittal')]","Identifying the veracity of a news article is an interesting problem while
automating this process can be a challenging task. Detection of a news article
as fake is still an open question as it is contingent on many factors which the
current state-of-the-art models fail to incorporate. In this paper, we explore
a subtask to fake news identification, and that is stance detection. Given a
news article, the task is to determine the relevance of the body and its claim.
We present a novel idea that combines the neural, statistical and external
features to provide an efficient solution to this problem. We compute the
neural embedding from the deep recurrent model, statistical features from the
weighted n-gram bag-of-words model and handcrafted external features with the
help of feature engineering heuristics. Finally, using deep neural layer all
the features are combined, thereby classifying the headline-body news pair as
agree, disagree, discuss, or unrelated. We compare our proposed technique with
the current state-of-the-art models on the fake news challenge dataset. Through
extensive experiments, we find that the proposed model outperforms all the
state-of-the-art techniques including the submissions to the fake news
challenge.",Source code available at - www.deeplearn-ai.com,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1712.03935v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1712.03935v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1712.03935v1,"{'id': 'http://arxiv.org/abs/1712.03935v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1712.03935v1', 'updated': '2017-12-11T18:32:11Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=11, tm_hour=18, tm_min=32, tm_sec=11, tm_wday=0, tm_yday=345, tm_isdst=0), 'published': '2017-12-11T18:32:11Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=11, tm_hour=18, tm_min=32, tm_sec=11, tm_wday=0, tm_yday=345, tm_isdst=0), 'title': 'On the Benefit of Combining Neural, Statistical and External Features\n  for Fake News Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the Benefit of Combining Neural, Statistical and External Features\n  for Fake News Identification'}, 'summary': 'Identifying the veracity of a news article is an interesting problem while\nautomating this process can be a challenging task. Detection of a news article\nas fake is still an open question as it is contingent on many factors which the\ncurrent state-of-the-art models fail to incorporate. In this paper, we explore\na subtask to fake news identification, and that is stance detection. Given a\nnews article, the task is to determine the relevance of the body and its claim.\nWe present a novel idea that combines the neural, statistical and external\nfeatures to provide an efficient solution to this problem. We compute the\nneural embedding from the deep recurrent model, statistical features from the\nweighted n-gram bag-of-words model and handcrafted external features with the\nhelp of feature engineering heuristics. Finally, using deep neural layer all\nthe features are combined, thereby classifying the headline-body news pair as\nagree, disagree, discuss, or unrelated. We compare our proposed technique with\nthe current state-of-the-art models on the fake news challenge dataset. Through\nextensive experiments, we find that the proposed model outperforms all the\nstate-of-the-art techniques including the submissions to the fake news\nchallenge.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying the veracity of a news article is an interesting problem while\nautomating this process can be a challenging task. Detection of a news article\nas fake is still an open question as it is contingent on many factors which the\ncurrent state-of-the-art models fail to incorporate. In this paper, we explore\na subtask to fake news identification, and that is stance detection. Given a\nnews article, the task is to determine the relevance of the body and its claim.\nWe present a novel idea that combines the neural, statistical and external\nfeatures to provide an efficient solution to this problem. We compute the\nneural embedding from the deep recurrent model, statistical features from the\nweighted n-gram bag-of-words model and handcrafted external features with the\nhelp of feature engineering heuristics. Finally, using deep neural layer all\nthe features are combined, thereby classifying the headline-body news pair as\nagree, disagree, discuss, or unrelated. We compare our proposed technique with\nthe current state-of-the-art models on the fake news challenge dataset. Through\nextensive experiments, we find that the proposed model outperforms all the\nstate-of-the-art techniques including the submissions to the fake news\nchallenge.'}, 'authors': [{'name': 'Gaurav Bhatt'}, {'name': 'Aman Sharma'}, {'name': 'Shivam Sharma'}, {'name': 'Ankush Nagpal'}, {'name': 'Balasubramanian Raman'}, {'name': 'Ankush Mittal'}], 'author_detail': {'name': 'Ankush Mittal'}, 'author': 'Ankush Mittal', 'arxiv_comment': 'Source code available at - www.deeplearn-ai.com', 'links': [{'href': 'http://arxiv.org/abs/1712.03935v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1712.03935v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
408,http://arxiv.org/abs/1711.10720v1,2017-11-29 08:22:31+00:00,2017-11-29 08:22:31+00:00,Organized Behavior Classification of Tweet Sets using Supervised Learning Methods,"[arxiv.Result.Author('Erdem Beğenilmiş'), arxiv.Result.Author('Suzan Üsküdarlı')]","During the 2016 US elections Twitter experienced unprecedented levels of
propaganda and fake news through the collaboration of bots and hired persons,
the ramifications of which are still being debated. This work proposes an
approach to identify the presence of organized behavior in tweets. The Random
Forest, Support Vector Machine, and Logistic Regression algorithms are each
used to train a model with a data set of 850 records consisting of 299 features
extracted from tweets gathered during the 2016 US presidential election. The
features represent user and temporal synchronization characteristics to capture
coordinated behavior. These models are trained to classify tweet sets among the
categories: organic vs organized, political vs non-political, and pro-Trump vs
pro-Hillary vs neither. The random forest algorithm performs better with
greater than 95% average accuracy and f-measure scores for each category. The
most valuable features for classification are identified as user based
features, with media use and marking tweets as favorite to be the most
dominant.","51 pages, 5 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1711.10720v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.10720v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.10720v1,"{'id': 'http://arxiv.org/abs/1711.10720v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.10720v1', 'updated': '2017-11-29T08:22:31Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=29, tm_hour=8, tm_min=22, tm_sec=31, tm_wday=2, tm_yday=333, tm_isdst=0), 'published': '2017-11-29T08:22:31Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=29, tm_hour=8, tm_min=22, tm_sec=31, tm_wday=2, tm_yday=333, tm_isdst=0), 'title': 'Organized Behavior Classification of Tweet Sets using Supervised\n  Learning Methods', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Organized Behavior Classification of Tweet Sets using Supervised\n  Learning Methods'}, 'summary': 'During the 2016 US elections Twitter experienced unprecedented levels of\npropaganda and fake news through the collaboration of bots and hired persons,\nthe ramifications of which are still being debated. This work proposes an\napproach to identify the presence of organized behavior in tweets. The Random\nForest, Support Vector Machine, and Logistic Regression algorithms are each\nused to train a model with a data set of 850 records consisting of 299 features\nextracted from tweets gathered during the 2016 US presidential election. The\nfeatures represent user and temporal synchronization characteristics to capture\ncoordinated behavior. These models are trained to classify tweet sets among the\ncategories: organic vs organized, political vs non-political, and pro-Trump vs\npro-Hillary vs neither. The random forest algorithm performs better with\ngreater than 95% average accuracy and f-measure scores for each category. The\nmost valuable features for classification are identified as user based\nfeatures, with media use and marking tweets as favorite to be the most\ndominant.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'During the 2016 US elections Twitter experienced unprecedented levels of\npropaganda and fake news through the collaboration of bots and hired persons,\nthe ramifications of which are still being debated. This work proposes an\napproach to identify the presence of organized behavior in tweets. The Random\nForest, Support Vector Machine, and Logistic Regression algorithms are each\nused to train a model with a data set of 850 records consisting of 299 features\nextracted from tweets gathered during the 2016 US presidential election. The\nfeatures represent user and temporal synchronization characteristics to capture\ncoordinated behavior. These models are trained to classify tweet sets among the\ncategories: organic vs organized, political vs non-political, and pro-Trump vs\npro-Hillary vs neither. The random forest algorithm performs better with\ngreater than 95% average accuracy and f-measure scores for each category. The\nmost valuable features for classification are identified as user based\nfeatures, with media use and marking tweets as favorite to be the most\ndominant.'}, 'authors': [{'name': 'Erdem Beğenilmiş'}, {'name': 'Suzan Üsküdarlı'}], 'author_detail': {'name': 'Suzan Üsküdarlı'}, 'author': 'Suzan Üsküdarlı', 'arxiv_comment': '51 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/1711.10720v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.10720v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
409,http://arxiv.org/abs/1711.10394v1,2017-11-28 16:51:22+00:00,2017-11-28 16:51:22+00:00,Exposing Computer Generated Images by Using Deep Convolutional Neural Networks,"[arxiv.Result.Author('Edmar R. S. de Rezende'), arxiv.Result.Author('Guilherme C. S. Ruppert'), arxiv.Result.Author('Antonio Theophilo'), arxiv.Result.Author('Tiago Carvalho')]","The recent computer graphics developments have upraised the quality of the
generated digital content, astonishing the most skeptical viewer. Games and
movies have taken advantage of this fact but, at the same time, these advances
have brought serious negative impacts like the ones yielded by fakeimages
produced with malicious intents. Digital artists can compose artificial images
capable of deceiving the great majority of people, turning this into a very
dangerous weapon in a timespan currently know as Fake News/Post-Truth"" Era. In
this work, we propose a new approach for dealing with the problem of detecting
computer generated images, through the application of deep convolutional
networks and transfer learning techniques. We start from Residual Networks and
develop different models adapted to the binary problem of identifying if an
image was or not computer generated. Differently from the current
state-of-the-art approaches, we don't rely on hand-crafted features, but
provide to the model the raw pixel information, achieving the same 0.97 of
state-of-the-art methods with two main advantages: our methods show more stable
results (depicted by lower variance) and eliminate the laborious and manual
step of specialized features extraction and selection.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1711.10394v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.10394v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.10394v1,"{'id': 'http://arxiv.org/abs/1711.10394v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.10394v1', 'updated': '2017-11-28T16:51:22Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=28, tm_hour=16, tm_min=51, tm_sec=22, tm_wday=1, tm_yday=332, tm_isdst=0), 'published': '2017-11-28T16:51:22Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=28, tm_hour=16, tm_min=51, tm_sec=22, tm_wday=1, tm_yday=332, tm_isdst=0), 'title': 'Exposing Computer Generated Images by Using Deep Convolutional Neural\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exposing Computer Generated Images by Using Deep Convolutional Neural\n  Networks'}, 'summary': 'The recent computer graphics developments have upraised the quality of the\ngenerated digital content, astonishing the most skeptical viewer. Games and\nmovies have taken advantage of this fact but, at the same time, these advances\nhave brought serious negative impacts like the ones yielded by fakeimages\nproduced with malicious intents. Digital artists can compose artificial images\ncapable of deceiving the great majority of people, turning this into a very\ndangerous weapon in a timespan currently know as Fake News/Post-Truth"" Era. In\nthis work, we propose a new approach for dealing with the problem of detecting\ncomputer generated images, through the application of deep convolutional\nnetworks and transfer learning techniques. We start from Residual Networks and\ndevelop different models adapted to the binary problem of identifying if an\nimage was or not computer generated. Differently from the current\nstate-of-the-art approaches, we don\'t rely on hand-crafted features, but\nprovide to the model the raw pixel information, achieving the same 0.97 of\nstate-of-the-art methods with two main advantages: our methods show more stable\nresults (depicted by lower variance) and eliminate the laborious and manual\nstep of specialized features extraction and selection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The recent computer graphics developments have upraised the quality of the\ngenerated digital content, astonishing the most skeptical viewer. Games and\nmovies have taken advantage of this fact but, at the same time, these advances\nhave brought serious negative impacts like the ones yielded by fakeimages\nproduced with malicious intents. Digital artists can compose artificial images\ncapable of deceiving the great majority of people, turning this into a very\ndangerous weapon in a timespan currently know as Fake News/Post-Truth"" Era. In\nthis work, we propose a new approach for dealing with the problem of detecting\ncomputer generated images, through the application of deep convolutional\nnetworks and transfer learning techniques. We start from Residual Networks and\ndevelop different models adapted to the binary problem of identifying if an\nimage was or not computer generated. Differently from the current\nstate-of-the-art approaches, we don\'t rely on hand-crafted features, but\nprovide to the model the raw pixel information, achieving the same 0.97 of\nstate-of-the-art methods with two main advantages: our methods show more stable\nresults (depicted by lower variance) and eliminate the laborious and manual\nstep of specialized features extraction and selection.'}, 'authors': [{'name': 'Edmar R. S. de Rezende'}, {'name': 'Guilherme C. S. Ruppert'}, {'name': 'Antonio Theophilo'}, {'name': 'Tiago Carvalho'}], 'author_detail': {'name': 'Tiago Carvalho'}, 'author': 'Tiago Carvalho', 'links': [{'href': 'http://arxiv.org/abs/1711.10394v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.10394v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
410,http://arxiv.org/abs/1711.09918v1,2017-11-27 19:00:08+00:00,2017-11-27 19:00:08+00:00,Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation,"[arxiv.Result.Author('Jooyeon Kim'), arxiv.Result.Author('Behzad Tabibian'), arxiv.Result.Author('Alice Oh'), arxiv.Result.Author('Bernhard Schoelkopf'), arxiv.Result.Author('Manuel Gomez-Rodriguez')]","Online social networking sites are experimenting with the following
crowd-powered procedure to reduce the spread of fake news and misinformation:
whenever a user is exposed to a story through her feed, she can flag the story
as misinformation and, if the story receives enough flags, it is sent to a
trusted third party for fact checking. If this party identifies the story as
misinformation, it is marked as disputed. However, given the uncertain number
of exposures, the high cost of fact checking, and the trade-off between flags
and exposures, the above mentioned procedure requires careful reasoning and
smart algorithms which, to the best of our knowledge, do not exist to date.
  In this paper, we first introduce a flexible representation of the above
procedure using the framework of marked temporal point processes. Then, we
develop a scalable online algorithm, Curb, to select which stories to send for
fact checking and when to do so to efficiently reduce the spread of
misinformation with provable guarantees. In doing so, we need to solve a novel
stochastic optimal control problem for stochastic differential equations with
jumps, which is of independent interest. Experiments on two real-world datasets
gathered from Twitter and Weibo show that our algorithm may be able to
effectively reduce the spread of fake news and misinformation.","To appear at the 11th ACM International Conference on Web Search and
  Data Mining (WSDM 2018)",,,cs.SI,"['cs.SI', 'cs.HC', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1711.09918v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.09918v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.09918v1,"{'id': 'http://arxiv.org/abs/1711.09918v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.09918v1', 'updated': '2017-11-27T19:00:08Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=27, tm_hour=19, tm_min=0, tm_sec=8, tm_wday=0, tm_yday=331, tm_isdst=0), 'published': '2017-11-27T19:00:08Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=27, tm_hour=19, tm_min=0, tm_sec=8, tm_wday=0, tm_yday=331, tm_isdst=0), 'title': 'Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation'}, 'summary': 'Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.'}, 'authors': [{'name': 'Jooyeon Kim'}, {'name': 'Behzad Tabibian'}, {'name': 'Alice Oh'}, {'name': 'Bernhard Schoelkopf'}, {'name': 'Manuel Gomez-Rodriguez'}], 'author_detail': {'name': 'Manuel Gomez-Rodriguez'}, 'author': 'Manuel Gomez-Rodriguez', 'arxiv_comment': 'To appear at the 11th ACM International Conference on Web Search and\n  Data Mining (WSDM 2018)', 'links': [{'href': 'http://arxiv.org/abs/1711.09918v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.09918v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
411,http://arxiv.org/abs/1711.09025v2,2018-03-02 16:57:43+00:00,2017-11-24 15:53:37+00:00,Fake News Detection in Social Networks via Crowd Signals,"[arxiv.Result.Author('Sebastian Tschiatschek'), arxiv.Result.Author('Adish Singla'), arxiv.Result.Author('Manuel Gomez Rodriguez'), arxiv.Result.Author('Arpit Merchant'), arxiv.Result.Author('Andreas Krause')]","Our work considers leveraging crowd signals for detecting fake news and is
motivated by tools recently introduced by Facebook that enable users to flag
fake news. By aggregating users' flags, our goal is to select a small subset of
news every day, send them to an expert (e.g., via a third-party fact-checking
organization), and stop the spread of news identified as fake by an expert. The
main objective of our work is to minimize the spread of misinformation by
stopping the propagation of fake news in the network. It is especially
challenging to achieve this objective as it requires detecting fake news with
high-confidence as quickly as possible. We show that in order to leverage
users' flags efficiently, it is crucial to learn about users' flagging
accuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian
inference for detecting fake news and jointly learns about users' flagging
accuracy over time. Our algorithm employs posterior sampling to actively trade
off exploitation (selecting news that maximize the objective value at a given
epoch) and exploration (selecting news that maximize the value of information
towards learning about users' flagging accuracy). We demonstrate the
effectiveness of our approach via extensive experiments and show the power of
leveraging community signals for fake news detection.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1711.09025v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.09025v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.09025v2,"{'id': 'http://arxiv.org/abs/1711.09025v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.09025v2', 'updated': '2018-03-02T16:57:43Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=2, tm_hour=16, tm_min=57, tm_sec=43, tm_wday=4, tm_yday=61, tm_isdst=0), 'published': '2017-11-24T15:53:37Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=24, tm_hour=15, tm_min=53, tm_sec=37, tm_wday=4, tm_yday=328, tm_isdst=0), 'title': 'Fake News Detection in Social Networks via Crowd Signals', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection in Social Networks via Crowd Signals'}, 'summary': ""Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.""}, 'authors': [{'name': 'Sebastian Tschiatschek'}, {'name': 'Adish Singla'}, {'name': 'Manuel Gomez Rodriguez'}, {'name': 'Arpit Merchant'}, {'name': 'Andreas Krause'}], 'author_detail': {'name': 'Andreas Krause'}, 'author': 'Andreas Krause', 'links': [{'href': 'http://arxiv.org/abs/1711.09025v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.09025v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
412,http://arxiv.org/abs/1711.08615v1,2017-11-23 08:36:17+00:00,2017-11-23 08:36:17+00:00,Controlling Elections through Social Influence,"[arxiv.Result.Author('Bryan Wilder'), arxiv.Result.Author('Yevgeniy Vorobeychik')]","Election control considers the problem of an adversary who attempts to tamper
with a voting process, in order to either ensure that their favored candidate
wins (constructive control) or another candidate loses (destructive control).
As online social networks have become significant sources of information for
potential voters, a new tool in an attacker's arsenal is to effect control by
harnessing social influence, for example, by spreading fake news and other
forms of misinformation through online social media.
  We consider the computational problem of election control via social
influence, studying the conditions under which finding good adversarial
strategies is computationally feasible. We consider two objectives for the
adversary in both the constructive and destructive control settings:
probability and margin of victory (POV and MOV, respectively). We present
several strong negative results, showing, for example, that the problem of
maximizing POV is inapproximable for any constant factor. On the other hand, we
present approximation algorithms which provide somewhat weaker approximation
guarantees, such as bicriteria approximations for the POV objective and
constant-factor approximations for MOV. Finally, we present mixed integer
programming formulations for these problems. Experimental results show that our
approximation algorithms often find near-optimal control strategies, indicating
that election control through social influence is a salient threat to election
integrity.","19 pages, 2 figures",,,cs.MA,"['cs.MA', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1711.08615v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.08615v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.08615v1,"{'id': 'http://arxiv.org/abs/1711.08615v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.08615v1', 'updated': '2017-11-23T08:36:17Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=23, tm_hour=8, tm_min=36, tm_sec=17, tm_wday=3, tm_yday=327, tm_isdst=0), 'published': '2017-11-23T08:36:17Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=23, tm_hour=8, tm_min=36, tm_sec=17, tm_wday=3, tm_yday=327, tm_isdst=0), 'title': 'Controlling Elections through Social Influence', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Controlling Elections through Social Influence'}, 'summary': ""Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.""}, 'authors': [{'name': 'Bryan Wilder'}, {'name': 'Yevgeniy Vorobeychik'}], 'author_detail': {'name': 'Yevgeniy Vorobeychik'}, 'author': 'Yevgeniy Vorobeychik', 'arxiv_comment': '19 pages, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/1711.08615v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.08615v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
413,http://arxiv.org/abs/1711.05303v1,2017-11-14 20:12:29+00:00,2017-11-14 20:12:29+00:00,Online Political Discourse in the Trump Era,"[arxiv.Result.Author('Rishab Nithyanand'), arxiv.Result.Author('Brian Schaffner'), arxiv.Result.Author('Phillipa Gill')]","We identify general trends in the (in)civility and complexity of political
discussions occurring on Reddit between January 2007 and May 2017 -- a period
spanning both terms of Barack Obama's presidency and the first 100 days of
Donald Trump's presidency. We then investigate four factors that are frequently
hypothesized as having contributed to the declining quality of American
political discourse -- (1) the rising popularity of Donald Trump, (2)
increasing polarization and negative partisanship, (3) the democratization of
news media and the rise of fake news, and (4) merging of fringe groups into
mainstream political discussions.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1711.05303v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.05303v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.05303v1,"{'id': 'http://arxiv.org/abs/1711.05303v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.05303v1', 'updated': '2017-11-14T20:12:29Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=14, tm_hour=20, tm_min=12, tm_sec=29, tm_wday=1, tm_yday=318, tm_isdst=0), 'published': '2017-11-14T20:12:29Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=14, tm_hour=20, tm_min=12, tm_sec=29, tm_wday=1, tm_yday=318, tm_isdst=0), 'title': 'Online Political Discourse in the Trump Era', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online Political Discourse in the Trump Era'}, 'summary': ""We identify general trends in the (in)civility and complexity of political\ndiscussions occurring on Reddit between January 2007 and May 2017 -- a period\nspanning both terms of Barack Obama's presidency and the first 100 days of\nDonald Trump's presidency. We then investigate four factors that are frequently\nhypothesized as having contributed to the declining quality of American\npolitical discourse -- (1) the rising popularity of Donald Trump, (2)\nincreasing polarization and negative partisanship, (3) the democratization of\nnews media and the rise of fake news, and (4) merging of fringe groups into\nmainstream political discussions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We identify general trends in the (in)civility and complexity of political\ndiscussions occurring on Reddit between January 2007 and May 2017 -- a period\nspanning both terms of Barack Obama's presidency and the first 100 days of\nDonald Trump's presidency. We then investigate four factors that are frequently\nhypothesized as having contributed to the declining quality of American\npolitical discourse -- (1) the rising popularity of Donald Trump, (2)\nincreasing polarization and negative partisanship, (3) the democratization of\nnews media and the rise of fake news, and (4) merging of fringe groups into\nmainstream political discussions.""}, 'authors': [{'name': 'Rishab Nithyanand'}, {'name': 'Brian Schaffner'}, {'name': 'Phillipa Gill'}], 'author_detail': {'name': 'Phillipa Gill'}, 'author': 'Phillipa Gill', 'links': [{'href': 'http://arxiv.org/abs/1711.05303v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.05303v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
414,http://arxiv.org/abs/1711.00715v1,2017-10-31 18:52:28+00:00,2017-10-31 18:52:28+00:00,Related Fact Checks: a tool for combating fake news,[arxiv.Result.Author('Sreya Guha')],"The emergence of ""Fake News"" and misinformation via online news and social
media has spurred an interest in computational tools to combat this phenomenon.
In this paper we present a new ""Related Fact Checks"" service, which can help a
reader critically evaluate an article and make a judgment on its veracity by
bringing up fact checks that are relevant to the article. We describe the core
technical problems that need to be solved in building a ""Related Fact Checks""
service, and present results from an evaluation of an implementation.",,,,cs.IR,"['cs.IR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1711.00715v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.00715v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.00715v1,"{'id': 'http://arxiv.org/abs/1711.00715v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.00715v1', 'updated': '2017-10-31T18:52:28Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=10, tm_mday=31, tm_hour=18, tm_min=52, tm_sec=28, tm_wday=1, tm_yday=304, tm_isdst=0), 'published': '2017-10-31T18:52:28Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=10, tm_mday=31, tm_hour=18, tm_min=52, tm_sec=28, tm_wday=1, tm_yday=304, tm_isdst=0), 'title': 'Related Fact Checks: a tool for combating fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Related Fact Checks: a tool for combating fake news'}, 'summary': 'The emergence of ""Fake News"" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new ""Related Fact Checks"" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a ""Related Fact Checks""\nservice, and present results from an evaluation of an implementation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The emergence of ""Fake News"" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new ""Related Fact Checks"" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a ""Related Fact Checks""\nservice, and present results from an evaluation of an implementation.'}, 'authors': [{'name': 'Sreya Guha'}], 'author_detail': {'name': 'Sreya Guha'}, 'author': 'Sreya Guha', 'links': [{'href': 'http://arxiv.org/abs/1711.00715v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.00715v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
415,http://arxiv.org/abs/1710.08528v1,2017-10-23 22:12:51+00:00,2017-10-23 22:12:51+00:00,A Two-Level Classification Approach for Detecting Clickbait Posts using Text-Based Features,"[arxiv.Result.Author('Olga Papadopoulou'), arxiv.Result.Author('Markos Zampoglou'), arxiv.Result.Author('Symeon Papadopoulos'), arxiv.Result.Author('Ioannis Kompatsiaris')]","The emergence of social media as news sources has led to the rise of
clickbait posts attempting to attract users to click on article links without
informing them on the actual article content. This paper presents our efforts
to create a clickbait detector inspired by fake news detection algorithms, and
our submission to the Clickbait Challenge 2017. The detector is based almost
exclusively on text-based features taken from previous work on clickbait
detection, our own work on fake post detection, and features we designed
specifically for the challenge. We use a two-level classification approach,
combining the outputs of 65 first-level classifiers in a second-level feature
vector. We present our exploratory results with individual features and their
combinations, taken from the post text and the target article title, as well as
feature selection. While our own blind tests with the dataset led to an F-score
of 0.63, our final evaluation in the Challenge only achieved an F-score of
0.43. We explore the possible causes of this, and lay out potential future
steps to achieve more successful results.",Clickbait Challenge 2017,,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/1710.08528v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1710.08528v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1710.08528v1,"{'id': 'http://arxiv.org/abs/1710.08528v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1710.08528v1', 'updated': '2017-10-23T22:12:51Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=10, tm_mday=23, tm_hour=22, tm_min=12, tm_sec=51, tm_wday=0, tm_yday=296, tm_isdst=0), 'published': '2017-10-23T22:12:51Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=10, tm_mday=23, tm_hour=22, tm_min=12, tm_sec=51, tm_wday=0, tm_yday=296, tm_isdst=0), 'title': 'A Two-Level Classification Approach for Detecting Clickbait Posts using\n  Text-Based Features', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Two-Level Classification Approach for Detecting Clickbait Posts using\n  Text-Based Features'}, 'summary': 'The emergence of social media as news sources has led to the rise of\nclickbait posts attempting to attract users to click on article links without\ninforming them on the actual article content. This paper presents our efforts\nto create a clickbait detector inspired by fake news detection algorithms, and\nour submission to the Clickbait Challenge 2017. The detector is based almost\nexclusively on text-based features taken from previous work on clickbait\ndetection, our own work on fake post detection, and features we designed\nspecifically for the challenge. We use a two-level classification approach,\ncombining the outputs of 65 first-level classifiers in a second-level feature\nvector. We present our exploratory results with individual features and their\ncombinations, taken from the post text and the target article title, as well as\nfeature selection. While our own blind tests with the dataset led to an F-score\nof 0.63, our final evaluation in the Challenge only achieved an F-score of\n0.43. We explore the possible causes of this, and lay out potential future\nsteps to achieve more successful results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The emergence of social media as news sources has led to the rise of\nclickbait posts attempting to attract users to click on article links without\ninforming them on the actual article content. This paper presents our efforts\nto create a clickbait detector inspired by fake news detection algorithms, and\nour submission to the Clickbait Challenge 2017. The detector is based almost\nexclusively on text-based features taken from previous work on clickbait\ndetection, our own work on fake post detection, and features we designed\nspecifically for the challenge. We use a two-level classification approach,\ncombining the outputs of 65 first-level classifiers in a second-level feature\nvector. We present our exploratory results with individual features and their\ncombinations, taken from the post text and the target article title, as well as\nfeature selection. While our own blind tests with the dataset led to an F-score\nof 0.63, our final evaluation in the Challenge only achieved an F-score of\n0.43. We explore the possible causes of this, and lay out potential future\nsteps to achieve more successful results.'}, 'authors': [{'name': 'Olga Papadopoulou'}, {'name': 'Markos Zampoglou'}, {'name': 'Symeon Papadopoulos'}, {'name': 'Ioannis Kompatsiaris'}], 'author_detail': {'name': 'Ioannis Kompatsiaris'}, 'author': 'Ioannis Kompatsiaris', 'arxiv_comment': 'Clickbait Challenge 2017', 'links': [{'href': 'http://arxiv.org/abs/1710.08528v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1710.08528v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
416,http://arxiv.org/abs/1708.07157v1,2017-08-23 19:18:11+00:00,2017-08-23 19:18:11+00:00,Evaluation Measures for Relevance and Credibility in Ranked Lists,"[arxiv.Result.Author('Christina Lioma'), arxiv.Result.Author('Jakob Grue Simonsen'), arxiv.Result.Author('Birger Larsen')]","Recent discussions on alternative facts, fake news, and post truth politics
have motivated research on creating technologies that allow people not only to
access information, but also to assess the credibility of the information
presented to them by information retrieval systems. Whereas technology is in
place for filtering information according to relevance and/or credibility, no
single measure currently exists for evaluating the accuracy or precision (and
more generally effectiveness) of both the relevance and the credibility of
retrieved results. One obvious way of doing so is to measure relevance and
credibility effectiveness separately, and then consolidate the two measures
into one. There at least two problems with such an approach: (I) it is not
certain that the same criteria are applied to the evaluation of both relevance
and credibility (and applying different criteria introduces bias to the
evaluation); (II) many more and richer measures exist for assessing relevance
effectiveness than for assessing credibility effectiveness (hence risking
further bias).
  Motivated by the above, we present two novel types of evaluation measures
that are designed to measure the effectiveness of both relevance and
credibility in ranked lists of retrieval results. Experimental evaluation on a
small human-annotated dataset (that we make freely available to the research
community) shows that our measures are expressive and intuitive in their
interpretation.",,,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/1708.07157v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.07157v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.07157v1,"{'id': 'http://arxiv.org/abs/1708.07157v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.07157v1', 'updated': '2017-08-23T19:18:11Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=23, tm_hour=19, tm_min=18, tm_sec=11, tm_wday=2, tm_yday=235, tm_isdst=0), 'published': '2017-08-23T19:18:11Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=23, tm_hour=19, tm_min=18, tm_sec=11, tm_wday=2, tm_yday=235, tm_isdst=0), 'title': 'Evaluation Measures for Relevance and Credibility in Ranked Lists', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evaluation Measures for Relevance and Credibility in Ranked Lists'}, 'summary': 'Recent discussions on alternative facts, fake news, and post truth politics\nhave motivated research on creating technologies that allow people not only to\naccess information, but also to assess the credibility of the information\npresented to them by information retrieval systems. Whereas technology is in\nplace for filtering information according to relevance and/or credibility, no\nsingle measure currently exists for evaluating the accuracy or precision (and\nmore generally effectiveness) of both the relevance and the credibility of\nretrieved results. One obvious way of doing so is to measure relevance and\ncredibility effectiveness separately, and then consolidate the two measures\ninto one. There at least two problems with such an approach: (I) it is not\ncertain that the same criteria are applied to the evaluation of both relevance\nand credibility (and applying different criteria introduces bias to the\nevaluation); (II) many more and richer measures exist for assessing relevance\neffectiveness than for assessing credibility effectiveness (hence risking\nfurther bias).\n  Motivated by the above, we present two novel types of evaluation measures\nthat are designed to measure the effectiveness of both relevance and\ncredibility in ranked lists of retrieval results. Experimental evaluation on a\nsmall human-annotated dataset (that we make freely available to the research\ncommunity) shows that our measures are expressive and intuitive in their\ninterpretation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent discussions on alternative facts, fake news, and post truth politics\nhave motivated research on creating technologies that allow people not only to\naccess information, but also to assess the credibility of the information\npresented to them by information retrieval systems. Whereas technology is in\nplace for filtering information according to relevance and/or credibility, no\nsingle measure currently exists for evaluating the accuracy or precision (and\nmore generally effectiveness) of both the relevance and the credibility of\nretrieved results. One obvious way of doing so is to measure relevance and\ncredibility effectiveness separately, and then consolidate the two measures\ninto one. There at least two problems with such an approach: (I) it is not\ncertain that the same criteria are applied to the evaluation of both relevance\nand credibility (and applying different criteria introduces bias to the\nevaluation); (II) many more and richer measures exist for assessing relevance\neffectiveness than for assessing credibility effectiveness (hence risking\nfurther bias).\n  Motivated by the above, we present two novel types of evaluation measures\nthat are designed to measure the effectiveness of both relevance and\ncredibility in ranked lists of retrieval results. Experimental evaluation on a\nsmall human-annotated dataset (that we make freely available to the research\ncommunity) shows that our measures are expressive and intuitive in their\ninterpretation.'}, 'authors': [{'name': 'Christina Lioma'}, {'name': 'Jakob Grue Simonsen'}, {'name': 'Birger Larsen'}], 'author_detail': {'name': 'Birger Larsen'}, 'author': 'Birger Larsen', 'links': [{'href': 'http://arxiv.org/abs/1708.07157v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.07157v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
417,http://arxiv.org/abs/1708.07104v1,2017-08-23 17:12:03+00:00,2017-08-23 17:12:03+00:00,Automatic Detection of Fake News,"[arxiv.Result.Author('Verónica Pérez-Rosas'), arxiv.Result.Author('Bennett Kleinberg'), arxiv.Result.Author('Alexandra Lefevre'), arxiv.Result.Author('Rada Mihalcea')]","The proliferation of misleading information in everyday access media outlets
such as social media feeds, news blogs, and online newspapers have made it
challenging to identify trustworthy news sources, thus increasing the need for
computational tools able to provide insights into the reliability of online
content. In this paper, we focus on the automatic identification of fake
content in online news. Our contribution is twofold. First, we introduce two
novel datasets for the task of fake news detection, covering seven different
news domains. We describe the collection, annotation, and validation process in
detail and present several exploratory analysis on the identification of
linguistic differences in fake and legitimate news content. Second, we conduct
a set of learning experiments to build accurate fake news detectors. In
addition, we provide comparative analyses of the automatic and manual
identification of fake news.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1708.07104v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.07104v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.07104v1,"{'id': 'http://arxiv.org/abs/1708.07104v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.07104v1', 'updated': '2017-08-23T17:12:03Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=23, tm_hour=17, tm_min=12, tm_sec=3, tm_wday=2, tm_yday=235, tm_isdst=0), 'published': '2017-08-23T17:12:03Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=23, tm_hour=17, tm_min=12, tm_sec=3, tm_wday=2, tm_yday=235, tm_isdst=0), 'title': 'Automatic Detection of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic Detection of Fake News'}, 'summary': 'The proliferation of misleading information in everyday access media outlets\nsuch as social media feeds, news blogs, and online newspapers have made it\nchallenging to identify trustworthy news sources, thus increasing the need for\ncomputational tools able to provide insights into the reliability of online\ncontent. In this paper, we focus on the automatic identification of fake\ncontent in online news. Our contribution is twofold. First, we introduce two\nnovel datasets for the task of fake news detection, covering seven different\nnews domains. We describe the collection, annotation, and validation process in\ndetail and present several exploratory analysis on the identification of\nlinguistic differences in fake and legitimate news content. Second, we conduct\na set of learning experiments to build accurate fake news detectors. In\naddition, we provide comparative analyses of the automatic and manual\nidentification of fake news.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The proliferation of misleading information in everyday access media outlets\nsuch as social media feeds, news blogs, and online newspapers have made it\nchallenging to identify trustworthy news sources, thus increasing the need for\ncomputational tools able to provide insights into the reliability of online\ncontent. In this paper, we focus on the automatic identification of fake\ncontent in online news. Our contribution is twofold. First, we introduce two\nnovel datasets for the task of fake news detection, covering seven different\nnews domains. We describe the collection, annotation, and validation process in\ndetail and present several exploratory analysis on the identification of\nlinguistic differences in fake and legitimate news content. Second, we conduct\na set of learning experiments to build accurate fake news detectors. In\naddition, we provide comparative analyses of the automatic and manual\nidentification of fake news.'}, 'authors': [{'name': 'Verónica Pérez-Rosas'}, {'name': 'Bennett Kleinberg'}, {'name': 'Alexandra Lefevre'}, {'name': 'Rada Mihalcea'}], 'author_detail': {'name': 'Rada Mihalcea'}, 'author': 'Rada Mihalcea', 'links': [{'href': 'http://arxiv.org/abs/1708.07104v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.07104v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
418,http://arxiv.org/abs/1708.06233v1,2017-08-21 14:09:31+00:00,2017-08-21 14:09:31+00:00,Fake News in Social Networks,"[arxiv.Result.Author('Christoph Aymanns'), arxiv.Result.Author('Jakob Foerster'), arxiv.Result.Author('Co-Pierre Georg')]","We model the spread of news as a social learning game on a network. Agents
can either endorse or oppose a claim made in a piece of news, which itself may
be either true or false. Agents base their decision on a private signal and
their neighbors' past actions. Given these inputs, agents follow strategies
derived via multi-agent deep reinforcement learning and receive utility from
acting in accordance with the veracity of claims. Our framework yields
strategies with agent utility close to a theoretical, Bayes optimal benchmark,
while remaining flexible to model re-specification. Optimized strategies allow
agents to correctly identify most false claims, when all agents receive
unbiased private signals. However, an adversary's attempt to spread fake news
by targeting a subset of agents with a biased private signal can be successful.
Even more so when the adversary has information about agents' network position
or private signal. When agents are aware of the presence of an adversary they
re-optimize their strategies in the training stage and the adversary's attack
is less effective. Hence, exposing agents to the possibility of fake news can
be an effective way to curtail the spread of fake news in social networks. Our
results also highlight that information about the users' private beliefs and
their social network structure can be extremely valuable to adversaries and
should be well protected.",,,,cs.AI,"['cs.AI', 'cs.MA', 'cs.SI', 'physics.soc-ph', 'q-fin.EC', 'I.2.1; I.2.6; J.4; K.4.2']","[arxiv.Result.Link('http://arxiv.org/abs/1708.06233v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.06233v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.06233v1,"{'id': 'http://arxiv.org/abs/1708.06233v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.06233v1', 'updated': '2017-08-21T14:09:31Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=21, tm_hour=14, tm_min=9, tm_sec=31, tm_wday=0, tm_yday=233, tm_isdst=0), 'published': '2017-08-21T14:09:31Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=21, tm_hour=14, tm_min=9, tm_sec=31, tm_wday=0, tm_yday=233, tm_isdst=0), 'title': 'Fake News in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News in Social Networks'}, 'summary': ""We model the spread of news as a social learning game on a network. Agents\ncan either endorse or oppose a claim made in a piece of news, which itself may\nbe either true or false. Agents base their decision on a private signal and\ntheir neighbors' past actions. Given these inputs, agents follow strategies\nderived via multi-agent deep reinforcement learning and receive utility from\nacting in accordance with the veracity of claims. Our framework yields\nstrategies with agent utility close to a theoretical, Bayes optimal benchmark,\nwhile remaining flexible to model re-specification. Optimized strategies allow\nagents to correctly identify most false claims, when all agents receive\nunbiased private signals. However, an adversary's attempt to spread fake news\nby targeting a subset of agents with a biased private signal can be successful.\nEven more so when the adversary has information about agents' network position\nor private signal. When agents are aware of the presence of an adversary they\nre-optimize their strategies in the training stage and the adversary's attack\nis less effective. Hence, exposing agents to the possibility of fake news can\nbe an effective way to curtail the spread of fake news in social networks. Our\nresults also highlight that information about the users' private beliefs and\ntheir social network structure can be extremely valuable to adversaries and\nshould be well protected."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We model the spread of news as a social learning game on a network. Agents\ncan either endorse or oppose a claim made in a piece of news, which itself may\nbe either true or false. Agents base their decision on a private signal and\ntheir neighbors' past actions. Given these inputs, agents follow strategies\nderived via multi-agent deep reinforcement learning and receive utility from\nacting in accordance with the veracity of claims. Our framework yields\nstrategies with agent utility close to a theoretical, Bayes optimal benchmark,\nwhile remaining flexible to model re-specification. Optimized strategies allow\nagents to correctly identify most false claims, when all agents receive\nunbiased private signals. However, an adversary's attempt to spread fake news\nby targeting a subset of agents with a biased private signal can be successful.\nEven more so when the adversary has information about agents' network position\nor private signal. When agents are aware of the presence of an adversary they\nre-optimize their strategies in the training stage and the adversary's attack\nis less effective. Hence, exposing agents to the possibility of fake news can\nbe an effective way to curtail the spread of fake news in social networks. Our\nresults also highlight that information about the users' private beliefs and\ntheir social network structure can be extremely valuable to adversaries and\nshould be well protected.""}, 'authors': [{'name': 'Christoph Aymanns'}, {'name': 'Jakob Foerster'}, {'name': 'Co-Pierre Georg'}], 'author_detail': {'name': 'Co-Pierre Georg'}, 'author': 'Co-Pierre Georg', 'links': [{'href': 'http://arxiv.org/abs/1708.06233v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.06233v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.1; I.2.6; J.4; K.4.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
419,http://arxiv.org/abs/1708.05286v2,2017-09-14 13:42:56+00:00,2017-08-17 14:06:58+00:00,Simple Open Stance Classification for Rumour Analysis,"[arxiv.Result.Author('Ahmet Aker'), arxiv.Result.Author('Leon Derczynski'), arxiv.Result.Author('Kalina Bontcheva')]","Stance classification determines the attitude, or stance, in a (typically
short) text. The task has powerful applications, such as the detection of fake
news or the automatic extraction of attitudes toward entities or events in the
media. This paper describes a surprisingly simple and efficient classification
approach to open stance classification in Twitter, for rumour and veracity
classification. The approach profits from a novel set of automatically
identifiable problem-specific features, which significantly boost classifier
accuracy and achieve above state-of-the-art results on recent benchmark
datasets. This calls into question the value of using complex sophisticated
models for stance classification without first doing informed feature
extraction.",,In RANLP 2017,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1708.05286v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.05286v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.05286v2,"{'id': 'http://arxiv.org/abs/1708.05286v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.05286v2', 'updated': '2017-09-14T13:42:56Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=9, tm_mday=14, tm_hour=13, tm_min=42, tm_sec=56, tm_wday=3, tm_yday=257, tm_isdst=0), 'published': '2017-08-17T14:06:58Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=17, tm_hour=14, tm_min=6, tm_sec=58, tm_wday=3, tm_yday=229, tm_isdst=0), 'title': 'Simple Open Stance Classification for Rumour Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Simple Open Stance Classification for Rumour Analysis'}, 'summary': 'Stance classification determines the attitude, or stance, in a (typically\nshort) text. The task has powerful applications, such as the detection of fake\nnews or the automatic extraction of attitudes toward entities or events in the\nmedia. This paper describes a surprisingly simple and efficient classification\napproach to open stance classification in Twitter, for rumour and veracity\nclassification. The approach profits from a novel set of automatically\nidentifiable problem-specific features, which significantly boost classifier\naccuracy and achieve above state-of-the-art results on recent benchmark\ndatasets. This calls into question the value of using complex sophisticated\nmodels for stance classification without first doing informed feature\nextraction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance classification determines the attitude, or stance, in a (typically\nshort) text. The task has powerful applications, such as the detection of fake\nnews or the automatic extraction of attitudes toward entities or events in the\nmedia. This paper describes a surprisingly simple and efficient classification\napproach to open stance classification in Twitter, for rumour and veracity\nclassification. The approach profits from a novel set of automatically\nidentifiable problem-specific features, which significantly boost classifier\naccuracy and achieve above state-of-the-art results on recent benchmark\ndatasets. This calls into question the value of using complex sophisticated\nmodels for stance classification without first doing informed feature\nextraction.'}, 'authors': [{'name': 'Ahmet Aker'}, {'name': 'Leon Derczynski'}, {'name': 'Kalina Bontcheva'}], 'author_detail': {'name': 'Kalina Bontcheva'}, 'author': 'Kalina Bontcheva', 'arxiv_journal_ref': 'In RANLP 2017', 'links': [{'href': 'http://arxiv.org/abs/1708.05286v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.05286v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
420,http://arxiv.org/abs/1708.01967v3,2017-09-03 02:40:05+00:00,2017-08-07 02:29:09+00:00,Fake News Detection on Social Media: A Data Mining Perspective,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Amy Sliva'), arxiv.Result.Author('Suhang Wang'), arxiv.Result.Author('Jiliang Tang'), arxiv.Result.Author('Huan Liu')]","Social media for news consumption is a double-edged sword. On the one hand,
its low cost, easy access, and rapid dissemination of information lead people
to seek out and consume news from social media. On the other hand, it enables
the wide spread of ""fake news"", i.e., low quality news with intentionally false
information. The extensive spread of fake news has the potential for extremely
negative impacts on individuals and society. Therefore, fake news detection on
social media has recently become an emerging research that is attracting
tremendous attention. Fake news detection on social media presents unique
characteristics and challenges that make existing detection algorithms from
traditional news media ineffective or not applicable. First, fake news is
intentionally written to mislead readers to believe false information, which
makes it difficult and nontrivial to detect based on news content; therefore,
we need to include auxiliary information, such as user social engagements on
social media, to help make a determination. Second, exploiting this auxiliary
information is challenging in and of itself as users' social engagements with
fake news produce data that is big, incomplete, unstructured, and noisy.
Because the issue of fake news detection on social media is both challenging
and relevant, we conducted this survey to further facilitate research on the
problem. In this survey, we present a comprehensive review of detecting fake
news on social media, including fake news characterizations on psychology and
social theories, existing algorithms from a data mining perspective, evaluation
metrics and representative datasets. We also discuss related research areas,
open problems, and future research directions for fake news detection on social
media.","ACM SIGKDD Explorations Newsletter, 2017",,,cs.SI,"['cs.SI', 'cs.AI', 'H.2.8']","[arxiv.Result.Link('http://arxiv.org/abs/1708.01967v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.01967v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.01967v3,"{'id': 'http://arxiv.org/abs/1708.01967v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.01967v3', 'updated': '2017-09-03T02:40:05Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=9, tm_mday=3, tm_hour=2, tm_min=40, tm_sec=5, tm_wday=6, tm_yday=246, tm_isdst=0), 'published': '2017-08-07T02:29:09Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=7, tm_hour=2, tm_min=29, tm_sec=9, tm_wday=0, tm_yday=219, tm_isdst=0), 'title': 'Fake News Detection on Social Media: A Data Mining Perspective', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection on Social Media: A Data Mining Perspective'}, 'summary': 'Social media for news consumption is a double-edged sword. On the one hand,\nits low cost, easy access, and rapid dissemination of information lead people\nto seek out and consume news from social media. On the other hand, it enables\nthe wide spread of ""fake news"", i.e., low quality news with intentionally false\ninformation. The extensive spread of fake news has the potential for extremely\nnegative impacts on individuals and society. Therefore, fake news detection on\nsocial media has recently become an emerging research that is attracting\ntremendous attention. Fake news detection on social media presents unique\ncharacteristics and challenges that make existing detection algorithms from\ntraditional news media ineffective or not applicable. First, fake news is\nintentionally written to mislead readers to believe false information, which\nmakes it difficult and nontrivial to detect based on news content; therefore,\nwe need to include auxiliary information, such as user social engagements on\nsocial media, to help make a determination. Second, exploiting this auxiliary\ninformation is challenging in and of itself as users\' social engagements with\nfake news produce data that is big, incomplete, unstructured, and noisy.\nBecause the issue of fake news detection on social media is both challenging\nand relevant, we conducted this survey to further facilitate research on the\nproblem. In this survey, we present a comprehensive review of detecting fake\nnews on social media, including fake news characterizations on psychology and\nsocial theories, existing algorithms from a data mining perspective, evaluation\nmetrics and representative datasets. We also discuss related research areas,\nopen problems, and future research directions for fake news detection on social\nmedia.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media for news consumption is a double-edged sword. On the one hand,\nits low cost, easy access, and rapid dissemination of information lead people\nto seek out and consume news from social media. On the other hand, it enables\nthe wide spread of ""fake news"", i.e., low quality news with intentionally false\ninformation. The extensive spread of fake news has the potential for extremely\nnegative impacts on individuals and society. Therefore, fake news detection on\nsocial media has recently become an emerging research that is attracting\ntremendous attention. Fake news detection on social media presents unique\ncharacteristics and challenges that make existing detection algorithms from\ntraditional news media ineffective or not applicable. First, fake news is\nintentionally written to mislead readers to believe false information, which\nmakes it difficult and nontrivial to detect based on news content; therefore,\nwe need to include auxiliary information, such as user social engagements on\nsocial media, to help make a determination. Second, exploiting this auxiliary\ninformation is challenging in and of itself as users\' social engagements with\nfake news produce data that is big, incomplete, unstructured, and noisy.\nBecause the issue of fake news detection on social media is both challenging\nand relevant, we conducted this survey to further facilitate research on the\nproblem. In this survey, we present a comprehensive review of detecting fake\nnews on social media, including fake news characterizations on psychology and\nsocial theories, existing algorithms from a data mining perspective, evaluation\nmetrics and representative datasets. We also discuss related research areas,\nopen problems, and future research directions for fake news detection on social\nmedia.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Amy Sliva'}, {'name': 'Suhang Wang'}, {'name': 'Jiliang Tang'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'ACM SIGKDD Explorations Newsletter, 2017', 'links': [{'href': 'http://arxiv.org/abs/1708.01967v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.01967v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.2.8', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
421,http://arxiv.org/abs/1707.03264v2,2018-05-21 10:31:40+00:00,2017-07-11 13:44:51+00:00,A simple but tough-to-beat baseline for the Fake News Challenge stance detection task,"[arxiv.Result.Author('Benjamin Riedel'), arxiv.Result.Author('Isabelle Augenstein'), arxiv.Result.Author('Georgios P. Spithourakis'), arxiv.Result.Author('Sebastian Riedel')]","Identifying public misinformation is a complicated and challenging task. An
important part of checking the veracity of a specific claim is to evaluate the
stance different news sources take towards the assertion. Automatic stance
evaluation, i.e. stance detection, would arguably facilitate the process of
fact checking. In this paper, we present our stance detection system which
claimed third place in Stage 1 of the Fake News Challenge. Despite our
straightforward approach, our system performs at a competitive level with the
complex ensembles of the top two winning teams. We therefore propose our system
as the 'simple but tough-to-beat baseline' for the Fake News Challenge stance
detection task.","6 pages, 1 figure, 3 tables; additional reference and details added,
  typos and wording corrected",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1707.03264v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1707.03264v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1707.03264v2,"{'id': 'http://arxiv.org/abs/1707.03264v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1707.03264v2', 'updated': '2018-05-21T10:31:40Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=21, tm_hour=10, tm_min=31, tm_sec=40, tm_wday=0, tm_yday=141, tm_isdst=0), 'published': '2017-07-11T13:44:51Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=11, tm_hour=13, tm_min=44, tm_sec=51, tm_wday=1, tm_yday=192, tm_isdst=0), 'title': 'A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task'}, 'summary': ""Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.""}, 'authors': [{'name': 'Benjamin Riedel'}, {'name': 'Isabelle Augenstein'}, {'name': 'Georgios P. Spithourakis'}, {'name': 'Sebastian Riedel'}], 'author_detail': {'name': 'Sebastian Riedel'}, 'author': 'Sebastian Riedel', 'arxiv_comment': '6 pages, 1 figure, 3 tables; additional reference and details added,\n  typos and wording corrected', 'links': [{'href': 'http://arxiv.org/abs/1707.03264v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1707.03264v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
422,http://arxiv.org/abs/1706.05924v2,2017-07-17 17:17:37+00:00,2017-06-19 13:26:41+00:00,"""Everything I Disagree With is #FakeNews"": Correlating Political Polarization and Spread of Misinformation","[arxiv.Result.Author('Manoel Horta Ribeiro'), arxiv.Result.Author('Pedro H. Calais'), arxiv.Result.Author('Virgílio A. F. Almeida'), arxiv.Result.Author('Wagner Meira Jr')]","An important challenge in the process of tracking and detecting the
dissemination of misinformation is to understand the political gap between
people that engage with the so called ""fake news"". A possible factor
responsible for this gap is opinion polarization, which may prompt the general
public to classify content that they disagree or want to discredit as fake. In
this work, we study the relationship between political polarization and content
reported by Twitter users as related to ""fake news"". We investigate how
polarization may create distinct narratives on what misinformation actually is.
We perform our study based on two datasets collected from Twitter. The first
dataset contains tweets about US politics in general, from which we compute the
degree of polarization of each user towards the Republican and Democratic
Party. In the second dataset, we collect tweets and URLs that co-occurred with
""fake news"" related keywords and hashtags, such as #FakeNews and
#AlternativeFact, as well as reactions towards such tweets and URLs. We then
analyze the relationship between polarization and what is perceived as
misinformation, and whether users are designating information that they
disagree as fake. Our results show an increase in the polarization of users and
URLs associated with fake-news keywords and hashtags, when compared to
information not labeled as ""fake news"". We discuss the impact of our findings
on the challenges of tracking ""fake news"" in the ongoing battle against
misinformation.","8 pages, 10 figures, to be presented at DS+J Workshop @ KDD'17",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1706.05924v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1706.05924v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1706.05924v2,"{'id': 'http://arxiv.org/abs/1706.05924v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1706.05924v2', 'updated': '2017-07-17T17:17:37Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=17, tm_hour=17, tm_min=17, tm_sec=37, tm_wday=0, tm_yday=198, tm_isdst=0), 'published': '2017-06-19T13:26:41Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=19, tm_hour=13, tm_min=26, tm_sec=41, tm_wday=0, tm_yday=170, tm_isdst=0), 'title': '""Everything I Disagree With is #FakeNews"": Correlating Political\n  Polarization and Spread of Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Everything I Disagree With is #FakeNews"": Correlating Political\n  Polarization and Spread of Misinformation'}, 'summary': 'An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called ""fake news"". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to ""fake news"". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n""fake news"" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as ""fake news"". We discuss the impact of our findings\non the challenges of tracking ""fake news"" in the ongoing battle against\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called ""fake news"". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to ""fake news"". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n""fake news"" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as ""fake news"". We discuss the impact of our findings\non the challenges of tracking ""fake news"" in the ongoing battle against\nmisinformation.'}, 'authors': [{'name': 'Manoel Horta Ribeiro'}, {'name': 'Pedro H. Calais'}, {'name': 'Virgílio A. F. Almeida'}, {'name': 'Wagner Meira Jr'}], 'author_detail': {'name': 'Wagner Meira Jr'}, 'author': 'Wagner Meira Jr', 'arxiv_comment': ""8 pages, 10 figures, to be presented at DS+J Workshop @ KDD'17"", 'links': [{'href': 'http://arxiv.org/abs/1706.05924v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1706.05924v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
423,http://arxiv.org/abs/1705.01613v2,2018-05-30 21:08:44+00:00,2017-05-03 20:34:19+00:00,Automatically Identifying Fake News in Popular Twitter Threads,"[arxiv.Result.Author('Cody Buntain'), arxiv.Result.Author('Jennifer Golbeck')]","Information quality in social media is an increasingly important issue, but
web-scale data hinders experts' ability to assess and correct much of the
inaccurate content, or `fake news,' present in these platforms. This paper
develops a method for automating fake news detection on Twitter by learning to
predict accuracy assessments in two credibility-focused Twitter datasets:
CREDBANK, a crowdsourced dataset of accuracy assessments for events in Twitter,
and PHEME, a dataset of potential rumors in Twitter and journalistic
assessments of their accuracies. We apply this method to Twitter content
sourced from BuzzFeed's fake news dataset and show models trained against
crowdsourced workers outperform models based on journalists' assessment and
models trained on a pooled dataset of both crowdsourced workers and
journalists. All three datasets, aligned into a uniform format, are also
publicly available. A feature analysis then identifies features that are most
predictive for crowdsourced and journalistic accuracy assessments, results of
which are consistent with prior work. We close with a discussion contrasting
accuracy and credibility and why models of non-experts outperform models of
journalists for fake news detection in Twitter.",,2017 IEEE International Conference on Smart Cloud (SmartCloud),10.1109/SmartCloud.2017.40,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/SmartCloud.2017.40', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1705.01613v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1705.01613v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1705.01613v2,"{'id': 'http://arxiv.org/abs/1705.01613v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1705.01613v2', 'updated': '2018-05-30T21:08:44Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=30, tm_hour=21, tm_min=8, tm_sec=44, tm_wday=2, tm_yday=150, tm_isdst=0), 'published': '2017-05-03T20:34:19Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=3, tm_hour=20, tm_min=34, tm_sec=19, tm_wday=2, tm_yday=123, tm_isdst=0), 'title': 'Automatically Identifying Fake News in Popular Twitter Threads', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatically Identifying Fake News in Popular Twitter Threads'}, 'summary': ""Information quality in social media is an increasingly important issue, but\nweb-scale data hinders experts' ability to assess and correct much of the\ninaccurate content, or `fake news,' present in these platforms. This paper\ndevelops a method for automating fake news detection on Twitter by learning to\npredict accuracy assessments in two credibility-focused Twitter datasets:\nCREDBANK, a crowdsourced dataset of accuracy assessments for events in Twitter,\nand PHEME, a dataset of potential rumors in Twitter and journalistic\nassessments of their accuracies. We apply this method to Twitter content\nsourced from BuzzFeed's fake news dataset and show models trained against\ncrowdsourced workers outperform models based on journalists' assessment and\nmodels trained on a pooled dataset of both crowdsourced workers and\njournalists. All three datasets, aligned into a uniform format, are also\npublicly available. A feature analysis then identifies features that are most\npredictive for crowdsourced and journalistic accuracy assessments, results of\nwhich are consistent with prior work. We close with a discussion contrasting\naccuracy and credibility and why models of non-experts outperform models of\njournalists for fake news detection in Twitter."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Information quality in social media is an increasingly important issue, but\nweb-scale data hinders experts' ability to assess and correct much of the\ninaccurate content, or `fake news,' present in these platforms. This paper\ndevelops a method for automating fake news detection on Twitter by learning to\npredict accuracy assessments in two credibility-focused Twitter datasets:\nCREDBANK, a crowdsourced dataset of accuracy assessments for events in Twitter,\nand PHEME, a dataset of potential rumors in Twitter and journalistic\nassessments of their accuracies. We apply this method to Twitter content\nsourced from BuzzFeed's fake news dataset and show models trained against\ncrowdsourced workers outperform models based on journalists' assessment and\nmodels trained on a pooled dataset of both crowdsourced workers and\njournalists. All three datasets, aligned into a uniform format, are also\npublicly available. A feature analysis then identifies features that are most\npredictive for crowdsourced and journalistic accuracy assessments, results of\nwhich are consistent with prior work. We close with a discussion contrasting\naccuracy and credibility and why models of non-experts outperform models of\njournalists for fake news detection in Twitter.""}, 'authors': [{'name': 'Cody Buntain'}, {'name': 'Jennifer Golbeck'}], 'author_detail': {'name': 'Jennifer Golbeck'}, 'author': 'Jennifer Golbeck', 'arxiv_doi': '10.1109/SmartCloud.2017.40', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/SmartCloud.2017.40', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1705.01613v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1705.01613v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': '2017 IEEE International Conference on Smart Cloud (SmartCloud)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
424,http://arxiv.org/abs/1705.00648v1,2017-05-01 18:20:47+00:00,2017-05-01 18:20:47+00:00,"""Liar, Liar Pants on Fire"": A New Benchmark Dataset for Fake News Detection",[arxiv.Result.Author('William Yang Wang')],"Automatic fake news detection is a challenging problem in deception
detection, and it has tremendous real-world political and social impacts.
However, statistical approaches to combating fake news has been dramatically
limited by the lack of labeled benchmark datasets. In this paper, we present
liar: a new, publicly available dataset for fake news detection. We collected a
decade-long, 12.8K manually labeled short statements in various contexts from
PolitiFact.com, which provides detailed analysis report and links to source
documents for each case. This dataset can be used for fact-checking research as
well. Notably, this new dataset is an order of magnitude larger than previously
largest public fake news datasets of similar type. Empirically, we investigate
automatic fake news detection based on surface-level linguistic patterns. We
have designed a novel, hybrid convolutional neural network to integrate
meta-data with text. We show that this hybrid approach can improve a text-only
deep learning model.",ACL 2017,,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1705.00648v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1705.00648v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1705.00648v1,"{'id': 'http://arxiv.org/abs/1705.00648v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1705.00648v1', 'updated': '2017-05-01T18:20:47Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=1, tm_hour=18, tm_min=20, tm_sec=47, tm_wday=0, tm_yday=121, tm_isdst=0), 'published': '2017-05-01T18:20:47Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=1, tm_hour=18, tm_min=20, tm_sec=47, tm_wday=0, tm_yday=121, tm_isdst=0), 'title': '""Liar, Liar Pants on Fire"": A New Benchmark Dataset for Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Liar, Liar Pants on Fire"": A New Benchmark Dataset for Fake News\n  Detection'}, 'summary': 'Automatic fake news detection is a challenging problem in deception\ndetection, and it has tremendous real-world political and social impacts.\nHowever, statistical approaches to combating fake news has been dramatically\nlimited by the lack of labeled benchmark datasets. In this paper, we present\nliar: a new, publicly available dataset for fake news detection. We collected a\ndecade-long, 12.8K manually labeled short statements in various contexts from\nPolitiFact.com, which provides detailed analysis report and links to source\ndocuments for each case. This dataset can be used for fact-checking research as\nwell. Notably, this new dataset is an order of magnitude larger than previously\nlargest public fake news datasets of similar type. Empirically, we investigate\nautomatic fake news detection based on surface-level linguistic patterns. We\nhave designed a novel, hybrid convolutional neural network to integrate\nmeta-data with text. We show that this hybrid approach can improve a text-only\ndeep learning model.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic fake news detection is a challenging problem in deception\ndetection, and it has tremendous real-world political and social impacts.\nHowever, statistical approaches to combating fake news has been dramatically\nlimited by the lack of labeled benchmark datasets. In this paper, we present\nliar: a new, publicly available dataset for fake news detection. We collected a\ndecade-long, 12.8K manually labeled short statements in various contexts from\nPolitiFact.com, which provides detailed analysis report and links to source\ndocuments for each case. This dataset can be used for fact-checking research as\nwell. Notably, this new dataset is an order of magnitude larger than previously\nlargest public fake news datasets of similar type. Empirically, we investigate\nautomatic fake news detection based on surface-level linguistic patterns. We\nhave designed a novel, hybrid convolutional neural network to integrate\nmeta-data with text. We show that this hybrid approach can improve a text-only\ndeep learning model.'}, 'authors': [{'name': 'William Yang Wang'}], 'author_detail': {'name': 'William Yang Wang'}, 'author': 'William Yang Wang', 'arxiv_comment': 'ACL 2017', 'links': [{'href': 'http://arxiv.org/abs/1705.00648v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1705.00648v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
425,http://arxiv.org/abs/1703.09398v1,2017-03-28 04:47:11+00:00,2017-03-28 04:47:11+00:00,"This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News","[arxiv.Result.Author('Benjamin D. Horne'), arxiv.Result.Author('Sibel Adali')]","The problem of fake news has gained a lot of attention as it is claimed to
have had a significant impact on 2016 US Presidential Elections. Fake news is
not a new problem and its spread in social networks is well-studied. Often an
underlying assumption in fake news discussion is that it is written to look
like real news, fooling the reader who does not check for reliability of the
sources or the arguments in its content. Through a unique study of three data
sets and features that capture the style and the language of articles, we show
that this assumption is not true. Fake news in most cases is more similar to
satire than to real news, leading us to conclude that persuasion in fake news
is achieved through heuristics rather than the strength of arguments. We show
overall title structure and the use of proper nouns in titles are very
significant in differentiating fake from real. This leads us to conclude that
fake news is targeted for audiences who are not likely to read beyond titles
and is aimed at creating mental associations between entities and claims.","Published at The 2nd International Workshop on News and Public
  Opinion at ICWSM",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/1703.09398v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1703.09398v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1703.09398v1,"{'id': 'http://arxiv.org/abs/1703.09398v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1703.09398v1', 'updated': '2017-03-28T04:47:11Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=28, tm_hour=4, tm_min=47, tm_sec=11, tm_wday=1, tm_yday=87, tm_isdst=0), 'published': '2017-03-28T04:47:11Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=28, tm_hour=4, tm_min=47, tm_sec=11, tm_wday=1, tm_yday=87, tm_isdst=0), 'title': 'This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive\n  Content in Text Body, More Similar to Satire than Real News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive\n  Content in Text Body, More Similar to Satire than Real News'}, 'summary': 'The problem of fake news has gained a lot of attention as it is claimed to\nhave had a significant impact on 2016 US Presidential Elections. Fake news is\nnot a new problem and its spread in social networks is well-studied. Often an\nunderlying assumption in fake news discussion is that it is written to look\nlike real news, fooling the reader who does not check for reliability of the\nsources or the arguments in its content. Through a unique study of three data\nsets and features that capture the style and the language of articles, we show\nthat this assumption is not true. Fake news in most cases is more similar to\nsatire than to real news, leading us to conclude that persuasion in fake news\nis achieved through heuristics rather than the strength of arguments. We show\noverall title structure and the use of proper nouns in titles are very\nsignificant in differentiating fake from real. This leads us to conclude that\nfake news is targeted for audiences who are not likely to read beyond titles\nand is aimed at creating mental associations between entities and claims.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The problem of fake news has gained a lot of attention as it is claimed to\nhave had a significant impact on 2016 US Presidential Elections. Fake news is\nnot a new problem and its spread in social networks is well-studied. Often an\nunderlying assumption in fake news discussion is that it is written to look\nlike real news, fooling the reader who does not check for reliability of the\nsources or the arguments in its content. Through a unique study of three data\nsets and features that capture the style and the language of articles, we show\nthat this assumption is not true. Fake news in most cases is more similar to\nsatire than to real news, leading us to conclude that persuasion in fake news\nis achieved through heuristics rather than the strength of arguments. We show\noverall title structure and the use of proper nouns in titles are very\nsignificant in differentiating fake from real. This leads us to conclude that\nfake news is targeted for audiences who are not likely to read beyond titles\nand is aimed at creating mental associations between entities and claims.'}, 'authors': [{'name': 'Benjamin D. Horne'}, {'name': 'Sibel Adali'}], 'author_detail': {'name': 'Sibel Adali'}, 'author': 'Sibel Adali', 'arxiv_comment': 'Published at The 2nd International Workshop on News and Public\n  Opinion at ICWSM', 'links': [{'href': 'http://arxiv.org/abs/1703.09398v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1703.09398v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
426,http://arxiv.org/abs/1703.07823v2,2017-06-19 20:59:29+00:00,2017-03-22 19:09:12+00:00,Fake News Mitigation via Point Process Based Intervention,"[arxiv.Result.Author('Mehrdad Farajtabar'), arxiv.Result.Author('Jiachen Yang'), arxiv.Result.Author('Xiaojing Ye'), arxiv.Result.Author('Huan Xu'), arxiv.Result.Author('Rakshit Trivedi'), arxiv.Result.Author('Elias Khalil'), arxiv.Result.Author('Shuang Li'), arxiv.Result.Author('Le Song'), arxiv.Result.Author('Hongyuan Zha')]","We propose the first multistage intervention framework that tackles fake news
in social networks by combining reinforcement learning with a point process
network activity model. The spread of fake news and mitigation events within
the network is modeled by a multivariate Hawkes process with additional
exogenous control terms. By choosing a feature representation of states,
defining mitigation actions and constructing reward functions to measure the
effectiveness of mitigation activities, we map the problem of fake news
mitigation into the reinforcement learning framework. We develop a policy
iteration method unique to the multivariate networked point process, with the
goal of optimizing the actions for maximal total reward under budget
constraints. Our method shows promising performance in real-time intervention
experiments on a Twitter network to mitigate a surrogate fake news campaign,
and outperforms alternatives on synthetic datasets.","Point Process, Hawkes Process, Social Networks, Intervention and
  Control, Reinforcement Learning, ICML 2017",,,cs.LG,"['cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1703.07823v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1703.07823v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1703.07823v2,"{'id': 'http://arxiv.org/abs/1703.07823v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1703.07823v2', 'updated': '2017-06-19T20:59:29Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=19, tm_hour=20, tm_min=59, tm_sec=29, tm_wday=0, tm_yday=170, tm_isdst=0), 'published': '2017-03-22T19:09:12Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=22, tm_hour=19, tm_min=9, tm_sec=12, tm_wday=2, tm_yday=81, tm_isdst=0), 'title': 'Fake News Mitigation via Point Process Based Intervention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Mitigation via Point Process Based Intervention'}, 'summary': 'We propose the first multistage intervention framework that tackles fake news\nin social networks by combining reinforcement learning with a point process\nnetwork activity model. The spread of fake news and mitigation events within\nthe network is modeled by a multivariate Hawkes process with additional\nexogenous control terms. By choosing a feature representation of states,\ndefining mitigation actions and constructing reward functions to measure the\neffectiveness of mitigation activities, we map the problem of fake news\nmitigation into the reinforcement learning framework. We develop a policy\niteration method unique to the multivariate networked point process, with the\ngoal of optimizing the actions for maximal total reward under budget\nconstraints. Our method shows promising performance in real-time intervention\nexperiments on a Twitter network to mitigate a surrogate fake news campaign,\nand outperforms alternatives on synthetic datasets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We propose the first multistage intervention framework that tackles fake news\nin social networks by combining reinforcement learning with a point process\nnetwork activity model. The spread of fake news and mitigation events within\nthe network is modeled by a multivariate Hawkes process with additional\nexogenous control terms. By choosing a feature representation of states,\ndefining mitigation actions and constructing reward functions to measure the\neffectiveness of mitigation activities, we map the problem of fake news\nmitigation into the reinforcement learning framework. We develop a policy\niteration method unique to the multivariate networked point process, with the\ngoal of optimizing the actions for maximal total reward under budget\nconstraints. Our method shows promising performance in real-time intervention\nexperiments on a Twitter network to mitigate a surrogate fake news campaign,\nand outperforms alternatives on synthetic datasets.'}, 'authors': [{'name': 'Mehrdad Farajtabar'}, {'name': 'Jiachen Yang'}, {'name': 'Xiaojing Ye'}, {'name': 'Huan Xu'}, {'name': 'Rakshit Trivedi'}, {'name': 'Elias Khalil'}, {'name': 'Shuang Li'}, {'name': 'Le Song'}, {'name': 'Hongyuan Zha'}], 'author_detail': {'name': 'Hongyuan Zha'}, 'author': 'Hongyuan Zha', 'arxiv_comment': 'Point Process, Hawkes Process, Social Networks, Intervention and\n  Control, Reinforcement Learning, ICML 2017', 'links': [{'href': 'http://arxiv.org/abs/1703.07823v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1703.07823v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
427,http://arxiv.org/abs/1703.06988v1,2017-03-20 22:19:22+00:00,2017-03-20 22:19:22+00:00,The Fake News Spreading Plague: Was it Preventable?,"[arxiv.Result.Author('Eni Mustafaraj'), arxiv.Result.Author('Panagiotis Takis Metaxas')]","In 2010, a paper entitled ""From Obscurity to Prominence in Minutes: Political
Speech and Real-time search"" won the Best Paper Prize of the Web Science 2010
Conference. Among its findings were the discovery and documentation of what was
termed a ""Twitter-bomb"", an organized effort to spread misinformation about the
democratic candidate Martha Coakley through anonymous Twitter accounts. In this
paper, after summarizing the details of that event, we outline the recipe of
how social networks are used to spread misinformation. One of the most
important steps in such a recipe is the ""infiltration"" of a community of users
who are already engaged in conversations about a topic, to use them as organic
spreaders of misinformation in their extended subnetworks. Then, we take this
misinformation spreading recipe and indicate how it was successfully used to
spread fake news during the 2016 U.S. Presidential Election. The main
differences between the scenarios are the use of Facebook instead of Twitter,
and the respective motivations (in 2010: political influence; in 2016:
financial benefit through online advertising). After situating these events in
the broader context of exploiting the Web, we seize this opportunity to address
limitations of the reach of research findings and to start a conversation about
how communities of researchers can increase their impact on real-world societal
issues.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1703.06988v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1703.06988v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1703.06988v1,"{'id': 'http://arxiv.org/abs/1703.06988v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1703.06988v1', 'updated': '2017-03-20T22:19:22Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=20, tm_hour=22, tm_min=19, tm_sec=22, tm_wday=0, tm_yday=79, tm_isdst=0), 'published': '2017-03-20T22:19:22Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=20, tm_hour=22, tm_min=19, tm_sec=22, tm_wday=0, tm_yday=79, tm_isdst=0), 'title': 'The Fake News Spreading Plague: Was it Preventable?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Fake News Spreading Plague: Was it Preventable?'}, 'summary': 'In 2010, a paper entitled ""From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search"" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a ""Twitter-bomb"", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the ""infiltration"" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In 2010, a paper entitled ""From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search"" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a ""Twitter-bomb"", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the ""infiltration"" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.'}, 'authors': [{'name': 'Eni Mustafaraj'}, {'name': 'Panagiotis Takis Metaxas'}], 'author_detail': {'name': 'Panagiotis Takis Metaxas'}, 'author': 'Panagiotis Takis Metaxas', 'links': [{'href': 'http://arxiv.org/abs/1703.06988v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1703.06988v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
428,http://arxiv.org/abs/1703.06959v4,2017-09-03 22:05:42+00:00,2017-03-20 20:33:32+00:00,CSI: A Hybrid Deep Model for Fake News Detection,"[arxiv.Result.Author('Natali Ruchansky'), arxiv.Result.Author('Sungyong Seo'), arxiv.Result.Author('Yan Liu')]","The topic of fake news has drawn attention both from the public and the
academic communities. Such misinformation has the potential of affecting public
opinion, providing an opportunity for malicious parties to manipulate the
outcomes of public events such as elections. Because such high stakes are at
play, automatically detecting fake news is an important, yet challenging
problem that is not yet well understood. Nevertheless, there are three
generally agreed upon characteristics of fake news: the text of an article, the
user response it receives, and the source users promoting it. Existing work has
largely focused on tailoring solutions to one particular characteristic which
has limited their success and generality. In this work, we propose a model that
combines all three characteristics for a more accurate and automated
prediction. Specifically, we incorporate the behavior of both parties, users
and articles, and the group behavior of users who propagate fake news.
Motivated by the three characteristics, we propose a model called CSI which is
composed of three modules: Capture, Score, and Integrate. The first module is
based on the response and text; it uses a Recurrent Neural Network to capture
the temporal pattern of user activity on a given article. The second module
learns the source characteristic based on the behavior of users, and the two
are integrated with the third module to classify an article as fake or not.
Experimental analysis on real-world data demonstrates that CSI achieves higher
accuracy than existing models, and extracts meaningful latent representations
of both users and articles.","In Proceedings of the 26th ACM International Conference on
  Information and Knowledge Management (CIKM) 2017",,10.1145/3132847.3132877,cs.LG,"['cs.LG', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3132847.3132877', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1703.06959v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1703.06959v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1703.06959v4,"{'id': 'http://arxiv.org/abs/1703.06959v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1703.06959v4', 'updated': '2017-09-03T22:05:42Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=9, tm_mday=3, tm_hour=22, tm_min=5, tm_sec=42, tm_wday=6, tm_yday=246, tm_isdst=0), 'published': '2017-03-20T20:33:32Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=20, tm_hour=20, tm_min=33, tm_sec=32, tm_wday=0, tm_yday=79, tm_isdst=0), 'title': 'CSI: A Hybrid Deep Model for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CSI: A Hybrid Deep Model for Fake News Detection'}, 'summary': 'The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.'}, 'authors': [{'name': 'Natali Ruchansky'}, {'name': 'Sungyong Seo'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_doi': '10.1145/3132847.3132877', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3132847.3132877', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1703.06959v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1703.06959v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'In Proceedings of the 26th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2017', 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
429,http://arxiv.org/abs/1702.06016v2,2017-06-16 10:14:10+00:00,2017-02-20 15:35:27+00:00,"Public discourse and news consumption on online social media: A quantitative, cross-platform analysis of the Italian Referendum","[arxiv.Result.Author('Michela Del Vicario'), arxiv.Result.Author('Sabrina Gaito'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Matteo Zignani'), arxiv.Result.Author('Fabiana Zollo')]","The rising attention to the spreading of fake news and unsubstantiated rumors
on online social media and the pivotal role played by confirmation bias led
researchers to investigate different aspects of the phenomenon. Experimental
evidence showed that confirmatory information gets accepted even if containing
deliberately false claims while dissenting information is mainly ignored or
might even increase group polarization. It seems reasonable that, to address
misinformation problem properly, we have to understand the main determinants
behind content consumption and the emergence of narratives on online social
media. In this paper we address such a challenge by focusing on the discussion
around the Italian Constitutional Referendum by conducting a quantitative,
cross-platform analysis on both Facebook public pages and Twitter accounts. We
observe the spontaneous emergence of well-separated communities on both
platforms. Such a segregation is completely spontaneous, since no
categorization of contents was performed a priori. By exploring the dynamics
behind the discussion, we find that users tend to restrict their attention to a
specific set of Facebook pages/Twitter accounts. Finally, taking advantage of
automatic topic extraction and sentiment analysis techniques, we are able to
identify the most controversial topics inside and across both platforms. We
measure the distance between how a certain topic is presented in the
posts/tweets and the related emotional response of users. Our results provide
interesting insights for the understanding of the evolution of the core
narratives behind different echo chambers and for the early detection of
massive viral phenomena around false claims.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1702.06016v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1702.06016v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1702.06016v2,"{'id': 'http://arxiv.org/abs/1702.06016v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1702.06016v2', 'updated': '2017-06-16T10:14:10Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=16, tm_hour=10, tm_min=14, tm_sec=10, tm_wday=4, tm_yday=167, tm_isdst=0), 'published': '2017-02-20T15:35:27Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=35, tm_sec=27, tm_wday=0, tm_yday=51, tm_isdst=0), 'title': 'Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum'}, 'summary': 'The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.'}, 'authors': [{'name': 'Michela Del Vicario'}, {'name': 'Sabrina Gaito'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Matteo Zignani'}, {'name': 'Fabiana Zollo'}], 'author_detail': {'name': 'Fabiana Zollo'}, 'author': 'Fabiana Zollo', 'links': [{'href': 'http://arxiv.org/abs/1702.06016v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1702.06016v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
430,http://arxiv.org/abs/1702.05854v2,2017-02-21 08:22:53+00:00,2017-02-20 04:28:46+00:00,Blocking Self-avoiding Walks Stops Cyber-epidemics: A Scalable GPU-based Approach,"[arxiv.Result.Author('Hung T. Nguyen'), arxiv.Result.Author('Alberto Cano'), arxiv.Result.Author('Tam Vu'), arxiv.Result.Author('Thang N. Dinh')]","Cyber-epidemics, the widespread of fake news or propaganda through social
media, can cause devastating economic and political consequences. A common
countermeasure against cyber-epidemics is to disable a small subset of
suspected social connections or accounts to effectively contain the epidemics.
An example is the recent shutdown of 125,000 ISIS-related Twitter accounts.
Despite many proposed methods to identify such subset, none are scalable enough
to provide high-quality solutions in nowadays billion-size networks.
  To this end, we investigate the Spread Interdiction problems that seek most
effective links (or nodes) for removal under the well-known Linear Threshold
model. We propose novel CPU-GPU methods that scale to networks with billions of
edges, yet, possess rigorous theoretical guarantee on the solution quality. At
the core of our methods is an $O(1)$-space out-of-core algorithm to generate a
new type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a
low memory requirement enables handling of big networks and, more importantly,
hiding latency via scheduling of millions of threads on GPUs. Comprehensive
experiments on real-world networks show that our algorithms provides much
higher quality solutions and are several order of magnitude faster than the
state-of-the art. Comparing to the (single-core) CPU counterpart, our GPU
implementations achieve significant speedup factors up to 177x on a single GPU
and 338x on a GPU pair.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1702.05854v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1702.05854v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1702.05854v2,"{'id': 'http://arxiv.org/abs/1702.05854v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1702.05854v2', 'updated': '2017-02-21T08:22:53Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=21, tm_hour=8, tm_min=22, tm_sec=53, tm_wday=1, tm_yday=52, tm_isdst=0), 'published': '2017-02-20T04:28:46Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=28, tm_sec=46, tm_wday=0, tm_yday=51, tm_isdst=0), 'title': 'Blocking Self-avoiding Walks Stops Cyber-epidemics: A Scalable GPU-based\n  Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Blocking Self-avoiding Walks Stops Cyber-epidemics: A Scalable GPU-based\n  Approach'}, 'summary': 'Cyber-epidemics, the widespread of fake news or propaganda through social\nmedia, can cause devastating economic and political consequences. A common\ncountermeasure against cyber-epidemics is to disable a small subset of\nsuspected social connections or accounts to effectively contain the epidemics.\nAn example is the recent shutdown of 125,000 ISIS-related Twitter accounts.\nDespite many proposed methods to identify such subset, none are scalable enough\nto provide high-quality solutions in nowadays billion-size networks.\n  To this end, we investigate the Spread Interdiction problems that seek most\neffective links (or nodes) for removal under the well-known Linear Threshold\nmodel. We propose novel CPU-GPU methods that scale to networks with billions of\nedges, yet, possess rigorous theoretical guarantee on the solution quality. At\nthe core of our methods is an $O(1)$-space out-of-core algorithm to generate a\nnew type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a\nlow memory requirement enables handling of big networks and, more importantly,\nhiding latency via scheduling of millions of threads on GPUs. Comprehensive\nexperiments on real-world networks show that our algorithms provides much\nhigher quality solutions and are several order of magnitude faster than the\nstate-of-the art. Comparing to the (single-core) CPU counterpart, our GPU\nimplementations achieve significant speedup factors up to 177x on a single GPU\nand 338x on a GPU pair.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cyber-epidemics, the widespread of fake news or propaganda through social\nmedia, can cause devastating economic and political consequences. A common\ncountermeasure against cyber-epidemics is to disable a small subset of\nsuspected social connections or accounts to effectively contain the epidemics.\nAn example is the recent shutdown of 125,000 ISIS-related Twitter accounts.\nDespite many proposed methods to identify such subset, none are scalable enough\nto provide high-quality solutions in nowadays billion-size networks.\n  To this end, we investigate the Spread Interdiction problems that seek most\neffective links (or nodes) for removal under the well-known Linear Threshold\nmodel. We propose novel CPU-GPU methods that scale to networks with billions of\nedges, yet, possess rigorous theoretical guarantee on the solution quality. At\nthe core of our methods is an $O(1)$-space out-of-core algorithm to generate a\nnew type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a\nlow memory requirement enables handling of big networks and, more importantly,\nhiding latency via scheduling of millions of threads on GPUs. Comprehensive\nexperiments on real-world networks show that our algorithms provides much\nhigher quality solutions and are several order of magnitude faster than the\nstate-of-the art. Comparing to the (single-core) CPU counterpart, our GPU\nimplementations achieve significant speedup factors up to 177x on a single GPU\nand 338x on a GPU pair.'}, 'authors': [{'name': 'Hung T. Nguyen'}, {'name': 'Alberto Cano'}, {'name': 'Tam Vu'}, {'name': 'Thang N. Dinh'}], 'author_detail': {'name': 'Thang N. Dinh'}, 'author': 'Thang N. Dinh', 'links': [{'href': 'http://arxiv.org/abs/1702.05854v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1702.05854v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
431,http://arxiv.org/abs/1702.05638v1,2017-02-18 18:10:04+00:00,2017-02-18 18:10:04+00:00,A Stylometric Inquiry into Hyperpartisan and Fake News,"[arxiv.Result.Author('Martin Potthast'), arxiv.Result.Author('Johannes Kiesel'), arxiv.Result.Author('Kevin Reinartz'), arxiv.Result.Author('Janek Bevendorff'), arxiv.Result.Author('Benno Stein')]","This paper reports on a writing style analysis of hyperpartisan (i.e.,
extremely one-sided) news in connection to fake news. It presents a large
corpus of 1,627 articles that were manually fact-checked by professional
journalists from BuzzFeed. The articles originated from 9 well-known political
publishers, 3 each from the mainstream, the hyperpartisan left-wing, and the
hyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of
which originated from hyperpartisan publishers.
  We propose and demonstrate a new way of assessing style similarity between
text categories via Unmasking---a meta-learning approach originally devised for
authorship verification---, revealing that the style of left-wing and
right-wing news have a lot more in common than any of the two have with the
mainstream. Furthermore, we show that hyperpartisan news can be discriminated
well by its style from the mainstream (F1=0.78), as can be satire from both
(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to
scratch (F1=0.46). Nevertheless, the former results are important to implement
pre-screening for fake news detectors.","10 pages, 3 figures, 6 tables, submitted to ACL 2017",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1702.05638v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1702.05638v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1702.05638v1,"{'id': 'http://arxiv.org/abs/1702.05638v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1702.05638v1', 'updated': '2017-02-18T18:10:04Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=10, tm_sec=4, tm_wday=5, tm_yday=49, tm_isdst=0), 'published': '2017-02-18T18:10:04Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=10, tm_sec=4, tm_wday=5, tm_yday=49, tm_isdst=0), 'title': 'A Stylometric Inquiry into Hyperpartisan and Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Stylometric Inquiry into Hyperpartisan and Fake News'}, 'summary': 'This paper reports on a writing style analysis of hyperpartisan (i.e.,\nextremely one-sided) news in connection to fake news. It presents a large\ncorpus of 1,627 articles that were manually fact-checked by professional\njournalists from BuzzFeed. The articles originated from 9 well-known political\npublishers, 3 each from the mainstream, the hyperpartisan left-wing, and the\nhyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of\nwhich originated from hyperpartisan publishers.\n  We propose and demonstrate a new way of assessing style similarity between\ntext categories via Unmasking---a meta-learning approach originally devised for\nauthorship verification---, revealing that the style of left-wing and\nright-wing news have a lot more in common than any of the two have with the\nmainstream. Furthermore, we show that hyperpartisan news can be discriminated\nwell by its style from the mainstream (F1=0.78), as can be satire from both\n(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to\nscratch (F1=0.46). Nevertheless, the former results are important to implement\npre-screening for fake news detectors.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper reports on a writing style analysis of hyperpartisan (i.e.,\nextremely one-sided) news in connection to fake news. It presents a large\ncorpus of 1,627 articles that were manually fact-checked by professional\njournalists from BuzzFeed. The articles originated from 9 well-known political\npublishers, 3 each from the mainstream, the hyperpartisan left-wing, and the\nhyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of\nwhich originated from hyperpartisan publishers.\n  We propose and demonstrate a new way of assessing style similarity between\ntext categories via Unmasking---a meta-learning approach originally devised for\nauthorship verification---, revealing that the style of left-wing and\nright-wing news have a lot more in common than any of the two have with the\nmainstream. Furthermore, we show that hyperpartisan news can be discriminated\nwell by its style from the mainstream (F1=0.78), as can be satire from both\n(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to\nscratch (F1=0.46). Nevertheless, the former results are important to implement\npre-screening for fake news detectors.'}, 'authors': [{'name': 'Martin Potthast'}, {'name': 'Johannes Kiesel'}, {'name': 'Kevin Reinartz'}, {'name': 'Janek Bevendorff'}, {'name': 'Benno Stein'}], 'author_detail': {'name': 'Benno Stein'}, 'author': 'Benno Stein', 'arxiv_comment': '10 pages, 3 figures, 6 tables, submitted to ACL 2017', 'links': [{'href': 'http://arxiv.org/abs/1702.05638v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1702.05638v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
432,http://arxiv.org/abs/1603.01511v1,2016-03-04 15:59:06+00:00,2016-03-04 15:59:06+00:00,Hoaxy: A Platform for Tracking Online Misinformation,"[arxiv.Result.Author('Chengcheng Shao'), arxiv.Result.Author('Giovanni Luca Ciampaglia'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Massive amounts of misinformation have been observed to spread in
uncontrolled fashion across social media. Examples include rumors, hoaxes, fake
news, and conspiracy theories. At the same time, several journalistic
organizations devote significant efforts to high-quality fact checking of
online claims. The resulting information cascades contain instances of both
accurate and inaccurate information, unfold over multiple time scales, and
often reach audiences of considerable size. All these factors pose challenges
for the study of the social dynamics of online news sharing. Here we introduce
Hoaxy, a platform for the collection, detection, and analysis of online
misinformation and its related fact-checking efforts. We discuss the design of
the platform and present a preliminary analysis of a sample of public tweets
containing both fake news and fact checking. We find that, in the aggregate,
the sharing of fact-checking content typically lags that of misinformation by
10--20 hours. Moreover, fake news are dominated by very active users, while
fact checking is a more grass-roots activity. With the increasing risks
connected to massive online misinformation, social news observatories have the
potential to help researchers, journalists, and the general public understand
the dynamics of real and fake news sharing.","6 pages, 6 figures, submitted to Third Workshop on Social News On the
  Web",,10.1145/2872518.2890098,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1145/2872518.2890098', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1603.01511v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1603.01511v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1603.01511v1,"{'id': 'http://arxiv.org/abs/1603.01511v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1603.01511v1', 'updated': '2016-03-04T15:59:06Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=3, tm_mday=4, tm_hour=15, tm_min=59, tm_sec=6, tm_wday=4, tm_yday=64, tm_isdst=0), 'published': '2016-03-04T15:59:06Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=3, tm_mday=4, tm_hour=15, tm_min=59, tm_sec=6, tm_wday=4, tm_yday=64, tm_isdst=0), 'title': 'Hoaxy: A Platform for Tracking Online Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hoaxy: A Platform for Tracking Online Misinformation'}, 'summary': 'Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.'}, 'authors': [{'name': 'Chengcheng Shao'}, {'name': 'Giovanni Luca Ciampaglia'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1145/2872518.2890098', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/2872518.2890098', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1603.01511v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1603.01511v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '6 pages, 6 figures, submitted to Third Workshop on Social News On the\n  Web', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
433,http://arxiv.org/abs/1111.4297v1,2011-11-18 08:21:58+00:00,2011-11-18 08:21:58+00:00,Battling the Internet Water Army: Detection of Hidden Paid Posters,"[arxiv.Result.Author('Cheng Chen'), arxiv.Result.Author('Kui Wu'), arxiv.Result.Author('Venkatesh Srinivasan'), arxiv.Result.Author('Xudong Zhang')]","We initiate a systematic study to help distinguish a special group of online
users, called hidden paid posters, or termed ""Internet water army"" in China,
from the legitimate ones. On the Internet, the paid posters represent a new
type of online job opportunity. They get paid for posting comments and new
threads or articles on different online communities and websites for some
hidden purposes, e.g., to influence the opinion of other people towards certain
social events or business markets. Though an interesting strategy in business
marketing, paid posters may create a significant negative effect on the online
communities, since the information from paid posters is usually not
trustworthy. When two competitive companies hire paid posters to post fake news
or negative comments about each other, normal online users may feel overwhelmed
and find it difficult to put any trust in the information they acquire from the
Internet. In this paper, we thoroughly investigate the behavioral pattern of
online paid posters based on real-world trace data. We design and validate a
new detection mechanism, using both non-semantic analysis and semantic
analysis, to identify potential online paid posters. Our test results with
real-world datasets show a very promising performance.","10 pages, 13 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1111.4297v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1111.4297v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1111.4297v1,"{'id': 'http://arxiv.org/abs/1111.4297v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1111.4297v1', 'updated': '2011-11-18T08:21:58Z', 'updated_parsed': time.struct_time(tm_year=2011, tm_mon=11, tm_mday=18, tm_hour=8, tm_min=21, tm_sec=58, tm_wday=4, tm_yday=322, tm_isdst=0), 'published': '2011-11-18T08:21:58Z', 'published_parsed': time.struct_time(tm_year=2011, tm_mon=11, tm_mday=18, tm_hour=8, tm_min=21, tm_sec=58, tm_wday=4, tm_yday=322, tm_isdst=0), 'title': 'Battling the Internet Water Army: Detection of Hidden Paid Posters', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Battling the Internet Water Army: Detection of Hidden Paid Posters'}, 'summary': 'We initiate a systematic study to help distinguish a special group of online\nusers, called hidden paid posters, or termed ""Internet water army"" in China,\nfrom the legitimate ones. On the Internet, the paid posters represent a new\ntype of online job opportunity. They get paid for posting comments and new\nthreads or articles on different online communities and websites for some\nhidden purposes, e.g., to influence the opinion of other people towards certain\nsocial events or business markets. Though an interesting strategy in business\nmarketing, paid posters may create a significant negative effect on the online\ncommunities, since the information from paid posters is usually not\ntrustworthy. When two competitive companies hire paid posters to post fake news\nor negative comments about each other, normal online users may feel overwhelmed\nand find it difficult to put any trust in the information they acquire from the\nInternet. In this paper, we thoroughly investigate the behavioral pattern of\nonline paid posters based on real-world trace data. We design and validate a\nnew detection mechanism, using both non-semantic analysis and semantic\nanalysis, to identify potential online paid posters. Our test results with\nreal-world datasets show a very promising performance.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We initiate a systematic study to help distinguish a special group of online\nusers, called hidden paid posters, or termed ""Internet water army"" in China,\nfrom the legitimate ones. On the Internet, the paid posters represent a new\ntype of online job opportunity. They get paid for posting comments and new\nthreads or articles on different online communities and websites for some\nhidden purposes, e.g., to influence the opinion of other people towards certain\nsocial events or business markets. Though an interesting strategy in business\nmarketing, paid posters may create a significant negative effect on the online\ncommunities, since the information from paid posters is usually not\ntrustworthy. When two competitive companies hire paid posters to post fake news\nor negative comments about each other, normal online users may feel overwhelmed\nand find it difficult to put any trust in the information they acquire from the\nInternet. In this paper, we thoroughly investigate the behavioral pattern of\nonline paid posters based on real-world trace data. We design and validate a\nnew detection mechanism, using both non-semantic analysis and semantic\nanalysis, to identify potential online paid posters. Our test results with\nreal-world datasets show a very promising performance.'}, 'authors': [{'name': 'Cheng Chen'}, {'name': 'Kui Wu'}, {'name': 'Venkatesh Srinivasan'}, {'name': 'Xudong Zhang'}], 'author_detail': {'name': 'Xudong Zhang'}, 'author': 'Xudong Zhang', 'arxiv_comment': '10 pages, 13 figures', 'links': [{'href': 'http://arxiv.org/abs/1111.4297v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1111.4297v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
434,http://arxiv.org/abs/1006.4542v1,2010-06-23 14:59:47+00:00,2010-06-23 14:59:47+00:00,Algorithm and Implementation of the Blog-Post Supervision Process,"[arxiv.Result.Author('Kamanashis Biswas'), arxiv.Result.Author('Md. Liakat Ali'), arxiv.Result.Author('S. A. M. Harun')]","A web log or blog in short is a trendy way to share personal entries with
others through website. A typical blog may consist of texts, images, audios and
videos etc. Most of the blogs work as personal online diaries, while others may
focus on specific interest such as photographs (photoblog), art (artblog),
travel (tourblog), IT (techblog) etc. Another type of blogging called
microblogging is also very well known now-a-days which contains very short
posts. Like the developed countries, the users of blogs are gradually
increasing in the developing countries e.g. Bangladesh. Due to the nature of
open access to all users, some people misuse it to spread fake news to achieve
individual or political goals. Some of them also post vulgar materials that
make an embarrass situation for other bloggers. Even, sometimes it indulges the
reputation of the victim. The only way to overcome this problem is to bring all
the posts under supervision of the blog moderator. But it totally contradicts
with blogging concepts. In this paper, we have implemented an algorithm that
would help to prevent the offensive entries from being posted. These entries
would go through a supervision process to justify themselves as legal posts.
From the analysis of the result, we have shown that this approach can eliminate
the chaotic situations in blogosphere at a great extent. Our experiment shows
that about 90% of offensive posts can be detected and stopped from being
published using this approach.","IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/","Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617",,cs.OH,['cs.OH'],"[arxiv.Result.Link('http://arxiv.org/abs/1006.4542v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1006.4542v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1006.4542v1,"{'id': 'http://arxiv.org/abs/1006.4542v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1006.4542v1', 'updated': '2010-06-23T14:59:47Z', 'updated_parsed': time.struct_time(tm_year=2010, tm_mon=6, tm_mday=23, tm_hour=14, tm_min=59, tm_sec=47, tm_wday=2, tm_yday=174, tm_isdst=0), 'published': '2010-06-23T14:59:47Z', 'published_parsed': time.struct_time(tm_year=2010, tm_mon=6, tm_mday=23, tm_hour=14, tm_min=59, tm_sec=47, tm_wday=2, tm_yday=174, tm_isdst=0), 'title': 'Algorithm and Implementation of the Blog-Post Supervision Process', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Algorithm and Implementation of the Blog-Post Supervision Process'}, 'summary': 'A web log or blog in short is a trendy way to share personal entries with\nothers through website. A typical blog may consist of texts, images, audios and\nvideos etc. Most of the blogs work as personal online diaries, while others may\nfocus on specific interest such as photographs (photoblog), art (artblog),\ntravel (tourblog), IT (techblog) etc. Another type of blogging called\nmicroblogging is also very well known now-a-days which contains very short\nposts. Like the developed countries, the users of blogs are gradually\nincreasing in the developing countries e.g. Bangladesh. Due to the nature of\nopen access to all users, some people misuse it to spread fake news to achieve\nindividual or political goals. Some of them also post vulgar materials that\nmake an embarrass situation for other bloggers. Even, sometimes it indulges the\nreputation of the victim. The only way to overcome this problem is to bring all\nthe posts under supervision of the blog moderator. But it totally contradicts\nwith blogging concepts. In this paper, we have implemented an algorithm that\nwould help to prevent the offensive entries from being posted. These entries\nwould go through a supervision process to justify themselves as legal posts.\nFrom the analysis of the result, we have shown that this approach can eliminate\nthe chaotic situations in blogosphere at a great extent. Our experiment shows\nthat about 90% of offensive posts can be detected and stopped from being\npublished using this approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A web log or blog in short is a trendy way to share personal entries with\nothers through website. A typical blog may consist of texts, images, audios and\nvideos etc. Most of the blogs work as personal online diaries, while others may\nfocus on specific interest such as photographs (photoblog), art (artblog),\ntravel (tourblog), IT (techblog) etc. Another type of blogging called\nmicroblogging is also very well known now-a-days which contains very short\nposts. Like the developed countries, the users of blogs are gradually\nincreasing in the developing countries e.g. Bangladesh. Due to the nature of\nopen access to all users, some people misuse it to spread fake news to achieve\nindividual or political goals. Some of them also post vulgar materials that\nmake an embarrass situation for other bloggers. Even, sometimes it indulges the\nreputation of the victim. The only way to overcome this problem is to bring all\nthe posts under supervision of the blog moderator. But it totally contradicts\nwith blogging concepts. In this paper, we have implemented an algorithm that\nwould help to prevent the offensive entries from being posted. These entries\nwould go through a supervision process to justify themselves as legal posts.\nFrom the analysis of the result, we have shown that this approach can eliminate\nthe chaotic situations in blogosphere at a great extent. Our experiment shows\nthat about 90% of offensive posts can be detected and stopped from being\npublished using this approach.'}, 'authors': [{'name': 'Kamanashis Biswas'}, {'name': 'Md. Liakat Ali'}, {'name': 'S. A. M. Harun'}], 'author_detail': {'name': 'S. A. M. Harun'}, 'author': 'S. A. M. Harun', 'arxiv_comment': 'IEEE Publication Format,\n  https://sites.google.com/site/journalofcomputing/', 'arxiv_journal_ref': 'Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN\n  2151-9617', 'links': [{'href': 'http://arxiv.org/abs/1006.4542v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1006.4542v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.OH', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.OH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
435,http://arxiv.org/abs/hep-ph/0511088v1,2005-11-08 09:39:31+00:00,2005-11-08 09:39:31+00:00,Electroweak corrections and anomalous triple gauge-boson couplings in WW and WZ production at the LHC,"[arxiv.Result.Author('E. Accomando'), arxiv.Result.Author('A. Kaiser')]","We have analysed the production of WW and WZ vector-boson pairs at the LHC.
These processes give rise to four-fermion final states, and are particularly
sensitive to possible non-standard trilinear gauge-boson couplings. We have
studied the interplay between the influence of these anomalous couplings and
the effect of the complete logarithmic electroweak O(\alpha) corrections.
Radiative corrections to the Standard Model processes in double-pole
approximation and non-standard terms due to trilinear couplings are implemented
into a Monte Carlo program for p p -> 4f (+\gamma) with final states involving
four or two charged leptons. We numerically investigate purely leptonic final
states and find that electroweak corrections can fake new-physics signals,
modifying the observables by the same amount and shape, in kinematical regions
of statistical significance.","19 pages, LaTex, 12 eps figures","Phys.Rev.D73:093006,2006",10.1103/PhysRevD.73.093006,hep-ph,['hep-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevD.73.093006', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/hep-ph/0511088v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/hep-ph/0511088v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/hep-ph/0511088v1,"{'id': 'http://arxiv.org/abs/hep-ph/0511088v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/hep-ph/0511088v1', 'updated': '2005-11-08T09:39:31Z', 'updated_parsed': time.struct_time(tm_year=2005, tm_mon=11, tm_mday=8, tm_hour=9, tm_min=39, tm_sec=31, tm_wday=1, tm_yday=312, tm_isdst=0), 'published': '2005-11-08T09:39:31Z', 'published_parsed': time.struct_time(tm_year=2005, tm_mon=11, tm_mday=8, tm_hour=9, tm_min=39, tm_sec=31, tm_wday=1, tm_yday=312, tm_isdst=0), 'title': 'Electroweak corrections and anomalous triple gauge-boson couplings in WW\n  and WZ production at the LHC', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Electroweak corrections and anomalous triple gauge-boson couplings in WW\n  and WZ production at the LHC'}, 'summary': 'We have analysed the production of WW and WZ vector-boson pairs at the LHC.\nThese processes give rise to four-fermion final states, and are particularly\nsensitive to possible non-standard trilinear gauge-boson couplings. We have\nstudied the interplay between the influence of these anomalous couplings and\nthe effect of the complete logarithmic electroweak O(\\alpha) corrections.\nRadiative corrections to the Standard Model processes in double-pole\napproximation and non-standard terms due to trilinear couplings are implemented\ninto a Monte Carlo program for p p -> 4f (+\\gamma) with final states involving\nfour or two charged leptons. We numerically investigate purely leptonic final\nstates and find that electroweak corrections can fake new-physics signals,\nmodifying the observables by the same amount and shape, in kinematical regions\nof statistical significance.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3A%22fake+news%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We have analysed the production of WW and WZ vector-boson pairs at the LHC.\nThese processes give rise to four-fermion final states, and are particularly\nsensitive to possible non-standard trilinear gauge-boson couplings. We have\nstudied the interplay between the influence of these anomalous couplings and\nthe effect of the complete logarithmic electroweak O(\\alpha) corrections.\nRadiative corrections to the Standard Model processes in double-pole\napproximation and non-standard terms due to trilinear couplings are implemented\ninto a Monte Carlo program for p p -> 4f (+\\gamma) with final states involving\nfour or two charged leptons. We numerically investigate purely leptonic final\nstates and find that electroweak corrections can fake new-physics signals,\nmodifying the observables by the same amount and shape, in kinematical regions\nof statistical significance.'}, 'authors': [{'name': 'E. Accomando'}, {'name': 'A. Kaiser'}], 'author_detail': {'name': 'A. Kaiser'}, 'author': 'A. Kaiser', 'arxiv_doi': '10.1103/PhysRevD.73.093006', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevD.73.093006', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/hep-ph/0511088v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/hep-ph/0511088v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '19 pages, LaTex, 12 eps figures', 'arxiv_journal_ref': 'Phys.Rev.D73:093006,2006', 'arxiv_primary_category': {'term': 'hep-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'hep-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}","abs:""fake news"""
