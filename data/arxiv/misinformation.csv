,entry_id,updated,published,title,authors,summary,comment,journal_ref,doi,primary_category,categories,links,pdf_url,_raw,query
0,http://arxiv.org/abs/2110.06962v1,2021-10-13 18:06:14+00:00,2021-10-13 18:06:14+00:00,Open-Domain Question-Answering for COVID-19 and Other Emergent Domains,"[arxiv.Result.Author('Sharon Levy'), arxiv.Result.Author('Kevin Mo'), arxiv.Result.Author('Wenhan Xiong'), arxiv.Result.Author('William Yang Wang')]","Since late 2019, COVID-19 has quickly emerged as the newest biomedical
domain, resulting in a surge of new information. As with other emergent
domains, the discussion surrounding the topic has been rapidly changing,
leading to the spread of misinformation. This has created the need for a public
space for users to ask questions and receive credible, scientific answers. To
fulfill this need, we turn to the task of open-domain question-answering, which
we can use to efficiently find answers to free-text questions from a large set
of documents. In this work, we present such a system for the emergent domain of
COVID-19. Despite the small data size available, we are able to successfully
train the system to retrieve answers from a large-scale corpus of published
COVID-19 scientific papers. Furthermore, we incorporate effective re-ranking
and question-answering techniques, such as document diversity and multiple
answer spans. Our open-domain question-answering system can further act as a
model for the quick development of similar systems that can be adapted and
modified for other developing emergent domains.",EMNLP 2021 Demo,,,cs.CL,"['cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2110.06962v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.06962v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.06962v1,"{'id': 'http://arxiv.org/abs/2110.06962v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.06962v1', 'updated': '2021-10-13T18:06:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=18, tm_min=6, tm_sec=14, tm_wday=2, tm_yday=286, tm_isdst=0), 'published': '2021-10-13T18:06:14Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=18, tm_min=6, tm_sec=14, tm_wday=2, tm_yday=286, tm_isdst=0), 'title': 'Open-Domain Question-Answering for COVID-19 and Other Emergent Domains', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Open-Domain Question-Answering for COVID-19 and Other Emergent Domains'}, 'summary': 'Since late 2019, COVID-19 has quickly emerged as the newest biomedical\ndomain, resulting in a surge of new information. As with other emergent\ndomains, the discussion surrounding the topic has been rapidly changing,\nleading to the spread of misinformation. This has created the need for a public\nspace for users to ask questions and receive credible, scientific answers. To\nfulfill this need, we turn to the task of open-domain question-answering, which\nwe can use to efficiently find answers to free-text questions from a large set\nof documents. In this work, we present such a system for the emergent domain of\nCOVID-19. Despite the small data size available, we are able to successfully\ntrain the system to retrieve answers from a large-scale corpus of published\nCOVID-19 scientific papers. Furthermore, we incorporate effective re-ranking\nand question-answering techniques, such as document diversity and multiple\nanswer spans. Our open-domain question-answering system can further act as a\nmodel for the quick development of similar systems that can be adapted and\nmodified for other developing emergent domains.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Since late 2019, COVID-19 has quickly emerged as the newest biomedical\ndomain, resulting in a surge of new information. As with other emergent\ndomains, the discussion surrounding the topic has been rapidly changing,\nleading to the spread of misinformation. This has created the need for a public\nspace for users to ask questions and receive credible, scientific answers. To\nfulfill this need, we turn to the task of open-domain question-answering, which\nwe can use to efficiently find answers to free-text questions from a large set\nof documents. In this work, we present such a system for the emergent domain of\nCOVID-19. Despite the small data size available, we are able to successfully\ntrain the system to retrieve answers from a large-scale corpus of published\nCOVID-19 scientific papers. Furthermore, we incorporate effective re-ranking\nand question-answering techniques, such as document diversity and multiple\nanswer spans. Our open-domain question-answering system can further act as a\nmodel for the quick development of similar systems that can be adapted and\nmodified for other developing emergent domains.'}, 'authors': [{'name': 'Sharon Levy'}, {'name': 'Kevin Mo'}, {'name': 'Wenhan Xiong'}, {'name': 'William Yang Wang'}], 'author_detail': {'name': 'William Yang Wang'}, 'author': 'William Yang Wang', 'arxiv_comment': 'EMNLP 2021 Demo', 'links': [{'href': 'http://arxiv.org/abs/2110.06962v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.06962v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
1,http://arxiv.org/abs/2110.06495v1,2021-10-13 04:44:02+00:00,2021-10-13 04:44:02+00:00,Cross-lingual COVID-19 Fake News Detection,"[arxiv.Result.Author('Jiangshu Du'), arxiv.Result.Author('Yingtong Dou'), arxiv.Result.Author('Congying Xia'), arxiv.Result.Author('Limeng Cui'), arxiv.Result.Author('Jing Ma'), arxiv.Result.Author('Philip S. Yu')]","The COVID-19 pandemic poses a great threat to global public health.
Meanwhile, there is massive misinformation associated with the pandemic which
advocates unfounded or unscientific claims. Even major social media and news
outlets have made an extra effort in debunking COVID-19 misinformation, most of
the fact-checking information is in English, whereas some unmoderated COVID-19
misinformation is still circulating in other languages, threatening the health
of less-informed people in immigrant communities and developing countries. In
this paper, we make the first attempt to detect COVID-19 misinformation in a
low-resource language (Chinese) only using the fact-checked news in a
high-resource language (English). We start by curating a Chinese real&fake news
dataset according to existing fact-checking information. Then, we propose a
deep learning framework named CrossFake to jointly encode the cross-lingual
news body texts and capture the news content as much as possible. Empirical
results on our dataset demonstrate the effectiveness of CorssFake under the
cross-lingual setting and it also outperforms several monolingual and
cross-lingual fake news detectors. The dataset is available at
https://github.com/YingtongDou/CrossFake.","Accepted by SDM at ICDM, data is available at
  https://github.com/YingtongDou/CrossFake",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2110.06495v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.06495v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.06495v1,"{'id': 'http://arxiv.org/abs/2110.06495v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.06495v1', 'updated': '2021-10-13T04:44:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=4, tm_min=44, tm_sec=2, tm_wday=2, tm_yday=286, tm_isdst=0), 'published': '2021-10-13T04:44:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=4, tm_min=44, tm_sec=2, tm_wday=2, tm_yday=286, tm_isdst=0), 'title': 'Cross-lingual COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cross-lingual COVID-19 Fake News Detection'}, 'summary': 'The COVID-19 pandemic poses a great threat to global public health.\nMeanwhile, there is massive misinformation associated with the pandemic which\nadvocates unfounded or unscientific claims. Even major social media and news\noutlets have made an extra effort in debunking COVID-19 misinformation, most of\nthe fact-checking information is in English, whereas some unmoderated COVID-19\nmisinformation is still circulating in other languages, threatening the health\nof less-informed people in immigrant communities and developing countries. In\nthis paper, we make the first attempt to detect COVID-19 misinformation in a\nlow-resource language (Chinese) only using the fact-checked news in a\nhigh-resource language (English). We start by curating a Chinese real&fake news\ndataset according to existing fact-checking information. Then, we propose a\ndeep learning framework named CrossFake to jointly encode the cross-lingual\nnews body texts and capture the news content as much as possible. Empirical\nresults on our dataset demonstrate the effectiveness of CorssFake under the\ncross-lingual setting and it also outperforms several monolingual and\ncross-lingual fake news detectors. The dataset is available at\nhttps://github.com/YingtongDou/CrossFake.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic poses a great threat to global public health.\nMeanwhile, there is massive misinformation associated with the pandemic which\nadvocates unfounded or unscientific claims. Even major social media and news\noutlets have made an extra effort in debunking COVID-19 misinformation, most of\nthe fact-checking information is in English, whereas some unmoderated COVID-19\nmisinformation is still circulating in other languages, threatening the health\nof less-informed people in immigrant communities and developing countries. In\nthis paper, we make the first attempt to detect COVID-19 misinformation in a\nlow-resource language (Chinese) only using the fact-checked news in a\nhigh-resource language (English). We start by curating a Chinese real&fake news\ndataset according to existing fact-checking information. Then, we propose a\ndeep learning framework named CrossFake to jointly encode the cross-lingual\nnews body texts and capture the news content as much as possible. Empirical\nresults on our dataset demonstrate the effectiveness of CorssFake under the\ncross-lingual setting and it also outperforms several monolingual and\ncross-lingual fake news detectors. The dataset is available at\nhttps://github.com/YingtongDou/CrossFake.'}, 'authors': [{'name': 'Jiangshu Du'}, {'name': 'Yingtong Dou'}, {'name': 'Congying Xia'}, {'name': 'Limeng Cui'}, {'name': 'Jing Ma'}, {'name': 'Philip S. Yu'}], 'author_detail': {'name': 'Philip S. Yu'}, 'author': 'Philip S. Yu', 'arxiv_comment': 'Accepted by SDM at ICDM, data is available at\n  https://github.com/YingtongDou/CrossFake', 'links': [{'href': 'http://arxiv.org/abs/2110.06495v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.06495v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
2,http://arxiv.org/abs/2110.04899v1,2021-10-10 20:40:11+00:00,2021-10-10 20:40:11+00:00,Influencing the Influencers: Evaluating Person-to-Person Influence on Social Networks Using Granger Causality,"[arxiv.Result.Author('Richard Kuzma'), arxiv.Result.Author('Iain J. Cruickshank'), arxiv.Result.Author('Kathleen M. Carley')]","We introduce a novel method for analyzing person-to-person content influence
on Twitter. Using an Ego-Alter framework and Granger Causality, we examine
President Donald Trump (the Ego) and the people he retweets (Alters) as a case
study. We find that each Alter has a different scope of influence across
multiple topics, different magnitude of influence on a given topic, and the
magnitude of a single Alter's influence can vary across topics. This work is
novel in its focus on person-to-person influence and content-based influence.
Its impact is two-fold: (1) identifying ""canaries in the coal mine"" who could
be observed by misinformation researchers or platforms to identify
misinformation narratives before super-influencers spread them to large
audiences, and (2) enabling digital marketing targeted toward upstream Alters
of super-influencers.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2110.04899v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.04899v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.04899v1,"{'id': 'http://arxiv.org/abs/2110.04899v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.04899v1', 'updated': '2021-10-10T20:40:11Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=10, tm_hour=20, tm_min=40, tm_sec=11, tm_wday=6, tm_yday=283, tm_isdst=0), 'published': '2021-10-10T20:40:11Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=10, tm_hour=20, tm_min=40, tm_sec=11, tm_wday=6, tm_yday=283, tm_isdst=0), 'title': 'Influencing the Influencers: Evaluating Person-to-Person Influence on\n  Social Networks Using Granger Causality', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Influencing the Influencers: Evaluating Person-to-Person Influence on\n  Social Networks Using Granger Causality'}, 'summary': 'We introduce a novel method for analyzing person-to-person content influence\non Twitter. Using an Ego-Alter framework and Granger Causality, we examine\nPresident Donald Trump (the Ego) and the people he retweets (Alters) as a case\nstudy. We find that each Alter has a different scope of influence across\nmultiple topics, different magnitude of influence on a given topic, and the\nmagnitude of a single Alter\'s influence can vary across topics. This work is\nnovel in its focus on person-to-person influence and content-based influence.\nIts impact is two-fold: (1) identifying ""canaries in the coal mine"" who could\nbe observed by misinformation researchers or platforms to identify\nmisinformation narratives before super-influencers spread them to large\naudiences, and (2) enabling digital marketing targeted toward upstream Alters\nof super-influencers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We introduce a novel method for analyzing person-to-person content influence\non Twitter. Using an Ego-Alter framework and Granger Causality, we examine\nPresident Donald Trump (the Ego) and the people he retweets (Alters) as a case\nstudy. We find that each Alter has a different scope of influence across\nmultiple topics, different magnitude of influence on a given topic, and the\nmagnitude of a single Alter\'s influence can vary across topics. This work is\nnovel in its focus on person-to-person influence and content-based influence.\nIts impact is two-fold: (1) identifying ""canaries in the coal mine"" who could\nbe observed by misinformation researchers or platforms to identify\nmisinformation narratives before super-influencers spread them to large\naudiences, and (2) enabling digital marketing targeted toward upstream Alters\nof super-influencers.'}, 'authors': [{'name': 'Richard Kuzma'}, {'name': 'Iain J. Cruickshank'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'links': [{'href': 'http://arxiv.org/abs/2110.04899v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.04899v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
3,http://arxiv.org/abs/2110.04037v1,2021-10-08 11:14:44+00:00,2021-10-08 11:14:44+00:00,Simulations for novel problems in recommendation: analyzing misinformation and data characteristics,"[arxiv.Result.Author('Alejandro Bellogín'), arxiv.Result.Author('Yashar Deldjoo')]","In this position paper, we discuss recent applications of simulation
approaches for recommender systems tasks. In particular, we describe how they
were used to analyze the problem of misinformation spreading and understand
which data characteristics affect the performance of recommendation algorithms
more significantly. We also present potential lines of future work where
simulation methods could advance the work in the recommendation community.",,,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2110.04037v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.04037v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.04037v1,"{'id': 'http://arxiv.org/abs/2110.04037v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.04037v1', 'updated': '2021-10-08T11:14:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=8, tm_hour=11, tm_min=14, tm_sec=44, tm_wday=4, tm_yday=281, tm_isdst=0), 'published': '2021-10-08T11:14:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=8, tm_hour=11, tm_min=14, tm_sec=44, tm_wday=4, tm_yday=281, tm_isdst=0), 'title': 'Simulations for novel problems in recommendation: analyzing\n  misinformation and data characteristics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Simulations for novel problems in recommendation: analyzing\n  misinformation and data characteristics'}, 'summary': 'In this position paper, we discuss recent applications of simulation\napproaches for recommender systems tasks. In particular, we describe how they\nwere used to analyze the problem of misinformation spreading and understand\nwhich data characteristics affect the performance of recommendation algorithms\nmore significantly. We also present potential lines of future work where\nsimulation methods could advance the work in the recommendation community.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this position paper, we discuss recent applications of simulation\napproaches for recommender systems tasks. In particular, we describe how they\nwere used to analyze the problem of misinformation spreading and understand\nwhich data characteristics affect the performance of recommendation algorithms\nmore significantly. We also present potential lines of future work where\nsimulation methods could advance the work in the recommendation community.'}, 'authors': [{'name': 'Alejandro Bellogín'}, {'name': 'Yashar Deldjoo'}], 'author_detail': {'name': 'Yashar Deldjoo'}, 'author': 'Yashar Deldjoo', 'links': [{'href': 'http://arxiv.org/abs/2110.04037v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.04037v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
4,http://arxiv.org/abs/2110.04149v1,2021-10-07 17:55:27+00:00,2021-10-07 17:55:27+00:00,KPop Fandoms drive COVID-19 Public Health Messaging on Social Media,"[arxiv.Result.Author('Ho-Chun Herbert Chang'), arxiv.Result.Author('Becky Pham'), arxiv.Result.Author('Emilio Ferrara')]","This report examines an unexpected but significant source of positive public
health messaging during the COVID-19 pandemic -- K-pop fandoms. Leveraging more
than 7 million tweets related to mask wearing and K-pop between March 2020 and
March 2021, we analyzed the online spread of the hashtag \#WearAMask amid
anti-mask sentiments and public health misinformation. Analyses reveal the
South Korean boyband BTS as the most significant driver of health discourse.
Tweets from health agencies and prominent figures that mentioned K-pop generate
111 times more of online response compared to tweets that did not. These tweets
also elicited a strong responses from South America, Southeast Asia, and rural
States -- areas often neglected in Twitter-based messaging by mainstream social
media campaigns. Our results suggest that public health institutions may
leverage pre-existing audience markets to synergistically diffuse and target
under-served communities both domestically and globally, especially during
health crises such as COVID-19.","12 pages, 2 figures, 2 tables",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2110.04149v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.04149v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.04149v1,"{'id': 'http://arxiv.org/abs/2110.04149v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.04149v1', 'updated': '2021-10-07T17:55:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=7, tm_hour=17, tm_min=55, tm_sec=27, tm_wday=3, tm_yday=280, tm_isdst=0), 'published': '2021-10-07T17:55:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=7, tm_hour=17, tm_min=55, tm_sec=27, tm_wday=3, tm_yday=280, tm_isdst=0), 'title': 'KPop Fandoms drive COVID-19 Public Health Messaging on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'KPop Fandoms drive COVID-19 Public Health Messaging on Social Media'}, 'summary': 'This report examines an unexpected but significant source of positive public\nhealth messaging during the COVID-19 pandemic -- K-pop fandoms. Leveraging more\nthan 7 million tweets related to mask wearing and K-pop between March 2020 and\nMarch 2021, we analyzed the online spread of the hashtag \\#WearAMask amid\nanti-mask sentiments and public health misinformation. Analyses reveal the\nSouth Korean boyband BTS as the most significant driver of health discourse.\nTweets from health agencies and prominent figures that mentioned K-pop generate\n111 times more of online response compared to tweets that did not. These tweets\nalso elicited a strong responses from South America, Southeast Asia, and rural\nStates -- areas often neglected in Twitter-based messaging by mainstream social\nmedia campaigns. Our results suggest that public health institutions may\nleverage pre-existing audience markets to synergistically diffuse and target\nunder-served communities both domestically and globally, especially during\nhealth crises such as COVID-19.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This report examines an unexpected but significant source of positive public\nhealth messaging during the COVID-19 pandemic -- K-pop fandoms. Leveraging more\nthan 7 million tweets related to mask wearing and K-pop between March 2020 and\nMarch 2021, we analyzed the online spread of the hashtag \\#WearAMask amid\nanti-mask sentiments and public health misinformation. Analyses reveal the\nSouth Korean boyband BTS as the most significant driver of health discourse.\nTweets from health agencies and prominent figures that mentioned K-pop generate\n111 times more of online response compared to tweets that did not. These tweets\nalso elicited a strong responses from South America, Southeast Asia, and rural\nStates -- areas often neglected in Twitter-based messaging by mainstream social\nmedia campaigns. Our results suggest that public health institutions may\nleverage pre-existing audience markets to synergistically diffuse and target\nunder-served communities both domestically and globally, especially during\nhealth crises such as COVID-19.'}, 'authors': [{'name': 'Ho-Chun Herbert Chang'}, {'name': 'Becky Pham'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'arxiv_comment': '12 pages, 2 figures, 2 tables', 'links': [{'href': 'http://arxiv.org/abs/2110.04149v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.04149v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
5,http://arxiv.org/abs/2110.03464v1,2021-10-07 13:45:13+00:00,2021-10-07 13:45:13+00:00,Differential Anomaly Detection for Facial Images,"[arxiv.Result.Author('Mathias Ibsen'), arxiv.Result.Author('Lázaro J. González-Soler'), arxiv.Result.Author('Christian Rathgeb'), arxiv.Result.Author('Pawel Drozdowski'), arxiv.Result.Author('Marta Gomez-Barrero'), arxiv.Result.Author('Christoph Busch')]","Due to their convenience and high accuracy, face recognition systems are
widely employed in governmental and personal security applications to
automatically recognise individuals. Despite recent advances, face recognition
systems have shown to be particularly vulnerable to identity attacks (i.e.,
digital manipulations and attack presentations). Identity attacks pose a big
security threat as they can be used to gain unauthorised access and spread
misinformation. In this context, most algorithms for detecting identity attacks
generalise poorly to attack types that are unknown at training time. To tackle
this problem, we introduce a differential anomaly detection framework in which
deep face embeddings are first extracted from pairs of images (i.e., reference
and probe) and then combined for identity attack detection. The experimental
evaluation conducted over several databases shows a high generalisation
capability of the proposed method for detecting unknown attacks in both the
digital and physical domains.",Accepted at WIFS'21,,,cs.CV,"['cs.CV', 'cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2110.03464v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.03464v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.03464v1,"{'id': 'http://arxiv.org/abs/2110.03464v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.03464v1', 'updated': '2021-10-07T13:45:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=7, tm_hour=13, tm_min=45, tm_sec=13, tm_wday=3, tm_yday=280, tm_isdst=0), 'published': '2021-10-07T13:45:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=7, tm_hour=13, tm_min=45, tm_sec=13, tm_wday=3, tm_yday=280, tm_isdst=0), 'title': 'Differential Anomaly Detection for Facial Images', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Differential Anomaly Detection for Facial Images'}, 'summary': 'Due to their convenience and high accuracy, face recognition systems are\nwidely employed in governmental and personal security applications to\nautomatically recognise individuals. Despite recent advances, face recognition\nsystems have shown to be particularly vulnerable to identity attacks (i.e.,\ndigital manipulations and attack presentations). Identity attacks pose a big\nsecurity threat as they can be used to gain unauthorised access and spread\nmisinformation. In this context, most algorithms for detecting identity attacks\ngeneralise poorly to attack types that are unknown at training time. To tackle\nthis problem, we introduce a differential anomaly detection framework in which\ndeep face embeddings are first extracted from pairs of images (i.e., reference\nand probe) and then combined for identity attack detection. The experimental\nevaluation conducted over several databases shows a high generalisation\ncapability of the proposed method for detecting unknown attacks in both the\ndigital and physical domains.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Due to their convenience and high accuracy, face recognition systems are\nwidely employed in governmental and personal security applications to\nautomatically recognise individuals. Despite recent advances, face recognition\nsystems have shown to be particularly vulnerable to identity attacks (i.e.,\ndigital manipulations and attack presentations). Identity attacks pose a big\nsecurity threat as they can be used to gain unauthorised access and spread\nmisinformation. In this context, most algorithms for detecting identity attacks\ngeneralise poorly to attack types that are unknown at training time. To tackle\nthis problem, we introduce a differential anomaly detection framework in which\ndeep face embeddings are first extracted from pairs of images (i.e., reference\nand probe) and then combined for identity attack detection. The experimental\nevaluation conducted over several databases shows a high generalisation\ncapability of the proposed method for detecting unknown attacks in both the\ndigital and physical domains.'}, 'authors': [{'name': 'Mathias Ibsen'}, {'name': 'Lázaro J. González-Soler'}, {'name': 'Christian Rathgeb'}, {'name': 'Pawel Drozdowski'}, {'name': 'Marta Gomez-Barrero'}, {'name': 'Christoph Busch'}], 'author_detail': {'name': 'Christoph Busch'}, 'author': 'Christoph Busch', 'arxiv_comment': ""Accepted at WIFS'21"", 'links': [{'href': 'http://arxiv.org/abs/2110.03464v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.03464v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
6,http://arxiv.org/abs/2110.03664v1,2021-10-04 06:17:12+00:00,2021-10-04 06:17:12+00:00,"TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity, Geo, and Gender Labels","[arxiv.Result.Author('Muhammad Imran'), arxiv.Result.Author('Umair Qazi'), arxiv.Result.Author('Ferda Ofli')]","The widespread usage of social networks during mass convergence events, such
as health emergencies and disease outbreaks, provides instant access to
citizen-generated data that carry rich information about public opinions,
sentiments, urgent needs, and situational reports. Such information can help
authorities understand the emergent situation and react accordingly. Moreover,
social media plays a vital role in tackling misinformation and disinformation.
This work presents TBCOV, a large-scale Twitter dataset comprising more than
two billion multilingual tweets related to the COVID-19 pandemic collected
worldwide over a continuous period of more than one year. More importantly,
several state-of-the-art deep learning models are used to enrich the data with
important attributes, including sentiment labels, named-entities (e.g.,
mentions of persons, organizations, locations), user types, and gender
information. Last but not least, a geotagging method is proposed to assign
country, state, county, and city information to tweets, enabling a myriad of
data analysis tasks to understand real-world issues. Our sentiment and trend
analyses reveal interesting insights and confirm TBCOV's broad coverage of
important topics.","20 pages, 13 figures, 8 tables",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2110.03664v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.03664v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.03664v1,"{'id': 'http://arxiv.org/abs/2110.03664v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.03664v1', 'updated': '2021-10-04T06:17:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=4, tm_hour=6, tm_min=17, tm_sec=12, tm_wday=0, tm_yday=277, tm_isdst=0), 'published': '2021-10-04T06:17:12Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=4, tm_hour=6, tm_min=17, tm_sec=12, tm_wday=0, tm_yday=277, tm_isdst=0), 'title': 'TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity,\n  Geo, and Gender Labels', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity,\n  Geo, and Gender Labels'}, 'summary': ""The widespread usage of social networks during mass convergence events, such\nas health emergencies and disease outbreaks, provides instant access to\ncitizen-generated data that carry rich information about public opinions,\nsentiments, urgent needs, and situational reports. Such information can help\nauthorities understand the emergent situation and react accordingly. Moreover,\nsocial media plays a vital role in tackling misinformation and disinformation.\nThis work presents TBCOV, a large-scale Twitter dataset comprising more than\ntwo billion multilingual tweets related to the COVID-19 pandemic collected\nworldwide over a continuous period of more than one year. More importantly,\nseveral state-of-the-art deep learning models are used to enrich the data with\nimportant attributes, including sentiment labels, named-entities (e.g.,\nmentions of persons, organizations, locations), user types, and gender\ninformation. Last but not least, a geotagging method is proposed to assign\ncountry, state, county, and city information to tweets, enabling a myriad of\ndata analysis tasks to understand real-world issues. Our sentiment and trend\nanalyses reveal interesting insights and confirm TBCOV's broad coverage of\nimportant topics."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The widespread usage of social networks during mass convergence events, such\nas health emergencies and disease outbreaks, provides instant access to\ncitizen-generated data that carry rich information about public opinions,\nsentiments, urgent needs, and situational reports. Such information can help\nauthorities understand the emergent situation and react accordingly. Moreover,\nsocial media plays a vital role in tackling misinformation and disinformation.\nThis work presents TBCOV, a large-scale Twitter dataset comprising more than\ntwo billion multilingual tweets related to the COVID-19 pandemic collected\nworldwide over a continuous period of more than one year. More importantly,\nseveral state-of-the-art deep learning models are used to enrich the data with\nimportant attributes, including sentiment labels, named-entities (e.g.,\nmentions of persons, organizations, locations), user types, and gender\ninformation. Last but not least, a geotagging method is proposed to assign\ncountry, state, county, and city information to tweets, enabling a myriad of\ndata analysis tasks to understand real-world issues. Our sentiment and trend\nanalyses reveal interesting insights and confirm TBCOV's broad coverage of\nimportant topics.""}, 'authors': [{'name': 'Muhammad Imran'}, {'name': 'Umair Qazi'}, {'name': 'Ferda Ofli'}], 'author_detail': {'name': 'Ferda Ofli'}, 'author': 'Ferda Ofli', 'arxiv_comment': '20 pages, 13 figures, 8 tables', 'links': [{'href': 'http://arxiv.org/abs/2110.03664v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.03664v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
7,http://arxiv.org/abs/2110.00737v1,2021-10-02 06:42:30+00:00,2021-10-02 06:42:30+00:00,"A Survey of COVID-19 Misinformation: Datasets, Detection Techniques and Open Issues","[arxiv.Result.Author('A. R. Sana Ullah'), arxiv.Result.Author('Anupam Das'), arxiv.Result.Author('Anik Das'), arxiv.Result.Author('Muhammad Ashad Kabir'), arxiv.Result.Author('Kai Shu')]","The inflammable growth of misinformation on social media and other platforms
during pandemic situations like COVID-19 can cause significant damage to the
physical and mental stability of the people. To detect such misinformation,
researchers have been applying various machine learning (ML) and deep learning
(DL) techniques. The objective of this study is to systematically review,
assess, and synthesize state-of-the-art research articles that have used
different ML and DL techniques to detect COVID-19 misinformation. A structured
literature search was conducted in the relevant bibliographic databases to
ensure that the survey solely centered on reproducible and high-quality
research. We reviewed 43 papers that fulfilled our inclusion criteria out of
260 articles found from our keyword search. We have surveyed a complete
pipeline of COVID-19 misinformation detection. In particular, we identify
various COVID-19 misinformation datasets and review different data processing,
feature extraction, and classification techniques to detect COVID-19
misinformation. At the end, the challenges and limitations in detecting
COVID-19 misinformation using machine learning techniques and the future
research directions are discussed.","47 pages, 6 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2110.00737v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.00737v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.00737v1,"{'id': 'http://arxiv.org/abs/2110.00737v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.00737v1', 'updated': '2021-10-02T06:42:30Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=2, tm_hour=6, tm_min=42, tm_sec=30, tm_wday=5, tm_yday=275, tm_isdst=0), 'published': '2021-10-02T06:42:30Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=2, tm_hour=6, tm_min=42, tm_sec=30, tm_wday=5, tm_yday=275, tm_isdst=0), 'title': 'A Survey of COVID-19 Misinformation: Datasets, Detection Techniques and\n  Open Issues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey of COVID-19 Misinformation: Datasets, Detection Techniques and\n  Open Issues'}, 'summary': 'The inflammable growth of misinformation on social media and other platforms\nduring pandemic situations like COVID-19 can cause significant damage to the\nphysical and mental stability of the people. To detect such misinformation,\nresearchers have been applying various machine learning (ML) and deep learning\n(DL) techniques. The objective of this study is to systematically review,\nassess, and synthesize state-of-the-art research articles that have used\ndifferent ML and DL techniques to detect COVID-19 misinformation. A structured\nliterature search was conducted in the relevant bibliographic databases to\nensure that the survey solely centered on reproducible and high-quality\nresearch. We reviewed 43 papers that fulfilled our inclusion criteria out of\n260 articles found from our keyword search. We have surveyed a complete\npipeline of COVID-19 misinformation detection. In particular, we identify\nvarious COVID-19 misinformation datasets and review different data processing,\nfeature extraction, and classification techniques to detect COVID-19\nmisinformation. At the end, the challenges and limitations in detecting\nCOVID-19 misinformation using machine learning techniques and the future\nresearch directions are discussed.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The inflammable growth of misinformation on social media and other platforms\nduring pandemic situations like COVID-19 can cause significant damage to the\nphysical and mental stability of the people. To detect such misinformation,\nresearchers have been applying various machine learning (ML) and deep learning\n(DL) techniques. The objective of this study is to systematically review,\nassess, and synthesize state-of-the-art research articles that have used\ndifferent ML and DL techniques to detect COVID-19 misinformation. A structured\nliterature search was conducted in the relevant bibliographic databases to\nensure that the survey solely centered on reproducible and high-quality\nresearch. We reviewed 43 papers that fulfilled our inclusion criteria out of\n260 articles found from our keyword search. We have surveyed a complete\npipeline of COVID-19 misinformation detection. In particular, we identify\nvarious COVID-19 misinformation datasets and review different data processing,\nfeature extraction, and classification techniques to detect COVID-19\nmisinformation. At the end, the challenges and limitations in detecting\nCOVID-19 misinformation using machine learning techniques and the future\nresearch directions are discussed.'}, 'authors': [{'name': 'A. R. Sana Ullah'}, {'name': 'Anupam Das'}, {'name': 'Anik Das'}, {'name': 'Muhammad Ashad Kabir'}, {'name': 'Kai Shu'}], 'author_detail': {'name': 'Kai Shu'}, 'author': 'Kai Shu', 'arxiv_comment': '47 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2110.00737v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.00737v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
8,http://arxiv.org/abs/2110.00230v1,2021-10-01 06:38:19+00:00,2021-10-01 06:38:19+00:00,Users' ability to perceive misinformation: An information quality assessment approach,"[arxiv.Result.Author('Aljaž Zrnec'), arxiv.Result.Author('Marko Poženel'), arxiv.Result.Author('Dejan Lavbič')]","Digital information exchange enables quick creation and sharing of
information and thus changes existing habits. Social media is becoming the main
source of news for end-users replacing traditional media. This also enables the
proliferation of fake news, which misinforms readers and is used to serve the
interests of the creators. As a result, automated fake news detection systems
are attracting attention. However, automatic fake news detection presents a
major challenge; content evaluation is increasingly becoming the responsibility
of the end-user. Thus, in the present study we used information quality (IQ) as
an instrument to investigate how users can detect fake news. Specifically, we
examined how users perceive fake news in the form of shorter paragraphs on
individual IQ dimensions. We also investigated which user characteristics might
affect fake news detection. We performed an empirical study with 1123 users,
who evaluated randomly generated stories with statements of various level of
correctness by individual IQ dimensions. The results reveal that IQ can be used
as a tool for fake news detection. Our findings show that (1) domain knowledge
has a positive impact on fake news detection; (2) education in combination with
domain knowledge improves fake news detection; and (3) personality trait
conscientiousness contributes significantly to fake news detection in all
dimensions.",,Information Processing & Management 59 (2020),10.1016/j.ipm.2021.102739,cs.IT,"['cs.IT', 'math.IT']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.ipm.2021.102739', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2110.00230v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.00230v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.00230v1,"{'id': 'http://arxiv.org/abs/2110.00230v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.00230v1', 'updated': '2021-10-01T06:38:19Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=1, tm_hour=6, tm_min=38, tm_sec=19, tm_wday=4, tm_yday=274, tm_isdst=0), 'published': '2021-10-01T06:38:19Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=1, tm_hour=6, tm_min=38, tm_sec=19, tm_wday=4, tm_yday=274, tm_isdst=0), 'title': ""Users' ability to perceive misinformation: An information quality\n  assessment approach"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Users' ability to perceive misinformation: An information quality\n  assessment approach""}, 'summary': 'Digital information exchange enables quick creation and sharing of\ninformation and thus changes existing habits. Social media is becoming the main\nsource of news for end-users replacing traditional media. This also enables the\nproliferation of fake news, which misinforms readers and is used to serve the\ninterests of the creators. As a result, automated fake news detection systems\nare attracting attention. However, automatic fake news detection presents a\nmajor challenge; content evaluation is increasingly becoming the responsibility\nof the end-user. Thus, in the present study we used information quality (IQ) as\nan instrument to investigate how users can detect fake news. Specifically, we\nexamined how users perceive fake news in the form of shorter paragraphs on\nindividual IQ dimensions. We also investigated which user characteristics might\naffect fake news detection. We performed an empirical study with 1123 users,\nwho evaluated randomly generated stories with statements of various level of\ncorrectness by individual IQ dimensions. The results reveal that IQ can be used\nas a tool for fake news detection. Our findings show that (1) domain knowledge\nhas a positive impact on fake news detection; (2) education in combination with\ndomain knowledge improves fake news detection; and (3) personality trait\nconscientiousness contributes significantly to fake news detection in all\ndimensions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Digital information exchange enables quick creation and sharing of\ninformation and thus changes existing habits. Social media is becoming the main\nsource of news for end-users replacing traditional media. This also enables the\nproliferation of fake news, which misinforms readers and is used to serve the\ninterests of the creators. As a result, automated fake news detection systems\nare attracting attention. However, automatic fake news detection presents a\nmajor challenge; content evaluation is increasingly becoming the responsibility\nof the end-user. Thus, in the present study we used information quality (IQ) as\nan instrument to investigate how users can detect fake news. Specifically, we\nexamined how users perceive fake news in the form of shorter paragraphs on\nindividual IQ dimensions. We also investigated which user characteristics might\naffect fake news detection. We performed an empirical study with 1123 users,\nwho evaluated randomly generated stories with statements of various level of\ncorrectness by individual IQ dimensions. The results reveal that IQ can be used\nas a tool for fake news detection. Our findings show that (1) domain knowledge\nhas a positive impact on fake news detection; (2) education in combination with\ndomain knowledge improves fake news detection; and (3) personality trait\nconscientiousness contributes significantly to fake news detection in all\ndimensions.'}, 'authors': [{'name': 'Aljaž Zrnec'}, {'name': 'Marko Poženel'}, {'name': 'Dejan Lavbič'}], 'author_detail': {'name': 'Dejan Lavbič'}, 'author': 'Dejan Lavbič', 'arxiv_doi': '10.1016/j.ipm.2021.102739', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.ipm.2021.102739', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2110.00230v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.00230v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Information Processing & Management 59 (2020)', 'arxiv_primary_category': {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
9,http://arxiv.org/abs/2110.00070v1,2021-09-30 20:00:18+00:00,2021-09-30 20:00:18+00:00,What Happened in Social Media during the 2020 BLM Movement? An Analysis of Deleted and Suspended Users in Twitter,"[arxiv.Result.Author('Cagri Toraman'), arxiv.Result.Author('Furkan Şahinuç'), arxiv.Result.Author('Eyup Halit Yilmaz')]","After George Floyd's death in May 2020, the volume of discussion in social
media increased dramatically. A series of protests followed this tragic event,
called as the 2020 BlackLivesMatter (BLM) movement. People participated in the
discussion for several reasons; including protesting and advocacy, as well as
spamming and misinformation spread. Eventually, many user accounts are deleted
by their owners or suspended due to violating the rules of social media
platforms. In this study, we analyze what happened in Twitter before and after
the event triggers. We create a novel dataset that includes approximately 500k
users sharing 20m tweets, half of whom actively participated in the 2020 BLM
discussion, but some of them were deleted or suspended later. We have the
following research questions: What differences exist (i) between the users who
did participate and not participate in the BLM discussion, and (ii) between old
and new users who participated in the discussion? And, (iii) why are users
deleted and suspended? To find answers, we conduct several experiments
supported by statistical tests; including lexical analysis, spamming, negative
language, hate speech, and misinformation spread.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2110.00070v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2110.00070v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2110.00070v1,"{'id': 'http://arxiv.org/abs/2110.00070v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2110.00070v1', 'updated': '2021-09-30T20:00:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=30, tm_hour=20, tm_min=0, tm_sec=18, tm_wday=3, tm_yday=273, tm_isdst=0), 'published': '2021-09-30T20:00:18Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=30, tm_hour=20, tm_min=0, tm_sec=18, tm_wday=3, tm_yday=273, tm_isdst=0), 'title': 'What Happened in Social Media during the 2020 BLM Movement? An Analysis\n  of Deleted and Suspended Users in Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What Happened in Social Media during the 2020 BLM Movement? An Analysis\n  of Deleted and Suspended Users in Twitter'}, 'summary': ""After George Floyd's death in May 2020, the volume of discussion in social\nmedia increased dramatically. A series of protests followed this tragic event,\ncalled as the 2020 BlackLivesMatter (BLM) movement. People participated in the\ndiscussion for several reasons; including protesting and advocacy, as well as\nspamming and misinformation spread. Eventually, many user accounts are deleted\nby their owners or suspended due to violating the rules of social media\nplatforms. In this study, we analyze what happened in Twitter before and after\nthe event triggers. We create a novel dataset that includes approximately 500k\nusers sharing 20m tweets, half of whom actively participated in the 2020 BLM\ndiscussion, but some of them were deleted or suspended later. We have the\nfollowing research questions: What differences exist (i) between the users who\ndid participate and not participate in the BLM discussion, and (ii) between old\nand new users who participated in the discussion? And, (iii) why are users\ndeleted and suspended? To find answers, we conduct several experiments\nsupported by statistical tests; including lexical analysis, spamming, negative\nlanguage, hate speech, and misinformation spread."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""After George Floyd's death in May 2020, the volume of discussion in social\nmedia increased dramatically. A series of protests followed this tragic event,\ncalled as the 2020 BlackLivesMatter (BLM) movement. People participated in the\ndiscussion for several reasons; including protesting and advocacy, as well as\nspamming and misinformation spread. Eventually, many user accounts are deleted\nby their owners or suspended due to violating the rules of social media\nplatforms. In this study, we analyze what happened in Twitter before and after\nthe event triggers. We create a novel dataset that includes approximately 500k\nusers sharing 20m tweets, half of whom actively participated in the 2020 BLM\ndiscussion, but some of them were deleted or suspended later. We have the\nfollowing research questions: What differences exist (i) between the users who\ndid participate and not participate in the BLM discussion, and (ii) between old\nand new users who participated in the discussion? And, (iii) why are users\ndeleted and suspended? To find answers, we conduct several experiments\nsupported by statistical tests; including lexical analysis, spamming, negative\nlanguage, hate speech, and misinformation spread.""}, 'authors': [{'name': 'Cagri Toraman'}, {'name': 'Furkan Şahinuç'}, {'name': 'Eyup Halit Yilmaz'}], 'author_detail': {'name': 'Eyup Halit Yilmaz'}, 'author': 'Eyup Halit Yilmaz', 'links': [{'href': 'http://arxiv.org/abs/2110.00070v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2110.00070v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
10,http://arxiv.org/abs/2109.14087v1,2021-09-28 23:05:46+00:00,2021-09-28 23:05:46+00:00,"Spreading of fake news, competence, and learning: kinetic modeling and numerical approximation","[arxiv.Result.Author('Jonathan Franceschi'), arxiv.Result.Author('Lorenzo Pareschi')]","The rise of social networks as the primary means of communication in almost
every country in the world has simultaneously triggered an increase in the
amount of fake news circulating online. This fact became particularly evident
during the 2016 U.S. political elections and even more so with the advent of
the COVID-19 pandemic. Several research studies have shown how the effects of
fake news dissemination can be mitigated by promoting greater competence
through lifelong learning and discussion communities, and generally rigorous
training in the scientific method and broad interdisciplinary education. The
urgent need for models that can describe the growing infodemic of fake news has
been highlighted by the current pandemic. The resulting slowdown in vaccination
campaigns due to misinformation and generally the inability of individuals to
discern the reliability of information is posing enormous risks to the
governments of many countries. In this research using the tools of kinetic
theory we describe the interaction between fake news spreading and competence
of individuals through multi-population models in which fake news spreads
analogously to an infectious disease with different impact depending on the
level of competence of individuals. The level of competence, in particular, is
subject to an evolutionary dynamic due to both social interactions between
agents and external learning dynamics. The results show how the model is able
to correctly describe the dynamics of diffusion of fake news and the important
role of competence in their containment.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.NA', 'cs.SI', 'math.NA']","[arxiv.Result.Link('http://arxiv.org/abs/2109.14087v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.14087v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.14087v1,"{'id': 'http://arxiv.org/abs/2109.14087v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.14087v1', 'updated': '2021-09-28T23:05:46Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=23, tm_min=5, tm_sec=46, tm_wday=1, tm_yday=271, tm_isdst=0), 'published': '2021-09-28T23:05:46Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=23, tm_min=5, tm_sec=46, tm_wday=1, tm_yday=271, tm_isdst=0), 'title': 'Spreading of fake news, competence, and learning: kinetic modeling and\n  numerical approximation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Spreading of fake news, competence, and learning: kinetic modeling and\n  numerical approximation'}, 'summary': 'The rise of social networks as the primary means of communication in almost\nevery country in the world has simultaneously triggered an increase in the\namount of fake news circulating online. This fact became particularly evident\nduring the 2016 U.S. political elections and even more so with the advent of\nthe COVID-19 pandemic. Several research studies have shown how the effects of\nfake news dissemination can be mitigated by promoting greater competence\nthrough lifelong learning and discussion communities, and generally rigorous\ntraining in the scientific method and broad interdisciplinary education. The\nurgent need for models that can describe the growing infodemic of fake news has\nbeen highlighted by the current pandemic. The resulting slowdown in vaccination\ncampaigns due to misinformation and generally the inability of individuals to\ndiscern the reliability of information is posing enormous risks to the\ngovernments of many countries. In this research using the tools of kinetic\ntheory we describe the interaction between fake news spreading and competence\nof individuals through multi-population models in which fake news spreads\nanalogously to an infectious disease with different impact depending on the\nlevel of competence of individuals. The level of competence, in particular, is\nsubject to an evolutionary dynamic due to both social interactions between\nagents and external learning dynamics. The results show how the model is able\nto correctly describe the dynamics of diffusion of fake news and the important\nrole of competence in their containment.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of social networks as the primary means of communication in almost\nevery country in the world has simultaneously triggered an increase in the\namount of fake news circulating online. This fact became particularly evident\nduring the 2016 U.S. political elections and even more so with the advent of\nthe COVID-19 pandemic. Several research studies have shown how the effects of\nfake news dissemination can be mitigated by promoting greater competence\nthrough lifelong learning and discussion communities, and generally rigorous\ntraining in the scientific method and broad interdisciplinary education. The\nurgent need for models that can describe the growing infodemic of fake news has\nbeen highlighted by the current pandemic. The resulting slowdown in vaccination\ncampaigns due to misinformation and generally the inability of individuals to\ndiscern the reliability of information is posing enormous risks to the\ngovernments of many countries. In this research using the tools of kinetic\ntheory we describe the interaction between fake news spreading and competence\nof individuals through multi-population models in which fake news spreads\nanalogously to an infectious disease with different impact depending on the\nlevel of competence of individuals. The level of competence, in particular, is\nsubject to an evolutionary dynamic due to both social interactions between\nagents and external learning dynamics. The results show how the model is able\nto correctly describe the dynamics of diffusion of fake news and the important\nrole of competence in their containment.'}, 'authors': [{'name': 'Jonathan Franceschi'}, {'name': 'Lorenzo Pareschi'}], 'author_detail': {'name': 'Lorenzo Pareschi'}, 'author': 'Lorenzo Pareschi', 'links': [{'href': 'http://arxiv.org/abs/2109.14087v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.14087v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
11,http://arxiv.org/abs/2109.13589v1,2021-09-28 09:58:02+00:00,2021-09-28 09:58:02+00:00,Learning Ideological Embeddings from Information Cascades,"[arxiv.Result.Author('Corrado Monti'), arxiv.Result.Author('Giuseppe Manco'), arxiv.Result.Author('Cigdem Aslay'), arxiv.Result.Author('Francesco Bonchi')]","Modeling information cascades in a social network through the lenses of the
ideological leaning of its users can help understanding phenomena such as
misinformation propagation and confirmation bias, and devising techniques for
mitigating their toxic effects.
  In this paper we propose a stochastic model to learn the ideological leaning
of each user in a multidimensional ideological space, by analyzing the way
politically salient content propagates. In particular, our model assumes that
information propagates from one user to another if both users are interested in
the topic and ideologically aligned with each other. To infer the parameters of
our model, we devise a gradient-based optimization procedure maximizing the
likelihood of an observed set of information cascades. Our experiments on
real-world political discussions on Twitter and Reddit confirm that our model
is able to learn the political stance of the social media users in a
multidimensional ideological space.",Published in CIKM 2021,"Proceedings of the 30th ACM International Conference on
  Information and Knowledge Management (CIKM 2021)",10.1145/3459637.3482444,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG', 'J.4; G.3']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3459637.3482444', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.13589v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.13589v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.13589v1,"{'id': 'http://arxiv.org/abs/2109.13589v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.13589v1', 'updated': '2021-09-28T09:58:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=9, tm_min=58, tm_sec=2, tm_wday=1, tm_yday=271, tm_isdst=0), 'published': '2021-09-28T09:58:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=28, tm_hour=9, tm_min=58, tm_sec=2, tm_wday=1, tm_yday=271, tm_isdst=0), 'title': 'Learning Ideological Embeddings from Information Cascades', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Learning Ideological Embeddings from Information Cascades'}, 'summary': 'Modeling information cascades in a social network through the lenses of the\nideological leaning of its users can help understanding phenomena such as\nmisinformation propagation and confirmation bias, and devising techniques for\nmitigating their toxic effects.\n  In this paper we propose a stochastic model to learn the ideological leaning\nof each user in a multidimensional ideological space, by analyzing the way\npolitically salient content propagates. In particular, our model assumes that\ninformation propagates from one user to another if both users are interested in\nthe topic and ideologically aligned with each other. To infer the parameters of\nour model, we devise a gradient-based optimization procedure maximizing the\nlikelihood of an observed set of information cascades. Our experiments on\nreal-world political discussions on Twitter and Reddit confirm that our model\nis able to learn the political stance of the social media users in a\nmultidimensional ideological space.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Modeling information cascades in a social network through the lenses of the\nideological leaning of its users can help understanding phenomena such as\nmisinformation propagation and confirmation bias, and devising techniques for\nmitigating their toxic effects.\n  In this paper we propose a stochastic model to learn the ideological leaning\nof each user in a multidimensional ideological space, by analyzing the way\npolitically salient content propagates. In particular, our model assumes that\ninformation propagates from one user to another if both users are interested in\nthe topic and ideologically aligned with each other. To infer the parameters of\nour model, we devise a gradient-based optimization procedure maximizing the\nlikelihood of an observed set of information cascades. Our experiments on\nreal-world political discussions on Twitter and Reddit confirm that our model\nis able to learn the political stance of the social media users in a\nmultidimensional ideological space.'}, 'authors': [{'name': 'Corrado Monti'}, {'name': 'Giuseppe Manco'}, {'name': 'Cigdem Aslay'}, {'name': 'Francesco Bonchi'}], 'author_detail': {'name': 'Francesco Bonchi'}, 'author': 'Francesco Bonchi', 'arxiv_doi': '10.1145/3459637.3482444', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3459637.3482444', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.13589v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.13589v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published in CIKM 2021', 'arxiv_journal_ref': 'Proceedings of the 30th ACM International Conference on\n  Information and Knowledge Management (CIKM 2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.4; G.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
12,http://arxiv.org/abs/2109.12777v1,2021-09-27 03:40:28+00:00,2021-09-27 03:40:28+00:00,ReINTEL Challenge 2020: A Comparative Study of Hybrid Deep Neural Network for Reliable Intelligence Identification on Vietnamese SNSs,"[arxiv.Result.Author('Hoang Viet Trinh'), arxiv.Result.Author('Tung Tien Bui'), arxiv.Result.Author('Tam Minh Nguyen'), arxiv.Result.Author('Huy Quang Dao'), arxiv.Result.Author('Quang Huu Pham'), arxiv.Result.Author('Ngoc N. Tran'), arxiv.Result.Author('Ta Minh Thanh')]","The overwhelming abundance of data has created a misinformation crisis.
Unverified sensationalism that is designed to grab the readers' short attention
span, when crafted with malice, has caused irreparable damage to our society's
structure. As a result, determining the reliability of an article has become a
crucial task. After various ablation studies, we propose a multi-input model
that can effectively leverage both tabular metadata and post content for the
task. Applying state-of-the-art finetuning techniques for the pretrained
component and training strategies for our complete model, we have achieved a
0.9462 ROC-score on the VLSP private test set.",,"Proceedings of the 7th International Workshop on Vietnamese
  Language and Speech Processing (VLSP), Hanoi, Vietnam, 2020, pp. 6-12",,cs.LG,"['cs.LG', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2109.12777v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12777v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12777v1,"{'id': 'http://arxiv.org/abs/2109.12777v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12777v1', 'updated': '2021-09-27T03:40:28Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=3, tm_min=40, tm_sec=28, tm_wday=0, tm_yday=270, tm_isdst=0), 'published': '2021-09-27T03:40:28Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=27, tm_hour=3, tm_min=40, tm_sec=28, tm_wday=0, tm_yday=270, tm_isdst=0), 'title': 'ReINTEL Challenge 2020: A Comparative Study of Hybrid Deep Neural\n  Network for Reliable Intelligence Identification on Vietnamese SNSs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'ReINTEL Challenge 2020: A Comparative Study of Hybrid Deep Neural\n  Network for Reliable Intelligence Identification on Vietnamese SNSs'}, 'summary': ""The overwhelming abundance of data has created a misinformation crisis.\nUnverified sensationalism that is designed to grab the readers' short attention\nspan, when crafted with malice, has caused irreparable damage to our society's\nstructure. As a result, determining the reliability of an article has become a\ncrucial task. After various ablation studies, we propose a multi-input model\nthat can effectively leverage both tabular metadata and post content for the\ntask. Applying state-of-the-art finetuning techniques for the pretrained\ncomponent and training strategies for our complete model, we have achieved a\n0.9462 ROC-score on the VLSP private test set."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The overwhelming abundance of data has created a misinformation crisis.\nUnverified sensationalism that is designed to grab the readers' short attention\nspan, when crafted with malice, has caused irreparable damage to our society's\nstructure. As a result, determining the reliability of an article has become a\ncrucial task. After various ablation studies, we propose a multi-input model\nthat can effectively leverage both tabular metadata and post content for the\ntask. Applying state-of-the-art finetuning techniques for the pretrained\ncomponent and training strategies for our complete model, we have achieved a\n0.9462 ROC-score on the VLSP private test set.""}, 'authors': [{'name': 'Hoang Viet Trinh'}, {'name': 'Tung Tien Bui'}, {'name': 'Tam Minh Nguyen'}, {'name': 'Huy Quang Dao'}, {'name': 'Quang Huu Pham'}, {'name': 'Ngoc N. Tran'}, {'name': 'Ta Minh Thanh'}], 'author_detail': {'name': 'Ta Minh Thanh'}, 'author': 'Ta Minh Thanh', 'arxiv_journal_ref': 'Proceedings of the 7th International Workshop on Vietnamese\n  Language and Speech Processing (VLSP), Hanoi, Vietnam, 2020, pp. 6-12', 'links': [{'href': 'http://arxiv.org/abs/2109.12777v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12777v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
13,http://arxiv.org/abs/2109.12547v1,2021-09-26 09:52:48+00:00,2021-09-26 09:52:48+00:00,Multi-modal Fusion using Fine-tuned Self-attention and Transfer Learning for Veracity Analysis of Web Information,"[arxiv.Result.Author('Priyanka Meel'), arxiv.Result.Author('Dinesh Kumar Vishwakarma')]","The nuisance of misinformation and fake news has escalated many folds since
the advent of online social networks. Human consciousness and decision-making
capabilities are negatively influenced by manipulated, fabricated, biased or
unverified news posts. Therefore, there is a high demand for designing veracity
analysis systems to detect fake information contents in multiple data
modalities. In an attempt to find a sophisticated solution to this critical
issue, we proposed an architecture to consider both the textual and visual
attributes of the data. After the data pre-processing is done, text and image
features are extracted from the training data using separate deep learning
models. Feature extraction from text is done using BERT and ALBERT language
models that leverage the benefits of bidirectional training of transformers
using a deep self-attention mechanism. The Inception-ResNet-v2 deep neural
network model is employed for image data to perform the task. The proposed
framework focused on two independent multi-modal fusion architectures of BERT
and Inception-ResNet-v2 as well as ALBERT and Inception-ResNet-v2. Multi-modal
fusion of textual and visual branches is extensively experimented and analysed
using concatenation of feature vectors and weighted averaging of probabilities
named as Early Fusion and Late Fusion respectively. Three publicly available
broadly accepted datasets All Data, Weibo and MediaEval 2016 that incorporates
English news articles, Chinese news articles, and Tweets correspondingly are
used so that our designed framework's outcomes can be properly tested and
compared with previous notable work in the domain.","31 pages, 12 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.12547v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12547v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12547v1,"{'id': 'http://arxiv.org/abs/2109.12547v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12547v1', 'updated': '2021-09-26T09:52:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=9, tm_min=52, tm_sec=48, tm_wday=6, tm_yday=269, tm_isdst=0), 'published': '2021-09-26T09:52:48Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=9, tm_min=52, tm_sec=48, tm_wday=6, tm_yday=269, tm_isdst=0), 'title': 'Multi-modal Fusion using Fine-tuned Self-attention and Transfer Learning\n  for Veracity Analysis of Web Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multi-modal Fusion using Fine-tuned Self-attention and Transfer Learning\n  for Veracity Analysis of Web Information'}, 'summary': ""The nuisance of misinformation and fake news has escalated many folds since\nthe advent of online social networks. Human consciousness and decision-making\ncapabilities are negatively influenced by manipulated, fabricated, biased or\nunverified news posts. Therefore, there is a high demand for designing veracity\nanalysis systems to detect fake information contents in multiple data\nmodalities. In an attempt to find a sophisticated solution to this critical\nissue, we proposed an architecture to consider both the textual and visual\nattributes of the data. After the data pre-processing is done, text and image\nfeatures are extracted from the training data using separate deep learning\nmodels. Feature extraction from text is done using BERT and ALBERT language\nmodels that leverage the benefits of bidirectional training of transformers\nusing a deep self-attention mechanism. The Inception-ResNet-v2 deep neural\nnetwork model is employed for image data to perform the task. The proposed\nframework focused on two independent multi-modal fusion architectures of BERT\nand Inception-ResNet-v2 as well as ALBERT and Inception-ResNet-v2. Multi-modal\nfusion of textual and visual branches is extensively experimented and analysed\nusing concatenation of feature vectors and weighted averaging of probabilities\nnamed as Early Fusion and Late Fusion respectively. Three publicly available\nbroadly accepted datasets All Data, Weibo and MediaEval 2016 that incorporates\nEnglish news articles, Chinese news articles, and Tweets correspondingly are\nused so that our designed framework's outcomes can be properly tested and\ncompared with previous notable work in the domain."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The nuisance of misinformation and fake news has escalated many folds since\nthe advent of online social networks. Human consciousness and decision-making\ncapabilities are negatively influenced by manipulated, fabricated, biased or\nunverified news posts. Therefore, there is a high demand for designing veracity\nanalysis systems to detect fake information contents in multiple data\nmodalities. In an attempt to find a sophisticated solution to this critical\nissue, we proposed an architecture to consider both the textual and visual\nattributes of the data. After the data pre-processing is done, text and image\nfeatures are extracted from the training data using separate deep learning\nmodels. Feature extraction from text is done using BERT and ALBERT language\nmodels that leverage the benefits of bidirectional training of transformers\nusing a deep self-attention mechanism. The Inception-ResNet-v2 deep neural\nnetwork model is employed for image data to perform the task. The proposed\nframework focused on two independent multi-modal fusion architectures of BERT\nand Inception-ResNet-v2 as well as ALBERT and Inception-ResNet-v2. Multi-modal\nfusion of textual and visual branches is extensively experimented and analysed\nusing concatenation of feature vectors and weighted averaging of probabilities\nnamed as Early Fusion and Late Fusion respectively. Three publicly available\nbroadly accepted datasets All Data, Weibo and MediaEval 2016 that incorporates\nEnglish news articles, Chinese news articles, and Tweets correspondingly are\nused so that our designed framework's outcomes can be properly tested and\ncompared with previous notable work in the domain.""}, 'authors': [{'name': 'Priyanka Meel'}, {'name': 'Dinesh Kumar Vishwakarma'}], 'author_detail': {'name': 'Dinesh Kumar Vishwakarma'}, 'author': 'Dinesh Kumar Vishwakarma', 'arxiv_comment': '31 pages, 12 figures', 'links': [{'href': 'http://arxiv.org/abs/2109.12547v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12547v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
14,http://arxiv.org/abs/2109.12523v1,2021-09-26 08:11:17+00:00,2021-09-26 08:11:17+00:00,A Study of Fake News Reading and Annotating in Social Media Context,"[arxiv.Result.Author('Jakub Simko'), arxiv.Result.Author('Patrik Racsko'), arxiv.Result.Author('Matus Tomlein'), arxiv.Result.Author('Martin Hanakova'), arxiv.Result.Author('Maria Bielikova')]","The online spreading of fake news is a major issue threatening entire
societies. Much of this spreading is enabled by new media formats, namely
social networks and online media sites. Researchers and practitioners have been
trying to answer this by characterizing the fake news and devising automated
methods for detecting them. The detection methods had so far only limited
success, mostly due to the complexity of the news content and context and lack
of properly annotated datasets. One possible way to boost the efficiency of
automated misinformation detection methods, is to imitate the detection work of
humans. It is also important to understand the news consumption behavior of
online users. In this paper, we present an eye-tracking study, in which we let
44 lay participants to casually read through a social media feed containing
posts with news articles, some of which were fake. In a second run, we asked
the participants to decide on the truthfulness of these articles. We also
describe a follow-up qualitative study with a similar scenario but this time
with 7 expert fake news annotators. We present the description of both studies,
characteristics of the resulting dataset (which we hereby publish) and several
findings.",,New Review of Hypermedia and Multimedia. pages 1-31 (2021),10.1080/13614568.2021.1889691,cs.HC,"['cs.HC', 'cs.CY', 'cs.LG', 'cs.SI', 'H.5.2; H.5.4; K.4.2; H.3.1']","[arxiv.Result.Link('http://dx.doi.org/10.1080/13614568.2021.1889691', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2109.12523v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.12523v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.12523v1,"{'id': 'http://arxiv.org/abs/2109.12523v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.12523v1', 'updated': '2021-09-26T08:11:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=8, tm_min=11, tm_sec=17, tm_wday=6, tm_yday=269, tm_isdst=0), 'published': '2021-09-26T08:11:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=26, tm_hour=8, tm_min=11, tm_sec=17, tm_wday=6, tm_yday=269, tm_isdst=0), 'title': 'A Study of Fake News Reading and Annotating in Social Media Context', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Study of Fake News Reading and Annotating in Social Media Context'}, 'summary': 'The online spreading of fake news is a major issue threatening entire\nsocieties. Much of this spreading is enabled by new media formats, namely\nsocial networks and online media sites. Researchers and practitioners have been\ntrying to answer this by characterizing the fake news and devising automated\nmethods for detecting them. The detection methods had so far only limited\nsuccess, mostly due to the complexity of the news content and context and lack\nof properly annotated datasets. One possible way to boost the efficiency of\nautomated misinformation detection methods, is to imitate the detection work of\nhumans. It is also important to understand the news consumption behavior of\nonline users. In this paper, we present an eye-tracking study, in which we let\n44 lay participants to casually read through a social media feed containing\nposts with news articles, some of which were fake. In a second run, we asked\nthe participants to decide on the truthfulness of these articles. We also\ndescribe a follow-up qualitative study with a similar scenario but this time\nwith 7 expert fake news annotators. We present the description of both studies,\ncharacteristics of the resulting dataset (which we hereby publish) and several\nfindings.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The online spreading of fake news is a major issue threatening entire\nsocieties. Much of this spreading is enabled by new media formats, namely\nsocial networks and online media sites. Researchers and practitioners have been\ntrying to answer this by characterizing the fake news and devising automated\nmethods for detecting them. The detection methods had so far only limited\nsuccess, mostly due to the complexity of the news content and context and lack\nof properly annotated datasets. One possible way to boost the efficiency of\nautomated misinformation detection methods, is to imitate the detection work of\nhumans. It is also important to understand the news consumption behavior of\nonline users. In this paper, we present an eye-tracking study, in which we let\n44 lay participants to casually read through a social media feed containing\nposts with news articles, some of which were fake. In a second run, we asked\nthe participants to decide on the truthfulness of these articles. We also\ndescribe a follow-up qualitative study with a similar scenario but this time\nwith 7 expert fake news annotators. We present the description of both studies,\ncharacteristics of the resulting dataset (which we hereby publish) and several\nfindings.'}, 'authors': [{'name': 'Jakub Simko'}, {'name': 'Patrik Racsko'}, {'name': 'Matus Tomlein'}, {'name': 'Martin Hanakova'}, {'name': 'Maria Bielikova'}], 'author_detail': {'name': 'Maria Bielikova'}, 'author': 'Maria Bielikova', 'arxiv_doi': '10.1080/13614568.2021.1889691', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1080/13614568.2021.1889691', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2109.12523v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.12523v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'New Review of Hypermedia and Multimedia. pages 1-31 (2021)', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.2; H.5.4; K.4.2; H.3.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
15,http://arxiv.org/abs/2109.10462v1,2021-09-22 00:00:02+00:00,2021-09-22 00:00:02+00:00,A Hierarchical Network-Oriented Analysis of User Participation in Misinformation Spread on WhatsApp,"[arxiv.Result.Author('Gabriel Peres Nobre'), arxiv.Result.Author('Carlos H. G. Ferreira'), arxiv.Result.Author('Jussara M. Almeida')]","WhatsApp emerged as a major communication platform in many countries in the
recent years. Despite offering only one-to-one and small group conversations,
WhatsApp has been shown to enable the formation of a rich underlying network,
crossing the boundaries of existing groups, and with structural properties that
favor information dissemination at large. Indeed, WhatsApp has reportedly been
used as a forum of misinformation campaigns with significant social, political
and economic consequences in several countries. In this article, we aim at
complementing recent studies on misinformation spread on WhatsApp, mostly
focused on content properties and propagation dynamics, by looking into the
network that connects users sharing the same piece of content. Specifically, we
present a hierarchical network-oriented characterization of the users engaged
in misinformation spread by focusing on three perspectives: individuals,
WhatsApp groups and user communities, i.e., groupings of users who,
intentionally or not, share the same content disproportionately often. By
analyzing sharing and network topological properties, our study offers valuable
insights into how WhatsApp users leverage the underlying network connecting
different groups to gain large reach in the spread of misinformation on the
platform.","Paper Accepted in Information Processing & Management, Elsevier",,,cs.SI,"['cs.SI', 'cs.AI', 'cs.CY', 'cs.LG', 'stat.CO']","[arxiv.Result.Link('http://arxiv.org/abs/2109.10462v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.10462v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.10462v1,"{'id': 'http://arxiv.org/abs/2109.10462v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.10462v1', 'updated': '2021-09-22T00:00:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=0, tm_min=0, tm_sec=2, tm_wday=2, tm_yday=265, tm_isdst=0), 'published': '2021-09-22T00:00:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=22, tm_hour=0, tm_min=0, tm_sec=2, tm_wday=2, tm_yday=265, tm_isdst=0), 'title': 'A Hierarchical Network-Oriented Analysis of User Participation in\n  Misinformation Spread on WhatsApp', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Hierarchical Network-Oriented Analysis of User Participation in\n  Misinformation Spread on WhatsApp'}, 'summary': 'WhatsApp emerged as a major communication platform in many countries in the\nrecent years. Despite offering only one-to-one and small group conversations,\nWhatsApp has been shown to enable the formation of a rich underlying network,\ncrossing the boundaries of existing groups, and with structural properties that\nfavor information dissemination at large. Indeed, WhatsApp has reportedly been\nused as a forum of misinformation campaigns with significant social, political\nand economic consequences in several countries. In this article, we aim at\ncomplementing recent studies on misinformation spread on WhatsApp, mostly\nfocused on content properties and propagation dynamics, by looking into the\nnetwork that connects users sharing the same piece of content. Specifically, we\npresent a hierarchical network-oriented characterization of the users engaged\nin misinformation spread by focusing on three perspectives: individuals,\nWhatsApp groups and user communities, i.e., groupings of users who,\nintentionally or not, share the same content disproportionately often. By\nanalyzing sharing and network topological properties, our study offers valuable\ninsights into how WhatsApp users leverage the underlying network connecting\ndifferent groups to gain large reach in the spread of misinformation on the\nplatform.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'WhatsApp emerged as a major communication platform in many countries in the\nrecent years. Despite offering only one-to-one and small group conversations,\nWhatsApp has been shown to enable the formation of a rich underlying network,\ncrossing the boundaries of existing groups, and with structural properties that\nfavor information dissemination at large. Indeed, WhatsApp has reportedly been\nused as a forum of misinformation campaigns with significant social, political\nand economic consequences in several countries. In this article, we aim at\ncomplementing recent studies on misinformation spread on WhatsApp, mostly\nfocused on content properties and propagation dynamics, by looking into the\nnetwork that connects users sharing the same piece of content. Specifically, we\npresent a hierarchical network-oriented characterization of the users engaged\nin misinformation spread by focusing on three perspectives: individuals,\nWhatsApp groups and user communities, i.e., groupings of users who,\nintentionally or not, share the same content disproportionately often. By\nanalyzing sharing and network topological properties, our study offers valuable\ninsights into how WhatsApp users leverage the underlying network connecting\ndifferent groups to gain large reach in the spread of misinformation on the\nplatform.'}, 'authors': [{'name': 'Gabriel Peres Nobre'}, {'name': 'Carlos H. G. Ferreira'}, {'name': 'Jussara M. Almeida'}], 'author_detail': {'name': 'Jussara M. Almeida'}, 'author': 'Jussara M. Almeida', 'arxiv_comment': 'Paper Accepted in Information Processing & Management, Elsevier', 'links': [{'href': 'http://arxiv.org/abs/2109.10462v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.10462v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
16,http://arxiv.org/abs/2109.09532v1,2021-09-20 13:31:15+00:00,2021-09-20 13:31:15+00:00,Characterizing User Susceptibility to COVID-19 Misinformation on Twitter,"[arxiv.Result.Author('Xian Teng'), arxiv.Result.Author('Yu-Ru Lin'), arxiv.Result.Author('Wen-Ting Chung'), arxiv.Result.Author('Ang Li'), arxiv.Result.Author('Adriana Kovashka')]","Though significant efforts such as removing false claims and promoting
reliable sources have been increased to combat COVID-19 ""misinfodemic"", it
remains an unsolved societal challenge if lacking a proper understanding of
susceptible online users, i.e., those who are likely to be attracted by,
believe and spread misinformation. This study attempts to answer {\it who}
constitutes the population vulnerable to the online misinformation in the
pandemic, and what are the robust features and short-term behavior signals that
distinguish susceptible users from others. Using a 6-month longitudinal user
panel on Twitter collected from a geopolitically diverse network-stratified
samples in the US, we distinguish different types of users, ranging from social
bots to humans with various level of engagement with COVID-related
misinformation. We then identify users' online features and situational
predictors that correlate with their susceptibility to COVID-19 misinformation.
This work brings unique contributions: First, contrary to the prior studies on
bot influence, our analysis shows that social bots' contribution to
misinformation sharing was surprisingly low, and human-like users'
misinformation behaviors exhibit heterogeneity and temporal variability. While
the sharing of misinformation was highly concentrated, the risk of occasionally
sharing misinformation for average users remained alarmingly high. Second, our
findings highlight the political sensitivity activeness and responsiveness to
emotionally-charged content among susceptible users. Third, we demonstrate a
feasible solution to efficiently predict users' transient susceptibility solely
based on their short-term news consumption and exposure from their networks.
Our work has an implication in designing effective intervention mechanism to
mitigate the misinformation dissipation.","Accepted into ICWSM 2022, 9 figures (main text)",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2109.09532v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.09532v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.09532v1,"{'id': 'http://arxiv.org/abs/2109.09532v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.09532v1', 'updated': '2021-09-20T13:31:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=13, tm_min=31, tm_sec=15, tm_wday=0, tm_yday=263, tm_isdst=0), 'published': '2021-09-20T13:31:15Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=13, tm_min=31, tm_sec=15, tm_wday=0, tm_yday=263, tm_isdst=0), 'title': 'Characterizing User Susceptibility to COVID-19 Misinformation on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing User Susceptibility to COVID-19 Misinformation on Twitter'}, 'summary': 'Though significant efforts such as removing false claims and promoting\nreliable sources have been increased to combat COVID-19 ""misinfodemic"", it\nremains an unsolved societal challenge if lacking a proper understanding of\nsusceptible online users, i.e., those who are likely to be attracted by,\nbelieve and spread misinformation. This study attempts to answer {\\it who}\nconstitutes the population vulnerable to the online misinformation in the\npandemic, and what are the robust features and short-term behavior signals that\ndistinguish susceptible users from others. Using a 6-month longitudinal user\npanel on Twitter collected from a geopolitically diverse network-stratified\nsamples in the US, we distinguish different types of users, ranging from social\nbots to humans with various level of engagement with COVID-related\nmisinformation. We then identify users\' online features and situational\npredictors that correlate with their susceptibility to COVID-19 misinformation.\nThis work brings unique contributions: First, contrary to the prior studies on\nbot influence, our analysis shows that social bots\' contribution to\nmisinformation sharing was surprisingly low, and human-like users\'\nmisinformation behaviors exhibit heterogeneity and temporal variability. While\nthe sharing of misinformation was highly concentrated, the risk of occasionally\nsharing misinformation for average users remained alarmingly high. Second, our\nfindings highlight the political sensitivity activeness and responsiveness to\nemotionally-charged content among susceptible users. Third, we demonstrate a\nfeasible solution to efficiently predict users\' transient susceptibility solely\nbased on their short-term news consumption and exposure from their networks.\nOur work has an implication in designing effective intervention mechanism to\nmitigate the misinformation dissipation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Though significant efforts such as removing false claims and promoting\nreliable sources have been increased to combat COVID-19 ""misinfodemic"", it\nremains an unsolved societal challenge if lacking a proper understanding of\nsusceptible online users, i.e., those who are likely to be attracted by,\nbelieve and spread misinformation. This study attempts to answer {\\it who}\nconstitutes the population vulnerable to the online misinformation in the\npandemic, and what are the robust features and short-term behavior signals that\ndistinguish susceptible users from others. Using a 6-month longitudinal user\npanel on Twitter collected from a geopolitically diverse network-stratified\nsamples in the US, we distinguish different types of users, ranging from social\nbots to humans with various level of engagement with COVID-related\nmisinformation. We then identify users\' online features and situational\npredictors that correlate with their susceptibility to COVID-19 misinformation.\nThis work brings unique contributions: First, contrary to the prior studies on\nbot influence, our analysis shows that social bots\' contribution to\nmisinformation sharing was surprisingly low, and human-like users\'\nmisinformation behaviors exhibit heterogeneity and temporal variability. While\nthe sharing of misinformation was highly concentrated, the risk of occasionally\nsharing misinformation for average users remained alarmingly high. Second, our\nfindings highlight the political sensitivity activeness and responsiveness to\nemotionally-charged content among susceptible users. Third, we demonstrate a\nfeasible solution to efficiently predict users\' transient susceptibility solely\nbased on their short-term news consumption and exposure from their networks.\nOur work has an implication in designing effective intervention mechanism to\nmitigate the misinformation dissipation.'}, 'authors': [{'name': 'Xian Teng'}, {'name': 'Yu-Ru Lin'}, {'name': 'Wen-Ting Chung'}, {'name': 'Ang Li'}, {'name': 'Adriana Kovashka'}], 'author_detail': {'name': 'Adriana Kovashka'}, 'author': 'Adriana Kovashka', 'arxiv_comment': 'Accepted into ICWSM 2022, 9 figures (main text)', 'links': [{'href': 'http://arxiv.org/abs/2109.09532v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.09532v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
17,http://arxiv.org/abs/2109.09322v1,2021-09-20 06:51:59+00:00,2021-09-20 06:51:59+00:00,What do fact checkers fact-check when?,"[arxiv.Result.Author('Manoel Horta Ribeiro'), arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Oana Goga'), arxiv.Result.Author('Fabrício Benevenuto'), arxiv.Result.Author('Robert West')]","Recent research suggests that not all fact checking efforts are equal: when
and what is fact checked plays a pivotal role in effectively correcting
misconceptions. In this paper, we propose a framework to study fact checking
efforts using Google Trends, a signal that captures search interest over topics
on the world's largest search engine. Our framework consists of extracting
claims from fact checking efforts, linking such claims with knowledge graph
entities, and estimating the online attention they receive. We use this
framework to study a dataset of 879 COVID-19-related fact checks done in 2020
by 81 international organizations. Our findings suggest that there is often a
disconnect between online attention and fact checking efforts. For example, in
around 40% of countries where 10 or more claims were fact checked, half or more
than half of the top 10 most popular claims were not fact checked. Our analysis
also shows that claims are first fact checked after receiving, on average, 35%
of the total online attention they would eventually receive in 2020. Yet, there
is a big variation among claims: some were fact checked before receiving a
surge of misinformation-induced online attention, others are fact checked much
later. Overall, our work suggests that the incorporation of online attention
signals may help organizations better assess and prioritize their fact checking
efforts. Also, in the context of international collaboration, where claims are
fact checked multiple times across different countries, online attention could
help organizations keep track of which claims are ""migrating"" between different
countries.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2109.09322v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.09322v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.09322v1,"{'id': 'http://arxiv.org/abs/2109.09322v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.09322v1', 'updated': '2021-09-20T06:51:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=6, tm_min=51, tm_sec=59, tm_wday=0, tm_yday=263, tm_isdst=0), 'published': '2021-09-20T06:51:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=6, tm_min=51, tm_sec=59, tm_wday=0, tm_yday=263, tm_isdst=0), 'title': 'What do fact checkers fact-check when?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What do fact checkers fact-check when?'}, 'summary': 'Recent research suggests that not all fact checking efforts are equal: when\nand what is fact checked plays a pivotal role in effectively correcting\nmisconceptions. In this paper, we propose a framework to study fact checking\nefforts using Google Trends, a signal that captures search interest over topics\non the world\'s largest search engine. Our framework consists of extracting\nclaims from fact checking efforts, linking such claims with knowledge graph\nentities, and estimating the online attention they receive. We use this\nframework to study a dataset of 879 COVID-19-related fact checks done in 2020\nby 81 international organizations. Our findings suggest that there is often a\ndisconnect between online attention and fact checking efforts. For example, in\naround 40% of countries where 10 or more claims were fact checked, half or more\nthan half of the top 10 most popular claims were not fact checked. Our analysis\nalso shows that claims are first fact checked after receiving, on average, 35%\nof the total online attention they would eventually receive in 2020. Yet, there\nis a big variation among claims: some were fact checked before receiving a\nsurge of misinformation-induced online attention, others are fact checked much\nlater. Overall, our work suggests that the incorporation of online attention\nsignals may help organizations better assess and prioritize their fact checking\nefforts. Also, in the context of international collaboration, where claims are\nfact checked multiple times across different countries, online attention could\nhelp organizations keep track of which claims are ""migrating"" between different\ncountries.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent research suggests that not all fact checking efforts are equal: when\nand what is fact checked plays a pivotal role in effectively correcting\nmisconceptions. In this paper, we propose a framework to study fact checking\nefforts using Google Trends, a signal that captures search interest over topics\non the world\'s largest search engine. Our framework consists of extracting\nclaims from fact checking efforts, linking such claims with knowledge graph\nentities, and estimating the online attention they receive. We use this\nframework to study a dataset of 879 COVID-19-related fact checks done in 2020\nby 81 international organizations. Our findings suggest that there is often a\ndisconnect between online attention and fact checking efforts. For example, in\naround 40% of countries where 10 or more claims were fact checked, half or more\nthan half of the top 10 most popular claims were not fact checked. Our analysis\nalso shows that claims are first fact checked after receiving, on average, 35%\nof the total online attention they would eventually receive in 2020. Yet, there\nis a big variation among claims: some were fact checked before receiving a\nsurge of misinformation-induced online attention, others are fact checked much\nlater. Overall, our work suggests that the incorporation of online attention\nsignals may help organizations better assess and prioritize their fact checking\nefforts. Also, in the context of international collaboration, where claims are\nfact checked multiple times across different countries, online attention could\nhelp organizations keep track of which claims are ""migrating"" between different\ncountries.'}, 'authors': [{'name': 'Manoel Horta Ribeiro'}, {'name': 'Savvas Zannettou'}, {'name': 'Oana Goga'}, {'name': 'Fabrício Benevenuto'}, {'name': 'Robert West'}], 'author_detail': {'name': 'Robert West'}, 'author': 'Robert West', 'links': [{'href': 'http://arxiv.org/abs/2109.09322v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.09322v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
18,http://arxiv.org/abs/2109.06416v2,2021-09-23 19:57:17+00:00,2021-09-14 03:57:50+00:00,MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake News Detection and a Baseline Architecture for Classification,"[arxiv.Result.Author('Mingxuan Chen'), arxiv.Result.Author('Xinqiao Chu'), arxiv.Result.Author('K. P. Subbalakshmi')]","The outbreak of COVID-19 has resulted in an ""infodemic"" that has encouraged
the propagation of misinformation about COVID-19 and cure methods which, in
turn, could negatively affect the adoption of recommended public health
measures in the larger population. In this paper, we provide a new multimodal
(consisting of images, text and temporal information) labeled dataset
containing news articles and tweets on the COVID-19 vaccine. We collected 2,593
news articles from 80 publishers for one year between Feb 16th 2020 to May 8th
2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th
2021). We combine ratings from two news media ranking sites: Medias Bias Chart
and Media Bias/Fact Check (MBFC) to classify the news dataset into two levels
of credibility: reliable and unreliable. The combination of two filters allows
for higher precision of labeling. We also propose a stance detection mechanism
to annotate tweets into three levels of credibility: reliable, unreliable and
inconclusive. We provide several statistics as well as other analytics like,
publisher distribution, publication date distribution, topic analysis, etc. We
also provide a novel architecture that classifies the news data into
misinformation or truth to provide a baseline performance for this dataset. We
find that the proposed architecture has an F-Score of 0.919 and accuracy of
0.882 for fake news detection. Furthermore, we provide benchmark performance
for misinformation detection on tweet dataset. This new multimodal dataset can
be used in research on COVID-19 vaccine, including misinformation detection,
influence of fake COVID-19 vaccine information, etc.","12 pages, 8 figures. This paper has been accepted for publication in
  ASONAM 2021",,,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2109.06416v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.06416v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.06416v2,"{'id': 'http://arxiv.org/abs/2109.06416v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.06416v2', 'updated': '2021-09-23T19:57:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=23, tm_hour=19, tm_min=57, tm_sec=17, tm_wday=3, tm_yday=266, tm_isdst=0), 'published': '2021-09-14T03:57:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=14, tm_hour=3, tm_min=57, tm_sec=50, tm_wday=1, tm_yday=257, tm_isdst=0), 'title': 'MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake\n  News Detection and a Baseline Architecture for Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake\n  News Detection and a Baseline Architecture for Classification'}, 'summary': 'The outbreak of COVID-19 has resulted in an ""infodemic"" that has encouraged\nthe propagation of misinformation about COVID-19 and cure methods which, in\nturn, could negatively affect the adoption of recommended public health\nmeasures in the larger population. In this paper, we provide a new multimodal\n(consisting of images, text and temporal information) labeled dataset\ncontaining news articles and tweets on the COVID-19 vaccine. We collected 2,593\nnews articles from 80 publishers for one year between Feb 16th 2020 to May 8th\n2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th\n2021). We combine ratings from two news media ranking sites: Medias Bias Chart\nand Media Bias/Fact Check (MBFC) to classify the news dataset into two levels\nof credibility: reliable and unreliable. The combination of two filters allows\nfor higher precision of labeling. We also propose a stance detection mechanism\nto annotate tweets into three levels of credibility: reliable, unreliable and\ninconclusive. We provide several statistics as well as other analytics like,\npublisher distribution, publication date distribution, topic analysis, etc. We\nalso provide a novel architecture that classifies the news data into\nmisinformation or truth to provide a baseline performance for this dataset. We\nfind that the proposed architecture has an F-Score of 0.919 and accuracy of\n0.882 for fake news detection. Furthermore, we provide benchmark performance\nfor misinformation detection on tweet dataset. This new multimodal dataset can\nbe used in research on COVID-19 vaccine, including misinformation detection,\ninfluence of fake COVID-19 vaccine information, etc.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The outbreak of COVID-19 has resulted in an ""infodemic"" that has encouraged\nthe propagation of misinformation about COVID-19 and cure methods which, in\nturn, could negatively affect the adoption of recommended public health\nmeasures in the larger population. In this paper, we provide a new multimodal\n(consisting of images, text and temporal information) labeled dataset\ncontaining news articles and tweets on the COVID-19 vaccine. We collected 2,593\nnews articles from 80 publishers for one year between Feb 16th 2020 to May 8th\n2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th\n2021). We combine ratings from two news media ranking sites: Medias Bias Chart\nand Media Bias/Fact Check (MBFC) to classify the news dataset into two levels\nof credibility: reliable and unreliable. The combination of two filters allows\nfor higher precision of labeling. We also propose a stance detection mechanism\nto annotate tweets into three levels of credibility: reliable, unreliable and\ninconclusive. We provide several statistics as well as other analytics like,\npublisher distribution, publication date distribution, topic analysis, etc. We\nalso provide a novel architecture that classifies the news data into\nmisinformation or truth to provide a baseline performance for this dataset. We\nfind that the proposed architecture has an F-Score of 0.919 and accuracy of\n0.882 for fake news detection. Furthermore, we provide benchmark performance\nfor misinformation detection on tweet dataset. This new multimodal dataset can\nbe used in research on COVID-19 vaccine, including misinformation detection,\ninfluence of fake COVID-19 vaccine information, etc.'}, 'authors': [{'name': 'Mingxuan Chen'}, {'name': 'Xinqiao Chu'}, {'name': 'K. P. Subbalakshmi'}], 'author_detail': {'name': 'K. P. Subbalakshmi'}, 'author': 'K. P. Subbalakshmi', 'arxiv_comment': '12 pages, 8 figures. This paper has been accepted for publication in\n  ASONAM 2021', 'links': [{'href': 'http://arxiv.org/abs/2109.06416v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.06416v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
19,http://arxiv.org/abs/2109.07909v1,2021-09-13 14:10:44+00:00,2021-09-13 14:10:44+00:00,Surveying the Research on Fake News in Social Media: a Tale of Networks and Language,"[arxiv.Result.Author('Giancarlo Ruffo'), arxiv.Result.Author('Alfonso Semeraro'), arxiv.Result.Author('Anastasia Giachanou'), arxiv.Result.Author('Paolo Rosso')]","The history of journalism and news diffusion is tightly coupled with the
effort to dispel hoaxes, misinformation, propaganda, unverified rumours, poor
reporting, and messages containing hate and divisions. With the explosive
growth of online social media and billions of individuals engaged with
consuming, creating, and sharing news, this ancient problem has surfaced with a
renewed intensity threatening our democracies, public health, and news outlets
credibility. This has triggered many researchers to develop new methods for
studying, understanding, detecting, and preventing fake-news diffusion; as a
consequence, thousands of scientific papers have been published in a relatively
short period, making researchers of different disciplines to struggle in search
of open problems and most relevant trends. The aim of this survey is threefold:
first, we want to provide the researchers interested in this multidisciplinary
and challenging area with a network-based analysis of the existing literature
to assist them with a visual exploration of papers that can be of interest;
second, we present a selection of the main results achieved so far adopting the
network as an unifying framework to represent and make sense of data, to model
diffusion processes, and to evaluate different debunking strategies. Finally,
we present an outline of the most relevant research trends focusing on the
moving target of fake-news, bots, and trolls identification by means of data
mining and text technologies; despite scholars working on computational
linguistics and networks traditionally belong to different scientific
communities, we expect that forthcoming computational approaches to prevent
fake news from polluting the social media must be developed using hybrid and
up-to-date methodologies.","43 pages, 8 figures",,,cs.CY,"['cs.CY', 'cs.CL', 'cs.SI', 'A.1; J.4; G.2; K.4; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2109.07909v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.07909v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.07909v1,"{'id': 'http://arxiv.org/abs/2109.07909v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.07909v1', 'updated': '2021-09-13T14:10:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=13, tm_hour=14, tm_min=10, tm_sec=44, tm_wday=0, tm_yday=256, tm_isdst=0), 'published': '2021-09-13T14:10:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=13, tm_hour=14, tm_min=10, tm_sec=44, tm_wday=0, tm_yday=256, tm_isdst=0), 'title': 'Surveying the Research on Fake News in Social Media: a Tale of Networks\n  and Language', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Surveying the Research on Fake News in Social Media: a Tale of Networks\n  and Language'}, 'summary': 'The history of journalism and news diffusion is tightly coupled with the\neffort to dispel hoaxes, misinformation, propaganda, unverified rumours, poor\nreporting, and messages containing hate and divisions. With the explosive\ngrowth of online social media and billions of individuals engaged with\nconsuming, creating, and sharing news, this ancient problem has surfaced with a\nrenewed intensity threatening our democracies, public health, and news outlets\ncredibility. This has triggered many researchers to develop new methods for\nstudying, understanding, detecting, and preventing fake-news diffusion; as a\nconsequence, thousands of scientific papers have been published in a relatively\nshort period, making researchers of different disciplines to struggle in search\nof open problems and most relevant trends. The aim of this survey is threefold:\nfirst, we want to provide the researchers interested in this multidisciplinary\nand challenging area with a network-based analysis of the existing literature\nto assist them with a visual exploration of papers that can be of interest;\nsecond, we present a selection of the main results achieved so far adopting the\nnetwork as an unifying framework to represent and make sense of data, to model\ndiffusion processes, and to evaluate different debunking strategies. Finally,\nwe present an outline of the most relevant research trends focusing on the\nmoving target of fake-news, bots, and trolls identification by means of data\nmining and text technologies; despite scholars working on computational\nlinguistics and networks traditionally belong to different scientific\ncommunities, we expect that forthcoming computational approaches to prevent\nfake news from polluting the social media must be developed using hybrid and\nup-to-date methodologies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The history of journalism and news diffusion is tightly coupled with the\neffort to dispel hoaxes, misinformation, propaganda, unverified rumours, poor\nreporting, and messages containing hate and divisions. With the explosive\ngrowth of online social media and billions of individuals engaged with\nconsuming, creating, and sharing news, this ancient problem has surfaced with a\nrenewed intensity threatening our democracies, public health, and news outlets\ncredibility. This has triggered many researchers to develop new methods for\nstudying, understanding, detecting, and preventing fake-news diffusion; as a\nconsequence, thousands of scientific papers have been published in a relatively\nshort period, making researchers of different disciplines to struggle in search\nof open problems and most relevant trends. The aim of this survey is threefold:\nfirst, we want to provide the researchers interested in this multidisciplinary\nand challenging area with a network-based analysis of the existing literature\nto assist them with a visual exploration of papers that can be of interest;\nsecond, we present a selection of the main results achieved so far adopting the\nnetwork as an unifying framework to represent and make sense of data, to model\ndiffusion processes, and to evaluate different debunking strategies. Finally,\nwe present an outline of the most relevant research trends focusing on the\nmoving target of fake-news, bots, and trolls identification by means of data\nmining and text technologies; despite scholars working on computational\nlinguistics and networks traditionally belong to different scientific\ncommunities, we expect that forthcoming computational approaches to prevent\nfake news from polluting the social media must be developed using hybrid and\nup-to-date methodologies.'}, 'authors': [{'name': 'Giancarlo Ruffo'}, {'name': 'Alfonso Semeraro'}, {'name': 'Anastasia Giachanou'}, {'name': 'Paolo Rosso'}], 'author_detail': {'name': 'Paolo Rosso'}, 'arxiv_affiliation': 'Universitat Politècnica de València', 'author': 'Paolo Rosso', 'arxiv_comment': '43 pages, 8 figures', 'links': [{'href': 'http://arxiv.org/abs/2109.07909v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.07909v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'A.1; J.4; G.2; K.4; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
20,http://arxiv.org/abs/2109.05152v1,2021-09-11 01:49:08+00:00,2021-09-11 01:49:08+00:00,Making Online Communities 'Better': A Taxonomy of Community Values on Reddit,"[arxiv.Result.Author('Galen Weld'), arxiv.Result.Author('Amy X. Zhang'), arxiv.Result.Author('Tim Althoff')]","Many researchers studying online social communities seek to make such
communities better. However, understanding what 'better' means is challenging,
due to the divergent opinions of community members, and the multitude of
possible community values which often conflict with one another. Community
members' own values for their communities are not well understood, and how
these values align with one another is an open question. Previous research has
mostly focused on specific and comparatively well-defined harms within online
communities, such as harassment, rule-breaking, and misinformation. In this
work, we ask 39 community members on reddit to describe their values for their
communities. We gather 301 responses in members' own words, spanning 125 unique
communities, and use iterative categorization to produce a taxonomy of 29
different community values across 9 major categories. We find that members
value a broad range of topics ranging from technical features to the diversity
of the community, and most frequently prioritize content quality. We identify
important understudied topics such as content quality and community size,
highlight where values conflict with one another, and call for research into
governance methods for communities that protect vulnerable members.","26 pages, 3 figures",,,cs.HC,"['cs.HC', 'cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2109.05152v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.05152v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.05152v1,"{'id': 'http://arxiv.org/abs/2109.05152v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.05152v1', 'updated': '2021-09-11T01:49:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=11, tm_hour=1, tm_min=49, tm_sec=8, tm_wday=5, tm_yday=254, tm_isdst=0), 'published': '2021-09-11T01:49:08Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=11, tm_hour=1, tm_min=49, tm_sec=8, tm_wday=5, tm_yday=254, tm_isdst=0), 'title': ""Making Online Communities 'Better': A Taxonomy of Community Values on\n  Reddit"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Making Online Communities 'Better': A Taxonomy of Community Values on\n  Reddit""}, 'summary': ""Many researchers studying online social communities seek to make such\ncommunities better. However, understanding what 'better' means is challenging,\ndue to the divergent opinions of community members, and the multitude of\npossible community values which often conflict with one another. Community\nmembers' own values for their communities are not well understood, and how\nthese values align with one another is an open question. Previous research has\nmostly focused on specific and comparatively well-defined harms within online\ncommunities, such as harassment, rule-breaking, and misinformation. In this\nwork, we ask 39 community members on reddit to describe their values for their\ncommunities. We gather 301 responses in members' own words, spanning 125 unique\ncommunities, and use iterative categorization to produce a taxonomy of 29\ndifferent community values across 9 major categories. We find that members\nvalue a broad range of topics ranging from technical features to the diversity\nof the community, and most frequently prioritize content quality. We identify\nimportant understudied topics such as content quality and community size,\nhighlight where values conflict with one another, and call for research into\ngovernance methods for communities that protect vulnerable members."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Many researchers studying online social communities seek to make such\ncommunities better. However, understanding what 'better' means is challenging,\ndue to the divergent opinions of community members, and the multitude of\npossible community values which often conflict with one another. Community\nmembers' own values for their communities are not well understood, and how\nthese values align with one another is an open question. Previous research has\nmostly focused on specific and comparatively well-defined harms within online\ncommunities, such as harassment, rule-breaking, and misinformation. In this\nwork, we ask 39 community members on reddit to describe their values for their\ncommunities. We gather 301 responses in members' own words, spanning 125 unique\ncommunities, and use iterative categorization to produce a taxonomy of 29\ndifferent community values across 9 major categories. We find that members\nvalue a broad range of topics ranging from technical features to the diversity\nof the community, and most frequently prioritize content quality. We identify\nimportant understudied topics such as content quality and community size,\nhighlight where values conflict with one another, and call for research into\ngovernance methods for communities that protect vulnerable members.""}, 'authors': [{'name': 'Galen Weld'}, {'name': 'Amy X. Zhang'}, {'name': 'Tim Althoff'}], 'author_detail': {'name': 'Tim Althoff'}, 'author': 'Tim Althoff', 'arxiv_comment': '26 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/2109.05152v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.05152v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
21,http://arxiv.org/abs/2109.04888v1,2021-09-10 14:01:01+00:00,2021-09-10 14:01:01+00:00,Auctioning with Strategically Reticent Bidders,"[arxiv.Result.Author('Jibang Wu'), arxiv.Result.Author('Ashwinkumar Badanidiyuru'), arxiv.Result.Author('Haifeng Xu')]","Classic mechanism design often assumes that a bidder's action is restricted
to report a type or a signal, possibly untruthfully. In today's digital
economy, bidders are holding increasing amount of private information about the
auctioned items. And due to legal or ethical concerns, they would demand to
reveal partial but truthful information, as opposed to report untrue signal or
misinformation. To accommodate such bidder behaviors in auction design, we
propose and study a novel mechanism design setup where each bidder holds two
kinds of information: (1) private \emph{value type}, which can be misreported;
(2) private \emph{information variable}, which the bidder may want to conceal
or partially reveal, but importantly, \emph{not} to misreport.
  We show that in this new setup, it is still possible to design mechanisms
that are both \emph{Incentive and Information Compatible} (IIC). We develop two
different black-box transformations, which convert any mechanism $\mathcal{M}$
for classic bidders to a mechanism $\mathcal{M}'$ for strategically reticent
bidders, based on either outcome of expectation or expectation of outcome,
respectively. We identify properties of the original mechanism $\mathcal{M}$
under which the transformation leads to IIC mechanisms $\mathcal{M}'$.
Interestingly, as corollaries of these results, we show that running VCG with
expected bidder values maximizes welfare whereas the mechanism using expected
outcome of Myerson's auction maximizes revenue. Finally, we study how
regulation on the auctioneer's usage of information may lead to more robust
mechanisms.",,,,cs.GT,"['cs.GT', 'econ.TH']","[arxiv.Result.Link('http://arxiv.org/abs/2109.04888v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.04888v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.04888v1,"{'id': 'http://arxiv.org/abs/2109.04888v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.04888v1', 'updated': '2021-09-10T14:01:01Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=10, tm_hour=14, tm_min=1, tm_sec=1, tm_wday=4, tm_yday=253, tm_isdst=0), 'published': '2021-09-10T14:01:01Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=10, tm_hour=14, tm_min=1, tm_sec=1, tm_wday=4, tm_yday=253, tm_isdst=0), 'title': 'Auctioning with Strategically Reticent Bidders', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Auctioning with Strategically Reticent Bidders'}, 'summary': ""Classic mechanism design often assumes that a bidder's action is restricted\nto report a type or a signal, possibly untruthfully. In today's digital\neconomy, bidders are holding increasing amount of private information about the\nauctioned items. And due to legal or ethical concerns, they would demand to\nreveal partial but truthful information, as opposed to report untrue signal or\nmisinformation. To accommodate such bidder behaviors in auction design, we\npropose and study a novel mechanism design setup where each bidder holds two\nkinds of information: (1) private \\emph{value type}, which can be misreported;\n(2) private \\emph{information variable}, which the bidder may want to conceal\nor partially reveal, but importantly, \\emph{not} to misreport.\n  We show that in this new setup, it is still possible to design mechanisms\nthat are both \\emph{Incentive and Information Compatible} (IIC). We develop two\ndifferent black-box transformations, which convert any mechanism $\\mathcal{M}$\nfor classic bidders to a mechanism $\\mathcal{M}'$ for strategically reticent\nbidders, based on either outcome of expectation or expectation of outcome,\nrespectively. We identify properties of the original mechanism $\\mathcal{M}$\nunder which the transformation leads to IIC mechanisms $\\mathcal{M}'$.\nInterestingly, as corollaries of these results, we show that running VCG with\nexpected bidder values maximizes welfare whereas the mechanism using expected\noutcome of Myerson's auction maximizes revenue. Finally, we study how\nregulation on the auctioneer's usage of information may lead to more robust\nmechanisms."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Classic mechanism design often assumes that a bidder's action is restricted\nto report a type or a signal, possibly untruthfully. In today's digital\neconomy, bidders are holding increasing amount of private information about the\nauctioned items. And due to legal or ethical concerns, they would demand to\nreveal partial but truthful information, as opposed to report untrue signal or\nmisinformation. To accommodate such bidder behaviors in auction design, we\npropose and study a novel mechanism design setup where each bidder holds two\nkinds of information: (1) private \\emph{value type}, which can be misreported;\n(2) private \\emph{information variable}, which the bidder may want to conceal\nor partially reveal, but importantly, \\emph{not} to misreport.\n  We show that in this new setup, it is still possible to design mechanisms\nthat are both \\emph{Incentive and Information Compatible} (IIC). We develop two\ndifferent black-box transformations, which convert any mechanism $\\mathcal{M}$\nfor classic bidders to a mechanism $\\mathcal{M}'$ for strategically reticent\nbidders, based on either outcome of expectation or expectation of outcome,\nrespectively. We identify properties of the original mechanism $\\mathcal{M}$\nunder which the transformation leads to IIC mechanisms $\\mathcal{M}'$.\nInterestingly, as corollaries of these results, we show that running VCG with\nexpected bidder values maximizes welfare whereas the mechanism using expected\noutcome of Myerson's auction maximizes revenue. Finally, we study how\nregulation on the auctioneer's usage of information may lead to more robust\nmechanisms.""}, 'authors': [{'name': 'Jibang Wu'}, {'name': 'Ashwinkumar Badanidiyuru'}, {'name': 'Haifeng Xu'}], 'author_detail': {'name': 'Haifeng Xu'}, 'author': 'Haifeng Xu', 'links': [{'href': 'http://arxiv.org/abs/2109.04888v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.04888v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
22,http://arxiv.org/abs/2109.04559v1,2021-09-09 20:51:41+00:00,2021-09-09 20:51:41+00:00,Fighting Fake News in Encrypted Messaging with the Fuzzy Anonymous Complaint Tally System (FACTS),"[arxiv.Result.Author('Linsheng Liu'), arxiv.Result.Author('Daniel S. Roche'), arxiv.Result.Author('Austin Theriault'), arxiv.Result.Author('Arkady Yerukhimovich')]","Recent years have seen a strong uptick in both the prevalence and real-world
consequences of false information spread through online platforms. At the same
time, encrypted messaging systems such as WhatsApp, Signal, and Telegram, are
rapidly gaining popularity as users seek increased privacy in their digital
lives.
  The challenge we address is how to combat the viral spread of misinformation
without compromising privacy. Our FACTS system tracks user complaints on
messages obliviously, only revealing the message's contents and originator once
sufficiently many complaints have been lodged.
  Our system is private, meaning it does not reveal anything about the senders
or contents of messages which have received few or no complaints; secure,
meaning there is no way for a malicious user to evade the system or gain an
outsized impact over the complaint system; and scalable, as we demonstrate
excellent practical efficiency for up to millions of complaints per day.
  Our main technical contribution is a new collaborative counting Bloom filter,
a simple construction with difficult probabilistic analysis, which may have
independent interest as a privacy-preserving randomized count sketch data
structure.
  Compared to prior work on message flagging and tracing in end-to-end
encrypted messaging, our novel contribution is the addition of a high threshold
of multiple complaints that are needed before a message is audited or flagged.
  We present and carefully analyze the probabilistic performance of our data
structure, provide a precise security definition and proof, and then measure
the accuracy and scalability of our scheme via experimentation.","16 pages, to appear in NDSS 2022",,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.04559v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.04559v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.04559v1,"{'id': 'http://arxiv.org/abs/2109.04559v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.04559v1', 'updated': '2021-09-09T20:51:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=9, tm_hour=20, tm_min=51, tm_sec=41, tm_wday=3, tm_yday=252, tm_isdst=0), 'published': '2021-09-09T20:51:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=9, tm_hour=20, tm_min=51, tm_sec=41, tm_wday=3, tm_yday=252, tm_isdst=0), 'title': 'Fighting Fake News in Encrypted Messaging with the Fuzzy Anonymous\n  Complaint Tally System (FACTS)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting Fake News in Encrypted Messaging with the Fuzzy Anonymous\n  Complaint Tally System (FACTS)'}, 'summary': ""Recent years have seen a strong uptick in both the prevalence and real-world\nconsequences of false information spread through online platforms. At the same\ntime, encrypted messaging systems such as WhatsApp, Signal, and Telegram, are\nrapidly gaining popularity as users seek increased privacy in their digital\nlives.\n  The challenge we address is how to combat the viral spread of misinformation\nwithout compromising privacy. Our FACTS system tracks user complaints on\nmessages obliviously, only revealing the message's contents and originator once\nsufficiently many complaints have been lodged.\n  Our system is private, meaning it does not reveal anything about the senders\nor contents of messages which have received few or no complaints; secure,\nmeaning there is no way for a malicious user to evade the system or gain an\noutsized impact over the complaint system; and scalable, as we demonstrate\nexcellent practical efficiency for up to millions of complaints per day.\n  Our main technical contribution is a new collaborative counting Bloom filter,\na simple construction with difficult probabilistic analysis, which may have\nindependent interest as a privacy-preserving randomized count sketch data\nstructure.\n  Compared to prior work on message flagging and tracing in end-to-end\nencrypted messaging, our novel contribution is the addition of a high threshold\nof multiple complaints that are needed before a message is audited or flagged.\n  We present and carefully analyze the probabilistic performance of our data\nstructure, provide a precise security definition and proof, and then measure\nthe accuracy and scalability of our scheme via experimentation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recent years have seen a strong uptick in both the prevalence and real-world\nconsequences of false information spread through online platforms. At the same\ntime, encrypted messaging systems such as WhatsApp, Signal, and Telegram, are\nrapidly gaining popularity as users seek increased privacy in their digital\nlives.\n  The challenge we address is how to combat the viral spread of misinformation\nwithout compromising privacy. Our FACTS system tracks user complaints on\nmessages obliviously, only revealing the message's contents and originator once\nsufficiently many complaints have been lodged.\n  Our system is private, meaning it does not reveal anything about the senders\nor contents of messages which have received few or no complaints; secure,\nmeaning there is no way for a malicious user to evade the system or gain an\noutsized impact over the complaint system; and scalable, as we demonstrate\nexcellent practical efficiency for up to millions of complaints per day.\n  Our main technical contribution is a new collaborative counting Bloom filter,\na simple construction with difficult probabilistic analysis, which may have\nindependent interest as a privacy-preserving randomized count sketch data\nstructure.\n  Compared to prior work on message flagging and tracing in end-to-end\nencrypted messaging, our novel contribution is the addition of a high threshold\nof multiple complaints that are needed before a message is audited or flagged.\n  We present and carefully analyze the probabilistic performance of our data\nstructure, provide a precise security definition and proof, and then measure\nthe accuracy and scalability of our scheme via experimentation.""}, 'authors': [{'name': 'Linsheng Liu'}, {'name': 'Daniel S. Roche'}, {'name': 'Austin Theriault'}, {'name': 'Arkady Yerukhimovich'}], 'author_detail': {'name': 'Arkady Yerukhimovich'}, 'author': 'Arkady Yerukhimovich', 'arxiv_comment': '16 pages, to appear in NDSS 2022', 'links': [{'href': 'http://arxiv.org/abs/2109.04559v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.04559v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
23,http://arxiv.org/abs/2109.02975v1,2021-09-07 10:15:54+00:00,2021-09-07 10:15:54+00:00,BERT based classification system for detecting rumours on Twitter,"[arxiv.Result.Author('Rini Anggrainingsih'), arxiv.Result.Author('Ghulam Mubashar Hassan'), arxiv.Result.Author('Amitava Datta')]","The role of social media in opinion formation has far-reaching implications
in all spheres of society. Though social media provide platforms for expressing
news and views, it is hard to control the quality of posts due to the sheer
volumes of posts on platforms like Twitter and Facebook. Misinformation and
rumours have lasting effects on society, as they tend to influence people's
opinions and also may motivate people to act irrationally. It is therefore very
important to detect and remove rumours from these platforms. The only way to
prevent the spread of rumours is through automatic detection and classification
of social media posts. Our focus in this paper is the Twitter social medium, as
it is relatively easy to collect data from Twitter. The majority of previous
studies used supervised learning approaches to classify rumours on Twitter.
These approaches rely on feature extraction to obtain both content and context
features from the text of tweets to distinguish rumours and non-rumours.
Manually extracting features however is time-consuming considering the volume
of tweets. We propose a novel approach to deal with this problem by utilising
sentence embedding using BERT to identify rumours on Twitter, rather than the
usual feature extraction techniques. We use sentence embedding using BERT to
represent each tweet's sentences into a vector according to the contextual
meaning of the tweet. We classify those vectors into rumours or non-rumours by
using various supervised learning techniques. Our BERT based models improved
the accuracy by approximately 10% as compared to previous methods.","Consists of 10 pages, 5 figures, and 8 tables, has been submitted to
  IEEE transactions on Computational and Social Systems (still underreview
  process)",,,cs.LG,['cs.LG'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.02975v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.02975v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.02975v1,"{'id': 'http://arxiv.org/abs/2109.02975v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.02975v1', 'updated': '2021-09-07T10:15:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=7, tm_hour=10, tm_min=15, tm_sec=54, tm_wday=1, tm_yday=250, tm_isdst=0), 'published': '2021-09-07T10:15:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=7, tm_hour=10, tm_min=15, tm_sec=54, tm_wday=1, tm_yday=250, tm_isdst=0), 'title': 'BERT based classification system for detecting rumours on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BERT based classification system for detecting rumours on Twitter'}, 'summary': ""The role of social media in opinion formation has far-reaching implications\nin all spheres of society. Though social media provide platforms for expressing\nnews and views, it is hard to control the quality of posts due to the sheer\nvolumes of posts on platforms like Twitter and Facebook. Misinformation and\nrumours have lasting effects on society, as they tend to influence people's\nopinions and also may motivate people to act irrationally. It is therefore very\nimportant to detect and remove rumours from these platforms. The only way to\nprevent the spread of rumours is through automatic detection and classification\nof social media posts. Our focus in this paper is the Twitter social medium, as\nit is relatively easy to collect data from Twitter. The majority of previous\nstudies used supervised learning approaches to classify rumours on Twitter.\nThese approaches rely on feature extraction to obtain both content and context\nfeatures from the text of tweets to distinguish rumours and non-rumours.\nManually extracting features however is time-consuming considering the volume\nof tweets. We propose a novel approach to deal with this problem by utilising\nsentence embedding using BERT to identify rumours on Twitter, rather than the\nusual feature extraction techniques. We use sentence embedding using BERT to\nrepresent each tweet's sentences into a vector according to the contextual\nmeaning of the tweet. We classify those vectors into rumours or non-rumours by\nusing various supervised learning techniques. Our BERT based models improved\nthe accuracy by approximately 10% as compared to previous methods."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The role of social media in opinion formation has far-reaching implications\nin all spheres of society. Though social media provide platforms for expressing\nnews and views, it is hard to control the quality of posts due to the sheer\nvolumes of posts on platforms like Twitter and Facebook. Misinformation and\nrumours have lasting effects on society, as they tend to influence people's\nopinions and also may motivate people to act irrationally. It is therefore very\nimportant to detect and remove rumours from these platforms. The only way to\nprevent the spread of rumours is through automatic detection and classification\nof social media posts. Our focus in this paper is the Twitter social medium, as\nit is relatively easy to collect data from Twitter. The majority of previous\nstudies used supervised learning approaches to classify rumours on Twitter.\nThese approaches rely on feature extraction to obtain both content and context\nfeatures from the text of tweets to distinguish rumours and non-rumours.\nManually extracting features however is time-consuming considering the volume\nof tweets. We propose a novel approach to deal with this problem by utilising\nsentence embedding using BERT to identify rumours on Twitter, rather than the\nusual feature extraction techniques. We use sentence embedding using BERT to\nrepresent each tweet's sentences into a vector according to the contextual\nmeaning of the tweet. We classify those vectors into rumours or non-rumours by\nusing various supervised learning techniques. Our BERT based models improved\nthe accuracy by approximately 10% as compared to previous methods.""}, 'authors': [{'name': 'Rini Anggrainingsih'}, {'name': 'Ghulam Mubashar Hassan'}, {'name': 'Amitava Datta'}], 'author_detail': {'name': 'Amitava Datta'}, 'author': 'Amitava Datta', 'arxiv_comment': 'Consists of 10 pages, 5 figures, and 8 tables, has been submitted to\n  IEEE transactions on Computational and Social Systems (still underreview\n  process)', 'links': [{'href': 'http://arxiv.org/abs/2109.02975v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.02975v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
24,http://arxiv.org/abs/2109.02927v1,2021-09-07 08:28:57+00:00,2021-09-07 08:28:57+00:00,Heterogeneity-aware Twitter Bot Detection with Relational Graph Transformers,"[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Rui Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an important and challenging task to combat
misinformation and protect the integrity of the online discourse.
State-of-the-art approaches generally leverage the topological structure of the
Twittersphere, while they neglect the heterogeneity of relations and influence
among users. In this paper, we propose a novel bot detection framework to
alleviate this problem, which leverages the topological structure of
user-formed heterogeneous graphs and models varying influence intensity between
users. Specifically, we construct a heterogeneous information network with
users as nodes and diversified relations as edges. We then propose relational
graph transformers to model heterogeneous influence between users and learn
node representations. Finally, we use semantic attention networks to aggregate
messages across users and relations and conduct heterogeneity-aware Twitter bot
detection. Extensive experiments demonstrate that our proposal outperforms
state-of-the-art methods on a comprehensive Twitter bot detection benchmark.
Additional studies also bear out the effectiveness of our proposed relational
graph transformers, semantic attention networks and the graph-based approach in
general.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2109.02927v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.02927v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.02927v1,"{'id': 'http://arxiv.org/abs/2109.02927v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.02927v1', 'updated': '2021-09-07T08:28:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=7, tm_hour=8, tm_min=28, tm_sec=57, tm_wday=1, tm_yday=250, tm_isdst=0), 'published': '2021-09-07T08:28:57Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=7, tm_hour=8, tm_min=28, tm_sec=57, tm_wday=1, tm_yday=250, tm_isdst=0), 'title': 'Heterogeneity-aware Twitter Bot Detection with Relational Graph\n  Transformers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Heterogeneity-aware Twitter Bot Detection with Relational Graph\n  Transformers'}, 'summary': 'Twitter bot detection has become an important and challenging task to combat\nmisinformation and protect the integrity of the online discourse.\nState-of-the-art approaches generally leverage the topological structure of the\nTwittersphere, while they neglect the heterogeneity of relations and influence\namong users. In this paper, we propose a novel bot detection framework to\nalleviate this problem, which leverages the topological structure of\nuser-formed heterogeneous graphs and models varying influence intensity between\nusers. Specifically, we construct a heterogeneous information network with\nusers as nodes and diversified relations as edges. We then propose relational\ngraph transformers to model heterogeneous influence between users and learn\nnode representations. Finally, we use semantic attention networks to aggregate\nmessages across users and relations and conduct heterogeneity-aware Twitter bot\ndetection. Extensive experiments demonstrate that our proposal outperforms\nstate-of-the-art methods on a comprehensive Twitter bot detection benchmark.\nAdditional studies also bear out the effectiveness of our proposed relational\ngraph transformers, semantic attention networks and the graph-based approach in\ngeneral.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Twitter bot detection has become an important and challenging task to combat\nmisinformation and protect the integrity of the online discourse.\nState-of-the-art approaches generally leverage the topological structure of the\nTwittersphere, while they neglect the heterogeneity of relations and influence\namong users. In this paper, we propose a novel bot detection framework to\nalleviate this problem, which leverages the topological structure of\nuser-formed heterogeneous graphs and models varying influence intensity between\nusers. Specifically, we construct a heterogeneous information network with\nusers as nodes and diversified relations as edges. We then propose relational\ngraph transformers to model heterogeneous influence between users and learn\nnode representations. Finally, we use semantic attention networks to aggregate\nmessages across users and relations and conduct heterogeneity-aware Twitter bot\ndetection. Extensive experiments demonstrate that our proposal outperforms\nstate-of-the-art methods on a comprehensive Twitter bot detection benchmark.\nAdditional studies also bear out the effectiveness of our proposed relational\ngraph transformers, semantic attention networks and the graph-based approach in\ngeneral.'}, 'authors': [{'name': 'Shangbin Feng'}, {'name': 'Zhaoxuan Tan'}, {'name': 'Rui Li'}, {'name': 'Minnan Luo'}], 'author_detail': {'name': 'Minnan Luo'}, 'author': 'Minnan Luo', 'links': [{'href': 'http://arxiv.org/abs/2109.02927v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.02927v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
25,http://arxiv.org/abs/2109.02283v1,2021-09-06 08:28:43+00:00,2021-09-06 08:28:43+00:00,Does Melania Trump have a body double from the perspective of automatic face recognition?,"[arxiv.Result.Author('Khawla Mallat'), arxiv.Result.Author('Fabiola Becerra-Riera'), arxiv.Result.Author('Annette Morales-González'), arxiv.Result.Author('Heydi Méndez-Vázquez'), arxiv.Result.Author('Jean-Luc Dugelay')]","In this paper, we explore whether automatic face recognition can help in
verifying widespread misinformation on social media, particularly conspiracy
theories that are based on the existence of body doubles. The conspiracy theory
addressed in this paper is the case of the Melania Trump body double. We
employed four different state-of-the-art descriptors for face recognition to
verify the integrity of the claim of the studied conspiracy theory. In
addition, we assessed the impact of different image quality metrics on the
variation of face recognition results. Two sets of image quality metrics were
considered: acquisition-related metrics and subject-related metrics.",,,,cs.CV,"['cs.CV', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2109.02283v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.02283v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.02283v1,"{'id': 'http://arxiv.org/abs/2109.02283v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.02283v1', 'updated': '2021-09-06T08:28:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=8, tm_min=28, tm_sec=43, tm_wday=0, tm_yday=249, tm_isdst=0), 'published': '2021-09-06T08:28:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=8, tm_min=28, tm_sec=43, tm_wday=0, tm_yday=249, tm_isdst=0), 'title': 'Does Melania Trump have a body double from the perspective of automatic\n  face recognition?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Does Melania Trump have a body double from the perspective of automatic\n  face recognition?'}, 'summary': 'In this paper, we explore whether automatic face recognition can help in\nverifying widespread misinformation on social media, particularly conspiracy\ntheories that are based on the existence of body doubles. The conspiracy theory\naddressed in this paper is the case of the Melania Trump body double. We\nemployed four different state-of-the-art descriptors for face recognition to\nverify the integrity of the claim of the studied conspiracy theory. In\naddition, we assessed the impact of different image quality metrics on the\nvariation of face recognition results. Two sets of image quality metrics were\nconsidered: acquisition-related metrics and subject-related metrics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we explore whether automatic face recognition can help in\nverifying widespread misinformation on social media, particularly conspiracy\ntheories that are based on the existence of body doubles. The conspiracy theory\naddressed in this paper is the case of the Melania Trump body double. We\nemployed four different state-of-the-art descriptors for face recognition to\nverify the integrity of the claim of the studied conspiracy theory. In\naddition, we assessed the impact of different image quality metrics on the\nvariation of face recognition results. Two sets of image quality metrics were\nconsidered: acquisition-related metrics and subject-related metrics.'}, 'authors': [{'name': 'Khawla Mallat'}, {'name': 'Fabiola Becerra-Riera'}, {'name': 'Annette Morales-González'}, {'name': 'Heydi Méndez-Vázquez'}, {'name': 'Jean-Luc Dugelay'}], 'author_detail': {'name': 'Jean-Luc Dugelay'}, 'author': 'Jean-Luc Dugelay', 'links': [{'href': 'http://arxiv.org/abs/2109.02283v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.02283v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
26,http://arxiv.org/abs/2109.02202v1,2021-09-06 01:39:48+00:00,2021-09-06 01:39:48+00:00,Fairness via AI: Bias Reduction in Medical Information,"[arxiv.Result.Author('Shiri Dori-Hacohen'), arxiv.Result.Author('Roberto Montenegro'), arxiv.Result.Author('Fabricio Murai'), arxiv.Result.Author('Scott A. Hale'), arxiv.Result.Author('Keen Sung'), arxiv.Result.Author('Michela Blain'), arxiv.Result.Author('Jennifer Edwards-Johnson')]","Most Fairness in AI research focuses on exposing biases in AI systems. A
broader lens on fairness reveals that AI can serve a greater aspiration:
rooting out societal inequities from their source. Specifically, we focus on
inequities in health information, and aim to reduce bias in that domain using
AI. The AI algorithms under the hood of search engines and social media, many
of which are based on recommender systems, have an outsized impact on the
quality of medical and health information online. Therefore, embedding bias
detection and reduction into these recommender systems serving up medical and
health content online could have an outsized positive impact on patient
outcomes and wellbeing.
  In this position paper, we offer the following contributions: (1) we propose
a novel framework of Fairness via AI, inspired by insights from medical
education, sociology and antiracism; (2) we define a new term, bisinformation,
which is related to, but distinct from, misinformation, and encourage
researchers to study it; (3) we propose using AI to study, detect and mitigate
biased, harmful, and/or false health information that disproportionately hurts
minority groups in society; and (4) we suggest several pillars and pose several
open problems in order to seed inquiry in this new space. While part (3) of
this work specifically focuses on the health domain, the fundamental computer
science advances and contributions stemming from research efforts in bias
reduction and Fairness via AI have broad implications in all areas of society.","To appear in: The 4th FAccTRec Workshop on Responsible Recommendation
  at RecSys 2021",,,cs.AI,"['cs.AI', 'cs.CY', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2109.02202v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2109.02202v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2109.02202v1,"{'id': 'http://arxiv.org/abs/2109.02202v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2109.02202v1', 'updated': '2021-09-06T01:39:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=1, tm_min=39, tm_sec=48, tm_wday=0, tm_yday=249, tm_isdst=0), 'published': '2021-09-06T01:39:48Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=6, tm_hour=1, tm_min=39, tm_sec=48, tm_wday=0, tm_yday=249, tm_isdst=0), 'title': 'Fairness via AI: Bias Reduction in Medical Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fairness via AI: Bias Reduction in Medical Information'}, 'summary': 'Most Fairness in AI research focuses on exposing biases in AI systems. A\nbroader lens on fairness reveals that AI can serve a greater aspiration:\nrooting out societal inequities from their source. Specifically, we focus on\ninequities in health information, and aim to reduce bias in that domain using\nAI. The AI algorithms under the hood of search engines and social media, many\nof which are based on recommender systems, have an outsized impact on the\nquality of medical and health information online. Therefore, embedding bias\ndetection and reduction into these recommender systems serving up medical and\nhealth content online could have an outsized positive impact on patient\noutcomes and wellbeing.\n  In this position paper, we offer the following contributions: (1) we propose\na novel framework of Fairness via AI, inspired by insights from medical\neducation, sociology and antiracism; (2) we define a new term, bisinformation,\nwhich is related to, but distinct from, misinformation, and encourage\nresearchers to study it; (3) we propose using AI to study, detect and mitigate\nbiased, harmful, and/or false health information that disproportionately hurts\nminority groups in society; and (4) we suggest several pillars and pose several\nopen problems in order to seed inquiry in this new space. While part (3) of\nthis work specifically focuses on the health domain, the fundamental computer\nscience advances and contributions stemming from research efforts in bias\nreduction and Fairness via AI have broad implications in all areas of society.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Most Fairness in AI research focuses on exposing biases in AI systems. A\nbroader lens on fairness reveals that AI can serve a greater aspiration:\nrooting out societal inequities from their source. Specifically, we focus on\ninequities in health information, and aim to reduce bias in that domain using\nAI. The AI algorithms under the hood of search engines and social media, many\nof which are based on recommender systems, have an outsized impact on the\nquality of medical and health information online. Therefore, embedding bias\ndetection and reduction into these recommender systems serving up medical and\nhealth content online could have an outsized positive impact on patient\noutcomes and wellbeing.\n  In this position paper, we offer the following contributions: (1) we propose\na novel framework of Fairness via AI, inspired by insights from medical\neducation, sociology and antiracism; (2) we define a new term, bisinformation,\nwhich is related to, but distinct from, misinformation, and encourage\nresearchers to study it; (3) we propose using AI to study, detect and mitigate\nbiased, harmful, and/or false health information that disproportionately hurts\nminority groups in society; and (4) we suggest several pillars and pose several\nopen problems in order to seed inquiry in this new space. While part (3) of\nthis work specifically focuses on the health domain, the fundamental computer\nscience advances and contributions stemming from research efforts in bias\nreduction and Fairness via AI have broad implications in all areas of society.'}, 'authors': [{'name': 'Shiri Dori-Hacohen'}, {'name': 'Roberto Montenegro'}, {'name': 'Fabricio Murai'}, {'name': 'Scott A. Hale'}, {'name': 'Keen Sung'}, {'name': 'Michela Blain'}, {'name': 'Jennifer Edwards-Johnson'}], 'author_detail': {'name': 'Jennifer Edwards-Johnson'}, 'author': 'Jennifer Edwards-Johnson', 'arxiv_comment': 'To appear in: The 4th FAccTRec Workshop on Responsible Recommendation\n  at RecSys 2021', 'links': [{'href': 'http://arxiv.org/abs/2109.02202v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2109.02202v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
27,http://arxiv.org/abs/2108.13687v2,2021-09-23 16:33:27+00:00,2021-08-31 08:55:47+00:00,The coercive logic of fake news,"[arxiv.Result.Author('Alexander J. Stewart'), arxiv.Result.Author('Antonio A. Arechar'), arxiv.Result.Author('David G. Rand'), arxiv.Result.Author('Joshua B. Plotkin')]","The spread of misinformation and ""fake news"" continues to be a major focus of
public concern. A great deal of research has examined who falls for
misinformation and why, and what can be done to make people more discerning
consumers of news. Comparatively little work, however, has considered the
choices of those who produce misinformation, and how these choices interact
with the psychology of news consumers. Here we use game-theoretic models to
study the strategic interaction between news publishers and news readers. We
show that publishers who seek to spread misinformation can generate high
engagement with falsehoods by using strategies that mix true and false stories
over time, in such a way that they serve more false stories to more loyal
readers. These coercive strategies cause false stories to receive higher reader
engagement than true stories - even when readers strictly prefer truth over
falsehood. In contrast, publishers who seek to promote engagement with accurate
information will use strategies that generate more engagement with true stories
than with false stories. We confirm these predictions empirically by examining
1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook
engagement data with 20,000 perceived accuracy ratings collected in a survey
experiment. We show that engagement is positively correlated with accuracy
among mainstream sites, but negatively correlated with accuracy among
misinformation sites. We then use our model to analyze the conditions under
which news sites seeking engagement will produce false stories. We show that if
a publisher incorrectly assumes that readers prefer falsehoods, their resulting
publication strategy can nonetheless manufacture greater engagement with false
news - leading to a self-reinforcing cycle of false news promotion.",,,,econ.TH,['econ.TH'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.13687v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.13687v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.13687v2,"{'id': 'http://arxiv.org/abs/2108.13687v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.13687v2', 'updated': '2021-09-23T16:33:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=23, tm_hour=16, tm_min=33, tm_sec=27, tm_wday=3, tm_yday=266, tm_isdst=0), 'published': '2021-08-31T08:55:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=31, tm_hour=8, tm_min=55, tm_sec=47, tm_wday=1, tm_yday=243, tm_isdst=0), 'title': 'The coercive logic of fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The coercive logic of fake news'}, 'summary': 'The spread of misinformation and ""fake news"" continues to be a major focus of\npublic concern. A great deal of research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We show that engagement is positively correlated with accuracy\namong mainstream sites, but negatively correlated with accuracy among\nmisinformation sites. We then use our model to analyze the conditions under\nwhich news sites seeking engagement will produce false stories. We show that if\na publisher incorrectly assumes that readers prefer falsehoods, their resulting\npublication strategy can nonetheless manufacture greater engagement with false\nnews - leading to a self-reinforcing cycle of false news promotion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of misinformation and ""fake news"" continues to be a major focus of\npublic concern. A great deal of research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We show that engagement is positively correlated with accuracy\namong mainstream sites, but negatively correlated with accuracy among\nmisinformation sites. We then use our model to analyze the conditions under\nwhich news sites seeking engagement will produce false stories. We show that if\na publisher incorrectly assumes that readers prefer falsehoods, their resulting\npublication strategy can nonetheless manufacture greater engagement with false\nnews - leading to a self-reinforcing cycle of false news promotion.'}, 'authors': [{'name': 'Alexander J. Stewart'}, {'name': 'Antonio A. Arechar'}, {'name': 'David G. Rand'}, {'name': 'Joshua B. Plotkin'}], 'author_detail': {'name': 'Joshua B. Plotkin'}, 'author': 'Joshua B. Plotkin', 'links': [{'href': 'http://arxiv.org/abs/2108.13687v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.13687v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
28,http://arxiv.org/abs/2108.12961v1,2021-08-30 02:39:13+00:00,2021-08-30 02:39:13+00:00,BioFors: A Large Biomedical Image Forensics Dataset,"[arxiv.Result.Author('Ekraam Sabir'), arxiv.Result.Author('Soumyaroop Nandi'), arxiv.Result.Author('Wael AbdAlmageed'), arxiv.Result.Author('Prem Natarajan')]","Research in media forensics has gained traction to combat the spread of
misinformation. However, most of this research has been directed towards
content generated on social media. Biomedical image forensics is a related
problem, where manipulation or misuse of images reported in biomedical research
documents is of serious concern. The problem has failed to gain momentum beyond
an academic discussion due to an absence of benchmark datasets and standardized
tasks. In this paper we present BioFors -- the first dataset for benchmarking
common biomedical image manipulations. BioFors comprises 47,805 images
extracted from 1,031 open-source research papers. Images in BioFors are divided
into four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also
propose three tasks for forensic analysis -- external duplication detection,
internal duplication detection and cut/sharp-transition detection. We benchmark
BioFors on all tasks with suitable state-of-the-art algorithms. Our results and
analysis show that existing algorithms developed on common computer vision
datasets are not robust when applied to biomedical images, validating that more
research is required to address the unique challenges of biomedical image
forensics.",To appear at ICCV 2021,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.12961v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.12961v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.12961v1,"{'id': 'http://arxiv.org/abs/2108.12961v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.12961v1', 'updated': '2021-08-30T02:39:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=30, tm_hour=2, tm_min=39, tm_sec=13, tm_wday=0, tm_yday=242, tm_isdst=0), 'published': '2021-08-30T02:39:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=30, tm_hour=2, tm_min=39, tm_sec=13, tm_wday=0, tm_yday=242, tm_isdst=0), 'title': 'BioFors: A Large Biomedical Image Forensics Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BioFors: A Large Biomedical Image Forensics Dataset'}, 'summary': 'Research in media forensics has gained traction to combat the spread of\nmisinformation. However, most of this research has been directed towards\ncontent generated on social media. Biomedical image forensics is a related\nproblem, where manipulation or misuse of images reported in biomedical research\ndocuments is of serious concern. The problem has failed to gain momentum beyond\nan academic discussion due to an absence of benchmark datasets and standardized\ntasks. In this paper we present BioFors -- the first dataset for benchmarking\ncommon biomedical image manipulations. BioFors comprises 47,805 images\nextracted from 1,031 open-source research papers. Images in BioFors are divided\ninto four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also\npropose three tasks for forensic analysis -- external duplication detection,\ninternal duplication detection and cut/sharp-transition detection. We benchmark\nBioFors on all tasks with suitable state-of-the-art algorithms. Our results and\nanalysis show that existing algorithms developed on common computer vision\ndatasets are not robust when applied to biomedical images, validating that more\nresearch is required to address the unique challenges of biomedical image\nforensics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Research in media forensics has gained traction to combat the spread of\nmisinformation. However, most of this research has been directed towards\ncontent generated on social media. Biomedical image forensics is a related\nproblem, where manipulation or misuse of images reported in biomedical research\ndocuments is of serious concern. The problem has failed to gain momentum beyond\nan academic discussion due to an absence of benchmark datasets and standardized\ntasks. In this paper we present BioFors -- the first dataset for benchmarking\ncommon biomedical image manipulations. BioFors comprises 47,805 images\nextracted from 1,031 open-source research papers. Images in BioFors are divided\ninto four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also\npropose three tasks for forensic analysis -- external duplication detection,\ninternal duplication detection and cut/sharp-transition detection. We benchmark\nBioFors on all tasks with suitable state-of-the-art algorithms. Our results and\nanalysis show that existing algorithms developed on common computer vision\ndatasets are not robust when applied to biomedical images, validating that more\nresearch is required to address the unique challenges of biomedical image\nforensics.'}, 'authors': [{'name': 'Ekraam Sabir'}, {'name': 'Soumyaroop Nandi'}, {'name': 'Wael AbdAlmageed'}, {'name': 'Prem Natarajan'}], 'author_detail': {'name': 'Prem Natarajan'}, 'author': 'Prem Natarajan', 'arxiv_comment': 'To appear at ICCV 2021', 'links': [{'href': 'http://arxiv.org/abs/2108.12961v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.12961v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
29,http://arxiv.org/abs/2108.12092v1,2021-08-27 02:36:29+00:00,2021-08-27 02:36:29+00:00,"Replaying Archived Twitter: When your bird is broken, will it bring you down?","[arxiv.Result.Author('Kritika Garg'), arxiv.Result.Author('Himarsha R. Jayanetti'), arxiv.Result.Author('Sawood Alam'), arxiv.Result.Author('Michele C. Weigle'), arxiv.Result.Author('Michael L. Nelson')]","Historians and researchers trust web archives to preserve social media
content that no longer exists on the live web. However, what we see on the live
web and how it is replayed in the archive are not always the same. In this
paper, we document and analyze the problems in archiving Twitter ever since
Twitter forced the use of its new UI in June 2020. Most web archives were
unable to archive the new UI, resulting in archived Twitter pages displaying
Twitter's ""Something went wrong"" error. The challenges in archiving the new UI
forced web archives to continue using the old UI. To analyze the potential loss
of information in web archival data due to this change, we used the personal
Twitter account of the 45th President of the United States, @realDonaldTrump,
which was suspended by Twitter on January 8, 2021. Trump's account was heavily
labeled by Twitter for spreading misinformation, however we discovered that
there is no evidence in web archives to prove that some of his tweets ever had
a label assigned to them. We also studied the possibility of temporal
violations in archived versions of the new UI, which may result in the replay
of pages that never existed on the live web. Our goal is to educate researchers
who may use web archives and caution them when drawing conclusions based on
archived Twitter pages.",,,,cs.DL,['cs.DL'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.12092v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.12092v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.12092v1,"{'id': 'http://arxiv.org/abs/2108.12092v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.12092v1', 'updated': '2021-08-27T02:36:29Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=27, tm_hour=2, tm_min=36, tm_sec=29, tm_wday=4, tm_yday=239, tm_isdst=0), 'published': '2021-08-27T02:36:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=27, tm_hour=2, tm_min=36, tm_sec=29, tm_wday=4, tm_yday=239, tm_isdst=0), 'title': 'Replaying Archived Twitter: When your bird is broken, will it bring you\n  down?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Replaying Archived Twitter: When your bird is broken, will it bring you\n  down?'}, 'summary': 'Historians and researchers trust web archives to preserve social media\ncontent that no longer exists on the live web. However, what we see on the live\nweb and how it is replayed in the archive are not always the same. In this\npaper, we document and analyze the problems in archiving Twitter ever since\nTwitter forced the use of its new UI in June 2020. Most web archives were\nunable to archive the new UI, resulting in archived Twitter pages displaying\nTwitter\'s ""Something went wrong"" error. The challenges in archiving the new UI\nforced web archives to continue using the old UI. To analyze the potential loss\nof information in web archival data due to this change, we used the personal\nTwitter account of the 45th President of the United States, @realDonaldTrump,\nwhich was suspended by Twitter on January 8, 2021. Trump\'s account was heavily\nlabeled by Twitter for spreading misinformation, however we discovered that\nthere is no evidence in web archives to prove that some of his tweets ever had\na label assigned to them. We also studied the possibility of temporal\nviolations in archived versions of the new UI, which may result in the replay\nof pages that never existed on the live web. Our goal is to educate researchers\nwho may use web archives and caution them when drawing conclusions based on\narchived Twitter pages.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Historians and researchers trust web archives to preserve social media\ncontent that no longer exists on the live web. However, what we see on the live\nweb and how it is replayed in the archive are not always the same. In this\npaper, we document and analyze the problems in archiving Twitter ever since\nTwitter forced the use of its new UI in June 2020. Most web archives were\nunable to archive the new UI, resulting in archived Twitter pages displaying\nTwitter\'s ""Something went wrong"" error. The challenges in archiving the new UI\nforced web archives to continue using the old UI. To analyze the potential loss\nof information in web archival data due to this change, we used the personal\nTwitter account of the 45th President of the United States, @realDonaldTrump,\nwhich was suspended by Twitter on January 8, 2021. Trump\'s account was heavily\nlabeled by Twitter for spreading misinformation, however we discovered that\nthere is no evidence in web archives to prove that some of his tweets ever had\na label assigned to them. We also studied the possibility of temporal\nviolations in archived versions of the new UI, which may result in the replay\nof pages that never existed on the live web. Our goal is to educate researchers\nwho may use web archives and caution them when drawing conclusions based on\narchived Twitter pages.'}, 'authors': [{'name': 'Kritika Garg'}, {'name': 'Himarsha R. Jayanetti'}, {'name': 'Sawood Alam'}, {'name': 'Michele C. Weigle'}, {'name': 'Michael L. Nelson'}], 'author_detail': {'name': 'Michael L. Nelson'}, 'author': 'Michael L. Nelson', 'links': [{'href': 'http://arxiv.org/abs/2108.12092v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.12092v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
30,http://arxiv.org/abs/2108.11896v1,2021-08-26 16:34:51+00:00,2021-08-26 16:34:51+00:00,A Survey on Automated Fact-Checking,"[arxiv.Result.Author('Zhijiang Guo'), arxiv.Result.Author('Michael Schlichtkrull'), arxiv.Result.Author('Andreas Vlachos')]","Fact-checking has become increasingly important due to the speed with which
both information and misinformation can spread in the modern media ecosystem.
Therefore, researchers have been exploring how fact-checking can be automated,
using techniques based on natural language processing, machine learning,
knowledge representation, and databases to automatically predict the veracity
of claims. In this paper, we survey automated fact-checking stemming from
natural language processing, and discuss its connections to related tasks and
disciplines. In this process, we present an overview of existing datasets and
models, aiming to unify the various definitions given and identify common
concepts. Finally, we highlight challenges for future research.","27 pages, 15 pages of references",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.11896v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.11896v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.11896v1,"{'id': 'http://arxiv.org/abs/2108.11896v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.11896v1', 'updated': '2021-08-26T16:34:51Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=26, tm_hour=16, tm_min=34, tm_sec=51, tm_wday=3, tm_yday=238, tm_isdst=0), 'published': '2021-08-26T16:34:51Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=26, tm_hour=16, tm_min=34, tm_sec=51, tm_wday=3, tm_yday=238, tm_isdst=0), 'title': 'A Survey on Automated Fact-Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Automated Fact-Checking'}, 'summary': 'Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.'}, 'authors': [{'name': 'Zhijiang Guo'}, {'name': 'Michael Schlichtkrull'}, {'name': 'Andreas Vlachos'}], 'author_detail': {'name': 'Andreas Vlachos'}, 'author': 'Andreas Vlachos', 'arxiv_comment': '27 pages, 15 pages of references', 'links': [{'href': 'http://arxiv.org/abs/2108.11896v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.11896v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
31,http://arxiv.org/abs/2108.10274v1,2021-08-23 16:22:50+00:00,2021-08-23 16:22:50+00:00,Towards Explainable Fact Checking,[arxiv.Result.Author('Isabelle Augenstein')],"The past decade has seen a substantial rise in the amount of mis- and
disinformation online, from targeted disinformation campaigns to influence
politics, to the unintentional spreading of misinformation about public health.
This development has spurred research in the area of automatic fact checking,
from approaches to detect check-worthy claims and determining the stance of
tweets towards claims, to methods to determine the veracity of claims given
evidence documents. These automatic methods are often content-based, using
natural language processing methods, which in turn utilise deep neural networks
to learn higher-order features from text in order to make predictions. As deep
neural networks are black-box models, their inner workings cannot be easily
explained. At the same time, it is desirable to explain how they arrive at
certain decisions, especially if they are to be used for decision making. While
this has been known for some time, the issues this raises have been exacerbated
by models increasing in size, and by EU legislation requiring models to be used
for decision making to provide explanations, and, very recently, by legislation
requiring online platforms operating in the EU to provide transparent reporting
on their services. Despite this, current solutions for explainability are still
lacking in the area of fact checking. This thesis presents my research on
automatic fact checking, including claim check-worthiness detection, stance
detection and veracity prediction. Its contributions go beyond fact checking,
with the thesis proposing more general machine learning solutions for natural
language processing in the area of learning with limited labelled data.
Finally, the thesis presents some first solutions for explainable fact
checking.","Thesis presented to the University of Copenhagen Faculty of Science
  in partial fulfillment of the requirements for the degree of Doctor
  Scientiarum (Dr. Scient.)",,,cs.CL,"['cs.CL', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2108.10274v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10274v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10274v1,"{'id': 'http://arxiv.org/abs/2108.10274v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10274v1', 'updated': '2021-08-23T16:22:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=23, tm_hour=16, tm_min=22, tm_sec=50, tm_wday=0, tm_yday=235, tm_isdst=0), 'published': '2021-08-23T16:22:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=23, tm_hour=16, tm_min=22, tm_sec=50, tm_wday=0, tm_yday=235, tm_isdst=0), 'title': 'Towards Explainable Fact Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Explainable Fact Checking'}, 'summary': 'The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.'}, 'authors': [{'name': 'Isabelle Augenstein'}], 'author_detail': {'name': 'Isabelle Augenstein'}, 'author': 'Isabelle Augenstein', 'arxiv_comment': 'Thesis presented to the University of Copenhagen Faculty of Science\n  in partial fulfillment of the requirements for the degree of Doctor\n  Scientiarum (Dr. Scient.)', 'links': [{'href': 'http://arxiv.org/abs/2108.10274v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10274v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
32,http://arxiv.org/abs/2108.13293v1,2021-08-22 00:11:19+00:00,2021-08-22 00:11:19+00:00,Public sentiment analysis and topic modeling regarding COVID-19 vaccines on the Reddit social media platform: A call to action for strengthening vaccine confidence,"[arxiv.Result.Author('Chad A Melton'), arxiv.Result.Author('Olufunto A Olusanya'), arxiv.Result.Author('Nariman Ammar'), arxiv.Result.Author('Arash Shaban-Nejad')]","The COVID-19 pandemic fueled one of the most rapid vaccine developments in
history. However, misinformation spread through online social media often leads
to negative vaccine sentiment and hesitancy. To investigate COVID-19
vaccine-related discussion in social media, we conducted a sentiment analysis
and Latent Dirichlet Allocation topic modeling on textual data collected from
13 Reddit communities focusing on the COVID-19 vaccine from Dec 1, 2020, to May
15, 2021. Data were aggregated and analyzed by month to detect changes in any
sentiment and latent topics. ty analysis suggested these communities expressed
more positive sentiment than negative regarding the vaccine-related discussions
and has remained static over time. Topic modeling revealed community members
mainly focused on side effects rather than outlandish conspiracy theories.
Covid-19 vaccine-related content from 13 subreddits show that the sentiments
expressed in these communities are overall more positive than negative and have
not meaningfully changed since December 2020. Keywords indicating vaccine
hesitancy were detected throughout the LDA topic modeling. Public sentiment and
topic modeling analysis regarding vaccines could facilitate the implementation
of appropriate messaging, digital interventions, and new policies to promote
vaccine confidence.","8 pages, 4 Figures, 2 Tables","Journal of Infection and Public Health, Available online 14 August
  2021",10.1016/j.jiph.2021.08.010,cs.IR,"['cs.IR', 'cs.SI', '68T50', 'I.2.7; J.3']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.jiph.2021.08.010', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.13293v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.13293v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.13293v1,"{'id': 'http://arxiv.org/abs/2108.13293v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.13293v1', 'updated': '2021-08-22T00:11:19Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=22, tm_hour=0, tm_min=11, tm_sec=19, tm_wday=6, tm_yday=234, tm_isdst=0), 'published': '2021-08-22T00:11:19Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=22, tm_hour=0, tm_min=11, tm_sec=19, tm_wday=6, tm_yday=234, tm_isdst=0), 'title': 'Public sentiment analysis and topic modeling regarding COVID-19 vaccines\n  on the Reddit social media platform: A call to action for strengthening\n  vaccine confidence', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Public sentiment analysis and topic modeling regarding COVID-19 vaccines\n  on the Reddit social media platform: A call to action for strengthening\n  vaccine confidence'}, 'summary': 'The COVID-19 pandemic fueled one of the most rapid vaccine developments in\nhistory. However, misinformation spread through online social media often leads\nto negative vaccine sentiment and hesitancy. To investigate COVID-19\nvaccine-related discussion in social media, we conducted a sentiment analysis\nand Latent Dirichlet Allocation topic modeling on textual data collected from\n13 Reddit communities focusing on the COVID-19 vaccine from Dec 1, 2020, to May\n15, 2021. Data were aggregated and analyzed by month to detect changes in any\nsentiment and latent topics. ty analysis suggested these communities expressed\nmore positive sentiment than negative regarding the vaccine-related discussions\nand has remained static over time. Topic modeling revealed community members\nmainly focused on side effects rather than outlandish conspiracy theories.\nCovid-19 vaccine-related content from 13 subreddits show that the sentiments\nexpressed in these communities are overall more positive than negative and have\nnot meaningfully changed since December 2020. Keywords indicating vaccine\nhesitancy were detected throughout the LDA topic modeling. Public sentiment and\ntopic modeling analysis regarding vaccines could facilitate the implementation\nof appropriate messaging, digital interventions, and new policies to promote\nvaccine confidence.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic fueled one of the most rapid vaccine developments in\nhistory. However, misinformation spread through online social media often leads\nto negative vaccine sentiment and hesitancy. To investigate COVID-19\nvaccine-related discussion in social media, we conducted a sentiment analysis\nand Latent Dirichlet Allocation topic modeling on textual data collected from\n13 Reddit communities focusing on the COVID-19 vaccine from Dec 1, 2020, to May\n15, 2021. Data were aggregated and analyzed by month to detect changes in any\nsentiment and latent topics. ty analysis suggested these communities expressed\nmore positive sentiment than negative regarding the vaccine-related discussions\nand has remained static over time. Topic modeling revealed community members\nmainly focused on side effects rather than outlandish conspiracy theories.\nCovid-19 vaccine-related content from 13 subreddits show that the sentiments\nexpressed in these communities are overall more positive than negative and have\nnot meaningfully changed since December 2020. Keywords indicating vaccine\nhesitancy were detected throughout the LDA topic modeling. Public sentiment and\ntopic modeling analysis regarding vaccines could facilitate the implementation\nof appropriate messaging, digital interventions, and new policies to promote\nvaccine confidence.'}, 'authors': [{'name': 'Chad A Melton'}, {'name': 'Olufunto A Olusanya'}, {'name': 'Nariman Ammar'}, {'name': 'Arash Shaban-Nejad'}], 'author_detail': {'name': 'Arash Shaban-Nejad'}, 'author': 'Arash Shaban-Nejad', 'arxiv_doi': '10.1016/j.jiph.2021.08.010', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.jiph.2021.08.010', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.13293v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.13293v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '8 pages, 4 Figures, 2 Tables', 'arxiv_journal_ref': 'Journal of Infection and Public Health, Available online 14 August\n  2021', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; J.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
33,http://arxiv.org/abs/2108.10735v1,2021-08-16 17:02:18+00:00,2021-08-16 17:02:18+00:00,Misleading the Covid-19 vaccination discourse on Twitter: An exploratory study of infodemic around the pandemic,"[arxiv.Result.Author('Shakshi Sharma'), arxiv.Result.Author('Rajesh Sharma'), arxiv.Result.Author('Anwitaman Datta')]","In this work, we collect a moderate-sized representative corpus of tweets
(200,000 approx.) pertaining Covid-19 vaccination spanning over a period of
seven months (September 2020 - March 2021). Following a Transfer Learning
approach, we utilize the pre-trained Transformer-based XLNet model to classify
tweets as Misleading or Non-Misleading and validate against a random subset of
results manually. We build on this to study and contrast the characteristics of
tweets in the corpus that are misleading in nature against non-misleading ones.
This exploratory analysis enables us to design features (such as sentiments,
hashtags, nouns, pronouns, etc) that can, in turn, be exploited for classifying
tweets as (Non-)Misleading using various ML models in an explainable manner.
Specifically, several ML models are employed for prediction, with up to 90%
accuracy, and the importance of each feature is explained using SHAP
Explainable AI (XAI) tool. While the thrust of this work is principally
exploratory analysis in order to obtain insights on the online discourse on
Covid-19 vaccination, we conclude the paper by outlining how these insights
provide the foundations for a more actionable approach to mitigate
misinformation. The curated dataset and code is made available (Github
repository) so that the research community at large can reproduce, compare
against, or build upon this work.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2108.10735v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10735v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10735v1,"{'id': 'http://arxiv.org/abs/2108.10735v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10735v1', 'updated': '2021-08-16T17:02:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=16, tm_hour=17, tm_min=2, tm_sec=18, tm_wday=0, tm_yday=228, tm_isdst=0), 'published': '2021-08-16T17:02:18Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=16, tm_hour=17, tm_min=2, tm_sec=18, tm_wday=0, tm_yday=228, tm_isdst=0), 'title': 'Misleading the Covid-19 vaccination discourse on Twitter: An exploratory\n  study of infodemic around the pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misleading the Covid-19 vaccination discourse on Twitter: An exploratory\n  study of infodemic around the pandemic'}, 'summary': 'In this work, we collect a moderate-sized representative corpus of tweets\n(200,000 approx.) pertaining Covid-19 vaccination spanning over a period of\nseven months (September 2020 - March 2021). Following a Transfer Learning\napproach, we utilize the pre-trained Transformer-based XLNet model to classify\ntweets as Misleading or Non-Misleading and validate against a random subset of\nresults manually. We build on this to study and contrast the characteristics of\ntweets in the corpus that are misleading in nature against non-misleading ones.\nThis exploratory analysis enables us to design features (such as sentiments,\nhashtags, nouns, pronouns, etc) that can, in turn, be exploited for classifying\ntweets as (Non-)Misleading using various ML models in an explainable manner.\nSpecifically, several ML models are employed for prediction, with up to 90%\naccuracy, and the importance of each feature is explained using SHAP\nExplainable AI (XAI) tool. While the thrust of this work is principally\nexploratory analysis in order to obtain insights on the online discourse on\nCovid-19 vaccination, we conclude the paper by outlining how these insights\nprovide the foundations for a more actionable approach to mitigate\nmisinformation. The curated dataset and code is made available (Github\nrepository) so that the research community at large can reproduce, compare\nagainst, or build upon this work.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work, we collect a moderate-sized representative corpus of tweets\n(200,000 approx.) pertaining Covid-19 vaccination spanning over a period of\nseven months (September 2020 - March 2021). Following a Transfer Learning\napproach, we utilize the pre-trained Transformer-based XLNet model to classify\ntweets as Misleading or Non-Misleading and validate against a random subset of\nresults manually. We build on this to study and contrast the characteristics of\ntweets in the corpus that are misleading in nature against non-misleading ones.\nThis exploratory analysis enables us to design features (such as sentiments,\nhashtags, nouns, pronouns, etc) that can, in turn, be exploited for classifying\ntweets as (Non-)Misleading using various ML models in an explainable manner.\nSpecifically, several ML models are employed for prediction, with up to 90%\naccuracy, and the importance of each feature is explained using SHAP\nExplainable AI (XAI) tool. While the thrust of this work is principally\nexploratory analysis in order to obtain insights on the online discourse on\nCovid-19 vaccination, we conclude the paper by outlining how these insights\nprovide the foundations for a more actionable approach to mitigate\nmisinformation. The curated dataset and code is made available (Github\nrepository) so that the research community at large can reproduce, compare\nagainst, or build upon this work.'}, 'authors': [{'name': 'Shakshi Sharma'}, {'name': 'Rajesh Sharma'}, {'name': 'Anwitaman Datta'}], 'author_detail': {'name': 'Anwitaman Datta'}, 'author': 'Anwitaman Datta', 'links': [{'href': 'http://arxiv.org/abs/2108.10735v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10735v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
34,http://arxiv.org/abs/2108.06249v1,2021-08-13 14:00:12+00:00,2021-08-13 14:00:12+00:00,MIND - Mainstream and Independent News Documents Corpus,"[arxiv.Result.Author('Danielle Caled'), arxiv.Result.Author('Paula Carvalho'), arxiv.Result.Author('Mário J. Silva')]","This paper presents and characterizes MIND, a new Portuguese corpus comprised
of different types of articles collected from online mainstream and alternative
media sources, over a 10-month period. The articles in the corpus are organized
into five collections: facts, opinions, entertainment, satires, and conspiracy
theories. Throughout this paper, we explain how the data collection process was
conducted, and present a set of linguistic metrics that allow us to perform a
preliminary characterization of the texts included in the corpus. Also, we
deliver an analysis of the most frequent topics in the corpus, and discuss the
main differences and similarities among the collections considered. Finally, we
enumerate some tasks and applications that could benefit from this corpus, in
particular the ones (in)directly related to misinformation detection. Overall,
our contribution of a corpus and initial analysis are designed to support
future exploratory news studies, and provide a better insight into
misinformation.",,,,cs.LG,['cs.LG'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.06249v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.06249v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.06249v1,"{'id': 'http://arxiv.org/abs/2108.06249v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.06249v1', 'updated': '2021-08-13T14:00:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=13, tm_hour=14, tm_min=0, tm_sec=12, tm_wday=4, tm_yday=225, tm_isdst=0), 'published': '2021-08-13T14:00:12Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=13, tm_hour=14, tm_min=0, tm_sec=12, tm_wday=4, tm_yday=225, tm_isdst=0), 'title': 'MIND - Mainstream and Independent News Documents Corpus', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MIND - Mainstream and Independent News Documents Corpus'}, 'summary': 'This paper presents and characterizes MIND, a new Portuguese corpus comprised\nof different types of articles collected from online mainstream and alternative\nmedia sources, over a 10-month period. The articles in the corpus are organized\ninto five collections: facts, opinions, entertainment, satires, and conspiracy\ntheories. Throughout this paper, we explain how the data collection process was\nconducted, and present a set of linguistic metrics that allow us to perform a\npreliminary characterization of the texts included in the corpus. Also, we\ndeliver an analysis of the most frequent topics in the corpus, and discuss the\nmain differences and similarities among the collections considered. Finally, we\nenumerate some tasks and applications that could benefit from this corpus, in\nparticular the ones (in)directly related to misinformation detection. Overall,\nour contribution of a corpus and initial analysis are designed to support\nfuture exploratory news studies, and provide a better insight into\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper presents and characterizes MIND, a new Portuguese corpus comprised\nof different types of articles collected from online mainstream and alternative\nmedia sources, over a 10-month period. The articles in the corpus are organized\ninto five collections: facts, opinions, entertainment, satires, and conspiracy\ntheories. Throughout this paper, we explain how the data collection process was\nconducted, and present a set of linguistic metrics that allow us to perform a\npreliminary characterization of the texts included in the corpus. Also, we\ndeliver an analysis of the most frequent topics in the corpus, and discuss the\nmain differences and similarities among the collections considered. Finally, we\nenumerate some tasks and applications that could benefit from this corpus, in\nparticular the ones (in)directly related to misinformation detection. Overall,\nour contribution of a corpus and initial analysis are designed to support\nfuture exploratory news studies, and provide a better insight into\nmisinformation.'}, 'authors': [{'name': 'Danielle Caled'}, {'name': 'Paula Carvalho'}, {'name': 'Mário J. Silva'}], 'author_detail': {'name': 'Mário J. Silva'}, 'author': 'Mário J. Silva', 'links': [{'href': 'http://arxiv.org/abs/2108.06249v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.06249v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
35,http://arxiv.org/abs/2108.06035v2,2021-09-01 22:01:41+00:00,2021-08-13 02:55:53+00:00,Narrative Sensemaking: Strategies for Narrative Maps Construction,"[arxiv.Result.Author('Brian Felipe Keith Norambuena'), arxiv.Result.Author('Tanushree Mitra'), arxiv.Result.Author('Chris North')]","Narrative sensemaking is a fundamental process to understand sequential
information. Narrative maps are a visual representation framework that can aid
analysts in this process. They allow analysts to understand the big picture of
a narrative, uncover new relationships between events, and model connections
between storylines. As a sensemaking tool, narrative maps have applications in
intelligence analysis, misinformation modeling, and computational journalism.
In this work, we seek to understand how analysts construct narrative maps in
order to improve narrative map representation and extraction methods. We
perform an experiment with a data set of news articles. Our main contribution
is an analysis of how analysts construct narrative maps. The insights extracted
from our study can be used to design narrative map visualizations, extraction
algorithms, and visual analytics tools to support the sensemaking process.","Accepted as a short paper in IEEE VIS 2021; added citation
  information",,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.06035v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.06035v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.06035v2,"{'id': 'http://arxiv.org/abs/2108.06035v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.06035v2', 'updated': '2021-09-01T22:01:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=1, tm_hour=22, tm_min=1, tm_sec=41, tm_wday=2, tm_yday=244, tm_isdst=0), 'published': '2021-08-13T02:55:53Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=13, tm_hour=2, tm_min=55, tm_sec=53, tm_wday=4, tm_yday=225, tm_isdst=0), 'title': 'Narrative Sensemaking: Strategies for Narrative Maps Construction', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Narrative Sensemaking: Strategies for Narrative Maps Construction'}, 'summary': 'Narrative sensemaking is a fundamental process to understand sequential\ninformation. Narrative maps are a visual representation framework that can aid\nanalysts in this process. They allow analysts to understand the big picture of\na narrative, uncover new relationships between events, and model connections\nbetween storylines. As a sensemaking tool, narrative maps have applications in\nintelligence analysis, misinformation modeling, and computational journalism.\nIn this work, we seek to understand how analysts construct narrative maps in\norder to improve narrative map representation and extraction methods. We\nperform an experiment with a data set of news articles. Our main contribution\nis an analysis of how analysts construct narrative maps. The insights extracted\nfrom our study can be used to design narrative map visualizations, extraction\nalgorithms, and visual analytics tools to support the sensemaking process.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Narrative sensemaking is a fundamental process to understand sequential\ninformation. Narrative maps are a visual representation framework that can aid\nanalysts in this process. They allow analysts to understand the big picture of\na narrative, uncover new relationships between events, and model connections\nbetween storylines. As a sensemaking tool, narrative maps have applications in\nintelligence analysis, misinformation modeling, and computational journalism.\nIn this work, we seek to understand how analysts construct narrative maps in\norder to improve narrative map representation and extraction methods. We\nperform an experiment with a data set of news articles. Our main contribution\nis an analysis of how analysts construct narrative maps. The insights extracted\nfrom our study can be used to design narrative map visualizations, extraction\nalgorithms, and visual analytics tools to support the sensemaking process.'}, 'authors': [{'name': 'Brian Felipe Keith Norambuena'}, {'name': 'Tanushree Mitra'}, {'name': 'Chris North'}], 'author_detail': {'name': 'Chris North'}, 'author': 'Chris North', 'arxiv_comment': 'Accepted as a short paper in IEEE VIS 2021; added citation\n  information', 'links': [{'href': 'http://arxiv.org/abs/2108.06035v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.06035v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
36,http://arxiv.org/abs/2108.10791v1,2021-08-11 12:54:26+00:00,2021-08-11 12:54:26+00:00,Ensuring the Inclusive Use of Natural Language Processing in the Global Response to COVID-19,"[arxiv.Result.Author('Alexandra Sasha Luccioni'), arxiv.Result.Author('Katherine Hoffmann Pham'), arxiv.Result.Author('Cynthia Sin Nga Lam'), arxiv.Result.Author('Joseph Aylett-Bullock'), arxiv.Result.Author('Miguel Luengo-Oroz')]","Natural language processing (NLP) plays a significant role in tools for the
COVID-19 pandemic response, from detecting misinformation on social media to
helping to provide accurate clinical information or summarizing scientific
research. However, the approaches developed thus far have not benefited all
populations, regions or languages equally. We discuss ways in which current and
future NLP approaches can be made more inclusive by covering low-resource
languages, including alternative modalities, leveraging out-of-the-box tools
and forming meaningful partnerships. We suggest several future directions for
researchers interested in maximizing the positive societal impacts of NLP.",,,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2108.10791v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.10791v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.10791v1,"{'id': 'http://arxiv.org/abs/2108.10791v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.10791v1', 'updated': '2021-08-11T12:54:26Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=12, tm_min=54, tm_sec=26, tm_wday=2, tm_yday=223, tm_isdst=0), 'published': '2021-08-11T12:54:26Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=12, tm_min=54, tm_sec=26, tm_wday=2, tm_yday=223, tm_isdst=0), 'title': 'Ensuring the Inclusive Use of Natural Language Processing in the Global\n  Response to COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Ensuring the Inclusive Use of Natural Language Processing in the Global\n  Response to COVID-19'}, 'summary': 'Natural language processing (NLP) plays a significant role in tools for the\nCOVID-19 pandemic response, from detecting misinformation on social media to\nhelping to provide accurate clinical information or summarizing scientific\nresearch. However, the approaches developed thus far have not benefited all\npopulations, regions or languages equally. We discuss ways in which current and\nfuture NLP approaches can be made more inclusive by covering low-resource\nlanguages, including alternative modalities, leveraging out-of-the-box tools\nand forming meaningful partnerships. We suggest several future directions for\nresearchers interested in maximizing the positive societal impacts of NLP.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Natural language processing (NLP) plays a significant role in tools for the\nCOVID-19 pandemic response, from detecting misinformation on social media to\nhelping to provide accurate clinical information or summarizing scientific\nresearch. However, the approaches developed thus far have not benefited all\npopulations, regions or languages equally. We discuss ways in which current and\nfuture NLP approaches can be made more inclusive by covering low-resource\nlanguages, including alternative modalities, leveraging out-of-the-box tools\nand forming meaningful partnerships. We suggest several future directions for\nresearchers interested in maximizing the positive societal impacts of NLP.'}, 'authors': [{'name': 'Alexandra Sasha Luccioni'}, {'name': 'Katherine Hoffmann Pham'}, {'name': 'Cynthia Sin Nga Lam'}, {'name': 'Joseph Aylett-Bullock'}, {'name': 'Miguel Luengo-Oroz'}], 'author_detail': {'name': 'Miguel Luengo-Oroz'}, 'author': 'Miguel Luengo-Oroz', 'links': [{'href': 'http://arxiv.org/abs/2108.10791v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.10791v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
37,http://arxiv.org/abs/2108.05150v1,2021-08-11 10:56:10+00:00,2021-08-11 10:56:10+00:00,Exploring the Links between Personality Traits and Suscep;bility to Disinformation,"[arxiv.Result.Author('Dipto Barman'), arxiv.Result.Author('Owen Conlan')]","The growth of online Digital/social media has allowed a variety of ideas and
opinions to coexist. Social Media has appealed users due to the ease of fast
dissemination of information at low cost and easy access. However, due to the
growth in affordance of Digital platforms, users have become prone to consume
disinformation, misinformation, propaganda, and conspiracy theories. In this
paper, we wish to explore the links between the personality traits given by the
Big Five Inventory and their susceptibility to disinformation. More
speciDically, this study is attributed to capture the short- term as well as
the long-term effects of disinformation and its effects on the Dive personality
traits. Further, we expect to observe that different personalities traits have
different shifts in opinion and different increase or decrease of uncertainty
on an issue after consuming the disinformation. Based on the Dindings of this
study, we would like to propose a personalized narrative-based change in
behavior for different personality traits.","4 pages, 1 figure, ACM conference",,10.1145/3465336.3475121,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3465336.3475121', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.05150v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.05150v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.05150v1,"{'id': 'http://arxiv.org/abs/2108.05150v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.05150v1', 'updated': '2021-08-11T10:56:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=10, tm_min=56, tm_sec=10, tm_wday=2, tm_yday=223, tm_isdst=0), 'published': '2021-08-11T10:56:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=11, tm_hour=10, tm_min=56, tm_sec=10, tm_wday=2, tm_yday=223, tm_isdst=0), 'title': 'Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation'}, 'summary': 'The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.'}, 'authors': [{'name': 'Dipto Barman'}, {'name': 'Owen Conlan'}], 'author_detail': {'name': 'Owen Conlan'}, 'author': 'Owen Conlan', 'arxiv_doi': '10.1145/3465336.3475121', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3465336.3475121', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.05150v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.05150v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '4 pages, 1 figure, ACM conference', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
38,http://arxiv.org/abs/2108.03805v1,2021-08-09 04:46:41+00:00,2021-08-09 04:46:41+00:00,Learning to Detect Few-Shot-Few-Clue Misinformation,"[arxiv.Result.Author('Qiang Zhang'), arxiv.Result.Author('Hongbin Huang'), arxiv.Result.Author('Shangsong Liang'), arxiv.Result.Author('Zaiqiao Meng'), arxiv.Result.Author('Emine Yilmaz')]","The quality of digital information on the web has been disquieting due to the
lack of careful manual review. Consequently, a large volume of false textual
information has been disseminating for a long time since the prevalence of
social media. The potential negative influence of misinformation on the public
is a growing concern. Therefore, it is strongly motivated to detect online
misinformation as early as possible. Few-shot-few-clue learning applies in this
misinformation detection task when the number of annotated statements is quite
few (called few shots) and the corresponding evidence is also quite limited in
each shot (called few clues). Within the few-shot-few-clue framework, we
propose a Bayesian meta-learning algorithm to extract the shared patterns among
different topics (i.e.different tasks) of misinformation. Moreover, we derive a
scalable method, i.e., amortized variational inference, to optimize the
Bayesian meta-learning algorithm. Empirical results on three benchmark datasets
demonstrate the superiority of our algorithm. This work focuses more on
optimizing parameters than designing detection models, and will generate fresh
insights into data-efficient detection of online misinformation at early
stages.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.03805v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.03805v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.03805v1,"{'id': 'http://arxiv.org/abs/2108.03805v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.03805v1', 'updated': '2021-08-09T04:46:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=9, tm_hour=4, tm_min=46, tm_sec=41, tm_wday=0, tm_yday=221, tm_isdst=0), 'published': '2021-08-09T04:46:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=9, tm_hour=4, tm_min=46, tm_sec=41, tm_wday=0, tm_yday=221, tm_isdst=0), 'title': 'Learning to Detect Few-Shot-Few-Clue Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Learning to Detect Few-Shot-Few-Clue Misinformation'}, 'summary': 'The quality of digital information on the web has been disquieting due to the\nlack of careful manual review. Consequently, a large volume of false textual\ninformation has been disseminating for a long time since the prevalence of\nsocial media. The potential negative influence of misinformation on the public\nis a growing concern. Therefore, it is strongly motivated to detect online\nmisinformation as early as possible. Few-shot-few-clue learning applies in this\nmisinformation detection task when the number of annotated statements is quite\nfew (called few shots) and the corresponding evidence is also quite limited in\neach shot (called few clues). Within the few-shot-few-clue framework, we\npropose a Bayesian meta-learning algorithm to extract the shared patterns among\ndifferent topics (i.e.different tasks) of misinformation. Moreover, we derive a\nscalable method, i.e., amortized variational inference, to optimize the\nBayesian meta-learning algorithm. Empirical results on three benchmark datasets\ndemonstrate the superiority of our algorithm. This work focuses more on\noptimizing parameters than designing detection models, and will generate fresh\ninsights into data-efficient detection of online misinformation at early\nstages.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The quality of digital information on the web has been disquieting due to the\nlack of careful manual review. Consequently, a large volume of false textual\ninformation has been disseminating for a long time since the prevalence of\nsocial media. The potential negative influence of misinformation on the public\nis a growing concern. Therefore, it is strongly motivated to detect online\nmisinformation as early as possible. Few-shot-few-clue learning applies in this\nmisinformation detection task when the number of annotated statements is quite\nfew (called few shots) and the corresponding evidence is also quite limited in\neach shot (called few clues). Within the few-shot-few-clue framework, we\npropose a Bayesian meta-learning algorithm to extract the shared patterns among\ndifferent topics (i.e.different tasks) of misinformation. Moreover, we derive a\nscalable method, i.e., amortized variational inference, to optimize the\nBayesian meta-learning algorithm. Empirical results on three benchmark datasets\ndemonstrate the superiority of our algorithm. This work focuses more on\noptimizing parameters than designing detection models, and will generate fresh\ninsights into data-efficient detection of online misinformation at early\nstages.'}, 'authors': [{'name': 'Qiang Zhang'}, {'name': 'Hongbin Huang'}, {'name': 'Shangsong Liang'}, {'name': 'Zaiqiao Meng'}, {'name': 'Emine Yilmaz'}], 'author_detail': {'name': 'Emine Yilmaz'}, 'author': 'Emine Yilmaz', 'links': [{'href': 'http://arxiv.org/abs/2108.03805v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.03805v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
39,http://arxiv.org/abs/2108.02325v2,2021-09-20 15:58:54+00:00,2021-08-05 00:44:43+00:00,Designing Transparency Cues in Online News Platforms to Promote Trust: Journalists' & Consumers' Perspectives,"[arxiv.Result.Author('Md Momen Bhuiyan'), arxiv.Result.Author('Hayden Whitley'), arxiv.Result.Author('Michael Horning'), arxiv.Result.Author('Sang Won Lee'), arxiv.Result.Author('Tanushree Mitra')]","As news organizations embrace transparency practices on their websites to
distinguish themselves from those spreading misinformation, HCI designers have
the opportunity to help them effectively utilize the ideals of transparency to
build trust. How can we utilize transparency to promote trust in news? We
examine this question through a qualitative lens by interviewing journalists
and news consumers -- the two stakeholders in a news system. We designed a
scenario to demonstrate transparency features using two fundamental news
attributes that convey the trustworthiness of a news article: source and
message. In the interviews, our news consumers expressed the idea that news
transparency could be best shown by providing indicators of objectivity in two
areas (news selection and framing) and by providing indicators of evidence in
four areas (presence of source materials, anonymous sourcing, verification, and
corrections upon erroneous reporting). While our journalists agreed with news
consumers' suggestions of using evidence indicators, they also suggested
additional transparency indicators in areas such as the news reporting process
and personal/organizational conflicts of interest. Prompted by our scenario,
participants offered new design considerations for building trustworthy news
platforms, such as designing for easy comprehension, presenting appropriate
details in news articles (e.g., showing the number and nature of corrections
made to an article), and comparing attributes across news organizations to
highlight diverging practices. Comparing the responses from our two stakeholder
groups reveals conflicting suggestions with trade-offs between them. Our study
has implications for HCI designers in building trustworthy news systems.","31 pages, CSCW 2021",,10.1145/3479539,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3479539', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.02325v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.02325v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.02325v2,"{'id': 'http://arxiv.org/abs/2108.02325v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.02325v2', 'updated': '2021-09-20T15:58:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=15, tm_min=58, tm_sec=54, tm_wday=0, tm_yday=263, tm_isdst=0), 'published': '2021-08-05T00:44:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=5, tm_hour=0, tm_min=44, tm_sec=43, tm_wday=3, tm_yday=217, tm_isdst=0), 'title': ""Designing Transparency Cues in Online News Platforms to Promote Trust:\n  Journalists' & Consumers' Perspectives"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Designing Transparency Cues in Online News Platforms to Promote Trust:\n  Journalists' & Consumers' Perspectives""}, 'summary': ""As news organizations embrace transparency practices on their websites to\ndistinguish themselves from those spreading misinformation, HCI designers have\nthe opportunity to help them effectively utilize the ideals of transparency to\nbuild trust. How can we utilize transparency to promote trust in news? We\nexamine this question through a qualitative lens by interviewing journalists\nand news consumers -- the two stakeholders in a news system. We designed a\nscenario to demonstrate transparency features using two fundamental news\nattributes that convey the trustworthiness of a news article: source and\nmessage. In the interviews, our news consumers expressed the idea that news\ntransparency could be best shown by providing indicators of objectivity in two\nareas (news selection and framing) and by providing indicators of evidence in\nfour areas (presence of source materials, anonymous sourcing, verification, and\ncorrections upon erroneous reporting). While our journalists agreed with news\nconsumers' suggestions of using evidence indicators, they also suggested\nadditional transparency indicators in areas such as the news reporting process\nand personal/organizational conflicts of interest. Prompted by our scenario,\nparticipants offered new design considerations for building trustworthy news\nplatforms, such as designing for easy comprehension, presenting appropriate\ndetails in news articles (e.g., showing the number and nature of corrections\nmade to an article), and comparing attributes across news organizations to\nhighlight diverging practices. Comparing the responses from our two stakeholder\ngroups reveals conflicting suggestions with trade-offs between them. Our study\nhas implications for HCI designers in building trustworthy news systems."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As news organizations embrace transparency practices on their websites to\ndistinguish themselves from those spreading misinformation, HCI designers have\nthe opportunity to help them effectively utilize the ideals of transparency to\nbuild trust. How can we utilize transparency to promote trust in news? We\nexamine this question through a qualitative lens by interviewing journalists\nand news consumers -- the two stakeholders in a news system. We designed a\nscenario to demonstrate transparency features using two fundamental news\nattributes that convey the trustworthiness of a news article: source and\nmessage. In the interviews, our news consumers expressed the idea that news\ntransparency could be best shown by providing indicators of objectivity in two\nareas (news selection and framing) and by providing indicators of evidence in\nfour areas (presence of source materials, anonymous sourcing, verification, and\ncorrections upon erroneous reporting). While our journalists agreed with news\nconsumers' suggestions of using evidence indicators, they also suggested\nadditional transparency indicators in areas such as the news reporting process\nand personal/organizational conflicts of interest. Prompted by our scenario,\nparticipants offered new design considerations for building trustworthy news\nplatforms, such as designing for easy comprehension, presenting appropriate\ndetails in news articles (e.g., showing the number and nature of corrections\nmade to an article), and comparing attributes across news organizations to\nhighlight diverging practices. Comparing the responses from our two stakeholder\ngroups reveals conflicting suggestions with trade-offs between them. Our study\nhas implications for HCI designers in building trustworthy news systems.""}, 'authors': [{'name': 'Md Momen Bhuiyan'}, {'name': 'Hayden Whitley'}, {'name': 'Michael Horning'}, {'name': 'Sang Won Lee'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_doi': '10.1145/3479539', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3479539', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.02325v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.02325v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '31 pages, CSCW 2021', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
40,http://arxiv.org/abs/2108.02314v2,2021-08-30 03:29:48+00:00,2021-08-04 23:27:10+00:00,Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link Prediction,"[arxiv.Result.Author('Maxwell A. Weinzierl'), arxiv.Result.Author('Sanda M. Harabagiu')]","Enormous hope in the efficacy of vaccines became recently a successful
reality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,
fueled by exposure to social media misinformation about COVID-19 vaccines
became a major hurdle. Therefore, it is essential to automatically detect where
misinformation about COVID-19 vaccines on social media is spread and what kind
of misinformation is discussed, such that inoculation interventions can be
delivered at the right time and in the right place, in addition to
interventions designed to address vaccine hesitancy. This paper is addressing
the first step in tackling hesitancy against COVID-19 vaccines, namely the
automatic detection of known misinformation about the vaccines on Twitter, the
social media platform that has the highest volume of conversations about
COVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged
relevant to several misinformation targets about COVID-19 vaccines on which a
novel method of detecting misinformation was developed. Our method organizes
CoVaxLies in a Misinformation Knowledge Graph as it casts misinformation
detection as a graph link prediction problem. The misinformation detection
method detailed in this paper takes advantage of the link scoring functions
provided by several knowledge embedding methods. The experimental results
demonstrate the superiority of this method when compared with
classification-based methods, widely used currently.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2108.02314v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.02314v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.02314v2,"{'id': 'http://arxiv.org/abs/2108.02314v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.02314v2', 'updated': '2021-08-30T03:29:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=30, tm_hour=3, tm_min=29, tm_sec=48, tm_wday=0, tm_yday=242, tm_isdst=0), 'published': '2021-08-04T23:27:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=4, tm_hour=23, tm_min=27, tm_sec=10, tm_wday=2, tm_yday=216, tm_isdst=0), 'title': 'Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link\n  Prediction', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link\n  Prediction'}, 'summary': 'Enormous hope in the efficacy of vaccines became recently a successful\nreality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,\nfueled by exposure to social media misinformation about COVID-19 vaccines\nbecame a major hurdle. Therefore, it is essential to automatically detect where\nmisinformation about COVID-19 vaccines on social media is spread and what kind\nof misinformation is discussed, such that inoculation interventions can be\ndelivered at the right time and in the right place, in addition to\ninterventions designed to address vaccine hesitancy. This paper is addressing\nthe first step in tackling hesitancy against COVID-19 vaccines, namely the\nautomatic detection of known misinformation about the vaccines on Twitter, the\nsocial media platform that has the highest volume of conversations about\nCOVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged\nrelevant to several misinformation targets about COVID-19 vaccines on which a\nnovel method of detecting misinformation was developed. Our method organizes\nCoVaxLies in a Misinformation Knowledge Graph as it casts misinformation\ndetection as a graph link prediction problem. The misinformation detection\nmethod detailed in this paper takes advantage of the link scoring functions\nprovided by several knowledge embedding methods. The experimental results\ndemonstrate the superiority of this method when compared with\nclassification-based methods, widely used currently.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Enormous hope in the efficacy of vaccines became recently a successful\nreality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,\nfueled by exposure to social media misinformation about COVID-19 vaccines\nbecame a major hurdle. Therefore, it is essential to automatically detect where\nmisinformation about COVID-19 vaccines on social media is spread and what kind\nof misinformation is discussed, such that inoculation interventions can be\ndelivered at the right time and in the right place, in addition to\ninterventions designed to address vaccine hesitancy. This paper is addressing\nthe first step in tackling hesitancy against COVID-19 vaccines, namely the\nautomatic detection of known misinformation about the vaccines on Twitter, the\nsocial media platform that has the highest volume of conversations about\nCOVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged\nrelevant to several misinformation targets about COVID-19 vaccines on which a\nnovel method of detecting misinformation was developed. Our method organizes\nCoVaxLies in a Misinformation Knowledge Graph as it casts misinformation\ndetection as a graph link prediction problem. The misinformation detection\nmethod detailed in this paper takes advantage of the link scoring functions\nprovided by several knowledge embedding methods. The experimental results\ndemonstrate the superiority of this method when compared with\nclassification-based methods, widely used currently.'}, 'authors': [{'name': 'Maxwell A. Weinzierl'}, {'name': 'Sanda M. Harabagiu'}], 'author_detail': {'name': 'Sanda M. Harabagiu'}, 'author': 'Sanda M. Harabagiu', 'links': [{'href': 'http://arxiv.org/abs/2108.02314v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.02314v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
41,http://arxiv.org/abs/2108.01536v2,2021-09-20 16:06:39+00:00,2021-08-03 14:39:52+00:00,NudgeCred: Supporting News Credibility Assessment on Social Media Through Nudges,"[arxiv.Result.Author('Md Momen Bhuiyan'), arxiv.Result.Author('Michael Horning'), arxiv.Result.Author('Sang Won Lee'), arxiv.Result.Author('Tanushree Mitra')]","Struggling to curb misinformation, social media platforms are experimenting
with design interventions to enhance consumption of credible news on their
platforms. Some of these interventions, such as the use of warning messages,
are examples of nudges -- a choice-preserving technique to steer behavior.
Despite their application, we do not know whether nudges could steer people
into making conscious news credibility judgments online and if they do, under
what constraints. To answer, we combine nudge techniques with heuristic based
information processing to design NudgeCred -- a browser extension for Twitter.
NudgeCred directs users' attention to two design cues: authority of a source
and other users' collective opinion on a report by activating three design
nudges -- Reliable, Questionable, and Unreliable, each denoting particular
levels of credibility for news tweets. In a controlled experiment, we found
that NudgeCred significantly helped users (n=430) distinguish news tweets'
credibility, unrestricted by three behavioral confounds -- political ideology,
political cynicism, and media skepticism. A five-day field deployment with
twelve participants revealed that NudgeCred improved their recognition of news
items and attention towards all of our nudges, particularly towards
Questionable. Among other considerations, participants proposed that designers
should incorporate heuristics that users' would trust. Our work informs
nudge-based system design approaches for online media.","30 pages, CSCW 2021",,10.1145/3479571,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3479571', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2108.01536v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.01536v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.01536v2,"{'id': 'http://arxiv.org/abs/2108.01536v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.01536v2', 'updated': '2021-09-20T16:06:39Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=20, tm_hour=16, tm_min=6, tm_sec=39, tm_wday=0, tm_yday=263, tm_isdst=0), 'published': '2021-08-03T14:39:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=3, tm_hour=14, tm_min=39, tm_sec=52, tm_wday=1, tm_yday=215, tm_isdst=0), 'title': 'NudgeCred: Supporting News Credibility Assessment on Social Media\n  Through Nudges', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'NudgeCred: Supporting News Credibility Assessment on Social Media\n  Through Nudges'}, 'summary': ""Struggling to curb misinformation, social media platforms are experimenting\nwith design interventions to enhance consumption of credible news on their\nplatforms. Some of these interventions, such as the use of warning messages,\nare examples of nudges -- a choice-preserving technique to steer behavior.\nDespite their application, we do not know whether nudges could steer people\ninto making conscious news credibility judgments online and if they do, under\nwhat constraints. To answer, we combine nudge techniques with heuristic based\ninformation processing to design NudgeCred -- a browser extension for Twitter.\nNudgeCred directs users' attention to two design cues: authority of a source\nand other users' collective opinion on a report by activating three design\nnudges -- Reliable, Questionable, and Unreliable, each denoting particular\nlevels of credibility for news tweets. In a controlled experiment, we found\nthat NudgeCred significantly helped users (n=430) distinguish news tweets'\ncredibility, unrestricted by three behavioral confounds -- political ideology,\npolitical cynicism, and media skepticism. A five-day field deployment with\ntwelve participants revealed that NudgeCred improved their recognition of news\nitems and attention towards all of our nudges, particularly towards\nQuestionable. Among other considerations, participants proposed that designers\nshould incorporate heuristics that users' would trust. Our work informs\nnudge-based system design approaches for online media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Struggling to curb misinformation, social media platforms are experimenting\nwith design interventions to enhance consumption of credible news on their\nplatforms. Some of these interventions, such as the use of warning messages,\nare examples of nudges -- a choice-preserving technique to steer behavior.\nDespite their application, we do not know whether nudges could steer people\ninto making conscious news credibility judgments online and if they do, under\nwhat constraints. To answer, we combine nudge techniques with heuristic based\ninformation processing to design NudgeCred -- a browser extension for Twitter.\nNudgeCred directs users' attention to two design cues: authority of a source\nand other users' collective opinion on a report by activating three design\nnudges -- Reliable, Questionable, and Unreliable, each denoting particular\nlevels of credibility for news tweets. In a controlled experiment, we found\nthat NudgeCred significantly helped users (n=430) distinguish news tweets'\ncredibility, unrestricted by three behavioral confounds -- political ideology,\npolitical cynicism, and media skepticism. A five-day field deployment with\ntwelve participants revealed that NudgeCred improved their recognition of news\nitems and attention towards all of our nudges, particularly towards\nQuestionable. Among other considerations, participants proposed that designers\nshould incorporate heuristics that users' would trust. Our work informs\nnudge-based system design approaches for online media.""}, 'authors': [{'name': 'Md Momen Bhuiyan'}, {'name': 'Michael Horning'}, {'name': 'Sang Won Lee'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_doi': '10.1145/3479571', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3479571', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2108.01536v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.01536v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '30 pages, CSCW 2021', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
42,http://arxiv.org/abs/2108.12269v1,2021-07-31 06:40:17+00:00,2021-07-31 06:40:17+00:00,Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic,"[arxiv.Result.Author('Rong-Ching Chang'), arxiv.Result.Author('Chu-Hsing Lin')]","The spread of misinformation, conspiracy, and questionable content and
information manipulation by foreign adversaries on social media has surged
along with the COVID-19 pandemic. Such malicious cyber-enabled actions may
cause increasing social polarization, health crises, and property loss. In this
paper, using fine-tuned contextualized embedding trained on Reddit, we tackle
the detection of the propaganda of such user accounts and their targeted issues
on Twitter during March 2020 when the COVID-19 epidemic became recognized as a
pandemic. Our result shows that the pro-China group appeared to be tweeting 35
to 115 times more than the neutral group. At the same time, neutral groups were
tweeting more positive-attitude content and voicing alarm for the COVID-19
situation. The pro-China group was also using more call-for-action words on
political issues not necessarily China-related.",,,,cs.CY,"['cs.CY', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2108.12269v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2108.12269v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2108.12269v1,"{'id': 'http://arxiv.org/abs/2108.12269v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2108.12269v1', 'updated': '2021-07-31T06:40:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=31, tm_hour=6, tm_min=40, tm_sec=17, tm_wday=5, tm_yday=212, tm_isdst=0), 'published': '2021-07-31T06:40:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=31, tm_hour=6, tm_min=40, tm_sec=17, tm_wday=5, tm_yday=212, tm_isdst=0), 'title': 'Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic'}, 'summary': 'The spread of misinformation, conspiracy, and questionable content and\ninformation manipulation by foreign adversaries on social media has surged\nalong with the COVID-19 pandemic. Such malicious cyber-enabled actions may\ncause increasing social polarization, health crises, and property loss. In this\npaper, using fine-tuned contextualized embedding trained on Reddit, we tackle\nthe detection of the propaganda of such user accounts and their targeted issues\non Twitter during March 2020 when the COVID-19 epidemic became recognized as a\npandemic. Our result shows that the pro-China group appeared to be tweeting 35\nto 115 times more than the neutral group. At the same time, neutral groups were\ntweeting more positive-attitude content and voicing alarm for the COVID-19\nsituation. The pro-China group was also using more call-for-action words on\npolitical issues not necessarily China-related.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of misinformation, conspiracy, and questionable content and\ninformation manipulation by foreign adversaries on social media has surged\nalong with the COVID-19 pandemic. Such malicious cyber-enabled actions may\ncause increasing social polarization, health crises, and property loss. In this\npaper, using fine-tuned contextualized embedding trained on Reddit, we tackle\nthe detection of the propaganda of such user accounts and their targeted issues\non Twitter during March 2020 when the COVID-19 epidemic became recognized as a\npandemic. Our result shows that the pro-China group appeared to be tweeting 35\nto 115 times more than the neutral group. At the same time, neutral groups were\ntweeting more positive-attitude content and voicing alarm for the COVID-19\nsituation. The pro-China group was also using more call-for-action words on\npolitical issues not necessarily China-related.'}, 'authors': [{'name': 'Rong-Ching Chang'}, {'name': 'Chu-Hsing Lin'}], 'author_detail': {'name': 'Chu-Hsing Lin'}, 'author': 'Chu-Hsing Lin', 'links': [{'href': 'http://arxiv.org/abs/2108.12269v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2108.12269v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
43,http://arxiv.org/abs/2107.14625v1,2021-07-30 13:46:36+00:00,2021-07-30 13:46:36+00:00,Single-Leader-Multiple-Followers Stackelberg Security Game with Hypergame Framework,"[arxiv.Result.Author('Zhaoyang Cheng'), arxiv.Result.Author('Guanpu Chen'), arxiv.Result.Author('Yiguang Hong')]","In this paper, we employ a hypergame framework to analyze the
single-leader-multiple-followers (SLMF) Stackelberg security game with two
typical misinformed situations: misperception and deception. We provide a
stability criterion with the help of hyper Nash equilibrium (HNE) to analyze
both strategic stability and cognitive stability of equilibria in SLMF games
with misinformation. To this end, we find mild stable conditions such that the
equilibria with misperception and deception can derive HNE. Moreover, we
analyze the robustness of the equilibria to reveal whether the players have the
ability to keep their profits.",,,,cs.GT,['cs.GT'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.14625v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.14625v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.14625v1,"{'id': 'http://arxiv.org/abs/2107.14625v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.14625v1', 'updated': '2021-07-30T13:46:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=13, tm_min=46, tm_sec=36, tm_wday=4, tm_yday=211, tm_isdst=0), 'published': '2021-07-30T13:46:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=13, tm_min=46, tm_sec=36, tm_wday=4, tm_yday=211, tm_isdst=0), 'title': 'Single-Leader-Multiple-Followers Stackelberg Security Game with\n  Hypergame Framework', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Single-Leader-Multiple-Followers Stackelberg Security Game with\n  Hypergame Framework'}, 'summary': 'In this paper, we employ a hypergame framework to analyze the\nsingle-leader-multiple-followers (SLMF) Stackelberg security game with two\ntypical misinformed situations: misperception and deception. We provide a\nstability criterion with the help of hyper Nash equilibrium (HNE) to analyze\nboth strategic stability and cognitive stability of equilibria in SLMF games\nwith misinformation. To this end, we find mild stable conditions such that the\nequilibria with misperception and deception can derive HNE. Moreover, we\nanalyze the robustness of the equilibria to reveal whether the players have the\nability to keep their profits.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we employ a hypergame framework to analyze the\nsingle-leader-multiple-followers (SLMF) Stackelberg security game with two\ntypical misinformed situations: misperception and deception. We provide a\nstability criterion with the help of hyper Nash equilibrium (HNE) to analyze\nboth strategic stability and cognitive stability of equilibria in SLMF games\nwith misinformation. To this end, we find mild stable conditions such that the\nequilibria with misperception and deception can derive HNE. Moreover, we\nanalyze the robustness of the equilibria to reveal whether the players have the\nability to keep their profits.'}, 'authors': [{'name': 'Zhaoyang Cheng'}, {'name': 'Guanpu Chen'}, {'name': 'Yiguang Hong'}], 'author_detail': {'name': 'Yiguang Hong'}, 'author': 'Yiguang Hong', 'links': [{'href': 'http://arxiv.org/abs/2107.14625v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.14625v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
44,http://arxiv.org/abs/2107.14155v1,2021-07-29 16:26:18+00:00,2021-07-29 16:26:18+00:00,Brexit and bots: characterizing the behaviour of automated accounts on Twitter during the UK election,"[arxiv.Result.Author('Matteo Bruno'), arxiv.Result.Author('Renaud Lambiotte'), arxiv.Result.Author('Fabio Saracco')]","Online Social Networks represent a novel opportunity for political campaigns,
revolutionising the paradigm of political communication. Nevertheless, many
studies uncovered the presence of d/misinformation campaigns or of malicious
activities by genuine or automated users, putting at severe risk the
credibility of online platforms. This phenomenon is particularly evident during
crucial political events, as political elections. In the present paper, we
provide a comprehensive description of the structure of the networks of
interactions among users and bots during the UK elections of 2019. In
particular, we focus on the polarised discussion about Brexit on Twitter
analysing a data set made of more than 10 million tweets posted for over a
month. We found that the presence of automated accounts fostered the debate
particularly in the days before the UK national elections, in which we find a
steep increase of bots in the discussion; in the days after the election day,
their incidence returned to values similar to the ones observed few weeks
before the elections. On the other hand, we found that the number of suspended
users (i.e. accounts that were removed by the platform for some violation of
the Twitter policy) remained constant until the election day, after which it
reached significantly higher values. Remarkably, after the TV debate between
Boris Johnson and Jeremy Corbyn, we observed the injection of a large number of
novel bots whose behaviour is markedly different from that of pre-existing
ones. Finally, we explored the bots' stance, finding that their activity is
spread across the whole political spectrum, although in different proportions,
and we studied the different usage of hashtags by automated accounts and
suspended users, thus targeting the formation of common narratives in different
sides of the debate.","18 pages, 13 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2107.14155v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.14155v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.14155v1,"{'id': 'http://arxiv.org/abs/2107.14155v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.14155v1', 'updated': '2021-07-29T16:26:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=29, tm_hour=16, tm_min=26, tm_sec=18, tm_wday=3, tm_yday=210, tm_isdst=0), 'published': '2021-07-29T16:26:18Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=29, tm_hour=16, tm_min=26, tm_sec=18, tm_wday=3, tm_yday=210, tm_isdst=0), 'title': 'Brexit and bots: characterizing the behaviour of automated accounts on\n  Twitter during the UK election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Brexit and bots: characterizing the behaviour of automated accounts on\n  Twitter during the UK election'}, 'summary': ""Online Social Networks represent a novel opportunity for political campaigns,\nrevolutionising the paradigm of political communication. Nevertheless, many\nstudies uncovered the presence of d/misinformation campaigns or of malicious\nactivities by genuine or automated users, putting at severe risk the\ncredibility of online platforms. This phenomenon is particularly evident during\ncrucial political events, as political elections. In the present paper, we\nprovide a comprehensive description of the structure of the networks of\ninteractions among users and bots during the UK elections of 2019. In\nparticular, we focus on the polarised discussion about Brexit on Twitter\nanalysing a data set made of more than 10 million tweets posted for over a\nmonth. We found that the presence of automated accounts fostered the debate\nparticularly in the days before the UK national elections, in which we find a\nsteep increase of bots in the discussion; in the days after the election day,\ntheir incidence returned to values similar to the ones observed few weeks\nbefore the elections. On the other hand, we found that the number of suspended\nusers (i.e. accounts that were removed by the platform for some violation of\nthe Twitter policy) remained constant until the election day, after which it\nreached significantly higher values. Remarkably, after the TV debate between\nBoris Johnson and Jeremy Corbyn, we observed the injection of a large number of\nnovel bots whose behaviour is markedly different from that of pre-existing\nones. Finally, we explored the bots' stance, finding that their activity is\nspread across the whole political spectrum, although in different proportions,\nand we studied the different usage of hashtags by automated accounts and\nsuspended users, thus targeting the formation of common narratives in different\nsides of the debate."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online Social Networks represent a novel opportunity for political campaigns,\nrevolutionising the paradigm of political communication. Nevertheless, many\nstudies uncovered the presence of d/misinformation campaigns or of malicious\nactivities by genuine or automated users, putting at severe risk the\ncredibility of online platforms. This phenomenon is particularly evident during\ncrucial political events, as political elections. In the present paper, we\nprovide a comprehensive description of the structure of the networks of\ninteractions among users and bots during the UK elections of 2019. In\nparticular, we focus on the polarised discussion about Brexit on Twitter\nanalysing a data set made of more than 10 million tweets posted for over a\nmonth. We found that the presence of automated accounts fostered the debate\nparticularly in the days before the UK national elections, in which we find a\nsteep increase of bots in the discussion; in the days after the election day,\ntheir incidence returned to values similar to the ones observed few weeks\nbefore the elections. On the other hand, we found that the number of suspended\nusers (i.e. accounts that were removed by the platform for some violation of\nthe Twitter policy) remained constant until the election day, after which it\nreached significantly higher values. Remarkably, after the TV debate between\nBoris Johnson and Jeremy Corbyn, we observed the injection of a large number of\nnovel bots whose behaviour is markedly different from that of pre-existing\nones. Finally, we explored the bots' stance, finding that their activity is\nspread across the whole political spectrum, although in different proportions,\nand we studied the different usage of hashtags by automated accounts and\nsuspended users, thus targeting the formation of common narratives in different\nsides of the debate.""}, 'authors': [{'name': 'Matteo Bruno'}, {'name': 'Renaud Lambiotte'}, {'name': 'Fabio Saracco'}], 'author_detail': {'name': 'Fabio Saracco'}, 'author': 'Fabio Saracco', 'arxiv_comment': '18 pages, 13 figures', 'links': [{'href': 'http://arxiv.org/abs/2107.14155v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.14155v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
45,http://arxiv.org/abs/2107.12303v2,2021-08-04 18:59:47+00:00,2021-07-26 16:20:44+00:00,The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal Analysis,"[arxiv.Result.Author('Iknoor Singh'), arxiv.Result.Author('Kalina Bontcheva'), arxiv.Result.Author('Carolina Scarton')]","The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a
global infodemic that has brought unprecedented challenges for society as a
whole. During this time, a number of manual fact-checking initiatives have
emerged to alleviate the spread of dis/mis-information. This study is about
COVID-19 debunks published in multiple languages by different fact-checking
organisations, sometimes as far as several months apart, despite the fact that
the claim has already been fact-checked before. The spatiotemporal analysis
reveals that similar or nearly duplicate false COVID-19 narratives have been
spreading in multifarious modalities on various social media platforms in
different countries. We also find that misinformation involving general medical
advice has spread across multiple countries and hence has the highest
proportion of false COVID-19 narratives that keep being debunked. Furthermore,
as manual fact-checking is an onerous task in itself, therefore debunking
similar claims recurrently is leading to a waste of resources. To this end, we
propound the idea of the inclusion of multilingual debunk search in the
fact-checking pipeline.",Under Review,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.12303v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.12303v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.12303v2,"{'id': 'http://arxiv.org/abs/2107.12303v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.12303v2', 'updated': '2021-08-04T18:59:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=4, tm_hour=18, tm_min=59, tm_sec=47, tm_wday=2, tm_yday=216, tm_isdst=0), 'published': '2021-07-26T16:20:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=26, tm_hour=16, tm_min=20, tm_sec=44, tm_wday=0, tm_yday=207, tm_isdst=0), 'title': 'The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis'}, 'summary': 'The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.'}, 'authors': [{'name': 'Iknoor Singh'}, {'name': 'Kalina Bontcheva'}, {'name': 'Carolina Scarton'}], 'author_detail': {'name': 'Carolina Scarton'}, 'author': 'Carolina Scarton', 'arxiv_comment': 'Under Review', 'links': [{'href': 'http://arxiv.org/abs/2107.12303v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.12303v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
46,http://arxiv.org/abs/2107.11755v2,2021-09-19 10:14:15+00:00,2021-07-25 08:37:09+00:00,Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent Misinformation about COVID-19,"[arxiv.Result.Author('Kevin Roitero'), arxiv.Result.Author('Michael Soprano'), arxiv.Result.Author('Beatrice Portelli'), arxiv.Result.Author('Massimiliano De Luise'), arxiv.Result.Author('Damiano Spina'), arxiv.Result.Author('Vincenzo Della Mea'), arxiv.Result.Author('Giuseppe Serra'), arxiv.Result.Author('Stefano Mizzaro'), arxiv.Result.Author('Gianluca Demartini')]","Recently, the misinformation problem has been addressed with a
crowdsourcing-based approach: to assess the truthfulness of a statement,
instead of relying on a few experts, a crowd of non-expert is exploited. We
study whether crowdsourcing is an effective and reliable method to assess
truthfulness during a pandemic, targeting statements related to COVID-19, thus
addressing (mis)information that is both related to a sensitive and personal
issue and very recent as compared to when the judgment is done. In our
experiments, crowd workers are asked to assess the truthfulness of statements,
and to provide evidence for the assessments. Besides showing that the crowd is
able to accurately judge the truthfulness of the statements, we report results
on workers behavior, agreement among workers, effect of aggregation functions,
of scales transformations, and of workers background and bias. We perform a
longitudinal study by re-launching the task multiple times with both novice and
experienced workers, deriving important insights on how the behavior and
quality change over time. Our results show that: workers are able to detect and
objectively categorize online (mis)information related to COVID-19; both
crowdsourced and expert judgments can be transformed and aggregated to improve
quality; worker background and other signals (e.g., source of information,
behavior) impact the quality of the data. The longitudinal study demonstrates
that the time-span has a major effect on the quality of the judgments, for both
novice and experienced workers. Finally, we provide an extensive failure
analysis of the statements misjudged by the crowd-workers.","31 pages; Preprint of an article accepted in Personal and Ubiquitous
  Computing (Special Issue on Intelligent Systems for Tackling Online Harms,
  2021). arXiv admin note: substantial text overlap with arXiv:2008.05701",,10.1007/s00779-021-01604-6,cs.IR,"['cs.IR', 'cs.SI', '68P20', 'H.3']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s00779-021-01604-6', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2107.11755v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.11755v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.11755v2,"{'id': 'http://arxiv.org/abs/2107.11755v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.11755v2', 'updated': '2021-09-19T10:14:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=19, tm_hour=10, tm_min=14, tm_sec=15, tm_wday=6, tm_yday=262, tm_isdst=0), 'published': '2021-07-25T08:37:09Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=25, tm_hour=8, tm_min=37, tm_sec=9, tm_wday=6, tm_yday=206, tm_isdst=0), 'title': 'Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent\n  Misinformation about COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent\n  Misinformation about COVID-19'}, 'summary': 'Recently, the misinformation problem has been addressed with a\ncrowdsourcing-based approach: to assess the truthfulness of a statement,\ninstead of relying on a few experts, a crowd of non-expert is exploited. We\nstudy whether crowdsourcing is an effective and reliable method to assess\ntruthfulness during a pandemic, targeting statements related to COVID-19, thus\naddressing (mis)information that is both related to a sensitive and personal\nissue and very recent as compared to when the judgment is done. In our\nexperiments, crowd workers are asked to assess the truthfulness of statements,\nand to provide evidence for the assessments. Besides showing that the crowd is\nable to accurately judge the truthfulness of the statements, we report results\non workers behavior, agreement among workers, effect of aggregation functions,\nof scales transformations, and of workers background and bias. We perform a\nlongitudinal study by re-launching the task multiple times with both novice and\nexperienced workers, deriving important insights on how the behavior and\nquality change over time. Our results show that: workers are able to detect and\nobjectively categorize online (mis)information related to COVID-19; both\ncrowdsourced and expert judgments can be transformed and aggregated to improve\nquality; worker background and other signals (e.g., source of information,\nbehavior) impact the quality of the data. The longitudinal study demonstrates\nthat the time-span has a major effect on the quality of the judgments, for both\nnovice and experienced workers. Finally, we provide an extensive failure\nanalysis of the statements misjudged by the crowd-workers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, the misinformation problem has been addressed with a\ncrowdsourcing-based approach: to assess the truthfulness of a statement,\ninstead of relying on a few experts, a crowd of non-expert is exploited. We\nstudy whether crowdsourcing is an effective and reliable method to assess\ntruthfulness during a pandemic, targeting statements related to COVID-19, thus\naddressing (mis)information that is both related to a sensitive and personal\nissue and very recent as compared to when the judgment is done. In our\nexperiments, crowd workers are asked to assess the truthfulness of statements,\nand to provide evidence for the assessments. Besides showing that the crowd is\nable to accurately judge the truthfulness of the statements, we report results\non workers behavior, agreement among workers, effect of aggregation functions,\nof scales transformations, and of workers background and bias. We perform a\nlongitudinal study by re-launching the task multiple times with both novice and\nexperienced workers, deriving important insights on how the behavior and\nquality change over time. Our results show that: workers are able to detect and\nobjectively categorize online (mis)information related to COVID-19; both\ncrowdsourced and expert judgments can be transformed and aggregated to improve\nquality; worker background and other signals (e.g., source of information,\nbehavior) impact the quality of the data. The longitudinal study demonstrates\nthat the time-span has a major effect on the quality of the judgments, for both\nnovice and experienced workers. Finally, we provide an extensive failure\nanalysis of the statements misjudged by the crowd-workers.'}, 'authors': [{'name': 'Kevin Roitero'}, {'name': 'Michael Soprano'}, {'name': 'Beatrice Portelli'}, {'name': 'Massimiliano De Luise'}, {'name': 'Damiano Spina'}, {'name': 'Vincenzo Della Mea'}, {'name': 'Giuseppe Serra'}, {'name': 'Stefano Mizzaro'}, {'name': 'Gianluca Demartini'}], 'author_detail': {'name': 'Gianluca Demartini'}, 'author': 'Gianluca Demartini', 'arxiv_doi': '10.1007/s00779-021-01604-6', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s00779-021-01604-6', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2107.11755v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.11755v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '31 pages; Preprint of an article accepted in Personal and Ubiquitous\n  Computing (Special Issue on Intelligent Systems for Tackling Online Harms,\n  2021). arXiv admin note: substantial text overlap with arXiv:2008.05701', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68P20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
47,http://arxiv.org/abs/2107.10204v1,2021-07-21 16:49:21+00:00,2021-07-21 16:49:21+00:00,Characterizing Social Imaginaries and Self-Disclosures of Dissonance in Online Conspiracy Discussion Communities,"[arxiv.Result.Author('Shruti Phadke'), arxiv.Result.Author('Mattia Samory'), arxiv.Result.Author('Tanushree Mitra')]","Online discussion platforms offer a forum to strengthen and propagate belief
in misinformed conspiracy theories. Yet, they also offer avenues for conspiracy
theorists to express their doubts and experiences of cognitive dissonance. Such
expressions of dissonance may shed light on who abandons misguided beliefs and
under which circumstances. This paper characterizes self-disclosures of
dissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q
and popularized by their followers, anons in conspiracy theory subreddits. To
understand what dissonance and disbelief mean within conspiracy communities, we
first characterize their social imaginaries, a broad understanding of how
people collectively imagine their social existence. Focusing on 2K posts from
two image boards, 4chan and 8chan, and 1.2 M comments and posts from 12
subreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the
symbolic language representing the movement, expectations, practices, heroes
and foes of the QAnon community. We use these social imaginaries to create a
computational framework for distinguishing belief and dissonance from general
discussion about QAnon. Further, analyzing user engagement with QAnon
conspiracy subreddits, we find that self-disclosures of dissonance correlate
with a significant decrease in user contributions and ultimately with their
departure from the community. We contribute a computational framework for
identifying dissonance self-disclosures and measuring the changes in user
engagement surrounding dissonance. Our work can provide insights into designing
dissonance-based interventions that can potentially dissuade conspiracists from
online conspiracy discussion communities.",Accepted at CSCW 2021,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2107.10204v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.10204v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.10204v1,"{'id': 'http://arxiv.org/abs/2107.10204v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.10204v1', 'updated': '2021-07-21T16:49:21Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=21, tm_hour=16, tm_min=49, tm_sec=21, tm_wday=2, tm_yday=202, tm_isdst=0), 'published': '2021-07-21T16:49:21Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=21, tm_hour=16, tm_min=49, tm_sec=21, tm_wday=2, tm_yday=202, tm_isdst=0), 'title': 'Characterizing Social Imaginaries and Self-Disclosures of Dissonance in\n  Online Conspiracy Discussion Communities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing Social Imaginaries and Self-Disclosures of Dissonance in\n  Online Conspiracy Discussion Communities'}, 'summary': 'Online discussion platforms offer a forum to strengthen and propagate belief\nin misinformed conspiracy theories. Yet, they also offer avenues for conspiracy\ntheorists to express their doubts and experiences of cognitive dissonance. Such\nexpressions of dissonance may shed light on who abandons misguided beliefs and\nunder which circumstances. This paper characterizes self-disclosures of\ndissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q\nand popularized by their followers, anons in conspiracy theory subreddits. To\nunderstand what dissonance and disbelief mean within conspiracy communities, we\nfirst characterize their social imaginaries, a broad understanding of how\npeople collectively imagine their social existence. Focusing on 2K posts from\ntwo image boards, 4chan and 8chan, and 1.2 M comments and posts from 12\nsubreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the\nsymbolic language representing the movement, expectations, practices, heroes\nand foes of the QAnon community. We use these social imaginaries to create a\ncomputational framework for distinguishing belief and dissonance from general\ndiscussion about QAnon. Further, analyzing user engagement with QAnon\nconspiracy subreddits, we find that self-disclosures of dissonance correlate\nwith a significant decrease in user contributions and ultimately with their\ndeparture from the community. We contribute a computational framework for\nidentifying dissonance self-disclosures and measuring the changes in user\nengagement surrounding dissonance. Our work can provide insights into designing\ndissonance-based interventions that can potentially dissuade conspiracists from\nonline conspiracy discussion communities.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online discussion platforms offer a forum to strengthen and propagate belief\nin misinformed conspiracy theories. Yet, they also offer avenues for conspiracy\ntheorists to express their doubts and experiences of cognitive dissonance. Such\nexpressions of dissonance may shed light on who abandons misguided beliefs and\nunder which circumstances. This paper characterizes self-disclosures of\ndissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q\nand popularized by their followers, anons in conspiracy theory subreddits. To\nunderstand what dissonance and disbelief mean within conspiracy communities, we\nfirst characterize their social imaginaries, a broad understanding of how\npeople collectively imagine their social existence. Focusing on 2K posts from\ntwo image boards, 4chan and 8chan, and 1.2 M comments and posts from 12\nsubreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the\nsymbolic language representing the movement, expectations, practices, heroes\nand foes of the QAnon community. We use these social imaginaries to create a\ncomputational framework for distinguishing belief and dissonance from general\ndiscussion about QAnon. Further, analyzing user engagement with QAnon\nconspiracy subreddits, we find that self-disclosures of dissonance correlate\nwith a significant decrease in user contributions and ultimately with their\ndeparture from the community. We contribute a computational framework for\nidentifying dissonance self-disclosures and measuring the changes in user\nengagement surrounding dissonance. Our work can provide insights into designing\ndissonance-based interventions that can potentially dissuade conspiracists from\nonline conspiracy discussion communities.'}, 'authors': [{'name': 'Shruti Phadke'}, {'name': 'Mattia Samory'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_comment': 'Accepted at CSCW 2021', 'links': [{'href': 'http://arxiv.org/abs/2107.10204v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.10204v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
48,http://arxiv.org/abs/2107.09768v1,2021-07-20 20:58:23+00:00,2021-07-20 20:58:23+00:00,Checkovid: A COVID-19 misinformation detection system on Twitter using network and content mining perspectives,"[arxiv.Result.Author('Sajad Dadgar'), arxiv.Result.Author('Mehdi Ghatee')]","During the COVID-19 pandemic, social media platforms were ideal for
communicating due to social isolation and quarantine. Also, it was the primary
source of misinformation dissemination on a large scale, referred to as the
infodemic. Therefore, automatic debunking misinformation is a crucial problem.
To tackle this problem, we present two COVID-19 related misinformation datasets
on Twitter and propose a misinformation detection system comprising
network-based and content-based processes based on machine learning algorithms
and NLP techniques. In the network-based process, we focus on social
properties, network characteristics, and users. On the other hand, we classify
misinformation using the content of the tweets directly in the content-based
process, which contains text classification models (paragraph-level and
sentence-level) and similarity models. The evaluation results on the
network-based process show the best results for the artificial neural network
model with an F1 score of 88.68%. In the content-based process, our novel
similarity models, which obtained an F1 score of 90.26%, show an improvement in
the misinformation classification results compared to the network-based models.
In addition, in the text classification models, the best result was achieved
using the stacking ensemble-learning model by obtaining an F1 score of 95.18%.
Furthermore, we test our content-based models on the Constraint@AAAI2021
dataset, and by getting an F1 score of 94.38%, we improve the baseline results.
Finally, we develop a fact-checking website called Checkovid that uses each
process to detect misinformative and informative claims in the domain of
COVID-19 from different perspectives.","20 Pages, 18 Figures, 7 Tables, Submitted for Review Process in a
  Journal",,,cs.LG,"['cs.LG', 'cs.CL', 'cs.SI', '68T05, 68T07', 'I.2; I.5']","[arxiv.Result.Link('http://arxiv.org/abs/2107.09768v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.09768v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.09768v1,"{'id': 'http://arxiv.org/abs/2107.09768v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.09768v1', 'updated': '2021-07-20T20:58:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=20, tm_hour=20, tm_min=58, tm_sec=23, tm_wday=1, tm_yday=201, tm_isdst=0), 'published': '2021-07-20T20:58:23Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=20, tm_hour=20, tm_min=58, tm_sec=23, tm_wday=1, tm_yday=201, tm_isdst=0), 'title': 'Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives'}, 'summary': 'During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.'}, 'authors': [{'name': 'Sajad Dadgar'}, {'name': 'Mehdi Ghatee'}], 'author_detail': {'name': 'Mehdi Ghatee'}, 'author': 'Mehdi Ghatee', 'arxiv_comment': '20 Pages, 18 Figures, 7 Tables, Submitted for Review Process in a\n  Journal', 'links': [{'href': 'http://arxiv.org/abs/2107.09768v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.09768v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T05, 68T07', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; I.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
49,http://arxiv.org/abs/2107.09183v2,2021-09-03 19:53:03+00:00,2021-07-19 22:47:17+00:00,Analysis of External Content in the Vaccination Discussion on Twitter,"[arxiv.Result.Author('Richard Kuzma'), arxiv.Result.Author('Iain J. Cruickshank'), arxiv.Result.Author('Kathleen M. Carley')]","The spread of coronavirus and anti-vaccine conspiracies online hindered
public health responses to the pandemic. We examined the content of external
articles shared on Twitter from February to June 2020 to understand how
conspiracy theories and fake news competed with legitimate sources of
information. Examining external content--articles, rather than social media
posts--is a novel methodology that allows for non-social media specific
analysis of misinformation, tracking of changing narratives over time, and
determining which types of resources (government, news, scientific, or dubious)
dominate the pandemic vaccine conversation. We find that distinct narratives
emerge, those narratives change over time, and lack of government and
scientific messaging on coronavirus created an information vacuum filled by
both traditional news and conspiracy theories.",Data Ownership Issues,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2107.09183v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.09183v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.09183v2,"{'id': 'http://arxiv.org/abs/2107.09183v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.09183v2', 'updated': '2021-09-03T19:53:03Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=3, tm_hour=19, tm_min=53, tm_sec=3, tm_wday=4, tm_yday=246, tm_isdst=0), 'published': '2021-07-19T22:47:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=19, tm_hour=22, tm_min=47, tm_sec=17, tm_wday=0, tm_yday=200, tm_isdst=0), 'title': 'Analysis of External Content in the Vaccination Discussion on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysis of External Content in the Vaccination Discussion on Twitter'}, 'summary': 'The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.'}, 'authors': [{'name': 'Richard Kuzma'}, {'name': 'Iain J. Cruickshank'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_comment': 'Data Ownership Issues', 'links': [{'href': 'http://arxiv.org/abs/2107.09183v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.09183v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
50,http://arxiv.org/abs/2107.08357v1,2021-07-18 04:09:47+00:00,2021-07-18 04:09:47+00:00,"As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical Translation","[arxiv.Result.Author('Jun Wang'), arxiv.Result.Author('Chang Xu'), arxiv.Result.Author('Francisco Guzman'), arxiv.Result.Author('Ahmed El-Kishky'), arxiv.Result.Author('Benjamin I. P. Rubinstein'), arxiv.Result.Author('Trevor Cohn')]","Mistranslated numbers have the potential to cause serious effects, such as
financial loss or medical misinformation. In this work we develop comprehensive
assessments of the robustness of neural machine translation systems to
numerical text via behavioural testing. We explore a variety of numerical
translation capabilities a system is expected to exhibit and design effective
test examples to expose system underperformance. We find that numerical
mistranslation is a general issue: major commercial systems and
state-of-the-art research models fail on many of our test examples, for high-
and low-resource languages. Our tests reveal novel errors that have not
previously been reported in NMT systems, to the best of our knowledge. Lastly,
we discuss strategies to mitigate numerical mistranslation.","Findings of ACL, to appear",,,cs.CL,"['cs.CL', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2107.08357v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.08357v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.08357v1,"{'id': 'http://arxiv.org/abs/2107.08357v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.08357v1', 'updated': '2021-07-18T04:09:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=18, tm_hour=4, tm_min=9, tm_sec=47, tm_wday=6, tm_yday=199, tm_isdst=0), 'published': '2021-07-18T04:09:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=18, tm_hour=4, tm_min=9, tm_sec=47, tm_wday=6, tm_yday=199, tm_isdst=0), 'title': 'As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical\n  Translation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical\n  Translation'}, 'summary': 'Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.'}, 'authors': [{'name': 'Jun Wang'}, {'name': 'Chang Xu'}, {'name': 'Francisco Guzman'}, {'name': 'Ahmed El-Kishky'}, {'name': 'Benjamin I. P. Rubinstein'}, {'name': 'Trevor Cohn'}], 'author_detail': {'name': 'Trevor Cohn'}, 'author': 'Trevor Cohn', 'arxiv_comment': 'Findings of ACL, to appear', 'links': [{'href': 'http://arxiv.org/abs/2107.08357v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.08357v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
51,http://arxiv.org/abs/2107.08034v1,2021-07-16 17:56:27+00:00,2021-07-16 17:56:27+00:00,Pilot Study Suggests Online Media Literacy Programming Reduces Belief in False News in Indonesia,"[arxiv.Result.Author('Pamela Bilo Thomas'), arxiv.Result.Author('Clark Hogan-Taylor'), arxiv.Result.Author('Michael Yankoski'), arxiv.Result.Author('Tim Weninger')]","Amidst the threat of digital misinformation, we offer a pilot study regarding
the efficacy of an online social media literacy campaign aimed at empowering
individuals in Indonesia with skills to help them identify misinformation. We
found that users who engaged with our online training materials and educational
videos were more likely to identify misinformation than those in our control
group (total $N$=1000). Given the promising results of our preliminary study,
we plan to expand efforts in this area, and build upon lessons learned from
this pilot study.",13 pages,,,cs.CY,"['cs.CY', 'cs.HC', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.08034v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.08034v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.08034v1,"{'id': 'http://arxiv.org/abs/2107.08034v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.08034v1', 'updated': '2021-07-16T17:56:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=16, tm_hour=17, tm_min=56, tm_sec=27, tm_wday=4, tm_yday=197, tm_isdst=0), 'published': '2021-07-16T17:56:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=16, tm_hour=17, tm_min=56, tm_sec=27, tm_wday=4, tm_yday=197, tm_isdst=0), 'title': 'Pilot Study Suggests Online Media Literacy Programming Reduces Belief in\n  False News in Indonesia', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Pilot Study Suggests Online Media Literacy Programming Reduces Belief in\n  False News in Indonesia'}, 'summary': 'Amidst the threat of digital misinformation, we offer a pilot study regarding\nthe efficacy of an online social media literacy campaign aimed at empowering\nindividuals in Indonesia with skills to help them identify misinformation. We\nfound that users who engaged with our online training materials and educational\nvideos were more likely to identify misinformation than those in our control\ngroup (total $N$=1000). Given the promising results of our preliminary study,\nwe plan to expand efforts in this area, and build upon lessons learned from\nthis pilot study.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Amidst the threat of digital misinformation, we offer a pilot study regarding\nthe efficacy of an online social media literacy campaign aimed at empowering\nindividuals in Indonesia with skills to help them identify misinformation. We\nfound that users who engaged with our online training materials and educational\nvideos were more likely to identify misinformation than those in our control\ngroup (total $N$=1000). Given the promising results of our preliminary study,\nwe plan to expand efforts in this area, and build upon lessons learned from\nthis pilot study.'}, 'authors': [{'name': 'Pamela Bilo Thomas'}, {'name': 'Clark Hogan-Taylor'}, {'name': 'Michael Yankoski'}, {'name': 'Tim Weninger'}], 'author_detail': {'name': 'Tim Weninger'}, 'author': 'Tim Weninger', 'arxiv_comment': '13 pages', 'links': [{'href': 'http://arxiv.org/abs/2107.08034v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.08034v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
52,http://arxiv.org/abs/2107.05243v1,2021-07-12 08:07:09+00:00,2021-07-12 08:07:09+00:00,Putting words into the system's mouth: A targeted attack on neural machine translation using monolingual data poisoning,"[arxiv.Result.Author('Jun Wang'), arxiv.Result.Author('Chang Xu'), arxiv.Result.Author('Francisco Guzman'), arxiv.Result.Author('Ahmed El-Kishky'), arxiv.Result.Author('Yuqing Tang'), arxiv.Result.Author('Benjamin I. P. Rubinstein'), arxiv.Result.Author('Trevor Cohn')]","Neural machine translation systems are known to be vulnerable to adversarial
test inputs, however, as we show in this paper, these systems are also
vulnerable to training attacks. Specifically, we propose a poisoning attack in
which a malicious adversary inserts a small poisoned sample of monolingual text
into the training set of a system trained using back-translation. This sample
is designed to induce a specific, targeted translation behaviour, such as
peddling misinformation. We present two methods for crafting poisoned examples,
and show that only a tiny handful of instances, amounting to only 0.02% of the
training set, is sufficient to enact a successful attack. We outline a defence
method against said attacks, which partly ameliorates the problem. However, we
stress that this is a blind-spot in modern NMT, demanding immediate attention.","Findings of ACL, to appear",,,cs.CL,"['cs.CL', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2107.05243v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.05243v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.05243v1,"{'id': 'http://arxiv.org/abs/2107.05243v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.05243v1', 'updated': '2021-07-12T08:07:09Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=12, tm_hour=8, tm_min=7, tm_sec=9, tm_wday=0, tm_yday=193, tm_isdst=0), 'published': '2021-07-12T08:07:09Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=12, tm_hour=8, tm_min=7, tm_sec=9, tm_wday=0, tm_yday=193, tm_isdst=0), 'title': ""Putting words into the system's mouth: A targeted attack on neural\n  machine translation using monolingual data poisoning"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Putting words into the system's mouth: A targeted attack on neural\n  machine translation using monolingual data poisoning""}, 'summary': 'Neural machine translation systems are known to be vulnerable to adversarial\ntest inputs, however, as we show in this paper, these systems are also\nvulnerable to training attacks. Specifically, we propose a poisoning attack in\nwhich a malicious adversary inserts a small poisoned sample of monolingual text\ninto the training set of a system trained using back-translation. This sample\nis designed to induce a specific, targeted translation behaviour, such as\npeddling misinformation. We present two methods for crafting poisoned examples,\nand show that only a tiny handful of instances, amounting to only 0.02% of the\ntraining set, is sufficient to enact a successful attack. We outline a defence\nmethod against said attacks, which partly ameliorates the problem. However, we\nstress that this is a blind-spot in modern NMT, demanding immediate attention.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Neural machine translation systems are known to be vulnerable to adversarial\ntest inputs, however, as we show in this paper, these systems are also\nvulnerable to training attacks. Specifically, we propose a poisoning attack in\nwhich a malicious adversary inserts a small poisoned sample of monolingual text\ninto the training set of a system trained using back-translation. This sample\nis designed to induce a specific, targeted translation behaviour, such as\npeddling misinformation. We present two methods for crafting poisoned examples,\nand show that only a tiny handful of instances, amounting to only 0.02% of the\ntraining set, is sufficient to enact a successful attack. We outline a defence\nmethod against said attacks, which partly ameliorates the problem. However, we\nstress that this is a blind-spot in modern NMT, demanding immediate attention.'}, 'authors': [{'name': 'Jun Wang'}, {'name': 'Chang Xu'}, {'name': 'Francisco Guzman'}, {'name': 'Ahmed El-Kishky'}, {'name': 'Yuqing Tang'}, {'name': 'Benjamin I. P. Rubinstein'}, {'name': 'Trevor Cohn'}], 'author_detail': {'name': 'Trevor Cohn'}, 'author': 'Trevor Cohn', 'arxiv_comment': 'Findings of ACL, to appear', 'links': [{'href': 'http://arxiv.org/abs/2107.05243v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.05243v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
53,http://arxiv.org/abs/2107.03766v1,2021-07-08 11:24:50+00:00,2021-07-08 11:24:50+00:00,Exploring the effect of social media and spatial characteristics during the COVID-19 pandemic in China,"[arxiv.Result.Author('Xiu-Xiu Zhan'), arxiv.Result.Author('Kaiyue Zhang'), arxiv.Result.Author('Lun Ge'), arxiv.Result.Author('Junming Huang'), arxiv.Result.Author('Zinan Zhang'), arxiv.Result.Author('Lu Wei'), arxiv.Result.Author('Gui-Quan Sun'), arxiv.Result.Author('Chuang Liu'), arxiv.Result.Author('Zi-Ke Zhang')]","The declaration of COVID-19 as a pandemic has largely amplified the spread of
related information on social media, such as Twitter, Facebook, and
WeChat.Unlike the previous studies which focused on how to detect the
misinformation or fake news related toCOVID-19, we investigate how the disease
and information co-evolve in the population. We focus onCOVID-19and its
information during the period when the disease was widely spread in China,
i.e., from January 25th to March 24th, 2020. We first explore how the disease
and information co-evolve via the spatial analysis of the two spreading
processes. We visualize the geo-location of both disease and information at the
province level and find that disease is more geo-localized compared to
information. We find a high correlation between the disease and information
data, and also people care about the spread only when it comes to their
neighborhood. Regard to the content of the information, we find that positive
messages are more negatively correlated with the disease compared to negative
and neutral messages. Additionally, we introduce machine learning algorithms,
i.e., linear regression and random forest, to further predict the number of
infected using different disease spatial related and information-related
characteristics. We obtain that the disease spatial related characteristics of
nearby cities can help to improve the prediction accuracy. Meanwhile,
information-related characteristics can also help to improve the prediction
performance, but with a delay, i.e., the improvement comes from using, for
instance, the number of messages 10 days ago, for disease prediction. The
methodology proposed in this paper may shed light on new clues of emerging
infections",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2107.03766v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.03766v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.03766v1,"{'id': 'http://arxiv.org/abs/2107.03766v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.03766v1', 'updated': '2021-07-08T11:24:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=8, tm_hour=11, tm_min=24, tm_sec=50, tm_wday=3, tm_yday=189, tm_isdst=0), 'published': '2021-07-08T11:24:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=8, tm_hour=11, tm_min=24, tm_sec=50, tm_wday=3, tm_yday=189, tm_isdst=0), 'title': 'Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China'}, 'summary': 'The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections'}, 'authors': [{'name': 'Xiu-Xiu Zhan'}, {'name': 'Kaiyue Zhang'}, {'name': 'Lun Ge'}, {'name': 'Junming Huang'}, {'name': 'Zinan Zhang'}, {'name': 'Lu Wei'}, {'name': 'Gui-Quan Sun'}, {'name': 'Chuang Liu'}, {'name': 'Zi-Ke Zhang'}], 'author_detail': {'name': 'Zi-Ke Zhang'}, 'author': 'Zi-Ke Zhang', 'links': [{'href': 'http://arxiv.org/abs/2107.03766v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.03766v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
54,http://arxiv.org/abs/2107.02828v1,2021-07-06 18:20:38+00:00,2021-07-06 18:20:38+00:00,Cognitive Contagion: How to model (and potentially counter) the spread of fake news,"[arxiv.Result.Author('Nicholas Rabb'), arxiv.Result.Author('Lenore Cowen'), arxiv.Result.Author('Jan P. de Ruiter'), arxiv.Result.Author('Matthias Scheutz')]","Understanding the spread of false or dangerous beliefs - so-called
mis/disinformation - through a population has never seemed so urgent to many.
Network science researchers have often taken a page from epidemiologists, and
modeled the spread of false beliefs as similar to how a disease spreads through
a social network. However, absent from those disease-inspired models is an
internal model of an individual's set of current beliefs, where cognitive
science has increasingly documented how the interaction between mental models
and incoming messages seems to be crucially important for their adoption or
rejection. We introduce a cognitive contagion model that combines a network
science approach with an internal cognitive model of the individual agents,
affecting what they believe, and what they pass on. We show that the model,
even with a very discrete and simplistic belief function to capture cognitive
dissonance, both adds expressive power over existing disease-based contagion
models, and qualitatively demonstrates the appropriate belief update phenomena
at the individual level. Moreover, we situate our cognitive contagion model in
a larger public opinion diffusion model, which attempts to capture the role of
institutions or media sources in belief diffusion - something that is often
left out. We conduct an analysis of the POD model with our simple cognitive
dissonance-sensitive update function across various graph topologies and
institutional messaging patterns. We demonstrate that population-level
aggregate outcomes of the model qualitatively match what has been reported in
COVID misinformation public opinion polls. The overall model sets up a
preliminary framework with which social science misinformation researchers and
computational opinion diffusion modelers can join forces to understand, and
hopefully learn how to best counter, the spread of misinformation and
""alternative facts.""",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2107.02828v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.02828v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.02828v1,"{'id': 'http://arxiv.org/abs/2107.02828v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.02828v1', 'updated': '2021-07-06T18:20:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=18, tm_min=20, tm_sec=38, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2021-07-06T18:20:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=18, tm_min=20, tm_sec=38, tm_wday=1, tm_yday=187, tm_isdst=0), 'title': 'Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news'}, 'summary': 'Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual\'s set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n""alternative facts.""', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual\'s set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n""alternative facts.""'}, 'authors': [{'name': 'Nicholas Rabb'}, {'name': 'Lenore Cowen'}, {'name': 'Jan P. de Ruiter'}, {'name': 'Matthias Scheutz'}], 'author_detail': {'name': 'Matthias Scheutz'}, 'author': 'Matthias Scheutz', 'links': [{'href': 'http://arxiv.org/abs/2107.02828v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.02828v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
55,http://arxiv.org/abs/2107.02775v1,2021-07-06 17:37:56+00:00,2021-07-06 17:37:56+00:00,Countering Misinformation on Social Media Through Educational Interventions: Evidence from a Randomized Experiment in Pakistan,"[arxiv.Result.Author('Ayesha Ali'), arxiv.Result.Author('Ihsan Ayyub Qazi')]","Fake news is a growing problem in developing countries with potentially
far-reaching consequences. We conduct a randomized experiment in urban Pakistan
to evaluate the effectiveness of two educational interventions to counter
misinformation among low-digital literacy populations. We do not find a
significant effect of video-based general educational messages about
misinformation. However, when such messages are augmented with personalized
feedback based on individuals' past engagement with fake news, we find an
improvement of 0.14 standard deviations in identifying fake news. We also find
negative but insignificant effects on identifying true news, driven by female
respondents. Our results suggest that educational interventions can enable
information discernment but their effectiveness critically depends on how well
their features and delivery are customized for the population of interest.",,,,econ.GN,"['econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/2107.02775v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.02775v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.02775v1,"{'id': 'http://arxiv.org/abs/2107.02775v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.02775v1', 'updated': '2021-07-06T17:37:56Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=17, tm_min=37, tm_sec=56, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2021-07-06T17:37:56Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=17, tm_min=37, tm_sec=56, tm_wday=1, tm_yday=187, tm_isdst=0), 'title': 'Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan'}, 'summary': ""Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest.""}, 'authors': [{'name': 'Ayesha Ali'}, {'name': 'Ihsan Ayyub Qazi'}], 'author_detail': {'name': 'Ihsan Ayyub Qazi'}, 'author': 'Ihsan Ayyub Qazi', 'links': [{'href': 'http://arxiv.org/abs/2107.02775v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.02775v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
56,http://arxiv.org/abs/2107.00941v1,2021-07-02 10:02:36+00:00,2021-07-02 10:02:36+00:00,Misinformation Detection on YouTube Using Video Captions,"[arxiv.Result.Author('Raj Jagtap'), arxiv.Result.Author('Abhinav Kumar'), arxiv.Result.Author('Rahul Goel'), arxiv.Result.Author('Shakshi Sharma'), arxiv.Result.Author('Rajesh Sharma'), arxiv.Result.Author('Clint P. George')]","Millions of people use platforms such as YouTube, Facebook, Twitter, and
other mass media. Due to the accessibility of these platforms, they are often
used to establish a narrative, conduct propaganda, and disseminate
misinformation. This work proposes an approach that uses state-of-the-art NLP
techniques to extract features from video captions (subtitles). To evaluate our
approach, we utilize a publicly accessible and labeled dataset for classifying
videos as misinformation or not. The motivation behind exploring video captions
stems from our analysis of videos metadata. Attributes such as the number of
views, likes, dislikes, and comments are ineffective as videos are hard to
differentiate using this information. Using caption dataset, the proposed
models can classify videos among three classes (Misinformation, Debunking
Misinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the
relevance of the misinformation class, we re-formulate our classification
problem as a two-class classification - Misinformation vs. others (Debunking
Misinformation and Neutral). In our experiments, the proposed models can
classify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.",,,,cs.LG,"['cs.LG', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2107.00941v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.00941v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.00941v1,"{'id': 'http://arxiv.org/abs/2107.00941v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.00941v1', 'updated': '2021-07-02T10:02:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=2, tm_hour=10, tm_min=2, tm_sec=36, tm_wday=4, tm_yday=183, tm_isdst=0), 'published': '2021-07-02T10:02:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=2, tm_hour=10, tm_min=2, tm_sec=36, tm_wday=4, tm_yday=183, tm_isdst=0), 'title': 'Misinformation Detection on YouTube Using Video Captions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation Detection on YouTube Using Video Captions'}, 'summary': 'Millions of people use platforms such as YouTube, Facebook, Twitter, and\nother mass media. Due to the accessibility of these platforms, they are often\nused to establish a narrative, conduct propaganda, and disseminate\nmisinformation. This work proposes an approach that uses state-of-the-art NLP\ntechniques to extract features from video captions (subtitles). To evaluate our\napproach, we utilize a publicly accessible and labeled dataset for classifying\nvideos as misinformation or not. The motivation behind exploring video captions\nstems from our analysis of videos metadata. Attributes such as the number of\nviews, likes, dislikes, and comments are ineffective as videos are hard to\ndifferentiate using this information. Using caption dataset, the proposed\nmodels can classify videos among three classes (Misinformation, Debunking\nMisinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the\nrelevance of the misinformation class, we re-formulate our classification\nproblem as a two-class classification - Misinformation vs. others (Debunking\nMisinformation and Neutral). In our experiments, the proposed models can\nclassify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Millions of people use platforms such as YouTube, Facebook, Twitter, and\nother mass media. Due to the accessibility of these platforms, they are often\nused to establish a narrative, conduct propaganda, and disseminate\nmisinformation. This work proposes an approach that uses state-of-the-art NLP\ntechniques to extract features from video captions (subtitles). To evaluate our\napproach, we utilize a publicly accessible and labeled dataset for classifying\nvideos as misinformation or not. The motivation behind exploring video captions\nstems from our analysis of videos metadata. Attributes such as the number of\nviews, likes, dislikes, and comments are ineffective as videos are hard to\ndifferentiate using this information. Using caption dataset, the proposed\nmodels can classify videos among three classes (Misinformation, Debunking\nMisinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the\nrelevance of the misinformation class, we re-formulate our classification\nproblem as a two-class classification - Misinformation vs. others (Debunking\nMisinformation and Neutral). In our experiments, the proposed models can\nclassify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.'}, 'authors': [{'name': 'Raj Jagtap'}, {'name': 'Abhinav Kumar'}, {'name': 'Rahul Goel'}, {'name': 'Shakshi Sharma'}, {'name': 'Rajesh Sharma'}, {'name': 'Clint P. George'}], 'author_detail': {'name': 'Clint P. George'}, 'author': 'Clint P. George', 'links': [{'href': 'http://arxiv.org/abs/2107.00941v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.00941v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
57,http://arxiv.org/abs/2107.02012v1,2021-07-01 11:07:47+00:00,2021-07-01 11:07:47+00:00,Tackling COVID-19 Infodemic using Deep Learning,"[arxiv.Result.Author('Prathmesh Pathwar'), arxiv.Result.Author('Simran Gill')]","Humanity is battling one of the most deleterious virus in modern history, the
COVID-19 pandemic, but along with the pandemic there's an infodemic permeating
the pupil and society with misinformation which exacerbates the current malady.
We try to detect and classify fake news on online media to detect fake
information relating to COVID-19 and coronavirus. The dataset contained fake
posts, articles and news gathered from fact checking websites like politifact
whereas real tweets were taken from verified twitter handles. We incorporated
multiple conventional classification techniques like Naive Bayes, KNN, Gradient
Boost and Random Forest along with Deep learning approaches, specifically CNN,
RNN, DNN and the ensemble model RMDL. We analyzed these approaches with two
feature extraction techniques, TF-IDF and GloVe Word Embeddings which would
provide deeper insights into the dataset containing COVID-19 info on online
media.","15 pages, 4 figures, Accepted in 4th International Conference on
  Computational Intelligence and Data Engineering",,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2107.02012v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2107.02012v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2107.02012v1,"{'id': 'http://arxiv.org/abs/2107.02012v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2107.02012v1', 'updated': '2021-07-01T11:07:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=1, tm_hour=11, tm_min=7, tm_sec=47, tm_wday=3, tm_yday=182, tm_isdst=0), 'published': '2021-07-01T11:07:47Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=1, tm_hour=11, tm_min=7, tm_sec=47, tm_wday=3, tm_yday=182, tm_isdst=0), 'title': 'Tackling COVID-19 Infodemic using Deep Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tackling COVID-19 Infodemic using Deep Learning'}, 'summary': ""Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.""}, 'authors': [{'name': 'Prathmesh Pathwar'}, {'name': 'Simran Gill'}], 'author_detail': {'name': 'Simran Gill'}, 'author': 'Simran Gill', 'arxiv_comment': '15 pages, 4 figures, Accepted in 4th International Conference on\n  Computational Intelligence and Data Engineering', 'links': [{'href': 'http://arxiv.org/abs/2107.02012v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2107.02012v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
58,http://arxiv.org/abs/2106.15715v2,2021-08-12 23:43:28+00:00,2021-06-29 20:39:17+00:00,No Calm in The Storm: Investigating QAnon Website Relationships,"[arxiv.Result.Author('Hans W. A. Hanley'), arxiv.Result.Author('Deepak Kumar'), arxiv.Result.Author('Zakir Durumeric')]","QAnon is a far-right conspiracy theory whose followers largely organize
online. In this work, we use web crawls seeded from two of the largest QAnon
hotbeds on the Internet, Voat and 8kun, to build a hyperlink graph. We then use
this graph to identify, understand, and learn from the websites that spread
QAnon content online. We curate the largest list of QAnon centered websites to
date, from which we document the types of QAnon sites, their hosting providers,
as well as their popularity. We further analyze QAnon websites' connection to
mainstream news and misinformation online, highlighting the outsized role
misinformation websites play in spreading the conspiracy. Finally, we leverage
the observed relationship between QAnon and misinformation sites to build a
random forest classifier that distinguishes between misinformation and
authentic news sites, getting a performance of 0.98 AUC on a test set. Our
results demonstrate new and effective ways to study conspiracy and
misinformation on the Internet.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2106.15715v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.15715v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.15715v2,"{'id': 'http://arxiv.org/abs/2106.15715v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.15715v2', 'updated': '2021-08-12T23:43:28Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=12, tm_hour=23, tm_min=43, tm_sec=28, tm_wday=3, tm_yday=224, tm_isdst=0), 'published': '2021-06-29T20:39:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=29, tm_hour=20, tm_min=39, tm_sec=17, tm_wday=1, tm_yday=180, tm_isdst=0), 'title': 'No Calm in The Storm: Investigating QAnon Website Relationships', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'No Calm in The Storm: Investigating QAnon Website Relationships'}, 'summary': ""QAnon is a far-right conspiracy theory whose followers largely organize\nonline. In this work, we use web crawls seeded from two of the largest QAnon\nhotbeds on the Internet, Voat and 8kun, to build a hyperlink graph. We then use\nthis graph to identify, understand, and learn from the websites that spread\nQAnon content online. We curate the largest list of QAnon centered websites to\ndate, from which we document the types of QAnon sites, their hosting providers,\nas well as their popularity. We further analyze QAnon websites' connection to\nmainstream news and misinformation online, highlighting the outsized role\nmisinformation websites play in spreading the conspiracy. Finally, we leverage\nthe observed relationship between QAnon and misinformation sites to build a\nrandom forest classifier that distinguishes between misinformation and\nauthentic news sites, getting a performance of 0.98 AUC on a test set. Our\nresults demonstrate new and effective ways to study conspiracy and\nmisinformation on the Internet."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""QAnon is a far-right conspiracy theory whose followers largely organize\nonline. In this work, we use web crawls seeded from two of the largest QAnon\nhotbeds on the Internet, Voat and 8kun, to build a hyperlink graph. We then use\nthis graph to identify, understand, and learn from the websites that spread\nQAnon content online. We curate the largest list of QAnon centered websites to\ndate, from which we document the types of QAnon sites, their hosting providers,\nas well as their popularity. We further analyze QAnon websites' connection to\nmainstream news and misinformation online, highlighting the outsized role\nmisinformation websites play in spreading the conspiracy. Finally, we leverage\nthe observed relationship between QAnon and misinformation sites to build a\nrandom forest classifier that distinguishes between misinformation and\nauthentic news sites, getting a performance of 0.98 AUC on a test set. Our\nresults demonstrate new and effective ways to study conspiracy and\nmisinformation on the Internet.""}, 'authors': [{'name': 'Hans W. A. Hanley'}, {'name': 'Deepak Kumar'}, {'name': 'Zakir Durumeric'}], 'author_detail': {'name': 'Zakir Durumeric'}, 'author': 'Zakir Durumeric', 'links': [{'href': 'http://arxiv.org/abs/2106.15715v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.15715v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
59,http://arxiv.org/abs/2106.13385v1,2021-06-25 01:49:45+00:00,2021-06-25 01:49:45+00:00,"Trends, Politics, Sentiments, and Misinformation: Understanding People's Reactions to COVID-19 During its Early Stages","[arxiv.Result.Author('Omar Abdel Wahab'), arxiv.Result.Author('Ali Mustafa'), arxiv.Result.Author('André Bertrand Abisseck Bamatakina')]","The sudden outbreak of COVID-19 resulted in large volumes of data shared on
different social media platforms. Analyzing and visualizing these data is
doubtlessly essential to having a deep understanding of the pandemic's impacts
on people's lives and their reactions to them. In this work, we conduct a
large-scale spatiotemporal data analytic study to understand peoples' reactions
to the COVID-19 pandemic during its early stages. In particular, we analyze a
JSON-based dataset that is collected from news/messages/boards/blogs in English
about COVID-19 over a period of 4 months, for a total of 5.2M posts. The data
are collected from December 2019 to March 2020 from several social media
platforms such as Facebook, LinkedIn, Pinterest, StumbleUpon and VK. Our study
aims mainly to understand which implications of COVID-19 have interested social
media users the most and how did they vary over time, the spatiotemporal
distribution of misinformation, and the public opinion toward public figures
during the pandemic. Our results can be used by many parties (e.g.,
governments, psychologists, etc.) to make more informative decisions, taking
into account the actual interests and opinions of the people.","13 pages, 6 figures",,,cs.SI,"['cs.SI', 'cs.IT', 'math.IT']","[arxiv.Result.Link('http://arxiv.org/abs/2106.13385v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.13385v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.13385v1,"{'id': 'http://arxiv.org/abs/2106.13385v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.13385v1', 'updated': '2021-06-25T01:49:45Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=25, tm_hour=1, tm_min=49, tm_sec=45, tm_wday=4, tm_yday=176, tm_isdst=0), 'published': '2021-06-25T01:49:45Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=25, tm_hour=1, tm_min=49, tm_sec=45, tm_wday=4, tm_yday=176, tm_isdst=0), 'title': ""Trends, Politics, Sentiments, and Misinformation: Understanding People's\n  Reactions to COVID-19 During its Early Stages"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Trends, Politics, Sentiments, and Misinformation: Understanding People's\n  Reactions to COVID-19 During its Early Stages""}, 'summary': ""The sudden outbreak of COVID-19 resulted in large volumes of data shared on\ndifferent social media platforms. Analyzing and visualizing these data is\ndoubtlessly essential to having a deep understanding of the pandemic's impacts\non people's lives and their reactions to them. In this work, we conduct a\nlarge-scale spatiotemporal data analytic study to understand peoples' reactions\nto the COVID-19 pandemic during its early stages. In particular, we analyze a\nJSON-based dataset that is collected from news/messages/boards/blogs in English\nabout COVID-19 over a period of 4 months, for a total of 5.2M posts. The data\nare collected from December 2019 to March 2020 from several social media\nplatforms such as Facebook, LinkedIn, Pinterest, StumbleUpon and VK. Our study\naims mainly to understand which implications of COVID-19 have interested social\nmedia users the most and how did they vary over time, the spatiotemporal\ndistribution of misinformation, and the public opinion toward public figures\nduring the pandemic. Our results can be used by many parties (e.g.,\ngovernments, psychologists, etc.) to make more informative decisions, taking\ninto account the actual interests and opinions of the people."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The sudden outbreak of COVID-19 resulted in large volumes of data shared on\ndifferent social media platforms. Analyzing and visualizing these data is\ndoubtlessly essential to having a deep understanding of the pandemic's impacts\non people's lives and their reactions to them. In this work, we conduct a\nlarge-scale spatiotemporal data analytic study to understand peoples' reactions\nto the COVID-19 pandemic during its early stages. In particular, we analyze a\nJSON-based dataset that is collected from news/messages/boards/blogs in English\nabout COVID-19 over a period of 4 months, for a total of 5.2M posts. The data\nare collected from December 2019 to March 2020 from several social media\nplatforms such as Facebook, LinkedIn, Pinterest, StumbleUpon and VK. Our study\naims mainly to understand which implications of COVID-19 have interested social\nmedia users the most and how did they vary over time, the spatiotemporal\ndistribution of misinformation, and the public opinion toward public figures\nduring the pandemic. Our results can be used by many parties (e.g.,\ngovernments, psychologists, etc.) to make more informative decisions, taking\ninto account the actual interests and opinions of the people.""}, 'authors': [{'name': 'Omar Abdel Wahab'}, {'name': 'Ali Mustafa'}, {'name': 'André Bertrand Abisseck Bamatakina'}], 'author_detail': {'name': 'André Bertrand Abisseck Bamatakina'}, 'author': 'André Bertrand Abisseck Bamatakina', 'arxiv_comment': '13 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2106.13385v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.13385v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
60,http://arxiv.org/abs/2106.11702v4,2021-07-08 08:39:43+00:00,2021-06-22 12:17:53+00:00,Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study of COVID-19 Infodemic,"[arxiv.Result.Author('Ye Jiang'), arxiv.Result.Author('Xingyi Song'), arxiv.Result.Author('Carolina Scarton'), arxiv.Result.Author('Ahmet Aker'), arxiv.Result.Author('Kalina Bontcheva')]","The spreading COVID-19 misinformation over social media already draws the
attention of many researchers. According to Google Scholar, about 26000
COVID-19 related misinformation studies have been published to date. Most of
these studies focusing on 1) detect and/or 2) analysing the characteristics of
COVID-19 related misinformation. However, the study of the social behaviours
related to misinformation is often neglected. In this paper, we introduce a
fine-grained annotated misinformation tweets dataset including social
behaviours annotation (e.g. comment or question to the misinformation). The
dataset not only allows social behaviours analysis but also suitable for both
evidence-based or non-evidence-based misinformation classification task. In
addition, we introduce leave claim out validation in our experiments and
demonstrate the misinformation classification performance could be
significantly different when applying to real-world unseen misinformation.",,,,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2106.11702v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.11702v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.11702v4,"{'id': 'http://arxiv.org/abs/2106.11702v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.11702v4', 'updated': '2021-07-08T08:39:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=8, tm_hour=8, tm_min=39, tm_sec=43, tm_wday=3, tm_yday=189, tm_isdst=0), 'published': '2021-06-22T12:17:53Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=12, tm_min=17, tm_sec=53, tm_wday=1, tm_yday=173, tm_isdst=0), 'title': 'Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study\n  of COVID-19 Infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study\n  of COVID-19 Infodemic'}, 'summary': 'The spreading COVID-19 misinformation over social media already draws the\nattention of many researchers. According to Google Scholar, about 26000\nCOVID-19 related misinformation studies have been published to date. Most of\nthese studies focusing on 1) detect and/or 2) analysing the characteristics of\nCOVID-19 related misinformation. However, the study of the social behaviours\nrelated to misinformation is often neglected. In this paper, we introduce a\nfine-grained annotated misinformation tweets dataset including social\nbehaviours annotation (e.g. comment or question to the misinformation). The\ndataset not only allows social behaviours analysis but also suitable for both\nevidence-based or non-evidence-based misinformation classification task. In\naddition, we introduce leave claim out validation in our experiments and\ndemonstrate the misinformation classification performance could be\nsignificantly different when applying to real-world unseen misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spreading COVID-19 misinformation over social media already draws the\nattention of many researchers. According to Google Scholar, about 26000\nCOVID-19 related misinformation studies have been published to date. Most of\nthese studies focusing on 1) detect and/or 2) analysing the characteristics of\nCOVID-19 related misinformation. However, the study of the social behaviours\nrelated to misinformation is often neglected. In this paper, we introduce a\nfine-grained annotated misinformation tweets dataset including social\nbehaviours annotation (e.g. comment or question to the misinformation). The\ndataset not only allows social behaviours analysis but also suitable for both\nevidence-based or non-evidence-based misinformation classification task. In\naddition, we introduce leave claim out validation in our experiments and\ndemonstrate the misinformation classification performance could be\nsignificantly different when applying to real-world unseen misinformation.'}, 'authors': [{'name': 'Ye Jiang'}, {'name': 'Xingyi Song'}, {'name': 'Carolina Scarton'}, {'name': 'Ahmet Aker'}, {'name': 'Kalina Bontcheva'}], 'author_detail': {'name': 'Kalina Bontcheva'}, 'author': 'Kalina Bontcheva', 'links': [{'href': 'http://arxiv.org/abs/2106.11702v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11702v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
61,http://arxiv.org/abs/2106.11227v1,2021-06-21 16:13:44+00:00,2021-06-21 16:13:44+00:00,FauxWard: A Graph Neural Network Approach to Fauxtography Detection Using Social Media Comments,"[arxiv.Result.Author('Lanyu Shang'), arxiv.Result.Author('Yang Zhang'), arxiv.Result.Author('Daniel Zhang'), arxiv.Result.Author('Dong Wang')]","Online social media has been a popular source for people to consume and share
news content. More recently, the spread of misinformation online has caused
widespread concerns. In this work, we focus on a critical task of detecting
fauxtography on social media where the image and associated text together
convey misleading information. Many efforts have been made to mitigate
misinformation online, but we found that the fauxtography problem has not been
fully addressed by existing work. Solutions focusing on detecting fake images
or misinformed texts alone on social media often fail to identify the
misinformation delivered together by the image and the associated text of a
fauxtography post. In this paper, we develop FauxWard, a novel graph
convolutional neural network framework that explicitly explores the complex
information extracted from a user comment network of a social media post to
effectively identify fauxtography. FauxWard is content-free in the sense that
it does not analyze the visual or textual contents of the post itself, which
makes it robust against sophisticated fauxtography uploaders who intentionally
craft image-centric posts by editing either the text or image content. We
evaluate FauxWard on two real-world datasets collected from mainstream social
media platforms (i.e., Reddit and Twitter). The results show that FauxWard is
both effective and efficient in identifying fauxtography posts on social media.",,"Soc. Netw. Anal. Min. 10, 76 (2020)",10.1007/s13278-020-00689-w,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/s13278-020-00689-w', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2106.11227v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.11227v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.11227v1,"{'id': 'http://arxiv.org/abs/2106.11227v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.11227v1', 'updated': '2021-06-21T16:13:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=16, tm_min=13, tm_sec=44, tm_wday=0, tm_yday=172, tm_isdst=0), 'published': '2021-06-21T16:13:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=16, tm_min=13, tm_sec=44, tm_wday=0, tm_yday=172, tm_isdst=0), 'title': 'FauxWard: A Graph Neural Network Approach to Fauxtography Detection\n  Using Social Media Comments', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FauxWard: A Graph Neural Network Approach to Fauxtography Detection\n  Using Social Media Comments'}, 'summary': 'Online social media has been a popular source for people to consume and share\nnews content. More recently, the spread of misinformation online has caused\nwidespread concerns. In this work, we focus on a critical task of detecting\nfauxtography on social media where the image and associated text together\nconvey misleading information. Many efforts have been made to mitigate\nmisinformation online, but we found that the fauxtography problem has not been\nfully addressed by existing work. Solutions focusing on detecting fake images\nor misinformed texts alone on social media often fail to identify the\nmisinformation delivered together by the image and the associated text of a\nfauxtography post. In this paper, we develop FauxWard, a novel graph\nconvolutional neural network framework that explicitly explores the complex\ninformation extracted from a user comment network of a social media post to\neffectively identify fauxtography. FauxWard is content-free in the sense that\nit does not analyze the visual or textual contents of the post itself, which\nmakes it robust against sophisticated fauxtography uploaders who intentionally\ncraft image-centric posts by editing either the text or image content. We\nevaluate FauxWard on two real-world datasets collected from mainstream social\nmedia platforms (i.e., Reddit and Twitter). The results show that FauxWard is\nboth effective and efficient in identifying fauxtography posts on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online social media has been a popular source for people to consume and share\nnews content. More recently, the spread of misinformation online has caused\nwidespread concerns. In this work, we focus on a critical task of detecting\nfauxtography on social media where the image and associated text together\nconvey misleading information. Many efforts have been made to mitigate\nmisinformation online, but we found that the fauxtography problem has not been\nfully addressed by existing work. Solutions focusing on detecting fake images\nor misinformed texts alone on social media often fail to identify the\nmisinformation delivered together by the image and the associated text of a\nfauxtography post. In this paper, we develop FauxWard, a novel graph\nconvolutional neural network framework that explicitly explores the complex\ninformation extracted from a user comment network of a social media post to\neffectively identify fauxtography. FauxWard is content-free in the sense that\nit does not analyze the visual or textual contents of the post itself, which\nmakes it robust against sophisticated fauxtography uploaders who intentionally\ncraft image-centric posts by editing either the text or image content. We\nevaluate FauxWard on two real-world datasets collected from mainstream social\nmedia platforms (i.e., Reddit and Twitter). The results show that FauxWard is\nboth effective and efficient in identifying fauxtography posts on social media.'}, 'authors': [{'name': 'Lanyu Shang'}, {'name': 'Yang Zhang'}, {'name': 'Daniel Zhang'}, {'name': 'Dong Wang'}], 'author_detail': {'name': 'Dong Wang'}, 'author': 'Dong Wang', 'arxiv_doi': '10.1007/s13278-020-00689-w', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s13278-020-00689-w', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2106.11227v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11227v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Soc. Netw. Anal. Min. 10, 76 (2020)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
62,http://arxiv.org/abs/2106.09672v2,2021-07-01 20:58:36+00:00,2021-06-17 17:23:59+00:00,The 2021 Image Similarity Dataset and Challenge,"[arxiv.Result.Author('Matthijs Douze'), arxiv.Result.Author('Giorgos Tolias'), arxiv.Result.Author('Ed Pizzi'), arxiv.Result.Author('Zoë Papakipos'), arxiv.Result.Author('Lowik Chanussot'), arxiv.Result.Author('Filip Radenovic'), arxiv.Result.Author('Tomas Jenicek'), arxiv.Result.Author('Maxim Maximov'), arxiv.Result.Author('Laura Leal-Taixé'), arxiv.Result.Author('Ismail Elezi'), arxiv.Result.Author('Ondřej Chum'), arxiv.Result.Author('Cristian Canton Ferrer')]","This paper introduces a new benchmark for large-scale image similarity
detection. This benchmark is used for the Image Similarity Challenge at
NeurIPS'21 (ISC2021). The goal is to determine whether a query image is a
modified copy of any image in a reference corpus of size 1~million. The
benchmark features a variety of image transformations such as automated
transformations, hand-crafted image edits and machine-learning based
manipulations. This mimics real-life cases appearing in social media, for
example for integrity-related problems dealing with misinformation and
objectionable content. The strength of the image manipulations, and therefore
the difficulty of the benchmark, is calibrated according to the performance of
a set of baseline approaches. Both the query and reference set contain a
majority of ""distractor"" images that do not match, which corresponds to a
real-life needle-in-haystack setting, and the evaluation metric reflects that.
We expect the DISC21 benchmark to promote image copy detection as an important
and challenging computer vision task and refresh the state of the art.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.09672v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.09672v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.09672v2,"{'id': 'http://arxiv.org/abs/2106.09672v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.09672v2', 'updated': '2021-07-01T20:58:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=1, tm_hour=20, tm_min=58, tm_sec=36, tm_wday=3, tm_yday=182, tm_isdst=0), 'published': '2021-06-17T17:23:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=17, tm_min=23, tm_sec=59, tm_wday=3, tm_yday=168, tm_isdst=0), 'title': 'The 2021 Image Similarity Dataset and Challenge', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The 2021 Image Similarity Dataset and Challenge'}, 'summary': 'This paper introduces a new benchmark for large-scale image similarity\ndetection. This benchmark is used for the Image Similarity Challenge at\nNeurIPS\'21 (ISC2021). The goal is to determine whether a query image is a\nmodified copy of any image in a reference corpus of size 1~million. The\nbenchmark features a variety of image transformations such as automated\ntransformations, hand-crafted image edits and machine-learning based\nmanipulations. This mimics real-life cases appearing in social media, for\nexample for integrity-related problems dealing with misinformation and\nobjectionable content. The strength of the image manipulations, and therefore\nthe difficulty of the benchmark, is calibrated according to the performance of\na set of baseline approaches. Both the query and reference set contain a\nmajority of ""distractor"" images that do not match, which corresponds to a\nreal-life needle-in-haystack setting, and the evaluation metric reflects that.\nWe expect the DISC21 benchmark to promote image copy detection as an important\nand challenging computer vision task and refresh the state of the art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper introduces a new benchmark for large-scale image similarity\ndetection. This benchmark is used for the Image Similarity Challenge at\nNeurIPS\'21 (ISC2021). The goal is to determine whether a query image is a\nmodified copy of any image in a reference corpus of size 1~million. The\nbenchmark features a variety of image transformations such as automated\ntransformations, hand-crafted image edits and machine-learning based\nmanipulations. This mimics real-life cases appearing in social media, for\nexample for integrity-related problems dealing with misinformation and\nobjectionable content. The strength of the image manipulations, and therefore\nthe difficulty of the benchmark, is calibrated according to the performance of\na set of baseline approaches. Both the query and reference set contain a\nmajority of ""distractor"" images that do not match, which corresponds to a\nreal-life needle-in-haystack setting, and the evaluation metric reflects that.\nWe expect the DISC21 benchmark to promote image copy detection as an important\nand challenging computer vision task and refresh the state of the art.'}, 'authors': [{'name': 'Matthijs Douze'}, {'name': 'Giorgos Tolias'}, {'name': 'Ed Pizzi'}, {'name': 'Zoë Papakipos'}, {'name': 'Lowik Chanussot'}, {'name': 'Filip Radenovic'}, {'name': 'Tomas Jenicek'}, {'name': 'Maxim Maximov'}, {'name': 'Laura Leal-Taixé'}, {'name': 'Ismail Elezi'}, {'name': 'Ondřej Chum'}, {'name': 'Cristian Canton Ferrer'}], 'author_detail': {'name': 'Cristian Canton Ferrer'}, 'author': 'Cristian Canton Ferrer', 'links': [{'href': 'http://arxiv.org/abs/2106.09672v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09672v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
63,http://arxiv.org/abs/2106.09338v2,2021-08-08 17:03:44+00:00,2021-06-17 09:19:45+00:00,Investigating Misinformation Dissemination on Social Media in Pakistan,"[arxiv.Result.Author('Danyal Haroon'), arxiv.Result.Author('Hammad Arif'), arxiv.Result.Author('Ahmed Abdullah Tariq'), arxiv.Result.Author('fareeda nawaz'), arxiv.Result.Author('Dr. Ihsan Ayyub Qazi'), arxiv.Result.Author('Dr. Maryam mustafa')]","Fake news and misinformation are one of the most significant challenges
brought about by advances in communication technologies. We chose to research
the spread of fake news in Pakistan because of some unfortunate incidents that
took place during 2020. These included the downplaying of the severity of the
COVID-19 pandemic, and protests by right-wing political movements. We observed
that fake news and misinformation contributed significantly to these events and
especially affected low-literate and low-income populations. We conducted a
cross-platform comparison of misinformation on WhatsApp, Twitter and YouTube
with a primary focus on messages shared in public WhatsApp groups, and analysed
the characteristics of misinformation, techniques used to make is believable,
and how users respond to it. To the best of our knowledge, this is the first
attempt to compare misinformation on all three platforms in Pakistan. Data
collected over a span of eight months helped us identify fake news and
misinformation related to politics, religion and health, among other
categories. Common elements which were used by fake news creators in Pakistan
to make false content seem believable included: appeals to emotion, conspiracy
theories, political and religious polarization, incorrect facts and
impersonation of credible sources.",i want to further work on it,,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.09338v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.09338v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.09338v2,"{'id': 'http://arxiv.org/abs/2106.09338v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.09338v2', 'updated': '2021-08-08T17:03:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=8, tm_hour=17, tm_min=3, tm_sec=44, tm_wday=6, tm_yday=220, tm_isdst=0), 'published': '2021-06-17T09:19:45Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=9, tm_min=19, tm_sec=45, tm_wday=3, tm_yday=168, tm_isdst=0), 'title': 'Investigating Misinformation Dissemination on Social Media in Pakistan', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Misinformation Dissemination on Social Media in Pakistan'}, 'summary': 'Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.'}, 'authors': [{'name': 'Danyal Haroon'}, {'name': 'Hammad Arif'}, {'name': 'Ahmed Abdullah Tariq'}, {'name': 'fareeda nawaz'}, {'name': 'Dr. Ihsan Ayyub Qazi'}, {'name': 'Dr. Maryam mustafa'}], 'author_detail': {'name': 'Dr. Maryam mustafa'}, 'author': 'Dr. Maryam mustafa', 'arxiv_comment': 'i want to further work on it', 'links': [{'href': 'http://arxiv.org/abs/2106.09338v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09338v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
64,http://arxiv.org/abs/2106.08423v1,2021-06-15 20:32:10+00:00,2021-06-15 20:32:10+00:00,COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine Hesitancy on Twitter,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Yizhou Zhang'), arxiv.Result.Author('Yan Liu')]","Vaccine hesitancy and misinformation on social media has increased concerns
about COVID-19 vaccine uptake required to achieve herd immunity and overcome
the pandemic. However anti-science and political misinformation and
conspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,
we investigate misinformation and conspiracy campaigns and their characteristic
behaviours. We identify whether coordinated efforts are used to promote
misinformation in vaccine related discussions, and find accounts coordinately
promoting a `Great Reset' conspiracy group promoting vaccine related
misinformation and strong anti-vaccine and anti-social messages such as boycott
vaccine passports, no lock-downs and masks. We characterize other
misinformation communities from the information diffusion structure, and study
the large anti-vaccine misinformation community and smaller anti-vaccine
communities, including a far-right anti-vaccine conspiracy group. In comparison
with the mainstream and health news, left-leaning group, which are more
pro-vaccine, the right-leaning group is influenced more by the anti-vaccine and
far-right misinformation/conspiracy communities. The misinformation communities
are more vocal either specific to the vaccine discussion or political
discussion, and we find other differences in the characteristic behaviours of
different communities. Lastly, we investigate misinformation narratives and
tactics of information distortion that can increase vaccine hesitancy, using
topic modeling and comparison with reported vaccine side-effects (VAERS)
finding rarer side-effects are more frequently discussed on social media.",,,,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2106.08423v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.08423v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.08423v1,"{'id': 'http://arxiv.org/abs/2106.08423v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.08423v1', 'updated': '2021-06-15T20:32:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=20, tm_min=32, tm_sec=10, tm_wday=1, tm_yday=166, tm_isdst=0), 'published': '2021-06-15T20:32:10Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=20, tm_min=32, tm_sec=10, tm_wday=1, tm_yday=166, tm_isdst=0), 'title': 'COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine\n  Hesitancy on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine\n  Hesitancy on Twitter'}, 'summary': ""Vaccine hesitancy and misinformation on social media has increased concerns\nabout COVID-19 vaccine uptake required to achieve herd immunity and overcome\nthe pandemic. However anti-science and political misinformation and\nconspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,\nwe investigate misinformation and conspiracy campaigns and their characteristic\nbehaviours. We identify whether coordinated efforts are used to promote\nmisinformation in vaccine related discussions, and find accounts coordinately\npromoting a `Great Reset' conspiracy group promoting vaccine related\nmisinformation and strong anti-vaccine and anti-social messages such as boycott\nvaccine passports, no lock-downs and masks. We characterize other\nmisinformation communities from the information diffusion structure, and study\nthe large anti-vaccine misinformation community and smaller anti-vaccine\ncommunities, including a far-right anti-vaccine conspiracy group. In comparison\nwith the mainstream and health news, left-leaning group, which are more\npro-vaccine, the right-leaning group is influenced more by the anti-vaccine and\nfar-right misinformation/conspiracy communities. The misinformation communities\nare more vocal either specific to the vaccine discussion or political\ndiscussion, and we find other differences in the characteristic behaviours of\ndifferent communities. Lastly, we investigate misinformation narratives and\ntactics of information distortion that can increase vaccine hesitancy, using\ntopic modeling and comparison with reported vaccine side-effects (VAERS)\nfinding rarer side-effects are more frequently discussed on social media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Vaccine hesitancy and misinformation on social media has increased concerns\nabout COVID-19 vaccine uptake required to achieve herd immunity and overcome\nthe pandemic. However anti-science and political misinformation and\nconspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,\nwe investigate misinformation and conspiracy campaigns and their characteristic\nbehaviours. We identify whether coordinated efforts are used to promote\nmisinformation in vaccine related discussions, and find accounts coordinately\npromoting a `Great Reset' conspiracy group promoting vaccine related\nmisinformation and strong anti-vaccine and anti-social messages such as boycott\nvaccine passports, no lock-downs and masks. We characterize other\nmisinformation communities from the information diffusion structure, and study\nthe large anti-vaccine misinformation community and smaller anti-vaccine\ncommunities, including a far-right anti-vaccine conspiracy group. In comparison\nwith the mainstream and health news, left-leaning group, which are more\npro-vaccine, the right-leaning group is influenced more by the anti-vaccine and\nfar-right misinformation/conspiracy communities. The misinformation communities\nare more vocal either specific to the vaccine discussion or political\ndiscussion, and we find other differences in the characteristic behaviours of\ndifferent communities. Lastly, we investigate misinformation narratives and\ntactics of information distortion that can increase vaccine hesitancy, using\ntopic modeling and comparison with reported vaccine side-effects (VAERS)\nfinding rarer side-effects are more frequently discussed on social media.""}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Yizhou Zhang'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'links': [{'href': 'http://arxiv.org/abs/2106.08423v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08423v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
65,http://arxiv.org/abs/2106.07435v1,2021-06-14 13:56:26+00:00,2021-06-14 13:56:26+00:00,Both Rates of Fake News and Fact-based News on Twitter Negatively Correlate with the State-level COVID-19 Vaccine Uptake,"[arxiv.Result.Author('Hanjia Lyu'), arxiv.Result.Author('Zihe Zheng'), arxiv.Result.Author('Jiebo Luo')]","There is evidence of misinformation in the online discourses and discussions
about the COVID-19 vaccines. Using a sample of 1.6 million geotagged English
tweets and the data from the CDC COVID Data Tracker, we conduct a quantitative
study to understand the influence of both misinformation and fact-based news on
Twitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.
adults were vaccine eligible to May 7, 2021, after controlling state-level
factors such as demographics, education, and the pandemic severity. We identify
the tweets related to either misinformation or fact-based news by analyzing the
URLs. By analyzing the content of the most frequent tweets of these two groups,
we find that their structures are similar, making it difficult for Twitter
users to distinguish one from another by reading the text alone. The users who
spread both fake news and fact-based news tend to show a negative attitude
towards the vaccines. We further conduct the Fama-MacBeth regression with the
Newey-West adjustment to examine the effect of fake-news-related and
fact-related tweets on the vaccination rate, and find marginally negative
correlations.",6 pages,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.07435v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.07435v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.07435v1,"{'id': 'http://arxiv.org/abs/2106.07435v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.07435v1', 'updated': '2021-06-14T13:56:26Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=14, tm_hour=13, tm_min=56, tm_sec=26, tm_wday=0, tm_yday=165, tm_isdst=0), 'published': '2021-06-14T13:56:26Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=14, tm_hour=13, tm_min=56, tm_sec=26, tm_wday=0, tm_yday=165, tm_isdst=0), 'title': 'Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake'}, 'summary': 'There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.'}, 'authors': [{'name': 'Hanjia Lyu'}, {'name': 'Zihe Zheng'}, {'name': 'Jiebo Luo'}], 'author_detail': {'name': 'Jiebo Luo'}, 'author': 'Jiebo Luo', 'arxiv_comment': '6 pages', 'links': [{'href': 'http://arxiv.org/abs/2106.07435v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.07435v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
66,http://arxiv.org/abs/2106.06811v1,2021-06-12 16:26:04+00:00,2021-06-12 16:26:04+00:00,Case Study on Detecting COVID-19 Health-Related Misinformation in Social Media,"[arxiv.Result.Author('Mir Mehedi A. Pritom'), arxiv.Result.Author('Rosana Montanez Rodriguez'), arxiv.Result.Author('Asad Ali Khan'), arxiv.Result.Author('Sebastian A. Nugroho'), arxiv.Result.Author(""Esra'a Alrashydah""), arxiv.Result.Author('Beatrice N. Ruiz'), arxiv.Result.Author('Anthony Rios')]","COVID-19 pandemic has generated what public health officials called an
infodemic of misinformation. As social distancing and stay-at-home orders came
into effect, many turned to social media for socializing. This increase in
social media usage has made it a prime vehicle for the spreading of
misinformation. This paper presents a mechanism to detect COVID-19
health-related misinformation in social media following an interdisciplinary
approach. Leveraging social psychology as a foundation and existing
misinformation frameworks, we defined misinformation themes and associated
keywords incorporated into the misinformation detection mechanism using applied
machine learning techniques. Next, using the Twitter dataset, we explored the
performance of the proposed methodology using multiple state-of-the-art machine
learning classifiers. Our method shows promising results with at most 78%
accuracy in classifying health-related misinformation versus true information
using uni-gram-based NLP feature generations from tweets and the Decision Tree
classifier. We also provide suggestions on alternatives for countering
misinformation and ethical consideration for the study.",10 pages,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2106.06811v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.06811v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.06811v1,"{'id': 'http://arxiv.org/abs/2106.06811v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.06811v1', 'updated': '2021-06-12T16:26:04Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=12, tm_hour=16, tm_min=26, tm_sec=4, tm_wday=5, tm_yday=163, tm_isdst=0), 'published': '2021-06-12T16:26:04Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=12, tm_hour=16, tm_min=26, tm_sec=4, tm_wday=5, tm_yday=163, tm_isdst=0), 'title': 'Case Study on Detecting COVID-19 Health-Related Misinformation in Social\n  Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Case Study on Detecting COVID-19 Health-Related Misinformation in Social\n  Media'}, 'summary': 'COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.'}, 'authors': [{'name': 'Mir Mehedi A. Pritom'}, {'name': 'Rosana Montanez Rodriguez'}, {'name': 'Asad Ali Khan'}, {'name': 'Sebastian A. Nugroho'}, {'name': ""Esra'a Alrashydah""}, {'name': 'Beatrice N. Ruiz'}, {'name': 'Anthony Rios'}], 'author_detail': {'name': 'Anthony Rios'}, 'author': 'Anthony Rios', 'arxiv_comment': '10 pages', 'links': [{'href': 'http://arxiv.org/abs/2106.06811v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.06811v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
67,http://arxiv.org/abs/2106.05815v1,2021-06-10 15:30:42+00:00,2021-06-10 15:30:42+00:00,Italian Twitter semantic network during the Covid-19 epidemic,"[arxiv.Result.Author('Mattia Mattei'), arxiv.Result.Author('Guido Caldarelli'), arxiv.Result.Author('Tiziano Squartini'), arxiv.Result.Author('Fabio Saracco')]","The Covid-19 pandemic has had a deep impact on the lives of the entire world
population, inducing a participated societal debate. As in other contexts, the
debate has been the subject of several d/misinformation campaigns; in a quite
unprecedented fashion, however, the presence of false information has seriously
put at risk the public health. In this sense, detecting the presence of
malicious narratives and identifying the kinds of users that are more prone to
spread them represent the first step to limit the persistence of the former
ones. In the present paper we analyse the semantic network observed on Twitter
during the first Italian lockdown (induced by the hashtags contained in
approximately 1.5 millions tweets published between the 23rd of March 2020 and
the 23rd of April 2020) and study the extent to which various discursive
communities are exposed to d/misinformation arguments. As observed in other
studies, the recovered discursive communities largely overlap with traditional
political parties, even if the debated topics concern different facets of the
management of the pandemic. Although the themes directly related to
d/misinformation are a minority of those discussed within our semantic
networks, their popularity is unevenly distributed among the various discursive
communities.","29 pages, 11 figures",,,cs.SI,"['cs.SI', 'physics.data-an']","[arxiv.Result.Link('http://arxiv.org/abs/2106.05815v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.05815v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.05815v1,"{'id': 'http://arxiv.org/abs/2106.05815v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.05815v1', 'updated': '2021-06-10T15:30:42Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=10, tm_hour=15, tm_min=30, tm_sec=42, tm_wday=3, tm_yday=161, tm_isdst=0), 'published': '2021-06-10T15:30:42Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=10, tm_hour=15, tm_min=30, tm_sec=42, tm_wday=3, tm_yday=161, tm_isdst=0), 'title': 'Italian Twitter semantic network during the Covid-19 epidemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Italian Twitter semantic network during the Covid-19 epidemic'}, 'summary': 'The Covid-19 pandemic has had a deep impact on the lives of the entire world\npopulation, inducing a participated societal debate. As in other contexts, the\ndebate has been the subject of several d/misinformation campaigns; in a quite\nunprecedented fashion, however, the presence of false information has seriously\nput at risk the public health. In this sense, detecting the presence of\nmalicious narratives and identifying the kinds of users that are more prone to\nspread them represent the first step to limit the persistence of the former\nones. In the present paper we analyse the semantic network observed on Twitter\nduring the first Italian lockdown (induced by the hashtags contained in\napproximately 1.5 millions tweets published between the 23rd of March 2020 and\nthe 23rd of April 2020) and study the extent to which various discursive\ncommunities are exposed to d/misinformation arguments. As observed in other\nstudies, the recovered discursive communities largely overlap with traditional\npolitical parties, even if the debated topics concern different facets of the\nmanagement of the pandemic. Although the themes directly related to\nd/misinformation are a minority of those discussed within our semantic\nnetworks, their popularity is unevenly distributed among the various discursive\ncommunities.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Covid-19 pandemic has had a deep impact on the lives of the entire world\npopulation, inducing a participated societal debate. As in other contexts, the\ndebate has been the subject of several d/misinformation campaigns; in a quite\nunprecedented fashion, however, the presence of false information has seriously\nput at risk the public health. In this sense, detecting the presence of\nmalicious narratives and identifying the kinds of users that are more prone to\nspread them represent the first step to limit the persistence of the former\nones. In the present paper we analyse the semantic network observed on Twitter\nduring the first Italian lockdown (induced by the hashtags contained in\napproximately 1.5 millions tweets published between the 23rd of March 2020 and\nthe 23rd of April 2020) and study the extent to which various discursive\ncommunities are exposed to d/misinformation arguments. As observed in other\nstudies, the recovered discursive communities largely overlap with traditional\npolitical parties, even if the debated topics concern different facets of the\nmanagement of the pandemic. Although the themes directly related to\nd/misinformation are a minority of those discussed within our semantic\nnetworks, their popularity is unevenly distributed among the various discursive\ncommunities.'}, 'authors': [{'name': 'Mattia Mattei'}, {'name': 'Guido Caldarelli'}, {'name': 'Tiziano Squartini'}, {'name': 'Fabio Saracco'}], 'author_detail': {'name': 'Fabio Saracco'}, 'author': 'Fabio Saracco', 'arxiv_comment': '29 pages, 11 figures', 'links': [{'href': 'http://arxiv.org/abs/2106.05815v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.05815v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
68,http://arxiv.org/abs/2106.05707v3,2021-10-12 09:41:34+00:00,2021-06-10 12:47:36+00:00,FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information,"[arxiv.Result.Author('Rami Aly'), arxiv.Result.Author('Zhijiang Guo'), arxiv.Result.Author('Michael Schlichtkrull'), arxiv.Result.Author('James Thorne'), arxiv.Result.Author('Andreas Vlachos'), arxiv.Result.Author('Christos Christodoulopoulos'), arxiv.Result.Author('Oana Cocarascu'), arxiv.Result.Author('Arpit Mittal')]","Fact verification has attracted a lot of attention in the machine learning
and natural language processing communities, as it is one of the key methods
for detecting misinformation. Existing large-scale benchmarks for this task
have focused mostly on textual sources, i.e. unstructured information, and thus
ignored the wealth of information available in structured formats, such as
tables. In this paper we introduce a novel dataset and benchmark, Fact
Extraction and VERification Over Unstructured and Structured information
(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated
with evidence in the form of sentences and/or cells from tables in Wikipedia,
as well as a label indicating whether this evidence supports, refutes, or does
not provide enough information to reach a verdict. Furthermore, we detail our
efforts to track and minimize the biases present in the dataset and could be
exploited by models, e.g. being able to predict the label without using
evidence. Finally, we develop a baseline for verifying claims against text and
tables which predicts both the correct evidence and verdict for 18% of the
claims.",Accepted at NeurIPS 2021 Datasets and Benchmarks Track,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.05707v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.05707v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.05707v3,"{'id': 'http://arxiv.org/abs/2106.05707v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.05707v3', 'updated': '2021-10-12T09:41:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=12, tm_hour=9, tm_min=41, tm_sec=34, tm_wday=1, tm_yday=285, tm_isdst=0), 'published': '2021-06-10T12:47:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=10, tm_hour=12, tm_min=47, tm_sec=36, tm_wday=3, tm_yday=161, tm_isdst=0), 'title': 'FEVEROUS: Fact Extraction and VERification Over Unstructured and\n  Structured information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FEVEROUS: Fact Extraction and VERification Over Unstructured and\n  Structured information'}, 'summary': 'Fact verification has attracted a lot of attention in the machine learning\nand natural language processing communities, as it is one of the key methods\nfor detecting misinformation. Existing large-scale benchmarks for this task\nhave focused mostly on textual sources, i.e. unstructured information, and thus\nignored the wealth of information available in structured formats, such as\ntables. In this paper we introduce a novel dataset and benchmark, Fact\nExtraction and VERification Over Unstructured and Structured information\n(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated\nwith evidence in the form of sentences and/or cells from tables in Wikipedia,\nas well as a label indicating whether this evidence supports, refutes, or does\nnot provide enough information to reach a verdict. Furthermore, we detail our\nefforts to track and minimize the biases present in the dataset and could be\nexploited by models, e.g. being able to predict the label without using\nevidence. Finally, we develop a baseline for verifying claims against text and\ntables which predicts both the correct evidence and verdict for 18% of the\nclaims.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact verification has attracted a lot of attention in the machine learning\nand natural language processing communities, as it is one of the key methods\nfor detecting misinformation. Existing large-scale benchmarks for this task\nhave focused mostly on textual sources, i.e. unstructured information, and thus\nignored the wealth of information available in structured formats, such as\ntables. In this paper we introduce a novel dataset and benchmark, Fact\nExtraction and VERification Over Unstructured and Structured information\n(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated\nwith evidence in the form of sentences and/or cells from tables in Wikipedia,\nas well as a label indicating whether this evidence supports, refutes, or does\nnot provide enough information to reach a verdict. Furthermore, we detail our\nefforts to track and minimize the biases present in the dataset and could be\nexploited by models, e.g. being able to predict the label without using\nevidence. Finally, we develop a baseline for verifying claims against text and\ntables which predicts both the correct evidence and verdict for 18% of the\nclaims.'}, 'authors': [{'name': 'Rami Aly'}, {'name': 'Zhijiang Guo'}, {'name': 'Michael Schlichtkrull'}, {'name': 'James Thorne'}, {'name': 'Andreas Vlachos'}, {'name': 'Christos Christodoulopoulos'}, {'name': 'Oana Cocarascu'}, {'name': 'Arpit Mittal'}], 'author_detail': {'name': 'Arpit Mittal'}, 'author': 'Arpit Mittal', 'arxiv_comment': 'Accepted at NeurIPS 2021 Datasets and Benchmarks Track', 'links': [{'href': 'http://arxiv.org/abs/2106.05707v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.05707v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
69,http://arxiv.org/abs/2106.05401v3,2021-08-12 04:14:15+00:00,2021-06-09 21:34:01+00:00,Mechanisms and Attributes of Echo Chambers in Social Media,"[arxiv.Result.Author('Bohan Jiang'), arxiv.Result.Author('Mansooreh Karami'), arxiv.Result.Author('Lu Cheng'), arxiv.Result.Author('Tyler Black'), arxiv.Result.Author('Huan Liu')]","Echo chambers may exclude social media users from being exposed to other
opinions, therefore, can cause rampant negative effects. Among abundant
evidence are the 2016 and 2020 US presidential elections conspiracy theories
and polarization, as well as the COVID-19 disinfodemic. To help better detect
echo chambers and mitigate its negative effects, this paper explores the
mechanisms and attributes of echo chambers in social media. In particular, we
first illustrate four primary mechanisms related to three main factors: human
psychology, social networks, and automatic systems. We then depict common
attributes of echo chambers with a focus on the diffusion of misinformation,
spreading of conspiracy theory, creation of social trends, political
polarization, and emotional contagion of users. We illustrate each mechanism
and attribute in a multi-perspective of sociology, psychology, and social
computing with recent case studies. Our analysis suggest an emerging need to
detect echo chambers and mitigate their negative effects.","10 pages, 2 figures, accepted at SBP-BRiMS 2021 (2021 International
  Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction
  and Behavior Representation in Modeling and Simulation),
  working/late-breaking paper track",,,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2106.05401v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.05401v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.05401v3,"{'id': 'http://arxiv.org/abs/2106.05401v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.05401v3', 'updated': '2021-08-12T04:14:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=12, tm_hour=4, tm_min=14, tm_sec=15, tm_wday=3, tm_yday=224, tm_isdst=0), 'published': '2021-06-09T21:34:01Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=9, tm_hour=21, tm_min=34, tm_sec=1, tm_wday=2, tm_yday=160, tm_isdst=0), 'title': 'Mechanisms and Attributes of Echo Chambers in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mechanisms and Attributes of Echo Chambers in Social Media'}, 'summary': 'Echo chambers may exclude social media users from being exposed to other\nopinions, therefore, can cause rampant negative effects. Among abundant\nevidence are the 2016 and 2020 US presidential elections conspiracy theories\nand polarization, as well as the COVID-19 disinfodemic. To help better detect\necho chambers and mitigate its negative effects, this paper explores the\nmechanisms and attributes of echo chambers in social media. In particular, we\nfirst illustrate four primary mechanisms related to three main factors: human\npsychology, social networks, and automatic systems. We then depict common\nattributes of echo chambers with a focus on the diffusion of misinformation,\nspreading of conspiracy theory, creation of social trends, political\npolarization, and emotional contagion of users. We illustrate each mechanism\nand attribute in a multi-perspective of sociology, psychology, and social\ncomputing with recent case studies. Our analysis suggest an emerging need to\ndetect echo chambers and mitigate their negative effects.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Echo chambers may exclude social media users from being exposed to other\nopinions, therefore, can cause rampant negative effects. Among abundant\nevidence are the 2016 and 2020 US presidential elections conspiracy theories\nand polarization, as well as the COVID-19 disinfodemic. To help better detect\necho chambers and mitigate its negative effects, this paper explores the\nmechanisms and attributes of echo chambers in social media. In particular, we\nfirst illustrate four primary mechanisms related to three main factors: human\npsychology, social networks, and automatic systems. We then depict common\nattributes of echo chambers with a focus on the diffusion of misinformation,\nspreading of conspiracy theory, creation of social trends, political\npolarization, and emotional contagion of users. We illustrate each mechanism\nand attribute in a multi-perspective of sociology, psychology, and social\ncomputing with recent case studies. Our analysis suggest an emerging need to\ndetect echo chambers and mitigate their negative effects.'}, 'authors': [{'name': 'Bohan Jiang'}, {'name': 'Mansooreh Karami'}, {'name': 'Lu Cheng'}, {'name': 'Tyler Black'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '10 pages, 2 figures, accepted at SBP-BRiMS 2021 (2021 International\n  Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction\n  and Behavior Representation in Modeling and Simulation),\n  working/late-breaking paper track', 'links': [{'href': 'http://arxiv.org/abs/2106.05401v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.05401v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
70,http://arxiv.org/abs/2106.03794v1,2021-06-07 16:59:46+00:00,2021-06-07 16:59:46+00:00,COVID-Fact: Fact Extraction and Verification of Real-World Claims on COVID-19 Pandemic,"[arxiv.Result.Author('Arkadiy Saakyan'), arxiv.Result.Author('Tuhin Chakrabarty'), arxiv.Result.Author('Smaranda Muresan')]","We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the
COVID-19 pandemic. The dataset contains claims, evidence for the claims, and
contradictory claims refuted by the evidence. Unlike previous approaches, we
automatically detect true claims and their source articles and then generate
counter-claims using automatic methods rather than employing human annotators.
Along with our constructed resource, we formally present the task of
identifying relevant evidence for the claims and verifying whether the evidence
refutes or supports a given claim. In addition to scientific claims, our data
contains simplified general claims from media sources, making it better suited
for detecting general misinformation regarding COVID-19. Our experiments
indicate that COVID-Fact will provide a challenging testbed for the development
of new systems and our approach will reduce the costs of building
domain-specific datasets for detecting misinformation.",ACL 2021 Camera Ready,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.03794v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.03794v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.03794v1,"{'id': 'http://arxiv.org/abs/2106.03794v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.03794v1', 'updated': '2021-06-07T16:59:46Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=7, tm_hour=16, tm_min=59, tm_sec=46, tm_wday=0, tm_yday=158, tm_isdst=0), 'published': '2021-06-07T16:59:46Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=7, tm_hour=16, tm_min=59, tm_sec=46, tm_wday=0, tm_yday=158, tm_isdst=0), 'title': 'COVID-Fact: Fact Extraction and Verification of Real-World Claims on\n  COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-Fact: Fact Extraction and Verification of Real-World Claims on\n  COVID-19 Pandemic'}, 'summary': 'We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the\nCOVID-19 pandemic. The dataset contains claims, evidence for the claims, and\ncontradictory claims refuted by the evidence. Unlike previous approaches, we\nautomatically detect true claims and their source articles and then generate\ncounter-claims using automatic methods rather than employing human annotators.\nAlong with our constructed resource, we formally present the task of\nidentifying relevant evidence for the claims and verifying whether the evidence\nrefutes or supports a given claim. In addition to scientific claims, our data\ncontains simplified general claims from media sources, making it better suited\nfor detecting general misinformation regarding COVID-19. Our experiments\nindicate that COVID-Fact will provide a challenging testbed for the development\nof new systems and our approach will reduce the costs of building\ndomain-specific datasets for detecting misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the\nCOVID-19 pandemic. The dataset contains claims, evidence for the claims, and\ncontradictory claims refuted by the evidence. Unlike previous approaches, we\nautomatically detect true claims and their source articles and then generate\ncounter-claims using automatic methods rather than employing human annotators.\nAlong with our constructed resource, we formally present the task of\nidentifying relevant evidence for the claims and verifying whether the evidence\nrefutes or supports a given claim. In addition to scientific claims, our data\ncontains simplified general claims from media sources, making it better suited\nfor detecting general misinformation regarding COVID-19. Our experiments\nindicate that COVID-Fact will provide a challenging testbed for the development\nof new systems and our approach will reduce the costs of building\ndomain-specific datasets for detecting misinformation.'}, 'authors': [{'name': 'Arkadiy Saakyan'}, {'name': 'Tuhin Chakrabarty'}, {'name': 'Smaranda Muresan'}], 'author_detail': {'name': 'Smaranda Muresan'}, 'author': 'Smaranda Muresan', 'arxiv_comment': 'ACL 2021 Camera Ready', 'links': [{'href': 'http://arxiv.org/abs/2106.03794v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.03794v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
71,http://arxiv.org/abs/2106.02607v1,2021-06-03 16:34:54+00:00,2021-06-03 16:34:54+00:00,Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation,"[arxiv.Result.Author('Anusua Trivedi'), arxiv.Result.Author('Alyssa Suhm'), arxiv.Result.Author('Prathamesh Mahankal'), arxiv.Result.Author('Subhiksha Mukuntharaj'), arxiv.Result.Author('Meghana D. Parab'), arxiv.Result.Author('Malvika Mohan'), arxiv.Result.Author('Meredith Berger'), arxiv.Result.Author('Arathi Sethumadhavan'), arxiv.Result.Author('Ashish Jaiman'), arxiv.Result.Author('Rahul Dodhia')]","The rise in online misinformation in recent years threatens democracies by
distorting authentic public discourse and causing confusion, fear, and even, in
extreme cases, violence. There is a need to understand the spread of false
content through online networks for developing interventions that disrupt
misinformation before it achieves virality. Using a Deep Bidirectional
Transformer for Language Understanding (BERT) and propagation graphs, this
study classifies and visualizes the spread of misinformation on a social media
network using publicly available Twitter data. The results confirm prior
research around user clusters and the virality of false content while improving
the precision of deep learning models for misinformation detection. The study
further demonstrates the suitability of BERT for providing a scalable model for
false information detection, which can contribute to the development of more
timely and accurate interventions to slow the spread of misinformation in
online environments.",,,,cs.SI,"['cs.SI', 'cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2106.02607v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.02607v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.02607v1,"{'id': 'http://arxiv.org/abs/2106.02607v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.02607v1', 'updated': '2021-06-03T16:34:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=16, tm_min=34, tm_sec=54, tm_wday=3, tm_yday=154, tm_isdst=0), 'published': '2021-06-03T16:34:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=16, tm_min=34, tm_sec=54, tm_wday=3, tm_yday=154, tm_isdst=0), 'title': 'Defending Democracy: Using Deep Learning to Identify and Prevent\n  Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Defending Democracy: Using Deep Learning to Identify and Prevent\n  Misinformation'}, 'summary': 'The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.'}, 'authors': [{'name': 'Anusua Trivedi'}, {'name': 'Alyssa Suhm'}, {'name': 'Prathamesh Mahankal'}, {'name': 'Subhiksha Mukuntharaj'}, {'name': 'Meghana D. Parab'}, {'name': 'Malvika Mohan'}, {'name': 'Meredith Berger'}, {'name': 'Arathi Sethumadhavan'}, {'name': 'Ashish Jaiman'}, {'name': 'Rahul Dodhia'}], 'author_detail': {'name': 'Rahul Dodhia'}, 'author': 'Rahul Dodhia', 'links': [{'href': 'http://arxiv.org/abs/2106.02607v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.02607v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
72,http://arxiv.org/abs/2106.01627v1,2021-06-03 06:56:09+00:00,2021-06-03 06:56:09+00:00,Piercing the Veil: Designs to Support Information Literacy on Social Platforms,[arxiv.Result.Author('Jan Wolff')],"In this position paper we approach problems concerning critical digital and
information literacy with ideas to provide more digestible explanations of
abstract concepts through interface design. In particular, we focus on social
media platforms where we see the possibility of counteracting the spread of
misinformation by providing users with more proficiency through our approaches.
We argue that the omnipresent trend to abstract away and hide information from
users via UI/UX design opposes their ability to self-learn. This leads us to
propose a different framework in which we unify elegant and simple interfaces
with nudges that promote a look behind the curtain. Such designs serve to
foster a deeper understanding of employed technologies and aim to increase the
critical assessment of content encountered on social platforms. Furthermore, we
consider users with an intermediary skill level to be largely ignored in
current approaches, as they are given no tools to broaden their knowledge
without consultation of expert material. The resulting stagnation is
exemplified by the tactics of misinformation campaigns, which exploit the
ensuing lack of information literacy and critical thinking. We propose an
approach to design that sufficiently emancipates users in both aspects by
promoting a look behind the abstraction of UI/UX so that an autonomous learning
process is given the chance to occur. Furthermore, we name ideas for future
research within this area that take our considerations into account.","Originally submitted to and presented at CHI'21 Workshop on
  Technologies to Support Critical Thinking in an Age of Misinformation",,,cs.HC,"['cs.HC', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2106.01627v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.01627v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.01627v1,"{'id': 'http://arxiv.org/abs/2106.01627v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.01627v1', 'updated': '2021-06-03T06:56:09Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=6, tm_min=56, tm_sec=9, tm_wday=3, tm_yday=154, tm_isdst=0), 'published': '2021-06-03T06:56:09Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=6, tm_min=56, tm_sec=9, tm_wday=3, tm_yday=154, tm_isdst=0), 'title': 'Piercing the Veil: Designs to Support Information Literacy on Social\n  Platforms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Piercing the Veil: Designs to Support Information Literacy on Social\n  Platforms'}, 'summary': 'In this position paper we approach problems concerning critical digital and\ninformation literacy with ideas to provide more digestible explanations of\nabstract concepts through interface design. In particular, we focus on social\nmedia platforms where we see the possibility of counteracting the spread of\nmisinformation by providing users with more proficiency through our approaches.\nWe argue that the omnipresent trend to abstract away and hide information from\nusers via UI/UX design opposes their ability to self-learn. This leads us to\npropose a different framework in which we unify elegant and simple interfaces\nwith nudges that promote a look behind the curtain. Such designs serve to\nfoster a deeper understanding of employed technologies and aim to increase the\ncritical assessment of content encountered on social platforms. Furthermore, we\nconsider users with an intermediary skill level to be largely ignored in\ncurrent approaches, as they are given no tools to broaden their knowledge\nwithout consultation of expert material. The resulting stagnation is\nexemplified by the tactics of misinformation campaigns, which exploit the\nensuing lack of information literacy and critical thinking. We propose an\napproach to design that sufficiently emancipates users in both aspects by\npromoting a look behind the abstraction of UI/UX so that an autonomous learning\nprocess is given the chance to occur. Furthermore, we name ideas for future\nresearch within this area that take our considerations into account.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this position paper we approach problems concerning critical digital and\ninformation literacy with ideas to provide more digestible explanations of\nabstract concepts through interface design. In particular, we focus on social\nmedia platforms where we see the possibility of counteracting the spread of\nmisinformation by providing users with more proficiency through our approaches.\nWe argue that the omnipresent trend to abstract away and hide information from\nusers via UI/UX design opposes their ability to self-learn. This leads us to\npropose a different framework in which we unify elegant and simple interfaces\nwith nudges that promote a look behind the curtain. Such designs serve to\nfoster a deeper understanding of employed technologies and aim to increase the\ncritical assessment of content encountered on social platforms. Furthermore, we\nconsider users with an intermediary skill level to be largely ignored in\ncurrent approaches, as they are given no tools to broaden their knowledge\nwithout consultation of expert material. The resulting stagnation is\nexemplified by the tactics of misinformation campaigns, which exploit the\nensuing lack of information literacy and critical thinking. We propose an\napproach to design that sufficiently emancipates users in both aspects by\npromoting a look behind the abstraction of UI/UX so that an autonomous learning\nprocess is given the chance to occur. Furthermore, we name ideas for future\nresearch within this area that take our considerations into account.'}, 'authors': [{'name': 'Jan Wolff'}], 'author_detail': {'name': 'Jan Wolff'}, 'author': 'Jan Wolff', 'arxiv_comment': ""Originally submitted to and presented at CHI'21 Workshop on\n  Technologies to Support Critical Thinking in an Age of Misinformation"", 'links': [{'href': 'http://arxiv.org/abs/2106.01627v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.01627v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
73,http://arxiv.org/abs/2106.01170v1,2021-06-02 14:10:28+00:00,2021-06-02 14:10:28+00:00,Detecting Bot-Generated Text by Characterizing Linguistic Accommodation in Human-Bot Interactions,"[arxiv.Result.Author('Paras Bhatt'), arxiv.Result.Author('Anthony Rios')]","Language generation models' democratization benefits many domains, from
answering health-related questions to enhancing education by providing
AI-driven tutoring services. However, language generation models'
democratization also makes it easier to generate human-like text at-scale for
nefarious activities, from spreading misinformation to targeting specific
groups with hate speech. Thus, it is essential to understand how people
interact with bots and develop methods to detect bot-generated text. This paper
shows that bot-generated text detection methods are more robust across datasets
and models if we use information about how people respond to it rather than
using the bot's text directly. We also analyze linguistic alignment, providing
insight into differences between human-human and human-bot conversations.","13 pages, to be published in Findings of ACL-IJCNLP 2021",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2106.01170v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.01170v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.01170v1,"{'id': 'http://arxiv.org/abs/2106.01170v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.01170v1', 'updated': '2021-06-02T14:10:28Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=2, tm_hour=14, tm_min=10, tm_sec=28, tm_wday=2, tm_yday=153, tm_isdst=0), 'published': '2021-06-02T14:10:28Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=2, tm_hour=14, tm_min=10, tm_sec=28, tm_wday=2, tm_yday=153, tm_isdst=0), 'title': 'Detecting Bot-Generated Text by Characterizing Linguistic Accommodation\n  in Human-Bot Interactions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Bot-Generated Text by Characterizing Linguistic Accommodation\n  in Human-Bot Interactions'}, 'summary': ""Language generation models' democratization benefits many domains, from\nanswering health-related questions to enhancing education by providing\nAI-driven tutoring services. However, language generation models'\ndemocratization also makes it easier to generate human-like text at-scale for\nnefarious activities, from spreading misinformation to targeting specific\ngroups with hate speech. Thus, it is essential to understand how people\ninteract with bots and develop methods to detect bot-generated text. This paper\nshows that bot-generated text detection methods are more robust across datasets\nand models if we use information about how people respond to it rather than\nusing the bot's text directly. We also analyze linguistic alignment, providing\ninsight into differences between human-human and human-bot conversations."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Language generation models' democratization benefits many domains, from\nanswering health-related questions to enhancing education by providing\nAI-driven tutoring services. However, language generation models'\ndemocratization also makes it easier to generate human-like text at-scale for\nnefarious activities, from spreading misinformation to targeting specific\ngroups with hate speech. Thus, it is essential to understand how people\ninteract with bots and develop methods to detect bot-generated text. This paper\nshows that bot-generated text detection methods are more robust across datasets\nand models if we use information about how people respond to it rather than\nusing the bot's text directly. We also analyze linguistic alignment, providing\ninsight into differences between human-human and human-bot conversations.""}, 'authors': [{'name': 'Paras Bhatt'}, {'name': 'Anthony Rios'}], 'author_detail': {'name': 'Anthony Rios'}, 'author': 'Anthony Rios', 'arxiv_comment': '13 pages, to be published in Findings of ACL-IJCNLP 2021', 'links': [{'href': 'http://arxiv.org/abs/2106.01170v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.01170v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
74,http://arxiv.org/abs/2106.00163v1,2021-06-01 01:12:44+00:00,2021-06-01 01:12:44+00:00,Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform,"[arxiv.Result.Author('Emma Pieroni'), arxiv.Result.Author('Peter Jachim'), arxiv.Result.Author('Nathaniel Jachim'), arxiv.Result.Author('Filipo Sharevski')]","This paper evaluates Parler, the controversial social media platform, from
two seemingly orthogonal perspectives: UX design perspective and data science.
UX design researchers explore how users react to the interface/content of their
social media feeds; Data science researchers analyze the misinformation flow in
these feeds to detect alternative narratives and state-sponsored disinformation
campaigns. We took a critical look into the intersection of these approaches to
understand how Parler's interface itself is conductive to the flow of
misinformation and the perception of ""free speech"" among its audience. Parler
drew widespread attention leading up to and after the 2020 U.S. elections as
the ""alternative"" place for free speech, as a reaction to other mainstream
social media platform which actively engaged in labeling misinformation with
content warnings. Because platforms like Parler are disruptive to the social
media landscape, we believe the evaluation uniquely uncovers the platform's
conductivity to the spread of misinformation.",,,,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2106.00163v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2106.00163v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2106.00163v1,"{'id': 'http://arxiv.org/abs/2106.00163v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2106.00163v1', 'updated': '2021-06-01T01:12:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=1, tm_hour=1, tm_min=12, tm_sec=44, tm_wday=1, tm_yday=152, tm_isdst=0), 'published': '2021-06-01T01:12:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=1, tm_hour=1, tm_min=12, tm_sec=44, tm_wday=1, tm_yday=152, tm_isdst=0), 'title': 'Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform'}, 'summary': 'This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler\'s interface itself is conductive to the flow of\nmisinformation and the perception of ""free speech"" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe ""alternative"" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform\'s\nconductivity to the spread of misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler\'s interface itself is conductive to the flow of\nmisinformation and the perception of ""free speech"" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe ""alternative"" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform\'s\nconductivity to the spread of misinformation.'}, 'authors': [{'name': 'Emma Pieroni'}, {'name': 'Peter Jachim'}, {'name': 'Nathaniel Jachim'}, {'name': 'Filipo Sharevski'}], 'author_detail': {'name': 'Filipo Sharevski'}, 'author': 'Filipo Sharevski', 'links': [{'href': 'http://arxiv.org/abs/2106.00163v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.00163v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
75,http://arxiv.org/abs/2105.14376v1,2021-05-29 21:22:24+00:00,2021-05-29 21:22:24+00:00,Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis,"[arxiv.Result.Author('Yang He'), arxiv.Result.Author('Ning Yu'), arxiv.Result.Author('Margret Keuper'), arxiv.Result.Author('Mario Fritz')]","The rapid advances in deep generative models over the past years have led to
highly {realistic media, known as deepfakes,} that are commonly
indistinguishable from real to human eyes. These advances make assessing the
authenticity of visual data increasingly difficult and pose a misinformation
threat to the trustworthiness of visual content in general. Although recent
work has shown strong detection accuracy of such deepfakes, the success largely
relies on identifying frequency artifacts in the generated images, which will
not yield a sustainable detection approach as generative models continue
evolving and closing the gap to real images. In order to overcome this issue,
we propose a novel fake detection that is designed to re-synthesize testing
images and extract visual cues for detection. The re-synthesis procedure is
flexible, allowing us to incorporate a series of visual tasks - we adopt
super-resolution, denoising and colorization as the re-synthesis. We
demonstrate the improved effectiveness, cross-GAN generalization, and
robustness against perturbations of our approach in a variety of detection
scenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN
datasets. Source code is available at
https://github.com/SSAW14/BeyondtheSpectrum.","To appear in IJCAI2021. Source code at
  https://github.com/SSAW14/BeyondtheSpectrum",,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/2105.14376v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.14376v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.14376v1,"{'id': 'http://arxiv.org/abs/2105.14376v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.14376v1', 'updated': '2021-05-29T21:22:24Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=29, tm_hour=21, tm_min=22, tm_sec=24, tm_wday=5, tm_yday=149, tm_isdst=0), 'published': '2021-05-29T21:22:24Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=29, tm_hour=21, tm_min=22, tm_sec=24, tm_wday=5, tm_yday=149, tm_isdst=0), 'title': 'Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis'}, 'summary': 'The rapid advances in deep generative models over the past years have led to\nhighly {realistic media, known as deepfakes,} that are commonly\nindistinguishable from real to human eyes. These advances make assessing the\nauthenticity of visual data increasingly difficult and pose a misinformation\nthreat to the trustworthiness of visual content in general. Although recent\nwork has shown strong detection accuracy of such deepfakes, the success largely\nrelies on identifying frequency artifacts in the generated images, which will\nnot yield a sustainable detection approach as generative models continue\nevolving and closing the gap to real images. In order to overcome this issue,\nwe propose a novel fake detection that is designed to re-synthesize testing\nimages and extract visual cues for detection. The re-synthesis procedure is\nflexible, allowing us to incorporate a series of visual tasks - we adopt\nsuper-resolution, denoising and colorization as the re-synthesis. We\ndemonstrate the improved effectiveness, cross-GAN generalization, and\nrobustness against perturbations of our approach in a variety of detection\nscenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN\ndatasets. Source code is available at\nhttps://github.com/SSAW14/BeyondtheSpectrum.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid advances in deep generative models over the past years have led to\nhighly {realistic media, known as deepfakes,} that are commonly\nindistinguishable from real to human eyes. These advances make assessing the\nauthenticity of visual data increasingly difficult and pose a misinformation\nthreat to the trustworthiness of visual content in general. Although recent\nwork has shown strong detection accuracy of such deepfakes, the success largely\nrelies on identifying frequency artifacts in the generated images, which will\nnot yield a sustainable detection approach as generative models continue\nevolving and closing the gap to real images. In order to overcome this issue,\nwe propose a novel fake detection that is designed to re-synthesize testing\nimages and extract visual cues for detection. The re-synthesis procedure is\nflexible, allowing us to incorporate a series of visual tasks - we adopt\nsuper-resolution, denoising and colorization as the re-synthesis. We\ndemonstrate the improved effectiveness, cross-GAN generalization, and\nrobustness against perturbations of our approach in a variety of detection\nscenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN\ndatasets. Source code is available at\nhttps://github.com/SSAW14/BeyondtheSpectrum.'}, 'authors': [{'name': 'Yang He'}, {'name': 'Ning Yu'}, {'name': 'Margret Keuper'}, {'name': 'Mario Fritz'}], 'author_detail': {'name': 'Mario Fritz'}, 'author': 'Mario Fritz', 'arxiv_comment': 'To appear in IJCAI2021. Source code at\n  https://github.com/SSAW14/BeyondtheSpectrum', 'links': [{'href': 'http://arxiv.org/abs/2105.14376v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.14376v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
76,http://arxiv.org/abs/2105.12479v2,2021-05-27 08:40:27+00:00,2021-05-26 11:28:36+00:00,Pattern Detection in the Activation Space for Identifying Synthesized Content,"[arxiv.Result.Author('Celia Cintas'), arxiv.Result.Author('Skyler Speakman'), arxiv.Result.Author('Girmaw Abebe Tadesse'), arxiv.Result.Author('Victor Akinwande'), arxiv.Result.Author('Edward McFowland III'), arxiv.Result.Author('Komminist Weldemariam')]","Generative Adversarial Networks (GANs) have recently achieved unprecedented
success in photo-realistic image synthesis from low-dimensional random noise.
The ability to synthesize high-quality content at a large scale brings
potential risks as the generated samples may lead to misinformation that can
create severe social, political, health, and business hazards. We propose
SubsetGAN to identify generated content by detecting a subset of anomalous
node-activations in the inner layers of pre-trained neural networks. These
nodes, as a group, maximize a non-parametric measure of divergence away from
the expected distribution of activations created from real data. This enable us
to identify synthesised images without prior knowledge of their distribution.
SubsetGAN efficiently scores subsets of nodes and returns the group of nodes
within the pre-trained classifier that contributed to the maximum score. The
classifier can be a general fake classifier trained over samples from multiple
sources or the discriminator network from different GANs. Our approach shows
consistently higher detection power than existing detection methods across
several state-of-the-art GANs (PGGAN, StarGAN, and CycleGAN) and over different
proportions of generated content.",The paper is under consideration at Pattern Recognition Letters,,,cs.CV,"['cs.CV', 'cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2105.12479v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.12479v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.12479v2,"{'id': 'http://arxiv.org/abs/2105.12479v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.12479v2', 'updated': '2021-05-27T08:40:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=27, tm_hour=8, tm_min=40, tm_sec=27, tm_wday=3, tm_yday=147, tm_isdst=0), 'published': '2021-05-26T11:28:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=26, tm_hour=11, tm_min=28, tm_sec=36, tm_wday=2, tm_yday=146, tm_isdst=0), 'title': 'Pattern Detection in the Activation Space for Identifying Synthesized\n  Content', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Pattern Detection in the Activation Space for Identifying Synthesized\n  Content'}, 'summary': 'Generative Adversarial Networks (GANs) have recently achieved unprecedented\nsuccess in photo-realistic image synthesis from low-dimensional random noise.\nThe ability to synthesize high-quality content at a large scale brings\npotential risks as the generated samples may lead to misinformation that can\ncreate severe social, political, health, and business hazards. We propose\nSubsetGAN to identify generated content by detecting a subset of anomalous\nnode-activations in the inner layers of pre-trained neural networks. These\nnodes, as a group, maximize a non-parametric measure of divergence away from\nthe expected distribution of activations created from real data. This enable us\nto identify synthesised images without prior knowledge of their distribution.\nSubsetGAN efficiently scores subsets of nodes and returns the group of nodes\nwithin the pre-trained classifier that contributed to the maximum score. The\nclassifier can be a general fake classifier trained over samples from multiple\nsources or the discriminator network from different GANs. Our approach shows\nconsistently higher detection power than existing detection methods across\nseveral state-of-the-art GANs (PGGAN, StarGAN, and CycleGAN) and over different\nproportions of generated content.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Generative Adversarial Networks (GANs) have recently achieved unprecedented\nsuccess in photo-realistic image synthesis from low-dimensional random noise.\nThe ability to synthesize high-quality content at a large scale brings\npotential risks as the generated samples may lead to misinformation that can\ncreate severe social, political, health, and business hazards. We propose\nSubsetGAN to identify generated content by detecting a subset of anomalous\nnode-activations in the inner layers of pre-trained neural networks. These\nnodes, as a group, maximize a non-parametric measure of divergence away from\nthe expected distribution of activations created from real data. This enable us\nto identify synthesised images without prior knowledge of their distribution.\nSubsetGAN efficiently scores subsets of nodes and returns the group of nodes\nwithin the pre-trained classifier that contributed to the maximum score. The\nclassifier can be a general fake classifier trained over samples from multiple\nsources or the discriminator network from different GANs. Our approach shows\nconsistently higher detection power than existing detection methods across\nseveral state-of-the-art GANs (PGGAN, StarGAN, and CycleGAN) and over different\nproportions of generated content.'}, 'authors': [{'name': 'Celia Cintas'}, {'name': 'Skyler Speakman'}, {'name': 'Girmaw Abebe Tadesse'}, {'name': 'Victor Akinwande'}, {'name': 'Edward McFowland III'}, {'name': 'Komminist Weldemariam'}], 'author_detail': {'name': 'Komminist Weldemariam'}, 'author': 'Komminist Weldemariam', 'arxiv_comment': 'The paper is under consideration at Pattern Recognition Letters', 'links': [{'href': 'http://arxiv.org/abs/2105.12479v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.12479v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
77,http://arxiv.org/abs/2105.10671v1,2021-05-22 09:26:13+00:00,2021-05-22 09:26:13+00:00,SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?,"[arxiv.Result.Author('Tanveer Khan'), arxiv.Result.Author('Antonis Michalas'), arxiv.Result.Author('Adnan Akhunzada')]","Social Networks' omnipresence and ease of use has revolutionized the
generation and distribution of information in today's world. However, easy
access to information does not equal an increased level of public knowledge.
Unlike traditional media channels, social networks also facilitate faster and
wider spread of disinformation and misinformation. Viral spread of false
information has serious implications on the behaviors, attitudes and beliefs of
the public, and ultimately can seriously endanger the democratic processes.
Limiting false information's negative impact through early detection and
control of extensive spread presents the main challenge facing researchers
today. In this survey paper, we extensively analyze a wide range of different
solutions for the early detection of fake news in the existing literature. More
precisely, we examine Machine Learning (ML) models for the identification and
classification of fake news, online fake news detection competitions,
statistical outputs as well as the advantages and disadvantages of some of the
available data sets. Finally, we evaluate the online web browsing tools
available for detecting and mitigating fake news and present some open research
challenges.","34 pages, 3 figures",,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2105.10671v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.10671v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.10671v1,"{'id': 'http://arxiv.org/abs/2105.10671v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.10671v1', 'updated': '2021-05-22T09:26:13Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=9, tm_min=26, tm_sec=13, tm_wday=5, tm_yday=142, tm_isdst=0), 'published': '2021-05-22T09:26:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=9, tm_min=26, tm_sec=13, tm_wday=5, tm_yday=142, tm_isdst=0), 'title': 'SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?'}, 'summary': ""Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.""}, 'authors': [{'name': 'Tanveer Khan'}, {'name': 'Antonis Michalas'}, {'name': 'Adnan Akhunzada'}], 'author_detail': {'name': 'Adnan Akhunzada'}, 'author': 'Adnan Akhunzada', 'arxiv_comment': '34 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/2105.10671v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.10671v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
78,http://arxiv.org/abs/2105.10272v1,2021-05-21 10:46:43+00:00,2021-05-21 10:46:43+00:00,Stance Detection with BERT Embeddings for Credibility Analysis of Information on Social Media,"[arxiv.Result.Author('Hema Karande'), arxiv.Result.Author('Rahee Walambe'), arxiv.Result.Author('Victor Benjamin'), arxiv.Result.Author('Ketan Kotecha'), arxiv.Result.Author('T. S. Raghu')]","The evolution of electronic media is a mixed blessing. Due to the easy
access, low cost, and faster reach of the information, people search out and
devour news from online social networks. In contrast, the increasing acceptance
of social media reporting leads to the spread of fake news. This is a minacious
problem that causes disputes and endangers societal stability and harmony. Fake
news spread has gained attention from researchers due to its vicious nature.
proliferation of misinformation in all media, from the internet to cable news,
paid advertising and local news outlets, has made it essential for people to
identify the misinformation and sort through the facts. Researchers are trying
to analyze the credibility of information and curtail false information on such
platforms. Credibility is the believability of the piece of information at
hand. Analyzing the credibility of fake news is challenging due to the intent
of its creation and the polychromatic nature of the news. In this work, we
propose a model for detecting fake news. Our method investigates the content of
the news at the early stage i.e. when the news is published but is yet to be
disseminated through social media. Our work interprets the content with
automatic feature extraction and the relevance of the text pieces. In summary,
we introduce stance as one of the features along with the content of the
article and employ the pre-trained contextualized word embeddings BERT to
obtain the state-of-art results for fake news detection. The experiment
conducted on the real-world dataset indicates that our model outperforms the
previous work and enables fake news detection with an accuracy of 95.32%.",,,10.7717/peerj-cs.467,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.7717/peerj-cs.467', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2105.10272v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.10272v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.10272v1,"{'id': 'http://arxiv.org/abs/2105.10272v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.10272v1', 'updated': '2021-05-21T10:46:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=21, tm_hour=10, tm_min=46, tm_sec=43, tm_wday=4, tm_yday=141, tm_isdst=0), 'published': '2021-05-21T10:46:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=21, tm_hour=10, tm_min=46, tm_sec=43, tm_wday=4, tm_yday=141, tm_isdst=0), 'title': 'Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media'}, 'summary': 'The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.'}, 'authors': [{'name': 'Hema Karande'}, {'name': 'Rahee Walambe'}, {'name': 'Victor Benjamin'}, {'name': 'Ketan Kotecha'}, {'name': 'T. S. Raghu'}], 'author_detail': {'name': 'T. S. Raghu'}, 'author': 'T. S. Raghu', 'arxiv_doi': '10.7717/peerj-cs.467', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.7717/peerj-cs.467', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2105.10272v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.10272v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
79,http://arxiv.org/abs/2105.09819v1,2021-05-20 15:10:48+00:00,2021-05-20 15:10:48+00:00,"Characterizing Abhorrent, Misinformative, and Mistargeted Content on YouTube",[arxiv.Result.Author('Kostantinos Papadamou')],"YouTube has revolutionized the way people discover and consume video.
Although YouTube facilitates easy access to hundreds of well-produced and
trustworthy videos, abhorrent, misinformative, and mistargeted content is also
common. The platform is plagued by various types of problematic content: 1)
disturbing videos targeting young children; 2) hateful and misogynistic
content; and 3) pseudoscientific misinformation. While YouTube's recommendation
algorithm plays a vital role in increasing user engagement and YouTube's
monetization, its role in unwittingly promoting problematic content is not
entirely understood. In this thesis, we shed some light on the degree of
problematic content on YouTube and the role of the recommendation algorithm in
the dissemination of such content. Following a data-driven quantitative
approach, we analyze thousands of videos on YouTube, to shed light on: 1) the
risks of YouTube media consumption by young children; 2) the role of the
recommendation algorithm in the dissemination of misogynistic content, by
focusing on the Involuntary Celibates (Incels) community; and 3) user exposure
to pseudoscientific content on various parts of the platform and how this
exposure changes based on the user's watch history. Our analysis reveals that
young children are likely to encounter disturbing content when they randomly
browse the platform. By analyzing the Incel community on YouTube, we find that
Incel activity is increasing over time and that platforms may play an active
role in steering users towards extreme content. Finally, when studying
pseudoscientific misinformation, we find that YouTube suggests more
pseudoscientific content regarding traditional pseudoscientific topics (e.g.,
flat earth) than for emerging ones (like COVID-19) and that these
recommendations are more common on the search results page than on a user's
homepage or the video recommendations section.","PhD Thesis. Overlaps with arXiv:1901.07046, arXiv:2001.08293,
  arXiv:2010.11638",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2105.09819v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.09819v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.09819v1,"{'id': 'http://arxiv.org/abs/2105.09819v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.09819v1', 'updated': '2021-05-20T15:10:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=20, tm_hour=15, tm_min=10, tm_sec=48, tm_wday=3, tm_yday=140, tm_isdst=0), 'published': '2021-05-20T15:10:48Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=20, tm_hour=15, tm_min=10, tm_sec=48, tm_wday=3, tm_yday=140, tm_isdst=0), 'title': 'Characterizing Abhorrent, Misinformative, and Mistargeted Content on\n  YouTube', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing Abhorrent, Misinformative, and Mistargeted Content on\n  YouTube'}, 'summary': ""YouTube has revolutionized the way people discover and consume video.\nAlthough YouTube facilitates easy access to hundreds of well-produced and\ntrustworthy videos, abhorrent, misinformative, and mistargeted content is also\ncommon. The platform is plagued by various types of problematic content: 1)\ndisturbing videos targeting young children; 2) hateful and misogynistic\ncontent; and 3) pseudoscientific misinformation. While YouTube's recommendation\nalgorithm plays a vital role in increasing user engagement and YouTube's\nmonetization, its role in unwittingly promoting problematic content is not\nentirely understood. In this thesis, we shed some light on the degree of\nproblematic content on YouTube and the role of the recommendation algorithm in\nthe dissemination of such content. Following a data-driven quantitative\napproach, we analyze thousands of videos on YouTube, to shed light on: 1) the\nrisks of YouTube media consumption by young children; 2) the role of the\nrecommendation algorithm in the dissemination of misogynistic content, by\nfocusing on the Involuntary Celibates (Incels) community; and 3) user exposure\nto pseudoscientific content on various parts of the platform and how this\nexposure changes based on the user's watch history. Our analysis reveals that\nyoung children are likely to encounter disturbing content when they randomly\nbrowse the platform. By analyzing the Incel community on YouTube, we find that\nIncel activity is increasing over time and that platforms may play an active\nrole in steering users towards extreme content. Finally, when studying\npseudoscientific misinformation, we find that YouTube suggests more\npseudoscientific content regarding traditional pseudoscientific topics (e.g.,\nflat earth) than for emerging ones (like COVID-19) and that these\nrecommendations are more common on the search results page than on a user's\nhomepage or the video recommendations section."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""YouTube has revolutionized the way people discover and consume video.\nAlthough YouTube facilitates easy access to hundreds of well-produced and\ntrustworthy videos, abhorrent, misinformative, and mistargeted content is also\ncommon. The platform is plagued by various types of problematic content: 1)\ndisturbing videos targeting young children; 2) hateful and misogynistic\ncontent; and 3) pseudoscientific misinformation. While YouTube's recommendation\nalgorithm plays a vital role in increasing user engagement and YouTube's\nmonetization, its role in unwittingly promoting problematic content is not\nentirely understood. In this thesis, we shed some light on the degree of\nproblematic content on YouTube and the role of the recommendation algorithm in\nthe dissemination of such content. Following a data-driven quantitative\napproach, we analyze thousands of videos on YouTube, to shed light on: 1) the\nrisks of YouTube media consumption by young children; 2) the role of the\nrecommendation algorithm in the dissemination of misogynistic content, by\nfocusing on the Involuntary Celibates (Incels) community; and 3) user exposure\nto pseudoscientific content on various parts of the platform and how this\nexposure changes based on the user's watch history. Our analysis reveals that\nyoung children are likely to encounter disturbing content when they randomly\nbrowse the platform. By analyzing the Incel community on YouTube, we find that\nIncel activity is increasing over time and that platforms may play an active\nrole in steering users towards extreme content. Finally, when studying\npseudoscientific misinformation, we find that YouTube suggests more\npseudoscientific content regarding traditional pseudoscientific topics (e.g.,\nflat earth) than for emerging ones (like COVID-19) and that these\nrecommendations are more common on the search results page than on a user's\nhomepage or the video recommendations section.""}, 'authors': [{'name': 'Kostantinos Papadamou'}], 'author_detail': {'name': 'Kostantinos Papadamou'}, 'author': 'Kostantinos Papadamou', 'arxiv_comment': 'PhD Thesis. Overlaps with arXiv:1901.07046, arXiv:2001.08293,\n  arXiv:2010.11638', 'links': [{'href': 'http://arxiv.org/abs/2105.09819v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.09819v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
80,http://arxiv.org/abs/2105.09114v1,2021-05-19 13:18:02+00:00,2021-05-19 13:18:02+00:00,Explainable Tsetlin Machine framework for fake news detection with credibility score assessment,"[arxiv.Result.Author('Bimal Bhattarai'), arxiv.Result.Author('Ole-Christoffer Granmo'), arxiv.Result.Author('Lei Jiao')]","The proliferation of fake news, i.e., news intentionally spread for
misinformation, poses a threat to individuals and society. Despite various
fact-checking websites such as PolitiFact, robust detection techniques are
required to deal with the increase in fake news. Several deep learning models
show promising results for fake news classification, however, their black-box
nature makes it difficult to explain their classification decisions and
quality-assure the models. We here address this problem by proposing a novel
interpretable fake news detection framework based on the recently introduced
Tsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to
capture lexical and semantic properties of both true and fake news text.
Further, we use the clause ensembles to calculate the credibility of fake news.
For evaluation, we conduct experiments on two publicly available datasets,
PolitiFact and GossipCop, and demonstrate that the TM framework significantly
outperforms previously published baselines by at least $5\%$ in terms of
accuracy, with the added benefit of an interpretable logic-based
representation. Further, our approach provides higher F1-score than BERT and
XLNet, however, we obtain slightly lower accuracy. We finally present a case
study on our model's explainability, demonstrating how it decomposes into
meaningful words and their negations.","11 pages, 4 figures, 4 tables",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG', 'I.2; I.5; I.7']","[arxiv.Result.Link('http://arxiv.org/abs/2105.09114v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.09114v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.09114v1,"{'id': 'http://arxiv.org/abs/2105.09114v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.09114v1', 'updated': '2021-05-19T13:18:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=13, tm_min=18, tm_sec=2, tm_wday=2, tm_yday=139, tm_isdst=0), 'published': '2021-05-19T13:18:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=13, tm_min=18, tm_sec=2, tm_wday=2, tm_yday=139, tm_isdst=0), 'title': 'Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment'}, 'summary': ""The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.""}, 'authors': [{'name': 'Bimal Bhattarai'}, {'name': 'Ole-Christoffer Granmo'}, {'name': 'Lei Jiao'}], 'author_detail': {'name': 'Lei Jiao'}, 'author': 'Lei Jiao', 'arxiv_comment': '11 pages, 4 figures, 4 tables', 'links': [{'href': 'http://arxiv.org/abs/2105.09114v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.09114v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; I.5; I.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
81,http://arxiv.org/abs/2105.09059v1,2021-05-19 10:59:17+00:00,2021-05-19 10:59:17+00:00,The State of AI Ethics Report (January 2021),"[arxiv.Result.Author('Abhishek Gupta'), arxiv.Result.Author('Alexandrine Royer'), arxiv.Result.Author('Connor Wright'), arxiv.Result.Author('Falaah Arif Khan'), arxiv.Result.Author('Victoria Heath'), arxiv.Result.Author('Erick Galinkin'), arxiv.Result.Author('Ryan Khurana'), arxiv.Result.Author('Marianna Bergamaschi Ganapini'), arxiv.Result.Author('Muriam Fancy'), arxiv.Result.Author('Masa Sweidan'), arxiv.Result.Author('Mo Akif'), arxiv.Result.Author('Renjie Butalid')]","The 3rd edition of the Montreal AI Ethics Institute's The State of AI Ethics
captures the most relevant developments in AI Ethics since October 2020. It
aims to help anyone, from machine learning experts to human rights activists
and policymakers, quickly digest and understand the field's ever-changing
developments. Through research and article summaries, as well as expert
commentary, this report distills the research and reporting surrounding various
domains related to the ethics of AI, including: algorithmic injustice,
discrimination, ethical AI, labor impacts, misinformation, privacy, risk and
security, social media, and more.
  In addition, The State of AI Ethics includes exclusive content written by
world-class AI Ethics experts from universities, research institutes,
consulting firms, and governments. Unique to this report is ""The Abuse and
Misogynoir Playbook,"" written by Dr. Katlyn Tuner (Research Scientist, Space
Enabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program
in Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;
Lead, Space Enabled Research Group, MIT) and Dr. Catherine D'Ignazio (Assistant
Professor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The
piece (and accompanying infographic), is a deep-dive into the historical and
systematic silencing, erasure, and revision of Black women's contributions to
knowledge and scholarship in the United Stations, and globally. Exposing and
countering this Playbook has become increasingly important following the firing
of AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.
  This report should be used not only as a point of reference and insight on
the latest thinking in the field of AI Ethics, but should also be used as a
tool for introspection as we aim to foster a more nuanced conversation
regarding the impacts of AI on the world.",188 pages,,,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2105.09059v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.09059v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.09059v1,"{'id': 'http://arxiv.org/abs/2105.09059v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.09059v1', 'updated': '2021-05-19T10:59:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=10, tm_min=59, tm_sec=17, tm_wday=2, tm_yday=139, tm_isdst=0), 'published': '2021-05-19T10:59:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=19, tm_hour=10, tm_min=59, tm_sec=17, tm_wday=2, tm_yday=139, tm_isdst=0), 'title': 'The State of AI Ethics Report (January 2021)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The State of AI Ethics Report (January 2021)'}, 'summary': 'The 3rd edition of the Montreal AI Ethics Institute\'s The State of AI Ethics\ncaptures the most relevant developments in AI Ethics since October 2020. It\naims to help anyone, from machine learning experts to human rights activists\nand policymakers, quickly digest and understand the field\'s ever-changing\ndevelopments. Through research and article summaries, as well as expert\ncommentary, this report distills the research and reporting surrounding various\ndomains related to the ethics of AI, including: algorithmic injustice,\ndiscrimination, ethical AI, labor impacts, misinformation, privacy, risk and\nsecurity, social media, and more.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. Unique to this report is ""The Abuse and\nMisogynoir Playbook,"" written by Dr. Katlyn Tuner (Research Scientist, Space\nEnabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program\nin Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;\nLead, Space Enabled Research Group, MIT) and Dr. Catherine D\'Ignazio (Assistant\nProfessor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The\npiece (and accompanying infographic), is a deep-dive into the historical and\nsystematic silencing, erasure, and revision of Black women\'s contributions to\nknowledge and scholarship in the United Stations, and globally. Exposing and\ncountering this Playbook has become increasingly important following the firing\nof AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The 3rd edition of the Montreal AI Ethics Institute\'s The State of AI Ethics\ncaptures the most relevant developments in AI Ethics since October 2020. It\naims to help anyone, from machine learning experts to human rights activists\nand policymakers, quickly digest and understand the field\'s ever-changing\ndevelopments. Through research and article summaries, as well as expert\ncommentary, this report distills the research and reporting surrounding various\ndomains related to the ethics of AI, including: algorithmic injustice,\ndiscrimination, ethical AI, labor impacts, misinformation, privacy, risk and\nsecurity, social media, and more.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. Unique to this report is ""The Abuse and\nMisogynoir Playbook,"" written by Dr. Katlyn Tuner (Research Scientist, Space\nEnabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program\nin Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;\nLead, Space Enabled Research Group, MIT) and Dr. Catherine D\'Ignazio (Assistant\nProfessor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The\npiece (and accompanying infographic), is a deep-dive into the historical and\nsystematic silencing, erasure, and revision of Black women\'s contributions to\nknowledge and scholarship in the United Stations, and globally. Exposing and\ncountering this Playbook has become increasingly important following the firing\nof AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.'}, 'authors': [{'name': 'Abhishek Gupta'}, {'name': 'Alexandrine Royer'}, {'name': 'Connor Wright'}, {'name': 'Falaah Arif Khan'}, {'name': 'Victoria Heath'}, {'name': 'Erick Galinkin'}, {'name': 'Ryan Khurana'}, {'name': 'Marianna Bergamaschi Ganapini'}, {'name': 'Muriam Fancy'}, {'name': 'Masa Sweidan'}, {'name': 'Mo Akif'}, {'name': 'Renjie Butalid'}], 'author_detail': {'name': 'Renjie Butalid'}, 'arxiv_affiliation': 'Montreal AI Ethics Institute', 'author': 'Renjie Butalid', 'arxiv_comment': '188 pages', 'links': [{'href': 'http://arxiv.org/abs/2105.09059v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.09059v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
82,http://arxiv.org/abs/2105.07730v1,2021-05-17 10:58:35+00:00,2021-05-17 10:58:35+00:00,The State of Infodemic on Twitter,"[arxiv.Result.Author('Drishti Jain'), arxiv.Result.Author('Tavpritesh Sethi')]","Following the wave of misinterpreted, manipulated and malicious information
growing on the Internet, the misinformation surrounding COVID-19 has become a
paramount issue. In the context of the current COVID-19 pandemic, social media
posts and platforms are at risk of rumors and misinformation in the face of the
serious uncertainty surrounding the virus itself. At the same time, the
uncertainty and new nature of COVID-19 means that other unconfirmed information
that may appear ""rumored"" may be an important indicator of the behavior and
impact of this new virus. Twitter, in particular, has taken a center stage in
this storm where Covid-19 has been a much talked about subject. We have
presented an exploratory analysis of the tweets and the users who are involved
in spreading misinformation and then delved into machine learning models and
natural language processing techniques to identify if a tweet contains
misinformation.",8 pages,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2105.07730v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.07730v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.07730v1,"{'id': 'http://arxiv.org/abs/2105.07730v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.07730v1', 'updated': '2021-05-17T10:58:35Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=17, tm_hour=10, tm_min=58, tm_sec=35, tm_wday=0, tm_yday=137, tm_isdst=0), 'published': '2021-05-17T10:58:35Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=17, tm_hour=10, tm_min=58, tm_sec=35, tm_wday=0, tm_yday=137, tm_isdst=0), 'title': 'The State of Infodemic on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The State of Infodemic on Twitter'}, 'summary': 'Following the wave of misinterpreted, manipulated and malicious information\ngrowing on the Internet, the misinformation surrounding COVID-19 has become a\nparamount issue. In the context of the current COVID-19 pandemic, social media\nposts and platforms are at risk of rumors and misinformation in the face of the\nserious uncertainty surrounding the virus itself. At the same time, the\nuncertainty and new nature of COVID-19 means that other unconfirmed information\nthat may appear ""rumored"" may be an important indicator of the behavior and\nimpact of this new virus. Twitter, in particular, has taken a center stage in\nthis storm where Covid-19 has been a much talked about subject. We have\npresented an exploratory analysis of the tweets and the users who are involved\nin spreading misinformation and then delved into machine learning models and\nnatural language processing techniques to identify if a tweet contains\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Following the wave of misinterpreted, manipulated and malicious information\ngrowing on the Internet, the misinformation surrounding COVID-19 has become a\nparamount issue. In the context of the current COVID-19 pandemic, social media\nposts and platforms are at risk of rumors and misinformation in the face of the\nserious uncertainty surrounding the virus itself. At the same time, the\nuncertainty and new nature of COVID-19 means that other unconfirmed information\nthat may appear ""rumored"" may be an important indicator of the behavior and\nimpact of this new virus. Twitter, in particular, has taken a center stage in\nthis storm where Covid-19 has been a much talked about subject. We have\npresented an exploratory analysis of the tweets and the users who are involved\nin spreading misinformation and then delved into machine learning models and\nnatural language processing techniques to identify if a tweet contains\nmisinformation.'}, 'authors': [{'name': 'Drishti Jain'}, {'name': 'Tavpritesh Sethi'}], 'author_detail': {'name': 'Tavpritesh Sethi'}, 'arxiv_affiliation': 'Indraprastha Institute of Information Technology', 'author': 'Tavpritesh Sethi', 'arxiv_comment': '8 pages', 'links': [{'href': 'http://arxiv.org/abs/2105.07730v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.07730v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
83,http://arxiv.org/abs/2105.07523v2,2021-05-22 10:59:53+00:00,2021-05-16 21:47:30+00:00,Follow the Money: Analyzing @slpng_giants_pt's Strategy to Combat Misinformation,"[arxiv.Result.Author('Bárbara Gomes Ribeiro'), arxiv.Result.Author('Manoel Horta Ribeiro'), arxiv.Result.Author('Virgílio Almeida'), arxiv.Result.Author('Wagner Meira Jr')]","In 2020, the activist movement @sleeping_giants_pt (SGB) made a splash in
Brazil. Similar to its international counterparts, the movement carried
""campaigns"" against media outlets spreading misinformation. In those, SGB
targeted companies whose ads were shown in these outlets, publicly asking them
to remove the ads. In this work, we present a careful characterization of SGB's
activism model, analyzing the three campaigns carried by the movement up to
September 2020. We study how successful its complaints were and what factors
are associated with their success, how attention towards the targeted media
outlets progressed, and how online interactions with the companies were
impacted after they were targeted. Leveraging an annotated corpus of SGB's
tweets as well as other data from Twitter and Google Search, we show that SGB's
""campaigns"" were largely successful: over 86\% of companies (n=161) responded
positively to SGB's requests, and, for those that responded, we find user
pressure to be negatively correlated with the time companies take to answer
($r$=-0.67; $p$<0.001). Finally, we find that, although changes in the
interactions with companies were transient, the impact in targeted media
outlets endured: all three outlets experienced a significant decrease in
engagement on Twitter and search volume on Google following the start of SGB's
campaigns. Overall, our work suggests that internet-based activism can leverage
the transient attention it captures towards concrete goals to have a
long-lasting impact.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2105.07523v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.07523v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.07523v2,"{'id': 'http://arxiv.org/abs/2105.07523v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.07523v2', 'updated': '2021-05-22T10:59:53Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=22, tm_hour=10, tm_min=59, tm_sec=53, tm_wday=5, tm_yday=142, tm_isdst=0), 'published': '2021-05-16T21:47:30Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=16, tm_hour=21, tm_min=47, tm_sec=30, tm_wday=6, tm_yday=136, tm_isdst=0), 'title': ""Follow the Money: Analyzing @slpng_giants_pt's Strategy to Combat\n  Misinformation"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Follow the Money: Analyzing @slpng_giants_pt's Strategy to Combat\n  Misinformation""}, 'summary': 'In 2020, the activist movement @sleeping_giants_pt (SGB) made a splash in\nBrazil. Similar to its international counterparts, the movement carried\n""campaigns"" against media outlets spreading misinformation. In those, SGB\ntargeted companies whose ads were shown in these outlets, publicly asking them\nto remove the ads. In this work, we present a careful characterization of SGB\'s\nactivism model, analyzing the three campaigns carried by the movement up to\nSeptember 2020. We study how successful its complaints were and what factors\nare associated with their success, how attention towards the targeted media\noutlets progressed, and how online interactions with the companies were\nimpacted after they were targeted. Leveraging an annotated corpus of SGB\'s\ntweets as well as other data from Twitter and Google Search, we show that SGB\'s\n""campaigns"" were largely successful: over 86\\% of companies (n=161) responded\npositively to SGB\'s requests, and, for those that responded, we find user\npressure to be negatively correlated with the time companies take to answer\n($r$=-0.67; $p$<0.001). Finally, we find that, although changes in the\ninteractions with companies were transient, the impact in targeted media\noutlets endured: all three outlets experienced a significant decrease in\nengagement on Twitter and search volume on Google following the start of SGB\'s\ncampaigns. Overall, our work suggests that internet-based activism can leverage\nthe transient attention it captures towards concrete goals to have a\nlong-lasting impact.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In 2020, the activist movement @sleeping_giants_pt (SGB) made a splash in\nBrazil. Similar to its international counterparts, the movement carried\n""campaigns"" against media outlets spreading misinformation. In those, SGB\ntargeted companies whose ads were shown in these outlets, publicly asking them\nto remove the ads. In this work, we present a careful characterization of SGB\'s\nactivism model, analyzing the three campaigns carried by the movement up to\nSeptember 2020. We study how successful its complaints were and what factors\nare associated with their success, how attention towards the targeted media\noutlets progressed, and how online interactions with the companies were\nimpacted after they were targeted. Leveraging an annotated corpus of SGB\'s\ntweets as well as other data from Twitter and Google Search, we show that SGB\'s\n""campaigns"" were largely successful: over 86\\% of companies (n=161) responded\npositively to SGB\'s requests, and, for those that responded, we find user\npressure to be negatively correlated with the time companies take to answer\n($r$=-0.67; $p$<0.001). Finally, we find that, although changes in the\ninteractions with companies were transient, the impact in targeted media\noutlets endured: all three outlets experienced a significant decrease in\nengagement on Twitter and search volume on Google following the start of SGB\'s\ncampaigns. Overall, our work suggests that internet-based activism can leverage\nthe transient attention it captures towards concrete goals to have a\nlong-lasting impact.'}, 'authors': [{'name': 'Bárbara Gomes Ribeiro'}, {'name': 'Manoel Horta Ribeiro'}, {'name': 'Virgílio Almeida'}, {'name': 'Wagner Meira Jr'}], 'author_detail': {'name': 'Wagner Meira Jr'}, 'author': 'Wagner Meira Jr', 'links': [{'href': 'http://arxiv.org/abs/2105.07523v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.07523v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
84,http://arxiv.org/abs/2105.07454v2,2021-06-05 15:10:56+00:00,2021-05-16 15:38:49+00:00,A Synchronized Action Framework for Responsible Detection of Coordination on Social Media,"[arxiv.Result.Author('Thomas Magelinski'), arxiv.Result.Author('Lynnette Hui Xian Ng'), arxiv.Result.Author('Kathleen M. Carley')]","The study of coordinated manipulation of conversations on social media has
become more prevalent as social media's role in amplifying misinformation,
hate, and polarization has come under scrutiny. We discuss the implications of
successful coordination detection algorithms based on shifts of power, and
consider how responsible coordination detection may be carried out through
synchronized action. We then propose a Synchronized Action Framework for
detection of automated coordination through construction and analysis of
multi-view networks. We validate our framework by examining the Reopen America
conversation on Twitter, discovering three coordinated campaigns. We further
investigate covert coordination surrounding the protests and find the task to
be far more complex than examples seen in prior work, demonstrating the need
for our multi-view approach. A cluster of suspicious users is identified and
the activity of three members is detailed. These users amplify protest messages
using the same hashtags at very similar times, though they all focus on
different states. Through this analysis, we emphasize both the potential
usefulness of coordination detection algorithms in investigating amplification,
and the need for careful and responsible deployment of such tools.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2105.07454v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.07454v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.07454v2,"{'id': 'http://arxiv.org/abs/2105.07454v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.07454v2', 'updated': '2021-06-05T15:10:56Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=5, tm_hour=15, tm_min=10, tm_sec=56, tm_wday=5, tm_yday=156, tm_isdst=0), 'published': '2021-05-16T15:38:49Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=16, tm_hour=15, tm_min=38, tm_sec=49, tm_wday=6, tm_yday=136, tm_isdst=0), 'title': 'A Synchronized Action Framework for Responsible Detection of\n  Coordination on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Synchronized Action Framework for Responsible Detection of\n  Coordination on Social Media'}, 'summary': ""The study of coordinated manipulation of conversations on social media has\nbecome more prevalent as social media's role in amplifying misinformation,\nhate, and polarization has come under scrutiny. We discuss the implications of\nsuccessful coordination detection algorithms based on shifts of power, and\nconsider how responsible coordination detection may be carried out through\nsynchronized action. We then propose a Synchronized Action Framework for\ndetection of automated coordination through construction and analysis of\nmulti-view networks. We validate our framework by examining the Reopen America\nconversation on Twitter, discovering three coordinated campaigns. We further\ninvestigate covert coordination surrounding the protests and find the task to\nbe far more complex than examples seen in prior work, demonstrating the need\nfor our multi-view approach. A cluster of suspicious users is identified and\nthe activity of three members is detailed. These users amplify protest messages\nusing the same hashtags at very similar times, though they all focus on\ndifferent states. Through this analysis, we emphasize both the potential\nusefulness of coordination detection algorithms in investigating amplification,\nand the need for careful and responsible deployment of such tools."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The study of coordinated manipulation of conversations on social media has\nbecome more prevalent as social media's role in amplifying misinformation,\nhate, and polarization has come under scrutiny. We discuss the implications of\nsuccessful coordination detection algorithms based on shifts of power, and\nconsider how responsible coordination detection may be carried out through\nsynchronized action. We then propose a Synchronized Action Framework for\ndetection of automated coordination through construction and analysis of\nmulti-view networks. We validate our framework by examining the Reopen America\nconversation on Twitter, discovering three coordinated campaigns. We further\ninvestigate covert coordination surrounding the protests and find the task to\nbe far more complex than examples seen in prior work, demonstrating the need\nfor our multi-view approach. A cluster of suspicious users is identified and\nthe activity of three members is detailed. These users amplify protest messages\nusing the same hashtags at very similar times, though they all focus on\ndifferent states. Through this analysis, we emphasize both the potential\nusefulness of coordination detection algorithms in investigating amplification,\nand the need for careful and responsible deployment of such tools.""}, 'authors': [{'name': 'Thomas Magelinski'}, {'name': 'Lynnette Hui Xian Ng'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'links': [{'href': 'http://arxiv.org/abs/2105.07454v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.07454v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
85,http://arxiv.org/abs/2105.05134v2,2021-05-14 21:05:27+00:00,2021-05-11 15:43:41+00:00,"COVID-19 Vaccine Hesitancy on Social Media: Building a Public Twitter Dataset of Anti-vaccine Content, Vaccine Misinformation and Conspiracies","[arxiv.Result.Author('Goran Muric'), arxiv.Result.Author('Yusong Wu'), arxiv.Result.Author('Emilio Ferrara')]","False claims about COVID-19 vaccines can undermine public trust in ongoing
vaccination campaigns, thus posing a threat to global public health.
Misinformation originating from various sources has been spreading online since
the beginning of the COVID-19 pandemic. In this paper, we present a dataset of
Twitter posts that exhibit a strong anti-vaccine stance. The dataset consists
of two parts: a) a streaming keyword-centered data collection with more than
1.8 million tweets, and b) a historical account-level collection with more than
135 million tweets. The former leverages the Twitter streaming API to follow a
set of specific vaccine-related keywords starting from mid-October 2020. The
latter consists of all historical tweets of 70K accounts that were engaged in
the active spreading of anti-vaccine narratives. We present descriptive
analyses showing the volume of activity over time, geographical distributions,
topics, news sources, and inferred account political leaning. This dataset can
be used in studying anti-vaccine misinformation on social media and enable a
better understanding of vaccine hesitancy. In compliance with Twitter's Terms
of Service, our anonymized dataset is publicly available at:
https://github.com/gmuric/avax-tweets-dataset",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2105.05134v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.05134v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.05134v2,"{'id': 'http://arxiv.org/abs/2105.05134v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.05134v2', 'updated': '2021-05-14T21:05:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=14, tm_hour=21, tm_min=5, tm_sec=27, tm_wday=4, tm_yday=134, tm_isdst=0), 'published': '2021-05-11T15:43:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=11, tm_hour=15, tm_min=43, tm_sec=41, tm_wday=1, tm_yday=131, tm_isdst=0), 'title': 'COVID-19 Vaccine Hesitancy on Social Media: Building a Public Twitter\n  Dataset of Anti-vaccine Content, Vaccine Misinformation and Conspiracies', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Vaccine Hesitancy on Social Media: Building a Public Twitter\n  Dataset of Anti-vaccine Content, Vaccine Misinformation and Conspiracies'}, 'summary': ""False claims about COVID-19 vaccines can undermine public trust in ongoing\nvaccination campaigns, thus posing a threat to global public health.\nMisinformation originating from various sources has been spreading online since\nthe beginning of the COVID-19 pandemic. In this paper, we present a dataset of\nTwitter posts that exhibit a strong anti-vaccine stance. The dataset consists\nof two parts: a) a streaming keyword-centered data collection with more than\n1.8 million tweets, and b) a historical account-level collection with more than\n135 million tweets. The former leverages the Twitter streaming API to follow a\nset of specific vaccine-related keywords starting from mid-October 2020. The\nlatter consists of all historical tweets of 70K accounts that were engaged in\nthe active spreading of anti-vaccine narratives. We present descriptive\nanalyses showing the volume of activity over time, geographical distributions,\ntopics, news sources, and inferred account political leaning. This dataset can\nbe used in studying anti-vaccine misinformation on social media and enable a\nbetter understanding of vaccine hesitancy. In compliance with Twitter's Terms\nof Service, our anonymized dataset is publicly available at:\nhttps://github.com/gmuric/avax-tweets-dataset"", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""False claims about COVID-19 vaccines can undermine public trust in ongoing\nvaccination campaigns, thus posing a threat to global public health.\nMisinformation originating from various sources has been spreading online since\nthe beginning of the COVID-19 pandemic. In this paper, we present a dataset of\nTwitter posts that exhibit a strong anti-vaccine stance. The dataset consists\nof two parts: a) a streaming keyword-centered data collection with more than\n1.8 million tweets, and b) a historical account-level collection with more than\n135 million tweets. The former leverages the Twitter streaming API to follow a\nset of specific vaccine-related keywords starting from mid-October 2020. The\nlatter consists of all historical tweets of 70K accounts that were engaged in\nthe active spreading of anti-vaccine narratives. We present descriptive\nanalyses showing the volume of activity over time, geographical distributions,\ntopics, news sources, and inferred account political leaning. This dataset can\nbe used in studying anti-vaccine misinformation on social media and enable a\nbetter understanding of vaccine hesitancy. In compliance with Twitter's Terms\nof Service, our anonymized dataset is publicly available at:\nhttps://github.com/gmuric/avax-tweets-dataset""}, 'authors': [{'name': 'Goran Muric'}, {'name': 'Yusong Wu'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'links': [{'href': 'http://arxiv.org/abs/2105.05134v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.05134v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
86,http://arxiv.org/abs/2105.07854v1,2021-05-06 15:26:48+00:00,2021-05-06 15:26:48+00:00,"""Hey Alexa, What do You Know About the COVID-19 Vaccine?"" -- (Mis)perceptions of Mass Immunization Among Voice Assistant Users","[arxiv.Result.Author('Filipo Sharevski'), arxiv.Result.Author('Anna Slowinski'), arxiv.Result.Author('Peter Jachim'), arxiv.Result.Author('Emma Pieroni')]","In this paper, we analyzed the perceived accuracy of COVID-19 vaccine
information spoken back by Amazon Alexa. Unlike social media, Amazon Alexa
doesn't apply soft moderation to unverified content, allowing for use of
third-party malicious skills to arbitrarily phrase COVID-19 vaccine
information. The results from a 210-participant study suggest that a
third-party malicious skill could successful reduce the perceived accuracy
among the users of information as to who gets the vaccine first, vaccine
testing, and the side effects of the vaccine. We also found that the
vaccine-hesitant participants are drawn to pessimistically rephrased Alexa
responses focused on the downsides of the mass immunization. We discuss
solutions for soft moderation against misperception-inducing or altogether
COVID-19 misinformation malicious third-party skills.",arXiv admin note: text overlap with arXiv:2104.04077,,,cs.CY,"['cs.CY', 'cs.CR', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2105.07854v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.07854v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.07854v1,"{'id': 'http://arxiv.org/abs/2105.07854v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.07854v1', 'updated': '2021-05-06T15:26:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=6, tm_hour=15, tm_min=26, tm_sec=48, tm_wday=3, tm_yday=126, tm_isdst=0), 'published': '2021-05-06T15:26:48Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=6, tm_hour=15, tm_min=26, tm_sec=48, tm_wday=3, tm_yday=126, tm_isdst=0), 'title': '""Hey Alexa, What do You Know About the COVID-19 Vaccine?"" --\n  (Mis)perceptions of Mass Immunization Among Voice Assistant Users', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Hey Alexa, What do You Know About the COVID-19 Vaccine?"" --\n  (Mis)perceptions of Mass Immunization Among Voice Assistant Users'}, 'summary': ""In this paper, we analyzed the perceived accuracy of COVID-19 vaccine\ninformation spoken back by Amazon Alexa. Unlike social media, Amazon Alexa\ndoesn't apply soft moderation to unverified content, allowing for use of\nthird-party malicious skills to arbitrarily phrase COVID-19 vaccine\ninformation. The results from a 210-participant study suggest that a\nthird-party malicious skill could successful reduce the perceived accuracy\namong the users of information as to who gets the vaccine first, vaccine\ntesting, and the side effects of the vaccine. We also found that the\nvaccine-hesitant participants are drawn to pessimistically rephrased Alexa\nresponses focused on the downsides of the mass immunization. We discuss\nsolutions for soft moderation against misperception-inducing or altogether\nCOVID-19 misinformation malicious third-party skills."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In this paper, we analyzed the perceived accuracy of COVID-19 vaccine\ninformation spoken back by Amazon Alexa. Unlike social media, Amazon Alexa\ndoesn't apply soft moderation to unverified content, allowing for use of\nthird-party malicious skills to arbitrarily phrase COVID-19 vaccine\ninformation. The results from a 210-participant study suggest that a\nthird-party malicious skill could successful reduce the perceived accuracy\namong the users of information as to who gets the vaccine first, vaccine\ntesting, and the side effects of the vaccine. We also found that the\nvaccine-hesitant participants are drawn to pessimistically rephrased Alexa\nresponses focused on the downsides of the mass immunization. We discuss\nsolutions for soft moderation against misperception-inducing or altogether\nCOVID-19 misinformation malicious third-party skills.""}, 'authors': [{'name': 'Filipo Sharevski'}, {'name': 'Anna Slowinski'}, {'name': 'Peter Jachim'}, {'name': 'Emma Pieroni'}], 'author_detail': {'name': 'Emma Pieroni'}, 'author': 'Emma Pieroni', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:2104.04077', 'links': [{'href': 'http://arxiv.org/abs/2105.07854v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.07854v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
87,http://arxiv.org/abs/2105.02306v1,2021-05-05 20:08:36+00:00,2021-05-05 20:08:36+00:00,Primary and Secondary Social Media Source Identification,"[arxiv.Result.Author('Brian C Hosler'), arxiv.Result.Author('Matthew C Stamm')]","Social networks like Facebook and WhatsApp have enabled users to share images
with other users around the world. Along with this has come the rapid spread of
misinformation. One step towards verifying the authenticity of an image is
understanding its origin, including it distribution history through social
media. In this paper, we present a method for tracing the posting history of an
image across different social networks. To do this, we propose a two-stage
deep-learning-based approach, which takes advantage of cascaded fingerprints in
images left by social networks during uploading. Our proposed system is not
reliant upon metadata or similar easily falsifiable information. Through a
series of experiments, we show that we are able to outperform existing social
media source identification algorithms. and identify chains of social networks
up to length two with over over 84% accuracy.",,,,eess.IV,['eess.IV'],"[arxiv.Result.Link('http://arxiv.org/abs/2105.02306v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.02306v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.02306v1,"{'id': 'http://arxiv.org/abs/2105.02306v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.02306v1', 'updated': '2021-05-05T20:08:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=5, tm_hour=20, tm_min=8, tm_sec=36, tm_wday=2, tm_yday=125, tm_isdst=0), 'published': '2021-05-05T20:08:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=5, tm_hour=20, tm_min=8, tm_sec=36, tm_wday=2, tm_yday=125, tm_isdst=0), 'title': 'Primary and Secondary Social Media Source Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Primary and Secondary Social Media Source Identification'}, 'summary': 'Social networks like Facebook and WhatsApp have enabled users to share images\nwith other users around the world. Along with this has come the rapid spread of\nmisinformation. One step towards verifying the authenticity of an image is\nunderstanding its origin, including it distribution history through social\nmedia. In this paper, we present a method for tracing the posting history of an\nimage across different social networks. To do this, we propose a two-stage\ndeep-learning-based approach, which takes advantage of cascaded fingerprints in\nimages left by social networks during uploading. Our proposed system is not\nreliant upon metadata or similar easily falsifiable information. Through a\nseries of experiments, we show that we are able to outperform existing social\nmedia source identification algorithms. and identify chains of social networks\nup to length two with over over 84% accuracy.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social networks like Facebook and WhatsApp have enabled users to share images\nwith other users around the world. Along with this has come the rapid spread of\nmisinformation. One step towards verifying the authenticity of an image is\nunderstanding its origin, including it distribution history through social\nmedia. In this paper, we present a method for tracing the posting history of an\nimage across different social networks. To do this, we propose a two-stage\ndeep-learning-based approach, which takes advantage of cascaded fingerprints in\nimages left by social networks during uploading. Our proposed system is not\nreliant upon metadata or similar easily falsifiable information. Through a\nseries of experiments, we show that we are able to outperform existing social\nmedia source identification algorithms. and identify chains of social networks\nup to length two with over over 84% accuracy.'}, 'authors': [{'name': 'Brian C Hosler'}, {'name': 'Matthew C Stamm'}], 'author_detail': {'name': 'Matthew C Stamm'}, 'author': 'Matthew C Stamm', 'links': [{'href': 'http://arxiv.org/abs/2105.02306v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.02306v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
88,http://arxiv.org/abs/2105.03313v1,2021-05-03 14:30:49+00:00,2021-05-03 14:30:49+00:00,Looking for COVID-19 misinformation in multilingual social media texts,"[arxiv.Result.Author('Raj Ratn Pranesh'), arxiv.Result.Author('Mehrdad Farokhnejad'), arxiv.Result.Author('Ambesh Shekhar'), arxiv.Result.Author('Genoveva Vargas-Solar')]","This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for
detecting and observing the spread of misinformation about this disease within
texts. CMTA proposes a data science (DS) pipeline that applies machine learning
models for processing, classifying (Dense-CNN) and analyzing (MBERT)
multilingual (micro)-texts. DS pipeline data preparation tasks extract features
from multilingual textual data and categorize it into specific information
classes (i.e., 'false', 'partly false', 'misleading'). The CMTA pipeline has
been experimented with multilingual micro-texts (tweets), showing
misinformation spread across different languages. To assess the performance of
CMTA and put it in perspective, we performed a comparative analysis of CMTA
with eight monolingual models used for detecting misinformation. The comparison
shows that CMTA has surpassed various monolingual models and suggests that it
can be used as a general method for detecting misinformation in multilingual
micro-texts. CMTA experimental results show misinformation trends about
COVID-19 in different languages during the first pandemic months.",,,,cs.CL,"['cs.CL', 'cs.DB']","[arxiv.Result.Link('http://arxiv.org/abs/2105.03313v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.03313v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.03313v1,"{'id': 'http://arxiv.org/abs/2105.03313v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.03313v1', 'updated': '2021-05-03T14:30:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=3, tm_hour=14, tm_min=30, tm_sec=49, tm_wday=0, tm_yday=123, tm_isdst=0), 'published': '2021-05-03T14:30:49Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=3, tm_hour=14, tm_min=30, tm_sec=49, tm_wday=0, tm_yday=123, tm_isdst=0), 'title': 'Looking for COVID-19 misinformation in multilingual social media texts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Looking for COVID-19 misinformation in multilingual social media texts'}, 'summary': ""This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for\ndetecting and observing the spread of misinformation about this disease within\ntexts. CMTA proposes a data science (DS) pipeline that applies machine learning\nmodels for processing, classifying (Dense-CNN) and analyzing (MBERT)\nmultilingual (micro)-texts. DS pipeline data preparation tasks extract features\nfrom multilingual textual data and categorize it into specific information\nclasses (i.e., 'false', 'partly false', 'misleading'). The CMTA pipeline has\nbeen experimented with multilingual micro-texts (tweets), showing\nmisinformation spread across different languages. To assess the performance of\nCMTA and put it in perspective, we performed a comparative analysis of CMTA\nwith eight monolingual models used for detecting misinformation. The comparison\nshows that CMTA has surpassed various monolingual models and suggests that it\ncan be used as a general method for detecting misinformation in multilingual\nmicro-texts. CMTA experimental results show misinformation trends about\nCOVID-19 in different languages during the first pandemic months."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for\ndetecting and observing the spread of misinformation about this disease within\ntexts. CMTA proposes a data science (DS) pipeline that applies machine learning\nmodels for processing, classifying (Dense-CNN) and analyzing (MBERT)\nmultilingual (micro)-texts. DS pipeline data preparation tasks extract features\nfrom multilingual textual data and categorize it into specific information\nclasses (i.e., 'false', 'partly false', 'misleading'). The CMTA pipeline has\nbeen experimented with multilingual micro-texts (tweets), showing\nmisinformation spread across different languages. To assess the performance of\nCMTA and put it in perspective, we performed a comparative analysis of CMTA\nwith eight monolingual models used for detecting misinformation. The comparison\nshows that CMTA has surpassed various monolingual models and suggests that it\ncan be used as a general method for detecting misinformation in multilingual\nmicro-texts. CMTA experimental results show misinformation trends about\nCOVID-19 in different languages during the first pandemic months.""}, 'authors': [{'name': 'Raj Ratn Pranesh'}, {'name': 'Mehrdad Farokhnejad'}, {'name': 'Ambesh Shekhar'}, {'name': 'Genoveva Vargas-Solar'}], 'author_detail': {'name': 'Genoveva Vargas-Solar'}, 'author': 'Genoveva Vargas-Solar', 'links': [{'href': 'http://arxiv.org/abs/2105.03313v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.03313v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
89,http://arxiv.org/abs/2105.00192v1,2021-05-01 08:25:43+00:00,2021-05-01 08:25:43+00:00,Deep Insights of Deepfake Technology : A Review,"[arxiv.Result.Author('Bahar Uddin Mahmud'), arxiv.Result.Author('Afsana Sharmin')]","Under the aegis of computer vision and deep learning technology, a new
emerging techniques has introduced that anyone can make highly realistic but
fake videos, images even can manipulates the voices. This technology is widely
known as Deepfake Technology. Although it seems interesting techniques to make
fake videos or image of something or some individuals but it could spread as
misinformation via internet. Deepfake contents could be dangerous for
individuals as well as for our communities, organizations, countries religions
etc. As Deepfake content creation involve a high level expertise with
combination of several algorithms of deep learning, it seems almost real and
genuine and difficult to differentiate. In this paper, a wide range of articles
have been examined to understand Deepfake technology more extensively. We have
examined several articles to find some insights such as what is Deepfake, who
are responsible for this, is there any benefits of Deepfake and what are the
challenges of this technology. We have also examined several creation and
detection techniques. Our study revealed that although Deepfake is a threat to
our societies, proper measures and strict regulations could prevent this.",,"DUJASE Vol. 5(1 & 2) 13-23, 2020 (January & July)",,cs.LG,['cs.LG'],"[arxiv.Result.Link('http://arxiv.org/abs/2105.00192v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2105.00192v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2105.00192v1,"{'id': 'http://arxiv.org/abs/2105.00192v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2105.00192v1', 'updated': '2021-05-01T08:25:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=1, tm_hour=8, tm_min=25, tm_sec=43, tm_wday=5, tm_yday=121, tm_isdst=0), 'published': '2021-05-01T08:25:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=1, tm_hour=8, tm_min=25, tm_sec=43, tm_wday=5, tm_yday=121, tm_isdst=0), 'title': 'Deep Insights of Deepfake Technology : A Review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deep Insights of Deepfake Technology : A Review'}, 'summary': 'Under the aegis of computer vision and deep learning technology, a new\nemerging techniques has introduced that anyone can make highly realistic but\nfake videos, images even can manipulates the voices. This technology is widely\nknown as Deepfake Technology. Although it seems interesting techniques to make\nfake videos or image of something or some individuals but it could spread as\nmisinformation via internet. Deepfake contents could be dangerous for\nindividuals as well as for our communities, organizations, countries religions\netc. As Deepfake content creation involve a high level expertise with\ncombination of several algorithms of deep learning, it seems almost real and\ngenuine and difficult to differentiate. In this paper, a wide range of articles\nhave been examined to understand Deepfake technology more extensively. We have\nexamined several articles to find some insights such as what is Deepfake, who\nare responsible for this, is there any benefits of Deepfake and what are the\nchallenges of this technology. We have also examined several creation and\ndetection techniques. Our study revealed that although Deepfake is a threat to\nour societies, proper measures and strict regulations could prevent this.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Under the aegis of computer vision and deep learning technology, a new\nemerging techniques has introduced that anyone can make highly realistic but\nfake videos, images even can manipulates the voices. This technology is widely\nknown as Deepfake Technology. Although it seems interesting techniques to make\nfake videos or image of something or some individuals but it could spread as\nmisinformation via internet. Deepfake contents could be dangerous for\nindividuals as well as for our communities, organizations, countries religions\netc. As Deepfake content creation involve a high level expertise with\ncombination of several algorithms of deep learning, it seems almost real and\ngenuine and difficult to differentiate. In this paper, a wide range of articles\nhave been examined to understand Deepfake technology more extensively. We have\nexamined several articles to find some insights such as what is Deepfake, who\nare responsible for this, is there any benefits of Deepfake and what are the\nchallenges of this technology. We have also examined several creation and\ndetection techniques. Our study revealed that although Deepfake is a threat to\nour societies, proper measures and strict regulations could prevent this.'}, 'authors': [{'name': 'Bahar Uddin Mahmud'}, {'name': 'Afsana Sharmin'}], 'author_detail': {'name': 'Afsana Sharmin'}, 'author': 'Afsana Sharmin', 'arxiv_journal_ref': 'DUJASE Vol. 5(1 & 2) 13-23, 2020 (January & July)', 'links': [{'href': 'http://arxiv.org/abs/2105.00192v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2105.00192v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
90,http://arxiv.org/abs/2104.13816v1,2021-04-28 15:04:22+00:00,2021-04-28 15:04:22+00:00,The Evolution of Rumors on a Closed Platform during COVID-19,"[arxiv.Result.Author('Andrea W Wang'), arxiv.Result.Author('Jo-Yu Lan'), arxiv.Result.Author('Chihhao Yu'), arxiv.Result.Author('Ming-Hung Wang')]","In this work we looked into a dataset of 114 thousands of suspicious messages
collected from the most popular closed messaging platform in Taiwan between
January and July, 2020. We proposed an hybrid algorithm that could efficiently
cluster a large number of text messages according their topics and narratives.
That is, we obtained groups of messages that are within a limited content
alterations within each other. By employing the algorithm to the dataset, we
were able to look at the content alterations and the temporal dynamics of each
particular rumor over time. With qualitative case studies of three COVID-19
related rumors, we have found that key authoritative figures were often
misquoted in false information. It was an effective measure to increase the
popularity of one false information. In addition, fact-check was not effective
in stopping misinformation from getting attention. In fact, the popularity of
one false information was often more influenced by major societal events and
effective content alterations.",,,,cs.CY,"['cs.CY', 'cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.13816v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13816v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13816v1,"{'id': 'http://arxiv.org/abs/2104.13816v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13816v1', 'updated': '2021-04-28T15:04:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=15, tm_min=4, tm_sec=22, tm_wday=2, tm_yday=118, tm_isdst=0), 'published': '2021-04-28T15:04:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=15, tm_min=4, tm_sec=22, tm_wday=2, tm_yday=118, tm_isdst=0), 'title': 'The Evolution of Rumors on a Closed Platform during COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Evolution of Rumors on a Closed Platform during COVID-19'}, 'summary': 'In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.'}, 'authors': [{'name': 'Andrea W Wang'}, {'name': 'Jo-Yu Lan'}, {'name': 'Chihhao Yu'}, {'name': 'Ming-Hung Wang'}], 'author_detail': {'name': 'Ming-Hung Wang'}, 'arxiv_affiliation': 'Department of Information Engineering and Computer Science, Feng Chia University', 'author': 'Ming-Hung Wang', 'links': [{'href': 'http://arxiv.org/abs/2104.13816v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13816v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
91,http://arxiv.org/abs/2104.13754v2,2021-10-13 09:34:57+00:00,2021-04-28 13:35:28+00:00,Can crowdsourcing rescue the social marketplace of ideas?,"[arxiv.Result.Author('Taha Yasseri'), arxiv.Result.Author('Filippo Menczer')]","Facebook and Twitter recently announced community-based review platforms to
address misinformation. We provide an overview of the potential affordances of
such community-based approaches to content moderation based on past research
and preliminary analysis of Twitter's Birdwatch data. While our analysis
generally supports a community-based approach to content moderation, it also
warns against potential pitfalls, particularly when the implementation of the
new infrastructure focuses on crowd-based ""validation"" rather than
""collaboration."" We call for multidisciplinary research utilizing methods from
complex systems studies, behavioural sociology, and computational social
science to advance the research on crowd-based content moderation.",Under Review - revision 2,,,cs.SI,"['cs.SI', 'cs.CY', 'physics.data-an', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2104.13754v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13754v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13754v2,"{'id': 'http://arxiv.org/abs/2104.13754v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13754v2', 'updated': '2021-10-13T09:34:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=13, tm_hour=9, tm_min=34, tm_sec=57, tm_wday=2, tm_yday=286, tm_isdst=0), 'published': '2021-04-28T13:35:28Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=13, tm_min=35, tm_sec=28, tm_wday=2, tm_yday=118, tm_isdst=0), 'title': 'Can crowdsourcing rescue the social marketplace of ideas?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can crowdsourcing rescue the social marketplace of ideas?'}, 'summary': 'Facebook and Twitter recently announced community-based review platforms to\naddress misinformation. We provide an overview of the potential affordances of\nsuch community-based approaches to content moderation based on past research\nand preliminary analysis of Twitter\'s Birdwatch data. While our analysis\ngenerally supports a community-based approach to content moderation, it also\nwarns against potential pitfalls, particularly when the implementation of the\nnew infrastructure focuses on crowd-based ""validation"" rather than\n""collaboration."" We call for multidisciplinary research utilizing methods from\ncomplex systems studies, behavioural sociology, and computational social\nscience to advance the research on crowd-based content moderation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Facebook and Twitter recently announced community-based review platforms to\naddress misinformation. We provide an overview of the potential affordances of\nsuch community-based approaches to content moderation based on past research\nand preliminary analysis of Twitter\'s Birdwatch data. While our analysis\ngenerally supports a community-based approach to content moderation, it also\nwarns against potential pitfalls, particularly when the implementation of the\nnew infrastructure focuses on crowd-based ""validation"" rather than\n""collaboration."" We call for multidisciplinary research utilizing methods from\ncomplex systems studies, behavioural sociology, and computational social\nscience to advance the research on crowd-based content moderation.'}, 'authors': [{'name': 'Taha Yasseri'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_comment': 'Under Review - revision 2', 'links': [{'href': 'http://arxiv.org/abs/2104.13754v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13754v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
92,http://arxiv.org/abs/2104.13748v1,2021-04-28 13:28:27+00:00,2021-04-28 13:28:27+00:00,QuTI! Quantifying Text-Image Consistency in Multimodal Documents,"[arxiv.Result.Author('Matthias Springstein'), arxiv.Result.Author('Eric Müller-Budack'), arxiv.Result.Author('Ralph Ewerth')]","The World Wide Web and social media platforms have become popular sources for
news and information. Typically, multimodal information, e.g., image and text
is used to convey information more effectively and to attract attention. While
in most cases image content is decorative or depicts additional information, it
has also been leveraged to spread misinformation and rumors in recent years. In
this paper, we present a Web-based demo application that automatically
quantifies the cross-modal relations of entities (persons, locations, and
events) in image and text. The applications are manifold. For example, the
system can help users to explore multimodal articles more efficiently, or can
assist human assessors and fact-checking efforts in the verification of the
credibility of news stories, tweets, or other multimodal documents.","Accepted for publication in: International ACM SIGIR Conference on
  Research and Development in Information Retrieval 2021",,,cs.IR,"['cs.IR', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2104.13748v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13748v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13748v1,"{'id': 'http://arxiv.org/abs/2104.13748v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13748v1', 'updated': '2021-04-28T13:28:27Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=13, tm_min=28, tm_sec=27, tm_wday=2, tm_yday=118, tm_isdst=0), 'published': '2021-04-28T13:28:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=13, tm_min=28, tm_sec=27, tm_wday=2, tm_yday=118, tm_isdst=0), 'title': 'QuTI! Quantifying Text-Image Consistency in Multimodal Documents', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'QuTI! Quantifying Text-Image Consistency in Multimodal Documents'}, 'summary': 'The World Wide Web and social media platforms have become popular sources for\nnews and information. Typically, multimodal information, e.g., image and text\nis used to convey information more effectively and to attract attention. While\nin most cases image content is decorative or depicts additional information, it\nhas also been leveraged to spread misinformation and rumors in recent years. In\nthis paper, we present a Web-based demo application that automatically\nquantifies the cross-modal relations of entities (persons, locations, and\nevents) in image and text. The applications are manifold. For example, the\nsystem can help users to explore multimodal articles more efficiently, or can\nassist human assessors and fact-checking efforts in the verification of the\ncredibility of news stories, tweets, or other multimodal documents.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The World Wide Web and social media platforms have become popular sources for\nnews and information. Typically, multimodal information, e.g., image and text\nis used to convey information more effectively and to attract attention. While\nin most cases image content is decorative or depicts additional information, it\nhas also been leveraged to spread misinformation and rumors in recent years. In\nthis paper, we present a Web-based demo application that automatically\nquantifies the cross-modal relations of entities (persons, locations, and\nevents) in image and text. The applications are manifold. For example, the\nsystem can help users to explore multimodal articles more efficiently, or can\nassist human assessors and fact-checking efforts in the verification of the\ncredibility of news stories, tweets, or other multimodal documents.'}, 'authors': [{'name': 'Matthias Springstein'}, {'name': 'Eric Müller-Budack'}, {'name': 'Ralph Ewerth'}], 'author_detail': {'name': 'Ralph Ewerth'}, 'author': 'Ralph Ewerth', 'arxiv_comment': 'Accepted for publication in: International ACM SIGIR Conference on\n  Research and Development in Information Retrieval 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.13748v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13748v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
93,http://arxiv.org/abs/2104.13559v2,2021-05-18 05:41:05+00:00,2021-04-28 03:38:24+00:00,AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance Detection for Fact Checking,"[arxiv.Result.Author('Tariq Alhindi'), arxiv.Result.Author('Amal Alabdulkarim'), arxiv.Result.Author('Ali Alshehri'), arxiv.Result.Author('Muhammad Abdul-Mageed'), arxiv.Result.Author('Preslav Nakov')]","With the continuing spread of misinformation and disinformation online, it is
of increasing importance to develop combating mechanisms at scale in the form
of automated systems that support multiple languages. One task of interest is
claim veracity prediction, which can be addressed using stance detection with
respect to relevant documents retrieved online. To this end, we present our new
Arabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from
a diverse set of sources comprising three fact-checking websites and one news
website. AraStance covers false and true claims from multiple domains (e.g.,
politics, sports, health) and several Arab countries, and it is well-balanced
between related and unrelated documents with respect to the claims. We
benchmark AraStance, along with two other stance detection datasets, using a
number of BERT-based models. Our best model achieves an accuracy of 85\% and a
macro F1 score of 78\%, which leaves room for improvement and reflects the
challenging nature of AraStance and the task of stance detection in general.","Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,
  and Propaganda",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.13559v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13559v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13559v2,"{'id': 'http://arxiv.org/abs/2104.13559v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13559v2', 'updated': '2021-05-18T05:41:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=18, tm_hour=5, tm_min=41, tm_sec=5, tm_wday=1, tm_yday=138, tm_isdst=0), 'published': '2021-04-28T03:38:24Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=28, tm_hour=3, tm_min=38, tm_sec=24, tm_wday=2, tm_yday=118, tm_isdst=0), 'title': 'AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking'}, 'summary': 'With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.'}, 'authors': [{'name': 'Tariq Alhindi'}, {'name': 'Amal Alabdulkarim'}, {'name': 'Ali Alshehri'}, {'name': 'Muhammad Abdul-Mageed'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,\n  and Propaganda', 'links': [{'href': 'http://arxiv.org/abs/2104.13559v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13559v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
94,http://arxiv.org/abs/2104.12918v1,2021-04-27 00:21:55+00:00,2021-04-27 00:21:55+00:00,Extractive and Abstractive Explanations for Fact-Checking and Evaluation of News,"[arxiv.Result.Author('Ashkan Kazemi'), arxiv.Result.Author('Zehua Li'), arxiv.Result.Author('Verónica Pérez-Rosas'), arxiv.Result.Author('Rada Mihalcea')]","In this paper, we explore the construction of natural language explanations
for news claims, with the goal of assisting fact-checking and news evaluation
applications. We experiment with two methods: (1) an extractive method based on
Biased TextRank -- a resource-effective unsupervised graph-based algorithm for
content extraction; and (2) an abstractive method based on the GPT-2 language
model. We perform comparative evaluations on two misinformation datasets in the
political and health news domains, and find that the extractive method shows
the most promise.",Accepted to NLP for Internet Freedom Workshop at NAACL 2021,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.12918v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.12918v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.12918v1,"{'id': 'http://arxiv.org/abs/2104.12918v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.12918v1', 'updated': '2021-04-27T00:21:55Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=27, tm_hour=0, tm_min=21, tm_sec=55, tm_wday=1, tm_yday=117, tm_isdst=0), 'published': '2021-04-27T00:21:55Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=27, tm_hour=0, tm_min=21, tm_sec=55, tm_wday=1, tm_yday=117, tm_isdst=0), 'title': 'Extractive and Abstractive Explanations for Fact-Checking and Evaluation\n  of News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Extractive and Abstractive Explanations for Fact-Checking and Evaluation\n  of News'}, 'summary': 'In this paper, we explore the construction of natural language explanations\nfor news claims, with the goal of assisting fact-checking and news evaluation\napplications. We experiment with two methods: (1) an extractive method based on\nBiased TextRank -- a resource-effective unsupervised graph-based algorithm for\ncontent extraction; and (2) an abstractive method based on the GPT-2 language\nmodel. We perform comparative evaluations on two misinformation datasets in the\npolitical and health news domains, and find that the extractive method shows\nthe most promise.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we explore the construction of natural language explanations\nfor news claims, with the goal of assisting fact-checking and news evaluation\napplications. We experiment with two methods: (1) an extractive method based on\nBiased TextRank -- a resource-effective unsupervised graph-based algorithm for\ncontent extraction; and (2) an abstractive method based on the GPT-2 language\nmodel. We perform comparative evaluations on two misinformation datasets in the\npolitical and health news domains, and find that the extractive method shows\nthe most promise.'}, 'authors': [{'name': 'Ashkan Kazemi'}, {'name': 'Zehua Li'}, {'name': 'Verónica Pérez-Rosas'}, {'name': 'Rada Mihalcea'}], 'author_detail': {'name': 'Rada Mihalcea'}, 'author': 'Rada Mihalcea', 'arxiv_comment': 'Accepted to NLP for Internet Freedom Workshop at NAACL 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.12918v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.12918v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
95,http://arxiv.org/abs/2104.12069v1,2021-04-25 05:56:57+00:00,2021-04-25 05:56:57+00:00,Making GAN-Generated Images Difficult To Spot: A New Attack Against Synthetic Image Detectors,"[arxiv.Result.Author('Xinwei Zhao'), arxiv.Result.Author('Matthew C. Stamm')]","Visually realistic GAN-generated images have recently emerged as an important
misinformation threat. Research has shown that these synthetic images contain
forensic traces that are readily identifiable by forensic detectors.
Unfortunately, these detectors are built upon neural networks, which are
vulnerable to recently developed adversarial attacks. In this paper, we propose
a new anti-forensic attack capable of fooling GAN-generated image detectors.
Our attack uses an adversarially trained generator to synthesize traces that
these detectors associate with real images. Furthermore, we propose a technique
to train our attack so that it can achieve transferability, i.e. it can fool
unknown CNNs that it was not explicitly trained against. We demonstrate the
performance of our attack through an extensive set of experiments, where we
show that our attack can fool eight state-of-the-art detection CNNs with
synthetic images created using seven different GANs.",,,,cs.CV,"['cs.CV', 'eess.IV']","[arxiv.Result.Link('http://arxiv.org/abs/2104.12069v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.12069v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.12069v1,"{'id': 'http://arxiv.org/abs/2104.12069v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.12069v1', 'updated': '2021-04-25T05:56:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=5, tm_min=56, tm_sec=57, tm_wday=6, tm_yday=115, tm_isdst=0), 'published': '2021-04-25T05:56:57Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=5, tm_min=56, tm_sec=57, tm_wday=6, tm_yday=115, tm_isdst=0), 'title': 'Making GAN-Generated Images Difficult To Spot: A New Attack Against\n  Synthetic Image Detectors', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Making GAN-Generated Images Difficult To Spot: A New Attack Against\n  Synthetic Image Detectors'}, 'summary': 'Visually realistic GAN-generated images have recently emerged as an important\nmisinformation threat. Research has shown that these synthetic images contain\nforensic traces that are readily identifiable by forensic detectors.\nUnfortunately, these detectors are built upon neural networks, which are\nvulnerable to recently developed adversarial attacks. In this paper, we propose\na new anti-forensic attack capable of fooling GAN-generated image detectors.\nOur attack uses an adversarially trained generator to synthesize traces that\nthese detectors associate with real images. Furthermore, we propose a technique\nto train our attack so that it can achieve transferability, i.e. it can fool\nunknown CNNs that it was not explicitly trained against. We demonstrate the\nperformance of our attack through an extensive set of experiments, where we\nshow that our attack can fool eight state-of-the-art detection CNNs with\nsynthetic images created using seven different GANs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Visually realistic GAN-generated images have recently emerged as an important\nmisinformation threat. Research has shown that these synthetic images contain\nforensic traces that are readily identifiable by forensic detectors.\nUnfortunately, these detectors are built upon neural networks, which are\nvulnerable to recently developed adversarial attacks. In this paper, we propose\na new anti-forensic attack capable of fooling GAN-generated image detectors.\nOur attack uses an adversarially trained generator to synthesize traces that\nthese detectors associate with real images. Furthermore, we propose a technique\nto train our attack so that it can achieve transferability, i.e. it can fool\nunknown CNNs that it was not explicitly trained against. We demonstrate the\nperformance of our attack through an extensive set of experiments, where we\nshow that our attack can fool eight state-of-the-art detection CNNs with\nsynthetic images created using seven different GANs.'}, 'authors': [{'name': 'Xinwei Zhao'}, {'name': 'Matthew C. Stamm'}], 'author_detail': {'name': 'Matthew C. Stamm'}, 'author': 'Matthew C. Stamm', 'links': [{'href': 'http://arxiv.org/abs/2104.12069v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.12069v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
96,http://arxiv.org/abs/2104.13352v2,2021-06-13 12:27:10+00:00,2021-04-24 08:54:02+00:00,Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of Red Fort Riots 2021,"[arxiv.Result.Author('Ajay Agarwal'), arxiv.Result.Author('Basant Agarwal')]","On 26 January 2021, India witnessed a national embarrassment from the
demographic least expected from - farmers. People across the nation watched in
horror as a pseudo-patriotic mob of farmers stormed capital Delhi and
vandalized the national pride- Red Fort. Investigations that followed the event
revealed the existence of a social media trail that led to the likes of such an
event. Consequently, it became essential and necessary to archive this trail
for social media analysis - not only to understand the bread-crumbs that are
dispersed across the trail but also to visualize the role played by
misinformation and fake news in this event. In this paper, we propose the
tractor2twitter dataset which contains around 0.05 million tweets that were
posted before, during, and after this event. Also, we benchmark our dataset
with an Explainable AI ML model for classification of each tweet into either of
the three categories - disinformation, misinformation, and opinion.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.13352v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.13352v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.13352v2,"{'id': 'http://arxiv.org/abs/2104.13352v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.13352v2', 'updated': '2021-06-13T12:27:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=13, tm_hour=12, tm_min=27, tm_sec=10, tm_wday=6, tm_yday=164, tm_isdst=0), 'published': '2021-04-24T08:54:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=24, tm_hour=8, tm_min=54, tm_sec=2, tm_wday=5, tm_yday=114, tm_isdst=0), 'title': 'Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021'}, 'summary': 'On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.'}, 'authors': [{'name': 'Ajay Agarwal'}, {'name': 'Basant Agarwal'}], 'author_detail': {'name': 'Basant Agarwal'}, 'author': 'Basant Agarwal', 'links': [{'href': 'http://arxiv.org/abs/2104.13352v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.13352v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
97,http://arxiv.org/abs/2104.11729v1,2021-04-23 17:25:38+00:00,2021-04-23 17:25:38+00:00,Evaluating Deception Detection Model Robustness To Linguistic Variation,"[arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Ellyn Ayton'), arxiv.Result.Author('Robin Cosbey'), arxiv.Result.Author('Dustin Arendt'), arxiv.Result.Author('Svitlana Volkova')]","With the increasing use of machine-learning driven algorithmic judgements, it
is critical to develop models that are robust to evolving or manipulated
inputs. We propose an extensive analysis of model robustness against linguistic
variation in the setting of deceptive news detection, an important task in the
context of misinformation spread online. We consider two prediction tasks and
compare three state-of-the-art embeddings to highlight consistent trends in
model performance, high confidence misclassifications, and high impact
failures. By measuring the effectiveness of adversarial defense strategies and
evaluating model susceptibility to adversarial attacks using character- and
word-perturbed text, we find that character or mixed ensemble models are the
most effective defenses and that character perturbation-based attack tactics
are more successful.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.11729v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.11729v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.11729v1,"{'id': 'http://arxiv.org/abs/2104.11729v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.11729v1', 'updated': '2021-04-23T17:25:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=23, tm_hour=17, tm_min=25, tm_sec=38, tm_wday=4, tm_yday=113, tm_isdst=0), 'published': '2021-04-23T17:25:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=23, tm_hour=17, tm_min=25, tm_sec=38, tm_wday=4, tm_yday=113, tm_isdst=0), 'title': 'Evaluating Deception Detection Model Robustness To Linguistic Variation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evaluating Deception Detection Model Robustness To Linguistic Variation'}, 'summary': 'With the increasing use of machine-learning driven algorithmic judgements, it\nis critical to develop models that are robust to evolving or manipulated\ninputs. We propose an extensive analysis of model robustness against linguistic\nvariation in the setting of deceptive news detection, an important task in the\ncontext of misinformation spread online. We consider two prediction tasks and\ncompare three state-of-the-art embeddings to highlight consistent trends in\nmodel performance, high confidence misclassifications, and high impact\nfailures. By measuring the effectiveness of adversarial defense strategies and\nevaluating model susceptibility to adversarial attacks using character- and\nword-perturbed text, we find that character or mixed ensemble models are the\nmost effective defenses and that character perturbation-based attack tactics\nare more successful.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the increasing use of machine-learning driven algorithmic judgements, it\nis critical to develop models that are robust to evolving or manipulated\ninputs. We propose an extensive analysis of model robustness against linguistic\nvariation in the setting of deceptive news detection, an important task in the\ncontext of misinformation spread online. We consider two prediction tasks and\ncompare three state-of-the-art embeddings to highlight consistent trends in\nmodel performance, high confidence misclassifications, and high impact\nfailures. By measuring the effectiveness of adversarial defense strategies and\nevaluating model susceptibility to adversarial attacks using character- and\nword-perturbed text, we find that character or mixed ensemble models are the\nmost effective defenses and that character perturbation-based attack tactics\nare more successful.'}, 'authors': [{'name': 'Maria Glenski'}, {'name': 'Ellyn Ayton'}, {'name': 'Robin Cosbey'}, {'name': 'Dustin Arendt'}, {'name': 'Svitlana Volkova'}], 'author_detail': {'name': 'Svitlana Volkova'}, 'author': 'Svitlana Volkova', 'links': [{'href': 'http://arxiv.org/abs/2104.11729v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.11729v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
98,http://arxiv.org/abs/2104.11639v2,2021-05-01 18:22:39+00:00,2021-04-23 14:45:31+00:00,Claim Detection in Biomedical Twitter Posts,"[arxiv.Result.Author('Amelie Wührl'), arxiv.Result.Author('Roman Klinger')]","Social media contains unfiltered and unique information, which is potentially
of great value, but, in the case of misinformation, can also do great harm.
With regards to biomedical topics, false information can be particularly
dangerous. Methods of automatic fact-checking and fake news detection address
this problem, but have not been applied to the biomedical domain in social
media yet. We aim to fill this research gap and annotate a corpus of 1200
tweets for implicit and explicit biomedical claims (the latter also with span
annotations for the claim phrase). With this corpus, which we sample to be
related to COVID-19, measles, cystic fibrosis, and depression, we develop
baseline models which detect tweets that contain a claim automatically. Our
analyses reveal that biomedical tweets are densely populated with claims (45 %
in a corpus sampled to contain 1200 tweets focused on the domains mentioned
above). Baseline classification experiments with embedding-based classifiers
and BERT-based transfer learning demonstrate that the detection is challenging,
however, shows acceptable performance for the identification of explicit
expressions of claims. Implicit claim tweets are more challenging to detect.",Accepted at the BioNLP Workshop at NAACL 2021,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.11639v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.11639v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.11639v2,"{'id': 'http://arxiv.org/abs/2104.11639v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.11639v2', 'updated': '2021-05-01T18:22:39Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=1, tm_hour=18, tm_min=22, tm_sec=39, tm_wday=5, tm_yday=121, tm_isdst=0), 'published': '2021-04-23T14:45:31Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=23, tm_hour=14, tm_min=45, tm_sec=31, tm_wday=4, tm_yday=113, tm_isdst=0), 'title': 'Claim Detection in Biomedical Twitter Posts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Claim Detection in Biomedical Twitter Posts'}, 'summary': 'Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.'}, 'authors': [{'name': 'Amelie Wührl'}, {'name': 'Roman Klinger'}], 'author_detail': {'name': 'Roman Klinger'}, 'author': 'Roman Klinger', 'arxiv_comment': 'Accepted at the BioNLP Workshop at NAACL 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.11639v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.11639v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
99,http://arxiv.org/abs/2104.10864v1,2021-04-22 05:09:25+00:00,2021-04-22 05:09:25+00:00,"Misinformation, Believability, and Vaccine Acceptance Over 40 Countries: Takeaways From the Initial Phase of The COVID-19 Infodemic","[arxiv.Result.Author('Karandeep Singh'), arxiv.Result.Author('Gabriel Lima'), arxiv.Result.Author('Meeyoung Cha'), arxiv.Result.Author('Chiyoung Cha'), arxiv.Result.Author('Juhi Kulshrestha'), arxiv.Result.Author('Yong-Yeol Ahn'), arxiv.Result.Author('Onur Varol')]","The COVID-19 pandemic has been damaging to the lives of people all around the
world. Accompanied by the pandemic is an infodemic, an abundant and
uncontrolled spreading of potentially harmful misinformation. The infodemic may
severely change the pandemic's course by interfering with public health
interventions such as wearing masks, social distancing, and vaccination. In
particular, the impact of the infodemic on vaccination is critical because it
holds the key to reverting to pre-pandemic normalcy. This paper presents
findings from a global survey on the extent of worldwide exposure to the
COVID-19 infodemic, assesses different populations' susceptibility to false
claims, and analyzes its association with vaccine acceptance. Based on
responses gathered from over 18,400 individuals from 40 countries, we find a
strong association between perceived believability of misinformation and
vaccination hesitancy. Additionally, our study shows that only half of the
online users exposed to rumors might have seen the fact-checked information.
Moreover, depending on the country, between 6% and 37% of individuals
considered these rumors believable. Our survey also shows that poorer regions
are more susceptible to encountering and believing COVID-19 misinformation. We
discuss implications of our findings on public campaigns that proactively
spread accurate information to countries that are more susceptible to the
infodemic. We also highlight fact-checking platforms' role in better
identifying and prioritizing claims that are perceived to be believable and
have wide exposure. Our findings give insights into better handling of risk
communication during the initial phase of a future pandemic.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2104.10864v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.10864v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.10864v1,"{'id': 'http://arxiv.org/abs/2104.10864v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.10864v1', 'updated': '2021-04-22T05:09:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=22, tm_hour=5, tm_min=9, tm_sec=25, tm_wday=3, tm_yday=112, tm_isdst=0), 'published': '2021-04-22T05:09:25Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=22, tm_hour=5, tm_min=9, tm_sec=25, tm_wday=3, tm_yday=112, tm_isdst=0), 'title': 'Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic'}, 'summary': ""The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic.""}, 'authors': [{'name': 'Karandeep Singh'}, {'name': 'Gabriel Lima'}, {'name': 'Meeyoung Cha'}, {'name': 'Chiyoung Cha'}, {'name': 'Juhi Kulshrestha'}, {'name': 'Yong-Yeol Ahn'}, {'name': 'Onur Varol'}], 'author_detail': {'name': 'Onur Varol'}, 'author': 'Onur Varol', 'links': [{'href': 'http://arxiv.org/abs/2104.10864v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.10864v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
100,http://arxiv.org/abs/2104.10635v2,2021-05-01 11:33:34+00:00,2021-04-21 16:59:54+00:00,The impact of online misinformation on U.S. COVID-19 vaccinations,"[arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Brea Perry'), arxiv.Result.Author('Matthew R. DeVerna'), arxiv.Result.Author('Kai-Cheng Yang'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('John Bryden')]","Widespread uptake of COVID-19 vaccines is necessary to achieve herd immunity.
However, surveys have found concerning numbers of U.S. adults hesitant or
unwilling to be vaccinated. Online misinformation may play an important role in
vaccine hesitancy, but we lack a clear picture of the extent to which it will
impact vaccination uptake. Here, we study how vaccination rates and vaccine
hesitancy are associated with levels of online misinformation about vaccines
shared by 1.6 million Twitter users geolocated at the U.S. state and county
levels. We find a negative relationship between misinformation and vaccination
uptake rates. Online misinformation is also correlated with vaccine hesitancy
rates taken from survey data. Associations between vaccine outcomes and
misinformation remain significant when accounting for political as well as
demographic and socioeconomic factors. While vaccine hesitancy is strongly
associated with Republican vote share, we observe that the effect of online
misinformation on hesitancy is strongest across Democratic rather than
Republican counties. These results suggest that addressing online
misinformation must be a key component of interventions aimed to maximize the
effectiveness of vaccination campaigns.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2104.10635v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.10635v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.10635v2,"{'id': 'http://arxiv.org/abs/2104.10635v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.10635v2', 'updated': '2021-05-01T11:33:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=1, tm_hour=11, tm_min=33, tm_sec=34, tm_wday=5, tm_yday=121, tm_isdst=0), 'published': '2021-04-21T16:59:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=21, tm_hour=16, tm_min=59, tm_sec=54, tm_wday=2, tm_yday=111, tm_isdst=0), 'title': 'The impact of online misinformation on U.S. COVID-19 vaccinations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The impact of online misinformation on U.S. COVID-19 vaccinations'}, 'summary': 'Widespread uptake of COVID-19 vaccines is necessary to achieve herd immunity.\nHowever, surveys have found concerning numbers of U.S. adults hesitant or\nunwilling to be vaccinated. Online misinformation may play an important role in\nvaccine hesitancy, but we lack a clear picture of the extent to which it will\nimpact vaccination uptake. Here, we study how vaccination rates and vaccine\nhesitancy are associated with levels of online misinformation about vaccines\nshared by 1.6 million Twitter users geolocated at the U.S. state and county\nlevels. We find a negative relationship between misinformation and vaccination\nuptake rates. Online misinformation is also correlated with vaccine hesitancy\nrates taken from survey data. Associations between vaccine outcomes and\nmisinformation remain significant when accounting for political as well as\ndemographic and socioeconomic factors. While vaccine hesitancy is strongly\nassociated with Republican vote share, we observe that the effect of online\nmisinformation on hesitancy is strongest across Democratic rather than\nRepublican counties. These results suggest that addressing online\nmisinformation must be a key component of interventions aimed to maximize the\neffectiveness of vaccination campaigns.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Widespread uptake of COVID-19 vaccines is necessary to achieve herd immunity.\nHowever, surveys have found concerning numbers of U.S. adults hesitant or\nunwilling to be vaccinated. Online misinformation may play an important role in\nvaccine hesitancy, but we lack a clear picture of the extent to which it will\nimpact vaccination uptake. Here, we study how vaccination rates and vaccine\nhesitancy are associated with levels of online misinformation about vaccines\nshared by 1.6 million Twitter users geolocated at the U.S. state and county\nlevels. We find a negative relationship between misinformation and vaccination\nuptake rates. Online misinformation is also correlated with vaccine hesitancy\nrates taken from survey data. Associations between vaccine outcomes and\nmisinformation remain significant when accounting for political as well as\ndemographic and socioeconomic factors. While vaccine hesitancy is strongly\nassociated with Republican vote share, we observe that the effect of online\nmisinformation on hesitancy is strongest across Democratic rather than\nRepublican counties. These results suggest that addressing online\nmisinformation must be a key component of interventions aimed to maximize the\neffectiveness of vaccination campaigns.'}, 'authors': [{'name': 'Francesco Pierri'}, {'name': 'Brea Perry'}, {'name': 'Matthew R. DeVerna'}, {'name': 'Kai-Cheng Yang'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}, {'name': 'John Bryden'}], 'author_detail': {'name': 'John Bryden'}, 'author': 'John Bryden', 'links': [{'href': 'http://arxiv.org/abs/2104.10635v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.10635v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
101,http://arxiv.org/abs/2104.11694v1,2021-04-20 23:19:43+00:00,2021-04-20 23:19:43+00:00,Mutual Hyperlinking Among Misinformation Peddlers,"[arxiv.Result.Author('Vibhor Sehgal'), arxiv.Result.Author('Ankit Peshin'), arxiv.Result.Author('Sadia Afroz'), arxiv.Result.Author('Hany Farid')]","The internet promised to democratize access to knowledge and make the world
more open and understanding. The reality of today's internet, however, is far
from this ideal. Misinformation, lies, and conspiracies dominate many social
media platforms. This toxic online world has had real-world implications
ranging from genocide to, election interference, and threats to global public
health. A frustrated public and impatient government regulators are calling for
a more vigorous response to mis- and disinformation campaigns designed to sow
civil unrest and inspire violence against individuals, societies, and
democracies. We describe a large-scale, domain-level analysis that reveals
seemingly coordinated efforts between multiple domains to spread and amplify
misinformation. We also describe how the hyperlinks shared by certain Twitter
users can be used to surface problematic domains. These analyses can be used by
search engines and social media recommendation algorithms to systematically
discover and demote misinformation peddlers.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.11694v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.11694v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.11694v1,"{'id': 'http://arxiv.org/abs/2104.11694v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.11694v1', 'updated': '2021-04-20T23:19:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=20, tm_hour=23, tm_min=19, tm_sec=43, tm_wday=1, tm_yday=110, tm_isdst=0), 'published': '2021-04-20T23:19:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=20, tm_hour=23, tm_min=19, tm_sec=43, tm_wday=1, tm_yday=110, tm_isdst=0), 'title': 'Mutual Hyperlinking Among Misinformation Peddlers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mutual Hyperlinking Among Misinformation Peddlers'}, 'summary': ""The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers.""}, 'authors': [{'name': 'Vibhor Sehgal'}, {'name': 'Ankit Peshin'}, {'name': 'Sadia Afroz'}, {'name': 'Hany Farid'}], 'author_detail': {'name': 'Hany Farid'}, 'author': 'Hany Farid', 'links': [{'href': 'http://arxiv.org/abs/2104.11694v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.11694v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
102,http://arxiv.org/abs/2104.08790v2,2021-10-14 05:41:42+00:00,2021-04-18 09:50:11+00:00,Misinfo Reaction Frames: Reasoning about Readers' Reactions to News Headlines,"[arxiv.Result.Author('Saadia Gabriel'), arxiv.Result.Author('Skyler Hallinan'), arxiv.Result.Author('Maarten Sap'), arxiv.Result.Author('Pemi Nguyen'), arxiv.Result.Author('Franziska Roesner'), arxiv.Result.Author('Eunsol Choi'), arxiv.Result.Author('Yejin Choi')]","Even to a simple and short news headline, readers react in a multitude of
ways: cognitively (e.g., inferring the writer's intent), emotionally (e.g.,
feeling distrust), and behaviorally (e.g., sharing the news with their
friends). Such reactions are instantaneous and yet complex, as they rely on
factors that go beyond interpreting the factual content the news headline.
Instead, understanding reactions require pragmatic understanding of the news
headline, including broader background knowledge about contentious news topics
as well as commonsense reasoning about people's intents and emotional
reactions. We propose Misinfo Reaction Frames, a pragmatic formalism for
modeling how readers might react to a news headline cognitively, emotionally,
and behaviorally. We also introduce a Misinfo Reaction Frames corpus, a dataset
of over 200k news headline annotated with crowdsourced reactions focusing on
global crises: the Covid-19 pandemic, climate change, and cancer. Empirical
results confirm that it is indeed possible to learn the prominent patterns of
readers' reactions to news headlines. We also find a potentially positive use
case of our model; When we present our model generated inferences to people, we
find that the machine inferences can increase readers' trust in real news while
decreasing their trust in misinformation. Our work demonstrates the feasibility
and the importance of pragmatic inferences of news to help enhance AI-guided
misinformation detection and mitigation.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.08790v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.08790v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.08790v2,"{'id': 'http://arxiv.org/abs/2104.08790v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.08790v2', 'updated': '2021-10-14T05:41:42Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=14, tm_hour=5, tm_min=41, tm_sec=42, tm_wday=3, tm_yday=287, tm_isdst=0), 'published': '2021-04-18T09:50:11Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=18, tm_hour=9, tm_min=50, tm_sec=11, tm_wday=6, tm_yday=108, tm_isdst=0), 'title': ""Misinfo Reaction Frames: Reasoning about Readers' Reactions to News\n  Headlines"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Misinfo Reaction Frames: Reasoning about Readers' Reactions to News\n  Headlines""}, 'summary': ""Even to a simple and short news headline, readers react in a multitude of\nways: cognitively (e.g., inferring the writer's intent), emotionally (e.g.,\nfeeling distrust), and behaviorally (e.g., sharing the news with their\nfriends). Such reactions are instantaneous and yet complex, as they rely on\nfactors that go beyond interpreting the factual content the news headline.\nInstead, understanding reactions require pragmatic understanding of the news\nheadline, including broader background knowledge about contentious news topics\nas well as commonsense reasoning about people's intents and emotional\nreactions. We propose Misinfo Reaction Frames, a pragmatic formalism for\nmodeling how readers might react to a news headline cognitively, emotionally,\nand behaviorally. We also introduce a Misinfo Reaction Frames corpus, a dataset\nof over 200k news headline annotated with crowdsourced reactions focusing on\nglobal crises: the Covid-19 pandemic, climate change, and cancer. Empirical\nresults confirm that it is indeed possible to learn the prominent patterns of\nreaders' reactions to news headlines. We also find a potentially positive use\ncase of our model; When we present our model generated inferences to people, we\nfind that the machine inferences can increase readers' trust in real news while\ndecreasing their trust in misinformation. Our work demonstrates the feasibility\nand the importance of pragmatic inferences of news to help enhance AI-guided\nmisinformation detection and mitigation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Even to a simple and short news headline, readers react in a multitude of\nways: cognitively (e.g., inferring the writer's intent), emotionally (e.g.,\nfeeling distrust), and behaviorally (e.g., sharing the news with their\nfriends). Such reactions are instantaneous and yet complex, as they rely on\nfactors that go beyond interpreting the factual content the news headline.\nInstead, understanding reactions require pragmatic understanding of the news\nheadline, including broader background knowledge about contentious news topics\nas well as commonsense reasoning about people's intents and emotional\nreactions. We propose Misinfo Reaction Frames, a pragmatic formalism for\nmodeling how readers might react to a news headline cognitively, emotionally,\nand behaviorally. We also introduce a Misinfo Reaction Frames corpus, a dataset\nof over 200k news headline annotated with crowdsourced reactions focusing on\nglobal crises: the Covid-19 pandemic, climate change, and cancer. Empirical\nresults confirm that it is indeed possible to learn the prominent patterns of\nreaders' reactions to news headlines. We also find a potentially positive use\ncase of our model; When we present our model generated inferences to people, we\nfind that the machine inferences can increase readers' trust in real news while\ndecreasing their trust in misinformation. Our work demonstrates the feasibility\nand the importance of pragmatic inferences of news to help enhance AI-guided\nmisinformation detection and mitigation.""}, 'authors': [{'name': 'Saadia Gabriel'}, {'name': 'Skyler Hallinan'}, {'name': 'Maarten Sap'}, {'name': 'Pemi Nguyen'}, {'name': 'Franziska Roesner'}, {'name': 'Eunsol Choi'}, {'name': 'Yejin Choi'}], 'author_detail': {'name': 'Yejin Choi'}, 'author': 'Yejin Choi', 'links': [{'href': 'http://arxiv.org/abs/2104.08790v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.08790v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
103,http://arxiv.org/abs/2104.12556v3,2021-08-04 10:37:23+00:00,2021-04-16 12:41:15+00:00,COVID-19 Modeling: A Review,"[arxiv.Result.Author('Longbing Cao'), arxiv.Result.Author('Qing Liu')]","The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and
overwhelming demand, challenges and opportunities to domain, model and data
driven modeling. This paper provides a comprehensive review of the challenges,
tasks, methods, progress, gaps and opportunities in relation to modeling
COVID-19 problems, data and objectives. It constructs a research landscape of
COVID-19 modeling tasks and methods, and further categorizes, summarizes,
compares and discusses the related methods and progress of modeling COVID-19
epidemic transmission processes and dynamics, case identification and tracing,
infection diagnosis and medical treatments, non-pharmaceutical interventions
and their effects, drug and vaccine development, psychological, economic and
social influence and impact, and misinformation, etc. The modeling methods
involve mathematical and statistical models, domain-driven modeling by
epidemiological compartmental models, medical and biomedical analysis, AI and
data science in particular shallow and deep machine learning, simulation
modeling, social science methods, and hybrid modeling.","73 pages, 3 figures, 9 tables",,,cs.CY,"['cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.12556v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.12556v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.12556v3,"{'id': 'http://arxiv.org/abs/2104.12556v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.12556v3', 'updated': '2021-08-04T10:37:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=4, tm_hour=10, tm_min=37, tm_sec=23, tm_wday=2, tm_yday=216, tm_isdst=0), 'published': '2021-04-16T12:41:15Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=16, tm_hour=12, tm_min=41, tm_sec=15, tm_wday=4, tm_yday=106, tm_isdst=0), 'title': 'COVID-19 Modeling: A Review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Modeling: A Review'}, 'summary': 'The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and\noverwhelming demand, challenges and opportunities to domain, model and data\ndriven modeling. This paper provides a comprehensive review of the challenges,\ntasks, methods, progress, gaps and opportunities in relation to modeling\nCOVID-19 problems, data and objectives. It constructs a research landscape of\nCOVID-19 modeling tasks and methods, and further categorizes, summarizes,\ncompares and discusses the related methods and progress of modeling COVID-19\nepidemic transmission processes and dynamics, case identification and tracing,\ninfection diagnosis and medical treatments, non-pharmaceutical interventions\nand their effects, drug and vaccine development, psychological, economic and\nsocial influence and impact, and misinformation, etc. The modeling methods\ninvolve mathematical and statistical models, domain-driven modeling by\nepidemiological compartmental models, medical and biomedical analysis, AI and\ndata science in particular shallow and deep machine learning, simulation\nmodeling, social science methods, and hybrid modeling.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and\noverwhelming demand, challenges and opportunities to domain, model and data\ndriven modeling. This paper provides a comprehensive review of the challenges,\ntasks, methods, progress, gaps and opportunities in relation to modeling\nCOVID-19 problems, data and objectives. It constructs a research landscape of\nCOVID-19 modeling tasks and methods, and further categorizes, summarizes,\ncompares and discusses the related methods and progress of modeling COVID-19\nepidemic transmission processes and dynamics, case identification and tracing,\ninfection diagnosis and medical treatments, non-pharmaceutical interventions\nand their effects, drug and vaccine development, psychological, economic and\nsocial influence and impact, and misinformation, etc. The modeling methods\ninvolve mathematical and statistical models, domain-driven modeling by\nepidemiological compartmental models, medical and biomedical analysis, AI and\ndata science in particular shallow and deep machine learning, simulation\nmodeling, social science methods, and hybrid modeling.'}, 'authors': [{'name': 'Longbing Cao'}, {'name': 'Qing Liu'}], 'author_detail': {'name': 'Qing Liu'}, 'author': 'Qing Liu', 'arxiv_comment': '73 pages, 3 figures, 9 tables', 'links': [{'href': 'http://arxiv.org/abs/2104.12556v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.12556v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
104,http://arxiv.org/abs/2104.07423v1,2021-04-15 12:39:37+00:00,2021-04-15 12:39:37+00:00,The Role of Context in Detecting Previously Fact-Checked Claims,"[arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Preslav Nakov')]","Recent years have seen the proliferation of disinformation and misinformation
online, thanks to the freedom of expression on the Internet and to the rise of
social media. Two solutions were proposed to address the problem: (i) manual
fact-checking, which is accurate and credible, but slow and non-scalable, and
(ii) automatic fact-checking, which is fast and scalable, but lacks
explainability and credibility. With the accumulation of enough manually
fact-checked claims, a middle-ground approach has emerged: checking whether a
given claim has previously been fact-checked. This can be made automatically,
and thus fast, while also offering credibility and explainability, thanks to
the human fact-checking and explanations in the associated fact-checking
article. This is a relatively new and understudied research direction, and here
we focus on claims made in a political debate, where context really matters.
Thus, we study the impact of modeling the context of the claim: both on the
source side, i.e., in the debate, as well as on the target side, i.e., in the
fact-checking explanation document. We do this by modeling the local context,
the global context, as well as by means of co-reference resolution, and
reasoning over the target text using Transformer-XH. The experimental results
show that each of these represents a valuable information source, but that
modeling the source-side context is more important, and can yield 10+ points of
absolute improvement.","detecting previously fact-checked claims, fact-checking,
  disinformation, fake news, social media, political debates",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG', 'cs.NE', '68T50', 'F.2.2; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2104.07423v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.07423v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.07423v1,"{'id': 'http://arxiv.org/abs/2104.07423v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.07423v1', 'updated': '2021-04-15T12:39:37Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=15, tm_hour=12, tm_min=39, tm_sec=37, tm_wday=3, tm_yday=105, tm_isdst=0), 'published': '2021-04-15T12:39:37Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=15, tm_hour=12, tm_min=39, tm_sec=37, tm_wday=3, tm_yday=105, tm_isdst=0), 'title': 'The Role of Context in Detecting Previously Fact-Checked Claims', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Role of Context in Detecting Previously Fact-Checked Claims'}, 'summary': 'Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.'}, 'authors': [{'name': 'Shaden Shaar'}, {'name': 'Firoj Alam'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates', 'links': [{'href': 'http://arxiv.org/abs/2104.07423v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.07423v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'F.2.2; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
105,http://arxiv.org/abs/2104.07175v2,2021-05-01 23:18:18+00:00,2021-04-15 00:25:52+00:00,Community-Based Fact-Checking on Twitter's Birdwatch Platform,[arxiv.Result.Author('Nicolas Pröllochs')],"Misinformation undermines the credibility of social media and poses
significant threats to modern societies. As a countermeasure, Twitter has
recently introduced ""Birdwatch,"" a community-driven approach to address
misinformation on Twitter. On Birdwatch, users can identify tweets they believe
are misleading, write notes that provide context to the tweet and rate the
quality of other users' notes. In this work, we empirically analyze how users
interact with this new feature. For this purpose, we collect all Birdwatch
notes and ratings since the introduction of the feature in early 2021. We then
map each Birdwatch note to the fact-checked tweet using Twitter's historical
API. In addition, we use text mining methods to extract content characteristics
from the text explanations in the Birdwatch notes (e.g., sentiment). Our
empirical analysis yields the following main findings: (i) users more
frequently file Birdwatch notes for misleading than not misleading tweets.
These misleading tweets are primarily reported because of factual errors, lack
of important context, or because they contain unverified claims. (ii) Birdwatch
notes are more helpful to other users if they link to trustworthy sources and
if they embed a more positive sentiment. (iii) The helpfulness of Birdwatch
notes depends on the social influence of the author of the fact-checked tweet.
For influential users with many followers, Birdwatch notes yield a lower level
of consensus among users and community-created fact checks are more likely to
be seen as being incorrect. Altogether, our findings can help social media
platforms to formulate guidelines for users on how to write more helpful fact
checks. At the same time, our analysis suggests that community-based
fact-checking faces challenges regarding biased views and polarization among
the user base.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2104.07175v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.07175v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.07175v2,"{'id': 'http://arxiv.org/abs/2104.07175v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.07175v2', 'updated': '2021-05-01T23:18:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=1, tm_hour=23, tm_min=18, tm_sec=18, tm_wday=5, tm_yday=121, tm_isdst=0), 'published': '2021-04-15T00:25:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=15, tm_hour=0, tm_min=25, tm_sec=52, tm_wday=3, tm_yday=105, tm_isdst=0), 'title': ""Community-Based Fact-Checking on Twitter's Birdwatch Platform"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Community-Based Fact-Checking on Twitter's Birdwatch Platform""}, 'summary': 'Misinformation undermines the credibility of social media and poses\nsignificant threats to modern societies. As a countermeasure, Twitter has\nrecently introduced ""Birdwatch,"" a community-driven approach to address\nmisinformation on Twitter. On Birdwatch, users can identify tweets they believe\nare misleading, write notes that provide context to the tweet and rate the\nquality of other users\' notes. In this work, we empirically analyze how users\ninteract with this new feature. For this purpose, we collect all Birdwatch\nnotes and ratings since the introduction of the feature in early 2021. We then\nmap each Birdwatch note to the fact-checked tweet using Twitter\'s historical\nAPI. In addition, we use text mining methods to extract content characteristics\nfrom the text explanations in the Birdwatch notes (e.g., sentiment). Our\nempirical analysis yields the following main findings: (i) users more\nfrequently file Birdwatch notes for misleading than not misleading tweets.\nThese misleading tweets are primarily reported because of factual errors, lack\nof important context, or because they contain unverified claims. (ii) Birdwatch\nnotes are more helpful to other users if they link to trustworthy sources and\nif they embed a more positive sentiment. (iii) The helpfulness of Birdwatch\nnotes depends on the social influence of the author of the fact-checked tweet.\nFor influential users with many followers, Birdwatch notes yield a lower level\nof consensus among users and community-created fact checks are more likely to\nbe seen as being incorrect. Altogether, our findings can help social media\nplatforms to formulate guidelines for users on how to write more helpful fact\nchecks. At the same time, our analysis suggests that community-based\nfact-checking faces challenges regarding biased views and polarization among\nthe user base.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation undermines the credibility of social media and poses\nsignificant threats to modern societies. As a countermeasure, Twitter has\nrecently introduced ""Birdwatch,"" a community-driven approach to address\nmisinformation on Twitter. On Birdwatch, users can identify tweets they believe\nare misleading, write notes that provide context to the tweet and rate the\nquality of other users\' notes. In this work, we empirically analyze how users\ninteract with this new feature. For this purpose, we collect all Birdwatch\nnotes and ratings since the introduction of the feature in early 2021. We then\nmap each Birdwatch note to the fact-checked tweet using Twitter\'s historical\nAPI. In addition, we use text mining methods to extract content characteristics\nfrom the text explanations in the Birdwatch notes (e.g., sentiment). Our\nempirical analysis yields the following main findings: (i) users more\nfrequently file Birdwatch notes for misleading than not misleading tweets.\nThese misleading tweets are primarily reported because of factual errors, lack\nof important context, or because they contain unverified claims. (ii) Birdwatch\nnotes are more helpful to other users if they link to trustworthy sources and\nif they embed a more positive sentiment. (iii) The helpfulness of Birdwatch\nnotes depends on the social influence of the author of the fact-checked tweet.\nFor influential users with many followers, Birdwatch notes yield a lower level\nof consensus among users and community-created fact checks are more likely to\nbe seen as being incorrect. Altogether, our findings can help social media\nplatforms to formulate guidelines for users on how to write more helpful fact\nchecks. At the same time, our analysis suggests that community-based\nfact-checking faces challenges regarding biased views and polarization among\nthe user base.'}, 'authors': [{'name': 'Nicolas Pröllochs'}], 'author_detail': {'name': 'Nicolas Pröllochs'}, 'author': 'Nicolas Pröllochs', 'links': [{'href': 'http://arxiv.org/abs/2104.07175v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.07175v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
106,http://arxiv.org/abs/2104.06952v1,2021-04-14 16:25:22+00:00,2021-04-14 16:25:22+00:00,The Surprising Performance of Simple Baselines for Misinformation Detection,"[arxiv.Result.Author('Kellin Pelrine'), arxiv.Result.Author('Jacob Danovitch'), arxiv.Result.Author('Reihaneh Rabbany')]","As social media becomes increasingly prominent in our day to day lives, it is
increasingly important to detect informative content and prevent the spread of
disinformation and unverified rumours. While many sophisticated and successful
models have been proposed in the literature, they are often compared with older
NLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the
performance of a broad set of modern transformer-based language models and show
that with basic fine-tuning, these models are competitive with and can even
significantly outperform recently proposed state-of-the-art methods. We present
our framework as a baseline for creating and evaluating new methods for
misinformation detection. We further study a comprehensive set of benchmark
datasets, and discuss potential data leakage and the need for careful design of
the experiments and understanding of datasets to account for confounding
variables. As an extreme case example, we show that classifying only based on
the first three digits of tweet ids, which contain information on the date,
gives state-of-the-art performance on a commonly used benchmark dataset for
fake news detection --Twitter16. We provide a simple tool to detect this
problem and suggest steps to mitigate it in future datasets.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.06952v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.06952v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.06952v1,"{'id': 'http://arxiv.org/abs/2104.06952v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.06952v1', 'updated': '2021-04-14T16:25:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=22, tm_wday=2, tm_yday=104, tm_isdst=0), 'published': '2021-04-14T16:25:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=16, tm_min=25, tm_sec=22, tm_wday=2, tm_yday=104, tm_isdst=0), 'title': 'The Surprising Performance of Simple Baselines for Misinformation\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Surprising Performance of Simple Baselines for Misinformation\n  Detection'}, 'summary': 'As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.'}, 'authors': [{'name': 'Kellin Pelrine'}, {'name': 'Jacob Danovitch'}, {'name': 'Reihaneh Rabbany'}], 'author_detail': {'name': 'Reihaneh Rabbany'}, 'author': 'Reihaneh Rabbany', 'links': [{'href': 'http://arxiv.org/abs/2104.06952v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.06952v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
107,http://arxiv.org/abs/2104.05893v2,2021-09-21 20:38:45+00:00,2021-04-13 01:53:26+00:00,NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media,"[arxiv.Result.Author('Grace Luo'), arxiv.Result.Author('Trevor Darrell'), arxiv.Result.Author('Anna Rohrbach')]","Online misinformation is a prevalent societal issue, with adversaries relying
on tools ranging from cheap fakes to sophisticated deep fakes. We are motivated
by the threat scenario where an image is used out of context to support a
certain narrative. While some prior datasets for detecting image-text
inconsistency generate samples via text manipulation, we propose a dataset
where both image and text are unmanipulated but mismatched. We introduce
several strategies for automatically retrieving convincing images for a given
caption, capturing cases with inconsistent entities or semantic context. Our
large-scale automatically generated NewsCLIPpings Dataset: (1) demonstrates
that machine-driven image repurposing is now a realistic threat, and (2)
provides samples that represent challenging instances of mismatch between text
and image in news that are able to mislead humans. We benchmark several
state-of-the-art multimodal models on our dataset and analyze their performance
across different pretraining domains and visual backbones.",EMNLP 2021,,,cs.CV,"['cs.CV', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2104.05893v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05893v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05893v2,"{'id': 'http://arxiv.org/abs/2104.05893v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05893v2', 'updated': '2021-09-21T20:38:45Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=21, tm_hour=20, tm_min=38, tm_sec=45, tm_wday=1, tm_yday=264, tm_isdst=0), 'published': '2021-04-13T01:53:26Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=13, tm_hour=1, tm_min=53, tm_sec=26, tm_wday=1, tm_yday=103, tm_isdst=0), 'title': 'NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media'}, 'summary': 'Online misinformation is a prevalent societal issue, with adversaries relying\non tools ranging from cheap fakes to sophisticated deep fakes. We are motivated\nby the threat scenario where an image is used out of context to support a\ncertain narrative. While some prior datasets for detecting image-text\ninconsistency generate samples via text manipulation, we propose a dataset\nwhere both image and text are unmanipulated but mismatched. We introduce\nseveral strategies for automatically retrieving convincing images for a given\ncaption, capturing cases with inconsistent entities or semantic context. Our\nlarge-scale automatically generated NewsCLIPpings Dataset: (1) demonstrates\nthat machine-driven image repurposing is now a realistic threat, and (2)\nprovides samples that represent challenging instances of mismatch between text\nand image in news that are able to mislead humans. We benchmark several\nstate-of-the-art multimodal models on our dataset and analyze their performance\nacross different pretraining domains and visual backbones.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online misinformation is a prevalent societal issue, with adversaries relying\non tools ranging from cheap fakes to sophisticated deep fakes. We are motivated\nby the threat scenario where an image is used out of context to support a\ncertain narrative. While some prior datasets for detecting image-text\ninconsistency generate samples via text manipulation, we propose a dataset\nwhere both image and text are unmanipulated but mismatched. We introduce\nseveral strategies for automatically retrieving convincing images for a given\ncaption, capturing cases with inconsistent entities or semantic context. Our\nlarge-scale automatically generated NewsCLIPpings Dataset: (1) demonstrates\nthat machine-driven image repurposing is now a realistic threat, and (2)\nprovides samples that represent challenging instances of mismatch between text\nand image in news that are able to mislead humans. We benchmark several\nstate-of-the-art multimodal models on our dataset and analyze their performance\nacross different pretraining domains and visual backbones.'}, 'authors': [{'name': 'Grace Luo'}, {'name': 'Trevor Darrell'}, {'name': 'Anna Rohrbach'}], 'author_detail': {'name': 'Anna Rohrbach'}, 'author': 'Anna Rohrbach', 'arxiv_comment': 'EMNLP 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.05893v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05893v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
108,http://arxiv.org/abs/2104.05866v1,2021-04-12 23:46:54+00:00,2021-04-12 23:46:54+00:00,On Representation Learning for Scientific News Articles Using Heterogeneous Knowledge Graphs,"[arxiv.Result.Author('Angelika Romanou'), arxiv.Result.Author('Panayiotis Smeros'), arxiv.Result.Author('Karl Aberer')]","In the era of misinformation and information inflation, the credibility
assessment of the produced news is of the essence. However, fact-checking can
be challenging considering the limited references presented in the news. This
challenge can be transcended by utilizing the knowledge graph that is related
to the news articles. In this work, we present a methodology for creating
scientific news article representations by modeling the directed graph between
the scientific news articles and the cited scientific publications. The network
used for the experiments is comprised of the scientific news articles, their
topic, the cited research literature, and their corresponding authors. We
implement and present three different approaches: 1) a baseline Relational
Graph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network
(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models
in the downstream task of link prediction on the: a) news article - paper links
and b) news article - article topic links. The results show promising
applications of graph neural network approaches in the domains of knowledge
tracing and scientific news credibility assessment.",,,10.1145/3442442.3451362,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3442442.3451362', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2104.05866v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05866v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05866v1,"{'id': 'http://arxiv.org/abs/2104.05866v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05866v1', 'updated': '2021-04-12T23:46:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=23, tm_min=46, tm_sec=54, tm_wday=0, tm_yday=102, tm_isdst=0), 'published': '2021-04-12T23:46:54Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=23, tm_min=46, tm_sec=54, tm_wday=0, tm_yday=102, tm_isdst=0), 'title': 'On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs'}, 'summary': 'In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.'}, 'authors': [{'name': 'Angelika Romanou'}, {'name': 'Panayiotis Smeros'}, {'name': 'Karl Aberer'}], 'author_detail': {'name': 'Karl Aberer'}, 'author': 'Karl Aberer', 'arxiv_doi': '10.1145/3442442.3451362', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3442442.3451362', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2104.05866v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05866v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
109,http://arxiv.org/abs/2104.05745v1,2021-04-12 18:13:40+00:00,2021-04-12 18:13:40+00:00,Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble,"[arxiv.Result.Author('Giorgos Tziafas'), arxiv.Result.Author('Konstantinos Kogkalidis'), arxiv.Result.Author('Tommaso Caselli')]","This paper describes the TOKOFOU system, an ensemble model for misinformation
detection tasks based on six different transformer-based pre-trained encoders,
implemented in the context of the COVID-19 Infodemic Shared Task for English.
We fine tune each model on each of the task's questions and aggregate their
prediction scores using a majority voting approach. TOKOFOU obtains an overall
F1 score of 89.7%, ranking first.","4 pages, NLP4IF 2021",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.05745v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05745v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05745v1,"{'id': 'http://arxiv.org/abs/2104.05745v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05745v1', 'updated': '2021-04-12T18:13:40Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=18, tm_min=13, tm_sec=40, tm_wday=0, tm_yday=102, tm_isdst=0), 'published': '2021-04-12T18:13:40Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=18, tm_min=13, tm_sec=40, tm_wday=0, tm_yday=102, tm_isdst=0), 'title': 'Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble'}, 'summary': ""This paper describes the TOKOFOU system, an ensemble model for misinformation\ndetection tasks based on six different transformer-based pre-trained encoders,\nimplemented in the context of the COVID-19 Infodemic Shared Task for English.\nWe fine tune each model on each of the task's questions and aggregate their\nprediction scores using a majority voting approach. TOKOFOU obtains an overall\nF1 score of 89.7%, ranking first."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper describes the TOKOFOU system, an ensemble model for misinformation\ndetection tasks based on six different transformer-based pre-trained encoders,\nimplemented in the context of the COVID-19 Infodemic Shared Task for English.\nWe fine tune each model on each of the task's questions and aggregate their\nprediction scores using a majority voting approach. TOKOFOU obtains an overall\nF1 score of 89.7%, ranking first.""}, 'authors': [{'name': 'Giorgos Tziafas'}, {'name': 'Konstantinos Kogkalidis'}, {'name': 'Tommaso Caselli'}], 'author_detail': {'name': 'Tommaso Caselli'}, 'author': 'Tommaso Caselli', 'arxiv_comment': '4 pages, NLP4IF 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.05745v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05745v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
110,http://arxiv.org/abs/2104.05321v1,2021-04-12 10:01:44+00:00,2021-04-12 10:01:44+00:00,Combining exogenous and endogenous signals with a semi-supervised co-attention network for early detection of COVID-19 fake tweets,"[arxiv.Result.Author('Rachit Bansal'), arxiv.Result.Author('William Scott Paka'), arxiv.Result.Author('Nidhi'), arxiv.Result.Author('Shubhashis Sengupta'), arxiv.Result.Author('Tanmoy Chakraborty')]","Fake tweets are observed to be ever-increasing, demanding immediate
countermeasures to combat their spread. During COVID-19, tweets with
misinformation should be flagged and neutralized in their early stages to
mitigate the damages. Most of the existing methods for early detection of fake
news assume to have enough propagation information for large labeled tweets --
which may not be an ideal setting for cases like COVID-19 where both aspects
are largely absent. In this work, we present ENDEMIC, a novel early detection
model which leverages exogenous and endogenous signals related to tweets, while
learning on limited labeled data. We first develop a novel dataset, called CTF
for early COVID-19 Twitter fake news, with additional behavioral test sets to
validate early detection. We build a heterogeneous graph with
follower-followee, user-tweet, and tweet-retweet connections and train a graph
embedding model to aggregate propagation information. Graph embeddings and
contextual features constitute endogenous, while time-relative web-scraped
information constitutes exogenous signals. ENDEMIC is trained in a
semi-supervised fashion, overcoming the challenge of limited labeled data. We
propose a co-attention mechanism to fuse signal representations optimally.
Experimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is
highly reliable in detecting early fake tweets, outperforming nine
state-of-the-art methods significantly.","Pacific-Asia Conference on Knowledge Discovery and Data Mining
  (PAKDD) 2021",,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.05321v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05321v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05321v1,"{'id': 'http://arxiv.org/abs/2104.05321v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05321v1', 'updated': '2021-04-12T10:01:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=10, tm_min=1, tm_sec=44, tm_wday=0, tm_yday=102, tm_isdst=0), 'published': '2021-04-12T10:01:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=10, tm_min=1, tm_sec=44, tm_wday=0, tm_yday=102, tm_isdst=0), 'title': 'Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets'}, 'summary': 'Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.'}, 'authors': [{'name': 'Rachit Bansal'}, {'name': 'William Scott Paka'}, {'name': 'Nidhi'}, {'name': 'Shubhashis Sengupta'}, {'name': 'Tanmoy Chakraborty'}], 'author_detail': {'name': 'Tanmoy Chakraborty'}, 'author': 'Tanmoy Chakraborty', 'arxiv_comment': 'Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.05321v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05321v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
111,http://arxiv.org/abs/2104.05243v1,2021-04-12 07:25:49+00:00,2021-04-12 07:25:49+00:00,On Unifying Misinformation Detection,"[arxiv.Result.Author('Nayeon Lee'), arxiv.Result.Author('Belinda Z. Li'), arxiv.Result.Author('Sinong Wang'), arxiv.Result.Author('Pascale Fung'), arxiv.Result.Author('Hao Ma'), arxiv.Result.Author('Wen-tau Yih'), arxiv.Result.Author('Madian Khabsa')]","In this paper, we introduce UnifiedM2, a general-purpose misinformation model
that jointly models multiple domains of misinformation with a single, unified
setup. The model is trained to handle four tasks: detecting news bias,
clickbait, fake news, and verifying rumors. By grouping these tasks together,
UnifiedM2learns a richer representation of misinformation, which leads to
state-of-the-art or comparable performance across all tasks. Furthermore, we
demonstrate that UnifiedM2's learned representation is helpful for few-shot
learning of unseen misinformation tasks/datasets and model's generalizability
to unseen events.",Accepted to NAACL2021,,,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2104.05243v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.05243v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.05243v1,"{'id': 'http://arxiv.org/abs/2104.05243v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.05243v1', 'updated': '2021-04-12T07:25:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=7, tm_min=25, tm_sec=49, tm_wday=0, tm_yday=102, tm_isdst=0), 'published': '2021-04-12T07:25:49Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=12, tm_hour=7, tm_min=25, tm_sec=49, tm_wday=0, tm_yday=102, tm_isdst=0), 'title': 'On Unifying Misinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On Unifying Misinformation Detection'}, 'summary': ""In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.""}, 'authors': [{'name': 'Nayeon Lee'}, {'name': 'Belinda Z. Li'}, {'name': 'Sinong Wang'}, {'name': 'Pascale Fung'}, {'name': 'Hao Ma'}, {'name': 'Wen-tau Yih'}, {'name': 'Madian Khabsa'}], 'author_detail': {'name': 'Madian Khabsa'}, 'author': 'Madian Khabsa', 'arxiv_comment': 'Accepted to NAACL2021', 'links': [{'href': 'http://arxiv.org/abs/2104.05243v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.05243v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
112,http://arxiv.org/abs/2104.04389v1,2021-04-09 14:22:52+00:00,2021-04-09 14:22:52+00:00,A Few Observations About State-Centric Online Propaganda,[arxiv.Result.Author('Jukka Ruohonen')],"This paper presents a few observations about pro-Kremlin propaganda between
2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),
which is affiliated with the European Union (EU) but working independently from
it. Instead of focusing on misinformation and disinformation, the observations
are motivated by classical propaganda research and the ongoing transformation
of media systems. According to the tentative results, (i) the propaganda can be
assumed to target both domestic and foreign audiences. Of the countries and
regions discussed, (ii) Russia, Ukraine, the United States, and within Europe,
Germany, Poland, and the EU have been the most frequently discussed. Also other
conflict regions such as Syria have often appeared in the propaganda. In terms
of longitudinal trends, however, (iii) most of these discussions have decreased
in volume after the digital tsunami in 2016, although the conflict in Ukraine
seems to have again increased the intensity of pro-Kremlin propaganda. Finally,
(iv) the themes discussed align with state-centric war propaganda and conflict
zones, although also post-truth themes frequently appear; from conspiracy
theories via COVID-19 to fascism -- anything goes, as is typical to propaganda.",Submitted,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2104.04389v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04389v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04389v1,"{'id': 'http://arxiv.org/abs/2104.04389v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04389v1', 'updated': '2021-04-09T14:22:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=14, tm_min=22, tm_sec=52, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2021-04-09T14:22:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=14, tm_min=22, tm_sec=52, tm_wday=4, tm_yday=99, tm_isdst=0), 'title': 'A Few Observations About State-Centric Online Propaganda', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Few Observations About State-Centric Online Propaganda'}, 'summary': 'This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.'}, 'authors': [{'name': 'Jukka Ruohonen'}], 'author_detail': {'name': 'Jukka Ruohonen'}, 'author': 'Jukka Ruohonen', 'arxiv_comment': 'Submitted', 'links': [{'href': 'http://arxiv.org/abs/2104.04389v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04389v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
113,http://arxiv.org/abs/2104.04331v1,2021-04-09 12:29:34+00:00,2021-04-09 12:29:34+00:00,The Burden of Being a Bridge: Understanding the Role of Multilingual Users during the COVID-19 Pandemic,"[arxiv.Result.Author('Ninghan Chen'), arxiv.Result.Author('Xihui Chen'), arxiv.Result.Author('Zhiqiang Zhong'), arxiv.Result.Author('Jun Pang')]","The outbreak of the COVID-19 pandemic triggers infodemic over online social
networks. It is thus important for governments to ensure their official
messages outpace misinformation and efficiently reach the public. Some
countries and regions that are currently worst affected by the virus including
Europe, South America and India, encounter an additional difficulty:
multilingualism. Understanding the specific role of multilingual users in the
process of information diffusion is critical to adjust their publishing
strategies for the governments of such countries and regions. In this paper, we
investigate the role of multilingual users in diffusing information during the
COVID-19 pandemic on popular social networks. We collect a large-scale dataset
of Twitter from a populated multilingual region from the beginning of the
pandemic. With this dataset, we successfully show that multilingual users act
as bridges in diffusing COVID-19 related information. We further study the
mental health of multilingual users and show that being the bridges,
multilingual users tend to be more negative. This is confirmed by a recent
psychological study stating that excessive exposure to social media may result
in a negative mood.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2104.04331v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04331v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04331v1,"{'id': 'http://arxiv.org/abs/2104.04331v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04331v1', 'updated': '2021-04-09T12:29:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=12, tm_min=29, tm_sec=34, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2021-04-09T12:29:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=12, tm_min=29, tm_sec=34, tm_wday=4, tm_yday=99, tm_isdst=0), 'title': 'The Burden of Being a Bridge: Understanding the Role of Multilingual\n  Users during the COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Burden of Being a Bridge: Understanding the Role of Multilingual\n  Users during the COVID-19 Pandemic'}, 'summary': 'The outbreak of the COVID-19 pandemic triggers infodemic over online social\nnetworks. It is thus important for governments to ensure their official\nmessages outpace misinformation and efficiently reach the public. Some\ncountries and regions that are currently worst affected by the virus including\nEurope, South America and India, encounter an additional difficulty:\nmultilingualism. Understanding the specific role of multilingual users in the\nprocess of information diffusion is critical to adjust their publishing\nstrategies for the governments of such countries and regions. In this paper, we\ninvestigate the role of multilingual users in diffusing information during the\nCOVID-19 pandemic on popular social networks. We collect a large-scale dataset\nof Twitter from a populated multilingual region from the beginning of the\npandemic. With this dataset, we successfully show that multilingual users act\nas bridges in diffusing COVID-19 related information. We further study the\nmental health of multilingual users and show that being the bridges,\nmultilingual users tend to be more negative. This is confirmed by a recent\npsychological study stating that excessive exposure to social media may result\nin a negative mood.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The outbreak of the COVID-19 pandemic triggers infodemic over online social\nnetworks. It is thus important for governments to ensure their official\nmessages outpace misinformation and efficiently reach the public. Some\ncountries and regions that are currently worst affected by the virus including\nEurope, South America and India, encounter an additional difficulty:\nmultilingualism. Understanding the specific role of multilingual users in the\nprocess of information diffusion is critical to adjust their publishing\nstrategies for the governments of such countries and regions. In this paper, we\ninvestigate the role of multilingual users in diffusing information during the\nCOVID-19 pandemic on popular social networks. We collect a large-scale dataset\nof Twitter from a populated multilingual region from the beginning of the\npandemic. With this dataset, we successfully show that multilingual users act\nas bridges in diffusing COVID-19 related information. We further study the\nmental health of multilingual users and show that being the bridges,\nmultilingual users tend to be more negative. This is confirmed by a recent\npsychological study stating that excessive exposure to social media may result\nin a negative mood.'}, 'authors': [{'name': 'Ninghan Chen'}, {'name': 'Xihui Chen'}, {'name': 'Zhiqiang Zhong'}, {'name': 'Jun Pang'}], 'author_detail': {'name': 'Jun Pang'}, 'author': 'Jun Pang', 'links': [{'href': 'http://arxiv.org/abs/2104.04331v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04331v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
114,http://arxiv.org/abs/2104.04311v1,2021-04-09 11:33:02+00:00,2021-04-09 11:33:02+00:00,Helping People Deal With Disinformation -- A Socio-Technical Perspective,[arxiv.Result.Author('Hendrik Heuer')],"At the latest since the advent of the Internet, disinformation and conspiracy
theories have become ubiquitous. Recent examples like QAnon and Pizzagate prove
that false information can lead to real violence. In this motivation statement
for the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my
research agenda focused on 1. why people believe in disinformation, 2. how
people can be best supported in recognizing disinformation, and 3. what the
potentials and risks of different tools designed to fight disinformation are.","This paper will be presented at the Workshop on Human Aspects of
  Misinformation at CHI 2021",,,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2104.04311v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04311v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04311v1,"{'id': 'http://arxiv.org/abs/2104.04311v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04311v1', 'updated': '2021-04-09T11:33:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=11, tm_min=33, tm_sec=2, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2021-04-09T11:33:02Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=11, tm_min=33, tm_sec=2, tm_wday=4, tm_yday=99, tm_isdst=0), 'title': 'Helping People Deal With Disinformation -- A Socio-Technical Perspective', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Helping People Deal With Disinformation -- A Socio-Technical Perspective'}, 'summary': 'At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.'}, 'authors': [{'name': 'Hendrik Heuer'}], 'author_detail': {'name': 'Hendrik Heuer'}, 'author': 'Hendrik Heuer', 'arxiv_comment': 'This paper will be presented at the Workshop on Human Aspects of\n  Misinformation at CHI 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.04311v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04311v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
115,http://arxiv.org/abs/2104.02752v1,2021-04-06 19:23:44+00:00,2021-04-06 19:23:44+00:00,Multiscale Governance,"[arxiv.Result.Author('David Pastor-Escuredo'), arxiv.Result.Author('Philip Treleaven')]","Future societal systems will be characterized by heterogeneous human
behaviors and also collective action. The interaction between local systems and
global systems will be complex. Humandemics will propagate because of the
pathways that connect the different systems and several invariant behaviors and
patterns that have emerged globally. On the contrary, infodemics of
misinformation can be a risk as it has occurred in the COVID-19 pandemic. The
emerging fragility or robustness of the system will depend on how this complex
network of systems is governed. Future societal systems will not be only
multiscale in terms of the social dimension, but also in the temporality.
Necessary and proper prevention and response systems based on complexity, ethic
and multi-scale governance will be required. Real-time response systems are the
basis for resilience to be the foundation of robust societies. A top-down
approach led by Governmental organs for managing humandemics is not sufficient
and may be only effective if policies are very restrictive and their efficacy
depends not only in the measures implemented but also on the dynamics of the
policies and the population perception and compliance. This top-down approach
is even weaker if there is not national and international coordination.
Coordinating top-down agencies with bottom-up constructs will be the design
principle. Multi-scale governance integrates decision-making processes with
signaling, sensing and leadership mechanisms to drive thriving societal systems
with real-time sensitivity.",,,,cs.CY,"['cs.CY', 'cs.CC', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/2104.02752v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.02752v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.02752v1,"{'id': 'http://arxiv.org/abs/2104.02752v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.02752v1', 'updated': '2021-04-06T19:23:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=6, tm_hour=19, tm_min=23, tm_sec=44, tm_wday=1, tm_yday=96, tm_isdst=0), 'published': '2021-04-06T19:23:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=6, tm_hour=19, tm_min=23, tm_sec=44, tm_wday=1, tm_yday=96, tm_isdst=0), 'title': 'Multiscale Governance', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multiscale Governance'}, 'summary': 'Future societal systems will be characterized by heterogeneous human\nbehaviors and also collective action. The interaction between local systems and\nglobal systems will be complex. Humandemics will propagate because of the\npathways that connect the different systems and several invariant behaviors and\npatterns that have emerged globally. On the contrary, infodemics of\nmisinformation can be a risk as it has occurred in the COVID-19 pandemic. The\nemerging fragility or robustness of the system will depend on how this complex\nnetwork of systems is governed. Future societal systems will not be only\nmultiscale in terms of the social dimension, but also in the temporality.\nNecessary and proper prevention and response systems based on complexity, ethic\nand multi-scale governance will be required. Real-time response systems are the\nbasis for resilience to be the foundation of robust societies. A top-down\napproach led by Governmental organs for managing humandemics is not sufficient\nand may be only effective if policies are very restrictive and their efficacy\ndepends not only in the measures implemented but also on the dynamics of the\npolicies and the population perception and compliance. This top-down approach\nis even weaker if there is not national and international coordination.\nCoordinating top-down agencies with bottom-up constructs will be the design\nprinciple. Multi-scale governance integrates decision-making processes with\nsignaling, sensing and leadership mechanisms to drive thriving societal systems\nwith real-time sensitivity.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Future societal systems will be characterized by heterogeneous human\nbehaviors and also collective action. The interaction between local systems and\nglobal systems will be complex. Humandemics will propagate because of the\npathways that connect the different systems and several invariant behaviors and\npatterns that have emerged globally. On the contrary, infodemics of\nmisinformation can be a risk as it has occurred in the COVID-19 pandemic. The\nemerging fragility or robustness of the system will depend on how this complex\nnetwork of systems is governed. Future societal systems will not be only\nmultiscale in terms of the social dimension, but also in the temporality.\nNecessary and proper prevention and response systems based on complexity, ethic\nand multi-scale governance will be required. Real-time response systems are the\nbasis for resilience to be the foundation of robust societies. A top-down\napproach led by Governmental organs for managing humandemics is not sufficient\nand may be only effective if policies are very restrictive and their efficacy\ndepends not only in the measures implemented but also on the dynamics of the\npolicies and the population perception and compliance. This top-down approach\nis even weaker if there is not national and international coordination.\nCoordinating top-down agencies with bottom-up constructs will be the design\nprinciple. Multi-scale governance integrates decision-making processes with\nsignaling, sensing and leadership mechanisms to drive thriving societal systems\nwith real-time sensitivity.'}, 'authors': [{'name': 'David Pastor-Escuredo'}, {'name': 'Philip Treleaven'}], 'author_detail': {'name': 'Philip Treleaven'}, 'author': 'Philip Treleaven', 'links': [{'href': 'http://arxiv.org/abs/2104.02752v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.02752v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
116,http://arxiv.org/abs/2104.01828v1,2021-04-05 09:45:14+00:00,2021-04-05 09:45:14+00:00,When Can Liquid Democracy Unveil the Truth?,"[arxiv.Result.Author('Ruben Becker'), arxiv.Result.Author(""Gianlorenzo D'Angelo""), arxiv.Result.Author('Esmaeil Delfaraz'), arxiv.Result.Author('Hugo Gilbert')]","In this paper, we investigate the so-called ODP-problem that has been
formulated by Caragiannis and Micha [10]. Here, we are in a setting with two
election alternatives out of which one is assumed to be correct. In ODP, the
goal is to organise the delegations in the social network in order to maximize
the probability that the correct alternative, referred to as ground truth, is
elected. While the problem is known to be computationally hard, we strengthen
existing hardness results by providing a novel strong approximation hardness
result: For any positive constant $C$, we prove that, unless $P=NP$, there is
no polynomial-time algorithm for ODP that achieves an approximation guarantee
of $\alpha \ge (\ln n)^{-C}$, where $n$ is the number of voters. The reduction
designed for this result uses poorly connected social networks in which some
voters suffer from misinformation. Interestingly, under some hypothesis on
either the accuracies of voters or the connectivity of the network, we obtain a
polynomial-time $1/2$-approximation algorithm. This observation proves formally
that the connectivity of the social network is a key feature for the efficiency
of the liquid democracy paradigm. Lastly, we run extensive simulations and
observe that simple algorithms (working either in a centralized or
decentralized way) outperform direct democracy on a large class of instances.
Overall, our contributions yield new insights on the question in which
situations liquid democracy can be beneficial.",,,,cs.GT,"['cs.GT', 'cs.AI', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.01828v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.01828v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.01828v1,"{'id': 'http://arxiv.org/abs/2104.01828v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.01828v1', 'updated': '2021-04-05T09:45:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=5, tm_hour=9, tm_min=45, tm_sec=14, tm_wday=0, tm_yday=95, tm_isdst=0), 'published': '2021-04-05T09:45:14Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=5, tm_hour=9, tm_min=45, tm_sec=14, tm_wday=0, tm_yday=95, tm_isdst=0), 'title': 'When Can Liquid Democracy Unveil the Truth?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'When Can Liquid Democracy Unveil the Truth?'}, 'summary': 'In this paper, we investigate the so-called ODP-problem that has been\nformulated by Caragiannis and Micha [10]. Here, we are in a setting with two\nelection alternatives out of which one is assumed to be correct. In ODP, the\ngoal is to organise the delegations in the social network in order to maximize\nthe probability that the correct alternative, referred to as ground truth, is\nelected. While the problem is known to be computationally hard, we strengthen\nexisting hardness results by providing a novel strong approximation hardness\nresult: For any positive constant $C$, we prove that, unless $P=NP$, there is\nno polynomial-time algorithm for ODP that achieves an approximation guarantee\nof $\\alpha \\ge (\\ln n)^{-C}$, where $n$ is the number of voters. The reduction\ndesigned for this result uses poorly connected social networks in which some\nvoters suffer from misinformation. Interestingly, under some hypothesis on\neither the accuracies of voters or the connectivity of the network, we obtain a\npolynomial-time $1/2$-approximation algorithm. This observation proves formally\nthat the connectivity of the social network is a key feature for the efficiency\nof the liquid democracy paradigm. Lastly, we run extensive simulations and\nobserve that simple algorithms (working either in a centralized or\ndecentralized way) outperform direct democracy on a large class of instances.\nOverall, our contributions yield new insights on the question in which\nsituations liquid democracy can be beneficial.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we investigate the so-called ODP-problem that has been\nformulated by Caragiannis and Micha [10]. Here, we are in a setting with two\nelection alternatives out of which one is assumed to be correct. In ODP, the\ngoal is to organise the delegations in the social network in order to maximize\nthe probability that the correct alternative, referred to as ground truth, is\nelected. While the problem is known to be computationally hard, we strengthen\nexisting hardness results by providing a novel strong approximation hardness\nresult: For any positive constant $C$, we prove that, unless $P=NP$, there is\nno polynomial-time algorithm for ODP that achieves an approximation guarantee\nof $\\alpha \\ge (\\ln n)^{-C}$, where $n$ is the number of voters. The reduction\ndesigned for this result uses poorly connected social networks in which some\nvoters suffer from misinformation. Interestingly, under some hypothesis on\neither the accuracies of voters or the connectivity of the network, we obtain a\npolynomial-time $1/2$-approximation algorithm. This observation proves formally\nthat the connectivity of the social network is a key feature for the efficiency\nof the liquid democracy paradigm. Lastly, we run extensive simulations and\nobserve that simple algorithms (working either in a centralized or\ndecentralized way) outperform direct democracy on a large class of instances.\nOverall, our contributions yield new insights on the question in which\nsituations liquid democracy can be beneficial.'}, 'authors': [{'name': 'Ruben Becker'}, {'name': ""Gianlorenzo D'Angelo""}, {'name': 'Esmaeil Delfaraz'}, {'name': 'Hugo Gilbert'}], 'author_detail': {'name': 'Hugo Gilbert'}, 'author': 'Hugo Gilbert', 'links': [{'href': 'http://arxiv.org/abs/2104.01828v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.01828v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
117,http://arxiv.org/abs/2104.01215v1,2021-04-02 19:27:53+00:00,2021-04-02 19:27:53+00:00,The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked Stories,"[arxiv.Result.Author('Lynnette Hui Xian Ng'), arxiv.Result.Author('Kathleen M. Carley')]","The 2020 coronavirus pandemic has heightened the need to flag
coronavirus-related misinformation, and fact-checking groups have taken to
verifying misinformation on the Internet. We explore stories reported by
fact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,
characterising them into six story clusters before then analyse time-series and
story validity trends and the level of agreement across sites. We further break
down the story clusters into more granular story types by proposing a unique
automated method with a BERT classifier, which can be used to classify diverse
story sources, in both fact-checked stories and tweets.",,SBP-Brims 2020 COVID Special Track,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2104.01215v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.01215v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.01215v1,"{'id': 'http://arxiv.org/abs/2104.01215v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.01215v1', 'updated': '2021-04-02T19:27:53Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=2, tm_hour=19, tm_min=27, tm_sec=53, tm_wday=4, tm_yday=92, tm_isdst=0), 'published': '2021-04-02T19:27:53Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=2, tm_hour=19, tm_min=27, tm_sec=53, tm_wday=4, tm_yday=92, tm_isdst=0), 'title': 'The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked\n  Stories', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked\n  Stories'}, 'summary': 'The 2020 coronavirus pandemic has heightened the need to flag\ncoronavirus-related misinformation, and fact-checking groups have taken to\nverifying misinformation on the Internet. We explore stories reported by\nfact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,\ncharacterising them into six story clusters before then analyse time-series and\nstory validity trends and the level of agreement across sites. We further break\ndown the story clusters into more granular story types by proposing a unique\nautomated method with a BERT classifier, which can be used to classify diverse\nstory sources, in both fact-checked stories and tweets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The 2020 coronavirus pandemic has heightened the need to flag\ncoronavirus-related misinformation, and fact-checking groups have taken to\nverifying misinformation on the Internet. We explore stories reported by\nfact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,\ncharacterising them into six story clusters before then analyse time-series and\nstory validity trends and the level of agreement across sites. We further break\ndown the story clusters into more granular story types by proposing a unique\nautomated method with a BERT classifier, which can be used to classify diverse\nstory sources, in both fact-checked stories and tweets.'}, 'authors': [{'name': 'Lynnette Hui Xian Ng'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_journal_ref': 'SBP-Brims 2020 COVID Special Track', 'links': [{'href': 'http://arxiv.org/abs/2104.01215v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.01215v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
118,http://arxiv.org/abs/2104.01140v1,2021-04-02 16:39:23+00:00,2021-04-02 16:39:23+00:00,The polarising effect of Review Bomb,"[arxiv.Result.Author('Venera Tomaselli'), arxiv.Result.Author('Giulio Giacomo Cantone'), arxiv.Result.Author('Valeria Mazzeo')]","This study discusses the Review Bomb, a phenomenon consisting of a massive
attack by groups of Internet users on a website that displays users' review on
products. It gained attention, especially on websites that aggregate numerical
ratings. Although this phenomenon can be considered an example of online
misinformation, it differs from conventional spam review, which happens within
larger time spans. In particular, the Bomb occurs suddenly and for a short
time, because in this way it leverages the notorious problem of cold-start: if
reviews are submitted by a lot of fresh new accounts, it makes hard to justify
preventative measures. The present research work is focused on the case of The
Last of Us Part II, a video game published by Sony, that was the target of the
widest phenomenon of Review Bomb, occurred in June 2020. By performing an
observational analysis of a linguistic corpus of English reviews and the
features of its users, this study confirms that the Bomb was an ideological
attack aimed at breaking down the rating system of the platform Metacritic.
Evidence supports that the bombing had the unintended consequence to induce a
reaction from users, ending into a consistent polarisation of ratings towards
extreme values. The results not only display the theory of polarity in online
reviews, but them also provide insights for the research on the problem of
cold-start detection of spam review. In particular, it illustrates the
relevance of detecting users discussing contextual elements instead of the
product and users with anomalous features.",,,,cs.CY,"['cs.CY', 'cs.SI', 'stat.AP']","[arxiv.Result.Link('http://arxiv.org/abs/2104.01140v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.01140v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.01140v1,"{'id': 'http://arxiv.org/abs/2104.01140v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.01140v1', 'updated': '2021-04-02T16:39:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=2, tm_hour=16, tm_min=39, tm_sec=23, tm_wday=4, tm_yday=92, tm_isdst=0), 'published': '2021-04-02T16:39:23Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=2, tm_hour=16, tm_min=39, tm_sec=23, tm_wday=4, tm_yday=92, tm_isdst=0), 'title': 'The polarising effect of Review Bomb', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The polarising effect of Review Bomb'}, 'summary': ""This study discusses the Review Bomb, a phenomenon consisting of a massive\nattack by groups of Internet users on a website that displays users' review on\nproducts. It gained attention, especially on websites that aggregate numerical\nratings. Although this phenomenon can be considered an example of online\nmisinformation, it differs from conventional spam review, which happens within\nlarger time spans. In particular, the Bomb occurs suddenly and for a short\ntime, because in this way it leverages the notorious problem of cold-start: if\nreviews are submitted by a lot of fresh new accounts, it makes hard to justify\npreventative measures. The present research work is focused on the case of The\nLast of Us Part II, a video game published by Sony, that was the target of the\nwidest phenomenon of Review Bomb, occurred in June 2020. By performing an\nobservational analysis of a linguistic corpus of English reviews and the\nfeatures of its users, this study confirms that the Bomb was an ideological\nattack aimed at breaking down the rating system of the platform Metacritic.\nEvidence supports that the bombing had the unintended consequence to induce a\nreaction from users, ending into a consistent polarisation of ratings towards\nextreme values. The results not only display the theory of polarity in online\nreviews, but them also provide insights for the research on the problem of\ncold-start detection of spam review. In particular, it illustrates the\nrelevance of detecting users discussing contextual elements instead of the\nproduct and users with anomalous features."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This study discusses the Review Bomb, a phenomenon consisting of a massive\nattack by groups of Internet users on a website that displays users' review on\nproducts. It gained attention, especially on websites that aggregate numerical\nratings. Although this phenomenon can be considered an example of online\nmisinformation, it differs from conventional spam review, which happens within\nlarger time spans. In particular, the Bomb occurs suddenly and for a short\ntime, because in this way it leverages the notorious problem of cold-start: if\nreviews are submitted by a lot of fresh new accounts, it makes hard to justify\npreventative measures. The present research work is focused on the case of The\nLast of Us Part II, a video game published by Sony, that was the target of the\nwidest phenomenon of Review Bomb, occurred in June 2020. By performing an\nobservational analysis of a linguistic corpus of English reviews and the\nfeatures of its users, this study confirms that the Bomb was an ideological\nattack aimed at breaking down the rating system of the platform Metacritic.\nEvidence supports that the bombing had the unintended consequence to induce a\nreaction from users, ending into a consistent polarisation of ratings towards\nextreme values. The results not only display the theory of polarity in online\nreviews, but them also provide insights for the research on the problem of\ncold-start detection of spam review. In particular, it illustrates the\nrelevance of detecting users discussing contextual elements instead of the\nproduct and users with anomalous features.""}, 'authors': [{'name': 'Venera Tomaselli'}, {'name': 'Giulio Giacomo Cantone'}, {'name': 'Valeria Mazzeo'}], 'author_detail': {'name': 'Valeria Mazzeo'}, 'author': 'Valeria Mazzeo', 'links': [{'href': 'http://arxiv.org/abs/2104.01140v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.01140v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
119,http://arxiv.org/abs/2104.01131v2,2021-07-20 04:06:18+00:00,2021-04-02 16:13:16+00:00,Mining Trends of COVID-19 Vaccine Beliefs on Twitter with Lexical Embeddings,"[arxiv.Result.Author('Harshita Chopra'), arxiv.Result.Author('Aniket Vashishtha'), arxiv.Result.Author('Ridam Pal'), arxiv.Result.Author('Ashima'), arxiv.Result.Author('Ananya Tyagi'), arxiv.Result.Author('Tavpritesh Sethi')]","Social media plays a pivotal role in disseminating news globally and acts as
a platform for people to express their opinions on various topics. A wide
variety of views accompanies COVID-19 vaccination drives across the globe,
often colored by emotions, which change along with rising cases, approval of
vaccines, and multiple factors discussed online. This study aims at analyzing
the temporal evolution of different Emotion categories: Hesitation, Rage,
Sorrow, Anticipation, Faith, and Contentment with Influencing Factors: Vaccine
Rollout, Misinformation, Health Effects, and Inequities as lexical categories
created from Tweets belonging to five countries with vital vaccine roll-out
programs, namely, India, United States of America, Brazil, United Kingdom, and
Australia. We extracted a corpus of nearly 1.8 million Twitter posts related to
COVID-19 vaccination. Using cosine distance from selected seed words, we
expanded the vocabulary of each category and tracked the longitudinal change in
their strength from June 2020 to April 2021. We used community detection
algorithms to find modules in positive correlation networks. Our findings
suggest that tweets expressing hesitancy towards vaccines contain the highest
mentions of health-related effects in all countries. Our results indicated that
the patterns of hesitancy were variable across geographies and can help us
learn targeted interventions. We also observed a significant change in the
linear trends of categories like hesitation and contentment before and after
approval of vaccines. Negative emotions like rage and sorrow gained the highest
importance in the alluvial diagram. They formed a significant module with all
the influencing factors in April 2021, when India observed the second wave of
COVID-19 cases. The relationship between Emotions and Influencing Factors was
found to be variable across the countries.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.01131v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.01131v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.01131v2,"{'id': 'http://arxiv.org/abs/2104.01131v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.01131v2', 'updated': '2021-07-20T04:06:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=20, tm_hour=4, tm_min=6, tm_sec=18, tm_wday=1, tm_yday=201, tm_isdst=0), 'published': '2021-04-02T16:13:16Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=2, tm_hour=16, tm_min=13, tm_sec=16, tm_wday=4, tm_yday=92, tm_isdst=0), 'title': 'Mining Trends of COVID-19 Vaccine Beliefs on Twitter with Lexical\n  Embeddings', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mining Trends of COVID-19 Vaccine Beliefs on Twitter with Lexical\n  Embeddings'}, 'summary': 'Social media plays a pivotal role in disseminating news globally and acts as\na platform for people to express their opinions on various topics. A wide\nvariety of views accompanies COVID-19 vaccination drives across the globe,\noften colored by emotions, which change along with rising cases, approval of\nvaccines, and multiple factors discussed online. This study aims at analyzing\nthe temporal evolution of different Emotion categories: Hesitation, Rage,\nSorrow, Anticipation, Faith, and Contentment with Influencing Factors: Vaccine\nRollout, Misinformation, Health Effects, and Inequities as lexical categories\ncreated from Tweets belonging to five countries with vital vaccine roll-out\nprograms, namely, India, United States of America, Brazil, United Kingdom, and\nAustralia. We extracted a corpus of nearly 1.8 million Twitter posts related to\nCOVID-19 vaccination. Using cosine distance from selected seed words, we\nexpanded the vocabulary of each category and tracked the longitudinal change in\ntheir strength from June 2020 to April 2021. We used community detection\nalgorithms to find modules in positive correlation networks. Our findings\nsuggest that tweets expressing hesitancy towards vaccines contain the highest\nmentions of health-related effects in all countries. Our results indicated that\nthe patterns of hesitancy were variable across geographies and can help us\nlearn targeted interventions. We also observed a significant change in the\nlinear trends of categories like hesitation and contentment before and after\napproval of vaccines. Negative emotions like rage and sorrow gained the highest\nimportance in the alluvial diagram. They formed a significant module with all\nthe influencing factors in April 2021, when India observed the second wave of\nCOVID-19 cases. The relationship between Emotions and Influencing Factors was\nfound to be variable across the countries.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media plays a pivotal role in disseminating news globally and acts as\na platform for people to express their opinions on various topics. A wide\nvariety of views accompanies COVID-19 vaccination drives across the globe,\noften colored by emotions, which change along with rising cases, approval of\nvaccines, and multiple factors discussed online. This study aims at analyzing\nthe temporal evolution of different Emotion categories: Hesitation, Rage,\nSorrow, Anticipation, Faith, and Contentment with Influencing Factors: Vaccine\nRollout, Misinformation, Health Effects, and Inequities as lexical categories\ncreated from Tweets belonging to five countries with vital vaccine roll-out\nprograms, namely, India, United States of America, Brazil, United Kingdom, and\nAustralia. We extracted a corpus of nearly 1.8 million Twitter posts related to\nCOVID-19 vaccination. Using cosine distance from selected seed words, we\nexpanded the vocabulary of each category and tracked the longitudinal change in\ntheir strength from June 2020 to April 2021. We used community detection\nalgorithms to find modules in positive correlation networks. Our findings\nsuggest that tweets expressing hesitancy towards vaccines contain the highest\nmentions of health-related effects in all countries. Our results indicated that\nthe patterns of hesitancy were variable across geographies and can help us\nlearn targeted interventions. We also observed a significant change in the\nlinear trends of categories like hesitation and contentment before and after\napproval of vaccines. Negative emotions like rage and sorrow gained the highest\nimportance in the alluvial diagram. They formed a significant module with all\nthe influencing factors in April 2021, when India observed the second wave of\nCOVID-19 cases. The relationship between Emotions and Influencing Factors was\nfound to be variable across the countries.'}, 'authors': [{'name': 'Harshita Chopra'}, {'name': 'Aniket Vashishtha'}, {'name': 'Ridam Pal'}, {'name': 'Ashima'}, {'name': 'Ananya Tyagi'}, {'name': 'Tavpritesh Sethi'}], 'author_detail': {'name': 'Tavpritesh Sethi'}, 'author': 'Tavpritesh Sethi', 'links': [{'href': 'http://arxiv.org/abs/2104.01131v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.01131v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
120,http://arxiv.org/abs/2104.04077v1,2021-04-01 22:37:34+00:00,2021-04-01 22:37:34+00:00,Two Truths and a Lie: Exploring Soft Moderation of COVID-19 Misinformation with Amazon Alexa,"[arxiv.Result.Author('Donald Gover'), arxiv.Result.Author('Filipo Sharevski')]","In this paper, we analyzed the perceived accuracy of COVID-19 vaccine Tweets
when they were spoken back by a third-party Amazon Alexa skill. We mimicked the
soft moderation that Twitter applies to COVID-19 misinformation content in both
forms of warning covers and warning tags to investigate whether the third-party
skill could affect how and when users heed these warnings. The results from a
304-participant study suggest that the spoken back warning covers may not work
as intended, even when converted from text to speech. We controlled for
COVID-19 vaccination hesitancy and political leanings and found that the
vaccination hesitant Alexa users ignored any type of warning as long as the
Tweets align with their personal beliefs. The politically independent users
trusted Alexa less then their politically-laden counterparts and that helped
them accurately perceiving truthful COVID-19 information. We discuss soft
moderation adaptations for voice assistants to achieve the intended effect of
curbing COVID-19 misinformation.",arXiv admin note: text overlap with arXiv:2104.00779,,,cs.CY,"['cs.CY', 'cs.CR', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2104.04077v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.04077v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.04077v1,"{'id': 'http://arxiv.org/abs/2104.04077v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.04077v1', 'updated': '2021-04-01T22:37:34Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=1, tm_hour=22, tm_min=37, tm_sec=34, tm_wday=3, tm_yday=91, tm_isdst=0), 'published': '2021-04-01T22:37:34Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=1, tm_hour=22, tm_min=37, tm_sec=34, tm_wday=3, tm_yday=91, tm_isdst=0), 'title': 'Two Truths and a Lie: Exploring Soft Moderation of COVID-19\n  Misinformation with Amazon Alexa', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Two Truths and a Lie: Exploring Soft Moderation of COVID-19\n  Misinformation with Amazon Alexa'}, 'summary': 'In this paper, we analyzed the perceived accuracy of COVID-19 vaccine Tweets\nwhen they were spoken back by a third-party Amazon Alexa skill. We mimicked the\nsoft moderation that Twitter applies to COVID-19 misinformation content in both\nforms of warning covers and warning tags to investigate whether the third-party\nskill could affect how and when users heed these warnings. The results from a\n304-participant study suggest that the spoken back warning covers may not work\nas intended, even when converted from text to speech. We controlled for\nCOVID-19 vaccination hesitancy and political leanings and found that the\nvaccination hesitant Alexa users ignored any type of warning as long as the\nTweets align with their personal beliefs. The politically independent users\ntrusted Alexa less then their politically-laden counterparts and that helped\nthem accurately perceiving truthful COVID-19 information. We discuss soft\nmoderation adaptations for voice assistants to achieve the intended effect of\ncurbing COVID-19 misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we analyzed the perceived accuracy of COVID-19 vaccine Tweets\nwhen they were spoken back by a third-party Amazon Alexa skill. We mimicked the\nsoft moderation that Twitter applies to COVID-19 misinformation content in both\nforms of warning covers and warning tags to investigate whether the third-party\nskill could affect how and when users heed these warnings. The results from a\n304-participant study suggest that the spoken back warning covers may not work\nas intended, even when converted from text to speech. We controlled for\nCOVID-19 vaccination hesitancy and political leanings and found that the\nvaccination hesitant Alexa users ignored any type of warning as long as the\nTweets align with their personal beliefs. The politically independent users\ntrusted Alexa less then their politically-laden counterparts and that helped\nthem accurately perceiving truthful COVID-19 information. We discuss soft\nmoderation adaptations for voice assistants to achieve the intended effect of\ncurbing COVID-19 misinformation.'}, 'authors': [{'name': 'Donald Gover'}, {'name': 'Filipo Sharevski'}], 'author_detail': {'name': 'Filipo Sharevski'}, 'author': 'Filipo Sharevski', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:2104.00779', 'links': [{'href': 'http://arxiv.org/abs/2104.04077v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.04077v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
121,http://arxiv.org/abs/2104.00779v1,2021-04-01 21:50:19+00:00,2021-04-01 21:50:19+00:00,Misinformation Warning Labels: Twitter's Soft Moderation Effects on COVID-19 Vaccine Belief Echoes,"[arxiv.Result.Author('Filipo Sharevski'), arxiv.Result.Author('Raniem Alsaadi'), arxiv.Result.Author('Peter Jachim'), arxiv.Result.Author('Emma Pieroni')]","Twitter, prompted by the rapid spread of alternative narratives, started
actively warning users about the spread of COVID-19 misinformation. This form
of soft moderation comes in two forms: as a warning cover before the Tweet is
displayed to the user and as a warning tag below the Tweet. This study
investigates how each of the soft moderation forms affects the perceived
accuracy of COVID-19 vaccine misinformation on Twitter. The results suggest
that the warning covers work, but not the tags, in reducing the perception of
accuracy of COVID-19 vaccine misinformation on Twitter. ""Belief echoes"" do
exist among Twitter users, unfettered by any warning labels, in relationship to
the perceived safety and efficacy of the COVID-19 vaccine as well as the
vaccination hesitancy for themselves and their children. The implications of
these results are discussed in the context of usable security affordances for
combating misinformation on social media.",,,,cs.SI,"['cs.SI', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2104.00779v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.00779v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.00779v1,"{'id': 'http://arxiv.org/abs/2104.00779v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.00779v1', 'updated': '2021-04-01T21:50:19Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=1, tm_hour=21, tm_min=50, tm_sec=19, tm_wday=3, tm_yday=91, tm_isdst=0), 'published': '2021-04-01T21:50:19Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=1, tm_hour=21, tm_min=50, tm_sec=19, tm_wday=3, tm_yday=91, tm_isdst=0), 'title': ""Misinformation Warning Labels: Twitter's Soft Moderation Effects on\n  COVID-19 Vaccine Belief Echoes"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Misinformation Warning Labels: Twitter's Soft Moderation Effects on\n  COVID-19 Vaccine Belief Echoes""}, 'summary': 'Twitter, prompted by the rapid spread of alternative narratives, started\nactively warning users about the spread of COVID-19 misinformation. This form\nof soft moderation comes in two forms: as a warning cover before the Tweet is\ndisplayed to the user and as a warning tag below the Tweet. This study\ninvestigates how each of the soft moderation forms affects the perceived\naccuracy of COVID-19 vaccine misinformation on Twitter. The results suggest\nthat the warning covers work, but not the tags, in reducing the perception of\naccuracy of COVID-19 vaccine misinformation on Twitter. ""Belief echoes"" do\nexist among Twitter users, unfettered by any warning labels, in relationship to\nthe perceived safety and efficacy of the COVID-19 vaccine as well as the\nvaccination hesitancy for themselves and their children. The implications of\nthese results are discussed in the context of usable security affordances for\ncombating misinformation on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Twitter, prompted by the rapid spread of alternative narratives, started\nactively warning users about the spread of COVID-19 misinformation. This form\nof soft moderation comes in two forms: as a warning cover before the Tweet is\ndisplayed to the user and as a warning tag below the Tweet. This study\ninvestigates how each of the soft moderation forms affects the perceived\naccuracy of COVID-19 vaccine misinformation on Twitter. The results suggest\nthat the warning covers work, but not the tags, in reducing the perception of\naccuracy of COVID-19 vaccine misinformation on Twitter. ""Belief echoes"" do\nexist among Twitter users, unfettered by any warning labels, in relationship to\nthe perceived safety and efficacy of the COVID-19 vaccine as well as the\nvaccination hesitancy for themselves and their children. The implications of\nthese results are discussed in the context of usable security affordances for\ncombating misinformation on social media.'}, 'authors': [{'name': 'Filipo Sharevski'}, {'name': 'Raniem Alsaadi'}, {'name': 'Peter Jachim'}, {'name': 'Emma Pieroni'}], 'author_detail': {'name': 'Emma Pieroni'}, 'author': 'Emma Pieroni', 'links': [{'href': 'http://arxiv.org/abs/2104.00779v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.00779v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
122,http://arxiv.org/abs/2104.00124v2,2021-04-03 17:34:31+00:00,2021-03-31 21:12:29+00:00,Misinformation detection in Luganda-English code-mixed social media text,"[arxiv.Result.Author('Peter Nabende'), arxiv.Result.Author('David Kabiito'), arxiv.Result.Author('Claire Babirye'), arxiv.Result.Author('Hewitt Tusiime'), arxiv.Result.Author('Joyce Nakatumba-Nabende')]","The increasing occurrence, forms, and negative effects of misinformation on
social media platforms has necessitated more misinformation detection tools.
Currently, work is being done addressing COVID-19 misinformation however, there
are no misinformation detection tools for any of the 40 distinct indigenous
Ugandan languages. This paper addresses this gap by presenting basic language
resources and a misinformation detection data set based on code-mixed
Luganda-English messages sourced from the Facebook and Twitter social media
platforms. Several machine learning methods are applied on the misinformation
detection data set to develop classification models for detecting whether a
code-mixed Luganda-English message contains misinformation or not. A 10-fold
cross validation evaluation of the classification methods in an experimental
misinformation detection task shows that a Discriminative Multinomial Naive
Bayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and
77.90% respectively. Also, Support Vector Machine and Bagging ensemble
classification models achieve comparable results. These results are promising
since the machine learning models are based on n-gram features from only the
misinformation detection dataset.",Accepted at African NLP workshop @EACL 2021,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2104.00124v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.00124v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.00124v2,"{'id': 'http://arxiv.org/abs/2104.00124v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.00124v2', 'updated': '2021-04-03T17:34:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=3, tm_hour=17, tm_min=34, tm_sec=31, tm_wday=5, tm_yday=93, tm_isdst=0), 'published': '2021-03-31T21:12:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=31, tm_hour=21, tm_min=12, tm_sec=29, tm_wday=2, tm_yday=90, tm_isdst=0), 'title': 'Misinformation detection in Luganda-English code-mixed social media text', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation detection in Luganda-English code-mixed social media text'}, 'summary': 'The increasing occurrence, forms, and negative effects of misinformation on\nsocial media platforms has necessitated more misinformation detection tools.\nCurrently, work is being done addressing COVID-19 misinformation however, there\nare no misinformation detection tools for any of the 40 distinct indigenous\nUgandan languages. This paper addresses this gap by presenting basic language\nresources and a misinformation detection data set based on code-mixed\nLuganda-English messages sourced from the Facebook and Twitter social media\nplatforms. Several machine learning methods are applied on the misinformation\ndetection data set to develop classification models for detecting whether a\ncode-mixed Luganda-English message contains misinformation or not. A 10-fold\ncross validation evaluation of the classification methods in an experimental\nmisinformation detection task shows that a Discriminative Multinomial Naive\nBayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and\n77.90% respectively. Also, Support Vector Machine and Bagging ensemble\nclassification models achieve comparable results. These results are promising\nsince the machine learning models are based on n-gram features from only the\nmisinformation detection dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The increasing occurrence, forms, and negative effects of misinformation on\nsocial media platforms has necessitated more misinformation detection tools.\nCurrently, work is being done addressing COVID-19 misinformation however, there\nare no misinformation detection tools for any of the 40 distinct indigenous\nUgandan languages. This paper addresses this gap by presenting basic language\nresources and a misinformation detection data set based on code-mixed\nLuganda-English messages sourced from the Facebook and Twitter social media\nplatforms. Several machine learning methods are applied on the misinformation\ndetection data set to develop classification models for detecting whether a\ncode-mixed Luganda-English message contains misinformation or not. A 10-fold\ncross validation evaluation of the classification methods in an experimental\nmisinformation detection task shows that a Discriminative Multinomial Naive\nBayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and\n77.90% respectively. Also, Support Vector Machine and Bagging ensemble\nclassification models achieve comparable results. These results are promising\nsince the machine learning models are based on n-gram features from only the\nmisinformation detection dataset.'}, 'authors': [{'name': 'Peter Nabende'}, {'name': 'David Kabiito'}, {'name': 'Claire Babirye'}, {'name': 'Hewitt Tusiime'}, {'name': 'Joyce Nakatumba-Nabende'}], 'author_detail': {'name': 'Joyce Nakatumba-Nabende'}, 'author': 'Joyce Nakatumba-Nabende', 'arxiv_comment': 'Accepted at African NLP workshop @EACL 2021', 'links': [{'href': 'http://arxiv.org/abs/2104.00124v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.00124v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
123,http://arxiv.org/abs/2104.00088v2,2021-05-03 15:42:38+00:00,2021-03-31 20:09:09+00:00,Transfer Learning for Node Regression Applied to Spreading Prediction,"[arxiv.Result.Author('Sebastian Mežnar'), arxiv.Result.Author('Nada Lavrač'), arxiv.Result.Author('Blaž Škrlj')]","Understanding how information propagates in real-life complex networks yields
a better understanding of dynamic processes such as misinformation or epidemic
spreading. The recently introduced branch of machine learning methods for
learning node representations offers many novel applications, one of them being
the task of spreading prediction addressed in this paper. We explore the
utility of the state-of-the-art node representation learners when used to
assess the effects of spreading from a given node, estimated via extensive
simulations. Further, as many real-life networks are topologically similar, we
systematically investigate whether the learned models generalize to previously
unseen networks, showing that in some cases very good model transfer can be
obtained. This work is one of the first to explore transferability of the
learned representations for the task of node regression; we show there exist
pairs of networks with similar structure between which the trained models can
be transferred (zero-shot), and demonstrate their competitive performance. To
our knowledge, this is one of the first attempts to evaluate the utility of
zero-shot transfer for the task of node regression.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2104.00088v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2104.00088v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2104.00088v2,"{'id': 'http://arxiv.org/abs/2104.00088v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2104.00088v2', 'updated': '2021-05-03T15:42:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=3, tm_hour=15, tm_min=42, tm_sec=38, tm_wday=0, tm_yday=123, tm_isdst=0), 'published': '2021-03-31T20:09:09Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=31, tm_hour=20, tm_min=9, tm_sec=9, tm_wday=2, tm_yday=90, tm_isdst=0), 'title': 'Transfer Learning for Node Regression Applied to Spreading Prediction', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transfer Learning for Node Regression Applied to Spreading Prediction'}, 'summary': 'Understanding how information propagates in real-life complex networks yields\na better understanding of dynamic processes such as misinformation or epidemic\nspreading. The recently introduced branch of machine learning methods for\nlearning node representations offers many novel applications, one of them being\nthe task of spreading prediction addressed in this paper. We explore the\nutility of the state-of-the-art node representation learners when used to\nassess the effects of spreading from a given node, estimated via extensive\nsimulations. Further, as many real-life networks are topologically similar, we\nsystematically investigate whether the learned models generalize to previously\nunseen networks, showing that in some cases very good model transfer can be\nobtained. This work is one of the first to explore transferability of the\nlearned representations for the task of node regression; we show there exist\npairs of networks with similar structure between which the trained models can\nbe transferred (zero-shot), and demonstrate their competitive performance. To\nour knowledge, this is one of the first attempts to evaluate the utility of\nzero-shot transfer for the task of node regression.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding how information propagates in real-life complex networks yields\na better understanding of dynamic processes such as misinformation or epidemic\nspreading. The recently introduced branch of machine learning methods for\nlearning node representations offers many novel applications, one of them being\nthe task of spreading prediction addressed in this paper. We explore the\nutility of the state-of-the-art node representation learners when used to\nassess the effects of spreading from a given node, estimated via extensive\nsimulations. Further, as many real-life networks are topologically similar, we\nsystematically investigate whether the learned models generalize to previously\nunseen networks, showing that in some cases very good model transfer can be\nobtained. This work is one of the first to explore transferability of the\nlearned representations for the task of node regression; we show there exist\npairs of networks with similar structure between which the trained models can\nbe transferred (zero-shot), and demonstrate their competitive performance. To\nour knowledge, this is one of the first attempts to evaluate the utility of\nzero-shot transfer for the task of node regression.'}, 'authors': [{'name': 'Sebastian Mežnar'}, {'name': 'Nada Lavrač'}, {'name': 'Blaž Škrlj'}], 'author_detail': {'name': 'Blaž Škrlj'}, 'author': 'Blaž Škrlj', 'links': [{'href': 'http://arxiv.org/abs/2104.00088v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2104.00088v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
124,http://arxiv.org/abs/2103.15581v1,2021-03-29 12:56:59+00:00,2021-03-29 12:56:59+00:00,Supporting verification of news articles with automated search for semantically similar articles,"[arxiv.Result.Author('Vishwani Gupta'), arxiv.Result.Author('Katharina Beckh'), arxiv.Result.Author('Sven Giesselbach'), arxiv.Result.Author('Dennis Wegener'), arxiv.Result.Author('Tim Wirtz')]","Fake information poses one of the major threats for society in the 21st
century. Identifying misinformation has become a key challenge due to the
amount of fake news that is published daily. Yet, no approach is established
that addresses the dynamics and versatility of fake news editorials. Instead of
classifying content, we propose an evidence retrieval approach to handle fake
news. The learning task is formulated as an unsupervised machine learning
problem. For validation purpose, we provide the user with a set of news
articles from reliable news sources supporting the hypothesis of the news
article in query and the final decision is left to the user. Technically we
propose a two-step process: (i) Aggregation-step: With information extracted
from the given text we query for similar content from reliable news sources.
(ii) Refining-step: We narrow the supporting evidence down by measuring the
semantic distance of the text with the collection from step (i). The distance
is calculated based on Word2Vec and the Word Mover's Distance. In our
experiments, only content that is below a certain distance threshold is
considered as supporting evidence. We find that our approach is agnostic to
concept drifts, i.e. the machine learning task is independent of the hypotheses
in a text. This makes it highly adaptable in times where fake news is as
diverse as classical news is. Our pipeline offers the possibility for further
analysis in the future, such as investigating bias and differences in news
reporting.",,,,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2103.15581v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.15581v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.15581v1,"{'id': 'http://arxiv.org/abs/2103.15581v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.15581v1', 'updated': '2021-03-29T12:56:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=29, tm_hour=12, tm_min=56, tm_sec=59, tm_wday=0, tm_yday=88, tm_isdst=0), 'published': '2021-03-29T12:56:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=29, tm_hour=12, tm_min=56, tm_sec=59, tm_wday=0, tm_yday=88, tm_isdst=0), 'title': 'Supporting verification of news articles with automated search for\n  semantically similar articles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Supporting verification of news articles with automated search for\n  semantically similar articles'}, 'summary': ""Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting.""}, 'authors': [{'name': 'Vishwani Gupta'}, {'name': 'Katharina Beckh'}, {'name': 'Sven Giesselbach'}, {'name': 'Dennis Wegener'}, {'name': 'Tim Wirtz'}], 'author_detail': {'name': 'Tim Wirtz'}, 'author': 'Tim Wirtz', 'links': [{'href': 'http://arxiv.org/abs/2103.15581v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.15581v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
125,http://arxiv.org/abs/2103.14748v1,2021-03-26 21:53:38+00:00,2021-03-26 21:53:38+00:00,Analysing the Effect of Recommendation Algorithms on the Amplification of Misinformation,"[arxiv.Result.Author('Miriam Fernández'), arxiv.Result.Author('Alejandro Bellogín'), arxiv.Result.Author('Iván Cantador')]","Recommendation algorithms have been pointed out as one of the major culprits
of misinformation spreading in the digital sphere. However, it is still unclear
how these algorithms really propagate misinformation, e.g., it has not been
shown which particular recommendation approaches are more prone to suggest
misinforming items, or which internal parameters of the algorithms could be
influencing more on their misinformation propagation capacity.
  Motivated by this fact, in this paper we present an analysis of the effect of
some of the most popular recommendation algorithms on the spread of
misinformation in Twitter. A set of guidelines on how to adapt these algorithms
is provided based on such analysis and a comprehensive review of the research
literature. A dataset is also generated and released to the scientific
community to stimulate discussions on the future design and development of
recommendation algorithms to counter misinformation. The dataset includes
editorially labelled news items and claims regarding their misinformation
nature.",,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2103.14748v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.14748v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.14748v1,"{'id': 'http://arxiv.org/abs/2103.14748v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.14748v1', 'updated': '2021-03-26T21:53:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=26, tm_hour=21, tm_min=53, tm_sec=38, tm_wday=4, tm_yday=85, tm_isdst=0), 'published': '2021-03-26T21:53:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=26, tm_hour=21, tm_min=53, tm_sec=38, tm_wday=4, tm_yday=85, tm_isdst=0), 'title': 'Analysing the Effect of Recommendation Algorithms on the Amplification\n  of Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysing the Effect of Recommendation Algorithms on the Amplification\n  of Misinformation'}, 'summary': 'Recommendation algorithms have been pointed out as one of the major culprits\nof misinformation spreading in the digital sphere. However, it is still unclear\nhow these algorithms really propagate misinformation, e.g., it has not been\nshown which particular recommendation approaches are more prone to suggest\nmisinforming items, or which internal parameters of the algorithms could be\ninfluencing more on their misinformation propagation capacity.\n  Motivated by this fact, in this paper we present an analysis of the effect of\nsome of the most popular recommendation algorithms on the spread of\nmisinformation in Twitter. A set of guidelines on how to adapt these algorithms\nis provided based on such analysis and a comprehensive review of the research\nliterature. A dataset is also generated and released to the scientific\ncommunity to stimulate discussions on the future design and development of\nrecommendation algorithms to counter misinformation. The dataset includes\neditorially labelled news items and claims regarding their misinformation\nnature.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recommendation algorithms have been pointed out as one of the major culprits\nof misinformation spreading in the digital sphere. However, it is still unclear\nhow these algorithms really propagate misinformation, e.g., it has not been\nshown which particular recommendation approaches are more prone to suggest\nmisinforming items, or which internal parameters of the algorithms could be\ninfluencing more on their misinformation propagation capacity.\n  Motivated by this fact, in this paper we present an analysis of the effect of\nsome of the most popular recommendation algorithms on the spread of\nmisinformation in Twitter. A set of guidelines on how to adapt these algorithms\nis provided based on such analysis and a comprehensive review of the research\nliterature. A dataset is also generated and released to the scientific\ncommunity to stimulate discussions on the future design and development of\nrecommendation algorithms to counter misinformation. The dataset includes\neditorially labelled news items and claims regarding their misinformation\nnature.'}, 'authors': [{'name': 'Miriam Fernández'}, {'name': 'Alejandro Bellogín'}, {'name': 'Iván Cantador'}], 'author_detail': {'name': 'Iván Cantador'}, 'author': 'Iván Cantador', 'links': [{'href': 'http://arxiv.org/abs/2103.14748v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.14748v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
126,http://arxiv.org/abs/2103.12191v1,2021-03-22 21:44:32+00:00,2021-03-22 21:44:32+00:00,Using an Epidemiological Model to Study the Spread of Misinformation during the Black Lives Matter Movement,"[arxiv.Result.Author('Maryam Maleki'), arxiv.Result.Author('Esther Mead'), arxiv.Result.Author('Mohammad Arani'), arxiv.Result.Author('Nitin Agarwal')]","The proliferation of social media platforms like Twitter has heightened the
consequences of the spread of misinformation. To understand and model the
spread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,
Exposed, Infected, Skeptics) epidemiological model to describe the underlying
process that delineates the spread of misinformation on Twitter. Compared to
the other epidemiological models, this model produces broader results because
it includes the additional Skeptics (Z) compartment, wherein a user may be
exposed to an item of misinformation but not engage in any reaction to it, and
the additional Exposed (E) compartment, wherein the user may need some time
before deciding to spread a misinformation item. We analyzed misinformation
regarding the unrest in Washington, D.C. in the month of March 2020 which was
propagated by the use of the #DCblackout hashtag by different users across the
U.S. on Twitter. Our analysis shows that misinformation can be modeled using
the concept of epidemiology. To the best of our knowledge, this research is the
first to attempt to apply the SEIZ epidemiological model to the spread of a
specific item of misinformation, which is a category distinct from that of
rumor, and a hoax on online social media platforms. Applying a mathematical
model can help to understand the trends and dynamics of the spread of
misinformation on Twitter and ultimately help to develop techniques to quickly
identify and control it.","This paper is accepted on the International Conference on Fake News,
  Social Media Manipulation and Misinformation 2021 (ICFNSMMM 2021)",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.12191v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.12191v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.12191v1,"{'id': 'http://arxiv.org/abs/2103.12191v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.12191v1', 'updated': '2021-03-22T21:44:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=22, tm_hour=21, tm_min=44, tm_sec=32, tm_wday=0, tm_yday=81, tm_isdst=0), 'published': '2021-03-22T21:44:32Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=22, tm_hour=21, tm_min=44, tm_sec=32, tm_wday=0, tm_yday=81, tm_isdst=0), 'title': 'Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement'}, 'summary': 'The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.'}, 'authors': [{'name': 'Maryam Maleki'}, {'name': 'Esther Mead'}, {'name': 'Mohammad Arani'}, {'name': 'Nitin Agarwal'}], 'author_detail': {'name': 'Nitin Agarwal'}, 'author': 'Nitin Agarwal', 'arxiv_comment': 'This paper is accepted on the International Conference on Fake News,\n  Social Media Manipulation and Misinformation 2021 (ICFNSMMM 2021)', 'links': [{'href': 'http://arxiv.org/abs/2103.12191v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.12191v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
127,http://arxiv.org/abs/2103.09258v1,2021-03-16 18:10:22+00:00,2021-03-16 18:10:22+00:00,The Rise and Fall of Fake News sites: A Traffic Analysis,"[arxiv.Result.Author('Manolis Chalkiadakis'), arxiv.Result.Author('Alexandros Kornilakis'), arxiv.Result.Author('Panagiotis Papadopoulos'), arxiv.Result.Author('Evangelos P. Markatos'), arxiv.Result.Author('Nicolas Kourtellis')]","Over the past decade, we have witnessed the rise of misinformation on the
Internet, with online users constantly falling victims of fake news. A
multitude of past studies have analyzed fake news diffusion mechanics and
detection and mitigation techniques. However, there are still open questions
about their operational behavior such as: How old are fake news websites? Do
they typically stay online for long periods of time? Do such websites
synchronize with each other their up and down time? Do they share similar
content through time? Which third-parties support their operations? How much
user traffic do they attract, in comparison to mainstream or real news
websites? In this paper, we perform a first of its kind investigation to answer
such questions regarding the online presence of fake news websites and
characterize their behavior in comparison to real news websites. Based on our
findings, we build a content-agnostic ML classifier for automatic detection of
fake news websites (i.e. accuracy) that are not yet included in manually
curated blacklists.",,,,cs.SI,"['cs.SI', 'cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2103.09258v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.09258v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.09258v1,"{'id': 'http://arxiv.org/abs/2103.09258v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.09258v1', 'updated': '2021-03-16T18:10:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=16, tm_hour=18, tm_min=10, tm_sec=22, tm_wday=1, tm_yday=75, tm_isdst=0), 'published': '2021-03-16T18:10:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=16, tm_hour=18, tm_min=10, tm_sec=22, tm_wday=1, tm_yday=75, tm_isdst=0), 'title': 'The Rise and Fall of Fake News sites: A Traffic Analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Rise and Fall of Fake News sites: A Traffic Analysis'}, 'summary': 'Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.'}, 'authors': [{'name': 'Manolis Chalkiadakis'}, {'name': 'Alexandros Kornilakis'}, {'name': 'Panagiotis Papadopoulos'}, {'name': 'Evangelos P. Markatos'}, {'name': 'Nicolas Kourtellis'}], 'author_detail': {'name': 'Nicolas Kourtellis'}, 'author': 'Nicolas Kourtellis', 'links': [{'href': 'http://arxiv.org/abs/2103.09258v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.09258v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
128,http://arxiv.org/abs/2103.12541v1,2021-03-13 18:04:17+00:00,2021-03-13 18:04:17+00:00,A Survey on Multimodal Disinformation Detection,"[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Stefano Cresci'), arxiv.Result.Author('Tanmoy Chakraborty'), arxiv.Result.Author('Fabrizio Silvestri'), arxiv.Result.Author('Dimiter Dimitrov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Hamed Firooz'), arxiv.Result.Author('Preslav Nakov')]","Recent years have witnessed the proliferation of fake news, propaganda,
misinformation, and disinformation online. While initially this was mostly
about textual content, over time images and videos gained popularity, as they
are much easier to consume, attract much more attention, and spread further
than simple text. As a result, researchers started targeting different
modalities and combinations thereof. As different modalities are studied in
different research communities, with insufficient interaction, here we offer a
survey that explores the state-of-the-art on multimodal disinformation
detection covering various combinations of modalities: text, images, audio,
video, network structure, and temporal information. Moreover, while some
studies focused on factuality, others investigated how harmful the content is.
While these two components in the definition of disinformation -- (i)
factuality and (ii) harmfulness, are equally important, they are typically
studied in isolation. Thus, we argue for the need to tackle disinformation
detection by taking into account multiple modalities as well as both factuality
and harmfulness, in the same framework. Finally, we discuss current challenges
and future research directions.","disinformation, misinformation, factuality, harmfulness, fake news,
  propaganda, multimodality, text, images, videos, network structure,
  temporality",,,cs.MM,"['cs.MM', 'cs.AI', 'cs.CL', 'cs.CR', 'cs.CY', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2103.12541v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.12541v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.12541v1,"{'id': 'http://arxiv.org/abs/2103.12541v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.12541v1', 'updated': '2021-03-13T18:04:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=17, tm_wday=5, tm_yday=72, tm_isdst=0), 'published': '2021-03-13T18:04:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=17, tm_wday=5, tm_yday=72, tm_isdst=0), 'title': 'A Survey on Multimodal Disinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Multimodal Disinformation Detection'}, 'summary': 'Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Stefano Cresci'}, {'name': 'Tanmoy Chakraborty'}, {'name': 'Fabrizio Silvestri'}, {'name': 'Dimiter Dimitrov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Shaden Shaar'}, {'name': 'Hamed Firooz'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality', 'links': [{'href': 'http://arxiv.org/abs/2103.12541v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.12541v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
129,http://arxiv.org/abs/2103.03409v1,2021-03-05 00:48:23+00:00,2021-03-05 00:48:23+00:00,A General Method to Find Highly Coordinating Communities in Social Media through Inferred Interaction Links,"[arxiv.Result.Author('Derek Weber'), arxiv.Result.Author('Frank Neumann')]","Political misinformation, astroturfing and organised trolling are online
malicious behaviours with significant real-world effects. Many previous
approaches examining these phenomena have focused on broad campaigns rather
than the small groups responsible for instigating or sustaining them. To reveal
latent (i.e., hidden) networks of cooperating accounts, we propose a novel
temporal window approach that relies on account interactions and metadata
alone. It detects groups of accounts engaging in various behaviours that, in
concert, come to execute different goal-based strategies, a number of which we
describe. The approach relies upon a pipeline that extracts relevant elements
from social media posts, infers connections between accounts based on criteria
matching the coordination strategies to build an undirected weighted network of
accounts, which is then mined for communities exhibiting high levels of
evidence of coordination using a novel community extraction method. We address
the temporal aspect of the data by using a windowing mechanism, which may be
suitable for near real-time application. We further highlight consistent
coordination with a sliding frame across multiple windows and application of a
decay factor. Our approach is compared with other recent similar processing
approaches and community detection methods and is validated against two
relevant datasets with ground truth data, using content, temporal, and network
analyses, as well as with the design, training and application of three
one-class classifiers built using the ground truth; its utility is furthermore
demonstrated in two case studies of contentious online discussions.","58 pages, 25 figures, submitted to the International Journal of
  Social Network Analysis and Mining (SNAM) as an expansion to an ASONAM'20
  paper (arXiv:2010.08180)",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2103.03409v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.03409v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.03409v1,"{'id': 'http://arxiv.org/abs/2103.03409v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.03409v1', 'updated': '2021-03-05T00:48:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=5, tm_hour=0, tm_min=48, tm_sec=23, tm_wday=4, tm_yday=64, tm_isdst=0), 'published': '2021-03-05T00:48:23Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=5, tm_hour=0, tm_min=48, tm_sec=23, tm_wday=4, tm_yday=64, tm_isdst=0), 'title': 'A General Method to Find Highly Coordinating Communities in Social Media\n  through Inferred Interaction Links', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A General Method to Find Highly Coordinating Communities in Social Media\n  through Inferred Interaction Links'}, 'summary': 'Political misinformation, astroturfing and organised trolling are online\nmalicious behaviours with significant real-world effects. Many previous\napproaches examining these phenomena have focused on broad campaigns rather\nthan the small groups responsible for instigating or sustaining them. To reveal\nlatent (i.e., hidden) networks of cooperating accounts, we propose a novel\ntemporal window approach that relies on account interactions and metadata\nalone. It detects groups of accounts engaging in various behaviours that, in\nconcert, come to execute different goal-based strategies, a number of which we\ndescribe. The approach relies upon a pipeline that extracts relevant elements\nfrom social media posts, infers connections between accounts based on criteria\nmatching the coordination strategies to build an undirected weighted network of\naccounts, which is then mined for communities exhibiting high levels of\nevidence of coordination using a novel community extraction method. We address\nthe temporal aspect of the data by using a windowing mechanism, which may be\nsuitable for near real-time application. We further highlight consistent\ncoordination with a sliding frame across multiple windows and application of a\ndecay factor. Our approach is compared with other recent similar processing\napproaches and community detection methods and is validated against two\nrelevant datasets with ground truth data, using content, temporal, and network\nanalyses, as well as with the design, training and application of three\none-class classifiers built using the ground truth; its utility is furthermore\ndemonstrated in two case studies of contentious online discussions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Political misinformation, astroturfing and organised trolling are online\nmalicious behaviours with significant real-world effects. Many previous\napproaches examining these phenomena have focused on broad campaigns rather\nthan the small groups responsible for instigating or sustaining them. To reveal\nlatent (i.e., hidden) networks of cooperating accounts, we propose a novel\ntemporal window approach that relies on account interactions and metadata\nalone. It detects groups of accounts engaging in various behaviours that, in\nconcert, come to execute different goal-based strategies, a number of which we\ndescribe. The approach relies upon a pipeline that extracts relevant elements\nfrom social media posts, infers connections between accounts based on criteria\nmatching the coordination strategies to build an undirected weighted network of\naccounts, which is then mined for communities exhibiting high levels of\nevidence of coordination using a novel community extraction method. We address\nthe temporal aspect of the data by using a windowing mechanism, which may be\nsuitable for near real-time application. We further highlight consistent\ncoordination with a sliding frame across multiple windows and application of a\ndecay factor. Our approach is compared with other recent similar processing\napproaches and community detection methods and is validated against two\nrelevant datasets with ground truth data, using content, temporal, and network\nanalyses, as well as with the design, training and application of three\none-class classifiers built using the ground truth; its utility is furthermore\ndemonstrated in two case studies of contentious online discussions.'}, 'authors': [{'name': 'Derek Weber'}, {'name': 'Frank Neumann'}], 'author_detail': {'name': 'Frank Neumann'}, 'author': 'Frank Neumann', 'arxiv_comment': ""58 pages, 25 figures, submitted to the International Journal of\n  Social Network Analysis and Mining (SNAM) as an expansion to an ASONAM'20\n  paper (arXiv:2010.08180)"", 'links': [{'href': 'http://arxiv.org/abs/2103.03409v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.03409v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
130,http://arxiv.org/abs/2103.02462v1,2021-03-03 15:13:25+00:00,2021-03-03 15:13:25+00:00,University of Copenhagen Participation in TREC Health Misinformation Track 2020,"[arxiv.Result.Author('Lucas Chaves Lima'), arxiv.Result.Author('Dustin Brandon Wright'), arxiv.Result.Author('Isabelle Augenstein'), arxiv.Result.Author('Maria Maistro')]","In this paper, we describe our participation in the TREC Health
Misinformation Track 2020. We submitted $11$ runs to the Total Recall Task and
13 runs to the Ad Hoc task. Our approach consists of 3 steps: (1) we create an
initial run with BM25 and RM3; (2) we estimate credibility and misinformation
scores for the documents in the initial run; (3) we merge the relevance,
credibility and misinformation scores to re-rank documents in the initial run.
To estimate credibility scores, we implement a classifier which exploits
features based on the content and the popularity of a document. To compute the
misinformation score, we apply a stance detection approach with a pretrained
Transformer language model. Finally, we use different approaches to merge
scores: weighted average, the distance among score vectors and rank fusion.",,,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.02462v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.02462v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.02462v1,"{'id': 'http://arxiv.org/abs/2103.02462v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.02462v1', 'updated': '2021-03-03T15:13:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=3, tm_hour=15, tm_min=13, tm_sec=25, tm_wday=2, tm_yday=62, tm_isdst=0), 'published': '2021-03-03T15:13:25Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=3, tm_hour=15, tm_min=13, tm_sec=25, tm_wday=2, tm_yday=62, tm_isdst=0), 'title': 'University of Copenhagen Participation in TREC Health Misinformation\n  Track 2020', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'University of Copenhagen Participation in TREC Health Misinformation\n  Track 2020'}, 'summary': 'In this paper, we describe our participation in the TREC Health\nMisinformation Track 2020. We submitted $11$ runs to the Total Recall Task and\n13 runs to the Ad Hoc task. Our approach consists of 3 steps: (1) we create an\ninitial run with BM25 and RM3; (2) we estimate credibility and misinformation\nscores for the documents in the initial run; (3) we merge the relevance,\ncredibility and misinformation scores to re-rank documents in the initial run.\nTo estimate credibility scores, we implement a classifier which exploits\nfeatures based on the content and the popularity of a document. To compute the\nmisinformation score, we apply a stance detection approach with a pretrained\nTransformer language model. Finally, we use different approaches to merge\nscores: weighted average, the distance among score vectors and rank fusion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we describe our participation in the TREC Health\nMisinformation Track 2020. We submitted $11$ runs to the Total Recall Task and\n13 runs to the Ad Hoc task. Our approach consists of 3 steps: (1) we create an\ninitial run with BM25 and RM3; (2) we estimate credibility and misinformation\nscores for the documents in the initial run; (3) we merge the relevance,\ncredibility and misinformation scores to re-rank documents in the initial run.\nTo estimate credibility scores, we implement a classifier which exploits\nfeatures based on the content and the popularity of a document. To compute the\nmisinformation score, we apply a stance detection approach with a pretrained\nTransformer language model. Finally, we use different approaches to merge\nscores: weighted average, the distance among score vectors and rank fusion.'}, 'authors': [{'name': 'Lucas Chaves Lima'}, {'name': 'Dustin Brandon Wright'}, {'name': 'Isabelle Augenstein'}, {'name': 'Maria Maistro'}], 'author_detail': {'name': 'Maria Maistro'}, 'author': 'Maria Maistro', 'links': [{'href': 'http://arxiv.org/abs/2103.02462v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.02462v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
131,http://arxiv.org/abs/2103.00747v1,2021-03-01 04:28:39+00:00,2021-03-01 04:28:39+00:00,Combat COVID-19 Infodemic Using Explainable Natural Language Processing Models,"[arxiv.Result.Author('Jackie Ayoub'), arxiv.Result.Author('X. Jessie Yang'), arxiv.Result.Author('Feng Zhou')]","Misinformation of COVID-19 is prevalent on social media as the pandemic
unfolds, and the associated risks are extremely high. Thus, it is critical to
detect and combat such misinformation. Recently, deep learning models using
natural language processing techniques, such as BERT (Bidirectional Encoder
Representations from Transformers), have achieved great successes in detecting
misinformation. In this paper, we proposed an explainable natural language
processing model based on DistilBERT and SHAP (Shapley Additive exPlanations)
to combat misinformation about COVID-19 due to their efficiency and
effectiveness. First, we collected a dataset of 984 claims about COVID-19 with
fact checking. By augmenting the data using back-translation, we doubled the
sample size of the dataset and the DistilBERT model was able to obtain good
performance (accuracy: 0.972; areas under the curve: 0.993) in detecting
misinformation about COVID-19. Our model was also tested on a larger dataset
for AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good
performance (accuracy: 0.938; areas under the curve: 0.985). The performance on
both datasets was better than traditional machine learning models. Second, in
order to boost public trust in model prediction, we employed SHAP to improve
model explainability, which was further evaluated using a between-subjects
experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),
and text+SHAP explanation+source and evidence (TSESE). The participants were
significantly more likely to trust and share information related to COVID-19 in
the TSE and TSESE conditions than in the T condition. Our results provided good
implications in detecting misinformation about COVID-19 and improving public
trust.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2103.00747v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.00747v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.00747v1,"{'id': 'http://arxiv.org/abs/2103.00747v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.00747v1', 'updated': '2021-03-01T04:28:39Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=4, tm_min=28, tm_sec=39, tm_wday=0, tm_yday=60, tm_isdst=0), 'published': '2021-03-01T04:28:39Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=4, tm_min=28, tm_sec=39, tm_wday=0, tm_yday=60, tm_isdst=0), 'title': 'Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models'}, 'summary': 'Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.'}, 'authors': [{'name': 'Jackie Ayoub'}, {'name': 'X. Jessie Yang'}, {'name': 'Feng Zhou'}], 'author_detail': {'name': 'Feng Zhou'}, 'author': 'Feng Zhou', 'links': [{'href': 'http://arxiv.org/abs/2103.00747v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.00747v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
132,http://arxiv.org/abs/2103.00242v1,2021-02-27 15:27:22+00:00,2021-02-27 15:27:22+00:00,A Survey on Stance Detection for Mis- and Disinformation Identification,"[arxiv.Result.Author('Momchil Hardalov'), arxiv.Result.Author('Arnav Arora'), arxiv.Result.Author('Preslav Nakov'), arxiv.Result.Author('Isabelle Augenstein')]","Detecting attitudes expressed in texts, also known as stance detection, has
become an important task for the detection of false information online, be it
misinformation (unintentionally false) or disinformation (intentionally false,
spread deliberately with malicious intent). Stance detection has been framed in
different ways, including: (a) as a component of fact-checking, rumour
detection, and detecting previously fact-checked claims; or (b) as a task in
its own right. While there have been prior efforts to contrast stance detection
with other related social media tasks such as argumentation mining and
sentiment analysis, there is no survey examining the relationship between
stance detection detection and mis- and disinformation detection from a
holistic viewpoint, which is the focus of this survey. We review and analyse
existing work in this area, before discussing lessons learnt and future
challenges.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2103.00242v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2103.00242v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2103.00242v1,"{'id': 'http://arxiv.org/abs/2103.00242v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2103.00242v1', 'updated': '2021-02-27T15:27:22Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=27, tm_hour=15, tm_min=27, tm_sec=22, tm_wday=5, tm_yday=58, tm_isdst=0), 'published': '2021-02-27T15:27:22Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=27, tm_hour=15, tm_min=27, tm_sec=22, tm_wday=5, tm_yday=58, tm_isdst=0), 'title': 'A Survey on Stance Detection for Mis- and Disinformation Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Survey on Stance Detection for Mis- and Disinformation Identification'}, 'summary': 'Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.'}, 'authors': [{'name': 'Momchil Hardalov'}, {'name': 'Arnav Arora'}, {'name': 'Preslav Nakov'}, {'name': 'Isabelle Augenstein'}], 'author_detail': {'name': 'Isabelle Augenstein'}, 'author': 'Isabelle Augenstein', 'links': [{'href': 'http://arxiv.org/abs/2103.00242v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2103.00242v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
133,http://arxiv.org/abs/2102.13167v1,2021-02-25 20:47:21+00:00,2021-02-25 20:47:21+00:00,"Images, Emotions, and Credibility: Effect of Emotional Facial Images on Perceptions of News Content Bias and Source Credibility in Social Media","[arxiv.Result.Author('Alireza Karduni'), arxiv.Result.Author('Ryan Wesslen'), arxiv.Result.Author('Douglas Markant'), arxiv.Result.Author('Wenwen Dou')]","Images are an indispensable part of the news content we consume. Highly
emotional images from sources of misinformation can greatly influence our
judgements. We present two studies on the effects of emotional facial images on
users' perception of bias in news content and the credibility of sources. In
study 1, we investigate the impact of happy and angry facial images on users'
decisions. In study 2, we focus on sources' systematic emotional treatment of
specific politicians. Our results show that depending on the political
orientation of the source, the cumulative effect of angry facial emotions
impacts users' perceived content bias and source credibility. When sources
systematically portray specific politicians as angry, users are more likely to
find those sources as less credible and their content as more biased. These
results highlight how implicit visual propositions manifested by emotions in
facial expressions might have a substantial effect on our trust of news content
and sources.","23 pages, 9 figures",,,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2102.13167v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.13167v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.13167v1,"{'id': 'http://arxiv.org/abs/2102.13167v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.13167v1', 'updated': '2021-02-25T20:47:21Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=25, tm_hour=20, tm_min=47, tm_sec=21, tm_wday=3, tm_yday=56, tm_isdst=0), 'published': '2021-02-25T20:47:21Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=25, tm_hour=20, tm_min=47, tm_sec=21, tm_wday=3, tm_yday=56, tm_isdst=0), 'title': 'Images, Emotions, and Credibility: Effect of Emotional Facial Images on\n  Perceptions of News Content Bias and Source Credibility in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Images, Emotions, and Credibility: Effect of Emotional Facial Images on\n  Perceptions of News Content Bias and Source Credibility in Social Media'}, 'summary': ""Images are an indispensable part of the news content we consume. Highly\nemotional images from sources of misinformation can greatly influence our\njudgements. We present two studies on the effects of emotional facial images on\nusers' perception of bias in news content and the credibility of sources. In\nstudy 1, we investigate the impact of happy and angry facial images on users'\ndecisions. In study 2, we focus on sources' systematic emotional treatment of\nspecific politicians. Our results show that depending on the political\norientation of the source, the cumulative effect of angry facial emotions\nimpacts users' perceived content bias and source credibility. When sources\nsystematically portray specific politicians as angry, users are more likely to\nfind those sources as less credible and their content as more biased. These\nresults highlight how implicit visual propositions manifested by emotions in\nfacial expressions might have a substantial effect on our trust of news content\nand sources."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Images are an indispensable part of the news content we consume. Highly\nemotional images from sources of misinformation can greatly influence our\njudgements. We present two studies on the effects of emotional facial images on\nusers' perception of bias in news content and the credibility of sources. In\nstudy 1, we investigate the impact of happy and angry facial images on users'\ndecisions. In study 2, we focus on sources' systematic emotional treatment of\nspecific politicians. Our results show that depending on the political\norientation of the source, the cumulative effect of angry facial emotions\nimpacts users' perceived content bias and source credibility. When sources\nsystematically portray specific politicians as angry, users are more likely to\nfind those sources as less credible and their content as more biased. These\nresults highlight how implicit visual propositions manifested by emotions in\nfacial expressions might have a substantial effect on our trust of news content\nand sources.""}, 'authors': [{'name': 'Alireza Karduni'}, {'name': 'Ryan Wesslen'}, {'name': 'Douglas Markant'}, {'name': 'Wenwen Dou'}], 'author_detail': {'name': 'Wenwen Dou'}, 'author': 'Wenwen Dou', 'arxiv_comment': '23 pages, 9 figures', 'links': [{'href': 'http://arxiv.org/abs/2102.13167v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.13167v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
134,http://arxiv.org/abs/2102.11917v1,2021-02-23 19:55:45+00:00,2021-02-23 19:55:45+00:00,The Sensitivity of Word Embeddings-based Author Detection Models to Semantic-preserving Adversarial Perturbations,"[arxiv.Result.Author('Jeremiah Duncan'), arxiv.Result.Author('Fabian Fallas'), arxiv.Result.Author('Chris Gropp'), arxiv.Result.Author('Emily Herron'), arxiv.Result.Author('Maria Mahbub'), arxiv.Result.Author('Paula Olaya'), arxiv.Result.Author('Eduardo Ponce'), arxiv.Result.Author('Tabitha K. Samuel'), arxiv.Result.Author('Daniel Schultz'), arxiv.Result.Author('Sudarshan Srinivasan'), arxiv.Result.Author('Maofeng Tang'), arxiv.Result.Author('Viktor Zenkov'), arxiv.Result.Author('Quan Zhou'), arxiv.Result.Author('Edmon Begoli')]","Authorship analysis is an important subject in the field of natural language
processing. It allows the detection of the most likely writer of articles,
news, books, or messages. This technique has multiple uses in tasks related to
authorship attribution, detection of plagiarism, style analysis, sources of
misinformation, etc. The focus of this paper is to explore the limitations and
sensitiveness of established approaches to adversarial manipulations of inputs.
To this end, and using those established techniques, we first developed an
experimental frame-work for author detection and input perturbations. Next, we
experimentally evaluated the performance of the authorship detection model to a
collection of semantic-preserving adversarial perturbations of input
narratives. Finally, we compare and analyze the effects of different
perturbation strategies, input and model configurations, and the effects of
these on the author detection model.",,,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2102.11917v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.11917v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.11917v1,"{'id': 'http://arxiv.org/abs/2102.11917v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.11917v1', 'updated': '2021-02-23T19:55:45Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=23, tm_hour=19, tm_min=55, tm_sec=45, tm_wday=1, tm_yday=54, tm_isdst=0), 'published': '2021-02-23T19:55:45Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=23, tm_hour=19, tm_min=55, tm_sec=45, tm_wday=1, tm_yday=54, tm_isdst=0), 'title': 'The Sensitivity of Word Embeddings-based Author Detection Models to\n  Semantic-preserving Adversarial Perturbations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Sensitivity of Word Embeddings-based Author Detection Models to\n  Semantic-preserving Adversarial Perturbations'}, 'summary': 'Authorship analysis is an important subject in the field of natural language\nprocessing. It allows the detection of the most likely writer of articles,\nnews, books, or messages. This technique has multiple uses in tasks related to\nauthorship attribution, detection of plagiarism, style analysis, sources of\nmisinformation, etc. The focus of this paper is to explore the limitations and\nsensitiveness of established approaches to adversarial manipulations of inputs.\nTo this end, and using those established techniques, we first developed an\nexperimental frame-work for author detection and input perturbations. Next, we\nexperimentally evaluated the performance of the authorship detection model to a\ncollection of semantic-preserving adversarial perturbations of input\nnarratives. Finally, we compare and analyze the effects of different\nperturbation strategies, input and model configurations, and the effects of\nthese on the author detection model.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Authorship analysis is an important subject in the field of natural language\nprocessing. It allows the detection of the most likely writer of articles,\nnews, books, or messages. This technique has multiple uses in tasks related to\nauthorship attribution, detection of plagiarism, style analysis, sources of\nmisinformation, etc. The focus of this paper is to explore the limitations and\nsensitiveness of established approaches to adversarial manipulations of inputs.\nTo this end, and using those established techniques, we first developed an\nexperimental frame-work for author detection and input perturbations. Next, we\nexperimentally evaluated the performance of the authorship detection model to a\ncollection of semantic-preserving adversarial perturbations of input\nnarratives. Finally, we compare and analyze the effects of different\nperturbation strategies, input and model configurations, and the effects of\nthese on the author detection model.'}, 'authors': [{'name': 'Jeremiah Duncan'}, {'name': 'Fabian Fallas'}, {'name': 'Chris Gropp'}, {'name': 'Emily Herron'}, {'name': 'Maria Mahbub'}, {'name': 'Paula Olaya'}, {'name': 'Eduardo Ponce'}, {'name': 'Tabitha K. Samuel'}, {'name': 'Daniel Schultz'}, {'name': 'Sudarshan Srinivasan'}, {'name': 'Maofeng Tang'}, {'name': 'Viktor Zenkov'}, {'name': 'Quan Zhou'}, {'name': 'Edmon Begoli'}], 'author_detail': {'name': 'Edmon Begoli'}, 'author': 'Edmon Begoli', 'links': [{'href': 'http://arxiv.org/abs/2102.11917v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.11917v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
135,http://arxiv.org/abs/2102.11362v1,2021-02-22 21:06:52+00:00,2021-02-22 21:06:52+00:00,An ontological analysis of misinformation in online social networks,"[arxiv.Result.Author('Izzat Alsmadi'), arxiv.Result.Author('Iyad Alazzam'), arxiv.Result.Author('Mohammad A. AlRamahi')]","The internet, Online Social Networks (OSNs) and smart phones enable users to
create tremendous amount of information. Users who search for general or
specific knowledge may not have these days problems of information scarce but
misinformation. Misinformation nowadays can refer to a continuous spectrum
between what can be seen as ""facts"" or ""truth"", if humans agree on the
existence of such, to false information that everyone agree that it is false.
In this paper, we will look at this spectrum of information/misinformation and
compare between some of the major relevant concepts. While few fact-checking
websites exist to evaluate news articles or some of the popular claims people
exchange, nonetheless this can be seen as a little effort in the mission to tag
online information with their ""proper"" category or label.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2102.11362v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.11362v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.11362v1,"{'id': 'http://arxiv.org/abs/2102.11362v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.11362v1', 'updated': '2021-02-22T21:06:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=22, tm_hour=21, tm_min=6, tm_sec=52, tm_wday=0, tm_yday=53, tm_isdst=0), 'published': '2021-02-22T21:06:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=22, tm_hour=21, tm_min=6, tm_sec=52, tm_wday=0, tm_yday=53, tm_isdst=0), 'title': 'An ontological analysis of misinformation in online social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An ontological analysis of misinformation in online social networks'}, 'summary': 'The internet, Online Social Networks (OSNs) and smart phones enable users to\ncreate tremendous amount of information. Users who search for general or\nspecific knowledge may not have these days problems of information scarce but\nmisinformation. Misinformation nowadays can refer to a continuous spectrum\nbetween what can be seen as ""facts"" or ""truth"", if humans agree on the\nexistence of such, to false information that everyone agree that it is false.\nIn this paper, we will look at this spectrum of information/misinformation and\ncompare between some of the major relevant concepts. While few fact-checking\nwebsites exist to evaluate news articles or some of the popular claims people\nexchange, nonetheless this can be seen as a little effort in the mission to tag\nonline information with their ""proper"" category or label.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The internet, Online Social Networks (OSNs) and smart phones enable users to\ncreate tremendous amount of information. Users who search for general or\nspecific knowledge may not have these days problems of information scarce but\nmisinformation. Misinformation nowadays can refer to a continuous spectrum\nbetween what can be seen as ""facts"" or ""truth"", if humans agree on the\nexistence of such, to false information that everyone agree that it is false.\nIn this paper, we will look at this spectrum of information/misinformation and\ncompare between some of the major relevant concepts. While few fact-checking\nwebsites exist to evaluate news articles or some of the popular claims people\nexchange, nonetheless this can be seen as a little effort in the mission to tag\nonline information with their ""proper"" category or label.'}, 'authors': [{'name': 'Izzat Alsmadi'}, {'name': 'Iyad Alazzam'}, {'name': 'Mohammad A. AlRamahi'}], 'author_detail': {'name': 'Mohammad A. AlRamahi'}, 'author': 'Mohammad A. AlRamahi', 'links': [{'href': 'http://arxiv.org/abs/2102.11362v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.11362v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
136,http://arxiv.org/abs/2102.11105v2,2021-04-22 16:05:49+00:00,2021-02-22 15:26:36+00:00,REMOD: Relation Extraction for Modeling Online Discourse,"[arxiv.Result.Author('Matthew Sumpter'), arxiv.Result.Author('Giovanni Luca Ciampaglia')]","The enormous amount of discourse taking place online poses challenges to the
functioning of a civil and informed public sphere. Efforts to standardize
online discourse data, such as ClaimReview, are making available a wealth of
new data about potentially inaccurate claims, reviewed by third-party
fact-checkers. These data could help shed light on the nature of online
discourse, the role of political elites in amplifying it, and its implications
for the integrity of the online information ecosystem. Unfortunately, the
semi-structured nature of much of this data presents significant challenges
when it comes to modeling and reasoning about online discourse. A key challenge
is relation extraction, which is the task of determining the semantic
relationships between named entities in a claim. Here we develop a novel
supervised learning method for relation extraction that combines graph
embedding techniques with path traversal on semantic dependency graphs. Our
approach is based on the intuitive observation that knowledge of the entities
along the path between the subject and object of a triple (e.g.
Washington,_D.C.}, and United_States_of_America) provides useful information
that can be leveraged for extracting its semantic relation (i.e. capitalOf). As
an example of a potential application of this technique for modeling online
discourse, we show that our method can be integrated into a pipeline to reason
about potential misinformation claims.","11 pages, 5 figures",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2102.11105v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.11105v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.11105v2,"{'id': 'http://arxiv.org/abs/2102.11105v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.11105v2', 'updated': '2021-04-22T16:05:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=22, tm_hour=16, tm_min=5, tm_sec=49, tm_wday=3, tm_yday=112, tm_isdst=0), 'published': '2021-02-22T15:26:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=22, tm_hour=15, tm_min=26, tm_sec=36, tm_wday=0, tm_yday=53, tm_isdst=0), 'title': 'REMOD: Relation Extraction for Modeling Online Discourse', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'REMOD: Relation Extraction for Modeling Online Discourse'}, 'summary': 'The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.'}, 'authors': [{'name': 'Matthew Sumpter'}, {'name': 'Giovanni Luca Ciampaglia'}], 'author_detail': {'name': 'Giovanni Luca Ciampaglia'}, 'author': 'Giovanni Luca Ciampaglia', 'arxiv_comment': '11 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2102.11105v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.11105v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
137,http://arxiv.org/abs/2102.08924v3,2021-04-13 08:38:02+00:00,2021-02-17 18:30:43+00:00,Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for COVID-19 Fake News Detection,"[arxiv.Result.Author('William Scott Paka'), arxiv.Result.Author('Rachit Bansal'), arxiv.Result.Author('Abhay Kaushik'), arxiv.Result.Author('Shubhashis Sengupta'), arxiv.Result.Author('Tanmoy Chakraborty')]","As the COVID-19 pandemic sweeps across the world, it has been accompanied by
a tsunami of fake news and misinformation on social media. At the time when
reliable information is vital for public health and safety, COVID-19 related
fake news has been spreading even faster than the facts. During times such as
the COVID-19 pandemic, fake news can not only cause intellectual confusion but
can also place lives of people at risk. This calls for an immediate need to
contain the spread of such misinformation on social media. We introduce CTF,
the first COVID-19 Twitter fake news dataset with labeled genuine and fake
tweets. Additionally, we propose Cross-SEAN, a cross-stitch based
semi-supervised end-to-end neural attention model, which leverages the large
amount of unlabelled data. Cross-SEAN partially generalises to emerging fake
news as it learns from relevant external knowledge. We compare Cross-SEAN with
seven state-of-the-art fake news detection methods. We observe that it achieves
$0.95$ F1 Score on CTF, outperforming the best baseline by $9\%$. We also
develop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time
detection of fake tweets.",The Journal of Applied Soft Computing,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2102.08924v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.08924v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.08924v3,"{'id': 'http://arxiv.org/abs/2102.08924v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.08924v3', 'updated': '2021-04-13T08:38:02Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=13, tm_hour=8, tm_min=38, tm_sec=2, tm_wday=1, tm_yday=103, tm_isdst=0), 'published': '2021-02-17T18:30:43Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=30, tm_sec=43, tm_wday=2, tm_yday=48, tm_isdst=0), 'title': 'Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection'}, 'summary': 'As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.'}, 'authors': [{'name': 'William Scott Paka'}, {'name': 'Rachit Bansal'}, {'name': 'Abhay Kaushik'}, {'name': 'Shubhashis Sengupta'}, {'name': 'Tanmoy Chakraborty'}], 'author_detail': {'name': 'Tanmoy Chakraborty'}, 'author': 'Tanmoy Chakraborty', 'arxiv_comment': 'The Journal of Applied Soft Computing', 'links': [{'href': 'http://arxiv.org/abs/2102.08924v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.08924v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
138,http://arxiv.org/abs/2102.08537v3,2021-04-07 05:06:05+00:00,2021-02-17 02:35:13+00:00,"Political Bias and Factualness in News Sharing across more than 100,000 Online Communities","[arxiv.Result.Author('Galen Weld'), arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Tim Althoff')]","As civil discourse increasingly takes place online, misinformation and the
polarization of news shared in online communities have become ever more
relevant concerns with real world harms across our society. Studying online
news sharing at scale is challenging due to the massive volume of content which
is shared by millions of users across thousands of communities. Therefore,
existing research has largely focused on specific communities or specific
interventions, such as bans. However, understanding the prevalence and spread
of misinformation and polarization more broadly, across thousands of online
communities, is critical for the development of governance strategies,
interventions, and community design. Here, we conduct the largest study of news
sharing on reddit to date, analyzing more than 550 million links spanning 4
years. We use non-partisan news source ratings from Media Bias/Fact Check to
annotate links to news sources with their political bias and factualness. We
find that, compared to left-leaning communities, right-leaning communities have
105% more variance in the political bias of their news sources, and more links
to relatively-more biased sources, on average. We observe that reddit users'
voting and re-sharing behaviors generally decrease the visibility of extremely
biased and low factual content, which receives 20% fewer upvotes and 30% fewer
exposures from crossposts than more neutral or more factual content. This
suggests that reddit is more resilient to low factual content than Twitter. We
show that extremely biased and low factual content is very concentrated, with
99% of such content being shared in only 0.5% of communities, giving credence
to the recent strategy of community-wide bans and quarantines.","12 pages, 7 figures. To appear at ICWSM 2021, camera ready version
  included here",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2102.08537v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.08537v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.08537v3,"{'id': 'http://arxiv.org/abs/2102.08537v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.08537v3', 'updated': '2021-04-07T05:06:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=7, tm_hour=5, tm_min=6, tm_sec=5, tm_wday=2, tm_yday=97, tm_isdst=0), 'published': '2021-02-17T02:35:13Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=35, tm_sec=13, tm_wday=2, tm_yday=48, tm_isdst=0), 'title': 'Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities'}, 'summary': ""As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines.""}, 'authors': [{'name': 'Galen Weld'}, {'name': 'Maria Glenski'}, {'name': 'Tim Althoff'}], 'author_detail': {'name': 'Tim Althoff'}, 'author': 'Tim Althoff', 'arxiv_comment': '12 pages, 7 figures. To appear at ICWSM 2021, camera ready version\n  included here', 'links': [{'href': 'http://arxiv.org/abs/2102.08537v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.08537v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
139,http://arxiv.org/abs/2102.08436v1,2021-02-16 20:18:59+00:00,2021-02-16 20:18:59+00:00,Social Bots and Social Media Manipulation in 2020: The Year in Review,"[arxiv.Result.Author('Ho-Chun Herbert Chang'), arxiv.Result.Author('Emily Chen'), arxiv.Result.Author('Meiqing Zhang'), arxiv.Result.Author('Goran Muric'), arxiv.Result.Author('Emilio Ferrara')]","The year 2020 will be remembered for two events of global significance: the
COVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we
summarize recent studies using large public Twitter data sets on these issues.
We have three primary objectives. First, we delineate epistemological and
practical considerations when combining the traditions of computational
research and social science research. A sensible balance should be struck when
the stakes are high between advancing social theory and concrete, timely
reporting of ongoing events. We additionally comment on the computational
challenges of gleaning insight from large amounts of social media data. Second,
we characterize the role of social bots in social media manipulation around the
discourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third,
we compare results from 2020 to prior years to note that, although bot accounts
still contribute to the emergence of echo-chambers, there is a transition from
state-sponsored campaigns to domestically emergent sources of distortion.
Furthermore, issues of public health can be confounded by political
orientation, especially from localized communities of actors who spread
misinformation. We conclude that automation and social media manipulation pose
issues to a healthy and democratic discourse, precisely because they distort
representation of pluralism within the public sphere.","Book Chapter submitted for the Handbook of Computational Social
  Science",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2102.08436v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.08436v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.08436v1,"{'id': 'http://arxiv.org/abs/2102.08436v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.08436v1', 'updated': '2021-02-16T20:18:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=18, tm_sec=59, tm_wday=1, tm_yday=47, tm_isdst=0), 'published': '2021-02-16T20:18:59Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=18, tm_sec=59, tm_wday=1, tm_yday=47, tm_isdst=0), 'title': 'Social Bots and Social Media Manipulation in 2020: The Year in Review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Bots and Social Media Manipulation in 2020: The Year in Review'}, 'summary': 'The year 2020 will be remembered for two events of global significance: the\nCOVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we\nsummarize recent studies using large public Twitter data sets on these issues.\nWe have three primary objectives. First, we delineate epistemological and\npractical considerations when combining the traditions of computational\nresearch and social science research. A sensible balance should be struck when\nthe stakes are high between advancing social theory and concrete, timely\nreporting of ongoing events. We additionally comment on the computational\nchallenges of gleaning insight from large amounts of social media data. Second,\nwe characterize the role of social bots in social media manipulation around the\ndiscourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third,\nwe compare results from 2020 to prior years to note that, although bot accounts\nstill contribute to the emergence of echo-chambers, there is a transition from\nstate-sponsored campaigns to domestically emergent sources of distortion.\nFurthermore, issues of public health can be confounded by political\norientation, especially from localized communities of actors who spread\nmisinformation. We conclude that automation and social media manipulation pose\nissues to a healthy and democratic discourse, precisely because they distort\nrepresentation of pluralism within the public sphere.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The year 2020 will be remembered for two events of global significance: the\nCOVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we\nsummarize recent studies using large public Twitter data sets on these issues.\nWe have three primary objectives. First, we delineate epistemological and\npractical considerations when combining the traditions of computational\nresearch and social science research. A sensible balance should be struck when\nthe stakes are high between advancing social theory and concrete, timely\nreporting of ongoing events. We additionally comment on the computational\nchallenges of gleaning insight from large amounts of social media data. Second,\nwe characterize the role of social bots in social media manipulation around the\ndiscourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third,\nwe compare results from 2020 to prior years to note that, although bot accounts\nstill contribute to the emergence of echo-chambers, there is a transition from\nstate-sponsored campaigns to domestically emergent sources of distortion.\nFurthermore, issues of public health can be confounded by political\norientation, especially from localized communities of actors who spread\nmisinformation. We conclude that automation and social media manipulation pose\nissues to a healthy and democratic discourse, precisely because they distort\nrepresentation of pluralism within the public sphere.'}, 'authors': [{'name': 'Ho-Chun Herbert Chang'}, {'name': 'Emily Chen'}, {'name': 'Meiqing Zhang'}, {'name': 'Goran Muric'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'arxiv_comment': 'Book Chapter submitted for the Handbook of Computational Social\n  Science', 'links': [{'href': 'http://arxiv.org/abs/2102.08436v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.08436v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
140,http://arxiv.org/abs/2102.08355v1,2021-02-16 18:45:01+00:00,2021-02-16 18:45:01+00:00,Adversarial Targeted Forgetting in Regularization and Generative Based Continual Learning Models,"[arxiv.Result.Author('Muhammad Umer'), arxiv.Result.Author('Robi Polikar')]","Continual (or ""incremental"") learning approaches are employed when additional
knowledge or tasks need to be learned from subsequent batches or from streaming
data. However these approaches are typically adversary agnostic, i.e., they do
not consider the possibility of a malicious attack. In our prior work, we
explored the vulnerabilities of Elastic Weight Consolidation (EWC) to the
perceptible misinformation. We now explore the vulnerabilities of other
regularization-based as well as generative replay-based continual learning
algorithms, and also extend the attack to imperceptible misinformation. We show
that an intelligent adversary can take advantage of a continual learning
algorithm's capabilities of retaining existing knowledge over time, and force
it to learn and retain deliberately introduced misinformation. To demonstrate
this vulnerability, we inject backdoor attack samples into the training data.
These attack samples constitute the misinformation, allowing the attacker to
capture control of the model at test time. We evaluate the extent of this
vulnerability on both rotated and split benchmark variants of the MNIST dataset
under two important domain and class incremental learning scenarios. We show
that the adversary can create a ""false memory"" about any task by inserting
carefully-designed backdoor samples to the test instances of that task thereby
controlling the amount of forgetting of any task of its choosing. Perhaps most
importantly, we show this vulnerability to be very acute and damaging: the
model memory can be easily compromised with the addition of backdoor samples
into as little as 1\% of the training data, even when the misinformation is
imperceptible to human eye.",arXiv admin note: text overlap with arXiv:2002.07111,,,cs.LG,"['cs.LG', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2102.08355v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.08355v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.08355v1,"{'id': 'http://arxiv.org/abs/2102.08355v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.08355v1', 'updated': '2021-02-16T18:45:01Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=45, tm_sec=1, tm_wday=1, tm_yday=47, tm_isdst=0), 'published': '2021-02-16T18:45:01Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=45, tm_sec=1, tm_wday=1, tm_yday=47, tm_isdst=0), 'title': 'Adversarial Targeted Forgetting in Regularization and Generative Based\n  Continual Learning Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversarial Targeted Forgetting in Regularization and Generative Based\n  Continual Learning Models'}, 'summary': 'Continual (or ""incremental"") learning approaches are employed when additional\nknowledge or tasks need to be learned from subsequent batches or from streaming\ndata. However these approaches are typically adversary agnostic, i.e., they do\nnot consider the possibility of a malicious attack. In our prior work, we\nexplored the vulnerabilities of Elastic Weight Consolidation (EWC) to the\nperceptible misinformation. We now explore the vulnerabilities of other\nregularization-based as well as generative replay-based continual learning\nalgorithms, and also extend the attack to imperceptible misinformation. We show\nthat an intelligent adversary can take advantage of a continual learning\nalgorithm\'s capabilities of retaining existing knowledge over time, and force\nit to learn and retain deliberately introduced misinformation. To demonstrate\nthis vulnerability, we inject backdoor attack samples into the training data.\nThese attack samples constitute the misinformation, allowing the attacker to\ncapture control of the model at test time. We evaluate the extent of this\nvulnerability on both rotated and split benchmark variants of the MNIST dataset\nunder two important domain and class incremental learning scenarios. We show\nthat the adversary can create a ""false memory"" about any task by inserting\ncarefully-designed backdoor samples to the test instances of that task thereby\ncontrolling the amount of forgetting of any task of its choosing. Perhaps most\nimportantly, we show this vulnerability to be very acute and damaging: the\nmodel memory can be easily compromised with the addition of backdoor samples\ninto as little as 1\\% of the training data, even when the misinformation is\nimperceptible to human eye.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Continual (or ""incremental"") learning approaches are employed when additional\nknowledge or tasks need to be learned from subsequent batches or from streaming\ndata. However these approaches are typically adversary agnostic, i.e., they do\nnot consider the possibility of a malicious attack. In our prior work, we\nexplored the vulnerabilities of Elastic Weight Consolidation (EWC) to the\nperceptible misinformation. We now explore the vulnerabilities of other\nregularization-based as well as generative replay-based continual learning\nalgorithms, and also extend the attack to imperceptible misinformation. We show\nthat an intelligent adversary can take advantage of a continual learning\nalgorithm\'s capabilities of retaining existing knowledge over time, and force\nit to learn and retain deliberately introduced misinformation. To demonstrate\nthis vulnerability, we inject backdoor attack samples into the training data.\nThese attack samples constitute the misinformation, allowing the attacker to\ncapture control of the model at test time. We evaluate the extent of this\nvulnerability on both rotated and split benchmark variants of the MNIST dataset\nunder two important domain and class incremental learning scenarios. We show\nthat the adversary can create a ""false memory"" about any task by inserting\ncarefully-designed backdoor samples to the test instances of that task thereby\ncontrolling the amount of forgetting of any task of its choosing. Perhaps most\nimportantly, we show this vulnerability to be very acute and damaging: the\nmodel memory can be easily compromised with the addition of backdoor samples\ninto as little as 1\\% of the training data, even when the misinformation is\nimperceptible to human eye.'}, 'authors': [{'name': 'Muhammad Umer'}, {'name': 'Robi Polikar'}], 'author_detail': {'name': 'Robi Polikar'}, 'author': 'Robi Polikar', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:2002.07111', 'links': [{'href': 'http://arxiv.org/abs/2102.08355v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.08355v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
141,http://arxiv.org/abs/2102.07857v1,2021-02-15 21:41:12+00:00,2021-02-15 21:41:12+00:00,KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for Misinformation Detection,"[arxiv.Result.Author('Sara Abdali'), arxiv.Result.Author('Neil Shah'), arxiv.Result.Author('Evangelos E. Papalexakis')]","Graphs are one of the most efficacious structures for representing datapoints
and their relations, and they have been largely exploited for different
applications. Previously, the higher-order relations between the nodes have
been modeled by a generalization of graphs known as hypergraphs. In
hypergraphs, the edges are defined by a set of nodes i.e., hyperedges to
demonstrate the higher order relationships between the data. However, there is
no explicit higher-order generalization for nodes themselves. In this work, we
introduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph
(KNH) where the nodes are defined by higher order Euclidean subspaces for
multi-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or
more precisely m-flats instead of datapoints. We experimentally evaluate the
KNH graph on two multi-aspect datasets for misinformation detection. The
experimental results suggest that multi-view modeling of articles using KNH
graph outperforms the classic KNN graph in terms of classification performance.",,"Second International TrueFact Workshop 2020: Making a Credible Web
  for Tomorrow",,cs.LG,"['cs.LG', 'cs.AI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2102.07857v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.07857v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.07857v1,"{'id': 'http://arxiv.org/abs/2102.07857v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.07857v1', 'updated': '2021-02-15T21:41:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=41, tm_sec=12, tm_wday=0, tm_yday=46, tm_isdst=0), 'published': '2021-02-15T21:41:12Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=41, tm_sec=12, tm_wday=0, tm_yday=46, tm_isdst=0), 'title': 'KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for\n  Misinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for\n  Misinformation Detection'}, 'summary': 'Graphs are one of the most efficacious structures for representing datapoints\nand their relations, and they have been largely exploited for different\napplications. Previously, the higher-order relations between the nodes have\nbeen modeled by a generalization of graphs known as hypergraphs. In\nhypergraphs, the edges are defined by a set of nodes i.e., hyperedges to\ndemonstrate the higher order relationships between the data. However, there is\nno explicit higher-order generalization for nodes themselves. In this work, we\nintroduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph\n(KNH) where the nodes are defined by higher order Euclidean subspaces for\nmulti-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or\nmore precisely m-flats instead of datapoints. We experimentally evaluate the\nKNH graph on two multi-aspect datasets for misinformation detection. The\nexperimental results suggest that multi-view modeling of articles using KNH\ngraph outperforms the classic KNN graph in terms of classification performance.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Graphs are one of the most efficacious structures for representing datapoints\nand their relations, and they have been largely exploited for different\napplications. Previously, the higher-order relations between the nodes have\nbeen modeled by a generalization of graphs known as hypergraphs. In\nhypergraphs, the edges are defined by a set of nodes i.e., hyperedges to\ndemonstrate the higher order relationships between the data. However, there is\nno explicit higher-order generalization for nodes themselves. In this work, we\nintroduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph\n(KNH) where the nodes are defined by higher order Euclidean subspaces for\nmulti-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or\nmore precisely m-flats instead of datapoints. We experimentally evaluate the\nKNH graph on two multi-aspect datasets for misinformation detection. The\nexperimental results suggest that multi-view modeling of articles using KNH\ngraph outperforms the classic KNN graph in terms of classification performance.'}, 'authors': [{'name': 'Sara Abdali'}, {'name': 'Neil Shah'}, {'name': 'Evangelos E. Papalexakis'}], 'author_detail': {'name': 'Evangelos E. Papalexakis'}, 'author': 'Evangelos E. Papalexakis', 'arxiv_journal_ref': 'Second International TrueFact Workshop 2020: Making a Credible Web\n  for Tomorrow', 'links': [{'href': 'http://arxiv.org/abs/2102.07857v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.07857v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
142,http://arxiv.org/abs/2102.07849v2,2021-06-03 22:32:32+00:00,2021-02-15 21:05:11+00:00,Identifying Misinformation from Website Screenshots,"[arxiv.Result.Author('Sara Abdali'), arxiv.Result.Author('Rutuja Gurav'), arxiv.Result.Author('Siddharth Menon'), arxiv.Result.Author('Daniel Fonseca'), arxiv.Result.Author('Negin Entezari'), arxiv.Result.Author('Neil Shah'), arxiv.Result.Author('Evangelos E. Papalexakis')]","Can the look and the feel of a website give information about the
trustworthiness of an article? In this paper, we propose to use a promising,
yet neglected aspect in detecting the misinformativeness: the overall look of
the domain webpage. To capture this overall look, we take screenshots of news
articles served by either misinformative or trustworthy web domains and
leverage a tensor decomposition based semi-supervised classification technique.
The proposed approach i.e., VizFake is insensitive to a number of image
transformations such as converting the image to grayscale, vectorizing the
image and losing some parts of the screenshots. VizFake leverages a very small
amount of known labels, mirroring realistic and practical scenarios, where
labels (especially for known misinformative articles), are scarce and quickly
become dated. The F1 score of VizFake on a dataset of 50k screenshots of news
articles spanning more than 500 domains is roughly 85% using only 5% of ground
truth labels. Furthermore, tensor representations of VizFake, obtained in an
unsupervised manner, allow for exploratory analysis of the data that provides
valuable insights into the problem. Finally, we compare VizFake with deep
transfer learning, since it is a very popular black-box approach for image
classification and also well-known text text-based methods. VizFake achieves
competitive accuracy with deep transfer learning models while being two orders
of magnitude faster and not requiring laborious hyper-parameter tuning.",,"The International AAAI Conference on Web and Social Media (ICWSM)
  2021",,cs.LG,"['cs.LG', 'cs.AI', 'cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2102.07849v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.07849v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.07849v2,"{'id': 'http://arxiv.org/abs/2102.07849v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.07849v2', 'updated': '2021-06-03T22:32:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=22, tm_min=32, tm_sec=32, tm_wday=3, tm_yday=154, tm_isdst=0), 'published': '2021-02-15T21:05:11Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=5, tm_sec=11, tm_wday=0, tm_yday=46, tm_isdst=0), 'title': 'Identifying Misinformation from Website Screenshots', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Misinformation from Website Screenshots'}, 'summary': 'Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.'}, 'authors': [{'name': 'Sara Abdali'}, {'name': 'Rutuja Gurav'}, {'name': 'Siddharth Menon'}, {'name': 'Daniel Fonseca'}, {'name': 'Negin Entezari'}, {'name': 'Neil Shah'}, {'name': 'Evangelos E. Papalexakis'}], 'author_detail': {'name': 'Evangelos E. Papalexakis'}, 'author': 'Evangelos E. Papalexakis', 'arxiv_journal_ref': 'The International AAAI Conference on Web and Social Media (ICWSM)\n  2021', 'links': [{'href': 'http://arxiv.org/abs/2102.07849v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.07849v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
143,http://arxiv.org/abs/2102.06109v1,2021-02-11 16:44:09+00:00,2021-02-11 16:44:09+00:00,The Deepfake Detection Dilemma: A Multistakeholder Exploration of Adversarial Dynamics in Synthetic Media,"[arxiv.Result.Author('Claire Leibowicz'), arxiv.Result.Author('Sean McGregor'), arxiv.Result.Author('Aviv Ovadya')]","Synthetic media detection technologies label media as either synthetic or
non-synthetic and are increasingly used by journalists, web platforms, and the
general public to identify misinformation and other forms of problematic
content. As both well-resourced organizations and the non-technical general
public generate more sophisticated synthetic media, the capacity for purveyors
of problematic content to adapt induces a \newterm{detection dilemma}: as
detection practices become more accessible, they become more easily
circumvented. This paper describes how a multistakeholder cohort from academia,
technology platforms, media entities, and civil society organizations active in
synthetic media detection and its socio-technical implications evaluates the
detection dilemma. Specifically, we offer an assessment of detection contexts
and adversary capacities sourced from the broader, global AI and media
integrity community concerned with mitigating the spread of harmful synthetic
media. A collection of personas illustrates the intersection between
unsophisticated and highly-resourced sponsors of misinformation in the context
of their technical capacities. This work concludes that there is no ""best""
approach to navigating the detector dilemma, but derives a set of implications
from multistakeholder input to better inform detection process decisions and
policies, in practice.","11 pages, 8 Figures",,,cs.CY,"['cs.CY', 'cs.CV', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2102.06109v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.06109v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.06109v1,"{'id': 'http://arxiv.org/abs/2102.06109v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.06109v1', 'updated': '2021-02-11T16:44:09Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=11, tm_hour=16, tm_min=44, tm_sec=9, tm_wday=3, tm_yday=42, tm_isdst=0), 'published': '2021-02-11T16:44:09Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=11, tm_hour=16, tm_min=44, tm_sec=9, tm_wday=3, tm_yday=42, tm_isdst=0), 'title': 'The Deepfake Detection Dilemma: A Multistakeholder Exploration of\n  Adversarial Dynamics in Synthetic Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Deepfake Detection Dilemma: A Multistakeholder Exploration of\n  Adversarial Dynamics in Synthetic Media'}, 'summary': 'Synthetic media detection technologies label media as either synthetic or\nnon-synthetic and are increasingly used by journalists, web platforms, and the\ngeneral public to identify misinformation and other forms of problematic\ncontent. As both well-resourced organizations and the non-technical general\npublic generate more sophisticated synthetic media, the capacity for purveyors\nof problematic content to adapt induces a \\newterm{detection dilemma}: as\ndetection practices become more accessible, they become more easily\ncircumvented. This paper describes how a multistakeholder cohort from academia,\ntechnology platforms, media entities, and civil society organizations active in\nsynthetic media detection and its socio-technical implications evaluates the\ndetection dilemma. Specifically, we offer an assessment of detection contexts\nand adversary capacities sourced from the broader, global AI and media\nintegrity community concerned with mitigating the spread of harmful synthetic\nmedia. A collection of personas illustrates the intersection between\nunsophisticated and highly-resourced sponsors of misinformation in the context\nof their technical capacities. This work concludes that there is no ""best""\napproach to navigating the detector dilemma, but derives a set of implications\nfrom multistakeholder input to better inform detection process decisions and\npolicies, in practice.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Synthetic media detection technologies label media as either synthetic or\nnon-synthetic and are increasingly used by journalists, web platforms, and the\ngeneral public to identify misinformation and other forms of problematic\ncontent. As both well-resourced organizations and the non-technical general\npublic generate more sophisticated synthetic media, the capacity for purveyors\nof problematic content to adapt induces a \\newterm{detection dilemma}: as\ndetection practices become more accessible, they become more easily\ncircumvented. This paper describes how a multistakeholder cohort from academia,\ntechnology platforms, media entities, and civil society organizations active in\nsynthetic media detection and its socio-technical implications evaluates the\ndetection dilemma. Specifically, we offer an assessment of detection contexts\nand adversary capacities sourced from the broader, global AI and media\nintegrity community concerned with mitigating the spread of harmful synthetic\nmedia. A collection of personas illustrates the intersection between\nunsophisticated and highly-resourced sponsors of misinformation in the context\nof their technical capacities. This work concludes that there is no ""best""\napproach to navigating the detector dilemma, but derives a set of implications\nfrom multistakeholder input to better inform detection process decisions and\npolicies, in practice.'}, 'authors': [{'name': 'Claire Leibowicz'}, {'name': 'Sean McGregor'}, {'name': 'Aviv Ovadya'}], 'author_detail': {'name': 'Aviv Ovadya'}, 'author': 'Aviv Ovadya', 'arxiv_comment': '11 pages, 8 Figures', 'links': [{'href': 'http://arxiv.org/abs/2102.06109v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.06109v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
144,http://arxiv.org/abs/2102.04031v1,2021-02-08 07:08:36+00:00,2021-02-08 07:08:36+00:00,Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers' Protest,"[arxiv.Result.Author('Dibyendu Mishra'), arxiv.Result.Author('Syeda Zainab Akbar'), arxiv.Result.Author('Arshia Arya'), arxiv.Result.Author('Saloni Dash'), arxiv.Result.Author('Rynaa Grover'), arxiv.Result.Author('Joyojeet Pal')]","A tweet from popular entertainer and businesswoman, Rihanna, bringing
attention to farmers' protests around Delhi set off heightened activity on
Indian social media. An immediate consequence was the weighing in by Indian
politicians, entertainers, media and other influencers on the issue. In this
paper, we use data from Twitter and an archive of debunked misinformation
stories to understand some of the patterns around influencer engagement with a
political issue. We found that more followed influencers were less likely to
come out in support of the tweet. We also find that the later engagement of
major influencers on the side of the government's position shows suggestion's
of collusion. Irrespective of their position on the issue, influencers who
engaged saw a significant rise in their following after their tweets. While a
number of tweets thanked Rihanna for raising awareness on the issue, she was
systematically trolled on the grounds of her gender, race, nationality and
religion. Finally, we observed how misinformation existing prior to the tweet
set up the grounds for alternative narratives that emerged.","13 pages, 12 figures",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2102.04031v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.04031v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.04031v1,"{'id': 'http://arxiv.org/abs/2102.04031v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.04031v1', 'updated': '2021-02-08T07:08:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=8, tm_hour=7, tm_min=8, tm_sec=36, tm_wday=0, tm_yday=39, tm_isdst=0), 'published': '2021-02-08T07:08:36Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=8, tm_hour=7, tm_min=8, tm_sec=36, tm_wday=0, tm_yday=39, tm_isdst=0), 'title': ""Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers'\n  Protest"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers'\n  Protest""}, 'summary': ""A tweet from popular entertainer and businesswoman, Rihanna, bringing\nattention to farmers' protests around Delhi set off heightened activity on\nIndian social media. An immediate consequence was the weighing in by Indian\npoliticians, entertainers, media and other influencers on the issue. In this\npaper, we use data from Twitter and an archive of debunked misinformation\nstories to understand some of the patterns around influencer engagement with a\npolitical issue. We found that more followed influencers were less likely to\ncome out in support of the tweet. We also find that the later engagement of\nmajor influencers on the side of the government's position shows suggestion's\nof collusion. Irrespective of their position on the issue, influencers who\nengaged saw a significant rise in their following after their tweets. While a\nnumber of tweets thanked Rihanna for raising awareness on the issue, she was\nsystematically trolled on the grounds of her gender, race, nationality and\nreligion. Finally, we observed how misinformation existing prior to the tweet\nset up the grounds for alternative narratives that emerged."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""A tweet from popular entertainer and businesswoman, Rihanna, bringing\nattention to farmers' protests around Delhi set off heightened activity on\nIndian social media. An immediate consequence was the weighing in by Indian\npoliticians, entertainers, media and other influencers on the issue. In this\npaper, we use data from Twitter and an archive of debunked misinformation\nstories to understand some of the patterns around influencer engagement with a\npolitical issue. We found that more followed influencers were less likely to\ncome out in support of the tweet. We also find that the later engagement of\nmajor influencers on the side of the government's position shows suggestion's\nof collusion. Irrespective of their position on the issue, influencers who\nengaged saw a significant rise in their following after their tweets. While a\nnumber of tweets thanked Rihanna for raising awareness on the issue, she was\nsystematically trolled on the grounds of her gender, race, nationality and\nreligion. Finally, we observed how misinformation existing prior to the tweet\nset up the grounds for alternative narratives that emerged.""}, 'authors': [{'name': 'Dibyendu Mishra'}, {'name': 'Syeda Zainab Akbar'}, {'name': 'Arshia Arya'}, {'name': 'Saloni Dash'}, {'name': 'Rynaa Grover'}, {'name': 'Joyojeet Pal'}], 'author_detail': {'name': 'Joyojeet Pal'}, 'author': 'Joyojeet Pal', 'arxiv_comment': '13 pages, 12 figures', 'links': [{'href': 'http://arxiv.org/abs/2102.04031v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.04031v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
145,http://arxiv.org/abs/2102.02680v1,2021-02-04 15:18:44+00:00,2021-02-04 15:18:44+00:00,Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","The widespread of fake news and misinformation in various domains ranging
from politics, economics to public health has posed an urgent need to
automatically fact-check information. A recent trend in fake news detection is
to utilize evidence from external sources. However, existing evidence-aware
fake news detection methods focused on either only word-level attention or
evidence-level attention, which may result in suboptimal performance. In this
paper, we propose a Hierarchical Multi-head Attentive Network to fact-check
textual claims. Our model jointly combines multi-head word-level attention and
multi-head document-level attention, which aid explanation in both word-level
and evidence-level. Experiments on two real-word datasets show that our model
outperforms seven state-of-the-art baselines. Improvements over baselines are
from 6\% to 18\%. Our source code and datasets are released at
\texttt{\url{https://github.com/nguyenvo09/EACL2021}}.",EACL2021,,,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2102.02680v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.02680v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.02680v1,"{'id': 'http://arxiv.org/abs/2102.02680v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.02680v1', 'updated': '2021-02-04T15:18:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=15, tm_min=18, tm_sec=44, tm_wday=3, tm_yday=35, tm_isdst=0), 'published': '2021-02-04T15:18:44Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=15, tm_min=18, tm_sec=44, tm_wday=3, tm_yday=35, tm_isdst=0), 'title': 'Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection'}, 'summary': 'The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.'}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'EACL2021', 'links': [{'href': 'http://arxiv.org/abs/2102.02680v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.02680v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
146,http://arxiv.org/abs/2102.02382v1,2021-02-04 02:47:31+00:00,2021-02-04 02:47:31+00:00,Mainstreaming of conspiracy theories and misinformation,"[arxiv.Result.Author('N. F. Johnson'), arxiv.Result.Author('N. Velasquez'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('R. Sear'), arxiv.Result.Author('N. Gabriel'), arxiv.Result.Author('H. Larson'), arxiv.Result.Author('Y. Lupu')]","Parents - particularly moms - increasingly consult social media for support
when taking decisions about their young children, and likely also when advising
other family members such as elderly relatives. Minimizing malignant online
influences is therefore crucial to securing their assent for policies ranging
from vaccinations, masks and social distancing against the pandemic, to
household best practices against climate change, to acceptance of future 5G
towers nearby. Here we show how a strengthening of bonds across online
communities during the pandemic, has led to non-Covid-19 conspiracy theories
(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream
parent communities. Alternative health communities act as the critical conduits
between conspiracy theorists and parents, and make the narratives more
palatable to the latter. We demonstrate experimentally that these
inter-community bonds can perpetually generate new misinformation, irrespective
of any changes in factual information. Our findings show explicitly why
Facebook's current policies have failed to stop the mainstreaming of
non-Covid-19 and Covid-19 conspiracy theories and misinformation, and why
targeting the largest communities will not work. A simple yet exactly solvable
and empirically grounded mathematical model, shows how modest tailoring of
mainstream communities' couplings could prevent them from tipping against
establishment guidance. Our conclusions should also apply to other social media
platforms and topics.",Working paper. Comments welcome to neiljohnson@gwu.edu,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'nlin.AO']","[arxiv.Result.Link('http://arxiv.org/abs/2102.02382v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.02382v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.02382v1,"{'id': 'http://arxiv.org/abs/2102.02382v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.02382v1', 'updated': '2021-02-04T02:47:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=2, tm_min=47, tm_sec=31, tm_wday=3, tm_yday=35, tm_isdst=0), 'published': '2021-02-04T02:47:31Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=4, tm_hour=2, tm_min=47, tm_sec=31, tm_wday=3, tm_yday=35, tm_isdst=0), 'title': 'Mainstreaming of conspiracy theories and misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mainstreaming of conspiracy theories and misinformation'}, 'summary': ""Parents - particularly moms - increasingly consult social media for support\nwhen taking decisions about their young children, and likely also when advising\nother family members such as elderly relatives. Minimizing malignant online\ninfluences is therefore crucial to securing their assent for policies ranging\nfrom vaccinations, masks and social distancing against the pandemic, to\nhousehold best practices against climate change, to acceptance of future 5G\ntowers nearby. Here we show how a strengthening of bonds across online\ncommunities during the pandemic, has led to non-Covid-19 conspiracy theories\n(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream\nparent communities. Alternative health communities act as the critical conduits\nbetween conspiracy theorists and parents, and make the narratives more\npalatable to the latter. We demonstrate experimentally that these\ninter-community bonds can perpetually generate new misinformation, irrespective\nof any changes in factual information. Our findings show explicitly why\nFacebook's current policies have failed to stop the mainstreaming of\nnon-Covid-19 and Covid-19 conspiracy theories and misinformation, and why\ntargeting the largest communities will not work. A simple yet exactly solvable\nand empirically grounded mathematical model, shows how modest tailoring of\nmainstream communities' couplings could prevent them from tipping against\nestablishment guidance. Our conclusions should also apply to other social media\nplatforms and topics."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Parents - particularly moms - increasingly consult social media for support\nwhen taking decisions about their young children, and likely also when advising\nother family members such as elderly relatives. Minimizing malignant online\ninfluences is therefore crucial to securing their assent for policies ranging\nfrom vaccinations, masks and social distancing against the pandemic, to\nhousehold best practices against climate change, to acceptance of future 5G\ntowers nearby. Here we show how a strengthening of bonds across online\ncommunities during the pandemic, has led to non-Covid-19 conspiracy theories\n(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream\nparent communities. Alternative health communities act as the critical conduits\nbetween conspiracy theorists and parents, and make the narratives more\npalatable to the latter. We demonstrate experimentally that these\ninter-community bonds can perpetually generate new misinformation, irrespective\nof any changes in factual information. Our findings show explicitly why\nFacebook's current policies have failed to stop the mainstreaming of\nnon-Covid-19 and Covid-19 conspiracy theories and misinformation, and why\ntargeting the largest communities will not work. A simple yet exactly solvable\nand empirically grounded mathematical model, shows how modest tailoring of\nmainstream communities' couplings could prevent them from tipping against\nestablishment guidance. Our conclusions should also apply to other social media\nplatforms and topics.""}, 'authors': [{'name': 'N. F. Johnson'}, {'name': 'N. Velasquez'}, {'name': 'N. Johnson Restrepo'}, {'name': 'R. Leahy'}, {'name': 'R. Sear'}, {'name': 'N. Gabriel'}, {'name': 'H. Larson'}, {'name': 'Y. Lupu'}], 'author_detail': {'name': 'Y. Lupu'}, 'author': 'Y. Lupu', 'arxiv_comment': 'Working paper. Comments welcome to neiljohnson@gwu.edu', 'links': [{'href': 'http://arxiv.org/abs/2102.02382v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.02382v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
147,http://arxiv.org/abs/2102.01148v1,2021-02-01 20:37:23+00:00,2021-02-01 20:37:23+00:00,A comparative study of Bot Detection techniques methods with an application related to Covid-19 discourse on Twitter,"[arxiv.Result.Author('Marzia Antenore'), arxiv.Result.Author('Jose M. Camacho-Rodriguez'), arxiv.Result.Author('Emanuele Panizzi')]","Bot Detection is an essential asset in a period where Online Social
Networks(OSN) is a part of our lives. This task becomes more relevant in
crises, as the Covid-19 pandemic, where there is an incipient risk of
proliferation of social bots, producing a possible source of misinformation. In
order to address this issue, it has been compared different methods to detect
automatically social bots on Twitter using Data Selection. The techniques
utilized to elaborate the bot detection models include the utilization of
features as the tweets metadata or the Digital Fingerprint of the Twitter
accounts. In addition, it was analyzed the presence of bots in tweets from
different periods of the first months of the Covid-19 pandemic, using the bot
detection technique which best fits the scope of the task. Moreover, this work
includes also analysis over aspects regarding the discourse of bots and humans,
such as sentiment or hashtag utilization.","36 pages, 10 figures, 5 tables",,,cs.SI,"['cs.SI', 'cs.IR', 'J.4']","[arxiv.Result.Link('http://arxiv.org/abs/2102.01148v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.01148v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.01148v1,"{'id': 'http://arxiv.org/abs/2102.01148v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.01148v1', 'updated': '2021-02-01T20:37:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=20, tm_min=37, tm_sec=23, tm_wday=0, tm_yday=32, tm_isdst=0), 'published': '2021-02-01T20:37:23Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=20, tm_min=37, tm_sec=23, tm_wday=0, tm_yday=32, tm_isdst=0), 'title': 'A comparative study of Bot Detection techniques methods with an\n  application related to Covid-19 discourse on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A comparative study of Bot Detection techniques methods with an\n  application related to Covid-19 discourse on Twitter'}, 'summary': 'Bot Detection is an essential asset in a period where Online Social\nNetworks(OSN) is a part of our lives. This task becomes more relevant in\ncrises, as the Covid-19 pandemic, where there is an incipient risk of\nproliferation of social bots, producing a possible source of misinformation. In\norder to address this issue, it has been compared different methods to detect\nautomatically social bots on Twitter using Data Selection. The techniques\nutilized to elaborate the bot detection models include the utilization of\nfeatures as the tweets metadata or the Digital Fingerprint of the Twitter\naccounts. In addition, it was analyzed the presence of bots in tweets from\ndifferent periods of the first months of the Covid-19 pandemic, using the bot\ndetection technique which best fits the scope of the task. Moreover, this work\nincludes also analysis over aspects regarding the discourse of bots and humans,\nsuch as sentiment or hashtag utilization.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Bot Detection is an essential asset in a period where Online Social\nNetworks(OSN) is a part of our lives. This task becomes more relevant in\ncrises, as the Covid-19 pandemic, where there is an incipient risk of\nproliferation of social bots, producing a possible source of misinformation. In\norder to address this issue, it has been compared different methods to detect\nautomatically social bots on Twitter using Data Selection. The techniques\nutilized to elaborate the bot detection models include the utilization of\nfeatures as the tweets metadata or the Digital Fingerprint of the Twitter\naccounts. In addition, it was analyzed the presence of bots in tweets from\ndifferent periods of the first months of the Covid-19 pandemic, using the bot\ndetection technique which best fits the scope of the task. Moreover, this work\nincludes also analysis over aspects regarding the discourse of bots and humans,\nsuch as sentiment or hashtag utilization.'}, 'authors': [{'name': 'Marzia Antenore'}, {'name': 'Jose M. Camacho-Rodriguez'}, {'name': 'Emanuele Panizzi'}], 'author_detail': {'name': 'Emanuele Panizzi'}, 'author': 'Emanuele Panizzi', 'arxiv_comment': '36 pages, 10 figures, 5 tables', 'links': [{'href': 'http://arxiv.org/abs/2102.01148v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.01148v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
148,http://arxiv.org/abs/2102.00976v1,2021-02-01 16:59:31+00:00,2021-02-01 16:59:31+00:00,Can Predominant Credible Information Suppress Misinformation in Crises? Empirical Studies of Tweets Related to Prevention Measures during COVID-19,"[arxiv.Result.Author('Yan Wang'), arxiv.Result.Author('Shangde Gao'), arxiv.Result.Author('Wenyu Gao')]","During COVID-19, misinformation on social media affects the adoption of
appropriate prevention behaviors. It is urgent to suppress the misinformation
to prevent negative public health consequences. Although an array of studies
has proposed misinformation suppression strategies, few have investigated the
role of predominant credible information during crises. None has examined its
effect quantitatively using longitudinal social media data. Therefore, this
research investigates the temporal correlations between credible information
and misinformation, and whether predominant credible information can suppress
misinformation for two prevention measures (i.e. topics), i.e. wearing masks
and social distancing using tweets collected from February 15 to June 30, 2020.
We trained Support Vector Machine classifiers to retrieve relevant tweets and
classify tweets containing credible information and misinformation for each
topic. Based on cross-correlation analyses of credible and misinformation time
series for both topics, we find that the previously predominant credible
information can lead to the decrease of misinformation (i.e. suppression) with
a time lag. The research findings provide empirical evidence for suppressing
misinformation with credible information in complex online environments and
suggest practical strategies for future information management during crises
and emergencies.",,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2102.00976v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.00976v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.00976v1,"{'id': 'http://arxiv.org/abs/2102.00976v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.00976v1', 'updated': '2021-02-01T16:59:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=16, tm_min=59, tm_sec=31, tm_wday=0, tm_yday=32, tm_isdst=0), 'published': '2021-02-01T16:59:31Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=16, tm_min=59, tm_sec=31, tm_wday=0, tm_yday=32, tm_isdst=0), 'title': 'Can Predominant Credible Information Suppress Misinformation in Crises?\n  Empirical Studies of Tweets Related to Prevention Measures during COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can Predominant Credible Information Suppress Misinformation in Crises?\n  Empirical Studies of Tweets Related to Prevention Measures during COVID-19'}, 'summary': 'During COVID-19, misinformation on social media affects the adoption of\nappropriate prevention behaviors. It is urgent to suppress the misinformation\nto prevent negative public health consequences. Although an array of studies\nhas proposed misinformation suppression strategies, few have investigated the\nrole of predominant credible information during crises. None has examined its\neffect quantitatively using longitudinal social media data. Therefore, this\nresearch investigates the temporal correlations between credible information\nand misinformation, and whether predominant credible information can suppress\nmisinformation for two prevention measures (i.e. topics), i.e. wearing masks\nand social distancing using tweets collected from February 15 to June 30, 2020.\nWe trained Support Vector Machine classifiers to retrieve relevant tweets and\nclassify tweets containing credible information and misinformation for each\ntopic. Based on cross-correlation analyses of credible and misinformation time\nseries for both topics, we find that the previously predominant credible\ninformation can lead to the decrease of misinformation (i.e. suppression) with\na time lag. The research findings provide empirical evidence for suppressing\nmisinformation with credible information in complex online environments and\nsuggest practical strategies for future information management during crises\nand emergencies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'During COVID-19, misinformation on social media affects the adoption of\nappropriate prevention behaviors. It is urgent to suppress the misinformation\nto prevent negative public health consequences. Although an array of studies\nhas proposed misinformation suppression strategies, few have investigated the\nrole of predominant credible information during crises. None has examined its\neffect quantitatively using longitudinal social media data. Therefore, this\nresearch investigates the temporal correlations between credible information\nand misinformation, and whether predominant credible information can suppress\nmisinformation for two prevention measures (i.e. topics), i.e. wearing masks\nand social distancing using tweets collected from February 15 to June 30, 2020.\nWe trained Support Vector Machine classifiers to retrieve relevant tweets and\nclassify tweets containing credible information and misinformation for each\ntopic. Based on cross-correlation analyses of credible and misinformation time\nseries for both topics, we find that the previously predominant credible\ninformation can lead to the decrease of misinformation (i.e. suppression) with\na time lag. The research findings provide empirical evidence for suppressing\nmisinformation with credible information in complex online environments and\nsuggest practical strategies for future information management during crises\nand emergencies.'}, 'authors': [{'name': 'Yan Wang'}, {'name': 'Shangde Gao'}, {'name': 'Wenyu Gao'}], 'author_detail': {'name': 'Wenyu Gao'}, 'author': 'Wenyu Gao', 'links': [{'href': 'http://arxiv.org/abs/2102.00976v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.00976v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
149,http://arxiv.org/abs/2102.00573v1,2021-02-01 00:34:38+00:00,2021-02-01 00:34:38+00:00,A Secure Learning Control Strategy via Dynamic Camouflaging for Unknown Dynamical Systems under Attacks,"[arxiv.Result.Author('Sayak Mukherjee'), arxiv.Result.Author('Veronica Adetola')]","This paper presents a secure reinforcement learning (RL) based control method
for unknown linear time-invariant cyber-physical systems (CPSs) that are
subjected to compositional attacks such as eavesdropping and covert attack. We
consider the attack scenario where the attacker learns about the dynamic model
during the exploration phase of the learning conducted by the designer to learn
a linear quadratic regulator (LQR), and thereafter, use such information to
conduct a covert attack on the dynamic system, which we refer to as doubly
learning-based control and attack (DLCA) framework. We propose a dynamic
camouflaging based attack-resilient reinforcement learning (ARRL) algorithm
which can learn the desired optimal controller for the dynamic system, and at
the same time, can inject sufficient misinformation in the estimation of system
dynamics by the attacker. The algorithm is accompanied by theoretical
guarantees and extensive numerical experiments on a consensus multi-agent
system and on a benchmark power grid model.","8 pages, 17 figures",,,eess.SY,"['eess.SY', 'cs.LG', 'cs.SY']","[arxiv.Result.Link('http://arxiv.org/abs/2102.00573v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.00573v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.00573v1,"{'id': 'http://arxiv.org/abs/2102.00573v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.00573v1', 'updated': '2021-02-01T00:34:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=0, tm_min=34, tm_sec=38, tm_wday=0, tm_yday=32, tm_isdst=0), 'published': '2021-02-01T00:34:38Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=0, tm_min=34, tm_sec=38, tm_wday=0, tm_yday=32, tm_isdst=0), 'title': 'A Secure Learning Control Strategy via Dynamic Camouflaging for Unknown\n  Dynamical Systems under Attacks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Secure Learning Control Strategy via Dynamic Camouflaging for Unknown\n  Dynamical Systems under Attacks'}, 'summary': 'This paper presents a secure reinforcement learning (RL) based control method\nfor unknown linear time-invariant cyber-physical systems (CPSs) that are\nsubjected to compositional attacks such as eavesdropping and covert attack. We\nconsider the attack scenario where the attacker learns about the dynamic model\nduring the exploration phase of the learning conducted by the designer to learn\na linear quadratic regulator (LQR), and thereafter, use such information to\nconduct a covert attack on the dynamic system, which we refer to as doubly\nlearning-based control and attack (DLCA) framework. We propose a dynamic\ncamouflaging based attack-resilient reinforcement learning (ARRL) algorithm\nwhich can learn the desired optimal controller for the dynamic system, and at\nthe same time, can inject sufficient misinformation in the estimation of system\ndynamics by the attacker. The algorithm is accompanied by theoretical\nguarantees and extensive numerical experiments on a consensus multi-agent\nsystem and on a benchmark power grid model.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper presents a secure reinforcement learning (RL) based control method\nfor unknown linear time-invariant cyber-physical systems (CPSs) that are\nsubjected to compositional attacks such as eavesdropping and covert attack. We\nconsider the attack scenario where the attacker learns about the dynamic model\nduring the exploration phase of the learning conducted by the designer to learn\na linear quadratic regulator (LQR), and thereafter, use such information to\nconduct a covert attack on the dynamic system, which we refer to as doubly\nlearning-based control and attack (DLCA) framework. We propose a dynamic\ncamouflaging based attack-resilient reinforcement learning (ARRL) algorithm\nwhich can learn the desired optimal controller for the dynamic system, and at\nthe same time, can inject sufficient misinformation in the estimation of system\ndynamics by the attacker. The algorithm is accompanied by theoretical\nguarantees and extensive numerical experiments on a consensus multi-agent\nsystem and on a benchmark power grid model.'}, 'authors': [{'name': 'Sayak Mukherjee'}, {'name': 'Veronica Adetola'}], 'author_detail': {'name': 'Veronica Adetola'}, 'author': 'Veronica Adetola', 'arxiv_comment': '8 pages, 17 figures', 'links': [{'href': 'http://arxiv.org/abs/2102.00573v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.00573v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
150,http://arxiv.org/abs/2101.12027v1,2021-01-28 14:43:42+00:00,2021-01-28 14:43:42+00:00,A transformer based approach for fighting COVID-19 fake news,"[arxiv.Result.Author('S. M. Sadiq-Ur-Rahman Shifath'), arxiv.Result.Author('Mohammad Faiyaz Khan'), arxiv.Result.Author('Md. Saiful Islam')]","The rapid outbreak of COVID-19 has caused humanity to come to a stand-still
and brought with it a plethora of other problems. COVID-19 is the first
pandemic in history when humanity is the most technologically advanced and
relies heavily on social media platforms for connectivity and other benefits.
Unfortunately, fake news and misinformation regarding this virus is also
available to people and causing some massive problems. So, fighting this
infodemic has become a significant challenge. We present our solution for the
""Constraint@AAAI2021 - COVID19 Fake News Detection in English"" challenge in
this work. After extensive experimentation with numerous architectures and
techniques, we use eight different transformer-based pre-trained models with
additional layers to construct a stacking ensemble classifier and fine-tuned
them for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,
0.979906542 recall, and 0.979907901 f1-score on the test dataset of the
competition.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.12027v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.12027v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.12027v1,"{'id': 'http://arxiv.org/abs/2101.12027v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.12027v1', 'updated': '2021-01-28T14:43:42Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=28, tm_hour=14, tm_min=43, tm_sec=42, tm_wday=3, tm_yday=28, tm_isdst=0), 'published': '2021-01-28T14:43:42Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=28, tm_hour=14, tm_min=43, tm_sec=42, tm_wday=3, tm_yday=28, tm_isdst=0), 'title': 'A transformer based approach for fighting COVID-19 fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A transformer based approach for fighting COVID-19 fake news'}, 'summary': 'The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n""Constraint@AAAI2021 - COVID19 Fake News Detection in English"" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n""Constraint@AAAI2021 - COVID19 Fake News Detection in English"" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.'}, 'authors': [{'name': 'S. M. Sadiq-Ur-Rahman Shifath'}, {'name': 'Mohammad Faiyaz Khan'}, {'name': 'Md. Saiful Islam'}], 'author_detail': {'name': 'Md. Saiful Islam'}, 'author': 'Md. Saiful Islam', 'links': [{'href': 'http://arxiv.org/abs/2101.12027v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.12027v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
151,http://arxiv.org/abs/2101.11824v5,2021-05-23 04:56:44+00:00,2021-01-28 05:45:01+00:00,Exploring Lightweight Interventions at Posting Time to Reduce the Sharing of Misinformation on Social Media,"[arxiv.Result.Author('Farnaz Jahanbakhsh'), arxiv.Result.Author('Amy X. Zhang'), arxiv.Result.Author('Adam J. Berinsky'), arxiv.Result.Author('Gordon Pennycook'), arxiv.Result.Author('David G. Rand'), arxiv.Result.Author('David R. Karger')]","When users on social media share content without considering its veracity,
they may unwittingly be spreading misinformation. In this work, we investigate
the design of lightweight interventions that nudge users to assess the accuracy
of information as they share it. Such assessment may deter users from posting
misinformation in the first place, and their assessments may also provide
useful guidance to friends aiming to assess those posts themselves. In support
of lightweight assessment, we first develop a taxonomy of the reasons why
people believe a news claim is or is not true; this taxonomy yields a checklist
that can be used at posting time. We conduct evaluations to demonstrate that
the checklist is an accurate and comprehensive encapsulation of people's
free-response rationales. In a second experiment, we study the effects of three
behavioral nudges -- 1) checkboxes indicating whether headings are accurate, 2)
tagging reasons (from our taxonomy) that a post is accurate via a checklist and
3) providing free-text rationales for why a headline is or is not accurate --
on people's intention of sharing the headline on social media. From an
experiment with 1668 participants, we find that both providing accuracy
assessment and rationale reduce the sharing of false content. They also reduce
the sharing of true content, but to a lesser degree that yields an overall
decrease in the fraction of shared content that is false. Our findings have
implications for designing social media and news sharing platforms that draw
from richer signals of content credibility contributed by users. In addition,
our validated taxonomy can be used by platforms and researchers as a way to
gather rationales in an easier fashion than free-response.",In CSCW'21,"Proc. ACM Hum.-Comput. Interact., Vol. 5, No. CSCW1, Article 18.
  Publication date: April 2021",10.1145/3449092,cs.HC,"['cs.HC', 'H.5.3; J.4']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3449092', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.11824v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.11824v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.11824v5,"{'id': 'http://arxiv.org/abs/2101.11824v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.11824v5', 'updated': '2021-05-23T04:56:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=23, tm_hour=4, tm_min=56, tm_sec=44, tm_wday=6, tm_yday=143, tm_isdst=0), 'published': '2021-01-28T05:45:01Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=28, tm_hour=5, tm_min=45, tm_sec=1, tm_wday=3, tm_yday=28, tm_isdst=0), 'title': 'Exploring Lightweight Interventions at Posting Time to Reduce the\n  Sharing of Misinformation on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exploring Lightweight Interventions at Posting Time to Reduce the\n  Sharing of Misinformation on Social Media'}, 'summary': ""When users on social media share content without considering its veracity,\nthey may unwittingly be spreading misinformation. In this work, we investigate\nthe design of lightweight interventions that nudge users to assess the accuracy\nof information as they share it. Such assessment may deter users from posting\nmisinformation in the first place, and their assessments may also provide\nuseful guidance to friends aiming to assess those posts themselves. In support\nof lightweight assessment, we first develop a taxonomy of the reasons why\npeople believe a news claim is or is not true; this taxonomy yields a checklist\nthat can be used at posting time. We conduct evaluations to demonstrate that\nthe checklist is an accurate and comprehensive encapsulation of people's\nfree-response rationales. In a second experiment, we study the effects of three\nbehavioral nudges -- 1) checkboxes indicating whether headings are accurate, 2)\ntagging reasons (from our taxonomy) that a post is accurate via a checklist and\n3) providing free-text rationales for why a headline is or is not accurate --\non people's intention of sharing the headline on social media. From an\nexperiment with 1668 participants, we find that both providing accuracy\nassessment and rationale reduce the sharing of false content. They also reduce\nthe sharing of true content, but to a lesser degree that yields an overall\ndecrease in the fraction of shared content that is false. Our findings have\nimplications for designing social media and news sharing platforms that draw\nfrom richer signals of content credibility contributed by users. In addition,\nour validated taxonomy can be used by platforms and researchers as a way to\ngather rationales in an easier fashion than free-response."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""When users on social media share content without considering its veracity,\nthey may unwittingly be spreading misinformation. In this work, we investigate\nthe design of lightweight interventions that nudge users to assess the accuracy\nof information as they share it. Such assessment may deter users from posting\nmisinformation in the first place, and their assessments may also provide\nuseful guidance to friends aiming to assess those posts themselves. In support\nof lightweight assessment, we first develop a taxonomy of the reasons why\npeople believe a news claim is or is not true; this taxonomy yields a checklist\nthat can be used at posting time. We conduct evaluations to demonstrate that\nthe checklist is an accurate and comprehensive encapsulation of people's\nfree-response rationales. In a second experiment, we study the effects of three\nbehavioral nudges -- 1) checkboxes indicating whether headings are accurate, 2)\ntagging reasons (from our taxonomy) that a post is accurate via a checklist and\n3) providing free-text rationales for why a headline is or is not accurate --\non people's intention of sharing the headline on social media. From an\nexperiment with 1668 participants, we find that both providing accuracy\nassessment and rationale reduce the sharing of false content. They also reduce\nthe sharing of true content, but to a lesser degree that yields an overall\ndecrease in the fraction of shared content that is false. Our findings have\nimplications for designing social media and news sharing platforms that draw\nfrom richer signals of content credibility contributed by users. In addition,\nour validated taxonomy can be used by platforms and researchers as a way to\ngather rationales in an easier fashion than free-response.""}, 'authors': [{'name': 'Farnaz Jahanbakhsh'}, {'name': 'Amy X. Zhang'}, {'name': 'Adam J. Berinsky'}, {'name': 'Gordon Pennycook'}, {'name': 'David G. Rand'}, {'name': 'David R. Karger'}], 'author_detail': {'name': 'David R. Karger'}, 'author': 'David R. Karger', 'arxiv_doi': '10.1145/3449092', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3449092', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.11824v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.11824v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""In CSCW'21"", 'arxiv_journal_ref': 'Proc. ACM Hum.-Comput. Interact., Vol. 5, No. CSCW1, Article 18.\n  Publication date: April 2021', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.3; J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
152,http://arxiv.org/abs/2101.09665v1,2021-01-24 07:21:50+00:00,2021-01-24 07:21:50+00:00,Corrective Information Does Not Necessarily Curb Social Disruption,"[arxiv.Result.Author('Ryusuke Iizuka'), arxiv.Result.Author('Fujio Toriumi'), arxiv.Result.Author('Mao Nishiguchi'), arxiv.Result.Author('Masanori Takano'), arxiv.Result.Author('Mitsuo Yoshida')]","The spread of misinformation can cause social confusion. The authenticity of
information on a social networking service (SNS) is unknown, and false
information can be easily spread. Consequently, many studies have been
conducted on methods to control the spread of misinformation on social
networking sites. However, few studies have examined the impact of the spread
of misinformation and its corrections on society. This study models the impact
of the reduction of misinformation and the diffusion of corrective information
on social disruption, and it identifies the features of this impact. In this
study, we analyzed misinformation regarding the shortage of toilet paper during
the 2020 COVID-19 epidemic, its corrections, and the excessive purchasing
caused by this information. First, we analyze the amount of misinformation and
corrective information spread on SNS, and we create a regression model to
estimate the real-world impact of misinformation and its correction. This model
is used to analyze the change in real-world impact corresponding to the change
in the diffusion of misinformation and corrective information. Our analysis
shows that the corrective information was spread to a much greater extent than
the misinformation. In addition, our model reveals that the corrective
information was what caused the excessive purchasing behavior. As a result of
our further analysis, we found that the amount of diffusion of corrective
information required to minimize the impact on the real world depends on the
amount of the diffusion of misinformation.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.09665v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.09665v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.09665v1,"{'id': 'http://arxiv.org/abs/2101.09665v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.09665v1', 'updated': '2021-01-24T07:21:50Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=24, tm_hour=7, tm_min=21, tm_sec=50, tm_wday=6, tm_yday=24, tm_isdst=0), 'published': '2021-01-24T07:21:50Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=24, tm_hour=7, tm_min=21, tm_sec=50, tm_wday=6, tm_yday=24, tm_isdst=0), 'title': 'Corrective Information Does Not Necessarily Curb Social Disruption', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Corrective Information Does Not Necessarily Curb Social Disruption'}, 'summary': 'The spread of misinformation can cause social confusion. The authenticity of\ninformation on a social networking service (SNS) is unknown, and false\ninformation can be easily spread. Consequently, many studies have been\nconducted on methods to control the spread of misinformation on social\nnetworking sites. However, few studies have examined the impact of the spread\nof misinformation and its corrections on society. This study models the impact\nof the reduction of misinformation and the diffusion of corrective information\non social disruption, and it identifies the features of this impact. In this\nstudy, we analyzed misinformation regarding the shortage of toilet paper during\nthe 2020 COVID-19 epidemic, its corrections, and the excessive purchasing\ncaused by this information. First, we analyze the amount of misinformation and\ncorrective information spread on SNS, and we create a regression model to\nestimate the real-world impact of misinformation and its correction. This model\nis used to analyze the change in real-world impact corresponding to the change\nin the diffusion of misinformation and corrective information. Our analysis\nshows that the corrective information was spread to a much greater extent than\nthe misinformation. In addition, our model reveals that the corrective\ninformation was what caused the excessive purchasing behavior. As a result of\nour further analysis, we found that the amount of diffusion of corrective\ninformation required to minimize the impact on the real world depends on the\namount of the diffusion of misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of misinformation can cause social confusion. The authenticity of\ninformation on a social networking service (SNS) is unknown, and false\ninformation can be easily spread. Consequently, many studies have been\nconducted on methods to control the spread of misinformation on social\nnetworking sites. However, few studies have examined the impact of the spread\nof misinformation and its corrections on society. This study models the impact\nof the reduction of misinformation and the diffusion of corrective information\non social disruption, and it identifies the features of this impact. In this\nstudy, we analyzed misinformation regarding the shortage of toilet paper during\nthe 2020 COVID-19 epidemic, its corrections, and the excessive purchasing\ncaused by this information. First, we analyze the amount of misinformation and\ncorrective information spread on SNS, and we create a regression model to\nestimate the real-world impact of misinformation and its correction. This model\nis used to analyze the change in real-world impact corresponding to the change\nin the diffusion of misinformation and corrective information. Our analysis\nshows that the corrective information was spread to a much greater extent than\nthe misinformation. In addition, our model reveals that the corrective\ninformation was what caused the excessive purchasing behavior. As a result of\nour further analysis, we found that the amount of diffusion of corrective\ninformation required to minimize the impact on the real world depends on the\namount of the diffusion of misinformation.'}, 'authors': [{'name': 'Ryusuke Iizuka'}, {'name': 'Fujio Toriumi'}, {'name': 'Mao Nishiguchi'}, {'name': 'Masanori Takano'}, {'name': 'Mitsuo Yoshida'}], 'author_detail': {'name': 'Mitsuo Yoshida'}, 'author': 'Mitsuo Yoshida', 'links': [{'href': 'http://arxiv.org/abs/2101.09665v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.09665v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
153,http://arxiv.org/abs/2101.09575v1,2021-01-23 20:14:05+00:00,2021-01-23 20:14:05+00:00,Examining Factors Associated with Twitter Account Suspension Following the 2020 U.S. Presidential Election,"[arxiv.Result.Author('Farhan Asif Chowdhury'), arxiv.Result.Author('Dheeman Saha'), arxiv.Result.Author('Md Rashidul Hasan'), arxiv.Result.Author('Koustuv Saha'), arxiv.Result.Author('Abdullah Mueen')]","Online social media enables mass-level, transparent, and democratized
discussion on numerous socio-political issues. Due to such openness, these
platforms often endure manipulation and misinformation - leading to negative
impacts. To prevent such harmful activities, platform moderators employ
countermeasures to safeguard against actors violating their rules. However, the
correlation between publicly outlined policies and employed action is less
clear to general people. In this work, we examine violations and subsequent
moderation related to the 2020 U.S. President Election discussion on Twitter, a
popular micro-blogging site. We focus on quantifying plausible reasons for the
suspension, drawing on Twitter's rules and policies by identifying suspended
users (Case) and comparing their activities and properties with (yet)
non-suspended (Control) users. Using a dataset of 240M election-related tweets
made by 21M unique users, we observe that Suspended users violate Twitter's
rules at a higher rate (statistically significant) than Control users across
all the considered aspects - hate speech, offensiveness, spamming, and civic
integrity. Moreover, through the lens of Twitter's suspension mechanism, we
qualitatively examine the targeted topics for manipulation.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.09575v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.09575v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.09575v1,"{'id': 'http://arxiv.org/abs/2101.09575v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.09575v1', 'updated': '2021-01-23T20:14:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=23, tm_hour=20, tm_min=14, tm_sec=5, tm_wday=5, tm_yday=23, tm_isdst=0), 'published': '2021-01-23T20:14:05Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=23, tm_hour=20, tm_min=14, tm_sec=5, tm_wday=5, tm_yday=23, tm_isdst=0), 'title': 'Examining Factors Associated with Twitter Account Suspension Following\n  the 2020 U.S. Presidential Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Examining Factors Associated with Twitter Account Suspension Following\n  the 2020 U.S. Presidential Election'}, 'summary': ""Online social media enables mass-level, transparent, and democratized\ndiscussion on numerous socio-political issues. Due to such openness, these\nplatforms often endure manipulation and misinformation - leading to negative\nimpacts. To prevent such harmful activities, platform moderators employ\ncountermeasures to safeguard against actors violating their rules. However, the\ncorrelation between publicly outlined policies and employed action is less\nclear to general people. In this work, we examine violations and subsequent\nmoderation related to the 2020 U.S. President Election discussion on Twitter, a\npopular micro-blogging site. We focus on quantifying plausible reasons for the\nsuspension, drawing on Twitter's rules and policies by identifying suspended\nusers (Case) and comparing their activities and properties with (yet)\nnon-suspended (Control) users. Using a dataset of 240M election-related tweets\nmade by 21M unique users, we observe that Suspended users violate Twitter's\nrules at a higher rate (statistically significant) than Control users across\nall the considered aspects - hate speech, offensiveness, spamming, and civic\nintegrity. Moreover, through the lens of Twitter's suspension mechanism, we\nqualitatively examine the targeted topics for manipulation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online social media enables mass-level, transparent, and democratized\ndiscussion on numerous socio-political issues. Due to such openness, these\nplatforms often endure manipulation and misinformation - leading to negative\nimpacts. To prevent such harmful activities, platform moderators employ\ncountermeasures to safeguard against actors violating their rules. However, the\ncorrelation between publicly outlined policies and employed action is less\nclear to general people. In this work, we examine violations and subsequent\nmoderation related to the 2020 U.S. President Election discussion on Twitter, a\npopular micro-blogging site. We focus on quantifying plausible reasons for the\nsuspension, drawing on Twitter's rules and policies by identifying suspended\nusers (Case) and comparing their activities and properties with (yet)\nnon-suspended (Control) users. Using a dataset of 240M election-related tweets\nmade by 21M unique users, we observe that Suspended users violate Twitter's\nrules at a higher rate (statistically significant) than Control users across\nall the considered aspects - hate speech, offensiveness, spamming, and civic\nintegrity. Moreover, through the lens of Twitter's suspension mechanism, we\nqualitatively examine the targeted topics for manipulation.""}, 'authors': [{'name': 'Farhan Asif Chowdhury'}, {'name': 'Dheeman Saha'}, {'name': 'Md Rashidul Hasan'}, {'name': 'Koustuv Saha'}, {'name': 'Abdullah Mueen'}], 'author_detail': {'name': 'Abdullah Mueen'}, 'author': 'Abdullah Mueen', 'links': [{'href': 'http://arxiv.org/abs/2101.09575v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.09575v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
154,http://arxiv.org/abs/2101.08419v2,2021-01-29 20:15:18+00:00,2021-01-21 03:16:29+00:00,Auditing E-Commerce Platforms for Algorithmically Curated Vaccine Misinformation,"[arxiv.Result.Author('Prerna Juneja'), arxiv.Result.Author('Tanushree Mitra')]","There is a growing concern that e-commerce platforms are amplifying
vaccine-misinformation. To investigate, we conduct two-sets of algorithmic
audits for vaccine misinformation on the search and recommendation algorithms
of Amazon -- world's leading e-retailer. First, we systematically audit
search-results belonging to vaccine-related search-queries without logging into
the platform -- unpersonalized audits. We find 10.47% of search-results promote
misinformative health products. We also observe ranking-bias, with Amazon
ranking misinformative search-results higher than debunking search-results.
Next, we analyze the effects of personalization due to account-history, where
history is built progressively by performing various real-world user-actions,
such as clicking a product. We find evidence of filter-bubble effect in
Amazon's recommendations; accounts performing actions on misinformative
products are presented with more misinformation compared to accounts performing
actions on neutral and debunking products. Interestingly, once user clicks on a
misinformative product, homepage recommendations become more contaminated
compared to when user shows an intention to buy that product.",,CHI Conference on Human Factors in Computing Systems 2021,10.1145/3411764.3445250,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3411764.3445250', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.08419v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.08419v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.08419v2,"{'id': 'http://arxiv.org/abs/2101.08419v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.08419v2', 'updated': '2021-01-29T20:15:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=29, tm_hour=20, tm_min=15, tm_sec=18, tm_wday=4, tm_yday=29, tm_isdst=0), 'published': '2021-01-21T03:16:29Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=21, tm_hour=3, tm_min=16, tm_sec=29, tm_wday=3, tm_yday=21, tm_isdst=0), 'title': 'Auditing E-Commerce Platforms for Algorithmically Curated Vaccine\n  Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Auditing E-Commerce Platforms for Algorithmically Curated Vaccine\n  Misinformation'}, 'summary': ""There is a growing concern that e-commerce platforms are amplifying\nvaccine-misinformation. To investigate, we conduct two-sets of algorithmic\naudits for vaccine misinformation on the search and recommendation algorithms\nof Amazon -- world's leading e-retailer. First, we systematically audit\nsearch-results belonging to vaccine-related search-queries without logging into\nthe platform -- unpersonalized audits. We find 10.47% of search-results promote\nmisinformative health products. We also observe ranking-bias, with Amazon\nranking misinformative search-results higher than debunking search-results.\nNext, we analyze the effects of personalization due to account-history, where\nhistory is built progressively by performing various real-world user-actions,\nsuch as clicking a product. We find evidence of filter-bubble effect in\nAmazon's recommendations; accounts performing actions on misinformative\nproducts are presented with more misinformation compared to accounts performing\nactions on neutral and debunking products. Interestingly, once user clicks on a\nmisinformative product, homepage recommendations become more contaminated\ncompared to when user shows an intention to buy that product."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""There is a growing concern that e-commerce platforms are amplifying\nvaccine-misinformation. To investigate, we conduct two-sets of algorithmic\naudits for vaccine misinformation on the search and recommendation algorithms\nof Amazon -- world's leading e-retailer. First, we systematically audit\nsearch-results belonging to vaccine-related search-queries without logging into\nthe platform -- unpersonalized audits. We find 10.47% of search-results promote\nmisinformative health products. We also observe ranking-bias, with Amazon\nranking misinformative search-results higher than debunking search-results.\nNext, we analyze the effects of personalization due to account-history, where\nhistory is built progressively by performing various real-world user-actions,\nsuch as clicking a product. We find evidence of filter-bubble effect in\nAmazon's recommendations; accounts performing actions on misinformative\nproducts are presented with more misinformation compared to accounts performing\nactions on neutral and debunking products. Interestingly, once user clicks on a\nmisinformative product, homepage recommendations become more contaminated\ncompared to when user shows an intention to buy that product.""}, 'authors': [{'name': 'Prerna Juneja'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_doi': '10.1145/3411764.3445250', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3411764.3445250', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.08419v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.08419v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'CHI Conference on Human Factors in Computing Systems 2021', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
155,http://arxiv.org/abs/2102.04217v1,2021-01-20 05:30:14+00:00,2021-01-20 05:30:14+00:00,The Fault in the Stars: Understanding the Underground Market of Amazon Reviews,[arxiv.Result.Author('Rajvardhan Oak')],"In recent times, the Internet has been plagued by a tremendous amount of
misinformation. Online markets such as Amazon are also not free from
misinformation. In this work, we study the misinformation propagated to
consumers through the form of Amazon reviews. There exists a vast underground
market where reviews by real Amazon users are purchased and sold. While such a
practice violates Amazon's terms of service, we observe that there exists a
complex network consisting of thousands of sellers and agents, who provide a
rebate to consumers for leaving positive reviews to over $5000$ products. Based
on interviews with members involved in the reviews market, we understand the
working of this market, and the tactics used to avoid detection by Amazon. We
also present a set of recommendations of features that Amazon and similar
online markets can take into consideration to detect such reviews.",This is a work in progress!,,,cs.CY,"['cs.CY', 'K.4.4']","[arxiv.Result.Link('http://arxiv.org/abs/2102.04217v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2102.04217v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2102.04217v1,"{'id': 'http://arxiv.org/abs/2102.04217v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2102.04217v1', 'updated': '2021-01-20T05:30:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=20, tm_hour=5, tm_min=30, tm_sec=14, tm_wday=2, tm_yday=20, tm_isdst=0), 'published': '2021-01-20T05:30:14Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=20, tm_hour=5, tm_min=30, tm_sec=14, tm_wday=2, tm_yday=20, tm_isdst=0), 'title': 'The Fault in the Stars: Understanding the Underground Market of Amazon\n  Reviews', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Fault in the Stars: Understanding the Underground Market of Amazon\n  Reviews'}, 'summary': ""In recent times, the Internet has been plagued by a tremendous amount of\nmisinformation. Online markets such as Amazon are also not free from\nmisinformation. In this work, we study the misinformation propagated to\nconsumers through the form of Amazon reviews. There exists a vast underground\nmarket where reviews by real Amazon users are purchased and sold. While such a\npractice violates Amazon's terms of service, we observe that there exists a\ncomplex network consisting of thousands of sellers and agents, who provide a\nrebate to consumers for leaving positive reviews to over $5000$ products. Based\non interviews with members involved in the reviews market, we understand the\nworking of this market, and the tactics used to avoid detection by Amazon. We\nalso present a set of recommendations of features that Amazon and similar\nonline markets can take into consideration to detect such reviews."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In recent times, the Internet has been plagued by a tremendous amount of\nmisinformation. Online markets such as Amazon are also not free from\nmisinformation. In this work, we study the misinformation propagated to\nconsumers through the form of Amazon reviews. There exists a vast underground\nmarket where reviews by real Amazon users are purchased and sold. While such a\npractice violates Amazon's terms of service, we observe that there exists a\ncomplex network consisting of thousands of sellers and agents, who provide a\nrebate to consumers for leaving positive reviews to over $5000$ products. Based\non interviews with members involved in the reviews market, we understand the\nworking of this market, and the tactics used to avoid detection by Amazon. We\nalso present a set of recommendations of features that Amazon and similar\nonline markets can take into consideration to detect such reviews.""}, 'authors': [{'name': 'Rajvardhan Oak'}], 'author_detail': {'name': 'Rajvardhan Oak'}, 'author': 'Rajvardhan Oak', 'arxiv_comment': 'This is a work in progress!', 'links': [{'href': 'http://arxiv.org/abs/2102.04217v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2102.04217v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'K.4.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
156,http://arxiv.org/abs/2101.07951v1,2021-01-20 03:49:51+00:00,2021-01-20 03:49:51+00:00,This photograph has been altered: Testing the effectiveness of image forensic labeling on news image credibility,"[arxiv.Result.Author('Cuihua Shen'), arxiv.Result.Author('Mona Kasra'), arxiv.Result.Author(""James O'Brien"")]","Despite the ubiquity and proliferation of images and videos in online news
environments, much of the existing research on misinformation and its
correction is solely focused on textual misinformation, and little is known
about how ordinary users evaluate fake or manipulated images and the most
effective ways to label and correct such falsities. We designed a visual
forensic label of image authenticity, Picture-O-Meter, and tested the label's
efficacy in relation to its source and placement in an experiment with 2440
participants. Our findings demonstrate that, despite human beings' general
inability to detect manipulated images on their own, image forensic labels are
an effective tool for counteracting visual misinformation.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.07951v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.07951v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.07951v1,"{'id': 'http://arxiv.org/abs/2101.07951v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.07951v1', 'updated': '2021-01-20T03:49:51Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=20, tm_hour=3, tm_min=49, tm_sec=51, tm_wday=2, tm_yday=20, tm_isdst=0), 'published': '2021-01-20T03:49:51Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=20, tm_hour=3, tm_min=49, tm_sec=51, tm_wday=2, tm_yday=20, tm_isdst=0), 'title': 'This photograph has been altered: Testing the effectiveness of image\n  forensic labeling on news image credibility', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This photograph has been altered: Testing the effectiveness of image\n  forensic labeling on news image credibility'}, 'summary': ""Despite the ubiquity and proliferation of images and videos in online news\nenvironments, much of the existing research on misinformation and its\ncorrection is solely focused on textual misinformation, and little is known\nabout how ordinary users evaluate fake or manipulated images and the most\neffective ways to label and correct such falsities. We designed a visual\nforensic label of image authenticity, Picture-O-Meter, and tested the label's\nefficacy in relation to its source and placement in an experiment with 2440\nparticipants. Our findings demonstrate that, despite human beings' general\ninability to detect manipulated images on their own, image forensic labels are\nan effective tool for counteracting visual misinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Despite the ubiquity and proliferation of images and videos in online news\nenvironments, much of the existing research on misinformation and its\ncorrection is solely focused on textual misinformation, and little is known\nabout how ordinary users evaluate fake or manipulated images and the most\neffective ways to label and correct such falsities. We designed a visual\nforensic label of image authenticity, Picture-O-Meter, and tested the label's\nefficacy in relation to its source and placement in an experiment with 2440\nparticipants. Our findings demonstrate that, despite human beings' general\ninability to detect manipulated images on their own, image forensic labels are\nan effective tool for counteracting visual misinformation.""}, 'authors': [{'name': 'Cuihua Shen'}, {'name': 'Mona Kasra'}, {'name': ""James O'Brien""}], 'author_detail': {'name': ""James O'Brien""}, 'author': ""James O'Brien"", 'links': [{'href': 'http://arxiv.org/abs/2101.07951v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.07951v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
157,http://arxiv.org/abs/2101.07664v1,2021-01-19 14:57:04+00:00,2021-01-19 14:57:04+00:00,Analysis of Moral Judgement on Reddit,"[arxiv.Result.Author('Nicholas Botzer'), arxiv.Result.Author('Shawn Gu'), arxiv.Result.Author('Tim Weninger')]","Moral outrage has become synonymous with social media in recent years.
However, the preponderance of academic analysis on social media websites has
focused on hate speech and misinformation. This paper focuses on analyzing
moral judgements rendered on social media by capturing the moral judgements
that are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels
associated with each judgement we train a classifier that can take a comment
and determine whether it judges the user who made the original post to have
positive or negative moral valence. Then, we use this classifier to investigate
an assortment of website traits surrounding moral judgements in ten other
subreddits, including where negative moral users like to post and their posting
patterns. Our findings also indicate that posts that are judged in a positive
manner will score higher.","Submitted to ICWSM 2021, 9 pages and 6 figures",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.07664v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.07664v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.07664v1,"{'id': 'http://arxiv.org/abs/2101.07664v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.07664v1', 'updated': '2021-01-19T14:57:04Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=19, tm_hour=14, tm_min=57, tm_sec=4, tm_wday=1, tm_yday=19, tm_isdst=0), 'published': '2021-01-19T14:57:04Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=19, tm_hour=14, tm_min=57, tm_sec=4, tm_wday=1, tm_yday=19, tm_isdst=0), 'title': 'Analysis of Moral Judgement on Reddit', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysis of Moral Judgement on Reddit'}, 'summary': 'Moral outrage has become synonymous with social media in recent years.\nHowever, the preponderance of academic analysis on social media websites has\nfocused on hate speech and misinformation. This paper focuses on analyzing\nmoral judgements rendered on social media by capturing the moral judgements\nthat are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels\nassociated with each judgement we train a classifier that can take a comment\nand determine whether it judges the user who made the original post to have\npositive or negative moral valence. Then, we use this classifier to investigate\nan assortment of website traits surrounding moral judgements in ten other\nsubreddits, including where negative moral users like to post and their posting\npatterns. Our findings also indicate that posts that are judged in a positive\nmanner will score higher.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Moral outrage has become synonymous with social media in recent years.\nHowever, the preponderance of academic analysis on social media websites has\nfocused on hate speech and misinformation. This paper focuses on analyzing\nmoral judgements rendered on social media by capturing the moral judgements\nthat are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels\nassociated with each judgement we train a classifier that can take a comment\nand determine whether it judges the user who made the original post to have\npositive or negative moral valence. Then, we use this classifier to investigate\nan assortment of website traits surrounding moral judgements in ten other\nsubreddits, including where negative moral users like to post and their posting\npatterns. Our findings also indicate that posts that are judged in a positive\nmanner will score higher.'}, 'authors': [{'name': 'Nicholas Botzer'}, {'name': 'Shawn Gu'}, {'name': 'Tim Weninger'}], 'author_detail': {'name': 'Tim Weninger'}, 'author': 'Tim Weninger', 'arxiv_comment': 'Submitted to ICWSM 2021, 9 pages and 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2101.07664v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.07664v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
158,http://arxiv.org/abs/2101.03841v1,2021-01-11 12:23:41+00:00,2021-01-11 12:23:41+00:00,Model Generalization on COVID-19 Fake News Detection,"[arxiv.Result.Author('Yejin Bang'), arxiv.Result.Author('Etsuko Ishii'), arxiv.Result.Author('Samuel Cahyawijaya'), arxiv.Result.Author('Ziwei Ji'), arxiv.Result.Author('Pascale Fung')]","Amid the pandemic COVID-19, the world is facing unprecedented infodemic with
the proliferation of both fake and real information. Considering the
problematic consequences that the COVID-19 fake-news have brought, the
scientific community has put effort to tackle it. To contribute to this fight
against the infodemic, we aim to achieve a robust model for the COVID-19
fake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking
two separate approaches: 1) fine-tuning transformers based language models with
robust loss functions and 2) removing harmful training instances through
influence calculation. We further evaluate the robustness of our models by
evaluating on different COVID-19 misinformation test set (Tweets-19) to
understand model generalization ability. With the first approach, we achieve
98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on
the Tweets-19 highest. On the contrary, by performing influence data cleansing,
our model with 99% cleansing percentage can achieve 54.33% W-F1 score on
Tweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news
test sets, we suggest the importance of model generalization ability in this
task to step forward to tackle the COVID-19 fake-news problem in online social
media platforms.",CONSTRAINT Workshop 2021 (Camera Ready Version),,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.03841v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03841v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03841v1,"{'id': 'http://arxiv.org/abs/2101.03841v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03841v1', 'updated': '2021-01-11T12:23:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=12, tm_min=23, tm_sec=41, tm_wday=0, tm_yday=11, tm_isdst=0), 'published': '2021-01-11T12:23:41Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=11, tm_hour=12, tm_min=23, tm_sec=41, tm_wday=0, tm_yday=11, tm_isdst=0), 'title': 'Model Generalization on COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Model Generalization on COVID-19 Fake News Detection'}, 'summary': 'Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.'}, 'authors': [{'name': 'Yejin Bang'}, {'name': 'Etsuko Ishii'}, {'name': 'Samuel Cahyawijaya'}, {'name': 'Ziwei Ji'}, {'name': 'Pascale Fung'}], 'author_detail': {'name': 'Pascale Fung'}, 'author': 'Pascale Fung', 'arxiv_comment': 'CONSTRAINT Workshop 2021 (Camera Ready Version)', 'links': [{'href': 'http://arxiv.org/abs/2101.03841v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03841v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
159,http://arxiv.org/abs/2101.03529v1,2021-01-10 11:52:17+00:00,2021-01-10 11:52:17+00:00,TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on Corona Virus and 5G Conspiracy,"[arxiv.Result.Author('Gullal S. Cheema'), arxiv.Result.Author('Sherzod Hakimov'), arxiv.Result.Author('Ralph Ewerth')]","Fake news on social media has become a hot topic of research as it negatively
impacts the discourse of real news in the public. Specifically, the ongoing
COVID-19 pandemic has seen a rise of inaccurate and misleading information due
to the surrounding controversies and unknown details at the beginning of the
pandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating
a challenge to automatically detect tweets containing misinformation based on
text and structure from Twitter follower network. In this paper, we present a
simple approach that uses BERT embeddings and a shallow neural network for
classifying tweets using only text, and discuss our findings and limitations of
the approach in text-based misinformation detection.",MediaEval 2020 Fake News Task,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.03529v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.03529v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.03529v1,"{'id': 'http://arxiv.org/abs/2101.03529v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.03529v1', 'updated': '2021-01-10T11:52:17Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=10, tm_hour=11, tm_min=52, tm_sec=17, tm_wday=6, tm_yday=10, tm_isdst=0), 'published': '2021-01-10T11:52:17Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=10, tm_hour=11, tm_min=52, tm_sec=17, tm_wday=6, tm_yday=10, tm_isdst=0), 'title': ""TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy""}, 'summary': 'Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.'}, 'authors': [{'name': 'Gullal S. Cheema'}, {'name': 'Sherzod Hakimov'}, {'name': 'Ralph Ewerth'}], 'author_detail': {'name': 'Ralph Ewerth'}, 'author': 'Ralph Ewerth', 'arxiv_comment': 'MediaEval 2020 Fake News Task', 'links': [{'href': 'http://arxiv.org/abs/2101.03529v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.03529v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
160,http://arxiv.org/abs/2101.05626v1,2021-01-09 22:52:21+00:00,2021-01-09 22:52:21+00:00,Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on the Arabic Content of Twitter,"[arxiv.Result.Author('Sarah Alqurashi'), arxiv.Result.Author('Btool Hamoui'), arxiv.Result.Author('Abdulaziz Alashaikh'), arxiv.Result.Author('Ahmad Alhindi'), arxiv.Result.Author('Eisa Alanazi')]","The rapid growth of social media content during the current pandemic provides
useful tools for disseminating information which has also become a root for
misinformation. Therefore, there is an urgent need for fact-checking and
effective techniques for detecting misinformation in social media. In this
work, we study the misinformation in the Arabic content of Twitter. We
construct a large Arabic dataset related to COVID-19 misinformation and
gold-annotate the tweets into two categories: misinformation or not. Then, we
apply eight different traditional and deep machine learning models, with
different features including word embeddings and word frequency. The word
embedding models (\textsc{FastText} and word2vec) exploit more than two million
Arabic tweets related to COVID-19. Experiments show that optimizing the area
under the curve (AUC) improves the models' performance and the Extreme Gradient
Boosting (XGBoost) presents the highest accuracy in detecting COVID-19
misinformation online.","18 pages, 4 figures",,,cs.IR,"['cs.IR', 'cs.CY', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.05626v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.05626v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.05626v1,"{'id': 'http://arxiv.org/abs/2101.05626v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.05626v1', 'updated': '2021-01-09T22:52:21Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=9, tm_hour=22, tm_min=52, tm_sec=21, tm_wday=5, tm_yday=9, tm_isdst=0), 'published': '2021-01-09T22:52:21Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=9, tm_hour=22, tm_min=52, tm_sec=21, tm_wday=5, tm_yday=9, tm_isdst=0), 'title': 'Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter'}, 'summary': ""The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online.""}, 'authors': [{'name': 'Sarah Alqurashi'}, {'name': 'Btool Hamoui'}, {'name': 'Abdulaziz Alashaikh'}, {'name': 'Ahmad Alhindi'}, {'name': 'Eisa Alanazi'}], 'author_detail': {'name': 'Eisa Alanazi'}, 'author': 'Eisa Alanazi', 'arxiv_comment': '18 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2101.05626v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.05626v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
161,http://arxiv.org/abs/2101.04079v2,2021-06-05 18:01:16+00:00,2021-01-07 01:40:52+00:00,Depolarization of echo chambers by random dynamical nudge,"[arxiv.Result.Author('Christopher Currin'), arxiv.Result.Author('Sebastian Vallejo Vera'), arxiv.Result.Author('Ali Khaledi-Nasab')]","Interactions among individuals in social networks lead to echo chambers where
the distribution of opinions follows a bimodal distribution with two peaks at
the opposite extremes. In issues with clear answers, such as global warming,
one of the echo chambers reflects an inaccurate judgment, potentially from
misinformation. However, in issues without clear answers such as elections, the
neutral consensus is preferable for promoting discourse. In this letter, we use
an opinion dynamics model to study the effect of a random dynamical nudge where
we present random input to each agent from the other individuals in the
network. We show that random dynamical nudge disallows the formation of echo
chambers and leads to a normal distribution of opinions centered around the
neutral consensus. The random dynamical nudge relies on the collective dynamics
and it does not require surveillance of every person's opinions. Social media
networks could implement a version of this self-feedback mechanism to prevent
the formation of segregated online communities on pressing issues such as
elections.","9 pages, 4 Figs",,,physics.soc-ph,"['physics.soc-ph', 'physics.bio-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2101.04079v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.04079v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.04079v2,"{'id': 'http://arxiv.org/abs/2101.04079v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.04079v2', 'updated': '2021-06-05T18:01:16Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=5, tm_hour=18, tm_min=1, tm_sec=16, tm_wday=5, tm_yday=156, tm_isdst=0), 'published': '2021-01-07T01:40:52Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=1, tm_min=40, tm_sec=52, tm_wday=3, tm_yday=7, tm_isdst=0), 'title': 'Depolarization of echo chambers by random dynamical nudge', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Depolarization of echo chambers by random dynamical nudge'}, 'summary': ""Interactions among individuals in social networks lead to echo chambers where\nthe distribution of opinions follows a bimodal distribution with two peaks at\nthe opposite extremes. In issues with clear answers, such as global warming,\none of the echo chambers reflects an inaccurate judgment, potentially from\nmisinformation. However, in issues without clear answers such as elections, the\nneutral consensus is preferable for promoting discourse. In this letter, we use\nan opinion dynamics model to study the effect of a random dynamical nudge where\nwe present random input to each agent from the other individuals in the\nnetwork. We show that random dynamical nudge disallows the formation of echo\nchambers and leads to a normal distribution of opinions centered around the\nneutral consensus. The random dynamical nudge relies on the collective dynamics\nand it does not require surveillance of every person's opinions. Social media\nnetworks could implement a version of this self-feedback mechanism to prevent\nthe formation of segregated online communities on pressing issues such as\nelections."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Interactions among individuals in social networks lead to echo chambers where\nthe distribution of opinions follows a bimodal distribution with two peaks at\nthe opposite extremes. In issues with clear answers, such as global warming,\none of the echo chambers reflects an inaccurate judgment, potentially from\nmisinformation. However, in issues without clear answers such as elections, the\nneutral consensus is preferable for promoting discourse. In this letter, we use\nan opinion dynamics model to study the effect of a random dynamical nudge where\nwe present random input to each agent from the other individuals in the\nnetwork. We show that random dynamical nudge disallows the formation of echo\nchambers and leads to a normal distribution of opinions centered around the\nneutral consensus. The random dynamical nudge relies on the collective dynamics\nand it does not require surveillance of every person's opinions. Social media\nnetworks could implement a version of this self-feedback mechanism to prevent\nthe formation of segregated online communities on pressing issues such as\nelections.""}, 'authors': [{'name': 'Christopher Currin'}, {'name': 'Sebastian Vallejo Vera'}, {'name': 'Ali Khaledi-Nasab'}], 'author_detail': {'name': 'Ali Khaledi-Nasab'}, 'author': 'Ali Khaledi-Nasab', 'arxiv_comment': '9 pages, 4 Figs', 'links': [{'href': 'http://arxiv.org/abs/2101.04079v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.04079v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.bio-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
162,http://arxiv.org/abs/2101.01688v2,2021-02-25 15:42:49+00:00,2021-01-05 18:21:03+00:00,What social media told about us in the time of COVID-19: a scoping review,"[arxiv.Result.Author('Shu-Feng Tsao'), arxiv.Result.Author('Helen Chen'), arxiv.Result.Author('Therese Tisseverasinghe'), arxiv.Result.Author('Yang Yang'), arxiv.Result.Author('Lianghua Li'), arxiv.Result.Author('Zahid A. Butt')]","With the onset of COVID-19 pandemic, social media has rapidly become a
crucial communication tool for information generation, dissemination, and
consumption. In this scoping review, we selected and examined peer-reviewed
empirical studies relating to COVID-19 and social media during the first
outbreak starting in November 2019 until May 2020. From an analysis of 81
studies, we identified five overarching public health themes concerning the
role of online social platforms and COVID-19. These themes focused on: (i)
surveying public attitudes, (ii) identifying infodemics, (iii) assessing mental
health, (iv) detecting or predicting COVID-19 cases, (v) analyzing government
responses to the pandemic, and (vi) evaluating quality of health information in
prevention education videos. Furthermore, our review highlights the paucity of
studies on the application of machine learning on social media data related to
COVID-19 and a lack of studies documenting real-time surveillance developed
with social media data on COVID-19. For COVID-19, social media can play a
crucial role in disseminating health information as well as tackling infodemics
and misinformation.","20 pages excluding reference list and table 2. 2 figures. Accepted
  manuscripts by Lancet Digital Health","The Lancet Digital Health, Review, Vol 3, Iss 3, E175-E194, March
  01, 2021",10.1016/S2589-7500(20)30315-0,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1016/S2589-7500(20)30315-0', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2101.01688v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.01688v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.01688v2,"{'id': 'http://arxiv.org/abs/2101.01688v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.01688v2', 'updated': '2021-02-25T15:42:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=25, tm_hour=15, tm_min=42, tm_sec=49, tm_wday=3, tm_yday=56, tm_isdst=0), 'published': '2021-01-05T18:21:03Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=5, tm_hour=18, tm_min=21, tm_sec=3, tm_wday=1, tm_yday=5, tm_isdst=0), 'title': 'What social media told about us in the time of COVID-19: a scoping\n  review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What social media told about us in the time of COVID-19: a scoping\n  review'}, 'summary': 'With the onset of COVID-19 pandemic, social media has rapidly become a\ncrucial communication tool for information generation, dissemination, and\nconsumption. In this scoping review, we selected and examined peer-reviewed\nempirical studies relating to COVID-19 and social media during the first\noutbreak starting in November 2019 until May 2020. From an analysis of 81\nstudies, we identified five overarching public health themes concerning the\nrole of online social platforms and COVID-19. These themes focused on: (i)\nsurveying public attitudes, (ii) identifying infodemics, (iii) assessing mental\nhealth, (iv) detecting or predicting COVID-19 cases, (v) analyzing government\nresponses to the pandemic, and (vi) evaluating quality of health information in\nprevention education videos. Furthermore, our review highlights the paucity of\nstudies on the application of machine learning on social media data related to\nCOVID-19 and a lack of studies documenting real-time surveillance developed\nwith social media data on COVID-19. For COVID-19, social media can play a\ncrucial role in disseminating health information as well as tackling infodemics\nand misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the onset of COVID-19 pandemic, social media has rapidly become a\ncrucial communication tool for information generation, dissemination, and\nconsumption. In this scoping review, we selected and examined peer-reviewed\nempirical studies relating to COVID-19 and social media during the first\noutbreak starting in November 2019 until May 2020. From an analysis of 81\nstudies, we identified five overarching public health themes concerning the\nrole of online social platforms and COVID-19. These themes focused on: (i)\nsurveying public attitudes, (ii) identifying infodemics, (iii) assessing mental\nhealth, (iv) detecting or predicting COVID-19 cases, (v) analyzing government\nresponses to the pandemic, and (vi) evaluating quality of health information in\nprevention education videos. Furthermore, our review highlights the paucity of\nstudies on the application of machine learning on social media data related to\nCOVID-19 and a lack of studies documenting real-time surveillance developed\nwith social media data on COVID-19. For COVID-19, social media can play a\ncrucial role in disseminating health information as well as tackling infodemics\nand misinformation.'}, 'authors': [{'name': 'Shu-Feng Tsao'}, {'name': 'Helen Chen'}, {'name': 'Therese Tisseverasinghe'}, {'name': 'Yang Yang'}, {'name': 'Lianghua Li'}, {'name': 'Zahid A. Butt'}], 'author_detail': {'name': 'Zahid A. Butt'}, 'author': 'Zahid A. Butt', 'arxiv_doi': '10.1016/S2589-7500(20)30315-0', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/S2589-7500(20)30315-0', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2101.01688v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.01688v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '20 pages excluding reference list and table 2. 2 figures. Accepted\n  manuscripts by Lancet Digital Health', 'arxiv_journal_ref': 'The Lancet Digital Health, Review, Vol 3, Iss 3, E175-E194, March\n  01, 2021', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
163,http://arxiv.org/abs/2101.00180v3,2021-01-21 15:18:40+00:00,2021-01-01 06:49:27+00:00,Transformer based Automatic COVID-19 Fake News Detection System,"[arxiv.Result.Author('Sunil Gundapu'), arxiv.Result.Author('Radhika Mamidi')]","Recent rapid technological advancements in online social networks such as
Twitter have led to a great incline in spreading false information and fake
news. Misinformation is especially prevalent in the ongoing coronavirus disease
(COVID-19) pandemic, leading to individuals accepting bogus and potentially
deleterious claims and articles. Quick detection of fake news can reduce the
spread of panic and confusion among the public. For our analysis in this paper,
we report a methodology to analyze the reliability of information shared on
social media pertaining to the COVID-19 pandemic. Our best approach is based on
an ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting
fake news. This model was trained and evaluated in the context of the
ConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our
system obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.","First Workshop on Combating Online Hostile Posts in Regional
  Languages during Emergency Situation, 12 pages",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2101.00180v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.00180v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.00180v3,"{'id': 'http://arxiv.org/abs/2101.00180v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.00180v3', 'updated': '2021-01-21T15:18:40Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=21, tm_hour=15, tm_min=18, tm_sec=40, tm_wday=3, tm_yday=21, tm_isdst=0), 'published': '2021-01-01T06:49:27Z', 'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=1, tm_hour=6, tm_min=49, tm_sec=27, tm_wday=4, tm_yday=1, tm_isdst=0), 'title': 'Transformer based Automatic COVID-19 Fake News Detection System', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Transformer based Automatic COVID-19 Fake News Detection System'}, 'summary': 'Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.'}, 'authors': [{'name': 'Sunil Gundapu'}, {'name': 'Radhika Mamidi'}], 'author_detail': {'name': 'Radhika Mamidi'}, 'author': 'Radhika Mamidi', 'arxiv_comment': 'First Workshop on Combating Online Hostile Posts in Regional\n  Languages during Emergency Situation, 12 pages', 'links': [{'href': 'http://arxiv.org/abs/2101.00180v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.00180v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
164,http://arxiv.org/abs/2012.14500v2,2021-01-25 02:29:18+00:00,2020-12-28 21:51:31+00:00,A Paragraph-level Multi-task Learning Model for Scientific Fact-Verification,"[arxiv.Result.Author('Xiangci Li'), arxiv.Result.Author('Gully Burns'), arxiv.Result.Author('Nanyun Peng')]","Even for domain experts, it is a non-trivial task to verify a scientific
claim by providing supporting or refuting evidence rationales. The situation
worsens as misinformation is proliferated on social media or news websites,
manually or programmatically, at every moment. As a result, an automatic
fact-verification tool becomes crucial for combating the spread of
misinformation. In this work, we propose a novel, paragraph-level, multi-task
learning model for the SciFact task by directly computing a sequence of
contextualized sentence embeddings from a BERT model and jointly training the
model on rationale selection and stance prediction.",5 pages; The AAAI-21 Workshop on Scientific Document Understanding,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.14500v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.14500v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.14500v2,"{'id': 'http://arxiv.org/abs/2012.14500v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.14500v2', 'updated': '2021-01-25T02:29:18Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=25, tm_hour=2, tm_min=29, tm_sec=18, tm_wday=0, tm_yday=25, tm_isdst=0), 'published': '2020-12-28T21:51:31Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=21, tm_min=51, tm_sec=31, tm_wday=0, tm_yday=363, tm_isdst=0), 'title': 'A Paragraph-level Multi-task Learning Model for Scientific\n  Fact-Verification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Paragraph-level Multi-task Learning Model for Scientific\n  Fact-Verification'}, 'summary': 'Even for domain experts, it is a non-trivial task to verify a scientific\nclaim by providing supporting or refuting evidence rationales. The situation\nworsens as misinformation is proliferated on social media or news websites,\nmanually or programmatically, at every moment. As a result, an automatic\nfact-verification tool becomes crucial for combating the spread of\nmisinformation. In this work, we propose a novel, paragraph-level, multi-task\nlearning model for the SciFact task by directly computing a sequence of\ncontextualized sentence embeddings from a BERT model and jointly training the\nmodel on rationale selection and stance prediction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Even for domain experts, it is a non-trivial task to verify a scientific\nclaim by providing supporting or refuting evidence rationales. The situation\nworsens as misinformation is proliferated on social media or news websites,\nmanually or programmatically, at every moment. As a result, an automatic\nfact-verification tool becomes crucial for combating the spread of\nmisinformation. In this work, we propose a novel, paragraph-level, multi-task\nlearning model for the SciFact task by directly computing a sequence of\ncontextualized sentence embeddings from a BERT model and jointly training the\nmodel on rationale selection and stance prediction.'}, 'authors': [{'name': 'Xiangci Li'}, {'name': 'Gully Burns'}, {'name': 'Nanyun Peng'}], 'author_detail': {'name': 'Nanyun Peng'}, 'author': 'Nanyun Peng', 'arxiv_comment': '5 pages; The AAAI-21 Workshop on Scientific Document Understanding', 'links': [{'href': 'http://arxiv.org/abs/2012.14500v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.14500v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
165,http://arxiv.org/abs/2101.01142v1,2020-12-28 13:07:42+00:00,2020-12-28 13:07:42+00:00,Advanced Machine Learning Techniques for Fake News (Online Disinformation) Detection: A Systematic Mapping Study,"[arxiv.Result.Author('Michal Choras'), arxiv.Result.Author('Konstantinos Demestichas'), arxiv.Result.Author('Agata Gielczyk'), arxiv.Result.Author('Alvaro Herrero'), arxiv.Result.Author('Pawel Ksieniewicz'), arxiv.Result.Author('Konstantina Remoundou'), arxiv.Result.Author('Daniel Urda'), arxiv.Result.Author('Michal Wozniak')]","Fake news has now grown into a big problem for societies and also a major
challenge for people fighting disinformation. This phenomenon plagues
democratic elections, reputations of individual persons or organizations, and
has negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US
or Brazil). Hence, developing effective tools to fight this phenomenon by
employing advanced Machine Learning (ML) methods poses a significant challenge.
The following paper displays the present body of knowledge on the application
of such intelligent tools in the fight against disinformation. It starts by
showing the historical perspective and the current role of fake news in the
information war. Proposed solutions based solely on the work of experts are
analysed and the most important directions of the application of intelligent
systems in the detection of misinformation sources are pointed out.
Additionally, the paper presents some useful resources (mainly datasets useful
when assessing ML solutions for fake news detection) and provides a short
overview of the most important R&D projects related to this subject. The main
purpose of this work is to analyse the current state of knowledge in detecting
fake news; on the one hand to show possible solutions, and on the other hand to
identify the main challenges and methodological gaps to motivate future
research.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.01142v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.01142v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.01142v1,"{'id': 'http://arxiv.org/abs/2101.01142v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.01142v1', 'updated': '2020-12-28T13:07:42Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=13, tm_min=7, tm_sec=42, tm_wday=0, tm_yday=363, tm_isdst=0), 'published': '2020-12-28T13:07:42Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=13, tm_min=7, tm_sec=42, tm_wday=0, tm_yday=363, tm_isdst=0), 'title': 'Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study'}, 'summary': 'Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.'}, 'authors': [{'name': 'Michal Choras'}, {'name': 'Konstantinos Demestichas'}, {'name': 'Agata Gielczyk'}, {'name': 'Alvaro Herrero'}, {'name': 'Pawel Ksieniewicz'}, {'name': 'Konstantina Remoundou'}, {'name': 'Daniel Urda'}, {'name': 'Michal Wozniak'}], 'author_detail': {'name': 'Michal Wozniak'}, 'author': 'Michal Wozniak', 'links': [{'href': 'http://arxiv.org/abs/2101.01142v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.01142v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
166,http://arxiv.org/abs/2012.13968v1,2020-12-27 16:03:32+00:00,2020-12-27 16:03:32+00:00,Detecting Medical Misinformation on Social Media Using Multimodal Deep Learning,"[arxiv.Result.Author('Zuhui Wang'), arxiv.Result.Author('Zhaozheng Yin'), arxiv.Result.Author('Young Anna Argyris')]","In 2019, outbreaks of vaccine-preventable diseases reached the highest number
in the US since 1992. Medical misinformation, such as antivaccine content
propagating through social media, is associated with increases in vaccine delay
and refusal. Our overall goal is to develop an automatic detector for
antivaccine messages to counteract the negative impact that antivaccine
messages have on the public health. Very few extant detection systems have
considered multimodality of social media posts (images, texts, and hashtags),
and instead focus on textual components, despite the rapid growth of
photo-sharing applications (e.g., Instagram). As a result, existing systems are
not sufficient for detecting antivaccine messages with heavy visual components
(e.g., images) posted on these newer platforms. To solve this problem, we
propose a deep learning network that leverages both visual and textual
information. A new semantic- and task-level attention mechanism was created to
help our model to focus on the essential contents of a post that signal
antivaccine messages. The proposed model, which consists of three branches, can
generate comprehensive fused features for predictions. Moreover, an ensemble
method is proposed to further improve the final prediction accuracy. To
evaluate the proposed model's performance, a real-world social media dataset
that consists of more than 30,000 samples was collected from Instagram between
January 2016 and October 2019. Our 30 experiment results demonstrate that the
final network achieves above 97% testing accuracy and outperforms other
relevant models, demonstrating that it can detect a large amount of antivaccine
messages posted daily. The implementation code is available at
https://github.com/wzhings/antivaccine_detection.",,,,cs.MM,['cs.MM'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.13968v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.13968v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.13968v1,"{'id': 'http://arxiv.org/abs/2012.13968v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.13968v1', 'updated': '2020-12-27T16:03:32Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=27, tm_hour=16, tm_min=3, tm_sec=32, tm_wday=6, tm_yday=362, tm_isdst=0), 'published': '2020-12-27T16:03:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=27, tm_hour=16, tm_min=3, tm_sec=32, tm_wday=6, tm_yday=362, tm_isdst=0), 'title': 'Detecting Medical Misinformation on Social Media Using Multimodal Deep\n  Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting Medical Misinformation on Social Media Using Multimodal Deep\n  Learning'}, 'summary': ""In 2019, outbreaks of vaccine-preventable diseases reached the highest number\nin the US since 1992. Medical misinformation, such as antivaccine content\npropagating through social media, is associated with increases in vaccine delay\nand refusal. Our overall goal is to develop an automatic detector for\nantivaccine messages to counteract the negative impact that antivaccine\nmessages have on the public health. Very few extant detection systems have\nconsidered multimodality of social media posts (images, texts, and hashtags),\nand instead focus on textual components, despite the rapid growth of\nphoto-sharing applications (e.g., Instagram). As a result, existing systems are\nnot sufficient for detecting antivaccine messages with heavy visual components\n(e.g., images) posted on these newer platforms. To solve this problem, we\npropose a deep learning network that leverages both visual and textual\ninformation. A new semantic- and task-level attention mechanism was created to\nhelp our model to focus on the essential contents of a post that signal\nantivaccine messages. The proposed model, which consists of three branches, can\ngenerate comprehensive fused features for predictions. Moreover, an ensemble\nmethod is proposed to further improve the final prediction accuracy. To\nevaluate the proposed model's performance, a real-world social media dataset\nthat consists of more than 30,000 samples was collected from Instagram between\nJanuary 2016 and October 2019. Our 30 experiment results demonstrate that the\nfinal network achieves above 97% testing accuracy and outperforms other\nrelevant models, demonstrating that it can detect a large amount of antivaccine\nmessages posted daily. The implementation code is available at\nhttps://github.com/wzhings/antivaccine_detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In 2019, outbreaks of vaccine-preventable diseases reached the highest number\nin the US since 1992. Medical misinformation, such as antivaccine content\npropagating through social media, is associated with increases in vaccine delay\nand refusal. Our overall goal is to develop an automatic detector for\nantivaccine messages to counteract the negative impact that antivaccine\nmessages have on the public health. Very few extant detection systems have\nconsidered multimodality of social media posts (images, texts, and hashtags),\nand instead focus on textual components, despite the rapid growth of\nphoto-sharing applications (e.g., Instagram). As a result, existing systems are\nnot sufficient for detecting antivaccine messages with heavy visual components\n(e.g., images) posted on these newer platforms. To solve this problem, we\npropose a deep learning network that leverages both visual and textual\ninformation. A new semantic- and task-level attention mechanism was created to\nhelp our model to focus on the essential contents of a post that signal\nantivaccine messages. The proposed model, which consists of three branches, can\ngenerate comprehensive fused features for predictions. Moreover, an ensemble\nmethod is proposed to further improve the final prediction accuracy. To\nevaluate the proposed model's performance, a real-world social media dataset\nthat consists of more than 30,000 samples was collected from Instagram between\nJanuary 2016 and October 2019. Our 30 experiment results demonstrate that the\nfinal network achieves above 97% testing accuracy and outperforms other\nrelevant models, demonstrating that it can detect a large amount of antivaccine\nmessages posted daily. The implementation code is available at\nhttps://github.com/wzhings/antivaccine_detection.""}, 'authors': [{'name': 'Zuhui Wang'}, {'name': 'Zhaozheng Yin'}, {'name': 'Young Anna Argyris'}], 'author_detail': {'name': 'Young Anna Argyris'}, 'author': 'Young Anna Argyris', 'links': [{'href': 'http://arxiv.org/abs/2012.13968v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.13968v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
167,http://arxiv.org/abs/2012.12593v2,2020-12-28 07:19:01+00:00,2020-12-23 10:50:30+00:00,Attention and misinformation sharing on social media,"[arxiv.Result.Author('Zaid Amin'), arxiv.Result.Author('Nazlena Mohamad Ali'), arxiv.Result.Author('Alan F. Smeaton')]","The behaviour of sharing information on social media should be fulfilled only
when a user is exhibiting attentive behaviour. So that the useful information
can be consumed constructively, and misinformation can be identified and
ignored. Attentive behaviour is related to users' cognitive abilities in their
processing of set information. The work described in this paper examines the
issue of attentive factors that affect users' behaviour when they share
misinformation on social media. The research aims to identify the significance
of prevailing attention factors towards sharing misinformation on social media.
We used a closed-ended questionnaire which consisted of a psychometric scale to
measure attention behaviour with participants (n = 112). The regression
equation results are obtained as: y=(19,533-0,390+e) from a set of regression
analyses shows that attention factors have a significant negative correlation
effect for users to share misinformation on social media. Along with the
findings of the analysis results, we propose that attentive factors are
incorporated into a social media application's future design that could
intervene in user attention and avoid potential harm caused by the spread of
misinformation.",,,,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2012.12593v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.12593v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.12593v2,"{'id': 'http://arxiv.org/abs/2012.12593v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.12593v2', 'updated': '2020-12-28T07:19:01Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=28, tm_hour=7, tm_min=19, tm_sec=1, tm_wday=0, tm_yday=363, tm_isdst=0), 'published': '2020-12-23T10:50:30Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=23, tm_hour=10, tm_min=50, tm_sec=30, tm_wday=2, tm_yday=358, tm_isdst=0), 'title': 'Attention and misinformation sharing on social media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Attention and misinformation sharing on social media'}, 'summary': ""The behaviour of sharing information on social media should be fulfilled only\nwhen a user is exhibiting attentive behaviour. So that the useful information\ncan be consumed constructively, and misinformation can be identified and\nignored. Attentive behaviour is related to users' cognitive abilities in their\nprocessing of set information. The work described in this paper examines the\nissue of attentive factors that affect users' behaviour when they share\nmisinformation on social media. The research aims to identify the significance\nof prevailing attention factors towards sharing misinformation on social media.\nWe used a closed-ended questionnaire which consisted of a psychometric scale to\nmeasure attention behaviour with participants (n = 112). The regression\nequation results are obtained as: y=(19,533-0,390+e) from a set of regression\nanalyses shows that attention factors have a significant negative correlation\neffect for users to share misinformation on social media. Along with the\nfindings of the analysis results, we propose that attentive factors are\nincorporated into a social media application's future design that could\nintervene in user attention and avoid potential harm caused by the spread of\nmisinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The behaviour of sharing information on social media should be fulfilled only\nwhen a user is exhibiting attentive behaviour. So that the useful information\ncan be consumed constructively, and misinformation can be identified and\nignored. Attentive behaviour is related to users' cognitive abilities in their\nprocessing of set information. The work described in this paper examines the\nissue of attentive factors that affect users' behaviour when they share\nmisinformation on social media. The research aims to identify the significance\nof prevailing attention factors towards sharing misinformation on social media.\nWe used a closed-ended questionnaire which consisted of a psychometric scale to\nmeasure attention behaviour with participants (n = 112). The regression\nequation results are obtained as: y=(19,533-0,390+e) from a set of regression\nanalyses shows that attention factors have a significant negative correlation\neffect for users to share misinformation on social media. Along with the\nfindings of the analysis results, we propose that attentive factors are\nincorporated into a social media application's future design that could\nintervene in user attention and avoid potential harm caused by the spread of\nmisinformation.""}, 'authors': [{'name': 'Zaid Amin'}, {'name': 'Nazlena Mohamad Ali'}, {'name': 'Alan F. Smeaton'}], 'author_detail': {'name': 'Alan F. Smeaton'}, 'author': 'Alan F. Smeaton', 'links': [{'href': 'http://arxiv.org/abs/2012.12593v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.12593v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
168,http://arxiv.org/abs/2012.11967v3,2021-01-13 11:36:32+00:00,2020-12-22 12:43:12+00:00,g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning for COVID-19 Fake News Detection,"[arxiv.Result.Author('Anna Glazkova'), arxiv.Result.Author('Maksim Glazkov'), arxiv.Result.Author('Timofey Trifonov')]","The COVID-19 pandemic has had a huge impact on various areas of human life.
Hence, the coronavirus pandemic and its consequences are being actively
discussed on social media. However, not all social media posts are truthful.
Many of them spread fake news that cause panic among readers, misinform people
and thus exacerbate the effect of the pandemic. In this paper, we present our
results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in
English. In particular, we propose our approach using the transformer-based
ensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,
the ways of text preprocessing and adding extra data. As a result, our best
model achieved the weighted F1-score of 98.69 on the test set (the first place
in the leaderboard) of this shared task that attracted 166 submitted teams in
total.",The winning solution at the Constraint shared task (AAAI-2021),"Combating Online Hostile Posts in Regional Languages during
  Emergency Situation, 116-127, 2021. Springer, Cham",10.1007/978-3-030-73696-5_12,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', '68T50', 'I.2.7; I.7.m; H.3.3']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-73696-5_12', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.11967v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.11967v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.11967v3,"{'id': 'http://arxiv.org/abs/2012.11967v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.11967v3', 'updated': '2021-01-13T11:36:32Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=13, tm_hour=11, tm_min=36, tm_sec=32, tm_wday=2, tm_yday=13, tm_isdst=0), 'published': '2020-12-22T12:43:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=22, tm_hour=12, tm_min=43, tm_sec=12, tm_wday=1, tm_yday=357, tm_isdst=0), 'title': 'g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection'}, 'summary': 'The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.'}, 'authors': [{'name': 'Anna Glazkova'}, {'name': 'Maksim Glazkov'}, {'name': 'Timofey Trifonov'}], 'author_detail': {'name': 'Timofey Trifonov'}, 'author': 'Timofey Trifonov', 'arxiv_doi': '10.1007/978-3-030-73696-5_12', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-73696-5_12', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.11967v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.11967v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'The winning solution at the Constraint shared task (AAAI-2021)', 'arxiv_journal_ref': 'Combating Online Hostile Posts in Regional Languages during\n  Emergency Situation, 116-127, 2021. Springer, Cham', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.7.m; H.3.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
169,http://arxiv.org/abs/2101.01076v1,2020-12-21 15:49:19+00:00,2020-12-21 15:49:19+00:00,Understanding Health Misinformation Transmission: An Interpretable Deep Learning Approach to Manage Infodemics,"[arxiv.Result.Author('Jiaheng Xie'), arxiv.Result.Author('Yidong Chai'), arxiv.Result.Author('Xiao Liu')]","Health misinformation on social media devastates physical and mental health,
invalidates health gains, and potentially costs lives. Understanding how health
misinformation is transmitted is an urgent goal for researchers, social media
platforms, health sectors, and policymakers to mitigate those ramifications.
Deep learning methods have been deployed to predict the spread of
misinformation. While achieving the state-of-the-art predictive performance,
deep learning methods lack the interpretability due to their blackbox nature.
To remedy this gap, this study proposes a novel interpretable deep learning
approach, Generative Adversarial Network based Piecewise Wide and Attention
Deep Learning (GAN-PiWAD), to predict health misinformation transmission in
social media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD
captures the interactions among multi-modal data, offers unbiased estimation of
the total effect of each feature, and models the dynamic total effect of each
feature when its value varies. We select features according to social exchange
theory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed
approach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates
video description, negative video content, and channel credibility are key
features that drive viral transmission of misinformation. This study
contributes to IS with a novel interpretable deep learning method that is
generalizable to understand other human decision factors. Our findings provide
direct implications for social media platforms and policymakers to design
proactive interventions to identify misinformation, control transmissions, and
manage infodemics.",,,,cs.LG,"['cs.LG', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2101.01076v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2101.01076v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2101.01076v1,"{'id': 'http://arxiv.org/abs/2101.01076v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2101.01076v1', 'updated': '2020-12-21T15:49:19Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=21, tm_hour=15, tm_min=49, tm_sec=19, tm_wday=0, tm_yday=356, tm_isdst=0), 'published': '2020-12-21T15:49:19Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=21, tm_hour=15, tm_min=49, tm_sec=19, tm_wday=0, tm_yday=356, tm_isdst=0), 'title': 'Understanding Health Misinformation Transmission: An Interpretable Deep\n  Learning Approach to Manage Infodemics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding Health Misinformation Transmission: An Interpretable Deep\n  Learning Approach to Manage Infodemics'}, 'summary': 'Health misinformation on social media devastates physical and mental health,\ninvalidates health gains, and potentially costs lives. Understanding how health\nmisinformation is transmitted is an urgent goal for researchers, social media\nplatforms, health sectors, and policymakers to mitigate those ramifications.\nDeep learning methods have been deployed to predict the spread of\nmisinformation. While achieving the state-of-the-art predictive performance,\ndeep learning methods lack the interpretability due to their blackbox nature.\nTo remedy this gap, this study proposes a novel interpretable deep learning\napproach, Generative Adversarial Network based Piecewise Wide and Attention\nDeep Learning (GAN-PiWAD), to predict health misinformation transmission in\nsocial media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD\ncaptures the interactions among multi-modal data, offers unbiased estimation of\nthe total effect of each feature, and models the dynamic total effect of each\nfeature when its value varies. We select features according to social exchange\ntheory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed\napproach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates\nvideo description, negative video content, and channel credibility are key\nfeatures that drive viral transmission of misinformation. This study\ncontributes to IS with a novel interpretable deep learning method that is\ngeneralizable to understand other human decision factors. Our findings provide\ndirect implications for social media platforms and policymakers to design\nproactive interventions to identify misinformation, control transmissions, and\nmanage infodemics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Health misinformation on social media devastates physical and mental health,\ninvalidates health gains, and potentially costs lives. Understanding how health\nmisinformation is transmitted is an urgent goal for researchers, social media\nplatforms, health sectors, and policymakers to mitigate those ramifications.\nDeep learning methods have been deployed to predict the spread of\nmisinformation. While achieving the state-of-the-art predictive performance,\ndeep learning methods lack the interpretability due to their blackbox nature.\nTo remedy this gap, this study proposes a novel interpretable deep learning\napproach, Generative Adversarial Network based Piecewise Wide and Attention\nDeep Learning (GAN-PiWAD), to predict health misinformation transmission in\nsocial media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD\ncaptures the interactions among multi-modal data, offers unbiased estimation of\nthe total effect of each feature, and models the dynamic total effect of each\nfeature when its value varies. We select features according to social exchange\ntheory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed\napproach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates\nvideo description, negative video content, and channel credibility are key\nfeatures that drive viral transmission of misinformation. This study\ncontributes to IS with a novel interpretable deep learning method that is\ngeneralizable to understand other human decision factors. Our findings provide\ndirect implications for social media platforms and policymakers to design\nproactive interventions to identify misinformation, control transmissions, and\nmanage infodemics.'}, 'authors': [{'name': 'Jiaheng Xie'}, {'name': 'Yidong Chai'}, {'name': 'Xiao Liu'}], 'author_detail': {'name': 'Xiao Liu'}, 'author': 'Xiao Liu', 'links': [{'href': 'http://arxiv.org/abs/2101.01076v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2101.01076v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
170,http://arxiv.org/abs/2012.11055v1,2020-12-21 00:02:04+00:00,2020-12-21 00:02:04+00:00,"Social Media COVID-19 Misinformation Interventions Viewed Positively, But Have Limited Impact","[arxiv.Result.Author('Christine Geeng'), arxiv.Result.Author('Tiona Francisco'), arxiv.Result.Author('Jevin West'), arxiv.Result.Author('Franziska Roesner')]","Amidst COVID-19 misinformation spreading, social media platforms like
Facebook and Twitter rolled out design interventions, including banners linking
to authoritative resources and more specific ""false information"" labels. In
late March 2020, shortly after these interventions began to appear, we
conducted an exploratory mixed-methods survey (N = 311) to learn: what are
social media users' attitudes towards these interventions, and to what extent
do they self-report effectiveness? We found that most participants indicated a
positive attitude towards interventions, particularly post-specific labels for
misinformation. Still, the majority of participants discovered or corrected
misinformation through other means, most commonly web searches, suggesting room
for platforms to do more to stem the spread of COVID-19 misinformation.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.11055v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.11055v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.11055v1,"{'id': 'http://arxiv.org/abs/2012.11055v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.11055v1', 'updated': '2020-12-21T00:02:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=21, tm_hour=0, tm_min=2, tm_sec=4, tm_wday=0, tm_yday=356, tm_isdst=0), 'published': '2020-12-21T00:02:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=21, tm_hour=0, tm_min=2, tm_sec=4, tm_wday=0, tm_yday=356, tm_isdst=0), 'title': 'Social Media COVID-19 Misinformation Interventions Viewed Positively,\n  But Have Limited Impact', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Media COVID-19 Misinformation Interventions Viewed Positively,\n  But Have Limited Impact'}, 'summary': 'Amidst COVID-19 misinformation spreading, social media platforms like\nFacebook and Twitter rolled out design interventions, including banners linking\nto authoritative resources and more specific ""false information"" labels. In\nlate March 2020, shortly after these interventions began to appear, we\nconducted an exploratory mixed-methods survey (N = 311) to learn: what are\nsocial media users\' attitudes towards these interventions, and to what extent\ndo they self-report effectiveness? We found that most participants indicated a\npositive attitude towards interventions, particularly post-specific labels for\nmisinformation. Still, the majority of participants discovered or corrected\nmisinformation through other means, most commonly web searches, suggesting room\nfor platforms to do more to stem the spread of COVID-19 misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Amidst COVID-19 misinformation spreading, social media platforms like\nFacebook and Twitter rolled out design interventions, including banners linking\nto authoritative resources and more specific ""false information"" labels. In\nlate March 2020, shortly after these interventions began to appear, we\nconducted an exploratory mixed-methods survey (N = 311) to learn: what are\nsocial media users\' attitudes towards these interventions, and to what extent\ndo they self-report effectiveness? We found that most participants indicated a\npositive attitude towards interventions, particularly post-specific labels for\nmisinformation. Still, the majority of participants discovered or corrected\nmisinformation through other means, most commonly web searches, suggesting room\nfor platforms to do more to stem the spread of COVID-19 misinformation.'}, 'authors': [{'name': 'Christine Geeng'}, {'name': 'Tiona Francisco'}, {'name': 'Jevin West'}, {'name': 'Franziska Roesner'}], 'author_detail': {'name': 'Franziska Roesner'}, 'author': 'Franziska Roesner', 'links': [{'href': 'http://arxiv.org/abs/2012.11055v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.11055v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
171,http://arxiv.org/abs/2012.10185v1,2020-12-18 12:10:13+00:00,2020-12-18 12:10:13+00:00,Recommenders with a mission: assessing diversity in newsrecommendations,"[arxiv.Result.Author('Sanne Vrijenhoek'), arxiv.Result.Author('Mesut Kaya'), arxiv.Result.Author('Nadia Metoui'), arxiv.Result.Author('Judith Möller'), arxiv.Result.Author('Daan Odijk'), arxiv.Result.Author('Natali Helberger')]","News recommenders help users to find relevant online content and have the
potential to fulfill a crucial role in a democratic society, directing the
scarce attention of citizens towards the information that is most important to
them. Simultaneously, recent concerns about so-called filter bubbles,
misinformation and selective exposure are symptomatic of the disruptive
potential of these digital news recommenders. Recommender systems can make or
break filter bubbles, and as such can be instrumental in creating either a more
closed or a more open internet. Current approaches to evaluating recommender
systems are often focused on measuring an increase in user clicks and
short-term engagement, rather than measuring the user's longer term interest in
diverse and important information.
  This paper aims to bridge the gap between normative notions of diversity,
rooted in democratic theory, and quantitative metrics necessary for evaluating
the recommender system. We propose a set of metrics grounded in social science
interpretations of diversity and suggest ways for practical implementations.",,,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.10185v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.10185v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.10185v1,"{'id': 'http://arxiv.org/abs/2012.10185v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.10185v1', 'updated': '2020-12-18T12:10:13Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=18, tm_hour=12, tm_min=10, tm_sec=13, tm_wday=4, tm_yday=353, tm_isdst=0), 'published': '2020-12-18T12:10:13Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=18, tm_hour=12, tm_min=10, tm_sec=13, tm_wday=4, tm_yday=353, tm_isdst=0), 'title': 'Recommenders with a mission: assessing diversity in newsrecommendations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recommenders with a mission: assessing diversity in newsrecommendations'}, 'summary': ""News recommenders help users to find relevant online content and have the\npotential to fulfill a crucial role in a democratic society, directing the\nscarce attention of citizens towards the information that is most important to\nthem. Simultaneously, recent concerns about so-called filter bubbles,\nmisinformation and selective exposure are symptomatic of the disruptive\npotential of these digital news recommenders. Recommender systems can make or\nbreak filter bubbles, and as such can be instrumental in creating either a more\nclosed or a more open internet. Current approaches to evaluating recommender\nsystems are often focused on measuring an increase in user clicks and\nshort-term engagement, rather than measuring the user's longer term interest in\ndiverse and important information.\n  This paper aims to bridge the gap between normative notions of diversity,\nrooted in democratic theory, and quantitative metrics necessary for evaluating\nthe recommender system. We propose a set of metrics grounded in social science\ninterpretations of diversity and suggest ways for practical implementations."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""News recommenders help users to find relevant online content and have the\npotential to fulfill a crucial role in a democratic society, directing the\nscarce attention of citizens towards the information that is most important to\nthem. Simultaneously, recent concerns about so-called filter bubbles,\nmisinformation and selective exposure are symptomatic of the disruptive\npotential of these digital news recommenders. Recommender systems can make or\nbreak filter bubbles, and as such can be instrumental in creating either a more\nclosed or a more open internet. Current approaches to evaluating recommender\nsystems are often focused on measuring an increase in user clicks and\nshort-term engagement, rather than measuring the user's longer term interest in\ndiverse and important information.\n  This paper aims to bridge the gap between normative notions of diversity,\nrooted in democratic theory, and quantitative metrics necessary for evaluating\nthe recommender system. We propose a set of metrics grounded in social science\ninterpretations of diversity and suggest ways for practical implementations.""}, 'authors': [{'name': 'Sanne Vrijenhoek'}, {'name': 'Mesut Kaya'}, {'name': 'Nadia Metoui'}, {'name': 'Judith Möller'}, {'name': 'Daan Odijk'}, {'name': 'Natali Helberger'}], 'author_detail': {'name': 'Natali Helberger'}, 'author': 'Natali Helberger', 'links': [{'href': 'http://arxiv.org/abs/2012.10185v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.10185v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
172,http://arxiv.org/abs/2012.09536v1,2020-12-17 12:17:55+00:00,2020-12-17 12:17:55+00:00,Conspiracy Machines -- The Role of Social Bots during the COVID-19 Infodemic,"[arxiv.Result.Author('Julian Marx'), arxiv.Result.Author('Felix Brünker'), arxiv.Result.Author('Milad Mirbabaie'), arxiv.Result.Author('Eric Hochstrate')]","The omnipresent COVID-19 pandemic gave rise to a parallel spreading of
misinformation, also referred to as an Infodemic. Consequently, social media
have become targets for the application of social bots, that is, algorithms
that mimic human behaviour. Their ability to exert influence on social media
can be exploited by amplifying misinformation, rumours, or conspiracy theories
which might be harmful to society and the mastery of the pandemic. By applying
social bot detection and content analysis techniques, this study aims to
determine the extent to which social bots interfere with COVID- 19 discussions
on Twitter. A total of 78 presumptive bots were detected within a sample of
542,345 users. The analysis revealed that bot-like users who disseminate
misinformation, at the same time, intersperse news from renowned sources. The
findings of this research provide implications for improved bot detection and
managing potential threats through social bots during ongoing and future
crises.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.09536v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.09536v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.09536v1,"{'id': 'http://arxiv.org/abs/2012.09536v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.09536v1', 'updated': '2020-12-17T12:17:55Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=17, tm_hour=12, tm_min=17, tm_sec=55, tm_wday=3, tm_yday=352, tm_isdst=0), 'published': '2020-12-17T12:17:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=17, tm_hour=12, tm_min=17, tm_sec=55, tm_wday=3, tm_yday=352, tm_isdst=0), 'title': 'Conspiracy Machines -- The Role of Social Bots during the COVID-19\n  Infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Conspiracy Machines -- The Role of Social Bots during the COVID-19\n  Infodemic'}, 'summary': 'The omnipresent COVID-19 pandemic gave rise to a parallel spreading of\nmisinformation, also referred to as an Infodemic. Consequently, social media\nhave become targets for the application of social bots, that is, algorithms\nthat mimic human behaviour. Their ability to exert influence on social media\ncan be exploited by amplifying misinformation, rumours, or conspiracy theories\nwhich might be harmful to society and the mastery of the pandemic. By applying\nsocial bot detection and content analysis techniques, this study aims to\ndetermine the extent to which social bots interfere with COVID- 19 discussions\non Twitter. A total of 78 presumptive bots were detected within a sample of\n542,345 users. The analysis revealed that bot-like users who disseminate\nmisinformation, at the same time, intersperse news from renowned sources. The\nfindings of this research provide implications for improved bot detection and\nmanaging potential threats through social bots during ongoing and future\ncrises.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The omnipresent COVID-19 pandemic gave rise to a parallel spreading of\nmisinformation, also referred to as an Infodemic. Consequently, social media\nhave become targets for the application of social bots, that is, algorithms\nthat mimic human behaviour. Their ability to exert influence on social media\ncan be exploited by amplifying misinformation, rumours, or conspiracy theories\nwhich might be harmful to society and the mastery of the pandemic. By applying\nsocial bot detection and content analysis techniques, this study aims to\ndetermine the extent to which social bots interfere with COVID- 19 discussions\non Twitter. A total of 78 presumptive bots were detected within a sample of\n542,345 users. The analysis revealed that bot-like users who disseminate\nmisinformation, at the same time, intersperse news from renowned sources. The\nfindings of this research provide implications for improved bot detection and\nmanaging potential threats through social bots during ongoing and future\ncrises.'}, 'authors': [{'name': 'Julian Marx'}, {'name': 'Felix Brünker'}, {'name': 'Milad Mirbabaie'}, {'name': 'Eric Hochstrate'}], 'author_detail': {'name': 'Eric Hochstrate'}, 'author': 'Eric Hochstrate', 'links': [{'href': 'http://arxiv.org/abs/2012.09536v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.09536v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
173,http://arxiv.org/abs/2012.09353v2,2021-04-03 00:22:38+00:00,2020-12-17 02:00:43+00:00,The COVID-19 Infodemic: Twitter versus Facebook,"[arxiv.Result.Author('Kai-Cheng Yang'), arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Pik-Mai Hui'), arxiv.Result.Author('David Axelrod'), arxiv.Result.Author('Christopher Torres-Lugo'), arxiv.Result.Author('John Bryden'), arxiv.Result.Author('Filippo Menczer')]","The global spread of the novel coronavirus is affected by the spread of
related misinformation -- the so-called COVID-19 Infodemic -- that makes
populations more vulnerable to the disease through resistance to mitigation
efforts. Here we analyze the prevalence and diffusion of links to
low-credibility content about the pandemic across two major social media
platforms, Twitter and Facebook. We characterize cross-platform similarities
and differences in popular sources, diffusion patterns, influencers,
coordination, and automation. Comparing the two platforms, we find divergence
among the prevalence of popular low-credibility sources and suspicious videos.
A minority of accounts and pages exert a strong influence on each platform.
These misinformation ""superspreaders"" are often associated with the
low-credibility sources and tend to be verified by the platforms. On both
platforms, there is evidence of coordinated sharing of Infodemic content. The
overt nature of this manipulation points to the need for societal-level
solutions in addition to mitigation strategies within the platforms. However,
we highlight limits imposed by inconsistent data-access policies on our
capability to study harmful manipulations of information ecosystems.","25 pages, 10 figures",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2012.09353v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.09353v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.09353v2,"{'id': 'http://arxiv.org/abs/2012.09353v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.09353v2', 'updated': '2021-04-03T00:22:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=3, tm_hour=0, tm_min=22, tm_sec=38, tm_wday=5, tm_yday=93, tm_isdst=0), 'published': '2020-12-17T02:00:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=17, tm_hour=2, tm_min=0, tm_sec=43, tm_wday=3, tm_yday=352, tm_isdst=0), 'title': 'The COVID-19 Infodemic: Twitter versus Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 Infodemic: Twitter versus Facebook'}, 'summary': 'The global spread of the novel coronavirus is affected by the spread of\nrelated misinformation -- the so-called COVID-19 Infodemic -- that makes\npopulations more vulnerable to the disease through resistance to mitigation\nefforts. Here we analyze the prevalence and diffusion of links to\nlow-credibility content about the pandemic across two major social media\nplatforms, Twitter and Facebook. We characterize cross-platform similarities\nand differences in popular sources, diffusion patterns, influencers,\ncoordination, and automation. Comparing the two platforms, we find divergence\namong the prevalence of popular low-credibility sources and suspicious videos.\nA minority of accounts and pages exert a strong influence on each platform.\nThese misinformation ""superspreaders"" are often associated with the\nlow-credibility sources and tend to be verified by the platforms. On both\nplatforms, there is evidence of coordinated sharing of Infodemic content. The\novert nature of this manipulation points to the need for societal-level\nsolutions in addition to mitigation strategies within the platforms. However,\nwe highlight limits imposed by inconsistent data-access policies on our\ncapability to study harmful manipulations of information ecosystems.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The global spread of the novel coronavirus is affected by the spread of\nrelated misinformation -- the so-called COVID-19 Infodemic -- that makes\npopulations more vulnerable to the disease through resistance to mitigation\nefforts. Here we analyze the prevalence and diffusion of links to\nlow-credibility content about the pandemic across two major social media\nplatforms, Twitter and Facebook. We characterize cross-platform similarities\nand differences in popular sources, diffusion patterns, influencers,\ncoordination, and automation. Comparing the two platforms, we find divergence\namong the prevalence of popular low-credibility sources and suspicious videos.\nA minority of accounts and pages exert a strong influence on each platform.\nThese misinformation ""superspreaders"" are often associated with the\nlow-credibility sources and tend to be verified by the platforms. On both\nplatforms, there is evidence of coordinated sharing of Infodemic content. The\novert nature of this manipulation points to the need for societal-level\nsolutions in addition to mitigation strategies within the platforms. However,\nwe highlight limits imposed by inconsistent data-access policies on our\ncapability to study harmful manipulations of information ecosystems.'}, 'authors': [{'name': 'Kai-Cheng Yang'}, {'name': 'Francesco Pierri'}, {'name': 'Pik-Mai Hui'}, {'name': 'David Axelrod'}, {'name': 'Christopher Torres-Lugo'}, {'name': 'John Bryden'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_comment': '25 pages, 10 figures', 'links': [{'href': 'http://arxiv.org/abs/2012.09353v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.09353v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
174,http://arxiv.org/abs/2012.08726v4,2021-03-30 23:51:15+00:00,2020-12-16 03:51:54+00:00,Responsible Disclosure of Generative Models Using Scalable Fingerprinting,"[arxiv.Result.Author('Ning Yu'), arxiv.Result.Author('Vladislav Skripniuk'), arxiv.Result.Author('Dingfan Chen'), arxiv.Result.Author('Larry Davis'), arxiv.Result.Author('Mario Fritz')]","Over the past six years, deep generative models have achieved a qualitatively
new level of performance. Generated data has become difficult, if not
impossible, to be distinguished from real data. While there are plenty of use
cases that benefit from this technology, there are also strong concerns on how
this new technology can be misused to spoof sensors, generate deep fakes, and
enable misinformation at scale. Unfortunately, current deep fake detection
methods are not sustainable, as the gap between real and fake continues to
close. In contrast, our work enables a responsible disclosure of such
state-of-the-art generative models, that allows researchers and companies to
fingerprint their models, so that the generated samples containing a
fingerprint can be accurately detected and attributed to a source. Our
technique achieves this by an efficient and scalable ad-hoc generation of a
large population of models with distinct fingerprints. Our recommended
operation point uses a 128-bit fingerprint which in principle results in more
than $10^{36}$ identifiable models. Experiments show that our method fulfills
key properties of a fingerprinting mechanism and achieves effectiveness in deep
fake detection and attribution.",,,,cs.CR,"['cs.CR', 'cs.CV', 'cs.CY', 'cs.GR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2012.08726v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.08726v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.08726v4,"{'id': 'http://arxiv.org/abs/2012.08726v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.08726v4', 'updated': '2021-03-30T23:51:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=30, tm_hour=23, tm_min=51, tm_sec=15, tm_wday=1, tm_yday=89, tm_isdst=0), 'published': '2020-12-16T03:51:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=16, tm_hour=3, tm_min=51, tm_sec=54, tm_wday=2, tm_yday=351, tm_isdst=0), 'title': 'Responsible Disclosure of Generative Models Using Scalable\n  Fingerprinting', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Responsible Disclosure of Generative Models Using Scalable\n  Fingerprinting'}, 'summary': 'Over the past six years, deep generative models have achieved a qualitatively\nnew level of performance. Generated data has become difficult, if not\nimpossible, to be distinguished from real data. While there are plenty of use\ncases that benefit from this technology, there are also strong concerns on how\nthis new technology can be misused to spoof sensors, generate deep fakes, and\nenable misinformation at scale. Unfortunately, current deep fake detection\nmethods are not sustainable, as the gap between real and fake continues to\nclose. In contrast, our work enables a responsible disclosure of such\nstate-of-the-art generative models, that allows researchers and companies to\nfingerprint their models, so that the generated samples containing a\nfingerprint can be accurately detected and attributed to a source. Our\ntechnique achieves this by an efficient and scalable ad-hoc generation of a\nlarge population of models with distinct fingerprints. Our recommended\noperation point uses a 128-bit fingerprint which in principle results in more\nthan $10^{36}$ identifiable models. Experiments show that our method fulfills\nkey properties of a fingerprinting mechanism and achieves effectiveness in deep\nfake detection and attribution.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past six years, deep generative models have achieved a qualitatively\nnew level of performance. Generated data has become difficult, if not\nimpossible, to be distinguished from real data. While there are plenty of use\ncases that benefit from this technology, there are also strong concerns on how\nthis new technology can be misused to spoof sensors, generate deep fakes, and\nenable misinformation at scale. Unfortunately, current deep fake detection\nmethods are not sustainable, as the gap between real and fake continues to\nclose. In contrast, our work enables a responsible disclosure of such\nstate-of-the-art generative models, that allows researchers and companies to\nfingerprint their models, so that the generated samples containing a\nfingerprint can be accurately detected and attributed to a source. Our\ntechnique achieves this by an efficient and scalable ad-hoc generation of a\nlarge population of models with distinct fingerprints. Our recommended\noperation point uses a 128-bit fingerprint which in principle results in more\nthan $10^{36}$ identifiable models. Experiments show that our method fulfills\nkey properties of a fingerprinting mechanism and achieves effectiveness in deep\nfake detection and attribution.'}, 'authors': [{'name': 'Ning Yu'}, {'name': 'Vladislav Skripniuk'}, {'name': 'Dingfan Chen'}, {'name': 'Larry Davis'}, {'name': 'Mario Fritz'}], 'author_detail': {'name': 'Mario Fritz'}, 'author': 'Mario Fritz', 'links': [{'href': 'http://arxiv.org/abs/2012.08726v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.08726v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
175,http://arxiv.org/abs/2012.07989v1,2020-12-14 22:40:49+00:00,2020-12-14 22:40:49+00:00,The Emerging Threats of Deepfake Attacks and Countermeasures,[arxiv.Result.Author('Shadrack Awah Buo')],"Deepfake technology (DT) has taken a new level of sophistication.
Cybercriminals now can manipulate sounds, images, and videos to defraud and
misinform individuals and businesses. This represents a growing threat to
international institutions and individuals which needs to be addressed. This
paper provides an overview of deepfakes, their benefits to society, and how DT
works. Highlights the threats that are presented by deepfakes to businesses,
politics, and judicial systems worldwide. Additionally, the paper will explore
potential solutions to deepfakes and conclude with future research direction.",5,,10.13140/RG.2.2.23089.81762,cs.CR,"['cs.CR', 'cs.AI']","[arxiv.Result.Link('http://dx.doi.org/10.13140/RG.2.2.23089.81762', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.07989v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.07989v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.07989v1,"{'id': 'http://arxiv.org/abs/2012.07989v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.07989v1', 'updated': '2020-12-14T22:40:49Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=14, tm_hour=22, tm_min=40, tm_sec=49, tm_wday=0, tm_yday=349, tm_isdst=0), 'published': '2020-12-14T22:40:49Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=14, tm_hour=22, tm_min=40, tm_sec=49, tm_wday=0, tm_yday=349, tm_isdst=0), 'title': 'The Emerging Threats of Deepfake Attacks and Countermeasures', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Emerging Threats of Deepfake Attacks and Countermeasures'}, 'summary': 'Deepfake technology (DT) has taken a new level of sophistication.\nCybercriminals now can manipulate sounds, images, and videos to defraud and\nmisinform individuals and businesses. This represents a growing threat to\ninternational institutions and individuals which needs to be addressed. This\npaper provides an overview of deepfakes, their benefits to society, and how DT\nworks. Highlights the threats that are presented by deepfakes to businesses,\npolitics, and judicial systems worldwide. Additionally, the paper will explore\npotential solutions to deepfakes and conclude with future research direction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deepfake technology (DT) has taken a new level of sophistication.\nCybercriminals now can manipulate sounds, images, and videos to defraud and\nmisinform individuals and businesses. This represents a growing threat to\ninternational institutions and individuals which needs to be addressed. This\npaper provides an overview of deepfakes, their benefits to society, and how DT\nworks. Highlights the threats that are presented by deepfakes to businesses,\npolitics, and judicial systems worldwide. Additionally, the paper will explore\npotential solutions to deepfakes and conclude with future research direction.'}, 'authors': [{'name': 'Shadrack Awah Buo'}], 'author_detail': {'name': 'Shadrack Awah Buo'}, 'author': 'Shadrack Awah Buo', 'arxiv_doi': '10.13140/RG.2.2.23089.81762', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.13140/RG.2.2.23089.81762', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.07989v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.07989v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '5', 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
176,http://arxiv.org/abs/2012.09110v3,2021-06-30 12:57:19+00:00,2020-12-14 18:54:05+00:00,"Developing Future Human-Centered Smart Cities: Critical Analysis of Smart City Security, Interpretability, and Ethical Challenges","[arxiv.Result.Author('Kashif Ahmad'), arxiv.Result.Author('Majdi Maabreh'), arxiv.Result.Author('Mohamed Ghaly'), arxiv.Result.Author('Khalil Khan'), arxiv.Result.Author('Junaid Qadir'), arxiv.Result.Author('Ala Al-Fuqaha')]","As we make tremendous advances in machine learning and artificial
intelligence technosciences, there is a renewed understanding in the AI
community that we must ensure that humans being are at the center of our
deliberations so that we don't end in technology-induced dystopias. As strongly
argued by Green in his book Smart Enough City, the incorporation of technology
in city environs does not automatically translate into prosperity, wellbeing,
urban livability, or social justice. There is a great need to deliberate on the
future of the cities worth living and designing. There are philosophical and
ethical questions involved along with various challenges that relate to the
security, safety, and interpretability of AI algorithms that will form the
technological bedrock of future cities. Several research institutes on human
centered AI have been established at top international universities. Globally
there are calls for technology to be made more humane and human-compatible. For
example, Stuart Russell has a book called Human Compatible AI. The Center for
Humane Technology advocates for regulators and technology companies to avoid
business models and product features that contribute to social problems such as
extremism, polarization, misinformation, and Internet addiction. In this paper,
we analyze and explore key challenges including security, robustness,
interpretability, and ethical challenges to a successful deployment of AI or ML
in human-centric applications, with a particular emphasis on the convergence of
these challenges. We provide a detailed review of existing literature on these
key challenges and analyze how one of these challenges may lead to others or
help in solving other challenges. The paper also advises on the current
limitations, pitfalls, and future directions of research in these domains, and
how it can fill the current gaps and lead to better solutions.","I withdraw this paper, as I uploaded it by mistake",,,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.09110v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.09110v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.09110v3,"{'id': 'http://arxiv.org/abs/2012.09110v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.09110v3', 'updated': '2021-06-30T12:57:19Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=30, tm_hour=12, tm_min=57, tm_sec=19, tm_wday=2, tm_yday=181, tm_isdst=0), 'published': '2020-12-14T18:54:05Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=14, tm_hour=18, tm_min=54, tm_sec=5, tm_wday=0, tm_yday=349, tm_isdst=0), 'title': 'Developing Future Human-Centered Smart Cities: Critical Analysis of\n  Smart City Security, Interpretability, and Ethical Challenges', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Developing Future Human-Centered Smart Cities: Critical Analysis of\n  Smart City Security, Interpretability, and Ethical Challenges'}, 'summary': ""As we make tremendous advances in machine learning and artificial\nintelligence technosciences, there is a renewed understanding in the AI\ncommunity that we must ensure that humans being are at the center of our\ndeliberations so that we don't end in technology-induced dystopias. As strongly\nargued by Green in his book Smart Enough City, the incorporation of technology\nin city environs does not automatically translate into prosperity, wellbeing,\nurban livability, or social justice. There is a great need to deliberate on the\nfuture of the cities worth living and designing. There are philosophical and\nethical questions involved along with various challenges that relate to the\nsecurity, safety, and interpretability of AI algorithms that will form the\ntechnological bedrock of future cities. Several research institutes on human\ncentered AI have been established at top international universities. Globally\nthere are calls for technology to be made more humane and human-compatible. For\nexample, Stuart Russell has a book called Human Compatible AI. The Center for\nHumane Technology advocates for regulators and technology companies to avoid\nbusiness models and product features that contribute to social problems such as\nextremism, polarization, misinformation, and Internet addiction. In this paper,\nwe analyze and explore key challenges including security, robustness,\ninterpretability, and ethical challenges to a successful deployment of AI or ML\nin human-centric applications, with a particular emphasis on the convergence of\nthese challenges. We provide a detailed review of existing literature on these\nkey challenges and analyze how one of these challenges may lead to others or\nhelp in solving other challenges. The paper also advises on the current\nlimitations, pitfalls, and future directions of research in these domains, and\nhow it can fill the current gaps and lead to better solutions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As we make tremendous advances in machine learning and artificial\nintelligence technosciences, there is a renewed understanding in the AI\ncommunity that we must ensure that humans being are at the center of our\ndeliberations so that we don't end in technology-induced dystopias. As strongly\nargued by Green in his book Smart Enough City, the incorporation of technology\nin city environs does not automatically translate into prosperity, wellbeing,\nurban livability, or social justice. There is a great need to deliberate on the\nfuture of the cities worth living and designing. There are philosophical and\nethical questions involved along with various challenges that relate to the\nsecurity, safety, and interpretability of AI algorithms that will form the\ntechnological bedrock of future cities. Several research institutes on human\ncentered AI have been established at top international universities. Globally\nthere are calls for technology to be made more humane and human-compatible. For\nexample, Stuart Russell has a book called Human Compatible AI. The Center for\nHumane Technology advocates for regulators and technology companies to avoid\nbusiness models and product features that contribute to social problems such as\nextremism, polarization, misinformation, and Internet addiction. In this paper,\nwe analyze and explore key challenges including security, robustness,\ninterpretability, and ethical challenges to a successful deployment of AI or ML\nin human-centric applications, with a particular emphasis on the convergence of\nthese challenges. We provide a detailed review of existing literature on these\nkey challenges and analyze how one of these challenges may lead to others or\nhelp in solving other challenges. The paper also advises on the current\nlimitations, pitfalls, and future directions of research in these domains, and\nhow it can fill the current gaps and lead to better solutions.""}, 'authors': [{'name': 'Kashif Ahmad'}, {'name': 'Majdi Maabreh'}, {'name': 'Mohamed Ghaly'}, {'name': 'Khalil Khan'}, {'name': 'Junaid Qadir'}, {'name': 'Ala Al-Fuqaha'}], 'author_detail': {'name': 'Ala Al-Fuqaha'}, 'author': 'Ala Al-Fuqaha', 'arxiv_comment': 'I withdraw this paper, as I uploaded it by mistake', 'links': [{'href': 'http://arxiv.org/abs/2012.09110v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.09110v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
177,http://arxiv.org/abs/2012.07729v2,2021-04-15 13:56:54+00:00,2020-12-14 17:24:59+00:00,"""Thought I'd Share First"" and Other Conspiracy Theory Tweets from the COVID-19 Infodemic: Exploratory Study","[arxiv.Result.Author('Dax Gerts'), arxiv.Result.Author('Courtney D. Shelley'), arxiv.Result.Author('Nidhi Parikh'), arxiv.Result.Author('Travis Pitts'), arxiv.Result.Author('Chrysm Watson Ross'), arxiv.Result.Author('Geoffrey Fairchild'), arxiv.Result.Author('Nidia Yadria Vaquera Chavez'), arxiv.Result.Author('Ashlynn R. Daughton')]","Background: The COVID-19 outbreak has left many people isolated within their
homes; these people are turning to social media for news and social connection,
which leaves them vulnerable to believing and sharing misinformation.
Health-related misinformation threatens adherence to public health messaging,
and monitoring its spread on social media is critical to understanding the
evolution of ideas that have potentially negative public health impacts.
Results: Analysis using model-labeled data was beneficial for increasing the
proportion of data matching misinformation indicators. Random forest classifier
metrics varied across the four conspiracy theories considered (F1 scores
between 0.347 and 0.857); this performance increased as the given conspiracy
theory was more narrowly defined. We showed that misinformation tweets
demonstrate more negative sentiment when compared to nonmisinformation tweets
and that theories evolve over time, incorporating details from unrelated
conspiracy theories as well as real-world events. Conclusions: Although we
focus here on health-related misinformation, this combination of approaches is
not specific to public health and is valuable for characterizing misinformation
in general, which is an important first step in creating targeted messaging to
counteract its spread. Initial messaging should aim to preempt generalized
misinformation before it becomes widespread, while later messaging will need to
target evolving conspiracy theories and the new facets of each as they become
incorporated.",,JMIR Pub Hlth Surv 2021 7(4),10.2196/26527,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.2196/26527', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.07729v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.07729v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.07729v2,"{'id': 'http://arxiv.org/abs/2012.07729v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.07729v2', 'updated': '2021-04-15T13:56:54Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=15, tm_hour=13, tm_min=56, tm_sec=54, tm_wday=3, tm_yday=105, tm_isdst=0), 'published': '2020-12-14T17:24:59Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=14, tm_hour=17, tm_min=24, tm_sec=59, tm_wday=0, tm_yday=349, tm_isdst=0), 'title': '""Thought I\'d Share First"" and Other Conspiracy Theory Tweets from the\n  COVID-19 Infodemic: Exploratory Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Thought I\'d Share First"" and Other Conspiracy Theory Tweets from the\n  COVID-19 Infodemic: Exploratory Study'}, 'summary': 'Background: The COVID-19 outbreak has left many people isolated within their\nhomes; these people are turning to social media for news and social connection,\nwhich leaves them vulnerable to believing and sharing misinformation.\nHealth-related misinformation threatens adherence to public health messaging,\nand monitoring its spread on social media is critical to understanding the\nevolution of ideas that have potentially negative public health impacts.\nResults: Analysis using model-labeled data was beneficial for increasing the\nproportion of data matching misinformation indicators. Random forest classifier\nmetrics varied across the four conspiracy theories considered (F1 scores\nbetween 0.347 and 0.857); this performance increased as the given conspiracy\ntheory was more narrowly defined. We showed that misinformation tweets\ndemonstrate more negative sentiment when compared to nonmisinformation tweets\nand that theories evolve over time, incorporating details from unrelated\nconspiracy theories as well as real-world events. Conclusions: Although we\nfocus here on health-related misinformation, this combination of approaches is\nnot specific to public health and is valuable for characterizing misinformation\nin general, which is an important first step in creating targeted messaging to\ncounteract its spread. Initial messaging should aim to preempt generalized\nmisinformation before it becomes widespread, while later messaging will need to\ntarget evolving conspiracy theories and the new facets of each as they become\nincorporated.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Background: The COVID-19 outbreak has left many people isolated within their\nhomes; these people are turning to social media for news and social connection,\nwhich leaves them vulnerable to believing and sharing misinformation.\nHealth-related misinformation threatens adherence to public health messaging,\nand monitoring its spread on social media is critical to understanding the\nevolution of ideas that have potentially negative public health impacts.\nResults: Analysis using model-labeled data was beneficial for increasing the\nproportion of data matching misinformation indicators. Random forest classifier\nmetrics varied across the four conspiracy theories considered (F1 scores\nbetween 0.347 and 0.857); this performance increased as the given conspiracy\ntheory was more narrowly defined. We showed that misinformation tweets\ndemonstrate more negative sentiment when compared to nonmisinformation tweets\nand that theories evolve over time, incorporating details from unrelated\nconspiracy theories as well as real-world events. Conclusions: Although we\nfocus here on health-related misinformation, this combination of approaches is\nnot specific to public health and is valuable for characterizing misinformation\nin general, which is an important first step in creating targeted messaging to\ncounteract its spread. Initial messaging should aim to preempt generalized\nmisinformation before it becomes widespread, while later messaging will need to\ntarget evolving conspiracy theories and the new facets of each as they become\nincorporated.'}, 'authors': [{'name': 'Dax Gerts'}, {'name': 'Courtney D. Shelley'}, {'name': 'Nidhi Parikh'}, {'name': 'Travis Pitts'}, {'name': 'Chrysm Watson Ross'}, {'name': 'Geoffrey Fairchild'}, {'name': 'Nidia Yadria Vaquera Chavez'}, {'name': 'Ashlynn R. Daughton'}], 'author_detail': {'name': 'Ashlynn R. Daughton'}, 'author': 'Ashlynn R. Daughton', 'arxiv_doi': '10.2196/26527', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.2196/26527', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.07729v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.07729v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'JMIR Pub Hlth Surv 2021 7(4)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
178,http://arxiv.org/abs/2012.02606v2,2020-12-07 02:59:24+00:00,2020-12-04 14:03:06+00:00,TrollHunter2020: Real-Time Detection of Trolling Narratives on Twitter During the 2020 US Elections,"[arxiv.Result.Author('Peter Jachim'), arxiv.Result.Author('Filipo Sharevski'), arxiv.Result.Author('Emma Pieroni')]","This paper presents TrollHunter2020, a real-time detection mechanism we used
to hunt for trolling narratives on Twitter during the 2020 U.S. elections.
Trolling narratives form on Twitter as alternative explanations of polarizing
events like the 2020 U.S. elections with the goal to conduct information
operations or provoke emotional response. Detecting trolling narratives thus is
an imperative step to preserve constructive discourse on Twitter and remove an
influx of misinformation. Using existing techniques, this takes time and a
wealth of data, which, in a rapidly changing election cycle with high stakes,
might not be available. To overcome this limitation, we developed
TrollHunter2020 to hunt for trolls in real-time with several dozens of trending
Twitter topics and hashtags corresponding to the candidates' debates, the
election night, and the election aftermath. TrollHunter2020 collects trending
data and utilizes a correspondence analysis to detect meaningful relationships
between the top nouns and verbs used in constructing trolling narratives while
they emerge on Twitter. Our results suggest that the TrollHunter2020 indeed
captures the emerging trolling narratives in a very early stage of an unfolding
polarizing event. We discuss the utility of TrollHunter2020 for early detection
of information operations or trolling and the implications of its use in
supporting a constrictive discourse on the platform around polarizing topics.",,,,cs.CR,"['cs.CR', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.02606v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.02606v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.02606v2,"{'id': 'http://arxiv.org/abs/2012.02606v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.02606v2', 'updated': '2020-12-07T02:59:24Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=7, tm_hour=2, tm_min=59, tm_sec=24, tm_wday=0, tm_yday=342, tm_isdst=0), 'published': '2020-12-04T14:03:06Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=4, tm_hour=14, tm_min=3, tm_sec=6, tm_wday=4, tm_yday=339, tm_isdst=0), 'title': 'TrollHunter2020: Real-Time Detection of Trolling Narratives on Twitter\n  During the 2020 US Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TrollHunter2020: Real-Time Detection of Trolling Narratives on Twitter\n  During the 2020 US Elections'}, 'summary': ""This paper presents TrollHunter2020, a real-time detection mechanism we used\nto hunt for trolling narratives on Twitter during the 2020 U.S. elections.\nTrolling narratives form on Twitter as alternative explanations of polarizing\nevents like the 2020 U.S. elections with the goal to conduct information\noperations or provoke emotional response. Detecting trolling narratives thus is\nan imperative step to preserve constructive discourse on Twitter and remove an\ninflux of misinformation. Using existing techniques, this takes time and a\nwealth of data, which, in a rapidly changing election cycle with high stakes,\nmight not be available. To overcome this limitation, we developed\nTrollHunter2020 to hunt for trolls in real-time with several dozens of trending\nTwitter topics and hashtags corresponding to the candidates' debates, the\nelection night, and the election aftermath. TrollHunter2020 collects trending\ndata and utilizes a correspondence analysis to detect meaningful relationships\nbetween the top nouns and verbs used in constructing trolling narratives while\nthey emerge on Twitter. Our results suggest that the TrollHunter2020 indeed\ncaptures the emerging trolling narratives in a very early stage of an unfolding\npolarizing event. We discuss the utility of TrollHunter2020 for early detection\nof information operations or trolling and the implications of its use in\nsupporting a constrictive discourse on the platform around polarizing topics."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper presents TrollHunter2020, a real-time detection mechanism we used\nto hunt for trolling narratives on Twitter during the 2020 U.S. elections.\nTrolling narratives form on Twitter as alternative explanations of polarizing\nevents like the 2020 U.S. elections with the goal to conduct information\noperations or provoke emotional response. Detecting trolling narratives thus is\nan imperative step to preserve constructive discourse on Twitter and remove an\ninflux of misinformation. Using existing techniques, this takes time and a\nwealth of data, which, in a rapidly changing election cycle with high stakes,\nmight not be available. To overcome this limitation, we developed\nTrollHunter2020 to hunt for trolls in real-time with several dozens of trending\nTwitter topics and hashtags corresponding to the candidates' debates, the\nelection night, and the election aftermath. TrollHunter2020 collects trending\ndata and utilizes a correspondence analysis to detect meaningful relationships\nbetween the top nouns and verbs used in constructing trolling narratives while\nthey emerge on Twitter. Our results suggest that the TrollHunter2020 indeed\ncaptures the emerging trolling narratives in a very early stage of an unfolding\npolarizing event. We discuss the utility of TrollHunter2020 for early detection\nof information operations or trolling and the implications of its use in\nsupporting a constrictive discourse on the platform around polarizing topics.""}, 'authors': [{'name': 'Peter Jachim'}, {'name': 'Filipo Sharevski'}, {'name': 'Emma Pieroni'}], 'author_detail': {'name': 'Emma Pieroni'}, 'author': 'Emma Pieroni', 'links': [{'href': 'http://arxiv.org/abs/2012.02606v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.02606v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
179,http://arxiv.org/abs/2012.02164v3,2021-09-09 15:55:04+00:00,2020-12-03 18:47:34+00:00,People Still Care About Facts: Twitter Users Engage More with Factual Discourse than Misinformation--A Comparison Between COVID and General Narratives on Twitter,"[arxiv.Result.Author('Mirela Silva'), arxiv.Result.Author('Fabrício Ceschin'), arxiv.Result.Author('Prakash Shrestha'), arxiv.Result.Author('Christopher Brant'), arxiv.Result.Author('Shlok Gilda'), arxiv.Result.Author('Juliana Fernandes'), arxiv.Result.Author('Catia S. Silva'), arxiv.Result.Author('André Grégio'), arxiv.Result.Author('Daniela Oliveira'), arxiv.Result.Author('Luiz Giovanini')]","Misinformation entails the dissemination of falsehoods that leads to the slow
fracturing of society via decreased trust in democratic processes,
institutions, and science. The public has grown aware of the role of social
media as a superspreader of untrustworthy information, where even pandemics
have not been immune. In this paper, we focus on COVID-19 misinformation and
examine a subset of 2.1M tweets to understand misinformation as a function of
engagement, tweet content (COVID-19- vs. non-COVID-19-related), and veracity
(misleading or factual). Using correlation analysis, we show the most relevant
feature subsets among over 126 features that most heavily correlate with
misinformation or facts. We found that (i) factual tweets, regardless of
whether COVID-related, were more engaging than misinformation tweets; and (ii)
features that most heavily correlated with engagement varied depending on the
veracity and content of the tweet.",22 pages,,,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2012.02164v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.02164v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.02164v3,"{'id': 'http://arxiv.org/abs/2012.02164v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.02164v3', 'updated': '2021-09-09T15:55:04Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=9, tm_hour=15, tm_min=55, tm_sec=4, tm_wday=3, tm_yday=252, tm_isdst=0), 'published': '2020-12-03T18:47:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=3, tm_hour=18, tm_min=47, tm_sec=34, tm_wday=3, tm_yday=338, tm_isdst=0), 'title': 'People Still Care About Facts: Twitter Users Engage More with Factual\n  Discourse than Misinformation--A Comparison Between COVID and General\n  Narratives on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'People Still Care About Facts: Twitter Users Engage More with Factual\n  Discourse than Misinformation--A Comparison Between COVID and General\n  Narratives on Twitter'}, 'summary': 'Misinformation entails the dissemination of falsehoods that leads to the slow\nfracturing of society via decreased trust in democratic processes,\ninstitutions, and science. The public has grown aware of the role of social\nmedia as a superspreader of untrustworthy information, where even pandemics\nhave not been immune. In this paper, we focus on COVID-19 misinformation and\nexamine a subset of 2.1M tweets to understand misinformation as a function of\nengagement, tweet content (COVID-19- vs. non-COVID-19-related), and veracity\n(misleading or factual). Using correlation analysis, we show the most relevant\nfeature subsets among over 126 features that most heavily correlate with\nmisinformation or facts. We found that (i) factual tweets, regardless of\nwhether COVID-related, were more engaging than misinformation tweets; and (ii)\nfeatures that most heavily correlated with engagement varied depending on the\nveracity and content of the tweet.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation entails the dissemination of falsehoods that leads to the slow\nfracturing of society via decreased trust in democratic processes,\ninstitutions, and science. The public has grown aware of the role of social\nmedia as a superspreader of untrustworthy information, where even pandemics\nhave not been immune. In this paper, we focus on COVID-19 misinformation and\nexamine a subset of 2.1M tweets to understand misinformation as a function of\nengagement, tweet content (COVID-19- vs. non-COVID-19-related), and veracity\n(misleading or factual). Using correlation analysis, we show the most relevant\nfeature subsets among over 126 features that most heavily correlate with\nmisinformation or facts. We found that (i) factual tweets, regardless of\nwhether COVID-related, were more engaging than misinformation tweets; and (ii)\nfeatures that most heavily correlated with engagement varied depending on the\nveracity and content of the tweet.'}, 'authors': [{'name': 'Mirela Silva'}, {'name': 'Fabrício Ceschin'}, {'name': 'Prakash Shrestha'}, {'name': 'Christopher Brant'}, {'name': 'Shlok Gilda'}, {'name': 'Juliana Fernandes'}, {'name': 'Catia S. Silva'}, {'name': 'André Grégio'}, {'name': 'Daniela Oliveira'}, {'name': 'Luiz Giovanini'}], 'author_detail': {'name': 'Luiz Giovanini'}, 'author': 'Luiz Giovanini', 'arxiv_comment': '22 pages', 'links': [{'href': 'http://arxiv.org/abs/2012.02164v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.02164v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
180,http://arxiv.org/abs/2012.01876v1,2020-12-03 12:45:29+00:00,2020-12-03 12:45:29+00:00,Optimizing sensors placement in complex networks for localization of hidden signal source: A review,"[arxiv.Result.Author('Robert Paluch'), arxiv.Result.Author('Łukasz G. Gajewski'), arxiv.Result.Author('Janusz A. Hołyst'), arxiv.Result.Author('Boleslaw K. Szymanski')]","As the world becomes more and more interconnected, our everyday objects
become part of the Internet of Things, and our lives get more and more mirrored
in virtual reality, where every piece of~information, including misinformation,
fake news and malware, can spread very fast practically anonymously. To
suppress such uncontrolled spread, efficient computer systems and algorithms
capable to~track down such malicious information spread have to be developed.
Currently, the most effective methods for source localization are based on
sensors which provide the times at which they detect the~spread. We investigate
the problem of the optimal placement of such sensors in complex networks and
propose a new graph measure, called Collective Betweenness, which we compare
against four other metrics. Extensive numerical tests are performed on
different types of complex networks over the wide ranges of densities of
sensors and stochasticities of signal. In these tests, we discovered clear
difference in comparative performance of the investigated optimal placement
methods between real or scale-free synthetic networks versus narrow degree
distribution networks. The former have a clear region for any given method's
dominance in contrast to the latter where the performance maps are less
homogeneous. We find that while choosing the best method is very network and
spread dependent, there are two methods that consistently stand out. High
Variance Observers seem to do very well for spread with low stochasticity
whereas Collective Betwenness, introduced in this paper, thrives when the
spread is highly unpredictable.","28 pages, 18 figures, 11 tables","Future Generation Computer Systems, Volume 112, November 2020,
  Pages 1070-1092",10.1016/j.future.2020.06.023,cs.SI,"['cs.SI', 'cs.CY', 'physics.data-an']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.future.2020.06.023', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2012.01876v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.01876v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.01876v1,"{'id': 'http://arxiv.org/abs/2012.01876v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.01876v1', 'updated': '2020-12-03T12:45:29Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=3, tm_hour=12, tm_min=45, tm_sec=29, tm_wday=3, tm_yday=338, tm_isdst=0), 'published': '2020-12-03T12:45:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=3, tm_hour=12, tm_min=45, tm_sec=29, tm_wday=3, tm_yday=338, tm_isdst=0), 'title': 'Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review'}, 'summary': ""As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.""}, 'authors': [{'name': 'Robert Paluch'}, {'name': 'Łukasz G. Gajewski'}, {'name': 'Janusz A. Hołyst'}, {'name': 'Boleslaw K. Szymanski'}], 'author_detail': {'name': 'Boleslaw K. Szymanski'}, 'author': 'Boleslaw K. Szymanski', 'arxiv_doi': '10.1016/j.future.2020.06.023', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.future.2020.06.023', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2012.01876v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.01876v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '28 pages, 18 figures, 11 tables', 'arxiv_journal_ref': 'Future Generation Computer Systems, Volume 112, November 2020,\n  Pages 1070-1092', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
181,http://arxiv.org/abs/2012.01462v3,2021-03-01 12:24:15+00:00,2020-12-02 19:05:25+00:00,ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus (COVID-19) Pandemic,"[arxiv.Result.Author('Hamdy Mubarak'), arxiv.Result.Author('Sabit Hassan')]","Over the past few months, there were huge numbers of circulating tweets and
discussions about Coronavirus (COVID-19) in the Arab region. It is important
for policy makers and many people to identify types of shared tweets to better
understand public behavior, topics of interest, requests from governments,
sources of tweets, etc. It is also crucial to prevent spreading of rumors and
misinformation about the virus or bad cures. To this end, we present the
largest manually annotated dataset of Arabic tweets related to COVID-19. We
describe annotation guidelines, analyze our dataset and build effective machine
learning and transformer based models for classification.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.01462v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.01462v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.01462v3,"{'id': 'http://arxiv.org/abs/2012.01462v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.01462v3', 'updated': '2021-03-01T12:24:15Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=12, tm_min=24, tm_sec=15, tm_wday=0, tm_yday=60, tm_isdst=0), 'published': '2020-12-02T19:05:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=2, tm_hour=19, tm_min=5, tm_sec=25, tm_wday=2, tm_yday=337, tm_isdst=0), 'title': 'ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus\n  (COVID-19) Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus\n  (COVID-19) Pandemic'}, 'summary': 'Over the past few months, there were huge numbers of circulating tweets and\ndiscussions about Coronavirus (COVID-19) in the Arab region. It is important\nfor policy makers and many people to identify types of shared tweets to better\nunderstand public behavior, topics of interest, requests from governments,\nsources of tweets, etc. It is also crucial to prevent spreading of rumors and\nmisinformation about the virus or bad cures. To this end, we present the\nlargest manually annotated dataset of Arabic tweets related to COVID-19. We\ndescribe annotation guidelines, analyze our dataset and build effective machine\nlearning and transformer based models for classification.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past few months, there were huge numbers of circulating tweets and\ndiscussions about Coronavirus (COVID-19) in the Arab region. It is important\nfor policy makers and many people to identify types of shared tweets to better\nunderstand public behavior, topics of interest, requests from governments,\nsources of tweets, etc. It is also crucial to prevent spreading of rumors and\nmisinformation about the virus or bad cures. To this end, we present the\nlargest manually annotated dataset of Arabic tweets related to COVID-19. We\ndescribe annotation guidelines, analyze our dataset and build effective machine\nlearning and transformer based models for classification.'}, 'authors': [{'name': 'Hamdy Mubarak'}, {'name': 'Sabit Hassan'}], 'author_detail': {'name': 'Sabit Hassan'}, 'author': 'Sabit Hassan', 'links': [{'href': 'http://arxiv.org/abs/2012.01462v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.01462v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
182,http://arxiv.org/abs/2012.00614v2,2021-01-02 16:07:48+00:00,2020-12-01 16:32:54+00:00,CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims,"[arxiv.Result.Author('Thomas Diggelmann'), arxiv.Result.Author('Jordan Boyd-Graber'), arxiv.Result.Author('Jannis Bulian'), arxiv.Result.Author('Massimiliano Ciaramita'), arxiv.Result.Author('Markus Leippold')]","We introduce CLIMATE-FEVER, a new publicly available dataset for verification
of climate change-related claims. By providing a dataset for the research
community, we aim to facilitate and encourage work on improving algorithms for
retrieving evidential support for climate-specific claims, addressing the
underlying language understanding challenges, and ultimately help alleviate the
impact of misinformation on climate change. We adapt the methodology of FEVER
[1], the largest dataset of artificially designed claims, to real-life claims
collected from the Internet. While during this process, we could rely on the
expertise of renowned climate scientists, it turned out to be no easy task. We
discuss the surprising, subtle complexity of modeling real-world
climate-related claims within the \textsc{fever} framework, which we believe
provides a valuable challenge for general natural language understanding. We
hope that our work will mark the beginning of a new exciting long-term joint
effort by the climate science and AI community.","Accepted for the Tackling Climate Change with Machine Learning
  Workshop at NeurIPS 2020",,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2012.00614v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.00614v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.00614v2,"{'id': 'http://arxiv.org/abs/2012.00614v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.00614v2', 'updated': '2021-01-02T16:07:48Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=2, tm_hour=16, tm_min=7, tm_sec=48, tm_wday=5, tm_yday=2, tm_isdst=0), 'published': '2020-12-01T16:32:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=1, tm_hour=16, tm_min=32, tm_sec=54, tm_wday=1, tm_yday=336, tm_isdst=0), 'title': 'CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims'}, 'summary': 'We introduce CLIMATE-FEVER, a new publicly available dataset for verification\nof climate change-related claims. By providing a dataset for the research\ncommunity, we aim to facilitate and encourage work on improving algorithms for\nretrieving evidential support for climate-specific claims, addressing the\nunderlying language understanding challenges, and ultimately help alleviate the\nimpact of misinformation on climate change. We adapt the methodology of FEVER\n[1], the largest dataset of artificially designed claims, to real-life claims\ncollected from the Internet. While during this process, we could rely on the\nexpertise of renowned climate scientists, it turned out to be no easy task. We\ndiscuss the surprising, subtle complexity of modeling real-world\nclimate-related claims within the \\textsc{fever} framework, which we believe\nprovides a valuable challenge for general natural language understanding. We\nhope that our work will mark the beginning of a new exciting long-term joint\neffort by the climate science and AI community.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We introduce CLIMATE-FEVER, a new publicly available dataset for verification\nof climate change-related claims. By providing a dataset for the research\ncommunity, we aim to facilitate and encourage work on improving algorithms for\nretrieving evidential support for climate-specific claims, addressing the\nunderlying language understanding challenges, and ultimately help alleviate the\nimpact of misinformation on climate change. We adapt the methodology of FEVER\n[1], the largest dataset of artificially designed claims, to real-life claims\ncollected from the Internet. While during this process, we could rely on the\nexpertise of renowned climate scientists, it turned out to be no easy task. We\ndiscuss the surprising, subtle complexity of modeling real-world\nclimate-related claims within the \\textsc{fever} framework, which we believe\nprovides a valuable challenge for general natural language understanding. We\nhope that our work will mark the beginning of a new exciting long-term joint\neffort by the climate science and AI community.'}, 'authors': [{'name': 'Thomas Diggelmann'}, {'name': 'Jordan Boyd-Graber'}, {'name': 'Jannis Bulian'}, {'name': 'Massimiliano Ciaramita'}, {'name': 'Markus Leippold'}], 'author_detail': {'name': 'Markus Leippold'}, 'author': 'Markus Leippold', 'arxiv_comment': 'Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020', 'links': [{'href': 'http://arxiv.org/abs/2012.00614v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.00614v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
183,http://arxiv.org/abs/2012.07517v1,2020-11-30 16:41:04+00:00,2020-11-30 16:41:04+00:00,Fake News Detection in Social Media using Graph Neural Networks and NLP Techniques: A COVID-19 Use-case,"[arxiv.Result.Author('Abdullah Hamid'), arxiv.Result.Author('Nasrullah Shiekh'), arxiv.Result.Author('Naina Said'), arxiv.Result.Author('Kashif Ahmad'), arxiv.Result.Author('Asma Gul'), arxiv.Result.Author('Laiq Hassan'), arxiv.Result.Author('Ala Al-Fuqaha')]","The paper presents our solutions for the MediaEval 2020 task namely FakeNews:
Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task
aims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect
misinformation spreaders. The task is composed of two sub-tasks namely (i)
text-based, and (ii) structure-based fake news detection. For the first task,
we propose six different solutions relying on Bag of Words (BoW) and BERT
embedding. Three of the methods aim at binary classification task by
differentiating in 5G conspiracy and the rest of the COVID-19 related tweets
while the rest of them treat the task as ternary classification problem. In the
ternary classification task, our BoW and BERT based methods obtained an
F1-score of .606% and .566% on the development set, respectively. On the binary
classification, the BoW and BERT based solutions obtained an average F1-score
of .666% and .693%, respectively. On the other hand, for structure-based fake
news detection, we rely on Graph Neural Networks (GNNs) achieving an average
ROC of .95% on the development set.",3 pages,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2012.07517v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2012.07517v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2012.07517v1,"{'id': 'http://arxiv.org/abs/2012.07517v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2012.07517v1', 'updated': '2020-11-30T16:41:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=30, tm_hour=16, tm_min=41, tm_sec=4, tm_wday=0, tm_yday=335, tm_isdst=0), 'published': '2020-11-30T16:41:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=30, tm_hour=16, tm_min=41, tm_sec=4, tm_wday=0, tm_yday=335, tm_isdst=0), 'title': 'Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case'}, 'summary': 'The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.'}, 'authors': [{'name': 'Abdullah Hamid'}, {'name': 'Nasrullah Shiekh'}, {'name': 'Naina Said'}, {'name': 'Kashif Ahmad'}, {'name': 'Asma Gul'}, {'name': 'Laiq Hassan'}, {'name': 'Ala Al-Fuqaha'}], 'author_detail': {'name': 'Ala Al-Fuqaha'}, 'author': 'Ala Al-Fuqaha', 'arxiv_comment': '3 pages', 'links': [{'href': 'http://arxiv.org/abs/2012.07517v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2012.07517v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
184,http://arxiv.org/abs/2011.14146v2,2021-02-15 02:26:25+00:00,2020-11-28 15:30:14+00:00,Towards Combating Pandemic-related Misinformation in Social Media,[arxiv.Result.Author('Isa Inuwa-Dutse')],"Conventional preventive measures during pandemic include social distancing
and lockdown. Such measures in the time of social media brought about a new set
of challenges - vulnerability to the toxic impact of online misinformation is
high. A case in point is the prevailing COVID-19; as the virus propagates, so
does the associated misinformation and fake news about it leading to infodemic.
Since the outbreak, there has been a surge of studies investigating various
aspects of the pandemic. Of interest to this chapter include studies centring
on datasets from online social media platforms where the bulk of the public
discourse happen. Consequently, the main goal is to support the fight against
negative infodemic by (1) contributing a diverse set of curated relevant
datasets (2) recommending relevant areas to study using the datasets (3)
discussion on how relevant datasets, strategies and state-of-the-art IT tools
can be leveraged in managing the pandemic.","13 pages, 5 figures",,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2011.14146v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.14146v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.14146v2,"{'id': 'http://arxiv.org/abs/2011.14146v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.14146v2', 'updated': '2021-02-15T02:26:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=26, tm_sec=25, tm_wday=0, tm_yday=46, tm_isdst=0), 'published': '2020-11-28T15:30:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=28, tm_hour=15, tm_min=30, tm_sec=14, tm_wday=5, tm_yday=333, tm_isdst=0), 'title': 'Towards Combating Pandemic-related Misinformation in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Combating Pandemic-related Misinformation in Social Media'}, 'summary': 'Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.'}, 'authors': [{'name': 'Isa Inuwa-Dutse'}], 'author_detail': {'name': 'Isa Inuwa-Dutse'}, 'author': 'Isa Inuwa-Dutse', 'arxiv_comment': '13 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2011.14146v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.14146v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
185,http://arxiv.org/abs/2011.13253v1,2020-11-26 11:50:45+00:00,2020-11-26 11:50:45+00:00,Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking,"[arxiv.Result.Author('Rutvik Vijjali'), arxiv.Result.Author('Prathyush Potluri'), arxiv.Result.Author('Siddharth Kumar'), arxiv.Result.Author('Sundeep Teki')]","The rapid advancement of technology in online communication via social media
platforms has led to a prolific rise in the spread of misinformation and fake
news. Fake news is especially rampant in the current COVID-19 pandemic, leading
to people believing in false and potentially harmful claims and stories.
Detecting fake news quickly can alleviate the spread of panic, chaos and
potential health hazards. We developed a two stage automated pipeline for
COVID-19 fake news detection using state of the art machine learning models for
natural language processing. The first model leverages a novel fact checking
algorithm that retrieves the most relevant facts concerning user claims about
particular COVID-19 claims. The second model verifies the level of truth in the
claim by computing the textual entailment between the claim and the true facts
retrieved from a manually curated COVID-19 dataset. The dataset is based on a
publicly available knowledge source consisting of more than 5000 COVID-19 false
claims and verified explanations, a subset of which was internally annotated
and cross-validated to train and evaluate our models. We evaluate a series of
models based on classical text-based features to more contextual Transformer
based models and observe that a model pipeline based on BERT and ALBERT for the
two stages respectively yields the best results.",,,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2011.13253v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.13253v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.13253v1,"{'id': 'http://arxiv.org/abs/2011.13253v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.13253v1', 'updated': '2020-11-26T11:50:45Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=26, tm_hour=11, tm_min=50, tm_sec=45, tm_wday=3, tm_yday=331, tm_isdst=0), 'published': '2020-11-26T11:50:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=26, tm_hour=11, tm_min=50, tm_sec=45, tm_wday=3, tm_yday=331, tm_isdst=0), 'title': 'Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking'}, 'summary': 'The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.'}, 'authors': [{'name': 'Rutvik Vijjali'}, {'name': 'Prathyush Potluri'}, {'name': 'Siddharth Kumar'}, {'name': 'Sundeep Teki'}], 'author_detail': {'name': 'Sundeep Teki'}, 'author': 'Sundeep Teki', 'links': [{'href': 'http://arxiv.org/abs/2011.13253v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.13253v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
186,http://arxiv.org/abs/2011.12758v2,2020-12-15 01:13:08+00:00,2020-11-25 14:22:36+00:00,Encounters with Visual Misinformation and Labels Across Platforms: An Interview and Diary Study to Inform Ecosystem Approaches to Misinformation Interventions,"[arxiv.Result.Author('Emily Saltz'), arxiv.Result.Author('Claire Leibowicz'), arxiv.Result.Author('Claire Wardle')]","Since 2016, the amount of academic research with the keyword ""misinformation""
has more than doubled [2]. This research often focuses on article headlines
shown in artificial testing environments, yet misinformation largely spreads
through images and video posts shared in highly-personalized platform contexts.
A foundation of qualitative research is necessary to begin filling this gap to
ensure platforms' visual misinformation interventions are aligned with users'
needs and understanding of information in their personal contexts, across
platforms. In two studies, we combined in-depth interviews (n=15) with diary
and co-design methods (n=23) to investigate how a broad mix of Americans
exposed to misinformation during COVID-19 understand their visual information
environments, including encounters with interventions such as Facebook
fact-checking labels. Analysis reveals a deep division in user attitudes about
platform labeling interventions for visual information which are perceived by
many as overly paternalistic, biased, and punitive. Alongside these findings,
we discuss our methods as a model for continued independent qualitative
research on cross-platform user experiences of misinformation that inform
interventions.",,,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.12758v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.12758v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.12758v2,"{'id': 'http://arxiv.org/abs/2011.12758v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.12758v2', 'updated': '2020-12-15T01:13:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=1, tm_min=13, tm_sec=8, tm_wday=1, tm_yday=350, tm_isdst=0), 'published': '2020-11-25T14:22:36Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=25, tm_hour=14, tm_min=22, tm_sec=36, tm_wday=2, tm_yday=330, tm_isdst=0), 'title': 'Encounters with Visual Misinformation and Labels Across Platforms: An\n  Interview and Diary Study to Inform Ecosystem Approaches to Misinformation\n  Interventions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Encounters with Visual Misinformation and Labels Across Platforms: An\n  Interview and Diary Study to Inform Ecosystem Approaches to Misinformation\n  Interventions'}, 'summary': 'Since 2016, the amount of academic research with the keyword ""misinformation""\nhas more than doubled [2]. This research often focuses on article headlines\nshown in artificial testing environments, yet misinformation largely spreads\nthrough images and video posts shared in highly-personalized platform contexts.\nA foundation of qualitative research is necessary to begin filling this gap to\nensure platforms\' visual misinformation interventions are aligned with users\'\nneeds and understanding of information in their personal contexts, across\nplatforms. In two studies, we combined in-depth interviews (n=15) with diary\nand co-design methods (n=23) to investigate how a broad mix of Americans\nexposed to misinformation during COVID-19 understand their visual information\nenvironments, including encounters with interventions such as Facebook\nfact-checking labels. Analysis reveals a deep division in user attitudes about\nplatform labeling interventions for visual information which are perceived by\nmany as overly paternalistic, biased, and punitive. Alongside these findings,\nwe discuss our methods as a model for continued independent qualitative\nresearch on cross-platform user experiences of misinformation that inform\ninterventions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Since 2016, the amount of academic research with the keyword ""misinformation""\nhas more than doubled [2]. This research often focuses on article headlines\nshown in artificial testing environments, yet misinformation largely spreads\nthrough images and video posts shared in highly-personalized platform contexts.\nA foundation of qualitative research is necessary to begin filling this gap to\nensure platforms\' visual misinformation interventions are aligned with users\'\nneeds and understanding of information in their personal contexts, across\nplatforms. In two studies, we combined in-depth interviews (n=15) with diary\nand co-design methods (n=23) to investigate how a broad mix of Americans\nexposed to misinformation during COVID-19 understand their visual information\nenvironments, including encounters with interventions such as Facebook\nfact-checking labels. Analysis reveals a deep division in user attitudes about\nplatform labeling interventions for visual information which are perceived by\nmany as overly paternalistic, biased, and punitive. Alongside these findings,\nwe discuss our methods as a model for continued independent qualitative\nresearch on cross-platform user experiences of misinformation that inform\ninterventions.'}, 'authors': [{'name': 'Emily Saltz'}, {'name': 'Claire Leibowicz'}, {'name': 'Claire Wardle'}], 'author_detail': {'name': 'Claire Wardle'}, 'author': 'Claire Wardle', 'links': [{'href': 'http://arxiv.org/abs/2011.12758v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.12758v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
187,http://arxiv.org/abs/2011.09957v1,2020-11-19 16:53:38+00:00,2020-11-19 16:53:38+00:00,Adversarial Threats to DeepFake Detection: A Practical Perspective,"[arxiv.Result.Author('Paarth Neekhara'), arxiv.Result.Author('Brian Dolhansky'), arxiv.Result.Author('Joanna Bitton'), arxiv.Result.Author('Cristian Canton Ferrer')]","Facially manipulated images and videos or DeepFakes can be used maliciously
to fuel misinformation or defame individuals. Therefore, detecting DeepFakes is
crucial to increase the credibility of social media platforms and other media
sharing web sites. State-of-the art DeepFake detection techniques rely on
neural network based classification models which are known to be vulnerable to
adversarial examples. In this work, we study the vulnerabilities of
state-of-the-art DeepFake detection methods from a practical stand point. We
perform adversarial attacks on DeepFake detectors in a black box setting where
the adversary does not have complete knowledge of the classification models. We
study the extent to which adversarial perturbations transfer across different
models and propose techniques to improve the transferability of adversarial
examples. We also create more accessible attacks using Universal Adversarial
Perturbations which pose a very feasible attack scenario since they can be
easily shared amongst attackers. We perform our evaluations on the winning
entries of the DeepFake Detection Challenge (DFDC) and demonstrate that they
can be easily bypassed in a practical attack scenario by designing transferable
and accessible adversarial attacks.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.09957v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.09957v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.09957v1,"{'id': 'http://arxiv.org/abs/2011.09957v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.09957v1', 'updated': '2020-11-19T16:53:38Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=19, tm_hour=16, tm_min=53, tm_sec=38, tm_wday=3, tm_yday=324, tm_isdst=0), 'published': '2020-11-19T16:53:38Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=19, tm_hour=16, tm_min=53, tm_sec=38, tm_wday=3, tm_yday=324, tm_isdst=0), 'title': 'Adversarial Threats to DeepFake Detection: A Practical Perspective', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Adversarial Threats to DeepFake Detection: A Practical Perspective'}, 'summary': 'Facially manipulated images and videos or DeepFakes can be used maliciously\nto fuel misinformation or defame individuals. Therefore, detecting DeepFakes is\ncrucial to increase the credibility of social media platforms and other media\nsharing web sites. State-of-the art DeepFake detection techniques rely on\nneural network based classification models which are known to be vulnerable to\nadversarial examples. In this work, we study the vulnerabilities of\nstate-of-the-art DeepFake detection methods from a practical stand point. We\nperform adversarial attacks on DeepFake detectors in a black box setting where\nthe adversary does not have complete knowledge of the classification models. We\nstudy the extent to which adversarial perturbations transfer across different\nmodels and propose techniques to improve the transferability of adversarial\nexamples. We also create more accessible attacks using Universal Adversarial\nPerturbations which pose a very feasible attack scenario since they can be\neasily shared amongst attackers. We perform our evaluations on the winning\nentries of the DeepFake Detection Challenge (DFDC) and demonstrate that they\ncan be easily bypassed in a practical attack scenario by designing transferable\nand accessible adversarial attacks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Facially manipulated images and videos or DeepFakes can be used maliciously\nto fuel misinformation or defame individuals. Therefore, detecting DeepFakes is\ncrucial to increase the credibility of social media platforms and other media\nsharing web sites. State-of-the art DeepFake detection techniques rely on\nneural network based classification models which are known to be vulnerable to\nadversarial examples. In this work, we study the vulnerabilities of\nstate-of-the-art DeepFake detection methods from a practical stand point. We\nperform adversarial attacks on DeepFake detectors in a black box setting where\nthe adversary does not have complete knowledge of the classification models. We\nstudy the extent to which adversarial perturbations transfer across different\nmodels and propose techniques to improve the transferability of adversarial\nexamples. We also create more accessible attacks using Universal Adversarial\nPerturbations which pose a very feasible attack scenario since they can be\neasily shared amongst attackers. We perform our evaluations on the winning\nentries of the DeepFake Detection Challenge (DFDC) and demonstrate that they\ncan be easily bypassed in a practical attack scenario by designing transferable\nand accessible adversarial attacks.'}, 'authors': [{'name': 'Paarth Neekhara'}, {'name': 'Brian Dolhansky'}, {'name': 'Joanna Bitton'}, {'name': 'Cristian Canton Ferrer'}], 'author_detail': {'name': 'Cristian Canton Ferrer'}, 'author': 'Cristian Canton Ferrer', 'links': [{'href': 'http://arxiv.org/abs/2011.09957v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.09957v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
188,http://arxiv.org/abs/2011.09145v2,2020-11-19 05:45:58+00:00,2020-11-18 07:56:24+00:00,A First Look at COVID-19 Messages on WhatsApp in Pakistan,"[arxiv.Result.Author('R. Tallal Javed'), arxiv.Result.Author('Mirza Elaaf Shuja'), arxiv.Result.Author('Muhammad Usama'), arxiv.Result.Author('Junaid Qadir'), arxiv.Result.Author('Waleed Iqbal'), arxiv.Result.Author('Gareth Tyson'), arxiv.Result.Author('Ignacio Castro'), arxiv.Result.Author('Kiran Garimella')]","The worldwide spread of COVID-19 has prompted extensive online discussions,
creating an `infodemic' on social media platforms such as WhatsApp and Twitter.
However, the information shared on these platforms is prone to be unreliable
and/or misleading. In this paper, we present the first analysis of COVID-19
discourse on public WhatsApp groups from Pakistan. Building on a large scale
annotation of thousands of messages containing text and images, we identify the
main categories of discussion. We focus on COVID-19 messages and understand the
different types of images/text messages being propagated. By exploring user
behavior related to COVID messages, we inspect how misinformation is spread.
Finally, by quantifying the flow of information across WhatsApp and Twitter, we
show how information spreads across platforms and how WhatsApp acts as a source
for much of the information shared on Twitter.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2011.09145v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.09145v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.09145v2,"{'id': 'http://arxiv.org/abs/2011.09145v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.09145v2', 'updated': '2020-11-19T05:45:58Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=19, tm_hour=5, tm_min=45, tm_sec=58, tm_wday=3, tm_yday=324, tm_isdst=0), 'published': '2020-11-18T07:56:24Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=18, tm_hour=7, tm_min=56, tm_sec=24, tm_wday=2, tm_yday=323, tm_isdst=0), 'title': 'A First Look at COVID-19 Messages on WhatsApp in Pakistan', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A First Look at COVID-19 Messages on WhatsApp in Pakistan'}, 'summary': ""The worldwide spread of COVID-19 has prompted extensive online discussions,\ncreating an `infodemic' on social media platforms such as WhatsApp and Twitter.\nHowever, the information shared on these platforms is prone to be unreliable\nand/or misleading. In this paper, we present the first analysis of COVID-19\ndiscourse on public WhatsApp groups from Pakistan. Building on a large scale\nannotation of thousands of messages containing text and images, we identify the\nmain categories of discussion. We focus on COVID-19 messages and understand the\ndifferent types of images/text messages being propagated. By exploring user\nbehavior related to COVID messages, we inspect how misinformation is spread.\nFinally, by quantifying the flow of information across WhatsApp and Twitter, we\nshow how information spreads across platforms and how WhatsApp acts as a source\nfor much of the information shared on Twitter."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The worldwide spread of COVID-19 has prompted extensive online discussions,\ncreating an `infodemic' on social media platforms such as WhatsApp and Twitter.\nHowever, the information shared on these platforms is prone to be unreliable\nand/or misleading. In this paper, we present the first analysis of COVID-19\ndiscourse on public WhatsApp groups from Pakistan. Building on a large scale\nannotation of thousands of messages containing text and images, we identify the\nmain categories of discussion. We focus on COVID-19 messages and understand the\ndifferent types of images/text messages being propagated. By exploring user\nbehavior related to COVID messages, we inspect how misinformation is spread.\nFinally, by quantifying the flow of information across WhatsApp and Twitter, we\nshow how information spreads across platforms and how WhatsApp acts as a source\nfor much of the information shared on Twitter.""}, 'authors': [{'name': 'R. Tallal Javed'}, {'name': 'Mirza Elaaf Shuja'}, {'name': 'Muhammad Usama'}, {'name': 'Junaid Qadir'}, {'name': 'Waleed Iqbal'}, {'name': 'Gareth Tyson'}, {'name': 'Ignacio Castro'}, {'name': 'Kiran Garimella'}], 'author_detail': {'name': 'Kiran Garimella'}, 'author': 'Kiran Garimella', 'links': [{'href': 'http://arxiv.org/abs/2011.09145v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.09145v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
189,http://arxiv.org/abs/2011.08787v1,2020-11-17 17:30:10+00:00,2020-11-17 17:30:10+00:00,The COVID19 infodemic. The role and place of academics in science communication,[arxiv.Result.Author('Jennifer Cole')],"As the COVID19 pandemic has spread across the world, a concurrent pandemic of
information has spread with it. Deemed an infodemic by the World Health
Organization, and described as an overabundance of information, some accurate,
some not, that occurs during an epidemic, this proliferation of data, research
and opinions provides both opportunities and challenges for academics.
Academics and scientists have a key role to play in the solutions to the
infodemic challenge: as educators, influences and communicators, even where
their expertise and experience does not align precisely with the SARS-Cov2
virus and its impacts.
  Successful communication requires a better understanding of how the public
seeks, understands and processes scientific information, however, in order to
maximise the ways in which experts engage with traditional and social media and
to make sure that such engagement does not add to confusion and misinformation
alongside efforts to counter or challenge it. This paper will outline the key
advantages to be had from greater engagement with COVID19 discussions, the
popular channels through which such discussions take place and through which
information is disseminated. It also warns against the common pitfalls those
who choose to engage might encounter, whilst stressing that the disadvantages
of doing so are far outweighed by the advantages such engagement offers.",17 Pages,Global Journal of Medicine and Public Health Vol 9 Issue 2 2020,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2011.08787v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.08787v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.08787v1,"{'id': 'http://arxiv.org/abs/2011.08787v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.08787v1', 'updated': '2020-11-17T17:30:10Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=17, tm_hour=17, tm_min=30, tm_sec=10, tm_wday=1, tm_yday=322, tm_isdst=0), 'published': '2020-11-17T17:30:10Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=17, tm_hour=17, tm_min=30, tm_sec=10, tm_wday=1, tm_yday=322, tm_isdst=0), 'title': 'The COVID19 infodemic. The role and place of academics in science\n  communication', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID19 infodemic. The role and place of academics in science\n  communication'}, 'summary': 'As the COVID19 pandemic has spread across the world, a concurrent pandemic of\ninformation has spread with it. Deemed an infodemic by the World Health\nOrganization, and described as an overabundance of information, some accurate,\nsome not, that occurs during an epidemic, this proliferation of data, research\nand opinions provides both opportunities and challenges for academics.\nAcademics and scientists have a key role to play in the solutions to the\ninfodemic challenge: as educators, influences and communicators, even where\ntheir expertise and experience does not align precisely with the SARS-Cov2\nvirus and its impacts.\n  Successful communication requires a better understanding of how the public\nseeks, understands and processes scientific information, however, in order to\nmaximise the ways in which experts engage with traditional and social media and\nto make sure that such engagement does not add to confusion and misinformation\nalongside efforts to counter or challenge it. This paper will outline the key\nadvantages to be had from greater engagement with COVID19 discussions, the\npopular channels through which such discussions take place and through which\ninformation is disseminated. It also warns against the common pitfalls those\nwho choose to engage might encounter, whilst stressing that the disadvantages\nof doing so are far outweighed by the advantages such engagement offers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the COVID19 pandemic has spread across the world, a concurrent pandemic of\ninformation has spread with it. Deemed an infodemic by the World Health\nOrganization, and described as an overabundance of information, some accurate,\nsome not, that occurs during an epidemic, this proliferation of data, research\nand opinions provides both opportunities and challenges for academics.\nAcademics and scientists have a key role to play in the solutions to the\ninfodemic challenge: as educators, influences and communicators, even where\ntheir expertise and experience does not align precisely with the SARS-Cov2\nvirus and its impacts.\n  Successful communication requires a better understanding of how the public\nseeks, understands and processes scientific information, however, in order to\nmaximise the ways in which experts engage with traditional and social media and\nto make sure that such engagement does not add to confusion and misinformation\nalongside efforts to counter or challenge it. This paper will outline the key\nadvantages to be had from greater engagement with COVID19 discussions, the\npopular channels through which such discussions take place and through which\ninformation is disseminated. It also warns against the common pitfalls those\nwho choose to engage might encounter, whilst stressing that the disadvantages\nof doing so are far outweighed by the advantages such engagement offers.'}, 'authors': [{'name': 'Jennifer Cole'}], 'author_detail': {'name': 'Jennifer Cole'}, 'author': 'Jennifer Cole', 'arxiv_comment': '17 Pages', 'arxiv_journal_ref': 'Global Journal of Medicine and Public Health Vol 9 Issue 2 2020', 'links': [{'href': 'http://arxiv.org/abs/2011.08787v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.08787v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
190,http://arxiv.org/abs/2011.06249v4,2021-08-19 04:58:00+00:00,2020-11-12 08:04:32+00:00,Characterizing the roles of bots during the COVID-19 infodemic on Twitter,"[arxiv.Result.Author('Wentao Xu'), arxiv.Result.Author('Kazutoshi Sasahara')]","An infodemic is an emerging phenomenon caused by an overabundance of
information online. This proliferation of information makes it difficult for
the public to distinguish trustworthy news and credible information from
untrustworthy sites and non-credible sources. The perils of an infodemic
debuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated
accounts controlled by a set of algorithms) that are suspected of spreading the
infodemic. Although previous research has revealed that bots played a central
role in spreading misinformation during major political events, how bots
behaved during the infodemic is unclear. In this paper, we examined the roles
of bots in the case of the COVID-19 infodemic and the diffusion of non-credible
information such as ""5G"" and ""Bill Gates"" conspiracy theories and content
related to ""Trump"" and ""WHO"" by analyzing retweet networks and retweeted items.
We show the segregated topology of their retweet networks, which indicates that
right-wing self-media accounts and conspiracy theorists may lead to this
opinion cleavage, while malicious bots might favor amplification of the
diffusion of non-credible information. Although the basic influence of
information diffusion could be larger in human users than bots, the effects of
bots are non-negligible under an infodemic situation.",Accepted by Journal of Computational Social Science (August 2021),,,cs.CY,"['cs.CY', 'cs.SI', 'J.4']","[arxiv.Result.Link('http://arxiv.org/abs/2011.06249v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.06249v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.06249v4,"{'id': 'http://arxiv.org/abs/2011.06249v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.06249v4', 'updated': '2021-08-19T04:58:00Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=19, tm_hour=4, tm_min=58, tm_sec=0, tm_wday=3, tm_yday=231, tm_isdst=0), 'published': '2020-11-12T08:04:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=12, tm_hour=8, tm_min=4, tm_sec=32, tm_wday=3, tm_yday=317, tm_isdst=0), 'title': 'Characterizing the roles of bots during the COVID-19 infodemic on\n  Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing the roles of bots during the COVID-19 infodemic on\n  Twitter'}, 'summary': 'An infodemic is an emerging phenomenon caused by an overabundance of\ninformation online. This proliferation of information makes it difficult for\nthe public to distinguish trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic\ndebuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated\naccounts controlled by a set of algorithms) that are suspected of spreading the\ninfodemic. Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, how bots\nbehaved during the infodemic is unclear. In this paper, we examined the roles\nof bots in the case of the COVID-19 infodemic and the diffusion of non-credible\ninformation such as ""5G"" and ""Bill Gates"" conspiracy theories and content\nrelated to ""Trump"" and ""WHO"" by analyzing retweet networks and retweeted items.\nWe show the segregated topology of their retweet networks, which indicates that\nright-wing self-media accounts and conspiracy theorists may lead to this\nopinion cleavage, while malicious bots might favor amplification of the\ndiffusion of non-credible information. Although the basic influence of\ninformation diffusion could be larger in human users than bots, the effects of\nbots are non-negligible under an infodemic situation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An infodemic is an emerging phenomenon caused by an overabundance of\ninformation online. This proliferation of information makes it difficult for\nthe public to distinguish trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic\ndebuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated\naccounts controlled by a set of algorithms) that are suspected of spreading the\ninfodemic. Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, how bots\nbehaved during the infodemic is unclear. In this paper, we examined the roles\nof bots in the case of the COVID-19 infodemic and the diffusion of non-credible\ninformation such as ""5G"" and ""Bill Gates"" conspiracy theories and content\nrelated to ""Trump"" and ""WHO"" by analyzing retweet networks and retweeted items.\nWe show the segregated topology of their retweet networks, which indicates that\nright-wing self-media accounts and conspiracy theorists may lead to this\nopinion cleavage, while malicious bots might favor amplification of the\ndiffusion of non-credible information. Although the basic influence of\ninformation diffusion could be larger in human users than bots, the effects of\nbots are non-negligible under an infodemic situation.'}, 'authors': [{'name': 'Wentao Xu'}, {'name': 'Kazutoshi Sasahara'}], 'author_detail': {'name': 'Kazutoshi Sasahara'}, 'author': 'Kazutoshi Sasahara', 'arxiv_comment': 'Accepted by Journal of Computational Social Science (August 2021)', 'links': [{'href': 'http://arxiv.org/abs/2011.06249v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.06249v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
191,http://arxiv.org/abs/2011.05773v2,2020-11-12 04:20:37+00:00,2020-11-11 13:48:44+00:00,The Role of the Crowd in Countering Misinformation: A Case Study of the COVID-19 Infodemic,"[arxiv.Result.Author('Nicholas Micallef'), arxiv.Result.Author('Bing He'), arxiv.Result.Author('Srijan Kumar'), arxiv.Result.Author('Mustaque Ahamad'), arxiv.Result.Author('Nasir Memon')]","Fact checking by professionals is viewed as a vital defense in the fight
against misinformation.While fact checking is important and its impact has been
significant, fact checks could have limited visibility and may not reach the
intended audience, such as those deeply embedded in polarized communities.
Concerned citizens (i.e., the crowd), who are users of the platforms where
misinformation appears, can play a crucial role in disseminating fact-checking
information and in countering the spread of misinformation. To explore if this
is the case, we conduct a data-driven study of misinformation on the Twitter
platform, focusing on tweets related to the COVID-19 pandemic, analyzing the
spread of misinformation, professional fact checks, and the crowd response to
popular misleading claims about COVID-19. In this work, we curate a dataset of
false claims and statements that seek to challenge or refute them. We train a
classifier to create a novel dataset of 155,468 COVID-19-related tweets,
containing 33,237 false claims and 33,413 refuting arguments.Our findings show
that professional fact-checking tweets have limited volume and reach. In
contrast, we observe that the surge in misinformation tweets results in a quick
response and a corresponding increase in tweets that refute such
misinformation. More importantly, we find contrasting differences in the way
the crowd refutes tweets, some tweets appear to be opinions, while others
contain concrete evidence, such as a link to a reputed source. Our work
provides insights into how misinformation is organically countered in social
platforms by some of their users and the role they play in amplifying
professional fact checks.These insights could lead to development of tools and
mechanisms that can empower concerned citizens in combating misinformation. The
code and data can be found in
http://claws.cc.gatech.edu/covid_counter_misinformation.html.","PrePrint - IEEE BigData 2020. The code and data can be found in
  http://claws.cc.gatech.edu/covid_counter_misinformation.html",,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2011.05773v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.05773v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.05773v2,"{'id': 'http://arxiv.org/abs/2011.05773v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.05773v2', 'updated': '2020-11-12T04:20:37Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=12, tm_hour=4, tm_min=20, tm_sec=37, tm_wday=3, tm_yday=317, tm_isdst=0), 'published': '2020-11-11T13:48:44Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=11, tm_hour=13, tm_min=48, tm_sec=44, tm_wday=2, tm_yday=316, tm_isdst=0), 'title': 'The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic'}, 'summary': 'Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.'}, 'authors': [{'name': 'Nicholas Micallef'}, {'name': 'Bing He'}, {'name': 'Srijan Kumar'}, {'name': 'Mustaque Ahamad'}, {'name': 'Nasir Memon'}], 'author_detail': {'name': 'Nasir Memon'}, 'author': 'Nasir Memon', 'arxiv_comment': 'PrePrint - IEEE BigData 2020. The code and data can be found in\n  http://claws.cc.gatech.edu/covid_counter_misinformation.html', 'links': [{'href': 'http://arxiv.org/abs/2011.05773v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.05773v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
192,http://arxiv.org/abs/2011.05416v1,2020-11-09 04:15:44+00:00,2020-11-09 04:15:44+00:00,Challenges and Opportunities in Rapid Epidemic Information Propagation with Live Knowledge Aggregation from Social Media,"[arxiv.Result.Author('Calton Pu'), arxiv.Result.Author('Abhijit Suprem'), arxiv.Result.Author('Rodrigo Alves Lima')]","A rapidly evolving situation such as the COVID-19 pandemic is a significant
challenge for AI/ML models because of its unpredictability. %The most reliable
indicator of the pandemic spreading has been the number of test positive cases.
However, the tests are both incomplete (due to untested asymptomatic cases) and
late (due the lag from the initial contact event, worsening symptoms, and test
results). Social media can complement physical test data due to faster and
higher coverage, but they present a different challenge: significant amounts of
noise, misinformation and disinformation. We believe that social media can
become good indicators of pandemic, provided two conditions are met. The first
(True Novelty) is the capture of new, previously unknown, information from
unpredictably evolving situations. The second (Fact vs. Fiction) is the
distinction of verifiable facts from misinformation and disinformation. Social
media information that satisfy those two conditions are called live knowledge.
We apply evidence-based knowledge acquisition (EBKA) approach to collect,
filter, and update live knowledge through the integration of social media
sources with authoritative sources. Although limited in quantity, the reliable
training data from authoritative sources enable the filtering of misinformation
as well as capturing truly new information. We describe the EDNA/LITMUS tools
that implement EBKA, integrating social media such as Twitter and Facebook with
authoritative sources such as WHO and CDC, creating and updating live knowledge
on the COVID-19 pandemic.",,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2011.05416v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2011.05416v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2011.05416v1,"{'id': 'http://arxiv.org/abs/2011.05416v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2011.05416v1', 'updated': '2020-11-09T04:15:44Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=9, tm_hour=4, tm_min=15, tm_sec=44, tm_wday=0, tm_yday=314, tm_isdst=0), 'published': '2020-11-09T04:15:44Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=9, tm_hour=4, tm_min=15, tm_sec=44, tm_wday=0, tm_yday=314, tm_isdst=0), 'title': 'Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media'}, 'summary': 'A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.'}, 'authors': [{'name': 'Calton Pu'}, {'name': 'Abhijit Suprem'}, {'name': 'Rodrigo Alves Lima'}], 'author_detail': {'name': 'Rodrigo Alves Lima'}, 'author': 'Rodrigo Alves Lima', 'links': [{'href': 'http://arxiv.org/abs/2011.05416v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2011.05416v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
193,http://arxiv.org/abs/2010.16357v1,2020-10-30 16:26:35+00:00,2020-10-30 16:26:35+00:00,A Cross-lingual Natural Language Processing Framework for Infodemic Management,"[arxiv.Result.Author('Ridam Pal'), arxiv.Result.Author('Rohan Pandey'), arxiv.Result.Author('Vaibhav Gautam'), arxiv.Result.Author('Kanav Bhagat'), arxiv.Result.Author('Tavpritesh Sethi')]","The COVID-19 pandemic has put immense pressure on health systems which are
further strained due to the misinformation surrounding it. Under such a
situation, providing the right information at the right time is crucial. There
is a growing demand for the management of information spread using Artificial
Intelligence. Hence, we have exploited the potential of Natural Language
Processing for identifying relevant information that needs to be disseminated
amongst the masses. In this work, we present a novel Cross-lingual Natural
Language Processing framework to provide relevant information by matching daily
news with trusted guidelines from the World Health Organization. The proposed
pipeline deploys various techniques of NLP such as summarizers, word
embeddings, and similarity metrics to provide users with news articles along
with a corresponding healthcare guideline. A total of 36 models were evaluated
and a combination of LexRank based summarizer on Word2Vec embedding with Word
Mover distance metric outperformed all other models. This novel open-source
approach can be used as a template for proactive dissemination of relevant
healthcare information in the midst of misinformation spread associated with
epidemics.","8 Pages, 2 Figures, 3 Tables",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2010.16357v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.16357v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.16357v1,"{'id': 'http://arxiv.org/abs/2010.16357v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.16357v1', 'updated': '2020-10-30T16:26:35Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=30, tm_hour=16, tm_min=26, tm_sec=35, tm_wday=4, tm_yday=304, tm_isdst=0), 'published': '2020-10-30T16:26:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=30, tm_hour=16, tm_min=26, tm_sec=35, tm_wday=4, tm_yday=304, tm_isdst=0), 'title': 'A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management'}, 'summary': 'The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.'}, 'authors': [{'name': 'Ridam Pal'}, {'name': 'Rohan Pandey'}, {'name': 'Vaibhav Gautam'}, {'name': 'Kanav Bhagat'}, {'name': 'Tavpritesh Sethi'}], 'author_detail': {'name': 'Tavpritesh Sethi'}, 'author': 'Tavpritesh Sethi', 'arxiv_comment': '8 Pages, 2 Figures, 3 Tables', 'links': [{'href': 'http://arxiv.org/abs/2010.16357v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.16357v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
194,http://arxiv.org/abs/2010.14190v1,2020-10-27 10:52:23+00:00,2020-10-27 10:52:23+00:00,Collective Movement with Signaling,"[arxiv.Result.Author('Mohammad Salahshour'), arxiv.Result.Author('Shahin Rouhani')]","We consider a population of mobile agents able to make noisy observation of
the environment and communicate their observation by production and
comprehension of signals. Individuals try to align their movement direction
with their neighbors. Besides, they try to collectively find and travel towards
an environmental direction. We show that, when the fraction of informed
individuals is small, by increasing the noise in communication, similarly to
the Viscek model, the model shows a discontinuous order-disorder transition
with strong finite size effects. In contrast, for large fraction of informed
individuals, it is possible to go from the ordered phase to the disordered
phase without passing any phase transition. The ordered phase is composed of
two phases separated by a discontinuous transition. Informed collective motion,
in which the population collectively infers the correct environmental
direction, occurs for high fraction of informed individuals. When the fraction
of informed individuals is low, misinformed collective motion, where the
population fails to find the environmental direction becomes stable as well.
Besides, we show that an amount of noise in the production of signals is more
detrimental for the inference capability of the population, and increases the
density fluctuations and the probability of group fragmentation, compared to
the same amount of noise in the comprehension.",16 pages; 5 figures,,,cond-mat.stat-mech,"['cond-mat.stat-mech', 'physics.bio-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2010.14190v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.14190v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.14190v1,"{'id': 'http://arxiv.org/abs/2010.14190v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.14190v1', 'updated': '2020-10-27T10:52:23Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=27, tm_hour=10, tm_min=52, tm_sec=23, tm_wday=1, tm_yday=301, tm_isdst=0), 'published': '2020-10-27T10:52:23Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=27, tm_hour=10, tm_min=52, tm_sec=23, tm_wday=1, tm_yday=301, tm_isdst=0), 'title': 'Collective Movement with Signaling', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Collective Movement with Signaling'}, 'summary': 'We consider a population of mobile agents able to make noisy observation of\nthe environment and communicate their observation by production and\ncomprehension of signals. Individuals try to align their movement direction\nwith their neighbors. Besides, they try to collectively find and travel towards\nan environmental direction. We show that, when the fraction of informed\nindividuals is small, by increasing the noise in communication, similarly to\nthe Viscek model, the model shows a discontinuous order-disorder transition\nwith strong finite size effects. In contrast, for large fraction of informed\nindividuals, it is possible to go from the ordered phase to the disordered\nphase without passing any phase transition. The ordered phase is composed of\ntwo phases separated by a discontinuous transition. Informed collective motion,\nin which the population collectively infers the correct environmental\ndirection, occurs for high fraction of informed individuals. When the fraction\nof informed individuals is low, misinformed collective motion, where the\npopulation fails to find the environmental direction becomes stable as well.\nBesides, we show that an amount of noise in the production of signals is more\ndetrimental for the inference capability of the population, and increases the\ndensity fluctuations and the probability of group fragmentation, compared to\nthe same amount of noise in the comprehension.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We consider a population of mobile agents able to make noisy observation of\nthe environment and communicate their observation by production and\ncomprehension of signals. Individuals try to align their movement direction\nwith their neighbors. Besides, they try to collectively find and travel towards\nan environmental direction. We show that, when the fraction of informed\nindividuals is small, by increasing the noise in communication, similarly to\nthe Viscek model, the model shows a discontinuous order-disorder transition\nwith strong finite size effects. In contrast, for large fraction of informed\nindividuals, it is possible to go from the ordered phase to the disordered\nphase without passing any phase transition. The ordered phase is composed of\ntwo phases separated by a discontinuous transition. Informed collective motion,\nin which the population collectively infers the correct environmental\ndirection, occurs for high fraction of informed individuals. When the fraction\nof informed individuals is low, misinformed collective motion, where the\npopulation fails to find the environmental direction becomes stable as well.\nBesides, we show that an amount of noise in the production of signals is more\ndetrimental for the inference capability of the population, and increases the\ndensity fluctuations and the probability of group fragmentation, compared to\nthe same amount of noise in the comprehension.'}, 'authors': [{'name': 'Mohammad Salahshour'}, {'name': 'Shahin Rouhani'}], 'author_detail': {'name': 'Shahin Rouhani'}, 'author': 'Shahin Rouhani', 'arxiv_comment': '16 pages; 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2010.14190v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.14190v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cond-mat.stat-mech', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cond-mat.stat-mech', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.bio-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
195,http://arxiv.org/abs/2010.13691v2,2021-03-17 02:21:05+00:00,2020-10-26 16:11:56+00:00,The Manufacture of Partisan Echo Chambers by Follow Train Abuse on Twitter,"[arxiv.Result.Author('Christopher Torres-Lugo'), arxiv.Result.Author('Kai-Cheng Yang'), arxiv.Result.Author('Filippo Menczer')]","A growing body of evidence points to critical vulnerabilities of social
media, such as the emergence of partisan echo chambers and the viral spread of
misinformation. We show that these vulnerabilities are amplified by abusive
behaviors associated with so-called ""follow trains"" on Twitter, in which long
lists of like-minded accounts are mentioned for others to follow. We present
the first systematic analysis of a large U.S. hyper-partisan train network. We
observe an artificial inflation of influence: accounts heavily promoted by
follow trains profit from a median six-fold increase in daily follower growth.
This catalyzes the formation of highly clustered echo chambers, hierarchically
organized around a dense core of active accounts. Train accounts also engage in
other behaviors that violate platform policies: we find evidence of activity by
inauthentic automated accounts and abnormal content deletion, as well as
amplification of toxic content from low-credibility and conspiratorial sources.
Some train accounts have been active for years, suggesting that platforms need
to pay greater attention to this kind of abuse.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2010.13691v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.13691v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.13691v2,"{'id': 'http://arxiv.org/abs/2010.13691v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.13691v2', 'updated': '2021-03-17T02:21:05Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=17, tm_hour=2, tm_min=21, tm_sec=5, tm_wday=2, tm_yday=76, tm_isdst=0), 'published': '2020-10-26T16:11:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=26, tm_hour=16, tm_min=11, tm_sec=56, tm_wday=0, tm_yday=300, tm_isdst=0), 'title': 'The Manufacture of Partisan Echo Chambers by Follow Train Abuse on\n  Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Manufacture of Partisan Echo Chambers by Follow Train Abuse on\n  Twitter'}, 'summary': 'A growing body of evidence points to critical vulnerabilities of social\nmedia, such as the emergence of partisan echo chambers and the viral spread of\nmisinformation. We show that these vulnerabilities are amplified by abusive\nbehaviors associated with so-called ""follow trains"" on Twitter, in which long\nlists of like-minded accounts are mentioned for others to follow. We present\nthe first systematic analysis of a large U.S. hyper-partisan train network. We\nobserve an artificial inflation of influence: accounts heavily promoted by\nfollow trains profit from a median six-fold increase in daily follower growth.\nThis catalyzes the formation of highly clustered echo chambers, hierarchically\norganized around a dense core of active accounts. Train accounts also engage in\nother behaviors that violate platform policies: we find evidence of activity by\ninauthentic automated accounts and abnormal content deletion, as well as\namplification of toxic content from low-credibility and conspiratorial sources.\nSome train accounts have been active for years, suggesting that platforms need\nto pay greater attention to this kind of abuse.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A growing body of evidence points to critical vulnerabilities of social\nmedia, such as the emergence of partisan echo chambers and the viral spread of\nmisinformation. We show that these vulnerabilities are amplified by abusive\nbehaviors associated with so-called ""follow trains"" on Twitter, in which long\nlists of like-minded accounts are mentioned for others to follow. We present\nthe first systematic analysis of a large U.S. hyper-partisan train network. We\nobserve an artificial inflation of influence: accounts heavily promoted by\nfollow trains profit from a median six-fold increase in daily follower growth.\nThis catalyzes the formation of highly clustered echo chambers, hierarchically\norganized around a dense core of active accounts. Train accounts also engage in\nother behaviors that violate platform policies: we find evidence of activity by\ninauthentic automated accounts and abnormal content deletion, as well as\namplification of toxic content from low-credibility and conspiratorial sources.\nSome train accounts have been active for years, suggesting that platforms need\nto pay greater attention to this kind of abuse.'}, 'authors': [{'name': 'Christopher Torres-Lugo'}, {'name': 'Kai-Cheng Yang'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'links': [{'href': 'http://arxiv.org/abs/2010.13691v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.13691v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
196,http://arxiv.org/abs/2010.13387v2,2021-07-10 06:08:44+00:00,2020-10-26 07:33:28+00:00,Check Mate: Prioritizing User Generated Multi-Media Content for Fact-Checking,"[arxiv.Result.Author('Tarunima Prabhakar'), arxiv.Result.Author('Anushree Gupta'), arxiv.Result.Author('Kruttika Nadig'), arxiv.Result.Author('Denny George')]","Volume of content and misinformation on social media is rapidly increasing.
There is a need for systems that can support fact checkers by prioritizing
content that needs to be fact checked. Prior research on prioritizing content
for fact-checking has focused on news media articles, predominantly in English
language. Increasingly, misinformation is found in user-generated content. In
this paper we present a novel dataset that can be used to prioritize
check-worthy posts from multi-media content in Hindi. It is unique in its 1)
focus on user generated content, 2) language and 3) accommodation of
multi-modality in social media posts. In addition, we also provide metadata for
each post such as number of shares and likes of the post on ShareChat, a
popular Indian social media platform, that allows for correlative analysis
around virality and misinformation. The data is accessible on Zenodo
(https://zenodo.org/record/4032629) under Creative Commons Attribution License
(CC BY 4.0).","8 pages, 13 figures, 2 tables","Proceedings of the International AAAI Conference on Web and Social
  Media, Volume 15(1), 2021",,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.13387v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.13387v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.13387v2,"{'id': 'http://arxiv.org/abs/2010.13387v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.13387v2', 'updated': '2021-07-10T06:08:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=10, tm_hour=6, tm_min=8, tm_sec=44, tm_wday=5, tm_yday=191, tm_isdst=0), 'published': '2020-10-26T07:33:28Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=26, tm_hour=7, tm_min=33, tm_sec=28, tm_wday=0, tm_yday=300, tm_isdst=0), 'title': 'Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking'}, 'summary': 'Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).'}, 'authors': [{'name': 'Tarunima Prabhakar'}, {'name': 'Anushree Gupta'}, {'name': 'Kruttika Nadig'}, {'name': 'Denny George'}], 'author_detail': {'name': 'Denny George'}, 'author': 'Denny George', 'arxiv_comment': '8 pages, 13 figures, 2 tables', 'arxiv_journal_ref': 'Proceedings of the International AAAI Conference on Web and Social\n  Media, Volume 15(1), 2021', 'links': [{'href': 'http://arxiv.org/abs/2010.13387v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.13387v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
197,http://arxiv.org/abs/2010.13352v1,2020-10-26 05:37:18+00:00,2020-10-26 05:37:18+00:00,The Age-related Differences in Web Information Search Process,"[arxiv.Result.Author('Zhaopeng Xing'), arxiv.Result.Author('Xiaojun'), arxiv.Result.Author('Yuan'), arxiv.Result.Author('Lisa Vizer')]","Older adults' need for quality health information has never been more
critical as during the COVID-19 pandemic. Yet, they are susceptible to the
wide-spread misinformation disseminated through search engines and social
media. To build a search-related behavioral profile of older adults, this
article surveys the empirical research on age-related differences in query
formulation, search strategies, information evaluation, and susceptibility to
misinformation effects. It also decomposes the mechanisms (i.e., cognitive
changes, development goal shift) and moderators (i.e., search task and
interface design) of such differences. To inform the design of information
systems to improve older adults' information search experience, we discuss
opportunities for future research.",,,,cs.HC,"['cs.HC', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2010.13352v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.13352v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.13352v1,"{'id': 'http://arxiv.org/abs/2010.13352v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.13352v1', 'updated': '2020-10-26T05:37:18Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=26, tm_hour=5, tm_min=37, tm_sec=18, tm_wday=0, tm_yday=300, tm_isdst=0), 'published': '2020-10-26T05:37:18Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=26, tm_hour=5, tm_min=37, tm_sec=18, tm_wday=0, tm_yday=300, tm_isdst=0), 'title': 'The Age-related Differences in Web Information Search Process', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Age-related Differences in Web Information Search Process'}, 'summary': ""Older adults' need for quality health information has never been more\ncritical as during the COVID-19 pandemic. Yet, they are susceptible to the\nwide-spread misinformation disseminated through search engines and social\nmedia. To build a search-related behavioral profile of older adults, this\narticle surveys the empirical research on age-related differences in query\nformulation, search strategies, information evaluation, and susceptibility to\nmisinformation effects. It also decomposes the mechanisms (i.e., cognitive\nchanges, development goal shift) and moderators (i.e., search task and\ninterface design) of such differences. To inform the design of information\nsystems to improve older adults' information search experience, we discuss\nopportunities for future research."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Older adults' need for quality health information has never been more\ncritical as during the COVID-19 pandemic. Yet, they are susceptible to the\nwide-spread misinformation disseminated through search engines and social\nmedia. To build a search-related behavioral profile of older adults, this\narticle surveys the empirical research on age-related differences in query\nformulation, search strategies, information evaluation, and susceptibility to\nmisinformation effects. It also decomposes the mechanisms (i.e., cognitive\nchanges, development goal shift) and moderators (i.e., search task and\ninterface design) of such differences. To inform the design of information\nsystems to improve older adults' information search experience, we discuss\nopportunities for future research.""}, 'authors': [{'name': 'Zhaopeng Xing'}, {'name': 'Xiaojun'}, {'name': 'Yuan'}, {'name': 'Lisa Vizer'}], 'author_detail': {'name': 'Lisa Vizer'}, 'arxiv_affiliation': 'Jenny', 'author': 'Lisa Vizer', 'links': [{'href': 'http://arxiv.org/abs/2010.13352v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.13352v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
198,http://arxiv.org/abs/2010.11638v5,2021-10-12 23:03:38+00:00,2020-10-22 12:20:01+00:00,"""It is just a flu"": Assessing the Effect of Watch History on YouTube's Pseudoscientific Video Recommendations","[arxiv.Result.Author('Kostantinos Papadamou'), arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Jeremy Blackburn'), arxiv.Result.Author('Emiliano De Cristofaro'), arxiv.Result.Author('Gianluca Stringhini'), arxiv.Result.Author('Michael Sirivianos')]","The role played by YouTube's recommendation algorithm in unwittingly
promoting misinformation and conspiracy theories is not entirely understood.
Yet, this can have dire real-world consequences, especially when
pseudoscientific content is promoted to users at critical times, such as the
COVID-19 pandemic. In this paper, we set out to characterize and detect
pseudoscientific misinformation on YouTube. We collect 6.6K videos related to
COVID-19, the Flat Earth theory, as well as the anti-vaccination and anti-mask
movements. Using crowdsourcing, we annotate them as pseudoscience, legitimate
science, or irrelevant and train a deep learning classifier to detect
pseudoscientific videos with an accuracy of 0.79.
  We quantify user exposure to this content on various parts of the platform
and how this exposure changes based on the user's watch history. We find that
YouTube suggests more pseudoscientific content regarding traditional
pseudoscientific topics (e.g., flat earth, anti-vaccination) than for emerging
ones (like COVID-19). At the same time, these recommendations are more common
on the search results page than on a user's homepage or in the recommendation
section when actively watching videos. Finally, we shed light on how a user's
watch history substantially affects the type of recommended videos.","To appear at the 16th International Conference on Web and Social
  Media (ICWSM 2022). Please cite the ICWSM version",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.11638v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.11638v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.11638v5,"{'id': 'http://arxiv.org/abs/2010.11638v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.11638v5', 'updated': '2021-10-12T23:03:38Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=12, tm_hour=23, tm_min=3, tm_sec=38, tm_wday=1, tm_yday=285, tm_isdst=0), 'published': '2020-10-22T12:20:01Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=22, tm_hour=12, tm_min=20, tm_sec=1, tm_wday=3, tm_yday=296, tm_isdst=0), 'title': '""It is just a flu"": Assessing the Effect of Watch History on YouTube\'s\n  Pseudoscientific Video Recommendations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""It is just a flu"": Assessing the Effect of Watch History on YouTube\'s\n  Pseudoscientific Video Recommendations'}, 'summary': ""The role played by YouTube's recommendation algorithm in unwittingly\npromoting misinformation and conspiracy theories is not entirely understood.\nYet, this can have dire real-world consequences, especially when\npseudoscientific content is promoted to users at critical times, such as the\nCOVID-19 pandemic. In this paper, we set out to characterize and detect\npseudoscientific misinformation on YouTube. We collect 6.6K videos related to\nCOVID-19, the Flat Earth theory, as well as the anti-vaccination and anti-mask\nmovements. Using crowdsourcing, we annotate them as pseudoscience, legitimate\nscience, or irrelevant and train a deep learning classifier to detect\npseudoscientific videos with an accuracy of 0.79.\n  We quantify user exposure to this content on various parts of the platform\nand how this exposure changes based on the user's watch history. We find that\nYouTube suggests more pseudoscientific content regarding traditional\npseudoscientific topics (e.g., flat earth, anti-vaccination) than for emerging\nones (like COVID-19). At the same time, these recommendations are more common\non the search results page than on a user's homepage or in the recommendation\nsection when actively watching videos. Finally, we shed light on how a user's\nwatch history substantially affects the type of recommended videos."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The role played by YouTube's recommendation algorithm in unwittingly\npromoting misinformation and conspiracy theories is not entirely understood.\nYet, this can have dire real-world consequences, especially when\npseudoscientific content is promoted to users at critical times, such as the\nCOVID-19 pandemic. In this paper, we set out to characterize and detect\npseudoscientific misinformation on YouTube. We collect 6.6K videos related to\nCOVID-19, the Flat Earth theory, as well as the anti-vaccination and anti-mask\nmovements. Using crowdsourcing, we annotate them as pseudoscience, legitimate\nscience, or irrelevant and train a deep learning classifier to detect\npseudoscientific videos with an accuracy of 0.79.\n  We quantify user exposure to this content on various parts of the platform\nand how this exposure changes based on the user's watch history. We find that\nYouTube suggests more pseudoscientific content regarding traditional\npseudoscientific topics (e.g., flat earth, anti-vaccination) than for emerging\nones (like COVID-19). At the same time, these recommendations are more common\non the search results page than on a user's homepage or in the recommendation\nsection when actively watching videos. Finally, we shed light on how a user's\nwatch history substantially affects the type of recommended videos.""}, 'authors': [{'name': 'Kostantinos Papadamou'}, {'name': 'Savvas Zannettou'}, {'name': 'Jeremy Blackburn'}, {'name': 'Emiliano De Cristofaro'}, {'name': 'Gianluca Stringhini'}, {'name': 'Michael Sirivianos'}], 'author_detail': {'name': 'Michael Sirivianos'}, 'author': 'Michael Sirivianos', 'arxiv_comment': 'To appear at the 16th International Conference on Web and Social\n  Media (ICWSM 2022). Please cite the ICWSM version', 'links': [{'href': 'http://arxiv.org/abs/2010.11638v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.11638v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
199,http://arxiv.org/abs/2010.10113v1,2020-10-20 08:11:47+00:00,2020-10-20 08:11:47+00:00,Is this pofma? Analysing public opinion and misinformation in a COVID-19 Telegram group chat,"[arxiv.Result.Author('Lynnette Hui Xian Ng'), arxiv.Result.Author('Loke Jia Yuan')]","We analyse a Singapore-based COVID-19 Telegram group with more than 10,000
participants. First, we study the group's opinion over time, focusing on four
dimensions: participation, sentiment, topics, and psychological features. We
find that engagement peaked when the Ministry of Health raised the disease
alert level, but this engagement was not sustained. Second, we search for
government-identified misinformation in the group. We find that
government-identified misinformation is rare, and that messages discussing
these pieces of misinformation express skepticism.",,"Workshop Proceedings of the 14th International AAAI Conference on
  Web and Social Media 2020",10.36190/2020.12,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.36190/2020.12', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.10113v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.10113v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.10113v1,"{'id': 'http://arxiv.org/abs/2010.10113v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.10113v1', 'updated': '2020-10-20T08:11:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=20, tm_hour=8, tm_min=11, tm_sec=47, tm_wday=1, tm_yday=294, tm_isdst=0), 'published': '2020-10-20T08:11:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=20, tm_hour=8, tm_min=11, tm_sec=47, tm_wday=1, tm_yday=294, tm_isdst=0), 'title': 'Is this pofma? Analysing public opinion and misinformation in a COVID-19\n  Telegram group chat', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Is this pofma? Analysing public opinion and misinformation in a COVID-19\n  Telegram group chat'}, 'summary': ""We analyse a Singapore-based COVID-19 Telegram group with more than 10,000\nparticipants. First, we study the group's opinion over time, focusing on four\ndimensions: participation, sentiment, topics, and psychological features. We\nfind that engagement peaked when the Ministry of Health raised the disease\nalert level, but this engagement was not sustained. Second, we search for\ngovernment-identified misinformation in the group. We find that\ngovernment-identified misinformation is rare, and that messages discussing\nthese pieces of misinformation express skepticism."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We analyse a Singapore-based COVID-19 Telegram group with more than 10,000\nparticipants. First, we study the group's opinion over time, focusing on four\ndimensions: participation, sentiment, topics, and psychological features. We\nfind that engagement peaked when the Ministry of Health raised the disease\nalert level, but this engagement was not sustained. Second, we search for\ngovernment-identified misinformation in the group. We find that\ngovernment-identified misinformation is rare, and that messages discussing\nthese pieces of misinformation express skepticism.""}, 'authors': [{'name': 'Lynnette Hui Xian Ng'}, {'name': 'Loke Jia Yuan'}], 'author_detail': {'name': 'Loke Jia Yuan'}, 'author': 'Loke Jia Yuan', 'arxiv_doi': '10.36190/2020.12', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.36190/2020.12', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.10113v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.10113v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Workshop Proceedings of the 14th International AAAI Conference on\n  Web and Social Media 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
200,http://arxiv.org/abs/2010.09113v1,2020-10-18 21:44:23+00:00,2020-10-18 21:44:23+00:00,"Disinformation in the Online Information Ecosystem: Detection, Mitigation and Challenges","[arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Min Gao'), arxiv.Result.Author('Huan Liu')]","With the rapid increase in access to internet and the subsequent growth in
the population of online social media users, the quality of information posted,
disseminated and consumed via these platforms is an issue of growing concern. A
large fraction of the common public turn to social media platforms and in
general the internet for news and even information regarding highly concerning
issues such as COVID-19 symptoms. Given that the online information ecosystem
is extremely noisy, fraught with misinformation and disinformation, and often
contaminated by malicious agents spreading propaganda, identifying genuine and
good quality information from disinformation is a challenging task for humans.
In this regard, there is a significant amount of ongoing research in the
directions of disinformation detection and mitigation. In this survey, we
discuss the online disinformation problem, focusing on the recent 'infodemic'
in the wake of the coronavirus pandemic. We then proceed to discuss the
inherent challenges in disinformation research, and then elaborate on the
computational and interdisciplinary approaches towards mitigation of
disinformation, after a short overview of the various directions explored in
detection efforts.","A Chinese version of this manuscript has been submitted to the
  Journal of Computer Research and Development",,,cs.SI,"['cs.SI', 'cs.CY', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2010.09113v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.09113v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.09113v1,"{'id': 'http://arxiv.org/abs/2010.09113v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.09113v1', 'updated': '2020-10-18T21:44:23Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=44, tm_sec=23, tm_wday=6, tm_yday=292, tm_isdst=0), 'published': '2020-10-18T21:44:23Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=44, tm_sec=23, tm_wday=6, tm_yday=292, tm_isdst=0), 'title': 'Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges'}, 'summary': ""With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.""}, 'authors': [{'name': 'Amrita Bhattacharjee'}, {'name': 'Kai Shu'}, {'name': 'Min Gao'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': 'A Chinese version of this manuscript has been submitted to the\n  Journal of Computer Research and Development', 'links': [{'href': 'http://arxiv.org/abs/2010.09113v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.09113v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
201,http://arxiv.org/abs/2010.09078v1,2020-10-18 19:37:24+00:00,2020-10-18 19:37:24+00:00,Incorporating Count-Based Features into Pre-Trained Models for Improved Stance Detection,"[arxiv.Result.Author('Anushka Prakash'), arxiv.Result.Author('Harish Tayyar Madabushi')]","The explosive growth and popularity of Social Media has revolutionised the
way we communicate and collaborate. Unfortunately, this same ease of accessing
and sharing information has led to an explosion of misinformation and
propaganda. Given that stance detection can significantly aid in veracity
prediction, this work focuses on boosting automated stance detection, a task on
which pre-trained models have been extremely successful on, as on several other
tasks. This work shows that the task of stance detection can benefit from
feature based information, especially on certain under performing classes,
however, integrating such features into pre-trained models using ensembling is
challenging. We propose a novel architecture for integrating features with
pre-trained models that address these challenges and test our method on the
RumourEval 2019 dataset. This method achieves state-of-the-art results with an
F1-score of 63.94 on the test set.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.09078v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.09078v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.09078v1,"{'id': 'http://arxiv.org/abs/2010.09078v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.09078v1', 'updated': '2020-10-18T19:37:24Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=37, tm_sec=24, tm_wday=6, tm_yday=292, tm_isdst=0), 'published': '2020-10-18T19:37:24Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=37, tm_sec=24, tm_wday=6, tm_yday=292, tm_isdst=0), 'title': 'Incorporating Count-Based Features into Pre-Trained Models for Improved\n  Stance Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Incorporating Count-Based Features into Pre-Trained Models for Improved\n  Stance Detection'}, 'summary': 'The explosive growth and popularity of Social Media has revolutionised the\nway we communicate and collaborate. Unfortunately, this same ease of accessing\nand sharing information has led to an explosion of misinformation and\npropaganda. Given that stance detection can significantly aid in veracity\nprediction, this work focuses on boosting automated stance detection, a task on\nwhich pre-trained models have been extremely successful on, as on several other\ntasks. This work shows that the task of stance detection can benefit from\nfeature based information, especially on certain under performing classes,\nhowever, integrating such features into pre-trained models using ensembling is\nchallenging. We propose a novel architecture for integrating features with\npre-trained models that address these challenges and test our method on the\nRumourEval 2019 dataset. This method achieves state-of-the-art results with an\nF1-score of 63.94 on the test set.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The explosive growth and popularity of Social Media has revolutionised the\nway we communicate and collaborate. Unfortunately, this same ease of accessing\nand sharing information has led to an explosion of misinformation and\npropaganda. Given that stance detection can significantly aid in veracity\nprediction, this work focuses on boosting automated stance detection, a task on\nwhich pre-trained models have been extremely successful on, as on several other\ntasks. This work shows that the task of stance detection can benefit from\nfeature based information, especially on certain under performing classes,\nhowever, integrating such features into pre-trained models using ensembling is\nchallenging. We propose a novel architecture for integrating features with\npre-trained models that address these challenges and test our method on the\nRumourEval 2019 dataset. This method achieves state-of-the-art results with an\nF1-score of 63.94 on the test set.'}, 'authors': [{'name': 'Anushka Prakash'}, {'name': 'Harish Tayyar Madabushi'}], 'author_detail': {'name': 'Harish Tayyar Madabushi'}, 'author': 'Harish Tayyar Madabushi', 'links': [{'href': 'http://arxiv.org/abs/2010.09078v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.09078v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
202,http://arxiv.org/abs/2010.09029v2,2021-06-13 02:17:47+00:00,2020-10-18 16:52:27+00:00,CHECKED: Chinese COVID-19 Fake News Dataset,"[arxiv.Result.Author('Chen Yang'), arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Reza Zafarani')]","COVID-19 has impacted all lives. To maintain social distancing and avoiding
exposure, works and lives have gradually moved online. Under this trend, social
media usage to obtain COVID-19 news has increased. Also, misinformation on
COVID-19 is frequently spread on social media. In this work, we develop
CHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides
a total 2,104 verified microblogs related to COVID-19 from December 2019 to
August 2020, identified by using a specific list of keywords. Correspondingly,
CHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes
that reveal how these verified microblogs are spread and reacted on Weibo. The
dataset contains a rich set of multimedia information for each microblog
including ground-truth label, textual, visual, temporal, and network
information. Extensive experiments have been conducted to analyze CHECKED data
and to provide benchmark results for well-established methods when predicting
fake news using CHECKED. We hope that CHECKED can facilitate studies that
target misinformation on coronavirus. The dataset is available at
https://github.com/cyang03/CHECKED.",Accepted to Social Network Analysis and Mining (SNAM),,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2010.09029v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.09029v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.09029v2,"{'id': 'http://arxiv.org/abs/2010.09029v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.09029v2', 'updated': '2021-06-13T02:17:47Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=13, tm_hour=2, tm_min=17, tm_sec=47, tm_wday=6, tm_yday=164, tm_isdst=0), 'published': '2020-10-18T16:52:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=18, tm_hour=16, tm_min=52, tm_sec=27, tm_wday=6, tm_yday=292, tm_isdst=0), 'title': 'CHECKED: Chinese COVID-19 Fake News Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CHECKED: Chinese COVID-19 Fake News Dataset'}, 'summary': 'COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.'}, 'authors': [{'name': 'Chen Yang'}, {'name': 'Xinyi Zhou'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'arxiv_comment': 'Accepted to Social Network Analysis and Mining (SNAM)', 'links': [{'href': 'http://arxiv.org/abs/2010.09029v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.09029v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
203,http://arxiv.org/abs/2010.08768v2,2021-03-13 20:26:35+00:00,2020-10-17 11:21:40+00:00,ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation Detection,"[arxiv.Result.Author('Fatima Haouari'), arxiv.Result.Author('Maram Hasanain'), arxiv.Result.Author('Reem Suwaileh'), arxiv.Result.Author('Tamer Elsayed')]","In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset
for misinformation detection composed of tweets containing claims from 27th
January till the end of April 2020. We collected 138 verified claims, mostly
from popular fact-checking websites, and identified 9.4K relevant tweets to
those claims. Tweets were manually-annotated by veracity to support research on
misinformation detection, which is one of the major problems faced during a
pandemic. ArCOV19-Rumors supports two levels of misinformation detection over
Twitter: verifying free-text claims (called claim-level verification) and
verifying claims expressed in tweets (called tweet-level verification). Our
dataset covers, in addition to health, claims related to other topical
categories that were influenced by COVID-19, namely, social, politics, sports,
entertainment, and religious. Moreover, we present benchmarking results for
tweet-level verification on the dataset. We experimented with SOTA models of
versatile approaches that either exploit content, user profiles features,
temporal features and propagation structure of the conversational threads for
tweet verification.","This work was accepted at the Sixth Arabic Natural Language
  Processing Workshop (EACL/WANLP 2021)",,,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.08768v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.08768v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.08768v2,"{'id': 'http://arxiv.org/abs/2010.08768v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.08768v2', 'updated': '2021-03-13T20:26:35Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=13, tm_hour=20, tm_min=26, tm_sec=35, tm_wday=5, tm_yday=72, tm_isdst=0), 'published': '2020-10-17T11:21:40Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=11, tm_min=21, tm_sec=40, tm_wday=5, tm_yday=291, tm_isdst=0), 'title': 'ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation\n  Detection'}, 'summary': 'In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset\nfor misinformation detection composed of tweets containing claims from 27th\nJanuary till the end of April 2020. We collected 138 verified claims, mostly\nfrom popular fact-checking websites, and identified 9.4K relevant tweets to\nthose claims. Tweets were manually-annotated by veracity to support research on\nmisinformation detection, which is one of the major problems faced during a\npandemic. ArCOV19-Rumors supports two levels of misinformation detection over\nTwitter: verifying free-text claims (called claim-level verification) and\nverifying claims expressed in tweets (called tweet-level verification). Our\ndataset covers, in addition to health, claims related to other topical\ncategories that were influenced by COVID-19, namely, social, politics, sports,\nentertainment, and religious. Moreover, we present benchmarking results for\ntweet-level verification on the dataset. We experimented with SOTA models of\nversatile approaches that either exploit content, user profiles features,\ntemporal features and propagation structure of the conversational threads for\ntweet verification.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset\nfor misinformation detection composed of tweets containing claims from 27th\nJanuary till the end of April 2020. We collected 138 verified claims, mostly\nfrom popular fact-checking websites, and identified 9.4K relevant tweets to\nthose claims. Tweets were manually-annotated by veracity to support research on\nmisinformation detection, which is one of the major problems faced during a\npandemic. ArCOV19-Rumors supports two levels of misinformation detection over\nTwitter: verifying free-text claims (called claim-level verification) and\nverifying claims expressed in tweets (called tweet-level verification). Our\ndataset covers, in addition to health, claims related to other topical\ncategories that were influenced by COVID-19, namely, social, politics, sports,\nentertainment, and religious. Moreover, we present benchmarking results for\ntweet-level verification on the dataset. We experimented with SOTA models of\nversatile approaches that either exploit content, user profiles features,\ntemporal features and propagation structure of the conversational threads for\ntweet verification.'}, 'authors': [{'name': 'Fatima Haouari'}, {'name': 'Maram Hasanain'}, {'name': 'Reem Suwaileh'}, {'name': 'Tamer Elsayed'}], 'author_detail': {'name': 'Tamer Elsayed'}, 'author': 'Tamer Elsayed', 'arxiv_comment': 'This work was accepted at the Sixth Arabic Natural Language\n  Processing Workshop (EACL/WANLP 2021)', 'links': [{'href': 'http://arxiv.org/abs/2010.08768v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.08768v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
204,http://arxiv.org/abs/2010.08743v1,2020-10-17 08:34:57+00:00,2020-10-17 08:34:57+00:00,Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed health decision making in the presence of COVID19 misinformation,"[arxiv.Result.Author('Arkin Dharawat'), arxiv.Result.Author('Ismini Lourentzou'), arxiv.Result.Author('Alex Morales'), arxiv.Result.Author('ChengXiang Zhai')]","Given the wide spread of inaccurate medical advice related to the 2019
coronavirus pandemic (COVID-19), such as fake remedies, treatments and
prevention suggestions, misinformation detection has emerged as an open problem
of high importance and interest for the NLP community. To combat potential harm
of COVID19-related misinformation, we release Covid-HeRA, a dataset for health
risk assessment of COVID-19-related social media posts. More specifically, we
study the severity of each misinformation story, i.e., how harmful a message
believed by the audience can be and what type of signals can be used to
discover high malicious fake news and detect refuted claims. We present a
detailed analysis, evaluate several simple and advanced classification models,
and conclude with our experimental analysis that presents open challenges and
future directions.",,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2010.08743v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.08743v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.08743v1,"{'id': 'http://arxiv.org/abs/2010.08743v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.08743v1', 'updated': '2020-10-17T08:34:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=8, tm_min=34, tm_sec=57, tm_wday=5, tm_yday=291, tm_isdst=0), 'published': '2020-10-17T08:34:57Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=17, tm_hour=8, tm_min=34, tm_sec=57, tm_wday=5, tm_yday=291, tm_isdst=0), 'title': 'Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation'}, 'summary': 'Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.'}, 'authors': [{'name': 'Arkin Dharawat'}, {'name': 'Ismini Lourentzou'}, {'name': 'Alex Morales'}, {'name': 'ChengXiang Zhai'}], 'author_detail': {'name': 'ChengXiang Zhai'}, 'author': 'ChengXiang Zhai', 'links': [{'href': 'http://arxiv.org/abs/2010.08743v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.08743v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
205,http://arxiv.org/abs/2010.07647v2,2021-07-06 09:16:25+00:00,2020-10-15 10:31:28+00:00,Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised Learning Approach,"[arxiv.Result.Author('Shakshi Sharma'), arxiv.Result.Author('Rajesh Sharma')]","Online Social Media (OSM) platforms such as Twitter, Facebook are extensively
exploited by the users of these platforms for spreading the (mis)information to
a large audience effortlessly at a rapid pace. It has been observed that the
misinformation can cause panic, fear, and financial loss to society. Thus, it
is important to detect and control the misinformation in such platforms before
it spreads to the masses. In this work, we focus on rumors, which is one type
of misinformation (other types are fake news, hoaxes, etc). One way to control
the spread of the rumors is by identifying users who are possibly the rumor
spreaders, that is, users who are often involved in spreading the rumors. Due
to the lack of availability of rumor spreaders labeled dataset (which is an
expensive task), we use publicly available PHEME dataset, which contains rumor
and non-rumor tweets information, and then apply a weak supervised learning
approach to transform the PHEME dataset into rumor spreaders dataset. We
utilize three types of features, that is, user, text, and ego-network features,
before applying various supervised learning approaches. In particular, to
exploit the inherent network property in this dataset (user-user reply graph),
we explore Graph Convolutional Network (GCN), a type of Graph Neural Network
(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and
LSTM. Extensive experiments performed on the rumor spreaders dataset, where we
achieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the
effectiveness of our methodology for identifying possible rumor spreaders using
the GCN technique.","Published at The International Joint Conference on Neural Networks
  2021 (IJCNN2021). Please cite the IJCNN version",,,cs.AI,['cs.AI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.07647v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.07647v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.07647v2,"{'id': 'http://arxiv.org/abs/2010.07647v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.07647v2', 'updated': '2021-07-06T09:16:25Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=9, tm_min=16, tm_sec=25, tm_wday=1, tm_yday=187, tm_isdst=0), 'published': '2020-10-15T10:31:28Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=15, tm_hour=10, tm_min=31, tm_sec=28, tm_wday=3, tm_yday=289, tm_isdst=0), 'title': 'Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach'}, 'summary': 'Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.'}, 'authors': [{'name': 'Shakshi Sharma'}, {'name': 'Rajesh Sharma'}], 'author_detail': {'name': 'Rajesh Sharma'}, 'author': 'Rajesh Sharma', 'arxiv_comment': 'Published at The International Joint Conference on Neural Networks\n  2021 (IJCNN2021). Please cite the IJCNN version', 'links': [{'href': 'http://arxiv.org/abs/2010.07647v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.07647v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
206,http://arxiv.org/abs/2010.06906v1,2020-10-14 09:37:51+00:00,2020-10-14 09:37:51+00:00,No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet Detection,"[arxiv.Result.Author('Debanjana Kar'), arxiv.Result.Author('Mohit Bhardwaj'), arxiv.Result.Author('Suranjana Samanta'), arxiv.Result.Author('Amar Prakash Azad')]","The sudden widespread menace created by the present global pandemic COVID-19
has had an unprecedented effect on our lives. Man-kind is going through
humongous fear and dependence on social media like never before. Fear
inevitably leads to panic, speculations, and the spread of misinformation. Many
governments have taken measures to curb the spread of such misinformation for
public well being. Besides global measures, to have effective outreach, systems
for demographically local languages have an important role to play in this
effort. Towards this, we propose an approach to detect fake news about COVID-19
early on from social media, such as tweets, for multiple Indic-Languages
besides English. In addition, we also create an annotated dataset of Hindi and
Bengali tweet for fake news detection. We propose a BERT based model augmented
with additional relevant features extracted from Twitter to identify fake
tweets. To expand our approach to multiple Indic languages, we resort to mBERT
based model which is fine-tuned over created dataset in Hindi and Bengali. We
also propose a zero-shot learning approach to alleviate the data scarcity issue
for such low resource languages. Through rigorous experiments, we show that our
approach reaches around 89% F-Score in fake tweet detection which supercedes
the state-of-the-art (SOTA) results. Moreover, we establish the first benchmark
for two Indic-Languages, Hindi and Bengali. Using our annotated data, our model
achieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our
zero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali
Tweets without any annotated data, which clearly indicates the efficacy of our
approach.","6 pages, 4 figures",,,cs.CL,"['cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.06906v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.06906v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.06906v1,"{'id': 'http://arxiv.org/abs/2010.06906v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.06906v1', 'updated': '2020-10-14T09:37:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=14, tm_hour=9, tm_min=37, tm_sec=51, tm_wday=2, tm_yday=288, tm_isdst=0), 'published': '2020-10-14T09:37:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=14, tm_hour=9, tm_min=37, tm_sec=51, tm_wday=2, tm_yday=288, tm_isdst=0), 'title': 'No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection'}, 'summary': 'The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.'}, 'authors': [{'name': 'Debanjana Kar'}, {'name': 'Mohit Bhardwaj'}, {'name': 'Suranjana Samanta'}, {'name': 'Amar Prakash Azad'}], 'author_detail': {'name': 'Amar Prakash Azad'}, 'author': 'Amar Prakash Azad', 'arxiv_comment': '6 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2010.06906v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.06906v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
207,http://arxiv.org/abs/2010.06455v2,2020-10-15 03:23:26+00:00,2020-10-13 15:10:26+00:00,"Characterizing and Comparing COVID-19 Misinformation Across Languages, Countries and Platforms","[arxiv.Result.Author('Golshan Madraki'), arxiv.Result.Author('Isabella Grasso'), arxiv.Result.Author('Jacqueline Otala'), arxiv.Result.Author('Yu Liu'), arxiv.Result.Author('Jeanna Matthews')]","Misinformation/disinformation about COVID-19 has been rampant on social media
around the world. In this study, we investigate COVID-19 misinformation/
disinformation on social media in multiple languages - Farsi (Persian),
Chinese, and English, about multiple countries - Iran, China, and the United
States (US), and on multiple platforms such as Twitter, Facebook, Instagram,
Weibo, and WhatsApp. Misinformation, especially about a global pandemic, is a
global problem yet it is common for studies of COVID-19 misinformation on
social media to focus on a single language, like English, a single country,
like the US, or a single platform, like Twitter. We utilized opportunistic
sampling to compile 200 specific items of viral and yet debunked misinformation
across these languages, countries and platforms emerged between January 1 and
August 31. We then categorized this collection based both on the topics of the
misinformation and the underlying roots of that misinformation. Our
multi-cultural and multilingual team observed that the nature of COVID-19
misinformation on social media varied in substantial ways across different
languages/countries depending on the cultures, beliefs/religions, popularity of
social media, types of platforms, freedom of speech and the power of people
versus governments. We observe that politics is at the root of most of the
collected misinformation across all three languages in this dataset. We further
observe the different impact of government restrictions on platforms and
platform restrictions on content in Iran, China, and the US and their impact on
a key question of our age: how do we control misinformation without silencing
the voices we need to hold governments accountable?",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.06455v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.06455v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.06455v2,"{'id': 'http://arxiv.org/abs/2010.06455v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.06455v2', 'updated': '2020-10-15T03:23:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=15, tm_hour=3, tm_min=23, tm_sec=26, tm_wday=3, tm_yday=289, tm_isdst=0), 'published': '2020-10-13T15:10:26Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=13, tm_hour=15, tm_min=10, tm_sec=26, tm_wday=1, tm_yday=287, tm_isdst=0), 'title': 'Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms'}, 'summary': 'Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?'}, 'authors': [{'name': 'Golshan Madraki'}, {'name': 'Isabella Grasso'}, {'name': 'Jacqueline Otala'}, {'name': 'Yu Liu'}, {'name': 'Jeanna Matthews'}], 'author_detail': {'name': 'Jeanna Matthews'}, 'author': 'Jeanna Matthews', 'links': [{'href': 'http://arxiv.org/abs/2010.06455v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.06455v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
208,http://arxiv.org/abs/2010.06019v2,2020-10-14 15:50:22+00:00,2020-10-12 20:43:41+00:00,Probabilistic Social Learning Improves the Public's Detection of Misinformation,"[arxiv.Result.Author('Douglas Guilbeault'), arxiv.Result.Author('Samuel Woolley'), arxiv.Result.Author('Joshua Becker')]","The digital spread of misinformation is one of the leading threats to
democracy, public health, and the global economy. Popular strategies for
mitigating misinformation include crowdsourcing, machine learning, and media
literacy programs that require social media users to classify news in binary
terms as either true or false. However, research on peer influence suggests
that framing decisions in binary terms can amplify judgment errors and limit
social learning, whereas framing decisions in probabilistic terms can reliably
improve judgments. In this preregistered experiment, we compare online peer
networks that collaboratively evaluate the veracity of news by communicating
either binary or probabilistic judgments. Exchanging probabilistic estimates of
news veracity substantially improved individual and group judgments, with the
effect of eliminating polarization in news evaluation. By contrast, exchanging
binary classifications reduced social learning and entrenched polarization. The
benefits of probabilistic social learning are robust to participants'
education, gender, race, income, religion, and partisanship.","11 pages, 4 figures",,10.1371/journal.pone.0247487,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0247487', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.06019v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.06019v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.06019v2,"{'id': 'http://arxiv.org/abs/2010.06019v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.06019v2', 'updated': '2020-10-14T15:50:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=14, tm_hour=15, tm_min=50, tm_sec=22, tm_wday=2, tm_yday=288, tm_isdst=0), 'published': '2020-10-12T20:43:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=12, tm_hour=20, tm_min=43, tm_sec=41, tm_wday=0, tm_yday=286, tm_isdst=0), 'title': ""Probabilistic Social Learning Improves the Public's Detection of\n  Misinformation"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Probabilistic Social Learning Improves the Public's Detection of\n  Misinformation""}, 'summary': ""The digital spread of misinformation is one of the leading threats to\ndemocracy, public health, and the global economy. Popular strategies for\nmitigating misinformation include crowdsourcing, machine learning, and media\nliteracy programs that require social media users to classify news in binary\nterms as either true or false. However, research on peer influence suggests\nthat framing decisions in binary terms can amplify judgment errors and limit\nsocial learning, whereas framing decisions in probabilistic terms can reliably\nimprove judgments. In this preregistered experiment, we compare online peer\nnetworks that collaboratively evaluate the veracity of news by communicating\neither binary or probabilistic judgments. Exchanging probabilistic estimates of\nnews veracity substantially improved individual and group judgments, with the\neffect of eliminating polarization in news evaluation. By contrast, exchanging\nbinary classifications reduced social learning and entrenched polarization. The\nbenefits of probabilistic social learning are robust to participants'\neducation, gender, race, income, religion, and partisanship."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The digital spread of misinformation is one of the leading threats to\ndemocracy, public health, and the global economy. Popular strategies for\nmitigating misinformation include crowdsourcing, machine learning, and media\nliteracy programs that require social media users to classify news in binary\nterms as either true or false. However, research on peer influence suggests\nthat framing decisions in binary terms can amplify judgment errors and limit\nsocial learning, whereas framing decisions in probabilistic terms can reliably\nimprove judgments. In this preregistered experiment, we compare online peer\nnetworks that collaboratively evaluate the veracity of news by communicating\neither binary or probabilistic judgments. Exchanging probabilistic estimates of\nnews veracity substantially improved individual and group judgments, with the\neffect of eliminating polarization in news evaluation. By contrast, exchanging\nbinary classifications reduced social learning and entrenched polarization. The\nbenefits of probabilistic social learning are robust to participants'\neducation, gender, race, income, religion, and partisanship.""}, 'authors': [{'name': 'Douglas Guilbeault'}, {'name': 'Samuel Woolley'}, {'name': 'Joshua Becker'}], 'author_detail': {'name': 'Joshua Becker'}, 'author': 'Joshua Becker', 'arxiv_doi': '10.1371/journal.pone.0247487', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0247487', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.06019v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.06019v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '11 pages, 4 figures', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
209,http://arxiv.org/abs/2010.16413v3,2021-09-05 20:27:35+00:00,2020-10-09 22:10:43+00:00,Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic with Natural Language Processing (NLP),"[arxiv.Result.Author('Qingyu Chen'), arxiv.Result.Author('Robert Leaman'), arxiv.Result.Author('Alexis Allot'), arxiv.Result.Author('Ling Luo'), arxiv.Result.Author('Chih-Hsuan Wei'), arxiv.Result.Author('Shankai Yan'), arxiv.Result.Author('Zhiyong Lu')]","The COVID-19 pandemic has had a significant impact on society, both because
of the serious health effects of COVID-19 and because of public health measures
implemented to slow its spread. Many of these difficulties are fundamentally
information needs; attempts to address these needs have caused an information
overload for both researchers and the public. Natural language processing
(NLP), the branch of artificial intelligence that interprets human language,
can be applied to address many of the information needs made urgent by the
COVID-19 pandemic. This review surveys approximately 150 NLP studies and more
than 50 systems and datasets addressing the COVID-19 pandemic. We detail work
on four core NLP tasks: information retrieval, named entity recognition,
literature-based discovery, and question answering. We also describe work that
directly addresses aspects of the pandemic through four additional tasks: topic
modeling, sentiment and emotion analysis, caseload forecasting, and
misinformation detection. We conclude by discussing observable trends and
remaining challenges.","51 pages, 3 figures and 2 tables; published at the Annual Review of
  Biomedical Data Science",Annual Review of Biomedical Data Science 4 (2021),10.1146/annurev-biodatasci-021821-061045,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1146/annurev-biodatasci-021821-061045', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.16413v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.16413v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.16413v3,"{'id': 'http://arxiv.org/abs/2010.16413v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.16413v3', 'updated': '2021-09-05T20:27:35Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=5, tm_hour=20, tm_min=27, tm_sec=35, tm_wday=6, tm_yday=248, tm_isdst=0), 'published': '2020-10-09T22:10:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=9, tm_hour=22, tm_min=10, tm_sec=43, tm_wday=4, tm_yday=283, tm_isdst=0), 'title': 'Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic\n  with Natural Language Processing (NLP)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic\n  with Natural Language Processing (NLP)'}, 'summary': 'The COVID-19 pandemic has had a significant impact on society, both because\nof the serious health effects of COVID-19 and because of public health measures\nimplemented to slow its spread. Many of these difficulties are fundamentally\ninformation needs; attempts to address these needs have caused an information\noverload for both researchers and the public. Natural language processing\n(NLP), the branch of artificial intelligence that interprets human language,\ncan be applied to address many of the information needs made urgent by the\nCOVID-19 pandemic. This review surveys approximately 150 NLP studies and more\nthan 50 systems and datasets addressing the COVID-19 pandemic. We detail work\non four core NLP tasks: information retrieval, named entity recognition,\nliterature-based discovery, and question answering. We also describe work that\ndirectly addresses aspects of the pandemic through four additional tasks: topic\nmodeling, sentiment and emotion analysis, caseload forecasting, and\nmisinformation detection. We conclude by discussing observable trends and\nremaining challenges.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has had a significant impact on society, both because\nof the serious health effects of COVID-19 and because of public health measures\nimplemented to slow its spread. Many of these difficulties are fundamentally\ninformation needs; attempts to address these needs have caused an information\noverload for both researchers and the public. Natural language processing\n(NLP), the branch of artificial intelligence that interprets human language,\ncan be applied to address many of the information needs made urgent by the\nCOVID-19 pandemic. This review surveys approximately 150 NLP studies and more\nthan 50 systems and datasets addressing the COVID-19 pandemic. We detail work\non four core NLP tasks: information retrieval, named entity recognition,\nliterature-based discovery, and question answering. We also describe work that\ndirectly addresses aspects of the pandemic through four additional tasks: topic\nmodeling, sentiment and emotion analysis, caseload forecasting, and\nmisinformation detection. We conclude by discussing observable trends and\nremaining challenges.'}, 'authors': [{'name': 'Qingyu Chen'}, {'name': 'Robert Leaman'}, {'name': 'Alexis Allot'}, {'name': 'Ling Luo'}, {'name': 'Chih-Hsuan Wei'}, {'name': 'Shankai Yan'}, {'name': 'Zhiyong Lu'}], 'author_detail': {'name': 'Zhiyong Lu'}, 'author': 'Zhiyong Lu', 'arxiv_doi': '10.1146/annurev-biodatasci-021821-061045', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1146/annurev-biodatasci-021821-061045', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.16413v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.16413v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '51 pages, 3 figures and 2 tables; published at the Annual Review of\n  Biomedical Data Science', 'arxiv_journal_ref': 'Annual Review of Biomedical Data Science 4 (2021)', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
210,http://arxiv.org/abs/2010.03159v1,2020-10-07 04:55:34+00:00,2020-10-07 04:55:34+00:00,Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","Although many fact-checking systems have been developed in academia and
industry, fake news is still proliferating on social media. These systems
mostly focus on fact-checking but usually neglect online users who are the main
drivers of the spread of misinformation. How can we use fact-checked
information to improve users' consciousness of fake news to which they are
exposed? How can we stop users from spreading fake news? To tackle these
questions, we propose a novel framework to search for fact-checking articles,
which address the content of an original tweet (that may contain
misinformation) posted by online users. The search can directly warn fake news
posters and online users (e.g. the posters' followers) about misinformation,
discourage them from spreading fake news, and scale up verified content on
social media. Our framework uses both text and images to search for
fact-checking articles, and achieves promising results on real-world datasets.
Our code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.","Full paper, EMNLP 2020",,,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2010.03159v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.03159v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.03159v1,"{'id': 'http://arxiv.org/abs/2010.03159v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.03159v1', 'updated': '2020-10-07T04:55:34Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=4, tm_min=55, tm_sec=34, tm_wday=2, tm_yday=281, tm_isdst=0), 'published': '2020-10-07T04:55:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=4, tm_min=55, tm_sec=34, tm_wday=2, tm_yday=281, tm_isdst=0), 'title': 'Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News'}, 'summary': ""Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.""}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'Full paper, EMNLP 2020', 'links': [{'href': 'http://arxiv.org/abs/2010.03159v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.03159v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
211,http://arxiv.org/abs/2010.02097v1,2020-10-05 15:34:52+00:00,2020-10-05 15:34:52+00:00,FaNDS: Fake News Detection System Using Energy Flow,"[arxiv.Result.Author('Jiawei Xu'), arxiv.Result.Author('Vladimir Zadorozhny'), arxiv.Result.Author('Danchen Zhang'), arxiv.Result.Author('John Grant')]","Recently, the term ""fake news"" has been broadly and extensively utilized for
disinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,
and junk news. It has become a serious problem around the world. We present a
new system, FaNDS, that detects fake news efficiently. The system is based on
several concepts used in some previous works but in a different context. There
are two main concepts: an Inconsistency Graph and Energy Flow. The
Inconsistency Graph contains news items as nodes and inconsistent opinions
between them for edges. Energy Flow assigns each node an initial energy and
then some energy is propagated along the edges until the energy distribution on
all nodes converges. To illustrate FaNDS we use the original data from the Fake
News Challenge (FNC-1). First, the data has to be reconstructed in order to
generate the Inconsistency Graph. The graph contains various subgraphs with
well-defined shapes that represent different types of connections between the
news items. Then the Energy Flow method is applied. The nodes with high energy
are the candidates for being fake news. In our experiments, all these were
indeed fake news as we checked each using several reliable web sites. We
compared FaNDS to several other fake news detection methods and found it to be
more sensitive in discovering fake news items.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.02097v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.02097v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.02097v1,"{'id': 'http://arxiv.org/abs/2010.02097v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.02097v1', 'updated': '2020-10-05T15:34:52Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=15, tm_min=34, tm_sec=52, tm_wday=0, tm_yday=279, tm_isdst=0), 'published': '2020-10-05T15:34:52Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=15, tm_min=34, tm_sec=52, tm_wday=0, tm_yday=279, tm_isdst=0), 'title': 'FaNDS: Fake News Detection System Using Energy Flow', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FaNDS: Fake News Detection System Using Energy Flow'}, 'summary': 'Recently, the term ""fake news"" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, the term ""fake news"" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.'}, 'authors': [{'name': 'Jiawei Xu'}, {'name': 'Vladimir Zadorozhny'}, {'name': 'Danchen Zhang'}, {'name': 'John Grant'}], 'author_detail': {'name': 'John Grant'}, 'author': 'John Grant', 'links': [{'href': 'http://arxiv.org/abs/2010.02097v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.02097v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
212,http://arxiv.org/abs/2010.01913v2,2021-02-23 12:00:09+00:00,2020-10-05 10:49:32+00:00,Flow of online misinformation during the peak of the COVID-19 pandemic in Italy,"[arxiv.Result.Author('Guido Caldarelli'), arxiv.Result.Author('Rocco de Nicola'), arxiv.Result.Author('Marinella Petrocchi'), arxiv.Result.Author('Manuel Pratelli'), arxiv.Result.Author('Fabio Saracco')]","The COVID-19 pandemic has impacted on every human activity and, because of
the urgency of finding the proper responses to such an unprecedented emergency,
it generated a diffused societal debate. The online version of this discussion
was not exempted by the presence of d/misinformation campaigns, but differently
from what already witnessed in other debates, the COVID-19 -- intentional or
not -- flow of false information put at severe risk the public health, reducing
the effectiveness of governments' countermeasures. In the present manuscript,
we study the effective impact of misinformation in the Italian societal debate
on Twitter during the pandemic, focusing on the various discursive communities.
In order to extract the discursive communities, we focus on verified users,
i.e. accounts whose identity is officially certified by Twitter. We thus infer
the various discursive communities based on how verified users are perceived by
standard ones: if two verified accounts are considered as similar by non
unverified ones, we link them in the network of certified accounts. We first
observe that, beside being a mostly scientific subject, the COVID-19 discussion
show a clear division in what results to be different political groups. At this
point, by using a commonly available fact-checking software (NewsGuard), we
assess the reputation of the pieces of news exchanged. We filter the network of
retweets (i.e. users re-broadcasting the same elementary piece of information,
or tweet) from random noise and check the presence of messages displaying an
url. The impact of misinformation posts reaches the 22.1% in the right and
center-right wing community and its contribution is even stronger in absolute
numbers, due to the activity of this group: 96% of all non reputable urls
shared by political groups come from this community.","25 pages, 4 figures. The Abstract, the Introduction, the Results, the
  Conclusions and the Methods were substantially rewritten. The plot of the
  network have been changed, as well as tables","EPJ Data Sci. 10, 34 (2021)",10.1140/epjds/s13688-021-00289-4,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1140/epjds/s13688-021-00289-4', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.01913v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.01913v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.01913v2,"{'id': 'http://arxiv.org/abs/2010.01913v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.01913v2', 'updated': '2021-02-23T12:00:09Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=23, tm_hour=12, tm_min=0, tm_sec=9, tm_wday=1, tm_yday=54, tm_isdst=0), 'published': '2020-10-05T10:49:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=5, tm_hour=10, tm_min=49, tm_sec=32, tm_wday=0, tm_yday=279, tm_isdst=0), 'title': 'Flow of online misinformation during the peak of the COVID-19 pandemic\n  in Italy', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Flow of online misinformation during the peak of the COVID-19 pandemic\n  in Italy'}, 'summary': ""The COVID-19 pandemic has impacted on every human activity and, because of\nthe urgency of finding the proper responses to such an unprecedented emergency,\nit generated a diffused societal debate. The online version of this discussion\nwas not exempted by the presence of d/misinformation campaigns, but differently\nfrom what already witnessed in other debates, the COVID-19 -- intentional or\nnot -- flow of false information put at severe risk the public health, reducing\nthe effectiveness of governments' countermeasures. In the present manuscript,\nwe study the effective impact of misinformation in the Italian societal debate\non Twitter during the pandemic, focusing on the various discursive communities.\nIn order to extract the discursive communities, we focus on verified users,\ni.e. accounts whose identity is officially certified by Twitter. We thus infer\nthe various discursive communities based on how verified users are perceived by\nstandard ones: if two verified accounts are considered as similar by non\nunverified ones, we link them in the network of certified accounts. We first\nobserve that, beside being a mostly scientific subject, the COVID-19 discussion\nshow a clear division in what results to be different political groups. At this\npoint, by using a commonly available fact-checking software (NewsGuard), we\nassess the reputation of the pieces of news exchanged. We filter the network of\nretweets (i.e. users re-broadcasting the same elementary piece of information,\nor tweet) from random noise and check the presence of messages displaying an\nurl. The impact of misinformation posts reaches the 22.1% in the right and\ncenter-right wing community and its contribution is even stronger in absolute\nnumbers, due to the activity of this group: 96% of all non reputable urls\nshared by political groups come from this community."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The COVID-19 pandemic has impacted on every human activity and, because of\nthe urgency of finding the proper responses to such an unprecedented emergency,\nit generated a diffused societal debate. The online version of this discussion\nwas not exempted by the presence of d/misinformation campaigns, but differently\nfrom what already witnessed in other debates, the COVID-19 -- intentional or\nnot -- flow of false information put at severe risk the public health, reducing\nthe effectiveness of governments' countermeasures. In the present manuscript,\nwe study the effective impact of misinformation in the Italian societal debate\non Twitter during the pandemic, focusing on the various discursive communities.\nIn order to extract the discursive communities, we focus on verified users,\ni.e. accounts whose identity is officially certified by Twitter. We thus infer\nthe various discursive communities based on how verified users are perceived by\nstandard ones: if two verified accounts are considered as similar by non\nunverified ones, we link them in the network of certified accounts. We first\nobserve that, beside being a mostly scientific subject, the COVID-19 discussion\nshow a clear division in what results to be different political groups. At this\npoint, by using a commonly available fact-checking software (NewsGuard), we\nassess the reputation of the pieces of news exchanged. We filter the network of\nretweets (i.e. users re-broadcasting the same elementary piece of information,\nor tweet) from random noise and check the presence of messages displaying an\nurl. The impact of misinformation posts reaches the 22.1% in the right and\ncenter-right wing community and its contribution is even stronger in absolute\nnumbers, due to the activity of this group: 96% of all non reputable urls\nshared by political groups come from this community.""}, 'authors': [{'name': 'Guido Caldarelli'}, {'name': 'Rocco de Nicola'}, {'name': 'Marinella Petrocchi'}, {'name': 'Manuel Pratelli'}, {'name': 'Fabio Saracco'}], 'author_detail': {'name': 'Fabio Saracco'}, 'author': 'Fabio Saracco', 'arxiv_doi': '10.1140/epjds/s13688-021-00289-4', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1140/epjds/s13688-021-00289-4', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.01913v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.01913v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '25 pages, 4 figures. The Abstract, the Introduction, the Results, the\n  Conclusions and the Methods were substantially rewritten. The plot of the\n  network have been changed, as well as tables', 'arxiv_journal_ref': 'EPJ Data Sci. 10, 34 (2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
213,http://arxiv.org/abs/2010.01462v2,2021-01-21 13:55:23+00:00,2020-10-04 01:36:14+00:00,"Right and left, partisanship predicts (asymmetric) vulnerability to misinformation","[arxiv.Result.Author('Dimitar Nikolov'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","We analyze the relationship between partisanship, echo chambers, and
vulnerability to online misinformation by studying news sharing behavior on
Twitter. While our results confirm prior findings that online misinformation
sharing is strongly correlated with right-leaning partisanship, we also uncover
a similar, though weaker trend among left-leaning users. Because of the
correlation between a user's partisanship and their position within a partisan
echo chamber, these types of influence are confounded. To disentangle their
effects, we perform a regression analysis and find that vulnerability to
misinformation is most strongly influenced by partisanship for both left- and
right-leaning users.",,"Harvard Kennedy School Misinformation Review, Volume 1, Issue 7,
  2021",10.37016/mr-2020-55,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.37016/mr-2020-55', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2010.01462v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.01462v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.01462v2,"{'id': 'http://arxiv.org/abs/2010.01462v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.01462v2', 'updated': '2021-01-21T13:55:23Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=21, tm_hour=13, tm_min=55, tm_sec=23, tm_wday=3, tm_yday=21, tm_isdst=0), 'published': '2020-10-04T01:36:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=4, tm_hour=1, tm_min=36, tm_sec=14, tm_wday=6, tm_yday=278, tm_isdst=0), 'title': 'Right and left, partisanship predicts (asymmetric) vulnerability to\n  misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Right and left, partisanship predicts (asymmetric) vulnerability to\n  misinformation'}, 'summary': ""We analyze the relationship between partisanship, echo chambers, and\nvulnerability to online misinformation by studying news sharing behavior on\nTwitter. While our results confirm prior findings that online misinformation\nsharing is strongly correlated with right-leaning partisanship, we also uncover\na similar, though weaker trend among left-leaning users. Because of the\ncorrelation between a user's partisanship and their position within a partisan\necho chamber, these types of influence are confounded. To disentangle their\neffects, we perform a regression analysis and find that vulnerability to\nmisinformation is most strongly influenced by partisanship for both left- and\nright-leaning users."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We analyze the relationship between partisanship, echo chambers, and\nvulnerability to online misinformation by studying news sharing behavior on\nTwitter. While our results confirm prior findings that online misinformation\nsharing is strongly correlated with right-leaning partisanship, we also uncover\na similar, though weaker trend among left-leaning users. Because of the\ncorrelation between a user's partisanship and their position within a partisan\necho chamber, these types of influence are confounded. To disentangle their\neffects, we perform a regression analysis and find that vulnerability to\nmisinformation is most strongly influenced by partisanship for both left- and\nright-leaning users.""}, 'authors': [{'name': 'Dimitar Nikolov'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.37016/mr-2020-55', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.37016/mr-2020-55', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2010.01462v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.01462v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Harvard Kennedy School Misinformation Review, Volume 1, Issue 7,\n  2021', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
214,http://arxiv.org/abs/2010.00600v1,2020-10-01 18:00:03+00:00,2020-10-01 18:00:03+00:00,#Election2020: The First Public Twitter Dataset on the 2020 US Presidential Election,"[arxiv.Result.Author('Emily Chen'), arxiv.Result.Author('Ashok Deb'), arxiv.Result.Author('Emilio Ferrara')]","The integrity of democratic political discourse is at the core to guarantee
free and fair elections. With social media often dictating the tones and trends
of politics-related discussion, it is of paramount important to be able to
study online chatter, especially in the run up to important voting events, like
in the case of the upcoming November 3, 2020 U.S. Presidential Election.
Limited access to social media data is often the first barrier to impede,
hinder, or slow down progress, and ultimately our understanding of online
political discourse. To mitigate this issue and try to empower the
Computational Social Science research community, we decided to publicly release
a massive-scale, longitudinal dataset of U.S. politics- and election-related
tweets. This multilingual dataset that we have been collecting for over one
year encompasses hundreds of millions of tweets and tracks all salient U.S.
politics trends, actors, and events between 2019 and 2020. It predates and
spans the whole period of Republican and Democratic primaries, with real-time
tracking of all presidential contenders of both sides of the isle. After that,
it focuses on presidential and vice-presidential candidates. Our dataset
release is curated, documented and will be constantly updated on a
weekly-basis, until the November 3, 2020 election and beyond. We hope that the
academic community, computational journalists, and research practitioners alike
will all take advantage of our dataset to study relevant scientific and social
issues, including problems like misinformation, information manipulation,
interference, and distortion of online political discourse that have been
prevalent in the context of recent election events in the United States and
worldwide.
  Our dataset is available at:
https://github.com/echen102/us-pres-elections-2020","Our dataset is available at:
  https://github.com/echen102/us-pres-elections-2020",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2010.00600v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.00600v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.00600v1,"{'id': 'http://arxiv.org/abs/2010.00600v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.00600v1', 'updated': '2020-10-01T18:00:03Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=1, tm_hour=18, tm_min=0, tm_sec=3, tm_wday=3, tm_yday=275, tm_isdst=0), 'published': '2020-10-01T18:00:03Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=1, tm_hour=18, tm_min=0, tm_sec=3, tm_wday=3, tm_yday=275, tm_isdst=0), 'title': '#Election2020: The First Public Twitter Dataset on the 2020 US\n  Presidential Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '#Election2020: The First Public Twitter Dataset on the 2020 US\n  Presidential Election'}, 'summary': 'The integrity of democratic political discourse is at the core to guarantee\nfree and fair elections. With social media often dictating the tones and trends\nof politics-related discussion, it is of paramount important to be able to\nstudy online chatter, especially in the run up to important voting events, like\nin the case of the upcoming November 3, 2020 U.S. Presidential Election.\nLimited access to social media data is often the first barrier to impede,\nhinder, or slow down progress, and ultimately our understanding of online\npolitical discourse. To mitigate this issue and try to empower the\nComputational Social Science research community, we decided to publicly release\na massive-scale, longitudinal dataset of U.S. politics- and election-related\ntweets. This multilingual dataset that we have been collecting for over one\nyear encompasses hundreds of millions of tweets and tracks all salient U.S.\npolitics trends, actors, and events between 2019 and 2020. It predates and\nspans the whole period of Republican and Democratic primaries, with real-time\ntracking of all presidential contenders of both sides of the isle. After that,\nit focuses on presidential and vice-presidential candidates. Our dataset\nrelease is curated, documented and will be constantly updated on a\nweekly-basis, until the November 3, 2020 election and beyond. We hope that the\nacademic community, computational journalists, and research practitioners alike\nwill all take advantage of our dataset to study relevant scientific and social\nissues, including problems like misinformation, information manipulation,\ninterference, and distortion of online political discourse that have been\nprevalent in the context of recent election events in the United States and\nworldwide.\n  Our dataset is available at:\nhttps://github.com/echen102/us-pres-elections-2020', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The integrity of democratic political discourse is at the core to guarantee\nfree and fair elections. With social media often dictating the tones and trends\nof politics-related discussion, it is of paramount important to be able to\nstudy online chatter, especially in the run up to important voting events, like\nin the case of the upcoming November 3, 2020 U.S. Presidential Election.\nLimited access to social media data is often the first barrier to impede,\nhinder, or slow down progress, and ultimately our understanding of online\npolitical discourse. To mitigate this issue and try to empower the\nComputational Social Science research community, we decided to publicly release\na massive-scale, longitudinal dataset of U.S. politics- and election-related\ntweets. This multilingual dataset that we have been collecting for over one\nyear encompasses hundreds of millions of tweets and tracks all salient U.S.\npolitics trends, actors, and events between 2019 and 2020. It predates and\nspans the whole period of Republican and Democratic primaries, with real-time\ntracking of all presidential contenders of both sides of the isle. After that,\nit focuses on presidential and vice-presidential candidates. Our dataset\nrelease is curated, documented and will be constantly updated on a\nweekly-basis, until the November 3, 2020 election and beyond. We hope that the\nacademic community, computational journalists, and research practitioners alike\nwill all take advantage of our dataset to study relevant scientific and social\nissues, including problems like misinformation, information manipulation,\ninterference, and distortion of online political discourse that have been\nprevalent in the context of recent election events in the United States and\nworldwide.\n  Our dataset is available at:\nhttps://github.com/echen102/us-pres-elections-2020'}, 'authors': [{'name': 'Emily Chen'}, {'name': 'Ashok Deb'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'arxiv_comment': 'Our dataset is available at:\n  https://github.com/echen102/us-pres-elections-2020', 'links': [{'href': 'http://arxiv.org/abs/2010.00600v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.00600v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
215,http://arxiv.org/abs/2010.00544v1,2020-10-01 16:58:12+00:00,2020-10-01 16:58:12+00:00,Designing Indicators to Combat Fake Media,"[arxiv.Result.Author('Imani N. Sherman'), arxiv.Result.Author('Elissa M. Redmiles'), arxiv.Result.Author('Jack W. Stokes')]","The growth of misinformation technology necessitates the need to identify
fake videos. One approach to preventing the consumption of these fake videos is
provenance which allows the user to authenticate media content to its original
source. This research designs and investigates the use of provenance indicators
to help users identify fake videos. We first interview users regarding their
experiences with different misinformation modes (text, image, video) to guide
the design of indicators within users' existing perspectives. Then, we conduct
a participatory design study to develop and design fake video indicators.
Finally, we evaluate participant-designed indicators via both expert
evaluations and quantitative surveys with a large group of end-users. Our
results provide concrete design guidelines for the emerging issue of fake
videos. Our findings also raise concerns regarding users' tendency to
overgeneralize from misinformation warning messages, suggesting the need for
further research on warning design in the ongoing fight against misinformation.","26 pages, 12 figures",,,cs.HC,"['cs.HC', 'cs.CR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2010.00544v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.00544v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.00544v1,"{'id': 'http://arxiv.org/abs/2010.00544v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.00544v1', 'updated': '2020-10-01T16:58:12Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=1, tm_hour=16, tm_min=58, tm_sec=12, tm_wday=3, tm_yday=275, tm_isdst=0), 'published': '2020-10-01T16:58:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=1, tm_hour=16, tm_min=58, tm_sec=12, tm_wday=3, tm_yday=275, tm_isdst=0), 'title': 'Designing Indicators to Combat Fake Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Designing Indicators to Combat Fake Media'}, 'summary': ""The growth of misinformation technology necessitates the need to identify\nfake videos. One approach to preventing the consumption of these fake videos is\nprovenance which allows the user to authenticate media content to its original\nsource. This research designs and investigates the use of provenance indicators\nto help users identify fake videos. We first interview users regarding their\nexperiences with different misinformation modes (text, image, video) to guide\nthe design of indicators within users' existing perspectives. Then, we conduct\na participatory design study to develop and design fake video indicators.\nFinally, we evaluate participant-designed indicators via both expert\nevaluations and quantitative surveys with a large group of end-users. Our\nresults provide concrete design guidelines for the emerging issue of fake\nvideos. Our findings also raise concerns regarding users' tendency to\novergeneralize from misinformation warning messages, suggesting the need for\nfurther research on warning design in the ongoing fight against misinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The growth of misinformation technology necessitates the need to identify\nfake videos. One approach to preventing the consumption of these fake videos is\nprovenance which allows the user to authenticate media content to its original\nsource. This research designs and investigates the use of provenance indicators\nto help users identify fake videos. We first interview users regarding their\nexperiences with different misinformation modes (text, image, video) to guide\nthe design of indicators within users' existing perspectives. Then, we conduct\na participatory design study to develop and design fake video indicators.\nFinally, we evaluate participant-designed indicators via both expert\nevaluations and quantitative surveys with a large group of end-users. Our\nresults provide concrete design guidelines for the emerging issue of fake\nvideos. Our findings also raise concerns regarding users' tendency to\novergeneralize from misinformation warning messages, suggesting the need for\nfurther research on warning design in the ongoing fight against misinformation.""}, 'authors': [{'name': 'Imani N. Sherman'}, {'name': 'Elissa M. Redmiles'}, {'name': 'Jack W. Stokes'}], 'author_detail': {'name': 'Jack W. Stokes'}, 'author': 'Jack W. Stokes', 'arxiv_comment': '26 pages, 12 figures', 'links': [{'href': 'http://arxiv.org/abs/2010.00544v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.00544v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
216,http://arxiv.org/abs/2010.00502v2,2021-08-10 11:41:16+00:00,2020-10-01 15:50:41+00:00,AMUSED: An Annotation Framework of Multi-modal Social Media Data,[arxiv.Result.Author('Gautam Kishore Shahi')],"In this paper, we present a semi-automated framework called AMUSED for
gathering multi-modal annotated data from the multiple social media platforms.
The framework is designed to mitigate the issues of collecting and annotating
social media data by cohesively combining machine and human in the data
collection process. From a given list of the articles from professional news
media or blog, AMUSED detects links to the social media posts from news
articles and then downloads contents of the same post from the respective
social media platform to gather details about that specific post. The framework
is capable of fetching the annotated data from multiple platforms like Twitter,
YouTube, Reddit. The framework aims to reduce the workload and problems behind
the data annotation from the social media platforms. AMUSED can be applied in
multiple application domains, as a use case, we have implemented the framework
for collecting COVID-19 misinformation data from different social media
platforms.","10 pages, 5 figures, 3 tables",,,cs.SI,"['cs.SI', 'cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2010.00502v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2010.00502v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2010.00502v2,"{'id': 'http://arxiv.org/abs/2010.00502v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2010.00502v2', 'updated': '2021-08-10T11:41:16Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=10, tm_hour=11, tm_min=41, tm_sec=16, tm_wday=1, tm_yday=222, tm_isdst=0), 'published': '2020-10-01T15:50:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=1, tm_hour=15, tm_min=50, tm_sec=41, tm_wday=3, tm_yday=275, tm_isdst=0), 'title': 'AMUSED: An Annotation Framework of Multi-modal Social Media Data', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AMUSED: An Annotation Framework of Multi-modal Social Media Data'}, 'summary': 'In this paper, we present a semi-automated framework called AMUSED for\ngathering multi-modal annotated data from the multiple social media platforms.\nThe framework is designed to mitigate the issues of collecting and annotating\nsocial media data by cohesively combining machine and human in the data\ncollection process. From a given list of the articles from professional news\nmedia or blog, AMUSED detects links to the social media posts from news\narticles and then downloads contents of the same post from the respective\nsocial media platform to gather details about that specific post. The framework\nis capable of fetching the annotated data from multiple platforms like Twitter,\nYouTube, Reddit. The framework aims to reduce the workload and problems behind\nthe data annotation from the social media platforms. AMUSED can be applied in\nmultiple application domains, as a use case, we have implemented the framework\nfor collecting COVID-19 misinformation data from different social media\nplatforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we present a semi-automated framework called AMUSED for\ngathering multi-modal annotated data from the multiple social media platforms.\nThe framework is designed to mitigate the issues of collecting and annotating\nsocial media data by cohesively combining machine and human in the data\ncollection process. From a given list of the articles from professional news\nmedia or blog, AMUSED detects links to the social media posts from news\narticles and then downloads contents of the same post from the respective\nsocial media platform to gather details about that specific post. The framework\nis capable of fetching the annotated data from multiple platforms like Twitter,\nYouTube, Reddit. The framework aims to reduce the workload and problems behind\nthe data annotation from the social media platforms. AMUSED can be applied in\nmultiple application domains, as a use case, we have implemented the framework\nfor collecting COVID-19 misinformation data from different social media\nplatforms.'}, 'authors': [{'name': 'Gautam Kishore Shahi'}], 'author_detail': {'name': 'Gautam Kishore Shahi'}, 'author': 'Gautam Kishore Shahi', 'arxiv_comment': '10 pages, 5 figures, 3 tables', 'links': [{'href': 'http://arxiv.org/abs/2010.00502v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2010.00502v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
217,http://arxiv.org/abs/2009.14337v1,2020-09-29 22:58:33+00:00,2020-09-29 22:58:33+00:00,StratLearner: Learning a Strategy for Misinformation Prevention in Social Networks,[arxiv.Result.Author('Guangmo Tong')],"Given a combinatorial optimization problem taking an input, can we learn a
strategy to solve it from the examples of input-solution pairs without knowing
its objective function? In this paper, we consider such a setting and study the
misinformation prevention problem. Given the examples of attacker-protector
pairs, our goal is to learn a strategy to compute protectors against future
attackers, without the need of knowing the underlying diffusion model. To this
end, we design a structured prediction framework, where the main idea is to
parameterize the scoring function using random features constructed through
distance functions on randomly sampled subgraphs, which leads to a kernelized
scoring function with weights learnable via the large margin method. Evidenced
by experiments, our method can produce near-optimal protectors without using
any information of the diffusion model, and it outperforms other possible
graph-based and learning-based methods by an evident margin.",NeurIPS'20,,,cs.LG,"['cs.LG', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2009.14337v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.14337v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.14337v1,"{'id': 'http://arxiv.org/abs/2009.14337v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.14337v1', 'updated': '2020-09-29T22:58:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=29, tm_hour=22, tm_min=58, tm_sec=33, tm_wday=1, tm_yday=273, tm_isdst=0), 'published': '2020-09-29T22:58:33Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=29, tm_hour=22, tm_min=58, tm_sec=33, tm_wday=1, tm_yday=273, tm_isdst=0), 'title': 'StratLearner: Learning a Strategy for Misinformation Prevention in\n  Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'StratLearner: Learning a Strategy for Misinformation Prevention in\n  Social Networks'}, 'summary': 'Given a combinatorial optimization problem taking an input, can we learn a\nstrategy to solve it from the examples of input-solution pairs without knowing\nits objective function? In this paper, we consider such a setting and study the\nmisinformation prevention problem. Given the examples of attacker-protector\npairs, our goal is to learn a strategy to compute protectors against future\nattackers, without the need of knowing the underlying diffusion model. To this\nend, we design a structured prediction framework, where the main idea is to\nparameterize the scoring function using random features constructed through\ndistance functions on randomly sampled subgraphs, which leads to a kernelized\nscoring function with weights learnable via the large margin method. Evidenced\nby experiments, our method can produce near-optimal protectors without using\nany information of the diffusion model, and it outperforms other possible\ngraph-based and learning-based methods by an evident margin.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Given a combinatorial optimization problem taking an input, can we learn a\nstrategy to solve it from the examples of input-solution pairs without knowing\nits objective function? In this paper, we consider such a setting and study the\nmisinformation prevention problem. Given the examples of attacker-protector\npairs, our goal is to learn a strategy to compute protectors against future\nattackers, without the need of knowing the underlying diffusion model. To this\nend, we design a structured prediction framework, where the main idea is to\nparameterize the scoring function using random features constructed through\ndistance functions on randomly sampled subgraphs, which leads to a kernelized\nscoring function with weights learnable via the large margin method. Evidenced\nby experiments, our method can produce near-optimal protectors without using\nany information of the diffusion model, and it outperforms other possible\ngraph-based and learning-based methods by an evident margin.'}, 'authors': [{'name': 'Guangmo Tong'}], 'author_detail': {'name': 'Guangmo Tong'}, 'author': 'Guangmo Tong', 'arxiv_comment': ""NeurIPS'20"", 'links': [{'href': 'http://arxiv.org/abs/2009.14337v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.14337v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
218,http://arxiv.org/abs/2009.13859v1,2020-09-29 08:32:32+00:00,2020-09-29 08:32:32+00:00,Fake News Spreader Detection on Twitter using Character N-Grams. Notebook for PAN at CLEF 2020,"[arxiv.Result.Author('Inna Vogel'), arxiv.Result.Author('Meghana Meghana')]","The authors of fake news often use facts from verified news sources and mix
them with misinformation to create confusion and provoke unrest among the
readers. The spread of fake news can thereby have serious implications on our
society. They can sway political elections, push down the stock price or crush
reputations of corporations or public figures. Several websites have taken on
the mission of checking rumors and allegations, but are often not fast enough
to check the content of all the news being disseminated. Especially social
media websites have offered an easy platform for the fast propagation of
information. Towards limiting fake news from being propagated among social
media users, the task of this year's PAN 2020 challenge lays the focus on the
fake news spreaders. The aim of the task is to determine whether it is possible
to discriminate authors that have shared fake news in the past from those that
have never done it. In this notebook, we describe our profiling system for the
fake news detection task on Twitter. For this, we conduct different feature
extraction techniques and learning experiments from a multilingual perspective,
namely English and Spanish. Our final submitted systems use character n-grams
as features in combination with a linear SVM for English and Logistic
Regression for the Spanish language. Our submitted models achieve an overall
accuracy of 73% and 79% on the English and Spanish official test set,
respectively. Our experiments show that it is difficult to differentiate
solidly fake news spreaders on Twitter from users who share credible
information leaving room for further investigations. Our model ranked 3rd out
of 72 competitors.","CLEF 2020 Labs and Workshops, Notebook Papers",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2009.13859v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.13859v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.13859v1,"{'id': 'http://arxiv.org/abs/2009.13859v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.13859v1', 'updated': '2020-09-29T08:32:32Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=29, tm_hour=8, tm_min=32, tm_sec=32, tm_wday=1, tm_yday=273, tm_isdst=0), 'published': '2020-09-29T08:32:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=29, tm_hour=8, tm_min=32, tm_sec=32, tm_wday=1, tm_yday=273, tm_isdst=0), 'title': 'Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020'}, 'summary': ""The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.""}, 'authors': [{'name': 'Inna Vogel'}, {'name': 'Meghana Meghana'}], 'author_detail': {'name': 'Meghana Meghana'}, 'author': 'Meghana Meghana', 'arxiv_comment': 'CLEF 2020 Labs and Workshops, Notebook Papers', 'links': [{'href': 'http://arxiv.org/abs/2009.13859v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.13859v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
219,http://arxiv.org/abs/2009.13375v3,2021-04-25 09:39:20+00:00,2020-09-28 14:48:27+00:00,Identifying Automatically Generated Headlines using Transformers,"[arxiv.Result.Author('Antonis Maronikolakis'), arxiv.Result.Author('Hinrich Schutze'), arxiv.Result.Author('Mark Stevenson')]","False information spread via the internet and social media influences public
opinion and user activity, while generative models enable fake content to be
generated faster and more cheaply than had previously been possible. In the not
so distant future, identifying fake content generated by deep learning models
will play a key role in protecting users from misinformation. To this end, a
dataset containing human and computer-generated headlines was created and a
user study indicated that humans were only able to identify the fake headlines
in 47.8% of the cases. However, the most accurate automatic approach,
transformers, achieved an overall accuracy of 85.7%, indicating that content
generated from language models can be filtered out accurately.","NLP4IF 2021 Proceedings, NAACL 2021",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2009.13375v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.13375v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.13375v3,"{'id': 'http://arxiv.org/abs/2009.13375v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.13375v3', 'updated': '2021-04-25T09:39:20Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=25, tm_hour=9, tm_min=39, tm_sec=20, tm_wday=6, tm_yday=115, tm_isdst=0), 'published': '2020-09-28T14:48:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=28, tm_hour=14, tm_min=48, tm_sec=27, tm_wday=0, tm_yday=272, tm_isdst=0), 'title': 'Identifying Automatically Generated Headlines using Transformers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Automatically Generated Headlines using Transformers'}, 'summary': 'False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.'}, 'authors': [{'name': 'Antonis Maronikolakis'}, {'name': 'Hinrich Schutze'}, {'name': 'Mark Stevenson'}], 'author_detail': {'name': 'Mark Stevenson'}, 'author': 'Mark Stevenson', 'arxiv_comment': 'NLP4IF 2021 Proceedings, NAACL 2021', 'links': [{'href': 'http://arxiv.org/abs/2009.13375v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.13375v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
220,http://arxiv.org/abs/2009.12905v1,2020-09-27 17:38:54+00:00,2020-09-27 17:38:54+00:00,COVID-19's (mis)information ecosystem on Twitter: How partisanship boosts the spread of conspiracy narratives on German speaking Twitter,"[arxiv.Result.Author('Morteza Shahrezaye'), arxiv.Result.Author('Miriam Meckel'), arxiv.Result.Author('Léa Steinacker'), arxiv.Result.Author('Viktor Suter')]","In late 2019, the gravest pandemic in a century began spreading across the
world. A state of uncertainty related to what has become known as SARS-CoV-2
has since fueled conspiracy narratives on social media about the origin,
transmission and medical treatment of and vaccination against the resulting
disease, COVID-19. Using social media intelligence to monitor and understand
the proliferation of conspiracy narratives is one way to analyze the
distribution of misinformation on the pandemic. We analyzed more than 9.5M
German language tweets about COVID-19. The results show that only about 0.6% of
all those tweets deal with conspiracy theory narratives. We also found that the
political orientation of users correlates with the volume of content users
contribute to the dissemination of conspiracy narratives, implying that
partisan communicators have a higher motivation to take part in conspiratorial
discussions on Twitter. Finally, we showed that contrary to other studies,
automated accounts do not significantly influence the spread of misinformation
in the German speaking Twitter sphere. They only represent about 1.31% of all
conspiracy-related activities in our database.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2009.12905v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.12905v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.12905v1,"{'id': 'http://arxiv.org/abs/2009.12905v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.12905v1', 'updated': '2020-09-27T17:38:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=27, tm_hour=17, tm_min=38, tm_sec=54, tm_wday=6, tm_yday=271, tm_isdst=0), 'published': '2020-09-27T17:38:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=27, tm_hour=17, tm_min=38, tm_sec=54, tm_wday=6, tm_yday=271, tm_isdst=0), 'title': ""COVID-19's (mis)information ecosystem on Twitter: How partisanship\n  boosts the spread of conspiracy narratives on German speaking Twitter"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""COVID-19's (mis)information ecosystem on Twitter: How partisanship\n  boosts the spread of conspiracy narratives on German speaking Twitter""}, 'summary': 'In late 2019, the gravest pandemic in a century began spreading across the\nworld. A state of uncertainty related to what has become known as SARS-CoV-2\nhas since fueled conspiracy narratives on social media about the origin,\ntransmission and medical treatment of and vaccination against the resulting\ndisease, COVID-19. Using social media intelligence to monitor and understand\nthe proliferation of conspiracy narratives is one way to analyze the\ndistribution of misinformation on the pandemic. We analyzed more than 9.5M\nGerman language tweets about COVID-19. The results show that only about 0.6% of\nall those tweets deal with conspiracy theory narratives. We also found that the\npolitical orientation of users correlates with the volume of content users\ncontribute to the dissemination of conspiracy narratives, implying that\npartisan communicators have a higher motivation to take part in conspiratorial\ndiscussions on Twitter. Finally, we showed that contrary to other studies,\nautomated accounts do not significantly influence the spread of misinformation\nin the German speaking Twitter sphere. They only represent about 1.31% of all\nconspiracy-related activities in our database.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In late 2019, the gravest pandemic in a century began spreading across the\nworld. A state of uncertainty related to what has become known as SARS-CoV-2\nhas since fueled conspiracy narratives on social media about the origin,\ntransmission and medical treatment of and vaccination against the resulting\ndisease, COVID-19. Using social media intelligence to monitor and understand\nthe proliferation of conspiracy narratives is one way to analyze the\ndistribution of misinformation on the pandemic. We analyzed more than 9.5M\nGerman language tweets about COVID-19. The results show that only about 0.6% of\nall those tweets deal with conspiracy theory narratives. We also found that the\npolitical orientation of users correlates with the volume of content users\ncontribute to the dissemination of conspiracy narratives, implying that\npartisan communicators have a higher motivation to take part in conspiratorial\ndiscussions on Twitter. Finally, we showed that contrary to other studies,\nautomated accounts do not significantly influence the spread of misinformation\nin the German speaking Twitter sphere. They only represent about 1.31% of all\nconspiracy-related activities in our database.'}, 'authors': [{'name': 'Morteza Shahrezaye'}, {'name': 'Miriam Meckel'}, {'name': 'Léa Steinacker'}, {'name': 'Viktor Suter'}], 'author_detail': {'name': 'Viktor Suter'}, 'author': 'Viktor Suter', 'links': [{'href': 'http://arxiv.org/abs/2009.12905v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.12905v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
221,http://arxiv.org/abs/2009.12468v1,2020-09-25 22:48:51+00:00,2020-09-25 22:48:51+00:00,Investigating Misinformation in Online Marketplaces: An Audit Study on Amazon,"[arxiv.Result.Author('Eslam Hussein'), arxiv.Result.Author('Hoda Eldardiry')]","Search and recommendation systems are ubiquitous and irreplaceable tools in
our daily lives. Despite their critical role in selecting and ranking the most
relevant information, they typically do not consider the veracity of
information presented to the user. In this paper, we introduce an audit
methodology to investigate the extent of misinformation presented in search
results and recommendations on online marketplaces. We investigate the factors
and personalization attributes that influence the amount of misinformation in
searches and recommendations. Recently, several media reports criticized Amazon
for hosting and recommending items that promote misinformation on topics such
as vaccines. Motivated by those reports, we apply our algorithmic auditing
methodology on Amazon to verify those claims. Our audit study investigates (a)
factors that might influence the search algorithms of Amazon and (b)
personalization attributes that contribute to amplifying the amount of
misinformation recommended to users in their search results and
recommendations. Our audit study collected ~526k search results and ~182k
homepage recommendations, with ~8.5k unique items. Each item is annotated for
its stance on vaccines' misinformation (pro, neutral, or anti). Our study
reveals that (1) the selection and ranking by the default Featured search
algorithm of search results that have misinformation stances are positively
correlated with the stance of search queries and customers' evaluation of items
(ratings and reviews), (2) misinformation stances of search results are neither
affected by users' activities nor by interacting (browsing, wish-listing,
shopping) with items that have a misinformation stance, and (3) a filter bubble
built-in users' homepages have a misinformation stance positively correlated
with the misinformation stance of items that a user interacts with.","8 pages, 9 figures, submitted to ASONAM",,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2009.12468v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.12468v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.12468v1,"{'id': 'http://arxiv.org/abs/2009.12468v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.12468v1', 'updated': '2020-09-25T22:48:51Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=25, tm_hour=22, tm_min=48, tm_sec=51, tm_wday=4, tm_yday=269, tm_isdst=0), 'published': '2020-09-25T22:48:51Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=25, tm_hour=22, tm_min=48, tm_sec=51, tm_wday=4, tm_yday=269, tm_isdst=0), 'title': 'Investigating Misinformation in Online Marketplaces: An Audit Study on\n  Amazon', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Misinformation in Online Marketplaces: An Audit Study on\n  Amazon'}, 'summary': ""Search and recommendation systems are ubiquitous and irreplaceable tools in\nour daily lives. Despite their critical role in selecting and ranking the most\nrelevant information, they typically do not consider the veracity of\ninformation presented to the user. In this paper, we introduce an audit\nmethodology to investigate the extent of misinformation presented in search\nresults and recommendations on online marketplaces. We investigate the factors\nand personalization attributes that influence the amount of misinformation in\nsearches and recommendations. Recently, several media reports criticized Amazon\nfor hosting and recommending items that promote misinformation on topics such\nas vaccines. Motivated by those reports, we apply our algorithmic auditing\nmethodology on Amazon to verify those claims. Our audit study investigates (a)\nfactors that might influence the search algorithms of Amazon and (b)\npersonalization attributes that contribute to amplifying the amount of\nmisinformation recommended to users in their search results and\nrecommendations. Our audit study collected ~526k search results and ~182k\nhomepage recommendations, with ~8.5k unique items. Each item is annotated for\nits stance on vaccines' misinformation (pro, neutral, or anti). Our study\nreveals that (1) the selection and ranking by the default Featured search\nalgorithm of search results that have misinformation stances are positively\ncorrelated with the stance of search queries and customers' evaluation of items\n(ratings and reviews), (2) misinformation stances of search results are neither\naffected by users' activities nor by interacting (browsing, wish-listing,\nshopping) with items that have a misinformation stance, and (3) a filter bubble\nbuilt-in users' homepages have a misinformation stance positively correlated\nwith the misinformation stance of items that a user interacts with."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Search and recommendation systems are ubiquitous and irreplaceable tools in\nour daily lives. Despite their critical role in selecting and ranking the most\nrelevant information, they typically do not consider the veracity of\ninformation presented to the user. In this paper, we introduce an audit\nmethodology to investigate the extent of misinformation presented in search\nresults and recommendations on online marketplaces. We investigate the factors\nand personalization attributes that influence the amount of misinformation in\nsearches and recommendations. Recently, several media reports criticized Amazon\nfor hosting and recommending items that promote misinformation on topics such\nas vaccines. Motivated by those reports, we apply our algorithmic auditing\nmethodology on Amazon to verify those claims. Our audit study investigates (a)\nfactors that might influence the search algorithms of Amazon and (b)\npersonalization attributes that contribute to amplifying the amount of\nmisinformation recommended to users in their search results and\nrecommendations. Our audit study collected ~526k search results and ~182k\nhomepage recommendations, with ~8.5k unique items. Each item is annotated for\nits stance on vaccines' misinformation (pro, neutral, or anti). Our study\nreveals that (1) the selection and ranking by the default Featured search\nalgorithm of search results that have misinformation stances are positively\ncorrelated with the stance of search queries and customers' evaluation of items\n(ratings and reviews), (2) misinformation stances of search results are neither\naffected by users' activities nor by interacting (browsing, wish-listing,\nshopping) with items that have a misinformation stance, and (3) a filter bubble\nbuilt-in users' homepages have a misinformation stance positively correlated\nwith the misinformation stance of items that a user interacts with.""}, 'authors': [{'name': 'Eslam Hussein'}, {'name': 'Hoda Eldardiry'}], 'author_detail': {'name': 'Hoda Eldardiry'}, 'author': 'Hoda Eldardiry', 'arxiv_comment': '8 pages, 9 figures, submitted to ASONAM', 'links': [{'href': 'http://arxiv.org/abs/2009.12468v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.12468v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
222,http://arxiv.org/abs/2009.11744v2,2020-10-08 07:24:45+00:00,2020-09-24 15:09:09+00:00,Anatomy of a Rumour: Social media and the suicide of Sushant Singh Rajput,"[arxiv.Result.Author('Syeda Zainab Akbar'), arxiv.Result.Author('Ankur Sharma'), arxiv.Result.Author('Himani Negi'), arxiv.Result.Author('Anmol Panda'), arxiv.Result.Author('Joyojeet Pal')]","The suicide of Indian actor Sushant Singh Rajput in the midst of the COVID-19
lockdown triggered a media frenzy of prime time coverage that lasted several
months and became a political hot button issue. Using data from Twitter,
YouTube, and an archive of debunked misinformation stories, we found two
important patterns. First, that retweet rates on Twitter clearly suggest that
commentators benefited from talking about the case, which got higher engagement
than other topics. Second, that politicians, in particular, were instrumental
in changing the course of the discourse by referring to the case as 'murder',
rather than 'suicide'. In conclusion, we consider the effects of Rajput's
outsider status as a small-town implant in the film industry within the broader
narrative of systemic injustice, as well as the gendered aspects of mob justice
that have taken aim at his former partner in the months since.","14 pages, 16 figures. For any queries regarding the paper, please
  email Joyojeet Pal (Joyojeet.Pal@microsoft.com)",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2009.11744v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.11744v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.11744v2,"{'id': 'http://arxiv.org/abs/2009.11744v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.11744v2', 'updated': '2020-10-08T07:24:45Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=8, tm_hour=7, tm_min=24, tm_sec=45, tm_wday=3, tm_yday=282, tm_isdst=0), 'published': '2020-09-24T15:09:09Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=24, tm_hour=15, tm_min=9, tm_sec=9, tm_wday=3, tm_yday=268, tm_isdst=0), 'title': 'Anatomy of a Rumour: Social media and the suicide of Sushant Singh\n  Rajput', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Anatomy of a Rumour: Social media and the suicide of Sushant Singh\n  Rajput'}, 'summary': ""The suicide of Indian actor Sushant Singh Rajput in the midst of the COVID-19\nlockdown triggered a media frenzy of prime time coverage that lasted several\nmonths and became a political hot button issue. Using data from Twitter,\nYouTube, and an archive of debunked misinformation stories, we found two\nimportant patterns. First, that retweet rates on Twitter clearly suggest that\ncommentators benefited from talking about the case, which got higher engagement\nthan other topics. Second, that politicians, in particular, were instrumental\nin changing the course of the discourse by referring to the case as 'murder',\nrather than 'suicide'. In conclusion, we consider the effects of Rajput's\noutsider status as a small-town implant in the film industry within the broader\nnarrative of systemic injustice, as well as the gendered aspects of mob justice\nthat have taken aim at his former partner in the months since."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The suicide of Indian actor Sushant Singh Rajput in the midst of the COVID-19\nlockdown triggered a media frenzy of prime time coverage that lasted several\nmonths and became a political hot button issue. Using data from Twitter,\nYouTube, and an archive of debunked misinformation stories, we found two\nimportant patterns. First, that retweet rates on Twitter clearly suggest that\ncommentators benefited from talking about the case, which got higher engagement\nthan other topics. Second, that politicians, in particular, were instrumental\nin changing the course of the discourse by referring to the case as 'murder',\nrather than 'suicide'. In conclusion, we consider the effects of Rajput's\noutsider status as a small-town implant in the film industry within the broader\nnarrative of systemic injustice, as well as the gendered aspects of mob justice\nthat have taken aim at his former partner in the months since.""}, 'authors': [{'name': 'Syeda Zainab Akbar'}, {'name': 'Ankur Sharma'}, {'name': 'Himani Negi'}, {'name': 'Anmol Panda'}, {'name': 'Joyojeet Pal'}], 'author_detail': {'name': 'Joyojeet Pal'}, 'author': 'Joyojeet Pal', 'arxiv_comment': '14 pages, 16 figures. For any queries regarding the paper, please\n  email Joyojeet Pal (Joyojeet.Pal@microsoft.com)', 'links': [{'href': 'http://arxiv.org/abs/2009.11744v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.11744v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
223,http://arxiv.org/abs/2009.10311v3,2020-09-25 17:55:20+00:00,2020-09-22 04:32:24+00:00,Preserving Integrity in Online Social Networks,"[arxiv.Result.Author('Alon Halevy'), arxiv.Result.Author('Cristian Canton Ferrer'), arxiv.Result.Author('Hao Ma'), arxiv.Result.Author('Umut Ozertem'), arxiv.Result.Author('Patrick Pantel'), arxiv.Result.Author('Marzieh Saeidi'), arxiv.Result.Author('Fabrizio Silvestri'), arxiv.Result.Author('Ves Stoyanov')]","Online social networks provide a platform for sharing information and free
expression. However, these networks are also used for malicious purposes, such
as distributing misinformation and hate speech, selling illegal drugs, and
coordinating sex trafficking or child exploitation. This paper surveys the
state of the art in keeping online platforms and their users safe from such
harm, also known as the problem of preserving integrity. This survey comes from
the perspective of having to combat a broad spectrum of integrity violations at
Facebook. We highlight the techniques that have been proven useful in practice
and that deserve additional attention from the academic community. Instead of
discussing the many individual violation types, we identify key aspects of the
social-media eco-system, each of which is common to a wide variety violation
types. Furthermore, each of these components represents an area for research
and development, and the innovations that are found can be applied widely.",,,,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2009.10311v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.10311v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.10311v3,"{'id': 'http://arxiv.org/abs/2009.10311v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.10311v3', 'updated': '2020-09-25T17:55:20Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=25, tm_hour=17, tm_min=55, tm_sec=20, tm_wday=4, tm_yday=269, tm_isdst=0), 'published': '2020-09-22T04:32:24Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=22, tm_hour=4, tm_min=32, tm_sec=24, tm_wday=1, tm_yday=266, tm_isdst=0), 'title': 'Preserving Integrity in Online Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Preserving Integrity in Online Social Networks'}, 'summary': 'Online social networks provide a platform for sharing information and free\nexpression. However, these networks are also used for malicious purposes, such\nas distributing misinformation and hate speech, selling illegal drugs, and\ncoordinating sex trafficking or child exploitation. This paper surveys the\nstate of the art in keeping online platforms and their users safe from such\nharm, also known as the problem of preserving integrity. This survey comes from\nthe perspective of having to combat a broad spectrum of integrity violations at\nFacebook. We highlight the techniques that have been proven useful in practice\nand that deserve additional attention from the academic community. Instead of\ndiscussing the many individual violation types, we identify key aspects of the\nsocial-media eco-system, each of which is common to a wide variety violation\ntypes. Furthermore, each of these components represents an area for research\nand development, and the innovations that are found can be applied widely.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online social networks provide a platform for sharing information and free\nexpression. However, these networks are also used for malicious purposes, such\nas distributing misinformation and hate speech, selling illegal drugs, and\ncoordinating sex trafficking or child exploitation. This paper surveys the\nstate of the art in keeping online platforms and their users safe from such\nharm, also known as the problem of preserving integrity. This survey comes from\nthe perspective of having to combat a broad spectrum of integrity violations at\nFacebook. We highlight the techniques that have been proven useful in practice\nand that deserve additional attention from the academic community. Instead of\ndiscussing the many individual violation types, we identify key aspects of the\nsocial-media eco-system, each of which is common to a wide variety violation\ntypes. Furthermore, each of these components represents an area for research\nand development, and the innovations that are found can be applied widely.'}, 'authors': [{'name': 'Alon Halevy'}, {'name': 'Cristian Canton Ferrer'}, {'name': 'Hao Ma'}, {'name': 'Umut Ozertem'}, {'name': 'Patrick Pantel'}, {'name': 'Marzieh Saeidi'}, {'name': 'Fabrizio Silvestri'}, {'name': 'Ves Stoyanov'}], 'author_detail': {'name': 'Ves Stoyanov'}, 'author': 'Ves Stoyanov', 'links': [{'href': 'http://arxiv.org/abs/2009.10311v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.10311v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
224,http://arxiv.org/abs/2009.09218v2,2021-05-27 22:07:08+00:00,2020-09-19 12:24:53+00:00,Misinformation and its stakeholders in Europe: a web-based analysis,"[arxiv.Result.Author('Emmanouil Koulas'), arxiv.Result.Author('Marios Anthopoulos'), arxiv.Result.Author('Sotiria Grammenou'), arxiv.Result.Author('Christos Kaimakamis'), arxiv.Result.Author('Konstantinos Kousaris'), arxiv.Result.Author('Fotini-Rafailia Panavou'), arxiv.Result.Author('Orestis Piskioulis'), arxiv.Result.Author('Syed Iftikhar H. Shah'), arxiv.Result.Author('Vasilios Peristeras')]","The rise of the internet and computational power in recent years allowed for
the exponential growth of misinformation phenomena. An issue that was a
non-issue a decade ago, became a challenge for societal cohesion. The emergence
of this new threat has led many stakeholders, especially in Europe, to act in
order to tackle this phenomenon. This paper provides in its first part a
literature review on misinformation in Europe, and in its second part a
webometrics analysis on the identified key stakeholders. In the results we
discuss who those stakeholders are, what actions do they perform to limit
misinformation and whether those actions have an impact.",,,,cs.CY,"['cs.CY', 'cs.NI']","[arxiv.Result.Link('http://arxiv.org/abs/2009.09218v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.09218v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.09218v2,"{'id': 'http://arxiv.org/abs/2009.09218v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.09218v2', 'updated': '2021-05-27T22:07:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=27, tm_hour=22, tm_min=7, tm_sec=8, tm_wday=3, tm_yday=147, tm_isdst=0), 'published': '2020-09-19T12:24:53Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=12, tm_min=24, tm_sec=53, tm_wday=5, tm_yday=263, tm_isdst=0), 'title': 'Misinformation and its stakeholders in Europe: a web-based analysis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation and its stakeholders in Europe: a web-based analysis'}, 'summary': 'The rise of the internet and computational power in recent years allowed for\nthe exponential growth of misinformation phenomena. An issue that was a\nnon-issue a decade ago, became a challenge for societal cohesion. The emergence\nof this new threat has led many stakeholders, especially in Europe, to act in\norder to tackle this phenomenon. This paper provides in its first part a\nliterature review on misinformation in Europe, and in its second part a\nwebometrics analysis on the identified key stakeholders. In the results we\ndiscuss who those stakeholders are, what actions do they perform to limit\nmisinformation and whether those actions have an impact.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rise of the internet and computational power in recent years allowed for\nthe exponential growth of misinformation phenomena. An issue that was a\nnon-issue a decade ago, became a challenge for societal cohesion. The emergence\nof this new threat has led many stakeholders, especially in Europe, to act in\norder to tackle this phenomenon. This paper provides in its first part a\nliterature review on misinformation in Europe, and in its second part a\nwebometrics analysis on the identified key stakeholders. In the results we\ndiscuss who those stakeholders are, what actions do they perform to limit\nmisinformation and whether those actions have an impact.'}, 'authors': [{'name': 'Emmanouil Koulas'}, {'name': 'Marios Anthopoulos'}, {'name': 'Sotiria Grammenou'}, {'name': 'Christos Kaimakamis'}, {'name': 'Konstantinos Kousaris'}, {'name': 'Fotini-Rafailia Panavou'}, {'name': 'Orestis Piskioulis'}, {'name': 'Syed Iftikhar H. Shah'}, {'name': 'Vasilios Peristeras'}], 'author_detail': {'name': 'Vasilios Peristeras'}, 'author': 'Vasilios Peristeras', 'links': [{'href': 'http://arxiv.org/abs/2009.09218v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.09218v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
225,http://arxiv.org/abs/2009.08413v1,2020-09-17 16:42:08+00:00,2020-09-17 16:42:08+00:00,Not sure? Handling hesitancy of COVID-19 vaccines,"[arxiv.Result.Author('N. F. Johnson'), arxiv.Result.Author('N. Velasquez'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('O. Jha'), arxiv.Result.Author('Y. Lupu')]","From the moment the first COVID-19 vaccines are rolled out, there will need
to be a large fraction of the global population ready in line. It is therefore
crucial to start managing the growing global hesitancy to any such COVID-19
vaccine. The current approach of trying to convince the ""no""s cannot work
quickly enough, nor can the current policy of trying to find, remove and/or
rebut all the individual pieces of COVID and vaccine misinformation. Instead,
we show how this can be done in a simpler way by moving away from chasing
misinformation content and focusing instead on managing the ""yes--no--not-sure""
hesitancy ecosystem.",Working paper. Comments welcome to neiljohnson@gwu.edu,,,physics.soc-ph,"['physics.soc-ph', 'nlin.AO', 'physics.med-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2009.08413v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.08413v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.08413v1,"{'id': 'http://arxiv.org/abs/2009.08413v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.08413v1', 'updated': '2020-09-17T16:42:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=17, tm_hour=16, tm_min=42, tm_sec=8, tm_wday=3, tm_yday=261, tm_isdst=0), 'published': '2020-09-17T16:42:08Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=17, tm_hour=16, tm_min=42, tm_sec=8, tm_wday=3, tm_yday=261, tm_isdst=0), 'title': 'Not sure? Handling hesitancy of COVID-19 vaccines', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Not sure? Handling hesitancy of COVID-19 vaccines'}, 'summary': 'From the moment the first COVID-19 vaccines are rolled out, there will need\nto be a large fraction of the global population ready in line. It is therefore\ncrucial to start managing the growing global hesitancy to any such COVID-19\nvaccine. The current approach of trying to convince the ""no""s cannot work\nquickly enough, nor can the current policy of trying to find, remove and/or\nrebut all the individual pieces of COVID and vaccine misinformation. Instead,\nwe show how this can be done in a simpler way by moving away from chasing\nmisinformation content and focusing instead on managing the ""yes--no--not-sure""\nhesitancy ecosystem.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'From the moment the first COVID-19 vaccines are rolled out, there will need\nto be a large fraction of the global population ready in line. It is therefore\ncrucial to start managing the growing global hesitancy to any such COVID-19\nvaccine. The current approach of trying to convince the ""no""s cannot work\nquickly enough, nor can the current policy of trying to find, remove and/or\nrebut all the individual pieces of COVID and vaccine misinformation. Instead,\nwe show how this can be done in a simpler way by moving away from chasing\nmisinformation content and focusing instead on managing the ""yes--no--not-sure""\nhesitancy ecosystem.'}, 'authors': [{'name': 'N. F. Johnson'}, {'name': 'N. Velasquez'}, {'name': 'R. Leahy'}, {'name': 'N. Johnson Restrepo'}, {'name': 'O. Jha'}, {'name': 'Y. Lupu'}], 'author_detail': {'name': 'Y. Lupu'}, 'author': 'Y. Lupu', 'arxiv_comment': 'Working paper. Comments welcome to neiljohnson@gwu.edu', 'links': [{'href': 'http://arxiv.org/abs/2009.08413v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.08413v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.med-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
226,http://arxiv.org/abs/2009.08395v1,2020-09-17 16:13:21+00:00,2020-09-17 16:13:21+00:00,A Multimodal Memes Classification: A Survey and Open Research Issues,"[arxiv.Result.Author('Tariq Habib Afridi'), arxiv.Result.Author('Aftab Alam'), arxiv.Result.Author('Muhammad Numan Khan'), arxiv.Result.Author('Jawad Khan'), arxiv.Result.Author('Young-Koo Lee')]","Memes are graphics and text overlapped so that together they present concepts
that become dubious if one of them is absent. It is spread mostly on social
media platforms, in the form of jokes, sarcasm, motivating, etc. After the
success of BERT in Natural Language Processing (NLP), researchers inclined to
Visual-Linguistic (VL) multimodal problems like memes classification, image
captioning, Visual Question Answering (VQA), and many more. Unfortunately, many
memes get uploaded each day on social media platforms that need automatic
censoring to curb misinformation and hate. Recently, this issue has attracted
the attention of researchers and practitioners. State-of-the-art methods that
performed significantly on other VL dataset, tends to fail on memes
classification. In this context, this work aims to conduct a comprehensive
study on memes classification, generally on the VL multimodal problems and
cutting edge solutions. We propose a generalized framework for VL problems. We
cover the early and next-generation works on VL problems. Finally, we identify
and articulate several open research issues and challenges. This is the first
study that presents the generalized view of the advanced classification
techniques concerning memes classification to the best of our knowledge. We
believe this study presents a clear road-map for the Machine Learning (ML)
research community to implement and enhance memes classification techniques.","This is a survey paper on recent state of the art VL models that can
  be used for memes classification. it has 15 pages and 2 figures",,,cs.CV,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2009.08395v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.08395v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.08395v1,"{'id': 'http://arxiv.org/abs/2009.08395v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.08395v1', 'updated': '2020-09-17T16:13:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=17, tm_hour=16, tm_min=13, tm_sec=21, tm_wday=3, tm_yday=261, tm_isdst=0), 'published': '2020-09-17T16:13:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=17, tm_hour=16, tm_min=13, tm_sec=21, tm_wday=3, tm_yday=261, tm_isdst=0), 'title': 'A Multimodal Memes Classification: A Survey and Open Research Issues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Multimodal Memes Classification: A Survey and Open Research Issues'}, 'summary': 'Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.'}, 'authors': [{'name': 'Tariq Habib Afridi'}, {'name': 'Aftab Alam'}, {'name': 'Muhammad Numan Khan'}, {'name': 'Jawad Khan'}, {'name': 'Young-Koo Lee'}], 'author_detail': {'name': 'Young-Koo Lee'}, 'author': 'Young-Koo Lee', 'arxiv_comment': 'This is a survey paper on recent state of the art VL models that can\n  be used for memes classification. it has 15 pages and 2 figures', 'links': [{'href': 'http://arxiv.org/abs/2009.08395v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.08395v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
227,http://arxiv.org/abs/2009.07255v1,2020-09-15 17:44:34+00:00,2020-09-15 17:44:34+00:00,Sustained Online Amplification of COVID-19 Elites in the United States,"[arxiv.Result.Author('Ryan J. Gallagher'), arxiv.Result.Author('Larissa Doroshenko'), arxiv.Result.Author('Sarah Shugars'), arxiv.Result.Author('David Lazer'), arxiv.Result.Author('Brooke Foucault Welles')]","The ongoing, fluid nature of the COVID-19 pandemic requires individuals to
regularly seek information about best health practices, local community
spreading, and public health guidelines. In the absence of a unified response
to the pandemic in the United States and clear, consistent directives from
federal and local officials, people have used social media to collectively
crowdsource COVID-19 elites, a small set of trusted COVID-19 information
sources. We take a census of COVID-19 crowdsourced elites in the United States
who have received sustained attention on Twitter during the pandemic. Using a
mixed methods approach with a panel of Twitter users linked to public U.S.
voter registration records, we find that journalists, media outlets, and
political accounts have been consistently amplified around COVID-19, while
epidemiologists, public health officials, and medical professionals make up
only a small portion of all COVID-19 elites on Twitter. We show that COVID-19
elites vary considerably across demographic groups, and that there are notable
racial, geographic, and political similarities and disparities between various
groups and the demographics of their elites. With this variation in mind, we
discuss the potential for using the disproportionate online voice of
crowdsourced COVID-19 elites to equitably promote timely public health
information and mitigate rampant misinformation.","11 pages, 2 figures","Social Media + Society, 2021",10.1177/20563051211024957,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1177/20563051211024957', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2009.07255v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.07255v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.07255v1,"{'id': 'http://arxiv.org/abs/2009.07255v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.07255v1', 'updated': '2020-09-15T17:44:34Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=15, tm_hour=17, tm_min=44, tm_sec=34, tm_wday=1, tm_yday=259, tm_isdst=0), 'published': '2020-09-15T17:44:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=15, tm_hour=17, tm_min=44, tm_sec=34, tm_wday=1, tm_yday=259, tm_isdst=0), 'title': 'Sustained Online Amplification of COVID-19 Elites in the United States', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sustained Online Amplification of COVID-19 Elites in the United States'}, 'summary': 'The ongoing, fluid nature of the COVID-19 pandemic requires individuals to\nregularly seek information about best health practices, local community\nspreading, and public health guidelines. In the absence of a unified response\nto the pandemic in the United States and clear, consistent directives from\nfederal and local officials, people have used social media to collectively\ncrowdsource COVID-19 elites, a small set of trusted COVID-19 information\nsources. We take a census of COVID-19 crowdsourced elites in the United States\nwho have received sustained attention on Twitter during the pandemic. Using a\nmixed methods approach with a panel of Twitter users linked to public U.S.\nvoter registration records, we find that journalists, media outlets, and\npolitical accounts have been consistently amplified around COVID-19, while\nepidemiologists, public health officials, and medical professionals make up\nonly a small portion of all COVID-19 elites on Twitter. We show that COVID-19\nelites vary considerably across demographic groups, and that there are notable\nracial, geographic, and political similarities and disparities between various\ngroups and the demographics of their elites. With this variation in mind, we\ndiscuss the potential for using the disproportionate online voice of\ncrowdsourced COVID-19 elites to equitably promote timely public health\ninformation and mitigate rampant misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The ongoing, fluid nature of the COVID-19 pandemic requires individuals to\nregularly seek information about best health practices, local community\nspreading, and public health guidelines. In the absence of a unified response\nto the pandemic in the United States and clear, consistent directives from\nfederal and local officials, people have used social media to collectively\ncrowdsource COVID-19 elites, a small set of trusted COVID-19 information\nsources. We take a census of COVID-19 crowdsourced elites in the United States\nwho have received sustained attention on Twitter during the pandemic. Using a\nmixed methods approach with a panel of Twitter users linked to public U.S.\nvoter registration records, we find that journalists, media outlets, and\npolitical accounts have been consistently amplified around COVID-19, while\nepidemiologists, public health officials, and medical professionals make up\nonly a small portion of all COVID-19 elites on Twitter. We show that COVID-19\nelites vary considerably across demographic groups, and that there are notable\nracial, geographic, and political similarities and disparities between various\ngroups and the demographics of their elites. With this variation in mind, we\ndiscuss the potential for using the disproportionate online voice of\ncrowdsourced COVID-19 elites to equitably promote timely public health\ninformation and mitigate rampant misinformation.'}, 'authors': [{'name': 'Ryan J. Gallagher'}, {'name': 'Larissa Doroshenko'}, {'name': 'Sarah Shugars'}, {'name': 'David Lazer'}, {'name': 'Brooke Foucault Welles'}], 'author_detail': {'name': 'Brooke Foucault Welles'}, 'author': 'Brooke Foucault Welles', 'arxiv_doi': '10.1177/20563051211024957', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1177/20563051211024957', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2009.07255v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.07255v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '11 pages, 2 figures', 'arxiv_journal_ref': 'Social Media + Society, 2021', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
228,http://arxiv.org/abs/2009.04508v2,2020-10-26 14:38:00+00:00,2020-09-09 18:30:44+00:00,Narrative Maps: An Algorithmic Approach to Represent and Extract Information Narratives,"[arxiv.Result.Author('Brian Keith'), arxiv.Result.Author('Tanushree Mitra')]","Narratives are fundamental to our perception of the world and are pervasive
in all activities that involve the representation of events in time. Yet,
modern online information systems do not incorporate narratives in their
representation of events occurring over time. This article aims to bridge this
gap, combining the theory of narrative representations with the data from
modern online systems. We make three key contributions: a theory-driven
computational representation of narratives, a novel extraction algorithm to
obtain these representations from data, and an evaluation of our approach. In
particular, given the effectiveness of visual metaphors, we employ a route map
metaphor to design a narrative map representation. The narrative map
representation illustrates the events and stories in the narrative as a series
of landmarks and routes on the map. Each element of our representation is
backed by a corresponding element from formal narrative theory, thus providing
a solid theoretical background to our method. Our approach extracts the
underlying graph structure of the narrative map using a novel optimization
technique focused on maximizing coherence while respecting structural and
coverage constraints. We showcase the effectiveness of our approach by
performing a user evaluation to assess the quality of the representation,
metaphor, and visualization. Evaluation results indicate that the Narrative Map
representation is a powerful method to communicate complex narratives to
individuals. Our findings have implications for intelligence analysts,
computational journalists, and misinformation researchers.","33 pages, 15 figures, CSCW 2020",,,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/2009.04508v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.04508v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.04508v2,"{'id': 'http://arxiv.org/abs/2009.04508v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.04508v2', 'updated': '2020-10-26T14:38:00Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=26, tm_hour=14, tm_min=38, tm_sec=0, tm_wday=0, tm_yday=300, tm_isdst=0), 'published': '2020-09-09T18:30:44Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=9, tm_hour=18, tm_min=30, tm_sec=44, tm_wday=2, tm_yday=253, tm_isdst=0), 'title': 'Narrative Maps: An Algorithmic Approach to Represent and Extract\n  Information Narratives', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Narrative Maps: An Algorithmic Approach to Represent and Extract\n  Information Narratives'}, 'summary': 'Narratives are fundamental to our perception of the world and are pervasive\nin all activities that involve the representation of events in time. Yet,\nmodern online information systems do not incorporate narratives in their\nrepresentation of events occurring over time. This article aims to bridge this\ngap, combining the theory of narrative representations with the data from\nmodern online systems. We make three key contributions: a theory-driven\ncomputational representation of narratives, a novel extraction algorithm to\nobtain these representations from data, and an evaluation of our approach. In\nparticular, given the effectiveness of visual metaphors, we employ a route map\nmetaphor to design a narrative map representation. The narrative map\nrepresentation illustrates the events and stories in the narrative as a series\nof landmarks and routes on the map. Each element of our representation is\nbacked by a corresponding element from formal narrative theory, thus providing\na solid theoretical background to our method. Our approach extracts the\nunderlying graph structure of the narrative map using a novel optimization\ntechnique focused on maximizing coherence while respecting structural and\ncoverage constraints. We showcase the effectiveness of our approach by\nperforming a user evaluation to assess the quality of the representation,\nmetaphor, and visualization. Evaluation results indicate that the Narrative Map\nrepresentation is a powerful method to communicate complex narratives to\nindividuals. Our findings have implications for intelligence analysts,\ncomputational journalists, and misinformation researchers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Narratives are fundamental to our perception of the world and are pervasive\nin all activities that involve the representation of events in time. Yet,\nmodern online information systems do not incorporate narratives in their\nrepresentation of events occurring over time. This article aims to bridge this\ngap, combining the theory of narrative representations with the data from\nmodern online systems. We make three key contributions: a theory-driven\ncomputational representation of narratives, a novel extraction algorithm to\nobtain these representations from data, and an evaluation of our approach. In\nparticular, given the effectiveness of visual metaphors, we employ a route map\nmetaphor to design a narrative map representation. The narrative map\nrepresentation illustrates the events and stories in the narrative as a series\nof landmarks and routes on the map. Each element of our representation is\nbacked by a corresponding element from formal narrative theory, thus providing\na solid theoretical background to our method. Our approach extracts the\nunderlying graph structure of the narrative map using a novel optimization\ntechnique focused on maximizing coherence while respecting structural and\ncoverage constraints. We showcase the effectiveness of our approach by\nperforming a user evaluation to assess the quality of the representation,\nmetaphor, and visualization. Evaluation results indicate that the Narrative Map\nrepresentation is a powerful method to communicate complex narratives to\nindividuals. Our findings have implications for intelligence analysts,\ncomputational journalists, and misinformation researchers.'}, 'authors': [{'name': 'Brian Keith'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_comment': '33 pages, 15 figures, CSCW 2020', 'links': [{'href': 'http://arxiv.org/abs/2009.04508v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.04508v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
229,http://arxiv.org/abs/2009.02931v1,2020-09-07 08:03:21+00:00,2020-09-07 08:03:21+00:00,Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With Transformer Models,"[arxiv.Result.Author('Alex Nikolov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Ivan Koychev'), arxiv.Result.Author('Preslav Nakov')]","While misinformation and disinformation have been thriving in social media
for years, with the emergence of the COVID-19 pandemic, the political and the
health misinformation merged, thus elevating the problem to a whole new level
and giving rise to the first global infodemic. The fight against this infodemic
has many aspects, with fact-checking and debunking false and misleading claims
being among the most important ones. Unfortunately, manual fact-checking is
time-consuming and automatic fact-checking is resource-intense, which means
that we need to pre-filter the input social media posts and to throw out those
that do not appear to be check-worthy. With this in mind, here we propose a
model for detecting check-worthy tweets about COVID-19, which combines deep
contextualized text representations with modeling the social context of the
tweet. We further describe a number of additional experiments and comparisons,
which we believe should be useful for future research as they provide some
indication about what techniques are effective for the task. Our official
submission to the English version of CLEF-2020 CheckThat! Task 1, system
Team_Alex, was ranked second with a MAP score of 0.8034, which is almost tied
with the wining system, lagging behind by just 0.003 MAP points absolute.",Check-worthiness; Fact-Checking; Veracity,CLEF-2020,,cs.CL,"['cs.CL', 'cs.IR', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2009.02931v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2009.02931v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2009.02931v1,"{'id': 'http://arxiv.org/abs/2009.02931v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2009.02931v1', 'updated': '2020-09-07T08:03:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=7, tm_hour=8, tm_min=3, tm_sec=21, tm_wday=0, tm_yday=251, tm_isdst=0), 'published': '2020-09-07T08:03:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=7, tm_hour=8, tm_min=3, tm_sec=21, tm_wday=0, tm_yday=251, tm_isdst=0), 'title': 'Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models'}, 'summary': 'While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.'}, 'authors': [{'name': 'Alex Nikolov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Ivan Koychev'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'Check-worthiness; Fact-Checking; Veracity', 'arxiv_journal_ref': 'CLEF-2020', 'links': [{'href': 'http://arxiv.org/abs/2009.02931v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2009.02931v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
230,http://arxiv.org/abs/2008.12742v1,2020-08-28 16:55:43+00:00,2020-08-28 16:55:43+00:00,Linked Credibility Reviews for Explainable Misinformation Detection,"[arxiv.Result.Author('Ronald Denaux'), arxiv.Result.Author('Jose Manuel Gomez-Perez')]","In recent years, misinformation on the Web has become increasingly rampant.
The research community has responded by proposing systems and challenges, which
are beginning to be useful for (various subtasks of) detecting misinformation.
However, most proposed systems are based on deep learning techniques which are
fine-tuned to specific domains, are difficult to interpret and produce results
which are not machine readable. This limits their applicability and adoption as
they can only be used by a select expert audience in very specific settings. In
this paper we propose an architecture based on a core concept of Credibility
Reviews (CRs) that can be used to build networks of distributed bots that
collaborate for misinformation detection. The CRs serve as building blocks to
compose graphs of (i) web content, (ii) existing credibility signals
--fact-checked claims and reputation reviews of websites--, and (iii)
automatically computed reviews. We implement this architecture on top of
lightweight extensions to Schema.org and services providing generic NLP tasks
for semantic similarity and stance detection. Evaluations on existing datasets
of social-media posts, fake news and political speeches demonstrates several
advantages over existing systems: extensibility, domain-independence,
composability, explainability and transparency via provenance. Furthermore, we
obtain competitive results without requiring finetuning and establish a new
state of the art on the Clef'18 CheckThat! Factuality task.","Accepted to the 19th International Semantic Web Conference (ISWC
  2020) https://iswc2020.semanticweb.org",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.DL']","[arxiv.Result.Link('http://arxiv.org/abs/2008.12742v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.12742v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.12742v1,"{'id': 'http://arxiv.org/abs/2008.12742v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.12742v1', 'updated': '2020-08-28T16:55:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=55, tm_sec=43, tm_wday=4, tm_yday=241, tm_isdst=0), 'published': '2020-08-28T16:55:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=16, tm_min=55, tm_sec=43, tm_wday=4, tm_yday=241, tm_isdst=0), 'title': 'Linked Credibility Reviews for Explainable Misinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Linked Credibility Reviews for Explainable Misinformation Detection'}, 'summary': ""In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.""}, 'authors': [{'name': 'Ronald Denaux'}, {'name': 'Jose Manuel Gomez-Perez'}], 'author_detail': {'name': 'Jose Manuel Gomez-Perez'}, 'author': 'Jose Manuel Gomez-Perez', 'arxiv_comment': 'Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org', 'links': [{'href': 'http://arxiv.org/abs/2008.12742v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.12742v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
231,http://arxiv.org/abs/2008.13632v1,2020-08-28 14:52:08+00:00,2020-08-28 14:52:08+00:00,TRUSTD: Combat Fake Content using Blockchain and Collective Signature Technologies,"[arxiv.Result.Author('Zakwan Jaroucheh'), arxiv.Result.Author('Mohamad Alissa'), arxiv.Result.Author('William J Buchanan')]","The growing trend of sharing news/contents, through social media platforms
and the World Wide Web has been seen to impact our perception of the truth,
altering our views about politics, economics, relationships, needs and wants.
This is because of the growing spread of misinformation and disinformation
intentionally or unintentionally by individuals and organizations. This trend
has grave political, social, ethical, and privacy implications for society due
to 1) the rapid developments in the field of Machine Learning (ML) and Deep
Learning (DL) algorithms in creating realistic-looking yet fake digital content
(such as text, images, and videos), 2) the ability to customize the content
feeds and to create a polarized so-called ""filter-bubbles"" leveraging the
availability of the big-data. Therefore, there is an ethical need to combat the
flow of fake content. This paper attempts to resolve some of the aspects of
this combat by presenting a high-level overview of TRUSTD, a blockchain and
collective signature-based ecosystem to help content creators in getting their
content backed by the community, and to help users judge on the credibility and
correctness of these contents.","arXiv admin note: text overlap with arXiv:1812.00315,
  arXiv:1807.06346, arXiv:1904.05386 by other authors","2020 IEEE International Conference on Blockchain and
  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3",10.1109/ICBC48266.2020.9169435,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/ICBC48266.2020.9169435', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.13632v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.13632v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.13632v1,"{'id': 'http://arxiv.org/abs/2008.13632v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.13632v1', 'updated': '2020-08-28T14:52:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=14, tm_min=52, tm_sec=8, tm_wday=4, tm_yday=241, tm_isdst=0), 'published': '2020-08-28T14:52:08Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=28, tm_hour=14, tm_min=52, tm_sec=8, tm_wday=4, tm_yday=241, tm_isdst=0), 'title': 'TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies'}, 'summary': 'The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called ""filter-bubbles"" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called ""filter-bubbles"" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.'}, 'authors': [{'name': 'Zakwan Jaroucheh'}, {'name': 'Mohamad Alissa'}, {'name': 'William J Buchanan'}], 'author_detail': {'name': 'William J Buchanan'}, 'author': 'William J Buchanan', 'arxiv_doi': '10.1109/ICBC48266.2020.9169435', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/ICBC48266.2020.9169435', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.13632v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.13632v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1812.00315,\n  arXiv:1807.06346, arXiv:1904.05386 by other authors', 'arxiv_journal_ref': '2020 IEEE International Conference on Blockchain and\n  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3', 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
232,http://arxiv.org/abs/2008.09533v1,2020-08-21 15:19:18+00:00,2020-08-21 15:19:18+00:00,"Investigating Differences in Crowdsourced News Credibility Assessment: Raters, Tasks, and Expert Criteria","[arxiv.Result.Author('Md Momen Bhuiyan'), arxiv.Result.Author('Amy X. Zhang'), arxiv.Result.Author('Connie Moon Sehat'), arxiv.Result.Author('Tanushree Mitra')]","Misinformation about critical issues such as climate change and vaccine
safety is oftentimes amplified on online social and search platforms. The
crowdsourcing of content credibility assessment by laypeople has been proposed
as one strategy to combat misinformation by attempting to replicate the
assessments of experts at scale. In this work, we investigate news credibility
assessments by crowds versus experts to understand when and how ratings between
them differ. We gather a dataset of over 4,000 credibility assessments taken
from 2 crowd groups---journalism students and Upwork workers---as well as 2
expert groups---journalists and scientists---on a varied set of 50 news
articles related to climate science, a topic with widespread disconnect between
public opinion and expert consensus. Examining the ratings, we find differences
in performance due to the makeup of the crowd, such as rater demographics and
political leaning, as well as the scope of the tasks that the crowd is assigned
to rate, such as the genre of the article and partisanship of the publication.
Finally, we find differences between expert assessments due to differing expert
criteria that journalism versus science experts use---differences that may
contribute to crowd discrepancies, but that also suggest a way to reduce the
gap by designing crowd tasks tailored to specific expert criteria. From these
findings, we outline future research directions to better design crowd
processes that are tailored to specific crowds and types of content.",,,10.1145/3415164,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3415164', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.09533v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.09533v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.09533v1,"{'id': 'http://arxiv.org/abs/2008.09533v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.09533v1', 'updated': '2020-08-21T15:19:18Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=21, tm_hour=15, tm_min=19, tm_sec=18, tm_wday=4, tm_yday=234, tm_isdst=0), 'published': '2020-08-21T15:19:18Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=21, tm_hour=15, tm_min=19, tm_sec=18, tm_wday=4, tm_yday=234, tm_isdst=0), 'title': 'Investigating Differences in Crowdsourced News Credibility Assessment:\n  Raters, Tasks, and Expert Criteria', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Differences in Crowdsourced News Credibility Assessment:\n  Raters, Tasks, and Expert Criteria'}, 'summary': 'Misinformation about critical issues such as climate change and vaccine\nsafety is oftentimes amplified on online social and search platforms. The\ncrowdsourcing of content credibility assessment by laypeople has been proposed\nas one strategy to combat misinformation by attempting to replicate the\nassessments of experts at scale. In this work, we investigate news credibility\nassessments by crowds versus experts to understand when and how ratings between\nthem differ. We gather a dataset of over 4,000 credibility assessments taken\nfrom 2 crowd groups---journalism students and Upwork workers---as well as 2\nexpert groups---journalists and scientists---on a varied set of 50 news\narticles related to climate science, a topic with widespread disconnect between\npublic opinion and expert consensus. Examining the ratings, we find differences\nin performance due to the makeup of the crowd, such as rater demographics and\npolitical leaning, as well as the scope of the tasks that the crowd is assigned\nto rate, such as the genre of the article and partisanship of the publication.\nFinally, we find differences between expert assessments due to differing expert\ncriteria that journalism versus science experts use---differences that may\ncontribute to crowd discrepancies, but that also suggest a way to reduce the\ngap by designing crowd tasks tailored to specific expert criteria. From these\nfindings, we outline future research directions to better design crowd\nprocesses that are tailored to specific crowds and types of content.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation about critical issues such as climate change and vaccine\nsafety is oftentimes amplified on online social and search platforms. The\ncrowdsourcing of content credibility assessment by laypeople has been proposed\nas one strategy to combat misinformation by attempting to replicate the\nassessments of experts at scale. In this work, we investigate news credibility\nassessments by crowds versus experts to understand when and how ratings between\nthem differ. We gather a dataset of over 4,000 credibility assessments taken\nfrom 2 crowd groups---journalism students and Upwork workers---as well as 2\nexpert groups---journalists and scientists---on a varied set of 50 news\narticles related to climate science, a topic with widespread disconnect between\npublic opinion and expert consensus. Examining the ratings, we find differences\nin performance due to the makeup of the crowd, such as rater demographics and\npolitical leaning, as well as the scope of the tasks that the crowd is assigned\nto rate, such as the genre of the article and partisanship of the publication.\nFinally, we find differences between expert assessments due to differing expert\ncriteria that journalism versus science experts use---differences that may\ncontribute to crowd discrepancies, but that also suggest a way to reduce the\ngap by designing crowd tasks tailored to specific expert criteria. From these\nfindings, we outline future research directions to better design crowd\nprocesses that are tailored to specific crowds and types of content.'}, 'authors': [{'name': 'Md Momen Bhuiyan'}, {'name': 'Amy X. Zhang'}, {'name': 'Connie Moon Sehat'}, {'name': 'Tanushree Mitra'}], 'author_detail': {'name': 'Tanushree Mitra'}, 'author': 'Tanushree Mitra', 'arxiv_doi': '10.1145/3415164', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3415164', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.09533v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.09533v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
233,http://arxiv.org/abs/2008.09194v2,2021-03-03 21:41:33+00:00,2020-08-20 20:25:18+00:00,On Attribution of Deepfakes,"[arxiv.Result.Author('Baiwu Zhang'), arxiv.Result.Author('Jin Peng Zhou'), arxiv.Result.Author('Ilia Shumailov'), arxiv.Result.Author('Nicolas Papernot')]","Progress in generative modelling, especially generative adversarial networks,
have made it possible to efficiently synthesize and alter media at scale.
Malicious individuals now rely on these machine-generated media, or deepfakes,
to manipulate social discourse. In order to ensure media authenticity, existing
research is focused on deepfake detection. Yet, the adversarial nature of
frameworks used for generative modeling suggests that progress towards
detecting deepfakes will enable more realistic deepfake generation. Therefore,
it comes at no surprise that developers of generative models are under the
scrutiny of stakeholders dealing with misinformation campaigns. At the same
time, generative models have a lot of positive applications. As such, there is
a clear need to develop tools that ensure the transparent use of generative
modeling, while minimizing the harm caused by malicious applications.
  Our technique optimizes over the source of entropy of each generative model
to probabilistically attribute a deepfake to one of the models. We evaluate our
method on the seminal example of face synthesis, demonstrating that our
approach achieves 97.62% attribution accuracy, and is less sensitive to
perturbations and adversarial examples. We discuss the ethical implications of
our work, identify where our technique can be used, and highlight that a more
meaningful legislative framework is required for a more transparent and ethical
use of generative modeling. Finally, we argue that model developers should be
capable of claiming plausible deniability and propose a second framework to do
so -- this allows a model developer to produce evidence that they did not
produce media that they are being accused of having produced.",,,,cs.LG,"['cs.LG', 'cs.CR', 'cs.CV', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2008.09194v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.09194v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.09194v2,"{'id': 'http://arxiv.org/abs/2008.09194v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.09194v2', 'updated': '2021-03-03T21:41:33Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=3, tm_hour=21, tm_min=41, tm_sec=33, tm_wday=2, tm_yday=62, tm_isdst=0), 'published': '2020-08-20T20:25:18Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=20, tm_hour=20, tm_min=25, tm_sec=18, tm_wday=3, tm_yday=233, tm_isdst=0), 'title': 'On Attribution of Deepfakes', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On Attribution of Deepfakes'}, 'summary': 'Progress in generative modelling, especially generative adversarial networks,\nhave made it possible to efficiently synthesize and alter media at scale.\nMalicious individuals now rely on these machine-generated media, or deepfakes,\nto manipulate social discourse. In order to ensure media authenticity, existing\nresearch is focused on deepfake detection. Yet, the adversarial nature of\nframeworks used for generative modeling suggests that progress towards\ndetecting deepfakes will enable more realistic deepfake generation. Therefore,\nit comes at no surprise that developers of generative models are under the\nscrutiny of stakeholders dealing with misinformation campaigns. At the same\ntime, generative models have a lot of positive applications. As such, there is\na clear need to develop tools that ensure the transparent use of generative\nmodeling, while minimizing the harm caused by malicious applications.\n  Our technique optimizes over the source of entropy of each generative model\nto probabilistically attribute a deepfake to one of the models. We evaluate our\nmethod on the seminal example of face synthesis, demonstrating that our\napproach achieves 97.62% attribution accuracy, and is less sensitive to\nperturbations and adversarial examples. We discuss the ethical implications of\nour work, identify where our technique can be used, and highlight that a more\nmeaningful legislative framework is required for a more transparent and ethical\nuse of generative modeling. Finally, we argue that model developers should be\ncapable of claiming plausible deniability and propose a second framework to do\nso -- this allows a model developer to produce evidence that they did not\nproduce media that they are being accused of having produced.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Progress in generative modelling, especially generative adversarial networks,\nhave made it possible to efficiently synthesize and alter media at scale.\nMalicious individuals now rely on these machine-generated media, or deepfakes,\nto manipulate social discourse. In order to ensure media authenticity, existing\nresearch is focused on deepfake detection. Yet, the adversarial nature of\nframeworks used for generative modeling suggests that progress towards\ndetecting deepfakes will enable more realistic deepfake generation. Therefore,\nit comes at no surprise that developers of generative models are under the\nscrutiny of stakeholders dealing with misinformation campaigns. At the same\ntime, generative models have a lot of positive applications. As such, there is\na clear need to develop tools that ensure the transparent use of generative\nmodeling, while minimizing the harm caused by malicious applications.\n  Our technique optimizes over the source of entropy of each generative model\nto probabilistically attribute a deepfake to one of the models. We evaluate our\nmethod on the seminal example of face synthesis, demonstrating that our\napproach achieves 97.62% attribution accuracy, and is less sensitive to\nperturbations and adversarial examples. We discuss the ethical implications of\nour work, identify where our technique can be used, and highlight that a more\nmeaningful legislative framework is required for a more transparent and ethical\nuse of generative modeling. Finally, we argue that model developers should be\ncapable of claiming plausible deniability and propose a second framework to do\nso -- this allows a model developer to produce evidence that they did not\nproduce media that they are being accused of having produced.'}, 'authors': [{'name': 'Baiwu Zhang'}, {'name': 'Jin Peng Zhou'}, {'name': 'Ilia Shumailov'}, {'name': 'Nicolas Papernot'}], 'author_detail': {'name': 'Nicolas Papernot'}, 'author': 'Nicolas Papernot', 'links': [{'href': 'http://arxiv.org/abs/2008.09194v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.09194v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
234,http://arxiv.org/abs/2008.08513v1,2020-08-19 15:44:36+00:00,2020-08-19 15:44:36+00:00,Covid-19 infodemic reveals new tipping point epidemiology and a revised $R$ formula,"[arxiv.Result.Author('N. F. Johnson'), arxiv.Result.Author('N. Velasquez'), arxiv.Result.Author('O. K. Jha'), arxiv.Result.Author('H. Niyazi'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('R. Sear'), arxiv.Result.Author('P. Manrique'), arxiv.Result.Author('Y. Lupu'), arxiv.Result.Author('P. Devkota'), arxiv.Result.Author('S. Wuchty')]","Many governments have managed to control their COVID-19 outbreak with a
simple message: keep the effective '$R$ number' $R<1$ to prevent widespread
contagion and flatten the curve. This raises the question whether a similar
policy could control dangerous online 'infodemics' of information,
misinformation and disinformation. Here we show, using multi-platform data from
the COVID-19 infodemic, that its online spreading instead encompasses a
different dynamical regime where communities and users within and across
independent platforms, sporadically form temporary active links on similar
timescales to the viral spreading. This allows material that might have died
out, to evolve and even mutate. This has enabled niche networks that were
already successfully spreading hate and anti-vaccination material, to rapidly
become global super-spreaders of narratives featuring fake COVID-19 treatments,
anti-Asian sentiment and conspiracy theories. We derive new tools that
incorporate these coupled social-viral dynamics, including an online $R$, to
help prevent infodemic spreading at all scales: from spreading across platforms
(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,
or topic. By accounting for similar social and viral timescales, the same
mathematical theory also offers a quantitative description of other
unconventional infection profiles such as rumors spreading in financial markets
and colds spreading in schools.",Working paper. Comments welcome to neiljohnson@gwu.edu,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'nlin.AO']","[arxiv.Result.Link('http://arxiv.org/abs/2008.08513v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.08513v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.08513v1,"{'id': 'http://arxiv.org/abs/2008.08513v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.08513v1', 'updated': '2020-08-19T15:44:36Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=19, tm_hour=15, tm_min=44, tm_sec=36, tm_wday=2, tm_yday=232, tm_isdst=0), 'published': '2020-08-19T15:44:36Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=19, tm_hour=15, tm_min=44, tm_sec=36, tm_wday=2, tm_yday=232, tm_isdst=0), 'title': 'Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula'}, 'summary': ""Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.""}, 'authors': [{'name': 'N. F. Johnson'}, {'name': 'N. Velasquez'}, {'name': 'O. K. Jha'}, {'name': 'H. Niyazi'}, {'name': 'R. Leahy'}, {'name': 'N. Johnson Restrepo'}, {'name': 'R. Sear'}, {'name': 'P. Manrique'}, {'name': 'Y. Lupu'}, {'name': 'P. Devkota'}, {'name': 'S. Wuchty'}], 'author_detail': {'name': 'S. Wuchty'}, 'author': 'S. Wuchty', 'arxiv_comment': 'Working paper. Comments welcome to neiljohnson@gwu.edu', 'links': [{'href': 'http://arxiv.org/abs/2008.08513v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.08513v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
235,http://arxiv.org/abs/2008.06854v1,2020-08-16 08:06:52+00:00,2020-08-16 08:06:52+00:00,"SGG: Spinbot, Grammarly and GloVe based Fake News Detection","[arxiv.Result.Author('Akansha Gautam'), arxiv.Result.Author('Koteswar Rao Jerripothula')]","Recently, news consumption using online news portals has increased
exponentially due to several reasons, such as low cost and easy accessibility.
However, such online platforms inadvertently also become the cause of spreading
false information across the web. They are being misused quite frequently as a
medium to disseminate misinformation and hoaxes. Such malpractices call for a
robust automatic fake news detection system that can keep us at bay from such
misinformation and hoaxes. We propose a robust yet simple fake news detection
system, leveraging the tools for paraphrasing, grammar-checking, and
word-embedding. In this paper, we try to the potential of these tools in
jointly unearthing the authenticity of a news article. Notably, we leverage
Spinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for
word-embedding) tools for this purpose. Using these tools, we were able to
extract novel features that could yield state-of-the-art results on the Fake
News AMT dataset and comparable results on Celebrity datasets when combined
with some of the essential features. More importantly, the proposed method is
found to be more robust empirically than the existing ones, as revealed in our
cross-domain analysis and multi-domain analysis.","9 pages, 7 figures, Accepted by IEEE International Conference on
  Multimedia Big Data (BigMM), 2020",,,cs.CL,"['cs.CL', 'cs.CY', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2008.06854v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.06854v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.06854v1,"{'id': 'http://arxiv.org/abs/2008.06854v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.06854v1', 'updated': '2020-08-16T08:06:52Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=16, tm_hour=8, tm_min=6, tm_sec=52, tm_wday=6, tm_yday=229, tm_isdst=0), 'published': '2020-08-16T08:06:52Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=16, tm_hour=8, tm_min=6, tm_sec=52, tm_wday=6, tm_yday=229, tm_isdst=0), 'title': 'SGG: Spinbot, Grammarly and GloVe based Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SGG: Spinbot, Grammarly and GloVe based Fake News Detection'}, 'summary': 'Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.'}, 'authors': [{'name': 'Akansha Gautam'}, {'name': 'Koteswar Rao Jerripothula'}], 'author_detail': {'name': 'Koteswar Rao Jerripothula'}, 'author': 'Koteswar Rao Jerripothula', 'arxiv_comment': '9 pages, 7 figures, Accepted by IEEE International Conference on\n  Multimedia Big Data (BigMM), 2020', 'links': [{'href': 'http://arxiv.org/abs/2008.06854v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.06854v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
236,http://arxiv.org/abs/2008.05940v1,2020-08-13 14:48:03+00:00,2020-08-13 14:48:03+00:00,Impossible by Conventional Means: Ten Years on from the DARPA Red Balloon Challenge,"[arxiv.Result.Author('Alex Rutherford'), arxiv.Result.Author('Manuel Cebrian'), arxiv.Result.Author('Inho Hong'), arxiv.Result.Author('Iyad Rahwan')]","Ten years ago, DARPA launched the 'Network Challenge', more commonly known as
the 'DARPA Red Balloon Challenge'. Ten red weather balloons were fixed at
unknown locations in the US. An open challenge was launched to locate all ten,
the first to do so would be declared the winner receiving a cash prize. A team
from MIT Media Lab was able to locate them all within 9 hours using social
media and a novel reward scheme that rewarded viral recruitment. This
achievement was rightly seen as proof of the remarkable ability of social
media, then relatively nascent, to solve real world problems such as
large-scale spatial search. Upon reflection, however, the challenge was also
remarkable as it succeeded despite many efforts to provide false information on
the location of the balloons. At the time the false reports were filtered based
on manual inspection of visual proof and comparing the IP addresses of those
reporting with the purported coordinates of the balloons. In the ten years
since, misinformation on social media has grown in prevalence and
sophistication to be one of the defining social issues of our time. Seen
differently we can cast the misinformation observed in the Red Balloon
Challenge, and unexpected adverse effects in other social mobilisation
challenges subsequently, not as bugs but as essential features. We further
investigate the role of the increasing levels of political polarisation in
modulating social mobilisation. We confirm that polarisation not only impedes
the overall success of mobilisation, but also leads to a low reachability to
oppositely polarised states, significantly hampering recruitment. We find that
diversifying geographic pathways of social influence are key to circumvent
barriers of political mobilisation and can boost the success of new open
challenges.",,,,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://arxiv.org/abs/2008.05940v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.05940v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.05940v1,"{'id': 'http://arxiv.org/abs/2008.05940v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.05940v1', 'updated': '2020-08-13T14:48:03Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=13, tm_hour=14, tm_min=48, tm_sec=3, tm_wday=3, tm_yday=226, tm_isdst=0), 'published': '2020-08-13T14:48:03Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=13, tm_hour=14, tm_min=48, tm_sec=3, tm_wday=3, tm_yday=226, tm_isdst=0), 'title': 'Impossible by Conventional Means: Ten Years on from the DARPA Red\n  Balloon Challenge', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Impossible by Conventional Means: Ten Years on from the DARPA Red\n  Balloon Challenge'}, 'summary': ""Ten years ago, DARPA launched the 'Network Challenge', more commonly known as\nthe 'DARPA Red Balloon Challenge'. Ten red weather balloons were fixed at\nunknown locations in the US. An open challenge was launched to locate all ten,\nthe first to do so would be declared the winner receiving a cash prize. A team\nfrom MIT Media Lab was able to locate them all within 9 hours using social\nmedia and a novel reward scheme that rewarded viral recruitment. This\nachievement was rightly seen as proof of the remarkable ability of social\nmedia, then relatively nascent, to solve real world problems such as\nlarge-scale spatial search. Upon reflection, however, the challenge was also\nremarkable as it succeeded despite many efforts to provide false information on\nthe location of the balloons. At the time the false reports were filtered based\non manual inspection of visual proof and comparing the IP addresses of those\nreporting with the purported coordinates of the balloons. In the ten years\nsince, misinformation on social media has grown in prevalence and\nsophistication to be one of the defining social issues of our time. Seen\ndifferently we can cast the misinformation observed in the Red Balloon\nChallenge, and unexpected adverse effects in other social mobilisation\nchallenges subsequently, not as bugs but as essential features. We further\ninvestigate the role of the increasing levels of political polarisation in\nmodulating social mobilisation. We confirm that polarisation not only impedes\nthe overall success of mobilisation, but also leads to a low reachability to\noppositely polarised states, significantly hampering recruitment. We find that\ndiversifying geographic pathways of social influence are key to circumvent\nbarriers of political mobilisation and can boost the success of new open\nchallenges."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Ten years ago, DARPA launched the 'Network Challenge', more commonly known as\nthe 'DARPA Red Balloon Challenge'. Ten red weather balloons were fixed at\nunknown locations in the US. An open challenge was launched to locate all ten,\nthe first to do so would be declared the winner receiving a cash prize. A team\nfrom MIT Media Lab was able to locate them all within 9 hours using social\nmedia and a novel reward scheme that rewarded viral recruitment. This\nachievement was rightly seen as proof of the remarkable ability of social\nmedia, then relatively nascent, to solve real world problems such as\nlarge-scale spatial search. Upon reflection, however, the challenge was also\nremarkable as it succeeded despite many efforts to provide false information on\nthe location of the balloons. At the time the false reports were filtered based\non manual inspection of visual proof and comparing the IP addresses of those\nreporting with the purported coordinates of the balloons. In the ten years\nsince, misinformation on social media has grown in prevalence and\nsophistication to be one of the defining social issues of our time. Seen\ndifferently we can cast the misinformation observed in the Red Balloon\nChallenge, and unexpected adverse effects in other social mobilisation\nchallenges subsequently, not as bugs but as essential features. We further\ninvestigate the role of the increasing levels of political polarisation in\nmodulating social mobilisation. We confirm that polarisation not only impedes\nthe overall success of mobilisation, but also leads to a low reachability to\noppositely polarised states, significantly hampering recruitment. We find that\ndiversifying geographic pathways of social influence are key to circumvent\nbarriers of political mobilisation and can boost the success of new open\nchallenges.""}, 'authors': [{'name': 'Alex Rutherford'}, {'name': 'Manuel Cebrian'}, {'name': 'Inho Hong'}, {'name': 'Iyad Rahwan'}], 'author_detail': {'name': 'Iyad Rahwan'}, 'author': 'Iyad Rahwan', 'links': [{'href': 'http://arxiv.org/abs/2008.05940v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.05940v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
237,http://arxiv.org/abs/2008.05701v1,2020-08-13 05:53:24+00:00,2020-08-13 05:53:24+00:00,The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation Objectively?,"[arxiv.Result.Author('Kevin Roitero'), arxiv.Result.Author('Michael Soprano'), arxiv.Result.Author('Beatrice Portelli'), arxiv.Result.Author('Damiano Spina'), arxiv.Result.Author('Vincenzo Della Mea'), arxiv.Result.Author('Giuseppe Serra'), arxiv.Result.Author('Stefano Mizzaro'), arxiv.Result.Author('Gianluca Demartini')]","Misinformation is an ever increasing problem that is difficult to solve for
the research community and has a negative impact on the society at large. Very
recently, the problem has been addressed with a crowdsourcing-based approach to
scale up labeling efforts: to assess the truthfulness of a statement, instead
of relying on a few experts, a crowd of (non-expert) judges is exploited. We
follow the same approach to study whether crowdsourcing is an effective and
reliable method to assess statements truthfulness during a pandemic. We
specifically target statements related to the COVID-19 health emergency, that
is still ongoing at the time of the study and has arguably caused an increase
of the amount of misinformation that is spreading online (a phenomenon for
which the term ""infodemic"" has been used). By doing so, we are able to address
(mis)information that is both related to a sensitive and personal issue like
health and very recent as compared to when the judgment is done: two issues
that have not been analyzed in related work. In our experiment, crowd workers
are asked to assess the truthfulness of statements, as well as to provide
evidence for the assessments as a URL and a text justification. Besides showing
that the crowd is able to accurately judge the truthfulness of the statements,
we also report results on many different aspects, including: agreement among
workers, the effect of different aggregation functions, of scales
transformations, and of workers background / bias. We also analyze workers
behavior, in terms of queries submitted, URLs found / selected, text
justifications, and other behavioral data like clicks and mouse actions
collected by means of an ad hoc logger.",10 pages; Preprint of the full paper accepted at CIKM 2020,,10.1145/3340531.3412048,cs.IR,"['cs.IR', 'cs.CL', '68P20', 'H.3']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3340531.3412048', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.05701v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.05701v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.05701v1,"{'id': 'http://arxiv.org/abs/2008.05701v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.05701v1', 'updated': '2020-08-13T05:53:24Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=13, tm_hour=5, tm_min=53, tm_sec=24, tm_wday=3, tm_yday=226, tm_isdst=0), 'published': '2020-08-13T05:53:24Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=13, tm_hour=5, tm_min=53, tm_sec=24, tm_wday=3, tm_yday=226, tm_isdst=0), 'title': 'The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation\n  Objectively?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation\n  Objectively?'}, 'summary': 'Misinformation is an ever increasing problem that is difficult to solve for\nthe research community and has a negative impact on the society at large. Very\nrecently, the problem has been addressed with a crowdsourcing-based approach to\nscale up labeling efforts: to assess the truthfulness of a statement, instead\nof relying on a few experts, a crowd of (non-expert) judges is exploited. We\nfollow the same approach to study whether crowdsourcing is an effective and\nreliable method to assess statements truthfulness during a pandemic. We\nspecifically target statements related to the COVID-19 health emergency, that\nis still ongoing at the time of the study and has arguably caused an increase\nof the amount of misinformation that is spreading online (a phenomenon for\nwhich the term ""infodemic"" has been used). By doing so, we are able to address\n(mis)information that is both related to a sensitive and personal issue like\nhealth and very recent as compared to when the judgment is done: two issues\nthat have not been analyzed in related work. In our experiment, crowd workers\nare asked to assess the truthfulness of statements, as well as to provide\nevidence for the assessments as a URL and a text justification. Besides showing\nthat the crowd is able to accurately judge the truthfulness of the statements,\nwe also report results on many different aspects, including: agreement among\nworkers, the effect of different aggregation functions, of scales\ntransformations, and of workers background / bias. We also analyze workers\nbehavior, in terms of queries submitted, URLs found / selected, text\njustifications, and other behavioral data like clicks and mouse actions\ncollected by means of an ad hoc logger.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation is an ever increasing problem that is difficult to solve for\nthe research community and has a negative impact on the society at large. Very\nrecently, the problem has been addressed with a crowdsourcing-based approach to\nscale up labeling efforts: to assess the truthfulness of a statement, instead\nof relying on a few experts, a crowd of (non-expert) judges is exploited. We\nfollow the same approach to study whether crowdsourcing is an effective and\nreliable method to assess statements truthfulness during a pandemic. We\nspecifically target statements related to the COVID-19 health emergency, that\nis still ongoing at the time of the study and has arguably caused an increase\nof the amount of misinformation that is spreading online (a phenomenon for\nwhich the term ""infodemic"" has been used). By doing so, we are able to address\n(mis)information that is both related to a sensitive and personal issue like\nhealth and very recent as compared to when the judgment is done: two issues\nthat have not been analyzed in related work. In our experiment, crowd workers\nare asked to assess the truthfulness of statements, as well as to provide\nevidence for the assessments as a URL and a text justification. Besides showing\nthat the crowd is able to accurately judge the truthfulness of the statements,\nwe also report results on many different aspects, including: agreement among\nworkers, the effect of different aggregation functions, of scales\ntransformations, and of workers background / bias. We also analyze workers\nbehavior, in terms of queries submitted, URLs found / selected, text\njustifications, and other behavioral data like clicks and mouse actions\ncollected by means of an ad hoc logger.'}, 'authors': [{'name': 'Kevin Roitero'}, {'name': 'Michael Soprano'}, {'name': 'Beatrice Portelli'}, {'name': 'Damiano Spina'}, {'name': 'Vincenzo Della Mea'}, {'name': 'Giuseppe Serra'}, {'name': 'Stefano Mizzaro'}, {'name': 'Gianluca Demartini'}], 'author_detail': {'name': 'Gianluca Demartini'}, 'author': 'Gianluca Demartini', 'arxiv_doi': '10.1145/3340531.3412048', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3340531.3412048', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.05701v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.05701v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '10 pages; Preprint of the full paper accepted at CIKM 2020', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68P20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
238,http://arxiv.org/abs/2008.05271v1,2020-08-12 12:42:57+00:00,2020-08-12 12:42:57+00:00,Social Media and Health Misinformation during the US COVID Crisis,"[arxiv.Result.Author('Gillian Bolsover'), arxiv.Result.Author('Janet Tokitsu Tizon')]","Health misinformation has been found to be prevalent on social media,
particularly in new public health crises in which there is limited scientific
information. However, social media can also play a role in limiting and
refuting health misinformation. Using as a case study US President Donald
Trump's controversial comments about the promise and power of UV light- and
disinfectant-based treatments, this data memo examines how these comments were
discussed and responded to on Twitter. We find that these comments fell into
established politically partisan narratives and dominated discussion of both
politics and COVID in the days following. Contestation of the comments was much
more prevalent than support. Supporters attacked media coverage in line with
existing Trump narratives. Contesters responded with humour and shared
mainstream media coverage condemning the comments. These practices would have
strengthened the original misinformation through repetition and done little to
construct a successful refutation for those who might have believed them. This
research adds much-needed knowledge to our understanding of the information
environment surrounding COVID and demonstrates that, despite calls for the
depoliticization of health information in this public health crisis, this is
largely being approached as a political issue along divisive, polarised,
partisan lines.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2008.05271v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.05271v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.05271v1,"{'id': 'http://arxiv.org/abs/2008.05271v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.05271v1', 'updated': '2020-08-12T12:42:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=12, tm_hour=12, tm_min=42, tm_sec=57, tm_wday=2, tm_yday=225, tm_isdst=0), 'published': '2020-08-12T12:42:57Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=12, tm_hour=12, tm_min=42, tm_sec=57, tm_wday=2, tm_yday=225, tm_isdst=0), 'title': 'Social Media and Health Misinformation during the US COVID Crisis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Media and Health Misinformation during the US COVID Crisis'}, 'summary': ""Health misinformation has been found to be prevalent on social media,\nparticularly in new public health crises in which there is limited scientific\ninformation. However, social media can also play a role in limiting and\nrefuting health misinformation. Using as a case study US President Donald\nTrump's controversial comments about the promise and power of UV light- and\ndisinfectant-based treatments, this data memo examines how these comments were\ndiscussed and responded to on Twitter. We find that these comments fell into\nestablished politically partisan narratives and dominated discussion of both\npolitics and COVID in the days following. Contestation of the comments was much\nmore prevalent than support. Supporters attacked media coverage in line with\nexisting Trump narratives. Contesters responded with humour and shared\nmainstream media coverage condemning the comments. These practices would have\nstrengthened the original misinformation through repetition and done little to\nconstruct a successful refutation for those who might have believed them. This\nresearch adds much-needed knowledge to our understanding of the information\nenvironment surrounding COVID and demonstrates that, despite calls for the\ndepoliticization of health information in this public health crisis, this is\nlargely being approached as a political issue along divisive, polarised,\npartisan lines."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Health misinformation has been found to be prevalent on social media,\nparticularly in new public health crises in which there is limited scientific\ninformation. However, social media can also play a role in limiting and\nrefuting health misinformation. Using as a case study US President Donald\nTrump's controversial comments about the promise and power of UV light- and\ndisinfectant-based treatments, this data memo examines how these comments were\ndiscussed and responded to on Twitter. We find that these comments fell into\nestablished politically partisan narratives and dominated discussion of both\npolitics and COVID in the days following. Contestation of the comments was much\nmore prevalent than support. Supporters attacked media coverage in line with\nexisting Trump narratives. Contesters responded with humour and shared\nmainstream media coverage condemning the comments. These practices would have\nstrengthened the original misinformation through repetition and done little to\nconstruct a successful refutation for those who might have believed them. This\nresearch adds much-needed knowledge to our understanding of the information\nenvironment surrounding COVID and demonstrates that, despite calls for the\ndepoliticization of health information in this public health crisis, this is\nlargely being approached as a political issue along divisive, polarised,\npartisan lines.""}, 'authors': [{'name': 'Gillian Bolsover'}, {'name': 'Janet Tokitsu Tizon'}], 'author_detail': {'name': 'Janet Tokitsu Tizon'}, 'author': 'Janet Tokitsu Tizon', 'links': [{'href': 'http://arxiv.org/abs/2008.05271v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.05271v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
239,http://arxiv.org/abs/2008.03951v1,2020-08-10 08:17:31+00:00,2020-08-10 08:17:31+00:00,Behavioral Modeling of Persian Instagram Users to detect Bots,"[arxiv.Result.Author('Muhammad Bazm'), arxiv.Result.Author('Masoud Asadpour')]","Bots are user accounts in social media which are controlled by computer
programs. Similar to many other things, they are used for both good and evil
purposes. One nefarious use-case for them is to spread misinformation or biased
data in the networks. There are many pieces of research being performed based
on social media data and their results validity is extremely threatened by the
harmful data bots spread. Consequently, effective methods and tools are
required for detecting bots and then removing misleading data spread by the
bots. In the present research, a method for detecting Instagram bots is
proposed. There is no data set including samples of Instagram bots and genuine
accounts, thus the current research has begun with gathering such a data set
with respect to generality concerns such that it includes 1,000 data points in
each group. The main approach is supervised machine learning and classic models
are preferred compared to deep neural networks. The final model is evaluated
using multiple methods starting with 10-fold cross-validation. After that,
confidence in classification studies and is followed by feature importance
analysis and feature behavior against the target probability computed by the
model. In the end, an experiment is designed to measure the models
effectiveness in an operational environment. Finally, It is strongly concluded
that the model performs very well in all evaluation experiments.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2008.03951v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.03951v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.03951v1,"{'id': 'http://arxiv.org/abs/2008.03951v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.03951v1', 'updated': '2020-08-10T08:17:31Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=10, tm_hour=8, tm_min=17, tm_sec=31, tm_wday=0, tm_yday=223, tm_isdst=0), 'published': '2020-08-10T08:17:31Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=10, tm_hour=8, tm_min=17, tm_sec=31, tm_wday=0, tm_yday=223, tm_isdst=0), 'title': 'Behavioral Modeling of Persian Instagram Users to detect Bots', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Behavioral Modeling of Persian Instagram Users to detect Bots'}, 'summary': 'Bots are user accounts in social media which are controlled by computer\nprograms. Similar to many other things, they are used for both good and evil\npurposes. One nefarious use-case for them is to spread misinformation or biased\ndata in the networks. There are many pieces of research being performed based\non social media data and their results validity is extremely threatened by the\nharmful data bots spread. Consequently, effective methods and tools are\nrequired for detecting bots and then removing misleading data spread by the\nbots. In the present research, a method for detecting Instagram bots is\nproposed. There is no data set including samples of Instagram bots and genuine\naccounts, thus the current research has begun with gathering such a data set\nwith respect to generality concerns such that it includes 1,000 data points in\neach group. The main approach is supervised machine learning and classic models\nare preferred compared to deep neural networks. The final model is evaluated\nusing multiple methods starting with 10-fold cross-validation. After that,\nconfidence in classification studies and is followed by feature importance\nanalysis and feature behavior against the target probability computed by the\nmodel. In the end, an experiment is designed to measure the models\neffectiveness in an operational environment. Finally, It is strongly concluded\nthat the model performs very well in all evaluation experiments.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Bots are user accounts in social media which are controlled by computer\nprograms. Similar to many other things, they are used for both good and evil\npurposes. One nefarious use-case for them is to spread misinformation or biased\ndata in the networks. There are many pieces of research being performed based\non social media data and their results validity is extremely threatened by the\nharmful data bots spread. Consequently, effective methods and tools are\nrequired for detecting bots and then removing misleading data spread by the\nbots. In the present research, a method for detecting Instagram bots is\nproposed. There is no data set including samples of Instagram bots and genuine\naccounts, thus the current research has begun with gathering such a data set\nwith respect to generality concerns such that it includes 1,000 data points in\neach group. The main approach is supervised machine learning and classic models\nare preferred compared to deep neural networks. The final model is evaluated\nusing multiple methods starting with 10-fold cross-validation. After that,\nconfidence in classification studies and is followed by feature importance\nanalysis and feature behavior against the target probability computed by the\nmodel. In the end, an experiment is designed to measure the models\neffectiveness in an operational environment. Finally, It is strongly concluded\nthat the model performs very well in all evaluation experiments.'}, 'authors': [{'name': 'Muhammad Bazm'}, {'name': 'Masoud Asadpour'}], 'author_detail': {'name': 'Masoud Asadpour'}, 'author': 'Masoud Asadpour', 'links': [{'href': 'http://arxiv.org/abs/2008.03951v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.03951v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
240,http://arxiv.org/abs/2008.01585v3,2021-01-26 14:09:49+00:00,2020-08-04 14:27:41+00:00,Dark Web Marketplaces and COVID-19: before the vaccine,"[arxiv.Result.Author('Alberto Bracci'), arxiv.Result.Author('Matthieu Nadini'), arxiv.Result.Author('Maxwell Aliapoulios'), arxiv.Result.Author('Damon McCoy'), arxiv.Result.Author('Ian Gray'), arxiv.Result.Author('Alexander Teytelboym'), arxiv.Result.Author('Angela Gallo'), arxiv.Result.Author('Andrea Baronchelli')]","The COVID-19 pandemic has reshaped the demand for goods and services
worldwide. The combination of a public health emergency, economic distress, and
misinformation-driven panic have pushed customers and vendors towards the
shadow economy. In particular, dark web marketplaces (DWMs), commercial
websites accessible via free software, have gained significant popularity.
Here, we analyse 851,199 listings extracted from 30 DWMs between January 1,
2020 and November 16, 2020. We identify 788 listings directly related to
COVID-19 products and monitor the temporal evolution of product categories
including Personal Protective Equipment (PPE), medicines (e.g.,
hydroxyclorochine), and medical frauds. Finally, we compare trends in their
temporal evolution with variations in public attention, as measured by Twitter
posts and Wikipedia page visits. We reveal how the online shadow economy has
evolved during the COVID-19 pandemic and highlight the importance of a
continuous monitoring of DWMs, especially now that real vaccines are available
and in short supply. We anticipate our analysis will be of interest both to
researchers and public agencies focused on the protection of public health.",,"EPJ Data Sci. 10, 6 (2021)",10.1140/epjds/s13688-021-00259-w,cs.CY,"['cs.CY', 'cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1140/epjds/s13688-021-00259-w', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.01585v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.01585v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.01585v3,"{'id': 'http://arxiv.org/abs/2008.01585v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.01585v3', 'updated': '2021-01-26T14:09:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=26, tm_hour=14, tm_min=9, tm_sec=49, tm_wday=1, tm_yday=26, tm_isdst=0), 'published': '2020-08-04T14:27:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=4, tm_hour=14, tm_min=27, tm_sec=41, tm_wday=1, tm_yday=217, tm_isdst=0), 'title': 'Dark Web Marketplaces and COVID-19: before the vaccine', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Dark Web Marketplaces and COVID-19: before the vaccine'}, 'summary': 'The COVID-19 pandemic has reshaped the demand for goods and services\nworldwide. The combination of a public health emergency, economic distress, and\nmisinformation-driven panic have pushed customers and vendors towards the\nshadow economy. In particular, dark web marketplaces (DWMs), commercial\nwebsites accessible via free software, have gained significant popularity.\nHere, we analyse 851,199 listings extracted from 30 DWMs between January 1,\n2020 and November 16, 2020. We identify 788 listings directly related to\nCOVID-19 products and monitor the temporal evolution of product categories\nincluding Personal Protective Equipment (PPE), medicines (e.g.,\nhydroxyclorochine), and medical frauds. Finally, we compare trends in their\ntemporal evolution with variations in public attention, as measured by Twitter\nposts and Wikipedia page visits. We reveal how the online shadow economy has\nevolved during the COVID-19 pandemic and highlight the importance of a\ncontinuous monitoring of DWMs, especially now that real vaccines are available\nand in short supply. We anticipate our analysis will be of interest both to\nresearchers and public agencies focused on the protection of public health.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has reshaped the demand for goods and services\nworldwide. The combination of a public health emergency, economic distress, and\nmisinformation-driven panic have pushed customers and vendors towards the\nshadow economy. In particular, dark web marketplaces (DWMs), commercial\nwebsites accessible via free software, have gained significant popularity.\nHere, we analyse 851,199 listings extracted from 30 DWMs between January 1,\n2020 and November 16, 2020. We identify 788 listings directly related to\nCOVID-19 products and monitor the temporal evolution of product categories\nincluding Personal Protective Equipment (PPE), medicines (e.g.,\nhydroxyclorochine), and medical frauds. Finally, we compare trends in their\ntemporal evolution with variations in public attention, as measured by Twitter\nposts and Wikipedia page visits. We reveal how the online shadow economy has\nevolved during the COVID-19 pandemic and highlight the importance of a\ncontinuous monitoring of DWMs, especially now that real vaccines are available\nand in short supply. We anticipate our analysis will be of interest both to\nresearchers and public agencies focused on the protection of public health.'}, 'authors': [{'name': 'Alberto Bracci'}, {'name': 'Matthieu Nadini'}, {'name': 'Maxwell Aliapoulios'}, {'name': 'Damon McCoy'}, {'name': 'Ian Gray'}, {'name': 'Alexander Teytelboym'}, {'name': 'Angela Gallo'}, {'name': 'Andrea Baronchelli'}], 'author_detail': {'name': 'Andrea Baronchelli'}, 'author': 'Andrea Baronchelli', 'arxiv_doi': '10.1140/epjds/s13688-021-00259-w', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1140/epjds/s13688-021-00259-w', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.01585v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.01585v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'EPJ Data Sci. 10, 6 (2021)', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
241,http://arxiv.org/abs/2008.01273v2,2021-02-15 22:03:49+00:00,2020-08-04 02:04:17+00:00,Analyzing Twitter Users' Behavior Before and After Contact by the Internet Research Agency,"[arxiv.Result.Author('Upasana Dutta'), arxiv.Result.Author('Rhett Hanscom'), arxiv.Result.Author('Jason Shuo Zhang'), arxiv.Result.Author('Richard Han'), arxiv.Result.Author('Tamara Lehman'), arxiv.Result.Author('Qin Lv'), arxiv.Result.Author('Shivakant Mishra')]","Social media platforms have been exploited to conduct election interference
in recent years. In particular, the Russian-backed Internet Research Agency
(IRA) has been identified as a key source of misinformation spread on Twitter
prior to the 2016 U.S. presidential election. The goal of this research is to
understand whether general Twitter users changed their behavior in the year
following first contact from an IRA account. We compare the before and after
behavior of contacted users to determine whether there were differences in
their mean tweet count, the sentiment of their tweets, and the frequency and
sentiment of tweets mentioning @realDonaldTrump or @HillaryClinton. Our results
indicate that users overall exhibited statistically significant changes in
behavior across most of these metrics, and that those users that engaged with
the IRA generally showed greater changes in behavior.",Accepted to CSCW 2021,,10.1145/3449164,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3449164', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2008.01273v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.01273v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.01273v2,"{'id': 'http://arxiv.org/abs/2008.01273v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.01273v2', 'updated': '2021-02-15T22:03:49Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=15, tm_hour=22, tm_min=3, tm_sec=49, tm_wday=0, tm_yday=46, tm_isdst=0), 'published': '2020-08-04T02:04:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=4, tm_hour=2, tm_min=4, tm_sec=17, tm_wday=1, tm_yday=217, tm_isdst=0), 'title': ""Analyzing Twitter Users' Behavior Before and After Contact by the\n  Internet Research Agency"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Analyzing Twitter Users' Behavior Before and After Contact by the\n  Internet Research Agency""}, 'summary': 'Social media platforms have been exploited to conduct election interference\nin recent years. In particular, the Russian-backed Internet Research Agency\n(IRA) has been identified as a key source of misinformation spread on Twitter\nprior to the 2016 U.S. presidential election. The goal of this research is to\nunderstand whether general Twitter users changed their behavior in the year\nfollowing first contact from an IRA account. We compare the before and after\nbehavior of contacted users to determine whether there were differences in\ntheir mean tweet count, the sentiment of their tweets, and the frequency and\nsentiment of tweets mentioning @realDonaldTrump or @HillaryClinton. Our results\nindicate that users overall exhibited statistically significant changes in\nbehavior across most of these metrics, and that those users that engaged with\nthe IRA generally showed greater changes in behavior.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media platforms have been exploited to conduct election interference\nin recent years. In particular, the Russian-backed Internet Research Agency\n(IRA) has been identified as a key source of misinformation spread on Twitter\nprior to the 2016 U.S. presidential election. The goal of this research is to\nunderstand whether general Twitter users changed their behavior in the year\nfollowing first contact from an IRA account. We compare the before and after\nbehavior of contacted users to determine whether there were differences in\ntheir mean tweet count, the sentiment of their tweets, and the frequency and\nsentiment of tweets mentioning @realDonaldTrump or @HillaryClinton. Our results\nindicate that users overall exhibited statistically significant changes in\nbehavior across most of these metrics, and that those users that engaged with\nthe IRA generally showed greater changes in behavior.'}, 'authors': [{'name': 'Upasana Dutta'}, {'name': 'Rhett Hanscom'}, {'name': 'Jason Shuo Zhang'}, {'name': 'Richard Han'}, {'name': 'Tamara Lehman'}, {'name': 'Qin Lv'}, {'name': 'Shivakant Mishra'}], 'author_detail': {'name': 'Shivakant Mishra'}, 'author': 'Shivakant Mishra', 'arxiv_doi': '10.1145/3449164', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3449164', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2008.01273v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.01273v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted to CSCW 2021', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
242,http://arxiv.org/abs/2008.00791v4,2020-09-19 07:11:39+00:00,2020-08-03 11:44:22+00:00,Characterizing COVID-19 Misinformation Communities Using a Novel Twitter Dataset,"[arxiv.Result.Author('Shahan Ali Memon'), arxiv.Result.Author('Kathleen M. Carley')]","From conspiracy theories to fake cures and fake treatments, COVID-19 has
become a hot-bed for the spread of misinformation online. It is more important
than ever to identify methods to debunk and correct false information online.
In this paper, we present a methodology and analyses to characterize the two
competing COVID-19 misinformation communities online: (i) misinformed users or
users who are actively posting misinformation, and (ii) informed users or users
who are actively spreading true information, or calling out misinformation. The
goals of this study are two-fold: (i) collecting a diverse set of annotated
COVID-19 Twitter dataset that can be used by the research community to conduct
meaningful analysis; and (ii) characterizing the two target communities in
terms of their network structure, linguistic patterns, and their membership in
other communities. Our analyses show that COVID-19 misinformed communities are
denser, and more organized than informed communities, with a possibility of a
high volume of the misinformation being part of disinformation campaigns. Our
analyses also suggest that a large majority of misinformed users may be
anti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19
informed users tend to use more narratives than misinformed users.","9 pages, In Proceedings of The 5th International Workshop on Mining
  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2008.00791v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.00791v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.00791v4,"{'id': 'http://arxiv.org/abs/2008.00791v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.00791v4', 'updated': '2020-09-19T07:11:39Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=7, tm_min=11, tm_sec=39, tm_wday=5, tm_yday=263, tm_isdst=0), 'published': '2020-08-03T11:44:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=3, tm_hour=11, tm_min=44, tm_sec=22, tm_wday=0, tm_yday=216, tm_isdst=0), 'title': 'Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset'}, 'summary': 'From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.'}, 'authors': [{'name': 'Shahan Ali Memon'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_comment': '9 pages, In Proceedings of The 5th International Workshop on Mining\n  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM', 'links': [{'href': 'http://arxiv.org/abs/2008.00791v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.00791v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
243,http://arxiv.org/abs/2008.00784v1,2020-08-03 11:25:47+00:00,2020-08-03 11:25:47+00:00,COVID-19 Misinformation and Disinformation on Social Networks -- The Limits of Veritistic Countermeasures,[arxiv.Result.Author('Andrew Buzzell')],"The COVID-19 pandemic has been the subject of a vast amount of
misinformation, particularly in digital information environments, and major
social media platforms recently publicized some of the countermeasures they are
adopting. This presents an opportunity to examine the nature of the
misinformation and disinformation being produced, and the theoretical and
technological paradigm used to counter it. I argue that this approach is based
on a conception of misinformation as epistemic pollution that can only justify
a limited and potentially inadequate response , and that some of the measures
undertaken in practice outrun this. In fact, social networks manage ecological
and architectural conditions that influence discourse on their platforms in
ways that should motivate reconsideration of the justifications that ground
epistemic interventions to combat misinformation, and the types of intervention
that they warrant. The editorial role of platforms should not be framed solely
as the management of epistemic pollution, but instead as managing the epistemic
environment in which narratives and social epistemic processes take place.
There is an element of inevitable epistemic paternalism involved in this, and
exploration of the independent constraints on its justifiability can help
determine proper limits of its exercise in practice.",,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2008.00784v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2008.00784v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2008.00784v1,"{'id': 'http://arxiv.org/abs/2008.00784v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2008.00784v1', 'updated': '2020-08-03T11:25:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=3, tm_hour=11, tm_min=25, tm_sec=47, tm_wday=0, tm_yday=216, tm_isdst=0), 'published': '2020-08-03T11:25:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=3, tm_hour=11, tm_min=25, tm_sec=47, tm_wday=0, tm_yday=216, tm_isdst=0), 'title': 'COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures'}, 'summary': 'The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.'}, 'authors': [{'name': 'Andrew Buzzell'}], 'author_detail': {'name': 'Andrew Buzzell'}, 'author': 'Andrew Buzzell', 'links': [{'href': 'http://arxiv.org/abs/2008.00784v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2008.00784v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
244,http://arxiv.org/abs/2007.14806v1,2020-07-29 12:46:45+00:00,2020-07-29 12:46:45+00:00,Towards Domain-Specific Characterization of Misinformation,"[arxiv.Result.Author('Fariha Afsana'), arxiv.Result.Author('Muhammad Ashad Kabir'), arxiv.Result.Author('Naeemul Hassan'), arxiv.Result.Author('Manoranjan Paul')]","The rapid dissemination of health misinformation poses an increasing risk to
public health. To best understand the way of combating health misinformation,
it is important to acknowledge how the fundamental characteristics of
misinformation differ from domain to domain. This paper presents a pathway
towards domain-specific characterization of misinformation so that we can
address the concealed behavior of health misinformation compared to others and
take proper initiative accordingly for combating it. With this aim, we have
mentioned several possible approaches to identify discriminating features of
medical misinformation from other types of misinformation. Thereafter, we
briefly propose a research plan followed by possible challenges to meet up. The
findings of the proposed research idea will provide new directions to the
misinformation research community.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2007.14806v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.14806v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.14806v1,"{'id': 'http://arxiv.org/abs/2007.14806v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.14806v1', 'updated': '2020-07-29T12:46:45Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=29, tm_hour=12, tm_min=46, tm_sec=45, tm_wday=2, tm_yday=211, tm_isdst=0), 'published': '2020-07-29T12:46:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=29, tm_hour=12, tm_min=46, tm_sec=45, tm_wday=2, tm_yday=211, tm_isdst=0), 'title': 'Towards Domain-Specific Characterization of Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Domain-Specific Characterization of Misinformation'}, 'summary': 'The rapid dissemination of health misinformation poses an increasing risk to\npublic health. To best understand the way of combating health misinformation,\nit is important to acknowledge how the fundamental characteristics of\nmisinformation differ from domain to domain. This paper presents a pathway\ntowards domain-specific characterization of misinformation so that we can\naddress the concealed behavior of health misinformation compared to others and\ntake proper initiative accordingly for combating it. With this aim, we have\nmentioned several possible approaches to identify discriminating features of\nmedical misinformation from other types of misinformation. Thereafter, we\nbriefly propose a research plan followed by possible challenges to meet up. The\nfindings of the proposed research idea will provide new directions to the\nmisinformation research community.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rapid dissemination of health misinformation poses an increasing risk to\npublic health. To best understand the way of combating health misinformation,\nit is important to acknowledge how the fundamental characteristics of\nmisinformation differ from domain to domain. This paper presents a pathway\ntowards domain-specific characterization of misinformation so that we can\naddress the concealed behavior of health misinformation compared to others and\ntake proper initiative accordingly for combating it. With this aim, we have\nmentioned several possible approaches to identify discriminating features of\nmedical misinformation from other types of misinformation. Thereafter, we\nbriefly propose a research plan followed by possible challenges to meet up. The\nfindings of the proposed research idea will provide new directions to the\nmisinformation research community.'}, 'authors': [{'name': 'Fariha Afsana'}, {'name': 'Muhammad Ashad Kabir'}, {'name': 'Naeemul Hassan'}, {'name': 'Manoranjan Paul'}], 'author_detail': {'name': 'Manoranjan Paul'}, 'author': 'Manoranjan Paul', 'links': [{'href': 'http://arxiv.org/abs/2007.14806v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.14806v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
245,http://arxiv.org/abs/2007.12841v3,2020-08-27 04:01:13+00:00,2020-07-25 03:03:20+00:00,"Combating Misinformation in Bangladesh: Roles and Responsibilities as Perceived by Journalists, Fact-checkers, and Users","[arxiv.Result.Author('Md Mahfuzul Haque'), arxiv.Result.Author('Mohammad Yousuf'), arxiv.Result.Author('Ahmed Shatil Alam'), arxiv.Result.Author('Pratyasha Saha'), arxiv.Result.Author('Syed Ishtiaque Ahmed'), arxiv.Result.Author('Naeemul Hassan')]","There has been a growing interest within CSCW community in understanding the
characteristics of misinformation propagated through computational media, and
the devising techniques to address the associated challenges. However, most
work in this area has been concentrated on the cases in the western world
leaving a major portion of this problem unaddressed that is situated in the
Global South. This paper aims to broaden the scope of this discourse by
focusing on this problem in the context of Bangladesh, a country in the Global
South. The spread of misinformation on Facebook in Bangladesh, a country with a
population over 163 million, has resulted in chaos, hate attacks, and killings.
By interviewing journalists, fact-checkers, in addition to surveying the
general public, we analyzed the current state of verifying misinformation in
Bangladesh. Our findings show that most people in the `news audience' want the
news media to verify the authenticity of online information that they see
online. However, the newspaper journalists say that fact-checking online
information is not a part of their job, and it is also beyond their capacity
given the amount of information being published online everyday. We further
find that the voluntary fact-checkers in Bangladesh are not equipped with
sufficient infrastructural support to fill in this gap. We show how our
findings are connected to some of the core concerns of CSCW community around
social media, collaboration, infrastructural politics, and information
inequality. From our analysis, we also suggest several pathways to increase the
impact of fact-checking efforts through collaboration, technology design, and
infrastructure development.",,,10.1145/3415201,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3415201', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.12841v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.12841v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.12841v3,"{'id': 'http://arxiv.org/abs/2007.12841v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.12841v3', 'updated': '2020-08-27T04:01:13Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=27, tm_hour=4, tm_min=1, tm_sec=13, tm_wday=3, tm_yday=240, tm_isdst=0), 'published': '2020-07-25T03:03:20Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=25, tm_hour=3, tm_min=3, tm_sec=20, tm_wday=5, tm_yday=207, tm_isdst=0), 'title': 'Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users'}, 'summary': ""There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development.""}, 'authors': [{'name': 'Md Mahfuzul Haque'}, {'name': 'Mohammad Yousuf'}, {'name': 'Ahmed Shatil Alam'}, {'name': 'Pratyasha Saha'}, {'name': 'Syed Ishtiaque Ahmed'}, {'name': 'Naeemul Hassan'}], 'author_detail': {'name': 'Naeemul Hassan'}, 'author': 'Naeemul Hassan', 'arxiv_doi': '10.1145/3415201', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3415201', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.12841v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.12841v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
246,http://arxiv.org/abs/2007.12358v2,2020-07-27 03:59:56+00:00,2020-07-24 05:42:29+00:00,Machine Learning Explanations to Prevent Overtrust in Fake News Detection,"[arxiv.Result.Author('Sina Mohseni'), arxiv.Result.Author('Fan Yang'), arxiv.Result.Author('Shiva Pentyala'), arxiv.Result.Author('Mengnan Du'), arxiv.Result.Author('Yi Liu'), arxiv.Result.Author('Nic Lupfer'), arxiv.Result.Author('Xia Hu'), arxiv.Result.Author('Shuiwang Ji'), arxiv.Result.Author('Eric Ragan')]","Combating fake news and misinformation propagation is a challenging task in
the post-truth era. News feed and search algorithms could potentially lead to
unintentional large-scale propagation of false and fabricated information with
users being exposed to algorithmically selected false content. Our research
investigates the effects of an Explainable AI assistant embedded in news review
platforms for combating the propagation of fake news. We design a news
reviewing and sharing interface, create a dataset of news stories, and train
four interpretable fake news detection algorithms to study the effects of
algorithmic transparency on end-users. We present evaluation results and
analysis from multiple controlled crowdsourced studies. For a deeper
understanding of Explainable AI systems, we discuss interactions between user
engagement, mental model, trust, and performance measures in the process of
explaining. The study results indicate that explanations helped participants to
build appropriate mental models of the intelligent assistants in different
conditions and adjust their trust accordingly for model limitations.",,,,cs.IR,"['cs.IR', 'cs.AI', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2007.12358v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.12358v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.12358v2,"{'id': 'http://arxiv.org/abs/2007.12358v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.12358v2', 'updated': '2020-07-27T03:59:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=27, tm_hour=3, tm_min=59, tm_sec=56, tm_wday=0, tm_yday=209, tm_isdst=0), 'published': '2020-07-24T05:42:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=24, tm_hour=5, tm_min=42, tm_sec=29, tm_wday=4, tm_yday=206, tm_isdst=0), 'title': 'Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection'}, 'summary': 'Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.'}, 'authors': [{'name': 'Sina Mohseni'}, {'name': 'Fan Yang'}, {'name': 'Shiva Pentyala'}, {'name': 'Mengnan Du'}, {'name': 'Yi Liu'}, {'name': 'Nic Lupfer'}, {'name': 'Xia Hu'}, {'name': 'Shuiwang Ji'}, {'name': 'Eric Ragan'}], 'author_detail': {'name': 'Eric Ragan'}, 'author': 'Eric Ragan', 'links': [{'href': 'http://arxiv.org/abs/2007.12358v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.12358v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
247,http://arxiv.org/abs/2007.12312v1,2020-07-24 01:09:56+00:00,2020-07-24 01:09:56+00:00,COVID-19 Remote Patient Monitoring: Social Impact of AI,"[arxiv.Result.Author('Ashlesha Nesarikar'), arxiv.Result.Author('Waqas Haque'), arxiv.Result.Author('Suchith Vuppala'), arxiv.Result.Author('Abhijit Nesarikar')]","A primary indicator of success in the fight against COVID-19 is avoiding
stress on critical care infrastructure and services (CCIS). However, CCIS will
likely remain stressed until sustained herd immunity is built. There are also
secondary considerations for success: mitigating economic damage; curbing the
spread of misinformation, improving morale, and preserving a sense of control;
building global trust for diplomacy, trade and travel; and restoring
reliability and normalcy to day-to-day life, among others. We envision
technology plays a pivotal role. Here, we focus on the effective use of readily
available technology to improve the primary and secondary success criteria for
the fight against SARS-CoV-2. In a multifaceted technology approach, we start
with effective technology use for remote patient monitoring (RPM) of COVID-19
with the following objectives:
  1. Deploy readily available technology for continuous real-time remote
monitoring of patient vitals with the help of biosensors on a large scale.
  2. Effective and safe remote large-scale communitywide care of low-severity
cases as a buffer against surges in COVID-19 hospitalizations to reduce strain
on critical care services and emergency hospitals.
  3. Improve the patient, their family, and their community's sense of control
and morale.
  4. Propose a clear technology and medical definition of remote patient
monitoring for COVID-19 to address an urgent technology need; address
obfuscated, narrow, and erroneous information and provide examples; and urge
publishers to be clear and complete in their disclosures.
  5. Leverage the cloud-based distributed cognitive RPM platform for community
leaders and decision makers to enable planning and resource management,
pandemic research, damage prevention and containment, and receiving feedback on
strategies and executions.","21 pages, 4 figures",,,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2007.12312v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.12312v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.12312v1,"{'id': 'http://arxiv.org/abs/2007.12312v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.12312v1', 'updated': '2020-07-24T01:09:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=24, tm_hour=1, tm_min=9, tm_sec=56, tm_wday=4, tm_yday=206, tm_isdst=0), 'published': '2020-07-24T01:09:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=24, tm_hour=1, tm_min=9, tm_sec=56, tm_wday=4, tm_yday=206, tm_isdst=0), 'title': 'COVID-19 Remote Patient Monitoring: Social Impact of AI', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 Remote Patient Monitoring: Social Impact of AI'}, 'summary': ""A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions.""}, 'authors': [{'name': 'Ashlesha Nesarikar'}, {'name': 'Waqas Haque'}, {'name': 'Suchith Vuppala'}, {'name': 'Abhijit Nesarikar'}], 'author_detail': {'name': 'Abhijit Nesarikar'}, 'arxiv_affiliation': 'Plano Intelligence', 'author': 'Abhijit Nesarikar', 'arxiv_comment': '21 pages, 4 figures', 'links': [{'href': 'http://arxiv.org/abs/2007.12312v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.12312v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
248,http://arxiv.org/abs/2007.12226v2,2020-10-01 16:44:25+00:00,2020-07-23 19:43:27+00:00,Understanding the dynamics emerging from infodemics: A call to action for interdisciplinary research,"[arxiv.Result.Author('Stephan Leitner'), arxiv.Result.Author('Bartosz Gula'), arxiv.Result.Author('Dietmar Jannach'), arxiv.Result.Author('Ulrike Krieg-Holz'), arxiv.Result.Author('Friederike Wall')]","Research on infodemics, i.e., the rapid spread of (mis)information related to
a hazardous event, such as the COVID-19 pandemic, requires the integration of a
multiplicity of scientific disciplines. The dynamics emerging from infodemics
have the potential to generate complex behavioral patterns. In order to react
appropriately, it is of ultimate importance for the fields of Business and
Economics to understand the dynamics emerging from it. In the short run,
dynamics might lead to an adaptation in household spending or to a shift in
buying behavior towards online providers. In the long run, changes in
investments, consumer behavior, and markets are to be expected. We argue that
the dynamics emerge from complex interactions among multiple factors, such as
information and misinformation accessible for individuals and the formation and
revision of beliefs. (Mis)information accessible to individuals is, amongst
others, affected by algorithms specifically designed to provide personalized
information, while automated fact-checking algorithms can help reduce the
amount of circulating misinformation. The formation and revision of individual
(and probably false) beliefs and individual fact-checking and interpretation of
information are heavily affected by linguistic patterns inherent to information
during pandemics and infodemics and further factors, such as affect, intuition
and motives. We argue that, in order to get a deep(er) understanding of the
dynamics emerging from infodemics, the fields of Business and Economics should
integrate the perspectives of Computer Science and Information Systems,
(Computational) Linguistics, and Cognitive Science into the wider context of
economic systems (e.g., organizations, markets or industries) and propose a way
to do so.",16 pages,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'econ.GN', 'math.DS', 'q-fin.EC', '68Q11, 68U35, 91E10, 68T50, 91F20, 91B44, 91B70', 'H.4; J.4; J.5']","[arxiv.Result.Link('http://arxiv.org/abs/2007.12226v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.12226v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.12226v2,"{'id': 'http://arxiv.org/abs/2007.12226v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.12226v2', 'updated': '2020-10-01T16:44:25Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=1, tm_hour=16, tm_min=44, tm_sec=25, tm_wday=3, tm_yday=275, tm_isdst=0), 'published': '2020-07-23T19:43:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=23, tm_hour=19, tm_min=43, tm_sec=27, tm_wday=3, tm_yday=205, tm_isdst=0), 'title': 'Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research'}, 'summary': 'Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.'}, 'authors': [{'name': 'Stephan Leitner'}, {'name': 'Bartosz Gula'}, {'name': 'Dietmar Jannach'}, {'name': 'Ulrike Krieg-Holz'}, {'name': 'Friederike Wall'}], 'author_detail': {'name': 'Friederike Wall'}, 'author': 'Friederike Wall', 'arxiv_comment': '16 pages', 'links': [{'href': 'http://arxiv.org/abs/2007.12226v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.12226v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68Q11, 68U35, 91E10, 68T50, 91F20, 91B44, 91B70', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.4; J.4; J.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
249,http://arxiv.org/abs/2007.11302v1,2020-07-22 09:43:43+00:00,2020-07-22 09:43:43+00:00,Information disorders on Italian Facebook during COVID-19 infodemic,"[arxiv.Result.Author('Alessandro Celestini'), arxiv.Result.Author('Marco Di Giovanni'), arxiv.Result.Author('Stefano Guarino'), arxiv.Result.Author('Francesco Pierri')]","In this work we carry out an exploratory analysis of online conversations on
the Italian Facebook during the recent COVID-19 pandemic. We analyze the
circulation of controversial topics associated with the origin of the virus,
which involve popular targets of misinformation, such as migrants and 5G
technology. We collected over 1.5 M posts in Italian language and related to
COVID-19, shared by nearly 80k public pages and groups for a period of four
months since January 2020. Overall, we find that potentially harmful content
shared by unreliable sources is substantially negligible compared to
traditional news websites, and that discussions over controversial topics has a
limited engagement w.r.t to the pandemic in general. Besides, we highlight a
""small-worldness"" effect in the URL sharing diffusion network, indicating that
users navigating through a limited set of pages could reach almost the entire
pool of shared content related to the pandemic, thus being easily exposed to
harmful propaganda as well as to verified information on the virus.","16 pages, 13 figures, 7 tables",,10.1016/j.osnem.2021.100124,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1016/j.osnem.2021.100124', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.11302v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.11302v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.11302v1,"{'id': 'http://arxiv.org/abs/2007.11302v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.11302v1', 'updated': '2020-07-22T09:43:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=22, tm_hour=9, tm_min=43, tm_sec=43, tm_wday=2, tm_yday=204, tm_isdst=0), 'published': '2020-07-22T09:43:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=22, tm_hour=9, tm_min=43, tm_sec=43, tm_wday=2, tm_yday=204, tm_isdst=0), 'title': 'Information disorders on Italian Facebook during COVID-19 infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information disorders on Italian Facebook during COVID-19 infodemic'}, 'summary': 'In this work we carry out an exploratory analysis of online conversations on\nthe Italian Facebook during the recent COVID-19 pandemic. We analyze the\ncirculation of controversial topics associated with the origin of the virus,\nwhich involve popular targets of misinformation, such as migrants and 5G\ntechnology. We collected over 1.5 M posts in Italian language and related to\nCOVID-19, shared by nearly 80k public pages and groups for a period of four\nmonths since January 2020. Overall, we find that potentially harmful content\nshared by unreliable sources is substantially negligible compared to\ntraditional news websites, and that discussions over controversial topics has a\nlimited engagement w.r.t to the pandemic in general. Besides, we highlight a\n""small-worldness"" effect in the URL sharing diffusion network, indicating that\nusers navigating through a limited set of pages could reach almost the entire\npool of shared content related to the pandemic, thus being easily exposed to\nharmful propaganda as well as to verified information on the virus.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work we carry out an exploratory analysis of online conversations on\nthe Italian Facebook during the recent COVID-19 pandemic. We analyze the\ncirculation of controversial topics associated with the origin of the virus,\nwhich involve popular targets of misinformation, such as migrants and 5G\ntechnology. We collected over 1.5 M posts in Italian language and related to\nCOVID-19, shared by nearly 80k public pages and groups for a period of four\nmonths since January 2020. Overall, we find that potentially harmful content\nshared by unreliable sources is substantially negligible compared to\ntraditional news websites, and that discussions over controversial topics has a\nlimited engagement w.r.t to the pandemic in general. Besides, we highlight a\n""small-worldness"" effect in the URL sharing diffusion network, indicating that\nusers navigating through a limited set of pages could reach almost the entire\npool of shared content related to the pandemic, thus being easily exposed to\nharmful propaganda as well as to verified information on the virus.'}, 'authors': [{'name': 'Alessandro Celestini'}, {'name': 'Marco Di Giovanni'}, {'name': 'Stefano Guarino'}, {'name': 'Francesco Pierri'}], 'author_detail': {'name': 'Francesco Pierri'}, 'author': 'Francesco Pierri', 'arxiv_doi': '10.1016/j.osnem.2021.100124', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.osnem.2021.100124', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.11302v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.11302v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '16 pages, 13 figures, 7 tables', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
250,http://arxiv.org/abs/2007.09703v1,2020-07-19 16:14:58+00:00,2020-07-19 16:14:58+00:00,A curated collection of COVID-19 online datasets,"[arxiv.Result.Author('Isa Inuwa-Dutse'), arxiv.Result.Author('Ioannis Korkontzelos')]","One of the defining moments of the year 2020 is the outbreak of Coronavirus
Disease (Covid-19), a deadly virus affecting the body's respiratory system to
the point of needing a breathing aid via ventilators. As of June 21, 2020 there
are 12,929,306 confirmed cases and 569,738 confirmed deaths across 216
countries, areas or territories. The scale of spread and impact of the pandemic
left many nations grappling with preventive and curative approaches. The
infamous lockdown measure introduced to mitigate the virus spread has altered
many aspects of our social routines in which demand for online-based services
skyrocketed. As the virus propagate, so does misinformation and fake news
around it via online social media, which seems to favour virality over
veracity. With a majority of the populace confined to their homes for a long
period, vulnerability to the toxic impact of online misinformation is high. A
case in point is the various myths and disinformation associated with the
Covid-19, which, if left unchecked, could lead to a catastrophic outcome and
hamper the fight against the virus.
  While the scientific community is actively engaged in identifying the virus
treatment, there is a growing interest in combating the associated harmful
infodemic. To this end, researchers have been curating and documenting various
datasets about Covid-19. In line with existing studies, we provide an expansive
collection of curated datasets to support the fight against the pandemic,
especially concerning misinformation. The collection consists of 3 categories
of Twitter data, information about standard practices from credible sources and
a chronicle of global situation reports. We describe how to retrieve the
hydrated version of the data and proffer some research problems that could be
addressed using the data.","10 pages, 7 figures",,,cs.IR,['cs.IR'],"[arxiv.Result.Link('http://arxiv.org/abs/2007.09703v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.09703v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.09703v1,"{'id': 'http://arxiv.org/abs/2007.09703v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.09703v1', 'updated': '2020-07-19T16:14:58Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=16, tm_min=14, tm_sec=58, tm_wday=6, tm_yday=201, tm_isdst=0), 'published': '2020-07-19T16:14:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=16, tm_min=14, tm_sec=58, tm_wday=6, tm_yday=201, tm_isdst=0), 'title': 'A curated collection of COVID-19 online datasets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A curated collection of COVID-19 online datasets'}, 'summary': ""One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.""}, 'authors': [{'name': 'Isa Inuwa-Dutse'}, {'name': 'Ioannis Korkontzelos'}], 'author_detail': {'name': 'Ioannis Korkontzelos'}, 'author': 'Ioannis Korkontzelos', 'arxiv_comment': '10 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/2007.09703v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.09703v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
251,http://arxiv.org/abs/2007.09682v3,2021-03-26 18:35:43+00:00,2020-07-19 14:52:34+00:00,Twitter and Facebook posts about COVID-19 are less likely to spread false and low-credibility content compared to other health topics,"[arxiv.Result.Author('David A. Broniatowski'), arxiv.Result.Author('Daniel Kerchner'), arxiv.Result.Author('Fouzia Farooq'), arxiv.Result.Author('Xiaolei Huang'), arxiv.Result.Author('Amelia M. Jamison'), arxiv.Result.Author('Mark Dredze'), arxiv.Result.Author('Sandra Crouse Quinn')]","On February 2, 2020, the World Health Organization declared a COVID-19 social
media ""infodemic"", with special attention to misinformation -- frequently
understood as false claims. To understand the infodemic's scope and scale, we
analyzed over 500 million posts from Twitter and Facebook about COVID-19 and
other health topics, between March 8 and May 1, 2020. Following prior work, we
assumed URL source credibility is a proxy for false content, but we also tested
this assumption. Contrary to expectations, we found that messages about
COVID-19 were more likely to contain links to more credible sources.
Additionally, messages linking to government sources, and to news with
intermediate credibility, were shared more often, on average, than links to
non-credible sources. These results suggest that more ambiguous forms of
misinformation about COVID-19 may be more likely to be disseminated through
credible sources when compared to other health topics. Furthermore, the
assumption that credibility is an adequate proxy for false content may
overestimate the prevalence of false content online: less than 25% of posts
linking to the least credible sources contained false content. Our results
emphasize the importance of distinguishing between explicit falsehoods and more
ambiguous forms of misinformation due to the search for meaning in an
environment of scientific uncertainty.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2007.09682v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.09682v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.09682v3,"{'id': 'http://arxiv.org/abs/2007.09682v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.09682v3', 'updated': '2021-03-26T18:35:43Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=26, tm_hour=18, tm_min=35, tm_sec=43, tm_wday=4, tm_yday=85, tm_isdst=0), 'published': '2020-07-19T14:52:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=19, tm_hour=14, tm_min=52, tm_sec=34, tm_wday=6, tm_yday=201, tm_isdst=0), 'title': 'Twitter and Facebook posts about COVID-19 are less likely to spread\n  false and low-credibility content compared to other health topics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Twitter and Facebook posts about COVID-19 are less likely to spread\n  false and low-credibility content compared to other health topics'}, 'summary': 'On February 2, 2020, the World Health Organization declared a COVID-19 social\nmedia ""infodemic"", with special attention to misinformation -- frequently\nunderstood as false claims. To understand the infodemic\'s scope and scale, we\nanalyzed over 500 million posts from Twitter and Facebook about COVID-19 and\nother health topics, between March 8 and May 1, 2020. Following prior work, we\nassumed URL source credibility is a proxy for false content, but we also tested\nthis assumption. Contrary to expectations, we found that messages about\nCOVID-19 were more likely to contain links to more credible sources.\nAdditionally, messages linking to government sources, and to news with\nintermediate credibility, were shared more often, on average, than links to\nnon-credible sources. These results suggest that more ambiguous forms of\nmisinformation about COVID-19 may be more likely to be disseminated through\ncredible sources when compared to other health topics. Furthermore, the\nassumption that credibility is an adequate proxy for false content may\noverestimate the prevalence of false content online: less than 25% of posts\nlinking to the least credible sources contained false content. Our results\nemphasize the importance of distinguishing between explicit falsehoods and more\nambiguous forms of misinformation due to the search for meaning in an\nenvironment of scientific uncertainty.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On February 2, 2020, the World Health Organization declared a COVID-19 social\nmedia ""infodemic"", with special attention to misinformation -- frequently\nunderstood as false claims. To understand the infodemic\'s scope and scale, we\nanalyzed over 500 million posts from Twitter and Facebook about COVID-19 and\nother health topics, between March 8 and May 1, 2020. Following prior work, we\nassumed URL source credibility is a proxy for false content, but we also tested\nthis assumption. Contrary to expectations, we found that messages about\nCOVID-19 were more likely to contain links to more credible sources.\nAdditionally, messages linking to government sources, and to news with\nintermediate credibility, were shared more often, on average, than links to\nnon-credible sources. These results suggest that more ambiguous forms of\nmisinformation about COVID-19 may be more likely to be disseminated through\ncredible sources when compared to other health topics. Furthermore, the\nassumption that credibility is an adequate proxy for false content may\noverestimate the prevalence of false content online: less than 25% of posts\nlinking to the least credible sources contained false content. Our results\nemphasize the importance of distinguishing between explicit falsehoods and more\nambiguous forms of misinformation due to the search for meaning in an\nenvironment of scientific uncertainty.'}, 'authors': [{'name': 'David A. Broniatowski'}, {'name': 'Daniel Kerchner'}, {'name': 'Fouzia Farooq'}, {'name': 'Xiaolei Huang'}, {'name': 'Amelia M. Jamison'}, {'name': 'Mark Dredze'}, {'name': 'Sandra Crouse Quinn'}], 'author_detail': {'name': 'Sandra Crouse Quinn'}, 'author': 'Sandra Crouse Quinn', 'links': [{'href': 'http://arxiv.org/abs/2007.09682v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.09682v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
252,http://arxiv.org/abs/2007.08457v6,2021-10-07 10:39:41+00:00,2020-07-16 16:49:55+00:00,Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data,"[arxiv.Result.Author('Ning Yu'), arxiv.Result.Author('Vladislav Skripniuk'), arxiv.Result.Author('Sahar Abdelnabi'), arxiv.Result.Author('Mario Fritz')]","Photorealistic image generation has reached a new level of quality due to the
breakthroughs of generative adversarial networks (GANs). Yet, the dark side of
such deepfakes, the malicious use of generated media, raises concerns about
visual misinformation. While existing research work on deepfake detection
demonstrates high accuracy, it is subject to advances in generation techniques
and adversarial iterations on detection countermeasure techniques. Thus, we
seek a proactive and sustainable solution on deepfake detection, that is
agnostic to the evolution of generative models, by introducing artificial
fingerprints into the models.
  Our approach is simple and effective. We first embed artificial fingerprints
into training data, then validate a surprising discovery on the transferability
of such fingerprints from training data to generative models, which in turn
appears in the generated deepfakes. Experiments show that our fingerprinting
solution (1) holds for a variety of cutting-edge generative models, (2) leads
to a negligible side effect on generation quality, (3) stays robust against
image-level and model-level perturbations, (4) stays hard to be detected by
adversaries, and (5) converts deepfake detection and attribution into trivial
tasks and outperforms the recent state-of-the-art baselines. Our solution
closes the responsibility loop between publishing pre-trained generative model
inventions and their possible misuses, which makes it independent of the
current arms race.",Accepted to ICCV'21 as Oral,,,cs.CR,"['cs.CR', 'cs.CV', 'cs.CY', 'cs.GR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2007.08457v6', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.08457v6', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.08457v6,"{'id': 'http://arxiv.org/abs/2007.08457v6', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.08457v6', 'updated': '2021-10-07T10:39:41Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=7, tm_hour=10, tm_min=39, tm_sec=41, tm_wday=3, tm_yday=280, tm_isdst=0), 'published': '2020-07-16T16:49:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=16, tm_hour=16, tm_min=49, tm_sec=55, tm_wday=3, tm_yday=198, tm_isdst=0), 'title': 'Artificial Fingerprinting for Generative Models: Rooting Deepfake\n  Attribution in Training Data', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Artificial Fingerprinting for Generative Models: Rooting Deepfake\n  Attribution in Training Data'}, 'summary': 'Photorealistic image generation has reached a new level of quality due to the\nbreakthroughs of generative adversarial networks (GANs). Yet, the dark side of\nsuch deepfakes, the malicious use of generated media, raises concerns about\nvisual misinformation. While existing research work on deepfake detection\ndemonstrates high accuracy, it is subject to advances in generation techniques\nand adversarial iterations on detection countermeasure techniques. Thus, we\nseek a proactive and sustainable solution on deepfake detection, that is\nagnostic to the evolution of generative models, by introducing artificial\nfingerprints into the models.\n  Our approach is simple and effective. We first embed artificial fingerprints\ninto training data, then validate a surprising discovery on the transferability\nof such fingerprints from training data to generative models, which in turn\nappears in the generated deepfakes. Experiments show that our fingerprinting\nsolution (1) holds for a variety of cutting-edge generative models, (2) leads\nto a negligible side effect on generation quality, (3) stays robust against\nimage-level and model-level perturbations, (4) stays hard to be detected by\nadversaries, and (5) converts deepfake detection and attribution into trivial\ntasks and outperforms the recent state-of-the-art baselines. Our solution\ncloses the responsibility loop between publishing pre-trained generative model\ninventions and their possible misuses, which makes it independent of the\ncurrent arms race.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Photorealistic image generation has reached a new level of quality due to the\nbreakthroughs of generative adversarial networks (GANs). Yet, the dark side of\nsuch deepfakes, the malicious use of generated media, raises concerns about\nvisual misinformation. While existing research work on deepfake detection\ndemonstrates high accuracy, it is subject to advances in generation techniques\nand adversarial iterations on detection countermeasure techniques. Thus, we\nseek a proactive and sustainable solution on deepfake detection, that is\nagnostic to the evolution of generative models, by introducing artificial\nfingerprints into the models.\n  Our approach is simple and effective. We first embed artificial fingerprints\ninto training data, then validate a surprising discovery on the transferability\nof such fingerprints from training data to generative models, which in turn\nappears in the generated deepfakes. Experiments show that our fingerprinting\nsolution (1) holds for a variety of cutting-edge generative models, (2) leads\nto a negligible side effect on generation quality, (3) stays robust against\nimage-level and model-level perturbations, (4) stays hard to be detected by\nadversaries, and (5) converts deepfake detection and attribution into trivial\ntasks and outperforms the recent state-of-the-art baselines. Our solution\ncloses the responsibility loop between publishing pre-trained generative model\ninventions and their possible misuses, which makes it independent of the\ncurrent arms race.'}, 'authors': [{'name': 'Ning Yu'}, {'name': 'Vladislav Skripniuk'}, {'name': 'Sahar Abdelnabi'}, {'name': 'Mario Fritz'}], 'author_detail': {'name': 'Mario Fritz'}, 'author': 'Mario Fritz', 'arxiv_comment': ""Accepted to ICCV'21 as Oral"", 'links': [{'href': 'http://arxiv.org/abs/2007.08457v6', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.08457v6', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
253,http://arxiv.org/abs/2007.08078v2,2021-03-06 15:11:31+00:00,2020-07-16 02:13:55+00:00,Political audience diversity and news reliability in algorithmic ranking,"[arxiv.Result.Author('Saumya Bhadani'), arxiv.Result.Author('Shun Yamaya'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Giovanni Luca Ciampaglia'), arxiv.Result.Author('Brendan Nyhan')]","Newsfeed algorithms frequently amplify misinformation and other low-quality
content. How can social media platforms more effectively promote reliable
information? Existing approaches are difficult to scale and vulnerable to
manipulation. In this paper, we propose using the political diversity of a
website's audience as a quality signal. Using news source reliability ratings
from domain experts and web browsing data from a diverse sample of 6,890 U.S.
citizens, we first show that websites with more extreme and less politically
diverse audiences have lower journalistic standards. We then incorporate
audience diversity into a standard collaborative filtering framework and show
that our improved algorithm increases the trustworthiness of websites suggested
to users -- especially those who most frequently consume misinformation --
while keeping recommendations relevant. These findings suggest that partisan
audience diversity is a valuable signal of higher journalistic standards that
should be incorporated into algorithmic ranking decisions.","47 pages, 23 figures, 5 tables (including supplementary materials)",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2007.08078v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.08078v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.08078v2,"{'id': 'http://arxiv.org/abs/2007.08078v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.08078v2', 'updated': '2021-03-06T15:11:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=6, tm_hour=15, tm_min=11, tm_sec=31, tm_wday=5, tm_yday=65, tm_isdst=0), 'published': '2020-07-16T02:13:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=16, tm_hour=2, tm_min=13, tm_sec=55, tm_wday=3, tm_yday=198, tm_isdst=0), 'title': 'Political audience diversity and news reliability in algorithmic ranking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Political audience diversity and news reliability in algorithmic ranking'}, 'summary': ""Newsfeed algorithms frequently amplify misinformation and other low-quality\ncontent. How can social media platforms more effectively promote reliable\ninformation? Existing approaches are difficult to scale and vulnerable to\nmanipulation. In this paper, we propose using the political diversity of a\nwebsite's audience as a quality signal. Using news source reliability ratings\nfrom domain experts and web browsing data from a diverse sample of 6,890 U.S.\ncitizens, we first show that websites with more extreme and less politically\ndiverse audiences have lower journalistic standards. We then incorporate\naudience diversity into a standard collaborative filtering framework and show\nthat our improved algorithm increases the trustworthiness of websites suggested\nto users -- especially those who most frequently consume misinformation --\nwhile keeping recommendations relevant. These findings suggest that partisan\naudience diversity is a valuable signal of higher journalistic standards that\nshould be incorporated into algorithmic ranking decisions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Newsfeed algorithms frequently amplify misinformation and other low-quality\ncontent. How can social media platforms more effectively promote reliable\ninformation? Existing approaches are difficult to scale and vulnerable to\nmanipulation. In this paper, we propose using the political diversity of a\nwebsite's audience as a quality signal. Using news source reliability ratings\nfrom domain experts and web browsing data from a diverse sample of 6,890 U.S.\ncitizens, we first show that websites with more extreme and less politically\ndiverse audiences have lower journalistic standards. We then incorporate\naudience diversity into a standard collaborative filtering framework and show\nthat our improved algorithm increases the trustworthiness of websites suggested\nto users -- especially those who most frequently consume misinformation --\nwhile keeping recommendations relevant. These findings suggest that partisan\naudience diversity is a valuable signal of higher journalistic standards that\nshould be incorporated into algorithmic ranking decisions.""}, 'authors': [{'name': 'Saumya Bhadani'}, {'name': 'Shun Yamaya'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}, {'name': 'Giovanni Luca Ciampaglia'}, {'name': 'Brendan Nyhan'}], 'author_detail': {'name': 'Brendan Nyhan'}, 'author': 'Brendan Nyhan', 'arxiv_comment': '47 pages, 23 figures, 5 tables (including supplementary materials)', 'links': [{'href': 'http://arxiv.org/abs/2007.08078v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.08078v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
254,http://arxiv.org/abs/2007.07996v2,2021-04-09 08:52:10+00:00,2020-07-15 21:18:30+00:00,Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective and a Call to Arms,"[arxiv.Result.Author('Firoj Alam'), arxiv.Result.Author('Fahim Dalvi'), arxiv.Result.Author('Shaden Shaar'), arxiv.Result.Author('Nadir Durrani'), arxiv.Result.Author('Hamdy Mubarak'), arxiv.Result.Author('Alex Nikolov'), arxiv.Result.Author('Giovanni Da San Martino'), arxiv.Result.Author('Ahmed Abdelali'), arxiv.Result.Author('Hassan Sajjad'), arxiv.Result.Author('Kareem Darwish'), arxiv.Result.Author('Preslav Nakov')]","With the outbreak of the COVID-19 pandemic, people turned to social media to
read and to share timely information including statistics, warnings, advice,
and inspirational stories. Unfortunately, alongside all this useful
information, there was also a new blending of medical and political
misinformation and disinformation, which gave rise to the first global
infodemic. While fighting this infodemic is typically thought of in terms of
factuality, the problem is much broader as malicious content includes not only
fake news, rumors, and conspiracy theories, but also promotion of fake cures,
panic, racism, xenophobia, and mistrust in the authorities, among others. This
is a complex problem that needs a holistic approach combining the perspectives
of journalists, fact-checkers, policymakers, government entities, social media
platforms, and society as a whole. Taking them into account we define an
annotation schema and detailed annotation instructions, which reflect these
perspectives. We performed initial annotations using this schema, and our
initial experiments demonstrated sizable improvements over the baselines. Now,
we issue a call to arms to the research community and beyond to join the fight
by supporting our crowdsourcing annotation efforts.","COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call
  to Arms, Crowdsourcing Annotations",,,cs.IR,"['cs.IR', 'cs.CL', 'cs.LG', 'cs.SI', '68T50', 'I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/2007.07996v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.07996v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.07996v2,"{'id': 'http://arxiv.org/abs/2007.07996v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.07996v2', 'updated': '2021-04-09T08:52:10Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=9, tm_hour=8, tm_min=52, tm_sec=10, tm_wday=4, tm_yday=99, tm_isdst=0), 'published': '2020-07-15T21:18:30Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=15, tm_hour=21, tm_min=18, tm_sec=30, tm_wday=2, tm_yday=197, tm_isdst=0), 'title': 'Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms'}, 'summary': 'With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.'}, 'authors': [{'name': 'Firoj Alam'}, {'name': 'Fahim Dalvi'}, {'name': 'Shaden Shaar'}, {'name': 'Nadir Durrani'}, {'name': 'Hamdy Mubarak'}, {'name': 'Alex Nikolov'}, {'name': 'Giovanni Da San Martino'}, {'name': 'Ahmed Abdelali'}, {'name': 'Hassan Sajjad'}, {'name': 'Kareem Darwish'}, {'name': 'Preslav Nakov'}], 'author_detail': {'name': 'Preslav Nakov'}, 'author': 'Preslav Nakov', 'arxiv_comment': 'COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations', 'links': [{'href': 'http://arxiv.org/abs/2007.07996v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.07996v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
255,http://arxiv.org/abs/2007.05848v1,2020-07-11 20:37:14+00:00,2020-07-11 20:37:14+00:00,Fighting Disaster Misinformation in Latin America: The #19S Mexican Earthquake Case Study,"[arxiv.Result.Author('Claudia Flores-Saviaga'), arxiv.Result.Author('Saiph Savage')]","Social media platforms have been extensively used during natural disasters.
However, most prior work has lacked focus on studying their usage during
disasters in the Global South, where Internet access and social media
utilization differs from developing countries. In this paper, we study how
social media was used in the aftermath of the 7.1-magnitude earthquake that hit
Mexico on September 19 of 2017 (known as the #19S earthquake). We conduct an
analysis of how participants utilized social media platforms in the #19S
aftermath. Our research extends investigations of crisis informatics by: 1)
examining how participants used different social media platforms in the
aftermath of a natural disaster in a Global South country; 2) uncovering how
individuals developed their own processes to verify news reports using an
on-the-ground citizen approach; 3) revealing how people developed their own
mechanisms to deal with outdated information. For this, we surveyed 356 people.
Additionally, we analyze one month of activity from: Facebook (12,606 posts),
Twitter (2,909,109 tweets), Slack (28,782 messages), and GitHub (2,602
commits). This work offers a multi-platform view on user behavior to coordinate
relief efforts, reduce the spread of misinformation and deal with obsolete
information which seems to have been essential to help in the coordination and
efficiency of relief efforts. Finally, based on our findings, we make
recommendations for technology design to improve the effectiveness of social
media use during crisis response efforts and mitigate the spread of
misinformation across social media platforms.",,Springer - Personal and Ubiquitous Computing 2020,10.1007/s00779-020-01411-5,cs.HC,"['cs.HC', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s00779-020-01411-5', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2007.05848v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.05848v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.05848v1,"{'id': 'http://arxiv.org/abs/2007.05848v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.05848v1', 'updated': '2020-07-11T20:37:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=11, tm_hour=20, tm_min=37, tm_sec=14, tm_wday=5, tm_yday=193, tm_isdst=0), 'published': '2020-07-11T20:37:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=11, tm_hour=20, tm_min=37, tm_sec=14, tm_wday=5, tm_yday=193, tm_isdst=0), 'title': 'Fighting Disaster Misinformation in Latin America: The #19S Mexican\n  Earthquake Case Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fighting Disaster Misinformation in Latin America: The #19S Mexican\n  Earthquake Case Study'}, 'summary': 'Social media platforms have been extensively used during natural disasters.\nHowever, most prior work has lacked focus on studying their usage during\ndisasters in the Global South, where Internet access and social media\nutilization differs from developing countries. In this paper, we study how\nsocial media was used in the aftermath of the 7.1-magnitude earthquake that hit\nMexico on September 19 of 2017 (known as the #19S earthquake). We conduct an\nanalysis of how participants utilized social media platforms in the #19S\naftermath. Our research extends investigations of crisis informatics by: 1)\nexamining how participants used different social media platforms in the\naftermath of a natural disaster in a Global South country; 2) uncovering how\nindividuals developed their own processes to verify news reports using an\non-the-ground citizen approach; 3) revealing how people developed their own\nmechanisms to deal with outdated information. For this, we surveyed 356 people.\nAdditionally, we analyze one month of activity from: Facebook (12,606 posts),\nTwitter (2,909,109 tweets), Slack (28,782 messages), and GitHub (2,602\ncommits). This work offers a multi-platform view on user behavior to coordinate\nrelief efforts, reduce the spread of misinformation and deal with obsolete\ninformation which seems to have been essential to help in the coordination and\nefficiency of relief efforts. Finally, based on our findings, we make\nrecommendations for technology design to improve the effectiveness of social\nmedia use during crisis response efforts and mitigate the spread of\nmisinformation across social media platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media platforms have been extensively used during natural disasters.\nHowever, most prior work has lacked focus on studying their usage during\ndisasters in the Global South, where Internet access and social media\nutilization differs from developing countries. In this paper, we study how\nsocial media was used in the aftermath of the 7.1-magnitude earthquake that hit\nMexico on September 19 of 2017 (known as the #19S earthquake). We conduct an\nanalysis of how participants utilized social media platforms in the #19S\naftermath. Our research extends investigations of crisis informatics by: 1)\nexamining how participants used different social media platforms in the\naftermath of a natural disaster in a Global South country; 2) uncovering how\nindividuals developed their own processes to verify news reports using an\non-the-ground citizen approach; 3) revealing how people developed their own\nmechanisms to deal with outdated information. For this, we surveyed 356 people.\nAdditionally, we analyze one month of activity from: Facebook (12,606 posts),\nTwitter (2,909,109 tweets), Slack (28,782 messages), and GitHub (2,602\ncommits). This work offers a multi-platform view on user behavior to coordinate\nrelief efforts, reduce the spread of misinformation and deal with obsolete\ninformation which seems to have been essential to help in the coordination and\nefficiency of relief efforts. Finally, based on our findings, we make\nrecommendations for technology design to improve the effectiveness of social\nmedia use during crisis response efforts and mitigate the spread of\nmisinformation across social media platforms.'}, 'authors': [{'name': 'Claudia Flores-Saviaga'}, {'name': 'Saiph Savage'}], 'author_detail': {'name': 'Saiph Savage'}, 'author': 'Saiph Savage', 'arxiv_doi': '10.1007/s00779-020-01411-5', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s00779-020-01411-5', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2007.05848v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.05848v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Springer - Personal and Ubiquitous Computing 2020', 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
256,http://arxiv.org/abs/2007.02620v2,2020-09-11 11:34:22+00:00,2020-07-06 10:20:12+00:00,Reducing Misinformation in Query Autocompletions,[arxiv.Result.Author('Djoerd Hiemstra')],"Query autocompletions help users of search engines to speed up their searches
by recommending completions of partially typed queries in a drop down box.
These recommended query autocompletions are usually based on large logs of
queries that were previously entered by the search engine's users. Therefore,
misinformation entered -- either accidentally or purposely to manipulate the
search engine -- might end up in the search engine's recommendations,
potentially harming organizations, individuals, and groups of people. This
paper proposes an alternative approach for generating query autocompletions by
extracting anchor texts from a large web crawl, without the need to use query
logs. Our evaluation shows that even though query log autocompletions perform
better for shorter queries, anchor text autocompletions outperform query log
autocompletions for queries of 2 words or more.","Published at the 2nd International Symposium on Open Search
  Technology, 12-14 October 2020, CERN, Geneva, Switzerland",,,cs.IR,"['cs.IR', 'IR']","[arxiv.Result.Link('http://arxiv.org/abs/2007.02620v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.02620v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.02620v2,"{'id': 'http://arxiv.org/abs/2007.02620v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.02620v2', 'updated': '2020-09-11T11:34:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=11, tm_hour=11, tm_min=34, tm_sec=22, tm_wday=4, tm_yday=255, tm_isdst=0), 'published': '2020-07-06T10:20:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=6, tm_hour=10, tm_min=20, tm_sec=12, tm_wday=0, tm_yday=188, tm_isdst=0), 'title': 'Reducing Misinformation in Query Autocompletions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Reducing Misinformation in Query Autocompletions'}, 'summary': ""Query autocompletions help users of search engines to speed up their searches\nby recommending completions of partially typed queries in a drop down box.\nThese recommended query autocompletions are usually based on large logs of\nqueries that were previously entered by the search engine's users. Therefore,\nmisinformation entered -- either accidentally or purposely to manipulate the\nsearch engine -- might end up in the search engine's recommendations,\npotentially harming organizations, individuals, and groups of people. This\npaper proposes an alternative approach for generating query autocompletions by\nextracting anchor texts from a large web crawl, without the need to use query\nlogs. Our evaluation shows that even though query log autocompletions perform\nbetter for shorter queries, anchor text autocompletions outperform query log\nautocompletions for queries of 2 words or more."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Query autocompletions help users of search engines to speed up their searches\nby recommending completions of partially typed queries in a drop down box.\nThese recommended query autocompletions are usually based on large logs of\nqueries that were previously entered by the search engine's users. Therefore,\nmisinformation entered -- either accidentally or purposely to manipulate the\nsearch engine -- might end up in the search engine's recommendations,\npotentially harming organizations, individuals, and groups of people. This\npaper proposes an alternative approach for generating query autocompletions by\nextracting anchor texts from a large web crawl, without the need to use query\nlogs. Our evaluation shows that even though query log autocompletions perform\nbetter for shorter queries, anchor text autocompletions outperform query log\nautocompletions for queries of 2 words or more.""}, 'authors': [{'name': 'Djoerd Hiemstra'}], 'author_detail': {'name': 'Djoerd Hiemstra'}, 'author': 'Djoerd Hiemstra', 'arxiv_comment': 'Published at the 2nd International Symposium on Open Search\n  Technology, 12-14 October 2020, CERN, Geneva, Switzerland', 'links': [{'href': 'http://arxiv.org/abs/2007.02620v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.02620v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
257,http://arxiv.org/abs/2007.03611v1,2020-07-06 03:18:54+00:00,2020-07-06 03:18:54+00:00,P-Values in a Post-Truth World,[arxiv.Result.Author('Joshua T. Vogelstein')],"The role of statisticians in society is to provide tools, techniques, and
guidance with regards to how much to trust data. This role is increasingly more
important with more data and more misinformation than ever before. The American
Statistical Association recently released two statements on p-values, and
provided four guiding principles. We evaluate their claims using these
principles and find that they failed to adhere to them. In this age of
distrust, we have an opportunity to be role models of trustworthiness, and
responsibility to take it.",10 pages,,,physics.soc-ph,"['physics.soc-ph', 'stat.OT']","[arxiv.Result.Link('http://arxiv.org/abs/2007.03611v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.03611v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.03611v1,"{'id': 'http://arxiv.org/abs/2007.03611v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.03611v1', 'updated': '2020-07-06T03:18:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=6, tm_hour=3, tm_min=18, tm_sec=54, tm_wday=0, tm_yday=188, tm_isdst=0), 'published': '2020-07-06T03:18:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=6, tm_hour=3, tm_min=18, tm_sec=54, tm_wday=0, tm_yday=188, tm_isdst=0), 'title': 'P-Values in a Post-Truth World', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'P-Values in a Post-Truth World'}, 'summary': 'The role of statisticians in society is to provide tools, techniques, and\nguidance with regards to how much to trust data. This role is increasingly more\nimportant with more data and more misinformation than ever before. The American\nStatistical Association recently released two statements on p-values, and\nprovided four guiding principles. We evaluate their claims using these\nprinciples and find that they failed to adhere to them. In this age of\ndistrust, we have an opportunity to be role models of trustworthiness, and\nresponsibility to take it.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The role of statisticians in society is to provide tools, techniques, and\nguidance with regards to how much to trust data. This role is increasingly more\nimportant with more data and more misinformation than ever before. The American\nStatistical Association recently released two statements on p-values, and\nprovided four guiding principles. We evaluate their claims using these\nprinciples and find that they failed to adhere to them. In this age of\ndistrust, we have an opportunity to be role models of trustworthiness, and\nresponsibility to take it.'}, 'authors': [{'name': 'Joshua T. Vogelstein'}], 'author_detail': {'name': 'Joshua T. Vogelstein'}, 'author': 'Joshua T. Vogelstein', 'arxiv_comment': '10 pages', 'links': [{'href': 'http://arxiv.org/abs/2007.03611v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.03611v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.OT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
258,http://arxiv.org/abs/2007.01242v1,2020-07-02 16:50:28+00:00,2020-07-02 16:50:28+00:00,Evolving Methods for Evaluating and Disseminating Computing Research,"[arxiv.Result.Author('Benjamin Zorn'), arxiv.Result.Author('Tom Conte'), arxiv.Result.Author('Keith Marzullo'), arxiv.Result.Author('Suresh Venkatasubramanian')]","Social and technical trends have significantly changed methods for evaluating
and disseminating computing research. Traditional venues for reviewing and
publishing, such as conferences and journals, worked effectively in the past.
Recently, trends have created new opportunities but also put new pressures on
the process of review and dissemination. For example, many conferences have
seen large increases in the number of submissions. Likewise, dissemination of
research ideas has become dramatically through publication venues such as
arXiv.org and social media networks. While these trends predate COVID-19, the
pandemic could accelerate longer term changes. Based on interviews with leading
academics in computing research, our findings include: (1) Trends impacting
computing research are largely positive and have increased the participation,
scope, accessibility, and speed of the research process. (2) Challenges remain
in securing the integrity of the process, including addressing ways to scale
the review process, avoiding attempts to misinform or confuse the dissemination
of results, and ensuring fairness and broad participation in the process
itself. Based on these findings, we recommend: (1) Regularly polling members of
the computing research community, including program and general conference
chairs, journal editors, authors, reviewers, etc., to identify specific
challenges they face to better understand these issues. (2) An influential
body, such as the Computing Research Association regularly issues a ""State of
the Computing Research Enterprise"" report to update the community on trends,
both positive and negative, impacting the computing research enterprise. (3) A
deeper investigation, specifically to better understand the influence that
social media and preprint archives have on computing research, is conducted.","A Computing Community Consortium (CCC) white paper, 12 pages",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2007.01242v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2007.01242v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2007.01242v1,"{'id': 'http://arxiv.org/abs/2007.01242v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2007.01242v1', 'updated': '2020-07-02T16:50:28Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=2, tm_hour=16, tm_min=50, tm_sec=28, tm_wday=3, tm_yday=184, tm_isdst=0), 'published': '2020-07-02T16:50:28Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=2, tm_hour=16, tm_min=50, tm_sec=28, tm_wday=3, tm_yday=184, tm_isdst=0), 'title': 'Evolving Methods for Evaluating and Disseminating Computing Research', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evolving Methods for Evaluating and Disseminating Computing Research'}, 'summary': 'Social and technical trends have significantly changed methods for evaluating\nand disseminating computing research. Traditional venues for reviewing and\npublishing, such as conferences and journals, worked effectively in the past.\nRecently, trends have created new opportunities but also put new pressures on\nthe process of review and dissemination. For example, many conferences have\nseen large increases in the number of submissions. Likewise, dissemination of\nresearch ideas has become dramatically through publication venues such as\narXiv.org and social media networks. While these trends predate COVID-19, the\npandemic could accelerate longer term changes. Based on interviews with leading\nacademics in computing research, our findings include: (1) Trends impacting\ncomputing research are largely positive and have increased the participation,\nscope, accessibility, and speed of the research process. (2) Challenges remain\nin securing the integrity of the process, including addressing ways to scale\nthe review process, avoiding attempts to misinform or confuse the dissemination\nof results, and ensuring fairness and broad participation in the process\nitself. Based on these findings, we recommend: (1) Regularly polling members of\nthe computing research community, including program and general conference\nchairs, journal editors, authors, reviewers, etc., to identify specific\nchallenges they face to better understand these issues. (2) An influential\nbody, such as the Computing Research Association regularly issues a ""State of\nthe Computing Research Enterprise"" report to update the community on trends,\nboth positive and negative, impacting the computing research enterprise. (3) A\ndeeper investigation, specifically to better understand the influence that\nsocial media and preprint archives have on computing research, is conducted.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social and technical trends have significantly changed methods for evaluating\nand disseminating computing research. Traditional venues for reviewing and\npublishing, such as conferences and journals, worked effectively in the past.\nRecently, trends have created new opportunities but also put new pressures on\nthe process of review and dissemination. For example, many conferences have\nseen large increases in the number of submissions. Likewise, dissemination of\nresearch ideas has become dramatically through publication venues such as\narXiv.org and social media networks. While these trends predate COVID-19, the\npandemic could accelerate longer term changes. Based on interviews with leading\nacademics in computing research, our findings include: (1) Trends impacting\ncomputing research are largely positive and have increased the participation,\nscope, accessibility, and speed of the research process. (2) Challenges remain\nin securing the integrity of the process, including addressing ways to scale\nthe review process, avoiding attempts to misinform or confuse the dissemination\nof results, and ensuring fairness and broad participation in the process\nitself. Based on these findings, we recommend: (1) Regularly polling members of\nthe computing research community, including program and general conference\nchairs, journal editors, authors, reviewers, etc., to identify specific\nchallenges they face to better understand these issues. (2) An influential\nbody, such as the Computing Research Association regularly issues a ""State of\nthe Computing Research Enterprise"" report to update the community on trends,\nboth positive and negative, impacting the computing research enterprise. (3) A\ndeeper investigation, specifically to better understand the influence that\nsocial media and preprint archives have on computing research, is conducted.'}, 'authors': [{'name': 'Benjamin Zorn'}, {'name': 'Tom Conte'}, {'name': 'Keith Marzullo'}, {'name': 'Suresh Venkatasubramanian'}], 'author_detail': {'name': 'Suresh Venkatasubramanian'}, 'author': 'Suresh Venkatasubramanian', 'arxiv_comment': 'A Computing Community Consortium (CCC) white paper, 12 pages', 'links': [{'href': 'http://arxiv.org/abs/2007.01242v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2007.01242v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
259,http://arxiv.org/abs/2006.12759v2,2021-04-05 15:06:08+00:00,2020-06-23 04:54:22+00:00,Estimation of COVID-19 under-reporting in Brazilian States through SARI,"[arxiv.Result.Author('Balthazar Paixão'), arxiv.Result.Author('Lais Baroni'), arxiv.Result.Author('Rebecca Salles'), arxiv.Result.Author('Luciana Escobar'), arxiv.Result.Author('Carlos de Sousa'), arxiv.Result.Author('Marcel Pedroso'), arxiv.Result.Author('Raphael Saldanha'), arxiv.Result.Author('Rafaelli Coutinho'), arxiv.Result.Author('Fabio Porto'), arxiv.Result.Author('Eduardo Ogasawara')]","Due to its impact, COVID-19 has been stressing the academy to search for
curing, mitigating, or controlling it. However, when it comes to controlling,
there are still few studies focused on under-reporting estimates. It is
believed that under-reporting is a relevant factor in determining the actual
mortality rate and, if not considered, can cause significant misinformation.
Therefore, the objective of this work is to estimate the under-reporting of
cases and deaths of COVID-19 in Brazilian states using data from the Infogripe
on notification of Severe Acute Respiratory Infection (SARI). The methodology
is based on the concepts of inertia and the use of event detection techniques
to study the time series of hospitalized SARI cases. The estimate of real cases
of the disease, called novelty, is calculated by comparing the difference in
SARI cases in 2020 (after COVID-19) with the total expected cases in recent
years (2016 to 2019) derived from a seasonal exponential moving average. The
results show that under-reporting rates vary significantly between states and
that there are no general patterns for states in the same region in Brazil.
  The published version of this paper is made available at
https://doi.org/10.1007/s00354-021-00125-3.
  Please cite as: B. Paix\~ao, L. Baroni, M. Pedroso, R. Salles, L. Escobar, C.
de Sousa, R. de Freitas Saldanha, J. Soares, R. Coutinho, et al., 2021,
Estimation of COVID-19 Under-Reporting in the Brazilian States Through SARI,
New Generation Computing",,,10.1007/s00354-021-00125-3,stat.AP,"['stat.AP', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s00354-021-00125-3', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.12759v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.12759v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.12759v2,"{'id': 'http://arxiv.org/abs/2006.12759v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.12759v2', 'updated': '2021-04-05T15:06:08Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=5, tm_hour=15, tm_min=6, tm_sec=8, tm_wday=0, tm_yday=95, tm_isdst=0), 'published': '2020-06-23T04:54:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=23, tm_hour=4, tm_min=54, tm_sec=22, tm_wday=1, tm_yday=175, tm_isdst=0), 'title': 'Estimation of COVID-19 under-reporting in Brazilian States through SARI', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Estimation of COVID-19 under-reporting in Brazilian States through SARI'}, 'summary': 'Due to its impact, COVID-19 has been stressing the academy to search for\ncuring, mitigating, or controlling it. However, when it comes to controlling,\nthere are still few studies focused on under-reporting estimates. It is\nbelieved that under-reporting is a relevant factor in determining the actual\nmortality rate and, if not considered, can cause significant misinformation.\nTherefore, the objective of this work is to estimate the under-reporting of\ncases and deaths of COVID-19 in Brazilian states using data from the Infogripe\non notification of Severe Acute Respiratory Infection (SARI). The methodology\nis based on the concepts of inertia and the use of event detection techniques\nto study the time series of hospitalized SARI cases. The estimate of real cases\nof the disease, called novelty, is calculated by comparing the difference in\nSARI cases in 2020 (after COVID-19) with the total expected cases in recent\nyears (2016 to 2019) derived from a seasonal exponential moving average. The\nresults show that under-reporting rates vary significantly between states and\nthat there are no general patterns for states in the same region in Brazil.\n  The published version of this paper is made available at\nhttps://doi.org/10.1007/s00354-021-00125-3.\n  Please cite as: B. Paix\\~ao, L. Baroni, M. Pedroso, R. Salles, L. Escobar, C.\nde Sousa, R. de Freitas Saldanha, J. Soares, R. Coutinho, et al., 2021,\nEstimation of COVID-19 Under-Reporting in the Brazilian States Through SARI,\nNew Generation Computing', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Due to its impact, COVID-19 has been stressing the academy to search for\ncuring, mitigating, or controlling it. However, when it comes to controlling,\nthere are still few studies focused on under-reporting estimates. It is\nbelieved that under-reporting is a relevant factor in determining the actual\nmortality rate and, if not considered, can cause significant misinformation.\nTherefore, the objective of this work is to estimate the under-reporting of\ncases and deaths of COVID-19 in Brazilian states using data from the Infogripe\non notification of Severe Acute Respiratory Infection (SARI). The methodology\nis based on the concepts of inertia and the use of event detection techniques\nto study the time series of hospitalized SARI cases. The estimate of real cases\nof the disease, called novelty, is calculated by comparing the difference in\nSARI cases in 2020 (after COVID-19) with the total expected cases in recent\nyears (2016 to 2019) derived from a seasonal exponential moving average. The\nresults show that under-reporting rates vary significantly between states and\nthat there are no general patterns for states in the same region in Brazil.\n  The published version of this paper is made available at\nhttps://doi.org/10.1007/s00354-021-00125-3.\n  Please cite as: B. Paix\\~ao, L. Baroni, M. Pedroso, R. Salles, L. Escobar, C.\nde Sousa, R. de Freitas Saldanha, J. Soares, R. Coutinho, et al., 2021,\nEstimation of COVID-19 Under-Reporting in the Brazilian States Through SARI,\nNew Generation Computing'}, 'authors': [{'name': 'Balthazar Paixão'}, {'name': 'Lais Baroni'}, {'name': 'Rebecca Salles'}, {'name': 'Luciana Escobar'}, {'name': 'Carlos de Sousa'}, {'name': 'Marcel Pedroso'}, {'name': 'Raphael Saldanha'}, {'name': 'Rafaelli Coutinho'}, {'name': 'Fabio Porto'}, {'name': 'Eduardo Ogasawara'}], 'author_detail': {'name': 'Eduardo Ogasawara'}, 'author': 'Eduardo Ogasawara', 'arxiv_doi': '10.1007/s00354-021-00125-3', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s00354-021-00125-3', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.12759v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.12759v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
260,http://arxiv.org/abs/2006.11002v2,2021-01-15 10:04:56+00:00,2020-06-19 08:02:31+00:00,A First Look at Android Applications in Google Play related to Covid-19,"[arxiv.Result.Author('Jordan Samhi'), arxiv.Result.Author('Kevin Allix'), arxiv.Result.Author('Tegawendé F. Bissyandé'), arxiv.Result.Author('Jacques Klein')]","Due to the convenience of access-on-demand to information and business
solutions, mobile apps have become an important asset in the digital world. In
the context of the Covid-19 pandemic, app developers have joined the response
effort in various ways by releasing apps that target different user bases
(e.g., all citizens or journalists), offer different services (e.g., location
tracking or diagnostic-aid), provide generic or specialized information, etc.
While many apps have raised some concerns by spreading misinformation or even
malware, the literature does not yet provide a clear landscape of the different
apps that were developed. In this study, we focus on the Android ecosystem and
investigate Covid-related Android apps. In a best-effort scenario, we attempt
to systematically identify all relevant apps and study their characteristics
with the objective to provide a First taxonomy of Covid-related apps,
broadening the relevance beyond the implementation of contact tracing. Overall,
our study yields a number of empirical insights that contribute to enlarge the
knowledge on Covid-related apps: (1) Developer communities contributed rapidly
to the Covid-19, with dedicated apps released as early as January 2020; (2)
Covid-related apps deliver digital tools to users (e.g., health diaries), serve
to broadcast information to users (e.g., spread statistics), and collect data
from users (e.g., for tracing); (3) Covid-related apps are less complex than
standard apps; (4) they generally do not seem to leak sensitive data; (5) in
the majority of cases, Covid-related apps are released by entities with past
experience on the market, mostly official government entities or public health
organizations.","Accepted in Empirical Software Engineering under reference:
  EMSE-D-20-00211R1",,,cs.SE,"['cs.SE', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2006.11002v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.11002v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.11002v2,"{'id': 'http://arxiv.org/abs/2006.11002v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.11002v2', 'updated': '2021-01-15T10:04:56Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=15, tm_hour=10, tm_min=4, tm_sec=56, tm_wday=4, tm_yday=15, tm_isdst=0), 'published': '2020-06-19T08:02:31Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=19, tm_hour=8, tm_min=2, tm_sec=31, tm_wday=4, tm_yday=171, tm_isdst=0), 'title': 'A First Look at Android Applications in Google Play related to Covid-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A First Look at Android Applications in Google Play related to Covid-19'}, 'summary': 'Due to the convenience of access-on-demand to information and business\nsolutions, mobile apps have become an important asset in the digital world. In\nthe context of the Covid-19 pandemic, app developers have joined the response\neffort in various ways by releasing apps that target different user bases\n(e.g., all citizens or journalists), offer different services (e.g., location\ntracking or diagnostic-aid), provide generic or specialized information, etc.\nWhile many apps have raised some concerns by spreading misinformation or even\nmalware, the literature does not yet provide a clear landscape of the different\napps that were developed. In this study, we focus on the Android ecosystem and\ninvestigate Covid-related Android apps. In a best-effort scenario, we attempt\nto systematically identify all relevant apps and study their characteristics\nwith the objective to provide a First taxonomy of Covid-related apps,\nbroadening the relevance beyond the implementation of contact tracing. Overall,\nour study yields a number of empirical insights that contribute to enlarge the\nknowledge on Covid-related apps: (1) Developer communities contributed rapidly\nto the Covid-19, with dedicated apps released as early as January 2020; (2)\nCovid-related apps deliver digital tools to users (e.g., health diaries), serve\nto broadcast information to users (e.g., spread statistics), and collect data\nfrom users (e.g., for tracing); (3) Covid-related apps are less complex than\nstandard apps; (4) they generally do not seem to leak sensitive data; (5) in\nthe majority of cases, Covid-related apps are released by entities with past\nexperience on the market, mostly official government entities or public health\norganizations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Due to the convenience of access-on-demand to information and business\nsolutions, mobile apps have become an important asset in the digital world. In\nthe context of the Covid-19 pandemic, app developers have joined the response\neffort in various ways by releasing apps that target different user bases\n(e.g., all citizens or journalists), offer different services (e.g., location\ntracking or diagnostic-aid), provide generic or specialized information, etc.\nWhile many apps have raised some concerns by spreading misinformation or even\nmalware, the literature does not yet provide a clear landscape of the different\napps that were developed. In this study, we focus on the Android ecosystem and\ninvestigate Covid-related Android apps. In a best-effort scenario, we attempt\nto systematically identify all relevant apps and study their characteristics\nwith the objective to provide a First taxonomy of Covid-related apps,\nbroadening the relevance beyond the implementation of contact tracing. Overall,\nour study yields a number of empirical insights that contribute to enlarge the\nknowledge on Covid-related apps: (1) Developer communities contributed rapidly\nto the Covid-19, with dedicated apps released as early as January 2020; (2)\nCovid-related apps deliver digital tools to users (e.g., health diaries), serve\nto broadcast information to users (e.g., spread statistics), and collect data\nfrom users (e.g., for tracing); (3) Covid-related apps are less complex than\nstandard apps; (4) they generally do not seem to leak sensitive data; (5) in\nthe majority of cases, Covid-related apps are released by entities with past\nexperience on the market, mostly official government entities or public health\norganizations.'}, 'authors': [{'name': 'Jordan Samhi'}, {'name': 'Kevin Allix'}, {'name': 'Tegawendé F. Bissyandé'}, {'name': 'Jacques Klein'}], 'author_detail': {'name': 'Jacques Klein'}, 'author': 'Jacques Klein', 'arxiv_comment': 'Accepted in Empirical Software Engineering under reference:\n  EMSE-D-20-00211R1', 'links': [{'href': 'http://arxiv.org/abs/2006.11002v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.11002v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
261,http://arxiv.org/abs/2006.09938v3,2021-04-14 20:05:52+00:00,2020-06-17 15:35:23+00:00,Did State-sponsored Trolls Shape the 2016 US Presidential Election Discourse? Quantifying Influence on Twitter,"[arxiv.Result.Author('Nikos Salamanos'), arxiv.Result.Author('Michael J. Jensen'), arxiv.Result.Author('Costas Iordanou'), arxiv.Result.Author('Michael Sirivianos')]","It is a widely accepted fact that state-sponsored Twitter accounts operated
during the 2016 US presidential election, spreading millions of tweets with
misinformation and inflammatory political content. Whether these social media
campaigns of the so-called ""troll"" accounts were able to manipulate public
opinion is still in question. Here, we quantify the influence of troll accounts
on Twitter by analyzing 152.5 million tweets (by 9.9 million users) from that
period. The data contain original tweets from 822 troll accounts identified as
such by Twitter itself. We construct and analyse a very large interaction graph
of 9.3 million nodes and 169.9 million edges using graph analysis techniques,
along with a game-theoretic centrality measure. Then, we quantify the influence
of all Twitter accounts on the overall information exchange as is defined by
the retweet cascades. We provide a global influence ranking of all Twitter
accounts and we find that one troll account appears in the top-100 and four in
the top-1000. This combined with other findings presented in this paper
constitute evidence that the driving force of virality and influence in the
network came from regular users - users who have not been classified as trolls
by Twitter. On the other hand, we find that on average, troll accounts were
tens of times more influential than regular users were. Moreover, 23% and 22%
of regular accounts in the top-100 and top-1000 respectively, have now been
suspended by Twitter. This raises questions about their authenticity and
practices during the 2016 US presidential election.","This article supersedes our work arXiv:1910.00531. This work has been
  submitted to the IEEE for possible publication. Copyright may be transferred
  without notice, after which this version may no longer be accessible",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2006.09938v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.09938v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.09938v3,"{'id': 'http://arxiv.org/abs/2006.09938v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.09938v3', 'updated': '2021-04-14T20:05:52Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=14, tm_hour=20, tm_min=5, tm_sec=52, tm_wday=2, tm_yday=104, tm_isdst=0), 'published': '2020-06-17T15:35:23Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=35, tm_sec=23, tm_wday=2, tm_yday=169, tm_isdst=0), 'title': 'Did State-sponsored Trolls Shape the 2016 US Presidential Election\n  Discourse? Quantifying Influence on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Did State-sponsored Trolls Shape the 2016 US Presidential Election\n  Discourse? Quantifying Influence on Twitter'}, 'summary': 'It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election, spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called ""troll"" accounts were able to manipulate public\nopinion is still in question. Here, we quantify the influence of troll accounts\non Twitter by analyzing 152.5 million tweets (by 9.9 million users) from that\nperiod. The data contain original tweets from 822 troll accounts identified as\nsuch by Twitter itself. We construct and analyse a very large interaction graph\nof 9.3 million nodes and 169.9 million edges using graph analysis techniques,\nalong with a game-theoretic centrality measure. Then, we quantify the influence\nof all Twitter accounts on the overall information exchange as is defined by\nthe retweet cascades. We provide a global influence ranking of all Twitter\naccounts and we find that one troll account appears in the top-100 and four in\nthe top-1000. This combined with other findings presented in this paper\nconstitute evidence that the driving force of virality and influence in the\nnetwork came from regular users - users who have not been classified as trolls\nby Twitter. On the other hand, we find that on average, troll accounts were\ntens of times more influential than regular users were. Moreover, 23% and 22%\nof regular accounts in the top-100 and top-1000 respectively, have now been\nsuspended by Twitter. This raises questions about their authenticity and\npractices during the 2016 US presidential election.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election, spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called ""troll"" accounts were able to manipulate public\nopinion is still in question. Here, we quantify the influence of troll accounts\non Twitter by analyzing 152.5 million tweets (by 9.9 million users) from that\nperiod. The data contain original tweets from 822 troll accounts identified as\nsuch by Twitter itself. We construct and analyse a very large interaction graph\nof 9.3 million nodes and 169.9 million edges using graph analysis techniques,\nalong with a game-theoretic centrality measure. Then, we quantify the influence\nof all Twitter accounts on the overall information exchange as is defined by\nthe retweet cascades. We provide a global influence ranking of all Twitter\naccounts and we find that one troll account appears in the top-100 and four in\nthe top-1000. This combined with other findings presented in this paper\nconstitute evidence that the driving force of virality and influence in the\nnetwork came from regular users - users who have not been classified as trolls\nby Twitter. On the other hand, we find that on average, troll accounts were\ntens of times more influential than regular users were. Moreover, 23% and 22%\nof regular accounts in the top-100 and top-1000 respectively, have now been\nsuspended by Twitter. This raises questions about their authenticity and\npractices during the 2016 US presidential election.'}, 'authors': [{'name': 'Nikos Salamanos'}, {'name': 'Michael J. Jensen'}, {'name': 'Costas Iordanou'}, {'name': 'Michael Sirivianos'}], 'author_detail': {'name': 'Michael Sirivianos'}, 'author': 'Michael Sirivianos', 'arxiv_comment': 'This article supersedes our work arXiv:1910.00531. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible', 'links': [{'href': 'http://arxiv.org/abs/2006.09938v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.09938v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
262,http://arxiv.org/abs/2006.08830v2,2021-01-27 20:23:36+00:00,2020-06-15 23:48:50+00:00,Examining the Global Spread of COVID-19 Misinformation,"[arxiv.Result.Author('Sophie Nightingale'), arxiv.Result.Author('Hany Farid')]","The global COVID-19 pandemic has led to the online proliferation of health-,
political-, and conspiratorial-based misinformation. Understanding the reach
and belief in this misinformation is vital to managing this crisis, as well as
future crises. The results from our global survey finds a troubling reach of
and belief in COVID-related misinformation, as well as a correlation with those
that primarily consume news from social media, and, in the United States, a
strong correlation with political leaning.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2006.08830v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.08830v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.08830v2,"{'id': 'http://arxiv.org/abs/2006.08830v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.08830v2', 'updated': '2021-01-27T20:23:36Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=27, tm_hour=20, tm_min=23, tm_sec=36, tm_wday=2, tm_yday=27, tm_isdst=0), 'published': '2020-06-15T23:48:50Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=15, tm_hour=23, tm_min=48, tm_sec=50, tm_wday=0, tm_yday=167, tm_isdst=0), 'title': 'Examining the Global Spread of COVID-19 Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Examining the Global Spread of COVID-19 Misinformation'}, 'summary': 'The global COVID-19 pandemic has led to the online proliferation of health-,\npolitical-, and conspiratorial-based misinformation. Understanding the reach\nand belief in this misinformation is vital to managing this crisis, as well as\nfuture crises. The results from our global survey finds a troubling reach of\nand belief in COVID-related misinformation, as well as a correlation with those\nthat primarily consume news from social media, and, in the United States, a\nstrong correlation with political leaning.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The global COVID-19 pandemic has led to the online proliferation of health-,\npolitical-, and conspiratorial-based misinformation. Understanding the reach\nand belief in this misinformation is vital to managing this crisis, as well as\nfuture crises. The results from our global survey finds a troubling reach of\nand belief in COVID-related misinformation, as well as a correlation with those\nthat primarily consume news from social media, and, in the United States, a\nstrong correlation with political leaning.'}, 'authors': [{'name': 'Sophie Nightingale'}, {'name': 'Hany Farid'}], 'author_detail': {'name': 'Hany Farid'}, 'author': 'Hany Farid', 'links': [{'href': 'http://arxiv.org/abs/2006.08830v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.08830v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
263,http://arxiv.org/abs/2006.06867v2,2020-08-14 20:04:21+00:00,2020-06-11 22:59:59+00:00,Detection of Novel Social Bots by Ensembles of Specialized Classifiers,"[arxiv.Result.Author('Mohsen Sayyadiharikandeh'), arxiv.Result.Author('Onur Varol'), arxiv.Result.Author('Kai-Cheng Yang'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Malicious actors create inauthentic social media accounts controlled in part
by algorithms, known as social bots, to disseminate misinformation and agitate
online discussion. While researchers have developed sophisticated methods to
detect abuse, novel bots with diverse behaviors evade detection. We show that
different types of bots are characterized by different behavioral features. As
a result, supervised learning techniques suffer severe performance
deterioration when attempting to detect behaviors not observed in the training
data. Moreover, tuning these models to recognize novel bots requires retraining
with a significant amount of new annotations, which are expensive to obtain. To
address these issues, we propose a new supervised learning method that trains
classifiers specialized for each class of bots and combines their decisions
through the maximum rule. The ensemble of specialized classifiers (ESC) can
better generalize, leading to an average improvement of 56\% in F1 score for
unseen accounts across datasets. Furthermore, novel bot behaviors are learned
with fewer labeled examples during retraining. We deployed ESC in the newest
version of Botometer, a popular tool to detect social bots in the wild, with a
cross-validation AUC of 0.99.","8 pages, 10 figures, Accepted to CIKM'20","Proc. 29th ACM International Conference on Information and
  Knowledge Management (CIKM), pages 2725-2732, 2020",10.1145/3340531.3412698,cs.SI,"['cs.SI', 'cs.IR', 'cs.LG']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3340531.3412698', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.06867v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.06867v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.06867v2,"{'id': 'http://arxiv.org/abs/2006.06867v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.06867v2', 'updated': '2020-08-14T20:04:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=14, tm_hour=20, tm_min=4, tm_sec=21, tm_wday=4, tm_yday=227, tm_isdst=0), 'published': '2020-06-11T22:59:59Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=11, tm_hour=22, tm_min=59, tm_sec=59, tm_wday=3, tm_yday=163, tm_isdst=0), 'title': 'Detection of Novel Social Bots by Ensembles of Specialized Classifiers', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detection of Novel Social Bots by Ensembles of Specialized Classifiers'}, 'summary': 'Malicious actors create inauthentic social media accounts controlled in part\nby algorithms, known as social bots, to disseminate misinformation and agitate\nonline discussion. While researchers have developed sophisticated methods to\ndetect abuse, novel bots with diverse behaviors evade detection. We show that\ndifferent types of bots are characterized by different behavioral features. As\na result, supervised learning techniques suffer severe performance\ndeterioration when attempting to detect behaviors not observed in the training\ndata. Moreover, tuning these models to recognize novel bots requires retraining\nwith a significant amount of new annotations, which are expensive to obtain. To\naddress these issues, we propose a new supervised learning method that trains\nclassifiers specialized for each class of bots and combines their decisions\nthrough the maximum rule. The ensemble of specialized classifiers (ESC) can\nbetter generalize, leading to an average improvement of 56\\% in F1 score for\nunseen accounts across datasets. Furthermore, novel bot behaviors are learned\nwith fewer labeled examples during retraining. We deployed ESC in the newest\nversion of Botometer, a popular tool to detect social bots in the wild, with a\ncross-validation AUC of 0.99.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Malicious actors create inauthentic social media accounts controlled in part\nby algorithms, known as social bots, to disseminate misinformation and agitate\nonline discussion. While researchers have developed sophisticated methods to\ndetect abuse, novel bots with diverse behaviors evade detection. We show that\ndifferent types of bots are characterized by different behavioral features. As\na result, supervised learning techniques suffer severe performance\ndeterioration when attempting to detect behaviors not observed in the training\ndata. Moreover, tuning these models to recognize novel bots requires retraining\nwith a significant amount of new annotations, which are expensive to obtain. To\naddress these issues, we propose a new supervised learning method that trains\nclassifiers specialized for each class of bots and combines their decisions\nthrough the maximum rule. The ensemble of specialized classifiers (ESC) can\nbetter generalize, leading to an average improvement of 56\\% in F1 score for\nunseen accounts across datasets. Furthermore, novel bot behaviors are learned\nwith fewer labeled examples during retraining. We deployed ESC in the newest\nversion of Botometer, a popular tool to detect social bots in the wild, with a\ncross-validation AUC of 0.99.'}, 'authors': [{'name': 'Mohsen Sayyadiharikandeh'}, {'name': 'Onur Varol'}, {'name': 'Kai-Cheng Yang'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1145/3340531.3412698', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3340531.3412698', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.06867v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.06867v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""8 pages, 10 figures, Accepted to CIKM'20"", 'arxiv_journal_ref': 'Proc. 29th ACM International Conference on Information and\n  Knowledge Management (CIKM), pages 2725-2732, 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
264,http://arxiv.org/abs/2006.05169v1,2020-06-09 10:34:41+00:00,2020-06-09 10:34:41+00:00,DyHGCN: A Dynamic Heterogeneous Graph Convolutional Network to Learn Users' Dynamic Preferences for Information Diffusion Prediction,"[arxiv.Result.Author('Chunyuan Yuan'), arxiv.Result.Author('Jiacheng Li'), arxiv.Result.Author('Wei Zhou'), arxiv.Result.Author('Yijun Lu'), arxiv.Result.Author('Xiaodan Zhang'), arxiv.Result.Author('Songlin Hu')]","Information diffusion prediction is a fundamental task for understanding the
information propagation process. It has wide applications in such as
misinformation spreading prediction and malicious account detection. Previous
works either concentrate on utilizing the context of a single diffusion
sequence or using the social network among users for information diffusion
prediction. However, the diffusion paths of different messages naturally
constitute a dynamic diffusion graph. For one thing, previous works cannot
jointly utilize both the social network and diffusion graph for prediction,
which is insufficient to model the complexity of the diffusion process and
results in unsatisfactory prediction performance. For another, they cannot
learn users' dynamic preferences. Intuitively, users' preferences are changing
as time goes on and users' personal preference determines whether the user will
repost the information. Thus, it is beneficial to consider users' dynamic
preferences in information diffusion prediction.
  In this paper, we propose a novel dynamic heterogeneous graph convolutional
network (DyHGCN) to jointly learn the structural characteristics of the social
graph and dynamic diffusion graph. Then, we encode the temporal information
into the heterogeneous graph to learn the users' dynamic preferences. Finally,
we apply multi-head attention to capture the context-dependency of the current
diffusion path to facilitate the information diffusion prediction task.
Experimental results show that DyHGCN significantly outperforms the
state-of-the-art models on three public datasets, which shows the effectiveness
of the proposed model.",Accepted to the ECML-PKDD 2020,,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2006.05169v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.05169v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.05169v1,"{'id': 'http://arxiv.org/abs/2006.05169v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.05169v1', 'updated': '2020-06-09T10:34:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=9, tm_hour=10, tm_min=34, tm_sec=41, tm_wday=1, tm_yday=161, tm_isdst=0), 'published': '2020-06-09T10:34:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=9, tm_hour=10, tm_min=34, tm_sec=41, tm_wday=1, tm_yday=161, tm_isdst=0), 'title': ""DyHGCN: A Dynamic Heterogeneous Graph Convolutional Network to Learn\n  Users' Dynamic Preferences for Information Diffusion Prediction"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""DyHGCN: A Dynamic Heterogeneous Graph Convolutional Network to Learn\n  Users' Dynamic Preferences for Information Diffusion Prediction""}, 'summary': ""Information diffusion prediction is a fundamental task for understanding the\ninformation propagation process. It has wide applications in such as\nmisinformation spreading prediction and malicious account detection. Previous\nworks either concentrate on utilizing the context of a single diffusion\nsequence or using the social network among users for information diffusion\nprediction. However, the diffusion paths of different messages naturally\nconstitute a dynamic diffusion graph. For one thing, previous works cannot\njointly utilize both the social network and diffusion graph for prediction,\nwhich is insufficient to model the complexity of the diffusion process and\nresults in unsatisfactory prediction performance. For another, they cannot\nlearn users' dynamic preferences. Intuitively, users' preferences are changing\nas time goes on and users' personal preference determines whether the user will\nrepost the information. Thus, it is beneficial to consider users' dynamic\npreferences in information diffusion prediction.\n  In this paper, we propose a novel dynamic heterogeneous graph convolutional\nnetwork (DyHGCN) to jointly learn the structural characteristics of the social\ngraph and dynamic diffusion graph. Then, we encode the temporal information\ninto the heterogeneous graph to learn the users' dynamic preferences. Finally,\nwe apply multi-head attention to capture the context-dependency of the current\ndiffusion path to facilitate the information diffusion prediction task.\nExperimental results show that DyHGCN significantly outperforms the\nstate-of-the-art models on three public datasets, which shows the effectiveness\nof the proposed model."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Information diffusion prediction is a fundamental task for understanding the\ninformation propagation process. It has wide applications in such as\nmisinformation spreading prediction and malicious account detection. Previous\nworks either concentrate on utilizing the context of a single diffusion\nsequence or using the social network among users for information diffusion\nprediction. However, the diffusion paths of different messages naturally\nconstitute a dynamic diffusion graph. For one thing, previous works cannot\njointly utilize both the social network and diffusion graph for prediction,\nwhich is insufficient to model the complexity of the diffusion process and\nresults in unsatisfactory prediction performance. For another, they cannot\nlearn users' dynamic preferences. Intuitively, users' preferences are changing\nas time goes on and users' personal preference determines whether the user will\nrepost the information. Thus, it is beneficial to consider users' dynamic\npreferences in information diffusion prediction.\n  In this paper, we propose a novel dynamic heterogeneous graph convolutional\nnetwork (DyHGCN) to jointly learn the structural characteristics of the social\ngraph and dynamic diffusion graph. Then, we encode the temporal information\ninto the heterogeneous graph to learn the users' dynamic preferences. Finally,\nwe apply multi-head attention to capture the context-dependency of the current\ndiffusion path to facilitate the information diffusion prediction task.\nExperimental results show that DyHGCN significantly outperforms the\nstate-of-the-art models on three public datasets, which shows the effectiveness\nof the proposed model.""}, 'authors': [{'name': 'Chunyuan Yuan'}, {'name': 'Jiacheng Li'}, {'name': 'Wei Zhou'}, {'name': 'Yijun Lu'}, {'name': 'Xiaodan Zhang'}, {'name': 'Songlin Hu'}], 'author_detail': {'name': 'Songlin Hu'}, 'author': 'Songlin Hu', 'arxiv_comment': 'Accepted to the ECML-PKDD 2020', 'links': [{'href': 'http://arxiv.org/abs/2006.05169v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.05169v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
265,http://arxiv.org/abs/2006.04666v2,2020-06-10 08:49:30+00:00,2020-06-08 15:13:44+00:00,Misinformation Has High Perplexity,"[arxiv.Result.Author('Nayeon Lee'), arxiv.Result.Author('Yejin Bang'), arxiv.Result.Author('Andrea Madotto'), arxiv.Result.Author('Pascale Fung')]","Debunking misinformation is an important and time-critical task as there
could be adverse consequences when misinformation is not quashed promptly.
However, the usual supervised approach to debunking via misinformation
classification requires human-annotated data and is not suited to the fast
time-frame of newly emerging events such as the COVID-19 outbreak. In this
paper, we postulate that misinformation itself has higher perplexity compared
to truthful statements, and propose to leverage the perplexity to debunk false
claims in an unsupervised manner. First, we extract reliable evidence from
scientific and news sources according to sentence similarity to the claims.
Second, we prime a language model with the extracted evidence and finally
evaluate the correctness of given claims based on the perplexity scores at
debunking time. We construct two new COVID-19-related test sets, one is
scientific, and another is political in content, and empirically verify that
our system performs favorably compared to existing systems. We are releasing
these datasets publicly to encourage more research in debunking misinformation
on COVID-19 and other topics.",,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2006.04666v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.04666v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.04666v2,"{'id': 'http://arxiv.org/abs/2006.04666v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.04666v2', 'updated': '2020-06-10T08:49:30Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=10, tm_hour=8, tm_min=49, tm_sec=30, tm_wday=2, tm_yday=162, tm_isdst=0), 'published': '2020-06-08T15:13:44Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=8, tm_hour=15, tm_min=13, tm_sec=44, tm_wday=0, tm_yday=160, tm_isdst=0), 'title': 'Misinformation Has High Perplexity', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation Has High Perplexity'}, 'summary': 'Debunking misinformation is an important and time-critical task as there\ncould be adverse consequences when misinformation is not quashed promptly.\nHowever, the usual supervised approach to debunking via misinformation\nclassification requires human-annotated data and is not suited to the fast\ntime-frame of newly emerging events such as the COVID-19 outbreak. In this\npaper, we postulate that misinformation itself has higher perplexity compared\nto truthful statements, and propose to leverage the perplexity to debunk false\nclaims in an unsupervised manner. First, we extract reliable evidence from\nscientific and news sources according to sentence similarity to the claims.\nSecond, we prime a language model with the extracted evidence and finally\nevaluate the correctness of given claims based on the perplexity scores at\ndebunking time. We construct two new COVID-19-related test sets, one is\nscientific, and another is political in content, and empirically verify that\nour system performs favorably compared to existing systems. We are releasing\nthese datasets publicly to encourage more research in debunking misinformation\non COVID-19 and other topics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Debunking misinformation is an important and time-critical task as there\ncould be adverse consequences when misinformation is not quashed promptly.\nHowever, the usual supervised approach to debunking via misinformation\nclassification requires human-annotated data and is not suited to the fast\ntime-frame of newly emerging events such as the COVID-19 outbreak. In this\npaper, we postulate that misinformation itself has higher perplexity compared\nto truthful statements, and propose to leverage the perplexity to debunk false\nclaims in an unsupervised manner. First, we extract reliable evidence from\nscientific and news sources according to sentence similarity to the claims.\nSecond, we prime a language model with the extracted evidence and finally\nevaluate the correctness of given claims based on the perplexity scores at\ndebunking time. We construct two new COVID-19-related test sets, one is\nscientific, and another is political in content, and empirically verify that\nour system performs favorably compared to existing systems. We are releasing\nthese datasets publicly to encourage more research in debunking misinformation\non COVID-19 and other topics.'}, 'authors': [{'name': 'Nayeon Lee'}, {'name': 'Yejin Bang'}, {'name': 'Andrea Madotto'}, {'name': 'Pascale Fung'}], 'author_detail': {'name': 'Pascale Fung'}, 'author': 'Pascale Fung', 'links': [{'href': 'http://arxiv.org/abs/2006.04666v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.04666v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
266,http://arxiv.org/abs/2006.04334v3,2020-10-04 13:28:50+00:00,2020-06-08 03:05:28+00:00,Characterizing Sociolinguistic Variation in the Competing Vaccination Communities,"[arxiv.Result.Author('Shahan Ali Memon'), arxiv.Result.Author('Aman Tyagi'), arxiv.Result.Author('David R. Mortensen'), arxiv.Result.Author('Kathleen M. Carley')]","Public health practitioners and policy makers grapple with the challenge of
devising effective message-based interventions for debunking public health
misinformation in cyber communities. ""Framing"" and ""personalization"" of the
message is one of the key features for devising a persuasive messaging
strategy. For an effective health communication, it is imperative to focus on
""preference-based framing"" where the preferences of the target sub-community
are taken into consideration. To achieve that, it is important to understand
and hence characterize the target sub-communities in terms of their social
interactions. In the context of health-related misinformation, vaccination
remains to be the most prevalent topic of discord. Hence, in this paper, we
conduct a sociolinguistic analysis of the two competing vaccination communities
on Twitter: ""pro-vaxxers"" or individuals who believe in the effectiveness of
vaccinations, and ""anti-vaxxers"" or individuals who are opposed to
vaccinations. Our data analysis show significant linguistic variation between
the two communities in terms of their usage of linguistic intensifiers,
pronouns, and uncertainty words. Our network-level analysis show significant
differences between the two communities in terms of their network density,
echo-chamberness, and the EI index. We hypothesize that these sociolinguistic
differences can be used as proxies to characterize and understand these
communities to devise better message interventions.","11 pages, 4 tables, 1 figure, 1 algorithm, accepted to SBP-BRiMS 2020
  -- International Conference on Social Computing, Behavioral-Cultural Modeling
  & Prediction and Behavior Representation in Modeling and Simulation",,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2006.04334v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.04334v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.04334v3,"{'id': 'http://arxiv.org/abs/2006.04334v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.04334v3', 'updated': '2020-10-04T13:28:50Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=4, tm_hour=13, tm_min=28, tm_sec=50, tm_wday=6, tm_yday=278, tm_isdst=0), 'published': '2020-06-08T03:05:28Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=8, tm_hour=3, tm_min=5, tm_sec=28, tm_wday=0, tm_yday=160, tm_isdst=0), 'title': 'Characterizing Sociolinguistic Variation in the Competing Vaccination\n  Communities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing Sociolinguistic Variation in the Competing Vaccination\n  Communities'}, 'summary': 'Public health practitioners and policy makers grapple with the challenge of\ndevising effective message-based interventions for debunking public health\nmisinformation in cyber communities. ""Framing"" and ""personalization"" of the\nmessage is one of the key features for devising a persuasive messaging\nstrategy. For an effective health communication, it is imperative to focus on\n""preference-based framing"" where the preferences of the target sub-community\nare taken into consideration. To achieve that, it is important to understand\nand hence characterize the target sub-communities in terms of their social\ninteractions. In the context of health-related misinformation, vaccination\nremains to be the most prevalent topic of discord. Hence, in this paper, we\nconduct a sociolinguistic analysis of the two competing vaccination communities\non Twitter: ""pro-vaxxers"" or individuals who believe in the effectiveness of\nvaccinations, and ""anti-vaxxers"" or individuals who are opposed to\nvaccinations. Our data analysis show significant linguistic variation between\nthe two communities in terms of their usage of linguistic intensifiers,\npronouns, and uncertainty words. Our network-level analysis show significant\ndifferences between the two communities in terms of their network density,\necho-chamberness, and the EI index. We hypothesize that these sociolinguistic\ndifferences can be used as proxies to characterize and understand these\ncommunities to devise better message interventions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Public health practitioners and policy makers grapple with the challenge of\ndevising effective message-based interventions for debunking public health\nmisinformation in cyber communities. ""Framing"" and ""personalization"" of the\nmessage is one of the key features for devising a persuasive messaging\nstrategy. For an effective health communication, it is imperative to focus on\n""preference-based framing"" where the preferences of the target sub-community\nare taken into consideration. To achieve that, it is important to understand\nand hence characterize the target sub-communities in terms of their social\ninteractions. In the context of health-related misinformation, vaccination\nremains to be the most prevalent topic of discord. Hence, in this paper, we\nconduct a sociolinguistic analysis of the two competing vaccination communities\non Twitter: ""pro-vaxxers"" or individuals who believe in the effectiveness of\nvaccinations, and ""anti-vaxxers"" or individuals who are opposed to\nvaccinations. Our data analysis show significant linguistic variation between\nthe two communities in terms of their usage of linguistic intensifiers,\npronouns, and uncertainty words. Our network-level analysis show significant\ndifferences between the two communities in terms of their network density,\necho-chamberness, and the EI index. We hypothesize that these sociolinguistic\ndifferences can be used as proxies to characterize and understand these\ncommunities to devise better message interventions.'}, 'authors': [{'name': 'Shahan Ali Memon'}, {'name': 'Aman Tyagi'}, {'name': 'David R. Mortensen'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_comment': '11 pages, 4 tables, 1 figure, 1 algorithm, accepted to SBP-BRiMS 2020\n  -- International Conference on Social Computing, Behavioral-Cultural Modeling\n  & Prediction and Behavior Representation in Modeling and Simulation', 'links': [{'href': 'http://arxiv.org/abs/2006.04334v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.04334v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
267,http://arxiv.org/abs/2006.02471v2,2020-08-06 03:11:38+00:00,2020-06-03 18:28:57+00:00,Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce Misinformation?,"[arxiv.Result.Author('Julio C. S. Reis'), arxiv.Result.Author('Philipe de Freitas Melo'), arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Fabrício Benevenuto')]","WhatsApp was alleged to be widely used to spread misinformation and
propaganda during elections in Brazil and India. Due to the private encrypted
nature of the messages on WhatsApp, it is hard to track the dissemination of
misinformation at scale. In this work, using public WhatsApp data, we observe
that misinformation has been largely shared on WhatsApp public groups even
after they were already fact-checked by popular fact-checking agencies. This
represents a significant portion of misinformation spread in both Brazil and
India in the groups analyzed. We posit that such misinformation content could
be prevented if WhatsApp had a means to flag already fact-checked content. To
this end, we propose an architecture that could be implemented by WhatsApp to
counter such misinformation. Our proposal respects the current end-to-end
encryption architecture on WhatsApp, thus protecting users' privacy while
providing an approach to detect the misinformation that benefits from
fact-checking efforts.","This is a preprint version of an accepted manuscript on The Harvard
  Kennedy School (HKS) Misinformation Review. Please, consider to cite it
  instead of this one",,,cs.CY,"['cs.CY', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2006.02471v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.02471v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.02471v2,"{'id': 'http://arxiv.org/abs/2006.02471v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.02471v2', 'updated': '2020-08-06T03:11:38Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=6, tm_hour=3, tm_min=11, tm_sec=38, tm_wday=3, tm_yday=219, tm_isdst=0), 'published': '2020-06-03T18:28:57Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=3, tm_hour=18, tm_min=28, tm_sec=57, tm_wday=2, tm_yday=155, tm_isdst=0), 'title': 'Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?'}, 'summary': ""WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.""}, 'authors': [{'name': 'Julio C. S. Reis'}, {'name': 'Philipe de Freitas Melo'}, {'name': 'Kiran Garimella'}, {'name': 'Fabrício Benevenuto'}], 'author_detail': {'name': 'Fabrício Benevenuto'}, 'author': 'Fabrício Benevenuto', 'arxiv_comment': 'This is a preprint version of an accepted manuscript on The Harvard\n  Kennedy School (HKS) Misinformation Review. Please, consider to cite it\n  instead of this one', 'links': [{'href': 'http://arxiv.org/abs/2006.02471v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.02471v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
268,http://arxiv.org/abs/2006.02181v3,2021-07-19 15:14:39+00:00,2020-06-03 11:34:25+00:00,Information Consumption and Social Response in a Segregated Environment: the Case of Gab,"[arxiv.Result.Author('Gabriele Etta'), arxiv.Result.Author('Alessandro Galeazzi'), arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Mauro Conti'), arxiv.Result.Author('Walter Quattrociocchi')]","Most of the information operations involve users who may foster polarization
and distrust toward science and mainstream journalism, without these users
being conscious of their role. Gab is well known to be an extremist-friendly
platform that performs little control on the posted content. Thus it represents
an ideal benchmark for studying phenomena potentially related to polarization
such as misinformation spreading. The combination of these factors may lead to
hate as well as to episodes of harm in the real world. In this work we provide
a characterization of the interaction patterns within Gab around the COVID-19
topic. To assess the spreading of different content type, we analyze
consumption patterns based on both interaction type and source reliability.
Overall we find that there are no strong statistical differences in the social
response to questionable and reliable content, both following a power law
distribution. However, questionable and reliable sources display structural and
topical differences in the use of hashtags. The commenting behaviour of users
in terms of both lifetime and sentiment reveals that questionable and reliable
posts are perceived in the same manner. We can conclude that despite evident
differences between questionable and reliable posts Gab users do not perform
such a differentiation thus treating them as a whole. Our results provide
insights toward the understanding of coordinated inauthentic behavior and on
the early-warning of information operation.",The paper is now replaced with an updated version: arXiv:2106.03924,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2006.02181v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.02181v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.02181v3,"{'id': 'http://arxiv.org/abs/2006.02181v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.02181v3', 'updated': '2021-07-19T15:14:39Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=19, tm_hour=15, tm_min=14, tm_sec=39, tm_wday=0, tm_yday=200, tm_isdst=0), 'published': '2020-06-03T11:34:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=3, tm_hour=11, tm_min=34, tm_sec=25, tm_wday=2, tm_yday=155, tm_isdst=0), 'title': 'Information Consumption and Social Response in a Segregated Environment:\n  the Case of Gab', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information Consumption and Social Response in a Segregated Environment:\n  the Case of Gab'}, 'summary': 'Most of the information operations involve users who may foster polarization\nand distrust toward science and mainstream journalism, without these users\nbeing conscious of their role. Gab is well known to be an extremist-friendly\nplatform that performs little control on the posted content. Thus it represents\nan ideal benchmark for studying phenomena potentially related to polarization\nsuch as misinformation spreading. The combination of these factors may lead to\nhate as well as to episodes of harm in the real world. In this work we provide\na characterization of the interaction patterns within Gab around the COVID-19\ntopic. To assess the spreading of different content type, we analyze\nconsumption patterns based on both interaction type and source reliability.\nOverall we find that there are no strong statistical differences in the social\nresponse to questionable and reliable content, both following a power law\ndistribution. However, questionable and reliable sources display structural and\ntopical differences in the use of hashtags. The commenting behaviour of users\nin terms of both lifetime and sentiment reveals that questionable and reliable\nposts are perceived in the same manner. We can conclude that despite evident\ndifferences between questionable and reliable posts Gab users do not perform\nsuch a differentiation thus treating them as a whole. Our results provide\ninsights toward the understanding of coordinated inauthentic behavior and on\nthe early-warning of information operation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Most of the information operations involve users who may foster polarization\nand distrust toward science and mainstream journalism, without these users\nbeing conscious of their role. Gab is well known to be an extremist-friendly\nplatform that performs little control on the posted content. Thus it represents\nan ideal benchmark for studying phenomena potentially related to polarization\nsuch as misinformation spreading. The combination of these factors may lead to\nhate as well as to episodes of harm in the real world. In this work we provide\na characterization of the interaction patterns within Gab around the COVID-19\ntopic. To assess the spreading of different content type, we analyze\nconsumption patterns based on both interaction type and source reliability.\nOverall we find that there are no strong statistical differences in the social\nresponse to questionable and reliable content, both following a power law\ndistribution. However, questionable and reliable sources display structural and\ntopical differences in the use of hashtags. The commenting behaviour of users\nin terms of both lifetime and sentiment reveals that questionable and reliable\nposts are perceived in the same manner. We can conclude that despite evident\ndifferences between questionable and reliable posts Gab users do not perform\nsuch a differentiation thus treating them as a whole. Our results provide\ninsights toward the understanding of coordinated inauthentic behavior and on\nthe early-warning of information operation.'}, 'authors': [{'name': 'Gabriele Etta'}, {'name': 'Alessandro Galeazzi'}, {'name': 'Matteo Cinelli'}, {'name': 'Mauro Conti'}, {'name': 'Walter Quattrociocchi'}], 'author_detail': {'name': 'Walter Quattrociocchi'}, 'author': 'Walter Quattrociocchi', 'arxiv_comment': 'The paper is now replaced with an updated version: arXiv:2106.03924', 'links': [{'href': 'http://arxiv.org/abs/2006.02181v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.02181v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
269,http://arxiv.org/abs/2006.01284v3,2020-06-30 22:30:37+00:00,2020-06-01 21:48:22+00:00,Independent Component Analysis for Trustworthy Cyberspace during High Impact Events: An Application to Covid-19,"[arxiv.Result.Author('Zois Boukouvalas'), arxiv.Result.Author('Christine Mallinson'), arxiv.Result.Author('Evan Crothers'), arxiv.Result.Author('Nathalie Japkowicz'), arxiv.Result.Author('Aritran Piplai'), arxiv.Result.Author('Sudip Mittal'), arxiv.Result.Author('Anupam Joshi'), arxiv.Result.Author('Tülay Adalı')]","Social media has become an important communication channel during high impact
events, such as the COVID-19 pandemic. As misinformation in social media can
rapidly spread, creating social unrest, curtailing the spread of misinformation
during such events is a significant data challenge. While recent solutions that
are based on machine learning have shown promise for the detection of
misinformation, most widely used methods include approaches that rely on either
handcrafted features that cannot be optimal for all scenarios, or those that
are based on deep learning where the interpretation of the prediction results
is not directly accessible. In this work, we propose a data-driven solution
that is based on the ICA model, such that knowledge discovery and detection of
misinformation are achieved jointly. To demonstrate the effectiveness of our
method and compare its performance with deep learning methods, we developed a
labeled COVID-19 Twitter dataset based on socio-linguistic criteria.",,,,cs.LG,"['cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2006.01284v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.01284v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.01284v3,"{'id': 'http://arxiv.org/abs/2006.01284v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.01284v3', 'updated': '2020-06-30T22:30:37Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=30, tm_hour=22, tm_min=30, tm_sec=37, tm_wday=1, tm_yday=182, tm_isdst=0), 'published': '2020-06-01T21:48:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=1, tm_hour=21, tm_min=48, tm_sec=22, tm_wday=0, tm_yday=153, tm_isdst=0), 'title': 'Independent Component Analysis for Trustworthy Cyberspace during High\n  Impact Events: An Application to Covid-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Independent Component Analysis for Trustworthy Cyberspace during High\n  Impact Events: An Application to Covid-19'}, 'summary': 'Social media has become an important communication channel during high impact\nevents, such as the COVID-19 pandemic. As misinformation in social media can\nrapidly spread, creating social unrest, curtailing the spread of misinformation\nduring such events is a significant data challenge. While recent solutions that\nare based on machine learning have shown promise for the detection of\nmisinformation, most widely used methods include approaches that rely on either\nhandcrafted features that cannot be optimal for all scenarios, or those that\nare based on deep learning where the interpretation of the prediction results\nis not directly accessible. In this work, we propose a data-driven solution\nthat is based on the ICA model, such that knowledge discovery and detection of\nmisinformation are achieved jointly. To demonstrate the effectiveness of our\nmethod and compare its performance with deep learning methods, we developed a\nlabeled COVID-19 Twitter dataset based on socio-linguistic criteria.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media has become an important communication channel during high impact\nevents, such as the COVID-19 pandemic. As misinformation in social media can\nrapidly spread, creating social unrest, curtailing the spread of misinformation\nduring such events is a significant data challenge. While recent solutions that\nare based on machine learning have shown promise for the detection of\nmisinformation, most widely used methods include approaches that rely on either\nhandcrafted features that cannot be optimal for all scenarios, or those that\nare based on deep learning where the interpretation of the prediction results\nis not directly accessible. In this work, we propose a data-driven solution\nthat is based on the ICA model, such that knowledge discovery and detection of\nmisinformation are achieved jointly. To demonstrate the effectiveness of our\nmethod and compare its performance with deep learning methods, we developed a\nlabeled COVID-19 Twitter dataset based on socio-linguistic criteria.'}, 'authors': [{'name': 'Zois Boukouvalas'}, {'name': 'Christine Mallinson'}, {'name': 'Evan Crothers'}, {'name': 'Nathalie Japkowicz'}, {'name': 'Aritran Piplai'}, {'name': 'Sudip Mittal'}, {'name': 'Anupam Joshi'}, {'name': 'Tülay Adalı'}], 'author_detail': {'name': 'Tülay Adalı'}, 'author': 'Tülay Adalı', 'links': [{'href': 'http://arxiv.org/abs/2006.01284v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.01284v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
270,http://arxiv.org/abs/2006.00765v2,2021-04-06 14:09:31+00:00,2020-06-01 07:45:35+00:00,Conspiracy vs science: A large-scale analysis of online discussion cascades,"[arxiv.Result.Author('Yafei Zhang'), arxiv.Result.Author('Lin Wang'), arxiv.Result.Author('Jonathan J. H. Zhu'), arxiv.Result.Author('Xiaofan Wang')]","With the emergence and rapid proliferation of social media platforms and
social networking sites, recent years have witnessed a surge of misinformation
spreading in our daily life. Drawing on a large-scale dataset which covers more
than 1.4M posts and 18M comments, we investigate the propagation of two
distinct narratives--(i) conspiracy information, whose claims are generally
unsubstantiated and thus referred as misinformation to some extent, and (ii)
scientific information, whose origins are generally readily identifiable and
verifiable--in an online social media platform. We find that conspiracy
cascades tend to propagate in a multigenerational branching process while
science cascades are more likely to grow in a breadth-first manner.
Specifically, conspiracy information triggers larger cascades, involves more
users and generations, persists longer, is more viral and bursty than science
information. Content analysis reveals that conspiracy cascades contain more
negative words and emotional words which convey anger, fear, disgust, surprise
and trust. We also find that conspiracy cascades are more concerned with
political and controversial topics. After applying machine learning models, we
achieve an AUC score of nearly 90% in discriminating conspiracy from science
narratives.
  We find that conspiracy cascades are more likely to be controlled by a
broader set of users than science cascades, imposing new challenges on the
management of misinformation. Although political affinity is thought to affect
the consumption of misinformation, there is very little evidence that political
orientation of the information source plays a role during the propagation of
conspiracy information. Our study provides complementing evidence to current
misinformation research and has practical policy implications to stem the
propagation and mitigate the influence of misinformation online.","24 pages, 9 figures, 3 tables","World Wide Web 24, 585-606 (2021)",10.1007/s11280-021-00862-x,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s11280-021-00862-x', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2006.00765v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.00765v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.00765v2,"{'id': 'http://arxiv.org/abs/2006.00765v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.00765v2', 'updated': '2021-04-06T14:09:31Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=6, tm_hour=14, tm_min=9, tm_sec=31, tm_wday=1, tm_yday=96, tm_isdst=0), 'published': '2020-06-01T07:45:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=1, tm_hour=7, tm_min=45, tm_sec=35, tm_wday=0, tm_yday=153, tm_isdst=0), 'title': 'Conspiracy vs science: A large-scale analysis of online discussion\n  cascades', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Conspiracy vs science: A large-scale analysis of online discussion\n  cascades'}, 'summary': 'With the emergence and rapid proliferation of social media platforms and\nsocial networking sites, recent years have witnessed a surge of misinformation\nspreading in our daily life. Drawing on a large-scale dataset which covers more\nthan 1.4M posts and 18M comments, we investigate the propagation of two\ndistinct narratives--(i) conspiracy information, whose claims are generally\nunsubstantiated and thus referred as misinformation to some extent, and (ii)\nscientific information, whose origins are generally readily identifiable and\nverifiable--in an online social media platform. We find that conspiracy\ncascades tend to propagate in a multigenerational branching process while\nscience cascades are more likely to grow in a breadth-first manner.\nSpecifically, conspiracy information triggers larger cascades, involves more\nusers and generations, persists longer, is more viral and bursty than science\ninformation. Content analysis reveals that conspiracy cascades contain more\nnegative words and emotional words which convey anger, fear, disgust, surprise\nand trust. We also find that conspiracy cascades are more concerned with\npolitical and controversial topics. After applying machine learning models, we\nachieve an AUC score of nearly 90% in discriminating conspiracy from science\nnarratives.\n  We find that conspiracy cascades are more likely to be controlled by a\nbroader set of users than science cascades, imposing new challenges on the\nmanagement of misinformation. Although political affinity is thought to affect\nthe consumption of misinformation, there is very little evidence that political\norientation of the information source plays a role during the propagation of\nconspiracy information. Our study provides complementing evidence to current\nmisinformation research and has practical policy implications to stem the\npropagation and mitigate the influence of misinformation online.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the emergence and rapid proliferation of social media platforms and\nsocial networking sites, recent years have witnessed a surge of misinformation\nspreading in our daily life. Drawing on a large-scale dataset which covers more\nthan 1.4M posts and 18M comments, we investigate the propagation of two\ndistinct narratives--(i) conspiracy information, whose claims are generally\nunsubstantiated and thus referred as misinformation to some extent, and (ii)\nscientific information, whose origins are generally readily identifiable and\nverifiable--in an online social media platform. We find that conspiracy\ncascades tend to propagate in a multigenerational branching process while\nscience cascades are more likely to grow in a breadth-first manner.\nSpecifically, conspiracy information triggers larger cascades, involves more\nusers and generations, persists longer, is more viral and bursty than science\ninformation. Content analysis reveals that conspiracy cascades contain more\nnegative words and emotional words which convey anger, fear, disgust, surprise\nand trust. We also find that conspiracy cascades are more concerned with\npolitical and controversial topics. After applying machine learning models, we\nachieve an AUC score of nearly 90% in discriminating conspiracy from science\nnarratives.\n  We find that conspiracy cascades are more likely to be controlled by a\nbroader set of users than science cascades, imposing new challenges on the\nmanagement of misinformation. Although political affinity is thought to affect\nthe consumption of misinformation, there is very little evidence that political\norientation of the information source plays a role during the propagation of\nconspiracy information. Our study provides complementing evidence to current\nmisinformation research and has practical policy implications to stem the\npropagation and mitigate the influence of misinformation online.'}, 'authors': [{'name': 'Yafei Zhang'}, {'name': 'Lin Wang'}, {'name': 'Jonathan J. H. Zhu'}, {'name': 'Xiaofan Wang'}], 'author_detail': {'name': 'Xiaofan Wang'}, 'author': 'Xiaofan Wang', 'arxiv_doi': '10.1007/s11280-021-00862-x', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s11280-021-00862-x', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2006.00765v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.00765v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '24 pages, 9 figures, 3 tables', 'arxiv_journal_ref': 'World Wide Web 24, 585-606 (2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
271,http://arxiv.org/abs/2005.13691v1,2020-05-27 22:41:02+00:00,2020-05-27 22:41:02+00:00,"Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics","[arxiv.Result.Author('Kaize Ding'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Yichuan Li'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Huan Liu')]","While the COVID-19 pandemic continues its global devastation, numerous
accompanying challenges emerge. One important challenge we face is to
efficiently and effectively use recently gathered data and find computational
tools to combat the COVID-19 infodemic, a typical information overloading
problem. Novel coronavirus presents many questions without ready answers; its
uncertainty and our eagerness in search of solutions offer a fertile
environment for infodemic. It is thus necessary to combat the infodemic and
make a concerted effort to confront COVID-19 and mitigate its negative impact
in all walks of life when saving lives and maintaining normal orders during
trying times. In this position paper of combating the COVID-19 infodemic, we
illustrate its need by providing real-world examples of rampant conspiracy
theories, misinformation, and various types of scams that take advantage of
human kindness, fear, and ignorance. We present three key challenges in this
fight against the COVID-19 infodemic where researchers and practitioners
instinctively want to contribute and help. We demonstrate that these three
challenges can and will be effectively addressed by collective wisdom,
crowdsourcing, and collaborative research.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2005.13691v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.13691v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.13691v1,"{'id': 'http://arxiv.org/abs/2005.13691v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.13691v1', 'updated': '2020-05-27T22:41:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=22, tm_min=41, tm_sec=2, tm_wday=2, tm_yday=148, tm_isdst=0), 'published': '2020-05-27T22:41:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=22, tm_min=41, tm_sec=2, tm_wday=2, tm_yday=148, tm_isdst=0), 'title': 'Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics'}, 'summary': 'While the COVID-19 pandemic continues its global devastation, numerous\naccompanying challenges emerge. One important challenge we face is to\nefficiently and effectively use recently gathered data and find computational\ntools to combat the COVID-19 infodemic, a typical information overloading\nproblem. Novel coronavirus presents many questions without ready answers; its\nuncertainty and our eagerness in search of solutions offer a fertile\nenvironment for infodemic. It is thus necessary to combat the infodemic and\nmake a concerted effort to confront COVID-19 and mitigate its negative impact\nin all walks of life when saving lives and maintaining normal orders during\ntrying times. In this position paper of combating the COVID-19 infodemic, we\nillustrate its need by providing real-world examples of rampant conspiracy\ntheories, misinformation, and various types of scams that take advantage of\nhuman kindness, fear, and ignorance. We present three key challenges in this\nfight against the COVID-19 infodemic where researchers and practitioners\ninstinctively want to contribute and help. We demonstrate that these three\nchallenges can and will be effectively addressed by collective wisdom,\ncrowdsourcing, and collaborative research.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While the COVID-19 pandemic continues its global devastation, numerous\naccompanying challenges emerge. One important challenge we face is to\nefficiently and effectively use recently gathered data and find computational\ntools to combat the COVID-19 infodemic, a typical information overloading\nproblem. Novel coronavirus presents many questions without ready answers; its\nuncertainty and our eagerness in search of solutions offer a fertile\nenvironment for infodemic. It is thus necessary to combat the infodemic and\nmake a concerted effort to confront COVID-19 and mitigate its negative impact\nin all walks of life when saving lives and maintaining normal orders during\ntrying times. In this position paper of combating the COVID-19 infodemic, we\nillustrate its need by providing real-world examples of rampant conspiracy\ntheories, misinformation, and various types of scams that take advantage of\nhuman kindness, fear, and ignorance. We present three key challenges in this\nfight against the COVID-19 infodemic where researchers and practitioners\ninstinctively want to contribute and help. We demonstrate that these three\nchallenges can and will be effectively addressed by collective wisdom,\ncrowdsourcing, and collaborative research.'}, 'authors': [{'name': 'Kaize Ding'}, {'name': 'Kai Shu'}, {'name': 'Yichuan Li'}, {'name': 'Amrita Bhattacharjee'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'links': [{'href': 'http://arxiv.org/abs/2005.13691v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.13691v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
272,http://arxiv.org/abs/2005.13270v1,2020-05-27 10:29:14+00:00,2020-05-27 10:29:14+00:00,BRENDA: Browser Extension for Fake News Detection,"[arxiv.Result.Author('Bjarte Botnevik'), arxiv.Result.Author('Eirik Sakariassen'), arxiv.Result.Author('Vinay Setty')]","Misinformation such as fake news has drawn a lot of attention in recent
years. It has serious consequences on society, politics and economy. This has
lead to a rise of manually fact-checking websites such as Snopes and
Politifact. However, the scale of misinformation limits their ability for
verification. In this demonstration, we propose BRENDA a browser extension
which can be used to automate the entire process of credibility assessments of
false claims. Behind the scenes BRENDA uses a tested deep neural network
architecture to automatically identify fact check worthy claims and classifies
as well as presents the result along with evidence to the user. Since BRENDA is
a browser extension, it facilities fast automated fact checking for the end
user without having to leave the Webpage.",Accepted as SIGIR demo,"In Proceedings of the 43rd International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR 2020), July 25 to
  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages",10.1145/3397271.3401396,cs.IR,"['cs.IR', 'cs.AI', 'I.2.7']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3397271.3401396', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.13270v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.13270v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.13270v1,"{'id': 'http://arxiv.org/abs/2005.13270v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.13270v1', 'updated': '2020-05-27T10:29:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=10, tm_min=29, tm_sec=14, tm_wday=2, tm_yday=148, tm_isdst=0), 'published': '2020-05-27T10:29:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=27, tm_hour=10, tm_min=29, tm_sec=14, tm_wday=2, tm_yday=148, tm_isdst=0), 'title': 'BRENDA: Browser Extension for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BRENDA: Browser Extension for Fake News Detection'}, 'summary': 'Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.'}, 'authors': [{'name': 'Bjarte Botnevik'}, {'name': 'Eirik Sakariassen'}, {'name': 'Vinay Setty'}], 'author_detail': {'name': 'Vinay Setty'}, 'author': 'Vinay Setty', 'arxiv_doi': '10.1145/3397271.3401396', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3397271.3401396', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.13270v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.13270v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted as SIGIR demo', 'arxiv_journal_ref': 'In Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2020), July 25 to\n  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
273,http://arxiv.org/abs/2006.00885v3,2020-11-03 20:37:11+00:00,2020-05-22 19:08:14+00:00,CoAID: COVID-19 Healthcare Misinformation Dataset,"[arxiv.Result.Author('Limeng Cui'), arxiv.Result.Author('Dongwon Lee')]","As the COVID-19 virus quickly spreads around the world, unfortunately,
misinformation related to COVID-19 also gets created and spreads like wild
fire. Such misinformation has caused confusion among people, disruptions in
society, and even deadly consequences in health problems. To be able to
understand, detect, and mitigate such COVID-19 misinformation, therefore, has
not only deep intellectual values but also huge societal impacts. To help
researchers combat COVID-19 health misinformation, therefore, we present CoAID
(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare
misinformation, including fake news on websites and social platforms, along
with users' social engagement about such news. CoAID includes 4,251 news,
296,000 related user engagements, 926 social platform posts about COVID-19, and
ground truth labels. The dataset is available at:
https://github.com/cuilimeng/CoAID.",,,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2006.00885v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2006.00885v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2006.00885v3,"{'id': 'http://arxiv.org/abs/2006.00885v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2006.00885v3', 'updated': '2020-11-03T20:37:11Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=20, tm_min=37, tm_sec=11, tm_wday=1, tm_yday=308, tm_isdst=0), 'published': '2020-05-22T19:08:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=22, tm_hour=19, tm_min=8, tm_sec=14, tm_wday=4, tm_yday=143, tm_isdst=0), 'title': 'CoAID: COVID-19 Healthcare Misinformation Dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CoAID: COVID-19 Healthcare Misinformation Dataset'}, 'summary': ""As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.""}, 'authors': [{'name': 'Limeng Cui'}, {'name': 'Dongwon Lee'}], 'author_detail': {'name': 'Dongwon Lee'}, 'author': 'Dongwon Lee', 'links': [{'href': 'http://arxiv.org/abs/2006.00885v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2006.00885v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
274,http://arxiv.org/abs/2005.10414v1,2020-05-21 01:34:08+00:00,2020-05-21 01:34:08+00:00,"Analysis of misinformation during the COVID-19 outbreak in China: cultural, social and political entanglements","[arxiv.Result.Author('Yan Leng'), arxiv.Result.Author('Yujia Zhai'), arxiv.Result.Author('Shaojing Sun'), arxiv.Result.Author('Yifei Wu'), arxiv.Result.Author('Jordan Selzer'), arxiv.Result.Author('Sharon Strover'), arxiv.Result.Author('Julia Fensel'), arxiv.Result.Author('Alex Pentland'), arxiv.Result.Author('Ying Ding')]","COVID-19 resulted in an infodemic, which could erode public trust, impede
virus containment, and outlive the pandemic itself. The evolving and fragmented
media landscape is a key driver of the spread of misinformation. Using
misinformation identified by the fact-checking platform by Tencent and posts on
Weibo, our results showed that the evolution of misinformation follows an
issue-attention cycle, pertaining to topics such as city lockdown, cures, and
preventions, and school reopening. Sources of authority weigh in on these
topics, but their influence is complicated by peoples' pre-existing beliefs and
cultural practices. Finally, social media has a complicated relationship with
established or legacy media systems. Sometimes they reinforce each other, but
in general, social media may have a topic cycle of its own making. Our findings
shed light on the distinct characteristics of misinformation during the
COVID-19 and offer insights into combating misinformation in China and across
the world at large.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2005.10414v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.10414v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.10414v1,"{'id': 'http://arxiv.org/abs/2005.10414v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.10414v1', 'updated': '2020-05-21T01:34:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=21, tm_hour=1, tm_min=34, tm_sec=8, tm_wday=3, tm_yday=142, tm_isdst=0), 'published': '2020-05-21T01:34:08Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=21, tm_hour=1, tm_min=34, tm_sec=8, tm_wday=3, tm_yday=142, tm_isdst=0), 'title': 'Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements'}, 'summary': ""COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.""}, 'authors': [{'name': 'Yan Leng'}, {'name': 'Yujia Zhai'}, {'name': 'Shaojing Sun'}, {'name': 'Yifei Wu'}, {'name': 'Jordan Selzer'}, {'name': 'Sharon Strover'}, {'name': 'Julia Fensel'}, {'name': 'Alex Pentland'}, {'name': 'Ying Ding'}], 'author_detail': {'name': 'Ying Ding'}, 'author': 'Ying Ding', 'links': [{'href': 'http://arxiv.org/abs/2005.10414v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.10414v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
275,http://arxiv.org/abs/2005.09784v1,2020-05-19 23:00:17+00:00,2020-05-19 23:00:17+00:00,Images and Misinformation in Political Groups: Evidence from WhatsApp in India,"[arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Dean Eckles')]","WhatsApp is a key medium for the spread of news and rumors, often shared as
images. We study a large collection of politically-oriented WhatsApp groups in
India, focusing on the period leading up to the 2019 Indian national elections.
By labeling samples of random and popular images, we find that around 13% of
shared images are known misinformation and most fall into three types of
images. Machine learning methods can be used to predict whether a viral image
is misinformation, but are brittle to shifts in content over time.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2005.09784v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.09784v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.09784v1,"{'id': 'http://arxiv.org/abs/2005.09784v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.09784v1', 'updated': '2020-05-19T23:00:17Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=19, tm_hour=23, tm_min=0, tm_sec=17, tm_wday=1, tm_yday=140, tm_isdst=0), 'published': '2020-05-19T23:00:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=19, tm_hour=23, tm_min=0, tm_sec=17, tm_wday=1, tm_yday=140, tm_isdst=0), 'title': 'Images and Misinformation in Political Groups: Evidence from WhatsApp in\n  India', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Images and Misinformation in Political Groups: Evidence from WhatsApp in\n  India'}, 'summary': 'WhatsApp is a key medium for the spread of news and rumors, often shared as\nimages. We study a large collection of politically-oriented WhatsApp groups in\nIndia, focusing on the period leading up to the 2019 Indian national elections.\nBy labeling samples of random and popular images, we find that around 13% of\nshared images are known misinformation and most fall into three types of\nimages. Machine learning methods can be used to predict whether a viral image\nis misinformation, but are brittle to shifts in content over time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'WhatsApp is a key medium for the spread of news and rumors, often shared as\nimages. We study a large collection of politically-oriented WhatsApp groups in\nIndia, focusing on the period leading up to the 2019 Indian national elections.\nBy labeling samples of random and popular images, we find that around 13% of\nshared images are known misinformation and most fall into three types of\nimages. Machine learning methods can be used to predict whether a viral image\nis misinformation, but are brittle to shifts in content over time.'}, 'authors': [{'name': 'Kiran Garimella'}, {'name': 'Dean Eckles'}], 'author_detail': {'name': 'Dean Eckles'}, 'author': 'Dean Eckles', 'links': [{'href': 'http://arxiv.org/abs/2005.09784v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.09784v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
276,http://arxiv.org/abs/2005.08141v4,2021-07-20 19:02:44+00:00,2020-05-17 01:20:24+00:00,Neutral bots probe political bias on social media,"[arxiv.Result.Author('Wen Chen'), arxiv.Result.Author('Diogo Pacheco'), arxiv.Result.Author('Kai-Cheng Yang'), arxiv.Result.Author('Filippo Menczer')]","Social media platforms attempting to curb abuse and misinformation have been
accused of political bias. We deploy neutral social bots who start following
different news sources on Twitter, and track them to probe distinct biases
emerging from platform mechanisms versus user interactions. We find no strong
or consistent evidence of political bias in the news feed. Despite this, the
news and information to which U.S. Twitter users are exposed depend strongly on
the political leaning of their early connections. The interactions of
conservative accounts are skewed toward the right, whereas liberal accounts are
exposed to moderate content shifting their experience toward the political
center. Partisan accounts, especially conservative ones, tend to receive more
followers and follow more automated accounts. Conservative accounts also find
themselves in denser communities and are exposed to more low-credibility
content.","26 pages, 6 figures. Appendix: 10 pages, 5 figures and 4 tables","Nat Commun 12, 5580 (2021)",10.1038/s41467-021-25738-6,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41467-021-25738-6', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.08141v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.08141v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.08141v4,"{'id': 'http://arxiv.org/abs/2005.08141v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.08141v4', 'updated': '2021-07-20T19:02:44Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=20, tm_hour=19, tm_min=2, tm_sec=44, tm_wday=1, tm_yday=201, tm_isdst=0), 'published': '2020-05-17T01:20:24Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=17, tm_hour=1, tm_min=20, tm_sec=24, tm_wday=6, tm_yday=138, tm_isdst=0), 'title': 'Neutral bots probe political bias on social media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Neutral bots probe political bias on social media'}, 'summary': 'Social media platforms attempting to curb abuse and misinformation have been\naccused of political bias. We deploy neutral social bots who start following\ndifferent news sources on Twitter, and track them to probe distinct biases\nemerging from platform mechanisms versus user interactions. We find no strong\nor consistent evidence of political bias in the news feed. Despite this, the\nnews and information to which U.S. Twitter users are exposed depend strongly on\nthe political leaning of their early connections. The interactions of\nconservative accounts are skewed toward the right, whereas liberal accounts are\nexposed to moderate content shifting their experience toward the political\ncenter. Partisan accounts, especially conservative ones, tend to receive more\nfollowers and follow more automated accounts. Conservative accounts also find\nthemselves in denser communities and are exposed to more low-credibility\ncontent.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media platforms attempting to curb abuse and misinformation have been\naccused of political bias. We deploy neutral social bots who start following\ndifferent news sources on Twitter, and track them to probe distinct biases\nemerging from platform mechanisms versus user interactions. We find no strong\nor consistent evidence of political bias in the news feed. Despite this, the\nnews and information to which U.S. Twitter users are exposed depend strongly on\nthe political leaning of their early connections. The interactions of\nconservative accounts are skewed toward the right, whereas liberal accounts are\nexposed to moderate content shifting their experience toward the political\ncenter. Partisan accounts, especially conservative ones, tend to receive more\nfollowers and follow more automated accounts. Conservative accounts also find\nthemselves in denser communities and are exposed to more low-credibility\ncontent.'}, 'authors': [{'name': 'Wen Chen'}, {'name': 'Diogo Pacheco'}, {'name': 'Kai-Cheng Yang'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1038/s41467-021-25738-6', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41467-021-25738-6', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.08141v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.08141v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '26 pages, 6 figures. Appendix: 10 pages, 5 figures and 4 tables', 'arxiv_journal_ref': 'Nat Commun 12, 5580 (2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
277,http://arxiv.org/abs/2005.08039v3,2021-05-10 11:02:30+00:00,2020-05-16 16:52:12+00:00,Improved x-space Algorithm for Min-Max Bilevel Integer Programming with an Application to Misinformation Spread in Social Networks,"[arxiv.Result.Author('Kübra Tanınmış'), arxiv.Result.Author('Necati Aras'), arxiv.Result.Author('İ. Kuban Altınel')]","In this work we propose an improvement of the $x$-space algorithm developed
for solving a class of min--max bilevel optimization problems (Tang Y., Richard
J.P.P., Smith J.C. (2016), A class of algorithms for mixed-integer bilevel
min--max optimization. Journal of Global Optimization, 66(2), 225--262). In
this setting, the leader of the upper level problem aims at restricting the
follower's decisions by minimizing an objective function, which the follower
intends to maximize in the lower level problem by making decisions still
available to her. The $x$-space algorithm solves upper and lower bound problems
consecutively until convergence, and requires the dualization of an
approximation of the follower's problem in formulating the lower bound problem.
We first reformulate the lower bound problem using the properties of an optimal
solution to the original formulation, which makes the dualization step
unnecessary. The reformulation makes possible the integration of a greedy
covering heuristic into the solution scheme, which results in a considerable
increase in the efficiency. The new algorithm referred to as the improved
$x$-space algorithm is implemented and applied to a recent min--max bilevel
optimization problem that arises in the context of reducing the misinformation
spread in social networks. It is also assessed on the benchmark instances of
two other bilevel problems: zero-one knapsack problem with interdiction and
maximum clique problem with interdiction. Numerical results indicate that the
performance of the new algorithm is superior to that of the original algorithm,
and also compares favorably with a recent algorithm developed for mixed-integer
bilevel linear programs.","31 pages, 7 tables, 4 figures. To be published in EJOR",,10.1016/j.ejor.2021.05.008,math.OC,['math.OC'],"[arxiv.Result.Link('http://dx.doi.org/10.1016/j.ejor.2021.05.008', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.08039v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.08039v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.08039v3,"{'id': 'http://arxiv.org/abs/2005.08039v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.08039v3', 'updated': '2021-05-10T11:02:30Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=10, tm_hour=11, tm_min=2, tm_sec=30, tm_wday=0, tm_yday=130, tm_isdst=0), 'published': '2020-05-16T16:52:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=16, tm_hour=16, tm_min=52, tm_sec=12, tm_wday=5, tm_yday=137, tm_isdst=0), 'title': 'Improved x-space Algorithm for Min-Max Bilevel Integer Programming with\n  an Application to Misinformation Spread in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Improved x-space Algorithm for Min-Max Bilevel Integer Programming with\n  an Application to Misinformation Spread in Social Networks'}, 'summary': ""In this work we propose an improvement of the $x$-space algorithm developed\nfor solving a class of min--max bilevel optimization problems (Tang Y., Richard\nJ.P.P., Smith J.C. (2016), A class of algorithms for mixed-integer bilevel\nmin--max optimization. Journal of Global Optimization, 66(2), 225--262). In\nthis setting, the leader of the upper level problem aims at restricting the\nfollower's decisions by minimizing an objective function, which the follower\nintends to maximize in the lower level problem by making decisions still\navailable to her. The $x$-space algorithm solves upper and lower bound problems\nconsecutively until convergence, and requires the dualization of an\napproximation of the follower's problem in formulating the lower bound problem.\nWe first reformulate the lower bound problem using the properties of an optimal\nsolution to the original formulation, which makes the dualization step\nunnecessary. The reformulation makes possible the integration of a greedy\ncovering heuristic into the solution scheme, which results in a considerable\nincrease in the efficiency. The new algorithm referred to as the improved\n$x$-space algorithm is implemented and applied to a recent min--max bilevel\noptimization problem that arises in the context of reducing the misinformation\nspread in social networks. It is also assessed on the benchmark instances of\ntwo other bilevel problems: zero-one knapsack problem with interdiction and\nmaximum clique problem with interdiction. Numerical results indicate that the\nperformance of the new algorithm is superior to that of the original algorithm,\nand also compares favorably with a recent algorithm developed for mixed-integer\nbilevel linear programs."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In this work we propose an improvement of the $x$-space algorithm developed\nfor solving a class of min--max bilevel optimization problems (Tang Y., Richard\nJ.P.P., Smith J.C. (2016), A class of algorithms for mixed-integer bilevel\nmin--max optimization. Journal of Global Optimization, 66(2), 225--262). In\nthis setting, the leader of the upper level problem aims at restricting the\nfollower's decisions by minimizing an objective function, which the follower\nintends to maximize in the lower level problem by making decisions still\navailable to her. The $x$-space algorithm solves upper and lower bound problems\nconsecutively until convergence, and requires the dualization of an\napproximation of the follower's problem in formulating the lower bound problem.\nWe first reformulate the lower bound problem using the properties of an optimal\nsolution to the original formulation, which makes the dualization step\nunnecessary. The reformulation makes possible the integration of a greedy\ncovering heuristic into the solution scheme, which results in a considerable\nincrease in the efficiency. The new algorithm referred to as the improved\n$x$-space algorithm is implemented and applied to a recent min--max bilevel\noptimization problem that arises in the context of reducing the misinformation\nspread in social networks. It is also assessed on the benchmark instances of\ntwo other bilevel problems: zero-one knapsack problem with interdiction and\nmaximum clique problem with interdiction. Numerical results indicate that the\nperformance of the new algorithm is superior to that of the original algorithm,\nand also compares favorably with a recent algorithm developed for mixed-integer\nbilevel linear programs.""}, 'authors': [{'name': 'Kübra Tanınmış'}, {'name': 'Necati Aras'}, {'name': 'İ. Kuban Altınel'}], 'author_detail': {'name': 'İ. Kuban Altınel'}, 'author': 'İ. Kuban Altınel', 'arxiv_doi': '10.1016/j.ejor.2021.05.008', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.ejor.2021.05.008', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.08039v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.08039v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '31 pages, 7 tables, 4 figures. To be published in EJOR', 'arxiv_primary_category': {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
278,http://arxiv.org/abs/2005.08705v1,2020-05-15 17:02:19+00:00,2020-05-15 17:02:19+00:00,Threat from being Social: Vulnerability Analysis of Social Network Coupled Smart Grid,"[arxiv.Result.Author('Tianyi Pan'), arxiv.Result.Author('Subhankar Mishra'), arxiv.Result.Author('Lan N. Nguyen'), arxiv.Result.Author('Gunhee Lee'), arxiv.Result.Author('Jungmin Kang'), arxiv.Result.Author('Jungtaek Seo'), arxiv.Result.Author('My T. Thai')]","Social Networks (SNs) have been gradually applied by utility companies as an
addition to smart grid and are proved to be helpful in smoothing load curves
and reducing energy usage. However, SNs also bring in new threats to smart
grid: misinformation in SNs may cause smart grid users to alter their demand,
resulting in transmission line overloading and in turn leading to catastrophic
impact to the grid. In this paper, we discuss the interdependency in the social
network coupled smart grid and focus on its vulnerability. That is, how much
can the smart grid be damaged when misinformation related to it diffuses in
SNs? To analytically study the problem, we propose the Misinformation Attack
Problem in Social-Smart Grid (MAPSS) that identifies the top critical nodes in
the SN, such that the smart grid can be greatly damaged when misinformation
propagates from those nodes. This problem is challenging as we have to
incorporate the complexity of the two networks concurrently. Nevertheless, we
propose a technique that can explicitly take into account information diffusion
in SN, power flow balance and cascading failure in smart grid integratedly when
evaluating node criticality, based on which we propose various strategies in
selecting the most critical nodes. Also, we introduce controlled load shedding
as a protection strategy to reduce the impact of cascading failure. The
effectiveness of our algorithms are demonstrated by experiments on IEEE bus
test cases as well as the Pegase data set.",16 pages,IEEE Access 5 (2017): 16774-16783,10.1109/ACCESS.2017.2738565,eess.SY,"['eess.SY', 'cs.SI', 'cs.SY']","[arxiv.Result.Link('http://dx.doi.org/10.1109/ACCESS.2017.2738565', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.08705v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.08705v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.08705v1,"{'id': 'http://arxiv.org/abs/2005.08705v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.08705v1', 'updated': '2020-05-15T17:02:19Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=15, tm_hour=17, tm_min=2, tm_sec=19, tm_wday=4, tm_yday=136, tm_isdst=0), 'published': '2020-05-15T17:02:19Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=15, tm_hour=17, tm_min=2, tm_sec=19, tm_wday=4, tm_yday=136, tm_isdst=0), 'title': 'Threat from being Social: Vulnerability Analysis of Social Network\n  Coupled Smart Grid', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Threat from being Social: Vulnerability Analysis of Social Network\n  Coupled Smart Grid'}, 'summary': 'Social Networks (SNs) have been gradually applied by utility companies as an\naddition to smart grid and are proved to be helpful in smoothing load curves\nand reducing energy usage. However, SNs also bring in new threats to smart\ngrid: misinformation in SNs may cause smart grid users to alter their demand,\nresulting in transmission line overloading and in turn leading to catastrophic\nimpact to the grid. In this paper, we discuss the interdependency in the social\nnetwork coupled smart grid and focus on its vulnerability. That is, how much\ncan the smart grid be damaged when misinformation related to it diffuses in\nSNs? To analytically study the problem, we propose the Misinformation Attack\nProblem in Social-Smart Grid (MAPSS) that identifies the top critical nodes in\nthe SN, such that the smart grid can be greatly damaged when misinformation\npropagates from those nodes. This problem is challenging as we have to\nincorporate the complexity of the two networks concurrently. Nevertheless, we\npropose a technique that can explicitly take into account information diffusion\nin SN, power flow balance and cascading failure in smart grid integratedly when\nevaluating node criticality, based on which we propose various strategies in\nselecting the most critical nodes. Also, we introduce controlled load shedding\nas a protection strategy to reduce the impact of cascading failure. The\neffectiveness of our algorithms are demonstrated by experiments on IEEE bus\ntest cases as well as the Pegase data set.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Networks (SNs) have been gradually applied by utility companies as an\naddition to smart grid and are proved to be helpful in smoothing load curves\nand reducing energy usage. However, SNs also bring in new threats to smart\ngrid: misinformation in SNs may cause smart grid users to alter their demand,\nresulting in transmission line overloading and in turn leading to catastrophic\nimpact to the grid. In this paper, we discuss the interdependency in the social\nnetwork coupled smart grid and focus on its vulnerability. That is, how much\ncan the smart grid be damaged when misinformation related to it diffuses in\nSNs? To analytically study the problem, we propose the Misinformation Attack\nProblem in Social-Smart Grid (MAPSS) that identifies the top critical nodes in\nthe SN, such that the smart grid can be greatly damaged when misinformation\npropagates from those nodes. This problem is challenging as we have to\nincorporate the complexity of the two networks concurrently. Nevertheless, we\npropose a technique that can explicitly take into account information diffusion\nin SN, power flow balance and cascading failure in smart grid integratedly when\nevaluating node criticality, based on which we propose various strategies in\nselecting the most critical nodes. Also, we introduce controlled load shedding\nas a protection strategy to reduce the impact of cascading failure. The\neffectiveness of our algorithms are demonstrated by experiments on IEEE bus\ntest cases as well as the Pegase data set.'}, 'authors': [{'name': 'Tianyi Pan'}, {'name': 'Subhankar Mishra'}, {'name': 'Lan N. Nguyen'}, {'name': 'Gunhee Lee'}, {'name': 'Jungmin Kang'}, {'name': 'Jungtaek Seo'}, {'name': 'My T. Thai'}], 'author_detail': {'name': 'My T. Thai'}, 'author': 'My T. Thai', 'arxiv_doi': '10.1109/ACCESS.2017.2738565', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/ACCESS.2017.2738565', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.08705v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.08705v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '16 pages', 'arxiv_journal_ref': 'IEEE Access 5 (2017): 16774-16783', 'arxiv_primary_category': {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
279,http://arxiv.org/abs/2005.07266v2,2021-04-21 08:27:12+00:00,2020-05-14 21:14:15+00:00,Characterizing information leaders in Twitter during COVID-19 crisis,[arxiv.Result.Author('David Pastor-Escuredo')],"Information is key during a crisis such as the one produced by the current
COVID-19 pandemic as it greatly shapes people opinion, behavior and their
psychology. Infodemic of misinformation is an important secondary crisis
associated to the pandemic. Infodemics can amplify the real negative
consequences of the pandemic in different dimensions: social, economic and even
sanitary. For instance, infodemics can lead to hatred between population groups
that fragment the society influencing its response or result in negative habits
that help the pandemic propagate. On the contrary, reliable and trustful
information along with messages of hope and solidarity can be used to control
the pandemic, build safety nets and help promote resilience. We propose the
foundation of a framework to characterize leaders in Twitter based on the
analysis of the social graph derived from the activity in this social network.
Centrality metrics are used to characterize the topology of the network and the
nodes as potential leaders. These metrics are compared with the user popularity
metrics managed by Twitter. We then assess the resulting topology of clusters
of leaders visually. We propose this tool to be the basis for a system to
detect and empower users with a positive influence in the collective behavior
of the network and the propagation of information.",,,,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2005.07266v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.07266v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.07266v2,"{'id': 'http://arxiv.org/abs/2005.07266v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.07266v2', 'updated': '2021-04-21T08:27:12Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=21, tm_hour=8, tm_min=27, tm_sec=12, tm_wday=2, tm_yday=111, tm_isdst=0), 'published': '2020-05-14T21:14:15Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=14, tm_hour=21, tm_min=14, tm_sec=15, tm_wday=3, tm_yday=135, tm_isdst=0), 'title': 'Characterizing information leaders in Twitter during COVID-19 crisis', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing information leaders in Twitter during COVID-19 crisis'}, 'summary': 'Information is key during a crisis such as the one produced by the current\nCOVID-19 pandemic as it greatly shapes people opinion, behavior and their\npsychology. Infodemic of misinformation is an important secondary crisis\nassociated to the pandemic. Infodemics can amplify the real negative\nconsequences of the pandemic in different dimensions: social, economic and even\nsanitary. For instance, infodemics can lead to hatred between population groups\nthat fragment the society influencing its response or result in negative habits\nthat help the pandemic propagate. On the contrary, reliable and trustful\ninformation along with messages of hope and solidarity can be used to control\nthe pandemic, build safety nets and help promote resilience. We propose the\nfoundation of a framework to characterize leaders in Twitter based on the\nanalysis of the social graph derived from the activity in this social network.\nCentrality metrics are used to characterize the topology of the network and the\nnodes as potential leaders. These metrics are compared with the user popularity\nmetrics managed by Twitter. We then assess the resulting topology of clusters\nof leaders visually. We propose this tool to be the basis for a system to\ndetect and empower users with a positive influence in the collective behavior\nof the network and the propagation of information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information is key during a crisis such as the one produced by the current\nCOVID-19 pandemic as it greatly shapes people opinion, behavior and their\npsychology. Infodemic of misinformation is an important secondary crisis\nassociated to the pandemic. Infodemics can amplify the real negative\nconsequences of the pandemic in different dimensions: social, economic and even\nsanitary. For instance, infodemics can lead to hatred between population groups\nthat fragment the society influencing its response or result in negative habits\nthat help the pandemic propagate. On the contrary, reliable and trustful\ninformation along with messages of hope and solidarity can be used to control\nthe pandemic, build safety nets and help promote resilience. We propose the\nfoundation of a framework to characterize leaders in Twitter based on the\nanalysis of the social graph derived from the activity in this social network.\nCentrality metrics are used to characterize the topology of the network and the\nnodes as potential leaders. These metrics are compared with the user popularity\nmetrics managed by Twitter. We then assess the resulting topology of clusters\nof leaders visually. We propose this tool to be the basis for a system to\ndetect and empower users with a positive influence in the collective behavior\nof the network and the propagation of information.'}, 'authors': [{'name': 'David Pastor-Escuredo'}], 'author_detail': {'name': 'David Pastor-Escuredo'}, 'author': 'David Pastor-Escuredo', 'links': [{'href': 'http://arxiv.org/abs/2005.07266v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.07266v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
280,http://arxiv.org/abs/2005.06915v3,2020-06-25 01:54:21+00:00,2020-05-14 12:37:48+00:00,Can The Crowd Identify Misinformation Objectively? The Effects of Judgment Scale and Assessor's Background,"[arxiv.Result.Author('Kevin Roitero'), arxiv.Result.Author('Michael Soprano'), arxiv.Result.Author('Shaoyang Fan'), arxiv.Result.Author('Damiano Spina'), arxiv.Result.Author('Stefano Mizzaro'), arxiv.Result.Author('Gianluca Demartini')]","Truthfulness judgments are a fundamental step in the process of fighting
misinformation, as they are crucial to train and evaluate classifiers that
automatically distinguish true and false statements. Usually such judgments are
made by experts, like journalists for political statements or medical doctors
for medical statements. In this paper, we follow a different approach and rely
on (non-expert) crowd workers. This of course leads to the following research
question: Can crowdsourcing be reliably used to assess the truthfulness of
information and to create large-scale labeled collections for information
credibility systems? To address this issue, we present the results of an
extensive study based on crowdsourcing: we collect thousands of truthfulness
assessments over two datasets, and we compare expert judgments with crowd
judgments, expressed on scales with various granularity levels. We also measure
the political bias and the cognitive background of the workers, and quantify
their effect on the reliability of the data provided by the crowd.",Preprint of the full paper accepted at SIGIR 2020,,10.1145/3397271.3401112,cs.IR,"['cs.IR', 'cs.SI', '68P20', 'H.3']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3397271.3401112', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.06915v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.06915v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.06915v3,"{'id': 'http://arxiv.org/abs/2005.06915v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.06915v3', 'updated': '2020-06-25T01:54:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=25, tm_hour=1, tm_min=54, tm_sec=21, tm_wday=3, tm_yday=177, tm_isdst=0), 'published': '2020-05-14T12:37:48Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=14, tm_hour=12, tm_min=37, tm_sec=48, tm_wday=3, tm_yday=135, tm_isdst=0), 'title': ""Can The Crowd Identify Misinformation Objectively? The Effects of\n  Judgment Scale and Assessor's Background"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Can The Crowd Identify Misinformation Objectively? The Effects of\n  Judgment Scale and Assessor's Background""}, 'summary': 'Truthfulness judgments are a fundamental step in the process of fighting\nmisinformation, as they are crucial to train and evaluate classifiers that\nautomatically distinguish true and false statements. Usually such judgments are\nmade by experts, like journalists for political statements or medical doctors\nfor medical statements. In this paper, we follow a different approach and rely\non (non-expert) crowd workers. This of course leads to the following research\nquestion: Can crowdsourcing be reliably used to assess the truthfulness of\ninformation and to create large-scale labeled collections for information\ncredibility systems? To address this issue, we present the results of an\nextensive study based on crowdsourcing: we collect thousands of truthfulness\nassessments over two datasets, and we compare expert judgments with crowd\njudgments, expressed on scales with various granularity levels. We also measure\nthe political bias and the cognitive background of the workers, and quantify\ntheir effect on the reliability of the data provided by the crowd.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Truthfulness judgments are a fundamental step in the process of fighting\nmisinformation, as they are crucial to train and evaluate classifiers that\nautomatically distinguish true and false statements. Usually such judgments are\nmade by experts, like journalists for political statements or medical doctors\nfor medical statements. In this paper, we follow a different approach and rely\non (non-expert) crowd workers. This of course leads to the following research\nquestion: Can crowdsourcing be reliably used to assess the truthfulness of\ninformation and to create large-scale labeled collections for information\ncredibility systems? To address this issue, we present the results of an\nextensive study based on crowdsourcing: we collect thousands of truthfulness\nassessments over two datasets, and we compare expert judgments with crowd\njudgments, expressed on scales with various granularity levels. We also measure\nthe political bias and the cognitive background of the workers, and quantify\ntheir effect on the reliability of the data provided by the crowd.'}, 'authors': [{'name': 'Kevin Roitero'}, {'name': 'Michael Soprano'}, {'name': 'Shaoyang Fan'}, {'name': 'Damiano Spina'}, {'name': 'Stefano Mizzaro'}, {'name': 'Gianluca Demartini'}], 'author_detail': {'name': 'Gianluca Demartini'}, 'author': 'Gianluca Demartini', 'arxiv_doi': '10.1145/3397271.3401112', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3397271.3401112', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.06915v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.06915v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Preprint of the full paper accepted at SIGIR 2020', 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68P20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
281,http://arxiv.org/abs/2005.06637v2,2020-06-06 06:58:24+00:00,2020-05-12 12:27:29+00:00,When Wireless Communication Faces COVID-19: Combating the Pandemic and Saving the Economy,"[arxiv.Result.Author('Nasir Saeed'), arxiv.Result.Author('Ahmed Bader'), arxiv.Result.Author('Tareq Y. Al-Naffouri'), arxiv.Result.Author('Mohamed-Slim Alouini')]","The year 2020 is experiencing a global health and economic crisis due to the
COVID-19 pandemic. Countries across the world are using digital technologies to
fight this global crisis. These digital technologies, in one way or another,
strongly rely on the availability of wireless communication technologies. In
this paper, we present the role of wireless communications in the COVID-19
pandemic from different perspectives. First, we show how these technologies are
helping to combat this pandemic, including monitoring of the virus spread,
enabling healthcare automation, and allowing virtual education and
conferencing. Also, we show the importance of digital inclusiveness in the
pandemic and possible solutions to connect the unconnected. Next, we discuss
the challenges faced by wireless technologies, including privacy, security, and
misinformation. Then, we present the importance of wireless communication
technologies in the survival of the global economy, such as automation of
industries and supply chain, e-commerce, and supporting occupations that are at
risk. Finally, we reveal that how the technologies developed during the
pandemic can be helpful in the post-pandemic era.",,,,cs.CY,"['cs.CY', 'cs.NI']","[arxiv.Result.Link('http://arxiv.org/abs/2005.06637v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.06637v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.06637v2,"{'id': 'http://arxiv.org/abs/2005.06637v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.06637v2', 'updated': '2020-06-06T06:58:24Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=6, tm_hour=6, tm_min=58, tm_sec=24, tm_wday=5, tm_yday=158, tm_isdst=0), 'published': '2020-05-12T12:27:29Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=12, tm_min=27, tm_sec=29, tm_wday=1, tm_yday=133, tm_isdst=0), 'title': 'When Wireless Communication Faces COVID-19: Combating the Pandemic and\n  Saving the Economy', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'When Wireless Communication Faces COVID-19: Combating the Pandemic and\n  Saving the Economy'}, 'summary': 'The year 2020 is experiencing a global health and economic crisis due to the\nCOVID-19 pandemic. Countries across the world are using digital technologies to\nfight this global crisis. These digital technologies, in one way or another,\nstrongly rely on the availability of wireless communication technologies. In\nthis paper, we present the role of wireless communications in the COVID-19\npandemic from different perspectives. First, we show how these technologies are\nhelping to combat this pandemic, including monitoring of the virus spread,\nenabling healthcare automation, and allowing virtual education and\nconferencing. Also, we show the importance of digital inclusiveness in the\npandemic and possible solutions to connect the unconnected. Next, we discuss\nthe challenges faced by wireless technologies, including privacy, security, and\nmisinformation. Then, we present the importance of wireless communication\ntechnologies in the survival of the global economy, such as automation of\nindustries and supply chain, e-commerce, and supporting occupations that are at\nrisk. Finally, we reveal that how the technologies developed during the\npandemic can be helpful in the post-pandemic era.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The year 2020 is experiencing a global health and economic crisis due to the\nCOVID-19 pandemic. Countries across the world are using digital technologies to\nfight this global crisis. These digital technologies, in one way or another,\nstrongly rely on the availability of wireless communication technologies. In\nthis paper, we present the role of wireless communications in the COVID-19\npandemic from different perspectives. First, we show how these technologies are\nhelping to combat this pandemic, including monitoring of the virus spread,\nenabling healthcare automation, and allowing virtual education and\nconferencing. Also, we show the importance of digital inclusiveness in the\npandemic and possible solutions to connect the unconnected. Next, we discuss\nthe challenges faced by wireless technologies, including privacy, security, and\nmisinformation. Then, we present the importance of wireless communication\ntechnologies in the survival of the global economy, such as automation of\nindustries and supply chain, e-commerce, and supporting occupations that are at\nrisk. Finally, we reveal that how the technologies developed during the\npandemic can be helpful in the post-pandemic era.'}, 'authors': [{'name': 'Nasir Saeed'}, {'name': 'Ahmed Bader'}, {'name': 'Tareq Y. Al-Naffouri'}, {'name': 'Mohamed-Slim Alouini'}], 'author_detail': {'name': 'Mohamed-Slim Alouini'}, 'author': 'Mohamed-Slim Alouini', 'links': [{'href': 'http://arxiv.org/abs/2005.06637v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.06637v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
282,http://arxiv.org/abs/2005.05710v2,2020-08-24 19:13:30+00:00,2020-05-12 12:07:35+00:00,An Exploratory Study of COVID-19 Misinformation on Twitter,"[arxiv.Result.Author('Gautam Kishore Shahi'), arxiv.Result.Author('Anne Dirkson'), arxiv.Result.Author('Tim A. Majchrzak')]","During the COVID-19 pandemic, social media has become a home ground for
misinformation. To tackle this infodemic, scientific oversight, as well as a
better understanding by practitioners in crisis management, is needed. We have
conducted an exploratory study into the propagation, authors and content of
misinformation on Twitter around the topic of COVID-19 in order to gain early
insights. We have collected all tweets mentioned in the verdicts of
fact-checked claims related to COVID-19 by over 92 professional fact-checking
organisations between January and mid-July 2020 and share this corpus with the
community. This resulted in 1 500 tweets relating to 1 274 false and 276
partially false claims, respectively. Exploratory analysis of author accounts
revealed that the verified twitter handle(including Organisation/celebrity) are
also involved in either creating (new tweets) or spreading (retweet) the
misinformation. Additionally, we found that false claims propagate faster than
partially false claims. Compare to a background corpus of COVID-19 tweets,
tweets with misinformation are more often concerned with discrediting other
information on social media. Authors use less tentative language and appear to
be more driven by concerns of potential harm to others. Our results enable us
to suggest gaps in the current scientific coverage of the topic as well as
propose actions for authorities and social media users to counter
misinformation.","20 pages, nine figures, four tables. Submitted for peer review,
  revision 1",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2005.05710v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.05710v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.05710v2,"{'id': 'http://arxiv.org/abs/2005.05710v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.05710v2', 'updated': '2020-08-24T19:13:30Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=24, tm_hour=19, tm_min=13, tm_sec=30, tm_wday=0, tm_yday=237, tm_isdst=0), 'published': '2020-05-12T12:07:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=12, tm_min=7, tm_sec=35, tm_wday=1, tm_yday=133, tm_isdst=0), 'title': 'An Exploratory Study of COVID-19 Misinformation on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Exploratory Study of COVID-19 Misinformation on Twitter'}, 'summary': 'During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.'}, 'authors': [{'name': 'Gautam Kishore Shahi'}, {'name': 'Anne Dirkson'}, {'name': 'Tim A. Majchrzak'}], 'author_detail': {'name': 'Tim A. Majchrzak'}, 'author': 'Tim A. Majchrzak', 'arxiv_comment': '20 pages, nine figures, four tables. Submitted for peer review,\n  revision 1', 'links': [{'href': 'http://arxiv.org/abs/2005.05710v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.05710v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
283,http://arxiv.org/abs/2005.05513v2,2020-05-13 16:47:44+00:00,2020-05-12 01:51:07+00:00,Psychometric Analysis and Coupling of Emotions Between State Bulletins and Twitter in India during COVID-19 Infodemic,"[arxiv.Result.Author('Baani Leen Kaur Jolly'), arxiv.Result.Author('Palash Aggrawal'), arxiv.Result.Author('Amogh Gulati'), arxiv.Result.Author('Amarjit Singh Sethi'), arxiv.Result.Author('Ponnurangam Kumaraguru'), arxiv.Result.Author('Tavpritesh Sethi')]","COVID-19 infodemic has been spreading faster than the pandemic itself. The
misinformation riding upon the infodemic wave poses a major threat to people's
health and governance systems. Since social media is the largest source of
information, managing the infodemic not only requires mitigating of
misinformation but also an early understanding of psychological patterns
resulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp
45% increase in the usage of its curated events page, and a 30% increase in its
direct messaging usage, since March 6th 2020. In this study, we analyze the
psychometric impact and coupling of the COVID-19 infodemic with the official
bulletins related to COVID-19 at the national and state level in India. We look
at these two sources with a psycho-linguistic lens of emotions and quantified
the extent and coupling between the two. We modified path, a deep skip-gram
based open-sourced lexicon builder for effective capture of health-related
emotions. We were then able to capture the time-evolution of health-related
emotions in social media and official bulletins. An analysis of lead-lag
relationships between the time series of extracted emotions from official
bulletins and social media using Granger's causality showed that state
bulletins were leading the social media for some emotions such as Medical
Emergency. Further insights that are potentially relevant for the policymaker
and the communicators actively engaged in mitigating misinformation are also
discussed. Our paper also introduces CoronaIndiaDataset2, the first social
media based COVID-19 dataset at national and state levels from India with over
5.6 million national and 2.6 million state-level tweets. Finally, we present
our findings as COVibes, an interactive web application capturing psychometric
insights captured upon the CoronaIndiaDataset, both at a national and state
level.",,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2005.05513v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.05513v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.05513v2,"{'id': 'http://arxiv.org/abs/2005.05513v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.05513v2', 'updated': '2020-05-13T16:47:44Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=13, tm_hour=16, tm_min=47, tm_sec=44, tm_wday=2, tm_yday=134, tm_isdst=0), 'published': '2020-05-12T01:51:07Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=12, tm_hour=1, tm_min=51, tm_sec=7, tm_wday=1, tm_yday=133, tm_isdst=0), 'title': 'Psychometric Analysis and Coupling of Emotions Between State Bulletins\n  and Twitter in India during COVID-19 Infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Psychometric Analysis and Coupling of Emotions Between State Bulletins\n  and Twitter in India during COVID-19 Infodemic'}, 'summary': ""COVID-19 infodemic has been spreading faster than the pandemic itself. The\nmisinformation riding upon the infodemic wave poses a major threat to people's\nhealth and governance systems. Since social media is the largest source of\ninformation, managing the infodemic not only requires mitigating of\nmisinformation but also an early understanding of psychological patterns\nresulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp\n45% increase in the usage of its curated events page, and a 30% increase in its\ndirect messaging usage, since March 6th 2020. In this study, we analyze the\npsychometric impact and coupling of the COVID-19 infodemic with the official\nbulletins related to COVID-19 at the national and state level in India. We look\nat these two sources with a psycho-linguistic lens of emotions and quantified\nthe extent and coupling between the two. We modified path, a deep skip-gram\nbased open-sourced lexicon builder for effective capture of health-related\nemotions. We were then able to capture the time-evolution of health-related\nemotions in social media and official bulletins. An analysis of lead-lag\nrelationships between the time series of extracted emotions from official\nbulletins and social media using Granger's causality showed that state\nbulletins were leading the social media for some emotions such as Medical\nEmergency. Further insights that are potentially relevant for the policymaker\nand the communicators actively engaged in mitigating misinformation are also\ndiscussed. Our paper also introduces CoronaIndiaDataset2, the first social\nmedia based COVID-19 dataset at national and state levels from India with over\n5.6 million national and 2.6 million state-level tweets. Finally, we present\nour findings as COVibes, an interactive web application capturing psychometric\ninsights captured upon the CoronaIndiaDataset, both at a national and state\nlevel."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""COVID-19 infodemic has been spreading faster than the pandemic itself. The\nmisinformation riding upon the infodemic wave poses a major threat to people's\nhealth and governance systems. Since social media is the largest source of\ninformation, managing the infodemic not only requires mitigating of\nmisinformation but also an early understanding of psychological patterns\nresulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp\n45% increase in the usage of its curated events page, and a 30% increase in its\ndirect messaging usage, since March 6th 2020. In this study, we analyze the\npsychometric impact and coupling of the COVID-19 infodemic with the official\nbulletins related to COVID-19 at the national and state level in India. We look\nat these two sources with a psycho-linguistic lens of emotions and quantified\nthe extent and coupling between the two. We modified path, a deep skip-gram\nbased open-sourced lexicon builder for effective capture of health-related\nemotions. We were then able to capture the time-evolution of health-related\nemotions in social media and official bulletins. An analysis of lead-lag\nrelationships between the time series of extracted emotions from official\nbulletins and social media using Granger's causality showed that state\nbulletins were leading the social media for some emotions such as Medical\nEmergency. Further insights that are potentially relevant for the policymaker\nand the communicators actively engaged in mitigating misinformation are also\ndiscussed. Our paper also introduces CoronaIndiaDataset2, the first social\nmedia based COVID-19 dataset at national and state levels from India with over\n5.6 million national and 2.6 million state-level tweets. Finally, we present\nour findings as COVibes, an interactive web application capturing psychometric\ninsights captured upon the CoronaIndiaDataset, both at a national and state\nlevel.""}, 'authors': [{'name': 'Baani Leen Kaur Jolly'}, {'name': 'Palash Aggrawal'}, {'name': 'Amogh Gulati'}, {'name': 'Amarjit Singh Sethi'}, {'name': 'Ponnurangam Kumaraguru'}, {'name': 'Tavpritesh Sethi'}], 'author_detail': {'name': 'Tavpritesh Sethi'}, 'author': 'Tavpritesh Sethi', 'links': [{'href': 'http://arxiv.org/abs/2005.05513v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.05513v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
284,http://arxiv.org/abs/2005.04682v2,2020-05-28 07:31:05+00:00,2020-05-10 14:55:50+00:00,Exposure to Social Engagement Metrics Increases Vulnerability to Misinformation,"[arxiv.Result.Author('Mihai Avram'), arxiv.Result.Author('Nicholas Micallef'), arxiv.Result.Author('Sameer Patil'), arxiv.Result.Author('Filippo Menczer')]","News feeds in virtually all social media platforms include engagement
metrics, such as the number of times each post is liked and shared. We find
that exposure to these social engagement signals increases the vulnerability of
users to misinformation. This finding has important implications for the design
of social media interactions in the misinformation age. To reduce the spread of
misinformation, we call for technology platforms to rethink the display of
social engagement metrics. Further research is needed to investigate whether
and how engagement metrics can be presented without amplifying the spread of
low-credibility information.","9 pages, 2 figures","HKS Misinformation Review Vol. 1 (No. 5), 2020",10.37016/mr-2020-033,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.37016/mr-2020-033', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2005.04682v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.04682v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.04682v2,"{'id': 'http://arxiv.org/abs/2005.04682v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.04682v2', 'updated': '2020-05-28T07:31:05Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=28, tm_hour=7, tm_min=31, tm_sec=5, tm_wday=3, tm_yday=149, tm_isdst=0), 'published': '2020-05-10T14:55:50Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=10, tm_hour=14, tm_min=55, tm_sec=50, tm_wday=6, tm_yday=131, tm_isdst=0), 'title': 'Exposure to Social Engagement Metrics Increases Vulnerability to\n  Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Exposure to Social Engagement Metrics Increases Vulnerability to\n  Misinformation'}, 'summary': 'News feeds in virtually all social media platforms include engagement\nmetrics, such as the number of times each post is liked and shared. We find\nthat exposure to these social engagement signals increases the vulnerability of\nusers to misinformation. This finding has important implications for the design\nof social media interactions in the misinformation age. To reduce the spread of\nmisinformation, we call for technology platforms to rethink the display of\nsocial engagement metrics. Further research is needed to investigate whether\nand how engagement metrics can be presented without amplifying the spread of\nlow-credibility information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'News feeds in virtually all social media platforms include engagement\nmetrics, such as the number of times each post is liked and shared. We find\nthat exposure to these social engagement signals increases the vulnerability of\nusers to misinformation. This finding has important implications for the design\nof social media interactions in the misinformation age. To reduce the spread of\nmisinformation, we call for technology platforms to rethink the display of\nsocial engagement metrics. Further research is needed to investigate whether\nand how engagement metrics can be presented without amplifying the spread of\nlow-credibility information.'}, 'authors': [{'name': 'Mihai Avram'}, {'name': 'Nicholas Micallef'}, {'name': 'Sameer Patil'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.37016/mr-2020-033', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.37016/mr-2020-033', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2005.04682v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.04682v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '9 pages, 2 figures', 'arxiv_journal_ref': 'HKS Misinformation Review Vol. 1 (No. 5), 2020', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
285,http://arxiv.org/abs/2005.04310v2,2021-06-03 22:30:14+00:00,2020-05-08 22:41:39+00:00,Semi-Supervised Multi-aspect Detection of Misinformation using Hierarchical Joint Decomposition,"[arxiv.Result.Author('Sara Abdali'), arxiv.Result.Author('Neil Shah'), arxiv.Result.Author('Evangelos E. Papalexakis')]","Distinguishing between misinformation and real information is one of the most
challenging problems in today's interconnected world. The vast majority of the
state-of-the-art in detecting misinformation is fully supervised, requiring a
large number of high-quality human annotations. However, the availability of
such annotations cannot be taken for granted, since it is very costly,
time-consuming, and challenging to do so in a way that keeps up with the
proliferation of misinformation. In this work, we are interested in exploring
scenarios where the number of annotations is limited. In such scenarios, we
investigate how tapping on a diverse number of resources that characterize a
news article, henceforth referred to as ""aspects"" can compensate for the lack
of labels. In particular, our contributions in this paper are twofold: 1) We
propose the use of three different aspects: article content, context of social
sharing behaviors, and host website/domain features, and 2) We introduce a
principled tensor based embedding framework that combines all those aspects
effectively. We propose HiJoD a 2-level decomposition pipeline which not only
outperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter
and Politifact datasets respectively but also is an order of magnitude faster
than similar ensemble approaches.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2005.04310v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.04310v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.04310v2,"{'id': 'http://arxiv.org/abs/2005.04310v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.04310v2', 'updated': '2021-06-03T22:30:14Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=3, tm_hour=22, tm_min=30, tm_sec=14, tm_wday=3, tm_yday=154, tm_isdst=0), 'published': '2020-05-08T22:41:39Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=8, tm_hour=22, tm_min=41, tm_sec=39, tm_wday=4, tm_yday=129, tm_isdst=0), 'title': 'Semi-Supervised Multi-aspect Detection of Misinformation using\n  Hierarchical Joint Decomposition', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Semi-Supervised Multi-aspect Detection of Misinformation using\n  Hierarchical Joint Decomposition'}, 'summary': 'Distinguishing between misinformation and real information is one of the most\nchallenging problems in today\'s interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as ""aspects"" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Distinguishing between misinformation and real information is one of the most\nchallenging problems in today\'s interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as ""aspects"" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.'}, 'authors': [{'name': 'Sara Abdali'}, {'name': 'Neil Shah'}, {'name': 'Evangelos E. Papalexakis'}], 'author_detail': {'name': 'Evangelos E. Papalexakis'}, 'author': 'Evangelos E. Papalexakis', 'links': [{'href': 'http://arxiv.org/abs/2005.04310v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.04310v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
286,http://arxiv.org/abs/2005.02443v1,2020-05-05 19:08:26+00:00,2020-05-05 19:08:26+00:00,A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian and Indian Elections,"[arxiv.Result.Author('Julio C. S. Reis'), arxiv.Result.Author('Philipe de Freitas Melo'), arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Jussara M. Almeida'), arxiv.Result.Author('Dean Eckles'), arxiv.Result.Author('Fabrício Benevenuto')]","Recently, messaging applications, such as WhatsApp, have been reportedly
abused by misinformation campaigns, especially in Brazil and India. A notable
form of abuse in WhatsApp relies on several manipulated images and memes
containing all kinds of fake stories. In this work, we performed an extensive
data collection from a large set of WhatsApp publicly accessible groups and
fact-checking agency websites. This paper opens a novel dataset to the research
community containing fact-checked fake images shared through WhatsApp for two
distinct scenarios known for the spread of fake news on the platform: the 2018
Brazilian elections and the 2019 Indian elections.","7 pages. This is a preprint version of an accepted paper on ICWSM'20.
  Please, consider to cite the conference version instead of this one",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2005.02443v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.02443v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.02443v1,"{'id': 'http://arxiv.org/abs/2005.02443v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.02443v1', 'updated': '2020-05-05T19:08:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=5, tm_hour=19, tm_min=8, tm_sec=26, tm_wday=1, tm_yday=126, tm_isdst=0), 'published': '2020-05-05T19:08:26Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=5, tm_hour=19, tm_min=8, tm_sec=26, tm_wday=1, tm_yday=126, tm_isdst=0), 'title': 'A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections'}, 'summary': 'Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.'}, 'authors': [{'name': 'Julio C. S. Reis'}, {'name': 'Philipe de Freitas Melo'}, {'name': 'Kiran Garimella'}, {'name': 'Jussara M. Almeida'}, {'name': 'Dean Eckles'}, {'name': 'Fabrício Benevenuto'}], 'author_detail': {'name': 'Fabrício Benevenuto'}, 'author': 'Fabrício Benevenuto', 'arxiv_comment': ""7 pages. This is a preprint version of an accepted paper on ICWSM'20.\n  Please, consider to cite the conference version instead of this one"", 'links': [{'href': 'http://arxiv.org/abs/2005.02443v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.02443v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
287,http://arxiv.org/abs/2005.06012v4,2021-02-05 22:19:06+00:00,2020-05-02 10:23:27+00:00,Mega-COV: A Billion-Scale Dataset of 100+ Languages for COVID-19,"[arxiv.Result.Author('Muhammad Abdul-Mageed'), arxiv.Result.Author('AbdelRahim Elmadany'), arxiv.Result.Author('El Moatez Billah Nagoudi'), arxiv.Result.Author('Dinesh Pabbi'), arxiv.Result.Author('Kunal Verma'), arxiv.Result.Author('Rannie Lin')]","We describe Mega-COV, a billion-scale dataset from Twitter for studying
COVID-19. The dataset is diverse (covers 268 countries), longitudinal (goes as
back as 2007), multilingual (comes in 100+ languages), and has a significant
number of location-tagged tweets (~169M tweets). We release tweet IDs from the
dataset. We also develop and release two powerful models, one for identifying
whether or not a tweet is related to the pandemic (best F1=97%) and another for
detecting misinformation about COVID-19 (best F1=92%). A human annotation study
reveals the utility of our models on a subset of Mega-COV. Our data and models
can be useful for studying a wide host of phenomena related to the pandemic.
Mega-COV and our models are publicly available.",,,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2005.06012v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2005.06012v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2005.06012v4,"{'id': 'http://arxiv.org/abs/2005.06012v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2005.06012v4', 'updated': '2021-02-05T22:19:06Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=5, tm_hour=22, tm_min=19, tm_sec=6, tm_wday=4, tm_yday=36, tm_isdst=0), 'published': '2020-05-02T10:23:27Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=2, tm_hour=10, tm_min=23, tm_sec=27, tm_wday=5, tm_yday=123, tm_isdst=0), 'title': 'Mega-COV: A Billion-Scale Dataset of 100+ Languages for COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mega-COV: A Billion-Scale Dataset of 100+ Languages for COVID-19'}, 'summary': 'We describe Mega-COV, a billion-scale dataset from Twitter for studying\nCOVID-19. The dataset is diverse (covers 268 countries), longitudinal (goes as\nback as 2007), multilingual (comes in 100+ languages), and has a significant\nnumber of location-tagged tweets (~169M tweets). We release tweet IDs from the\ndataset. We also develop and release two powerful models, one for identifying\nwhether or not a tweet is related to the pandemic (best F1=97%) and another for\ndetecting misinformation about COVID-19 (best F1=92%). A human annotation study\nreveals the utility of our models on a subset of Mega-COV. Our data and models\ncan be useful for studying a wide host of phenomena related to the pandemic.\nMega-COV and our models are publicly available.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We describe Mega-COV, a billion-scale dataset from Twitter for studying\nCOVID-19. The dataset is diverse (covers 268 countries), longitudinal (goes as\nback as 2007), multilingual (comes in 100+ languages), and has a significant\nnumber of location-tagged tweets (~169M tweets). We release tweet IDs from the\ndataset. We also develop and release two powerful models, one for identifying\nwhether or not a tweet is related to the pandemic (best F1=97%) and another for\ndetecting misinformation about COVID-19 (best F1=92%). A human annotation study\nreveals the utility of our models on a subset of Mega-COV. Our data and models\ncan be useful for studying a wide host of phenomena related to the pandemic.\nMega-COV and our models are publicly available.'}, 'authors': [{'name': 'Muhammad Abdul-Mageed'}, {'name': 'AbdelRahim Elmadany'}, {'name': 'El Moatez Billah Nagoudi'}, {'name': 'Dinesh Pabbi'}, {'name': 'Kunal Verma'}, {'name': 'Rannie Lin'}], 'author_detail': {'name': 'Rannie Lin'}, 'author': 'Rannie Lin', 'links': [{'href': 'http://arxiv.org/abs/2005.06012v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2005.06012v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
288,http://arxiv.org/abs/2004.14907v1,2020-04-30 16:06:02+00:00,2020-04-30 16:06:02+00:00,You are right. I am ALARMED -- But by Climate Change Counter Movement,"[arxiv.Result.Author('Shraey Bhatia'), arxiv.Result.Author('Jey Han Lau'), arxiv.Result.Author('Timothy Baldwin')]","The world is facing the challenge of climate crisis. Despite the consensus in
scientific community about anthropogenic global warming, the web is flooded
with articles spreading climate misinformation. These articles are carefully
constructed by climate change counter movement (cccm) organizations to
influence the narrative around climate change. We revisit the literature on
climate misinformation in social sciences and repackage it to introduce in the
community of NLP. Despite considerable work in detection of fake news, there is
no misinformation dataset available that is specific to the domain.of climate
change. We try to bridge this gap by scraping and releasing articles with known
climate change misinformation.",5 pages,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.14907v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.14907v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.14907v1,"{'id': 'http://arxiv.org/abs/2004.14907v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.14907v1', 'updated': '2020-04-30T16:06:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=16, tm_min=6, tm_sec=2, tm_wday=3, tm_yday=121, tm_isdst=0), 'published': '2020-04-30T16:06:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=30, tm_hour=16, tm_min=6, tm_sec=2, tm_wday=3, tm_yday=121, tm_isdst=0), 'title': 'You are right. I am ALARMED -- But by Climate Change Counter Movement', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'You are right. I am ALARMED -- But by Climate Change Counter Movement'}, 'summary': 'The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.'}, 'authors': [{'name': 'Shraey Bhatia'}, {'name': 'Jey Han Lau'}, {'name': 'Timothy Baldwin'}], 'author_detail': {'name': 'Timothy Baldwin'}, 'author': 'Timothy Baldwin', 'arxiv_comment': '5 pages', 'links': [{'href': 'http://arxiv.org/abs/2004.14907v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.14907v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
289,http://arxiv.org/abs/2004.14484v2,2020-06-08 06:18:40+00:00,2020-04-29 21:08:44+00:00,Prevalence of Low-Credibility Information on Twitter During the COVID-19 Outbreak,"[arxiv.Result.Author('Kai-Cheng Yang'), arxiv.Result.Author('Christopher Torres-Lugo'), arxiv.Result.Author('Filippo Menczer')]","As the novel coronavirus spreads across the world, concerns regarding the
spreading of misinformation about it are also growing. Here we estimate the
prevalence of links to low-credibility information on Twitter during the
outbreak, and the role of bots in spreading these links. We find that the
combined volume of tweets linking to low-credibility information is comparable
to the volume of New York Times articles and CDC links. Content analysis
reveals a politicization of the pandemic. The majority of this content spreads
via retweets. Social bots are involved in both posting and amplifying
low-credibility information, although the majority of volume is generated by
likely humans. Some of these accounts appear to amplify low-credibility sources
in a coordinated fashion.","5 pages, 4 figures","Proc. ICWSM Intl. Workshop on Cyber Social Threats (CySoc), 2020",10.36190/2020.16,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.36190/2020.16', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.14484v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.14484v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.14484v2,"{'id': 'http://arxiv.org/abs/2004.14484v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.14484v2', 'updated': '2020-06-08T06:18:40Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=8, tm_hour=6, tm_min=18, tm_sec=40, tm_wday=0, tm_yday=160, tm_isdst=0), 'published': '2020-04-29T21:08:44Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=29, tm_hour=21, tm_min=8, tm_sec=44, tm_wday=2, tm_yday=120, tm_isdst=0), 'title': 'Prevalence of Low-Credibility Information on Twitter During the COVID-19\n  Outbreak', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Prevalence of Low-Credibility Information on Twitter During the COVID-19\n  Outbreak'}, 'summary': 'As the novel coronavirus spreads across the world, concerns regarding the\nspreading of misinformation about it are also growing. Here we estimate the\nprevalence of links to low-credibility information on Twitter during the\noutbreak, and the role of bots in spreading these links. We find that the\ncombined volume of tweets linking to low-credibility information is comparable\nto the volume of New York Times articles and CDC links. Content analysis\nreveals a politicization of the pandemic. The majority of this content spreads\nvia retweets. Social bots are involved in both posting and amplifying\nlow-credibility information, although the majority of volume is generated by\nlikely humans. Some of these accounts appear to amplify low-credibility sources\nin a coordinated fashion.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the novel coronavirus spreads across the world, concerns regarding the\nspreading of misinformation about it are also growing. Here we estimate the\nprevalence of links to low-credibility information on Twitter during the\noutbreak, and the role of bots in spreading these links. We find that the\ncombined volume of tweets linking to low-credibility information is comparable\nto the volume of New York Times articles and CDC links. Content analysis\nreveals a politicization of the pandemic. The majority of this content spreads\nvia retweets. Social bots are involved in both posting and amplifying\nlow-credibility information, although the majority of volume is generated by\nlikely humans. Some of these accounts appear to amplify low-credibility sources\nin a coordinated fashion.'}, 'authors': [{'name': 'Kai-Cheng Yang'}, {'name': 'Christopher Torres-Lugo'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.36190/2020.16', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.36190/2020.16', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.14484v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.14484v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '5 pages, 4 figures', 'arxiv_journal_ref': 'Proc. ICWSM Intl. Workshop on Cyber Social Threats (CySoc), 2020', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
290,http://arxiv.org/abs/2004.12864v1,2020-04-27 15:18:49+00:00,2020-04-27 15:18:49+00:00,DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking,"[arxiv.Result.Author('Christopher Hidey'), arxiv.Result.Author('Tuhin Chakrabarty'), arxiv.Result.Author('Tariq Alhindi'), arxiv.Result.Author('Siddharth Varia'), arxiv.Result.Author('Kriste Krstovski'), arxiv.Result.Author('Mona Diab'), arxiv.Result.Author('Smaranda Muresan')]","The increased focus on misinformation has spurred development of data and
systems for detecting the veracity of a claim as well as retrieving
authoritative evidence. The Fact Extraction and VERification (FEVER) dataset
provides such a resource for evaluating end-to-end fact-checking, requiring
retrieval of evidence from Wikipedia to validate a veracity prediction. We show
that current systems for FEVER are vulnerable to three categories of realistic
challenges for fact-checking -- multiple propositions, temporal reasoning, and
ambiguity and lexical variation -- and introduce a resource with these types of
claims. Then we present a system designed to be resilient to these ""attacks""
using multiple pointer networks for document selection and jointly modeling a
sequence of evidence sentences and veracity relation predictions. We find that
in handling these attacks we obtain state-of-the-art results on FEVER, largely
due to improved evidence retrieval.",ACL 2020,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.12864v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.12864v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.12864v1,"{'id': 'http://arxiv.org/abs/2004.12864v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.12864v1', 'updated': '2020-04-27T15:18:49Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=27, tm_hour=15, tm_min=18, tm_sec=49, tm_wday=0, tm_yday=118, tm_isdst=0), 'published': '2020-04-27T15:18:49Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=27, tm_hour=15, tm_min=18, tm_sec=49, tm_wday=0, tm_yday=118, tm_isdst=0), 'title': 'DeSePtion: Dual Sequence Prediction and Adversarial Examples for\n  Improved Fact-Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DeSePtion: Dual Sequence Prediction and Adversarial Examples for\n  Improved Fact-Checking'}, 'summary': 'The increased focus on misinformation has spurred development of data and\nsystems for detecting the veracity of a claim as well as retrieving\nauthoritative evidence. The Fact Extraction and VERification (FEVER) dataset\nprovides such a resource for evaluating end-to-end fact-checking, requiring\nretrieval of evidence from Wikipedia to validate a veracity prediction. We show\nthat current systems for FEVER are vulnerable to three categories of realistic\nchallenges for fact-checking -- multiple propositions, temporal reasoning, and\nambiguity and lexical variation -- and introduce a resource with these types of\nclaims. Then we present a system designed to be resilient to these ""attacks""\nusing multiple pointer networks for document selection and jointly modeling a\nsequence of evidence sentences and veracity relation predictions. We find that\nin handling these attacks we obtain state-of-the-art results on FEVER, largely\ndue to improved evidence retrieval.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The increased focus on misinformation has spurred development of data and\nsystems for detecting the veracity of a claim as well as retrieving\nauthoritative evidence. The Fact Extraction and VERification (FEVER) dataset\nprovides such a resource for evaluating end-to-end fact-checking, requiring\nretrieval of evidence from Wikipedia to validate a veracity prediction. We show\nthat current systems for FEVER are vulnerable to three categories of realistic\nchallenges for fact-checking -- multiple propositions, temporal reasoning, and\nambiguity and lexical variation -- and introduce a resource with these types of\nclaims. Then we present a system designed to be resilient to these ""attacks""\nusing multiple pointer networks for document selection and jointly modeling a\nsequence of evidence sentences and veracity relation predictions. We find that\nin handling these attacks we obtain state-of-the-art results on FEVER, largely\ndue to improved evidence retrieval.'}, 'authors': [{'name': 'Christopher Hidey'}, {'name': 'Tuhin Chakrabarty'}, {'name': 'Tariq Alhindi'}, {'name': 'Siddharth Varia'}, {'name': 'Kriste Krstovski'}, {'name': 'Mona Diab'}, {'name': 'Smaranda Muresan'}], 'author_detail': {'name': 'Smaranda Muresan'}, 'author': 'Smaranda Muresan', 'arxiv_comment': 'ACL 2020', 'links': [{'href': 'http://arxiv.org/abs/2004.12864v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.12864v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
291,http://arxiv.org/abs/2004.12226v1,2020-04-25 20:07:54+00:00,2020-04-25 20:07:54+00:00,A First Instagram Dataset on COVID-19,"[arxiv.Result.Author('Koosha Zarei'), arxiv.Result.Author('Reza Farahbakhsh'), arxiv.Result.Author('Noel Crespi'), arxiv.Result.Author('Gareth Tyson')]","The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and
reshaping many aspects of our life, with a huge impact on our social life. In
this era of lockdown policies in most of the major cities around the world, we
see a huge increase in people and professional engagement in social media.
Social media is playing an important role in news propagation as well as
keeping people in contact. At the same time, this source is both a blessing and
a curse as the coronavirus infodemic has become a major concern, and is already
a topic that needs special attention and further research. In this paper, we
provide a multilingual coronavirus (COVID-19) Instagram dataset that we have
been continuously collected since March 30, 2020. We are making our dataset
available to the research community at Github. We believe that this
contribution will help the community to better understand the dynamics behind
this phenomenon in Instagram, as one of the major social media. This dataset
could also help study the propagation of misinformation related to this
outbreak.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.12226v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.12226v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.12226v1,"{'id': 'http://arxiv.org/abs/2004.12226v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.12226v1', 'updated': '2020-04-25T20:07:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=25, tm_hour=20, tm_min=7, tm_sec=54, tm_wday=5, tm_yday=116, tm_isdst=0), 'published': '2020-04-25T20:07:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=25, tm_hour=20, tm_min=7, tm_sec=54, tm_wday=5, tm_yday=116, tm_isdst=0), 'title': 'A First Instagram Dataset on COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A First Instagram Dataset on COVID-19'}, 'summary': 'The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and\nreshaping many aspects of our life, with a huge impact on our social life. In\nthis era of lockdown policies in most of the major cities around the world, we\nsee a huge increase in people and professional engagement in social media.\nSocial media is playing an important role in news propagation as well as\nkeeping people in contact. At the same time, this source is both a blessing and\na curse as the coronavirus infodemic has become a major concern, and is already\na topic that needs special attention and further research. In this paper, we\nprovide a multilingual coronavirus (COVID-19) Instagram dataset that we have\nbeen continuously collected since March 30, 2020. We are making our dataset\navailable to the research community at Github. We believe that this\ncontribution will help the community to better understand the dynamics behind\nthis phenomenon in Instagram, as one of the major social media. This dataset\ncould also help study the propagation of misinformation related to this\noutbreak.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and\nreshaping many aspects of our life, with a huge impact on our social life. In\nthis era of lockdown policies in most of the major cities around the world, we\nsee a huge increase in people and professional engagement in social media.\nSocial media is playing an important role in news propagation as well as\nkeeping people in contact. At the same time, this source is both a blessing and\na curse as the coronavirus infodemic has become a major concern, and is already\na topic that needs special attention and further research. In this paper, we\nprovide a multilingual coronavirus (COVID-19) Instagram dataset that we have\nbeen continuously collected since March 30, 2020. We are making our dataset\navailable to the research community at Github. We believe that this\ncontribution will help the community to better understand the dynamics behind\nthis phenomenon in Instagram, as one of the major social media. This dataset\ncould also help study the propagation of misinformation related to this\noutbreak.'}, 'authors': [{'name': 'Koosha Zarei'}, {'name': 'Reza Farahbakhsh'}, {'name': 'Noel Crespi'}, {'name': 'Gareth Tyson'}], 'author_detail': {'name': 'Gareth Tyson'}, 'author': 'Gareth Tyson', 'links': [{'href': 'http://arxiv.org/abs/2004.12226v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.12226v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
292,http://arxiv.org/abs/2004.11138v3,2020-09-13 22:44:33+00:00,2020-04-23 13:35:49+00:00,The Creation and Detection of Deepfakes: A Survey,"[arxiv.Result.Author('Yisroel Mirsky'), arxiv.Result.Author('Wenke Lee')]","Generative deep learning algorithms have progressed to a point where it is
difficult to tell the difference between what is real and what is fake. In
2018, it was discovered how easy it is to use this technology for unethical and
malicious applications, such as the spread of misinformation, impersonation of
political leaders, and the defamation of innocent individuals. Since then,
these `deepfakes' have advanced significantly.
  In this paper, we explore the creation and detection of deepfakes and provide
an in-depth view of how these architectures work. The purpose of this survey is
to provide the reader with a deeper understanding of (1) how deepfakes are
created and detected, (2) the current trends and advancements in this domain,
(3) the shortcomings of the current defense solutions, and (4) the areas which
require further research and attention.",,"ACM Computing Surveys (CSUR), 2020, preprint",10.1145/3425780,cs.CV,"['cs.CV', 'cs.LG', 'eess.IV']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3425780', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.11138v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.11138v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.11138v3,"{'id': 'http://arxiv.org/abs/2004.11138v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.11138v3', 'updated': '2020-09-13T22:44:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=13, tm_hour=22, tm_min=44, tm_sec=33, tm_wday=6, tm_yday=257, tm_isdst=0), 'published': '2020-04-23T13:35:49Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=23, tm_hour=13, tm_min=35, tm_sec=49, tm_wday=3, tm_yday=114, tm_isdst=0), 'title': 'The Creation and Detection of Deepfakes: A Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Creation and Detection of Deepfakes: A Survey'}, 'summary': ""Generative deep learning algorithms have progressed to a point where it is\ndifficult to tell the difference between what is real and what is fake. In\n2018, it was discovered how easy it is to use this technology for unethical and\nmalicious applications, such as the spread of misinformation, impersonation of\npolitical leaders, and the defamation of innocent individuals. Since then,\nthese `deepfakes' have advanced significantly.\n  In this paper, we explore the creation and detection of deepfakes and provide\nan in-depth view of how these architectures work. The purpose of this survey is\nto provide the reader with a deeper understanding of (1) how deepfakes are\ncreated and detected, (2) the current trends and advancements in this domain,\n(3) the shortcomings of the current defense solutions, and (4) the areas which\nrequire further research and attention."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Generative deep learning algorithms have progressed to a point where it is\ndifficult to tell the difference between what is real and what is fake. In\n2018, it was discovered how easy it is to use this technology for unethical and\nmalicious applications, such as the spread of misinformation, impersonation of\npolitical leaders, and the defamation of innocent individuals. Since then,\nthese `deepfakes' have advanced significantly.\n  In this paper, we explore the creation and detection of deepfakes and provide\nan in-depth view of how these architectures work. The purpose of this survey is\nto provide the reader with a deeper understanding of (1) how deepfakes are\ncreated and detected, (2) the current trends and advancements in this domain,\n(3) the shortcomings of the current defense solutions, and (4) the areas which\nrequire further research and attention.""}, 'authors': [{'name': 'Yisroel Mirsky'}, {'name': 'Wenke Lee'}], 'author_detail': {'name': 'Wenke Lee'}, 'author': 'Wenke Lee', 'arxiv_doi': '10.1145/3425780', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3425780', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.11138v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.11138v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'ACM Computing Surveys (CSUR), 2020, preprint', 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
293,http://arxiv.org/abs/2004.09600v1,2020-04-20 19:56:48+00:00,2020-04-20 19:56:48+00:00,Why do People Share Misinformation during the COVID-19 Pandemic?,"[arxiv.Result.Author('Samuli Laato'), arxiv.Result.Author('A. K. M. Najmul Islam'), arxiv.Result.Author('Muhammad Nazrul Islam'), arxiv.Result.Author('Eoin Whelan')]","The World Health Organization have emphasised that misinformation - spreading
rapidly through social media - poses a serious threat to the COVID-19 response.
Drawing from theories of health perception and cognitive load, we develop and
test a research model hypothesizing why people share unverified COVID-19
information through social media. Our findings suggest a person's trust in
online information and perceived information overload are strong predictors of
unverified information sharing. Furthermore, these factors, along with a
person's perceived COVID-19 severity and vulnerability influence cyberchondria.
Females were significantly more likely to suffer from cyberchondria, however,
males were more likely to share news without fact checking their source. Our
findings suggest that to mitigate the spread of COVID-19 misinformation and
cyberchondria, measures should be taken to enhance a healthy skepticism of
health news while simultaneously guarding against information overload.",,European Journal of Information Systems (2020),10.1080/0960085X.2020.1770632,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://dx.doi.org/10.1080/0960085X.2020.1770632', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.09600v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.09600v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.09600v1,"{'id': 'http://arxiv.org/abs/2004.09600v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.09600v1', 'updated': '2020-04-20T19:56:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=20, tm_hour=19, tm_min=56, tm_sec=48, tm_wday=0, tm_yday=111, tm_isdst=0), 'published': '2020-04-20T19:56:48Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=20, tm_hour=19, tm_min=56, tm_sec=48, tm_wday=0, tm_yday=111, tm_isdst=0), 'title': 'Why do People Share Misinformation during the COVID-19 Pandemic?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Why do People Share Misinformation during the COVID-19 Pandemic?'}, 'summary': ""The World Health Organization have emphasised that misinformation - spreading\nrapidly through social media - poses a serious threat to the COVID-19 response.\nDrawing from theories of health perception and cognitive load, we develop and\ntest a research model hypothesizing why people share unverified COVID-19\ninformation through social media. Our findings suggest a person's trust in\nonline information and perceived information overload are strong predictors of\nunverified information sharing. Furthermore, these factors, along with a\nperson's perceived COVID-19 severity and vulnerability influence cyberchondria.\nFemales were significantly more likely to suffer from cyberchondria, however,\nmales were more likely to share news without fact checking their source. Our\nfindings suggest that to mitigate the spread of COVID-19 misinformation and\ncyberchondria, measures should be taken to enhance a healthy skepticism of\nhealth news while simultaneously guarding against information overload."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The World Health Organization have emphasised that misinformation - spreading\nrapidly through social media - poses a serious threat to the COVID-19 response.\nDrawing from theories of health perception and cognitive load, we develop and\ntest a research model hypothesizing why people share unverified COVID-19\ninformation through social media. Our findings suggest a person's trust in\nonline information and perceived information overload are strong predictors of\nunverified information sharing. Furthermore, these factors, along with a\nperson's perceived COVID-19 severity and vulnerability influence cyberchondria.\nFemales were significantly more likely to suffer from cyberchondria, however,\nmales were more likely to share news without fact checking their source. Our\nfindings suggest that to mitigate the spread of COVID-19 misinformation and\ncyberchondria, measures should be taken to enhance a healthy skepticism of\nhealth news while simultaneously guarding against information overload.""}, 'authors': [{'name': 'Samuli Laato'}, {'name': 'A. K. M. Najmul Islam'}, {'name': 'Muhammad Nazrul Islam'}, {'name': 'Eoin Whelan'}], 'author_detail': {'name': 'Eoin Whelan'}, 'author': 'Eoin Whelan', 'arxiv_doi': '10.1080/0960085X.2020.1770632', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1080/0960085X.2020.1770632', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.09600v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.09600v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'European Journal of Information Systems (2020)', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
294,http://arxiv.org/abs/2004.08166v2,2021-02-14 20:33:58+00:00,2020-04-17 10:55:07+00:00,Too Many Claims to Fact-Check: Prioritizing Political Claims Based on Check-Worthiness,"[arxiv.Result.Author('Yavuz Selim Kartal'), arxiv.Result.Author('Busra Guvenen'), arxiv.Result.Author('Mucahid Kutlu')]","The massive amount of misinformation spreading on the Internet on a daily
basis has enormous negative impacts on societies. Therefore, we need automated
systems helping fact-checkers in the combat against misinformation. In this
paper, we propose a model prioritizing the claims based on their
check-worthiness. We use BERT model with additional features including
domain-specific controversial topics, word embeddings, and others. In our
experiments, we show that our proposed model outperforms all state-of-the-art
models in both test collections of CLEF Check That! Lab in 2018 and 2019. We
also conduct a qualitative analysis to shed light-detecting check-worthy
claims. We suggest requesting rationales behind judgments are needed to
understand subjective nature of the task and problematic labels.",,,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.08166v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.08166v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.08166v2,"{'id': 'http://arxiv.org/abs/2004.08166v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.08166v2', 'updated': '2021-02-14T20:33:58Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=14, tm_hour=20, tm_min=33, tm_sec=58, tm_wday=6, tm_yday=45, tm_isdst=0), 'published': '2020-04-17T10:55:07Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=17, tm_hour=10, tm_min=55, tm_sec=7, tm_wday=4, tm_yday=108, tm_isdst=0), 'title': 'Too Many Claims to Fact-Check: Prioritizing Political Claims Based on\n  Check-Worthiness', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Too Many Claims to Fact-Check: Prioritizing Political Claims Based on\n  Check-Worthiness'}, 'summary': 'The massive amount of misinformation spreading on the Internet on a daily\nbasis has enormous negative impacts on societies. Therefore, we need automated\nsystems helping fact-checkers in the combat against misinformation. In this\npaper, we propose a model prioritizing the claims based on their\ncheck-worthiness. We use BERT model with additional features including\ndomain-specific controversial topics, word embeddings, and others. In our\nexperiments, we show that our proposed model outperforms all state-of-the-art\nmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. We\nalso conduct a qualitative analysis to shed light-detecting check-worthy\nclaims. We suggest requesting rationales behind judgments are needed to\nunderstand subjective nature of the task and problematic labels.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The massive amount of misinformation spreading on the Internet on a daily\nbasis has enormous negative impacts on societies. Therefore, we need automated\nsystems helping fact-checkers in the combat against misinformation. In this\npaper, we propose a model prioritizing the claims based on their\ncheck-worthiness. We use BERT model with additional features including\ndomain-specific controversial topics, word embeddings, and others. In our\nexperiments, we show that our proposed model outperforms all state-of-the-art\nmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. We\nalso conduct a qualitative analysis to shed light-detecting check-worthy\nclaims. We suggest requesting rationales behind judgments are needed to\nunderstand subjective nature of the task and problematic labels.'}, 'authors': [{'name': 'Yavuz Selim Kartal'}, {'name': 'Busra Guvenen'}, {'name': 'Mucahid Kutlu'}], 'author_detail': {'name': 'Mucahid Kutlu'}, 'author': 'Mucahid Kutlu', 'links': [{'href': 'http://arxiv.org/abs/2004.08166v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.08166v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
295,http://arxiv.org/abs/2004.04565v3,2020-05-23 15:16:31+00:00,2020-04-09 14:37:43+00:00,CovidSens: A Vision on Reliable Social Sensing for COVID-19,"[arxiv.Result.Author('Md Tahmid Rashid'), arxiv.Result.Author('Dong Wang')]","With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it
has becoming inherently important to disseminate accurate and timely
information about the disease. Due to the ubiquity of Internet connectivity and
smart devices, social sensing is emerging as a dynamic AI-driven sensing
paradigm to extract real-time observations from online users. In this paper, we
propose CovidSens, a vision of social sensing based risk alert systems to
spontaneously obtain and analyze social data to infer COVID-19 propagation.
CovidSens can actively help to keep the general public informed about the
COVID-19 spread and identify risk-prone areas. The CovidSens concept is
motivated by three observations: 1) people actively share their experience of
COVID-19 via online social media, 2) official warning channels and news
agencies are relatively slower than people reporting on social media, and 3)
online users are frequently equipped with powerful mobile devices that can
perform data processing and analytics. We envision unprecedented opportunities
to leverage posts generated by ordinary people to build real-time sensing and
analytic system for gathering and circulating COVID-19 propagation data.
Specifically, the vision of CovidSens attempts to answer the questions: How to
distill reliable information on COVID-19 with prevailing rumors and
misinformation? How to inform the general public about the state of the spread
timely and effectively? How to leverage the computational power on edge devices
to construct fully integrated edge-based social sensing platforms? In this
vision paper, we discuss the roles of CovidSens and identify potential
challenges in developing reliable social sensing based risk alert systems. We
envision that approaches originating from multiple disciplines can be effective
in addressing the challenges. Finally, we outline a few research directions for
future work in CovidSens.",Artificial Intelligence Review (accepted for publication),,,cs.SI,"['cs.SI', 'physics.soc-ph', 'q-bio.PE', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2004.04565v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.04565v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.04565v3,"{'id': 'http://arxiv.org/abs/2004.04565v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.04565v3', 'updated': '2020-05-23T15:16:31Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=23, tm_hour=15, tm_min=16, tm_sec=31, tm_wday=5, tm_yday=144, tm_isdst=0), 'published': '2020-04-09T14:37:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=9, tm_hour=14, tm_min=37, tm_sec=43, tm_wday=3, tm_yday=100, tm_isdst=0), 'title': 'CovidSens: A Vision on Reliable Social Sensing for COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CovidSens: A Vision on Reliable Social Sensing for COVID-19'}, 'summary': 'With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it\nhas becoming inherently important to disseminate accurate and timely\ninformation about the disease. Due to the ubiquity of Internet connectivity and\nsmart devices, social sensing is emerging as a dynamic AI-driven sensing\nparadigm to extract real-time observations from online users. In this paper, we\npropose CovidSens, a vision of social sensing based risk alert systems to\nspontaneously obtain and analyze social data to infer COVID-19 propagation.\nCovidSens can actively help to keep the general public informed about the\nCOVID-19 spread and identify risk-prone areas. The CovidSens concept is\nmotivated by three observations: 1) people actively share their experience of\nCOVID-19 via online social media, 2) official warning channels and news\nagencies are relatively slower than people reporting on social media, and 3)\nonline users are frequently equipped with powerful mobile devices that can\nperform data processing and analytics. We envision unprecedented opportunities\nto leverage posts generated by ordinary people to build real-time sensing and\nanalytic system for gathering and circulating COVID-19 propagation data.\nSpecifically, the vision of CovidSens attempts to answer the questions: How to\ndistill reliable information on COVID-19 with prevailing rumors and\nmisinformation? How to inform the general public about the state of the spread\ntimely and effectively? How to leverage the computational power on edge devices\nto construct fully integrated edge-based social sensing platforms? In this\nvision paper, we discuss the roles of CovidSens and identify potential\nchallenges in developing reliable social sensing based risk alert systems. We\nenvision that approaches originating from multiple disciplines can be effective\nin addressing the challenges. Finally, we outline a few research directions for\nfuture work in CovidSens.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it\nhas becoming inherently important to disseminate accurate and timely\ninformation about the disease. Due to the ubiquity of Internet connectivity and\nsmart devices, social sensing is emerging as a dynamic AI-driven sensing\nparadigm to extract real-time observations from online users. In this paper, we\npropose CovidSens, a vision of social sensing based risk alert systems to\nspontaneously obtain and analyze social data to infer COVID-19 propagation.\nCovidSens can actively help to keep the general public informed about the\nCOVID-19 spread and identify risk-prone areas. The CovidSens concept is\nmotivated by three observations: 1) people actively share their experience of\nCOVID-19 via online social media, 2) official warning channels and news\nagencies are relatively slower than people reporting on social media, and 3)\nonline users are frequently equipped with powerful mobile devices that can\nperform data processing and analytics. We envision unprecedented opportunities\nto leverage posts generated by ordinary people to build real-time sensing and\nanalytic system for gathering and circulating COVID-19 propagation data.\nSpecifically, the vision of CovidSens attempts to answer the questions: How to\ndistill reliable information on COVID-19 with prevailing rumors and\nmisinformation? How to inform the general public about the state of the spread\ntimely and effectively? How to leverage the computational power on edge devices\nto construct fully integrated edge-based social sensing platforms? In this\nvision paper, we discuss the roles of CovidSens and identify potential\nchallenges in developing reliable social sensing based risk alert systems. We\nenvision that approaches originating from multiple disciplines can be effective\nin addressing the challenges. Finally, we outline a few research directions for\nfuture work in CovidSens.'}, 'authors': [{'name': 'Md Tahmid Rashid'}, {'name': 'Dong Wang'}], 'author_detail': {'name': 'Dong Wang'}, 'author': 'Dong Wang', 'arxiv_comment': 'Artificial Intelligence Review (accepted for publication)', 'links': [{'href': 'http://arxiv.org/abs/2004.04565v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.04565v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
296,http://arxiv.org/abs/2004.04315v2,2020-04-22 22:38:15+00:00,2020-04-09 01:07:12+00:00,Large Arabic Twitter Dataset on COVID-19,"[arxiv.Result.Author('Sarah Alqurashi'), arxiv.Result.Author('Ahmad Alhindi'), arxiv.Result.Author('Eisa Alanazi')]","The 2019 coronavirus disease (COVID-19), emerged late December 2019 in China,
is now rapidly spreading across the globe. At the time of writing this paper,
the number of global confirmed cases has passed two millions and half with over
180,000 fatalities. Many countries have enforced strict social distancing
policies to contain the spread of the virus. This have changed the daily life
of tens of millions of people, and urged people to turn their discussions
online, e.g., via online social media sites like Twitter. In this work, we
describe the first Arabic tweets dataset on COVID-19 that we have been
collecting since January 1st, 2020. The dataset would help researchers and
policy makers in studying different societal issues related to the pandemic.
Many other tasks related to behavioral change, information sharing,
misinformation and rumors spreading can also be analyzed.",,,,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2004.04315v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.04315v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.04315v2,"{'id': 'http://arxiv.org/abs/2004.04315v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.04315v2', 'updated': '2020-04-22T22:38:15Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=22, tm_hour=22, tm_min=38, tm_sec=15, tm_wday=2, tm_yday=113, tm_isdst=0), 'published': '2020-04-09T01:07:12Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=9, tm_hour=1, tm_min=7, tm_sec=12, tm_wday=3, tm_yday=100, tm_isdst=0), 'title': 'Large Arabic Twitter Dataset on COVID-19', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Large Arabic Twitter Dataset on COVID-19'}, 'summary': 'The 2019 coronavirus disease (COVID-19), emerged late December 2019 in China,\nis now rapidly spreading across the globe. At the time of writing this paper,\nthe number of global confirmed cases has passed two millions and half with over\n180,000 fatalities. Many countries have enforced strict social distancing\npolicies to contain the spread of the virus. This have changed the daily life\nof tens of millions of people, and urged people to turn their discussions\nonline, e.g., via online social media sites like Twitter. In this work, we\ndescribe the first Arabic tweets dataset on COVID-19 that we have been\ncollecting since January 1st, 2020. The dataset would help researchers and\npolicy makers in studying different societal issues related to the pandemic.\nMany other tasks related to behavioral change, information sharing,\nmisinformation and rumors spreading can also be analyzed.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The 2019 coronavirus disease (COVID-19), emerged late December 2019 in China,\nis now rapidly spreading across the globe. At the time of writing this paper,\nthe number of global confirmed cases has passed two millions and half with over\n180,000 fatalities. Many countries have enforced strict social distancing\npolicies to contain the spread of the virus. This have changed the daily life\nof tens of millions of people, and urged people to turn their discussions\nonline, e.g., via online social media sites like Twitter. In this work, we\ndescribe the first Arabic tweets dataset on COVID-19 that we have been\ncollecting since January 1st, 2020. The dataset would help researchers and\npolicy makers in studying different societal issues related to the pandemic.\nMany other tasks related to behavioral change, information sharing,\nmisinformation and rumors spreading can also be analyzed.'}, 'authors': [{'name': 'Sarah Alqurashi'}, {'name': 'Ahmad Alhindi'}, {'name': 'Eisa Alanazi'}], 'author_detail': {'name': 'Eisa Alanazi'}, 'author': 'Eisa Alanazi', 'links': [{'href': 'http://arxiv.org/abs/2004.04315v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.04315v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
297,http://arxiv.org/abs/2004.03788v1,2020-04-08 03:22:21+00:00,2020-04-08 03:22:21+00:00,Satirical News Detection with Semantic Feature Extraction and Game-theoretic Rough Sets,"[arxiv.Result.Author('Yue Zhou'), arxiv.Result.Author('Yan Zhang'), arxiv.Result.Author('JingTao Yao')]","Satirical news detection is an important yet challenging task to prevent
spread of misinformation. Many feature based and end-to-end neural nets based
satirical news detection systems have been proposed and delivered promising
results. Existing approaches explore comprehensive word features from satirical
news articles, but lack semantic metrics using word vectors for tweet form
satirical news. Moreover, the vagueness of satire and news parody determines
that a news tweet can hardly be classified with a binary decision, that is,
satirical or legitimate. To address these issues, we collect satirical and
legitimate news tweets, and propose a semantic feature based approach. Features
are extracted by exploring inconsistencies in phrases, entities, and between
main and relative clauses. We apply game-theoretic rough set model to detect
satirical news, in which probabilistic thresholds are derived by game
equilibrium and repetition learning mechanism. Experimental results on the
collected dataset show the robustness and improvement of the proposed approach
compared with Pawlak rough set model and SVM.",12 pages,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/2004.03788v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.03788v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.03788v1,"{'id': 'http://arxiv.org/abs/2004.03788v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.03788v1', 'updated': '2020-04-08T03:22:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=8, tm_hour=3, tm_min=22, tm_sec=21, tm_wday=2, tm_yday=99, tm_isdst=0), 'published': '2020-04-08T03:22:21Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=8, tm_hour=3, tm_min=22, tm_sec=21, tm_wday=2, tm_yday=99, tm_isdst=0), 'title': 'Satirical News Detection with Semantic Feature Extraction and\n  Game-theoretic Rough Sets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Satirical News Detection with Semantic Feature Extraction and\n  Game-theoretic Rough Sets'}, 'summary': 'Satirical news detection is an important yet challenging task to prevent\nspread of misinformation. Many feature based and end-to-end neural nets based\nsatirical news detection systems have been proposed and delivered promising\nresults. Existing approaches explore comprehensive word features from satirical\nnews articles, but lack semantic metrics using word vectors for tweet form\nsatirical news. Moreover, the vagueness of satire and news parody determines\nthat a news tweet can hardly be classified with a binary decision, that is,\nsatirical or legitimate. To address these issues, we collect satirical and\nlegitimate news tweets, and propose a semantic feature based approach. Features\nare extracted by exploring inconsistencies in phrases, entities, and between\nmain and relative clauses. We apply game-theoretic rough set model to detect\nsatirical news, in which probabilistic thresholds are derived by game\nequilibrium and repetition learning mechanism. Experimental results on the\ncollected dataset show the robustness and improvement of the proposed approach\ncompared with Pawlak rough set model and SVM.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Satirical news detection is an important yet challenging task to prevent\nspread of misinformation. Many feature based and end-to-end neural nets based\nsatirical news detection systems have been proposed and delivered promising\nresults. Existing approaches explore comprehensive word features from satirical\nnews articles, but lack semantic metrics using word vectors for tweet form\nsatirical news. Moreover, the vagueness of satire and news parody determines\nthat a news tweet can hardly be classified with a binary decision, that is,\nsatirical or legitimate. To address these issues, we collect satirical and\nlegitimate news tweets, and propose a semantic feature based approach. Features\nare extracted by exploring inconsistencies in phrases, entities, and between\nmain and relative clauses. We apply game-theoretic rough set model to detect\nsatirical news, in which probabilistic thresholds are derived by game\nequilibrium and repetition learning mechanism. Experimental results on the\ncollected dataset show the robustness and improvement of the proposed approach\ncompared with Pawlak rough set model and SVM.'}, 'authors': [{'name': 'Yue Zhou'}, {'name': 'Yan Zhang'}, {'name': 'JingTao Yao'}], 'author_detail': {'name': 'JingTao Yao'}, 'author': 'JingTao Yao', 'arxiv_comment': '12 pages', 'links': [{'href': 'http://arxiv.org/abs/2004.03788v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.03788v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
298,http://arxiv.org/abs/2004.03688v2,2020-11-13 16:20:38+00:00,2020-04-07 20:25:26+00:00,A large-scale COVID-19 Twitter chatter dataset for open scientific research -- an international collaboration,"[arxiv.Result.Author('Juan M. Banda'), arxiv.Result.Author('Ramya Tekumalla'), arxiv.Result.Author('Guanyu Wang'), arxiv.Result.Author('Jingyuan Yu'), arxiv.Result.Author('Tuo Liu'), arxiv.Result.Author('Yuning Ding'), arxiv.Result.Author('Katya Artemova'), arxiv.Result.Author('Elena Tutubalina'), arxiv.Result.Author('Gerardo Chowell')]","As the COVID-19 pandemic continues its march around the world, an
unprecedented amount of open data is being generated for genetics and
epidemiological research. The unparalleled rate at which many research groups
around the world are releasing data and publications on the ongoing pandemic is
allowing other scientists to learn from local experiences and data generated in
the front lines of the COVID-19 pandemic. However, there is a need to integrate
additional data sources that map and measure the role of social dynamics of
such a unique world-wide event into biomedical, biological, and epidemiological
analyses. For this purpose, we present a large-scale curated dataset of over
152 million tweets, growing daily, related to COVID-19 chatter generated from
January 1st to April 4th at the time of writing. This open dataset will allow
researchers to conduct a number of research projects relating to the emotional
and mental responses to social distancing measures, the identification of
sources of misinformation, and the stratified measurement of sentiment towards
the pandemic in near real time.","8 pages, 1 figure 2 table. Update: new version of paper with
  up-to-date statistics and new co-authors",,10.3390/epidemiologia2030024,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://dx.doi.org/10.3390/epidemiologia2030024', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.03688v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.03688v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.03688v2,"{'id': 'http://arxiv.org/abs/2004.03688v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.03688v2', 'updated': '2020-11-13T16:20:38Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=13, tm_hour=16, tm_min=20, tm_sec=38, tm_wday=4, tm_yday=318, tm_isdst=0), 'published': '2020-04-07T20:25:26Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=7, tm_hour=20, tm_min=25, tm_sec=26, tm_wday=1, tm_yday=98, tm_isdst=0), 'title': 'A large-scale COVID-19 Twitter chatter dataset for open scientific\n  research -- an international collaboration', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A large-scale COVID-19 Twitter chatter dataset for open scientific\n  research -- an international collaboration'}, 'summary': 'As the COVID-19 pandemic continues its march around the world, an\nunprecedented amount of open data is being generated for genetics and\nepidemiological research. The unparalleled rate at which many research groups\naround the world are releasing data and publications on the ongoing pandemic is\nallowing other scientists to learn from local experiences and data generated in\nthe front lines of the COVID-19 pandemic. However, there is a need to integrate\nadditional data sources that map and measure the role of social dynamics of\nsuch a unique world-wide event into biomedical, biological, and epidemiological\nanalyses. For this purpose, we present a large-scale curated dataset of over\n152 million tweets, growing daily, related to COVID-19 chatter generated from\nJanuary 1st to April 4th at the time of writing. This open dataset will allow\nresearchers to conduct a number of research projects relating to the emotional\nand mental responses to social distancing measures, the identification of\nsources of misinformation, and the stratified measurement of sentiment towards\nthe pandemic in near real time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As the COVID-19 pandemic continues its march around the world, an\nunprecedented amount of open data is being generated for genetics and\nepidemiological research. The unparalleled rate at which many research groups\naround the world are releasing data and publications on the ongoing pandemic is\nallowing other scientists to learn from local experiences and data generated in\nthe front lines of the COVID-19 pandemic. However, there is a need to integrate\nadditional data sources that map and measure the role of social dynamics of\nsuch a unique world-wide event into biomedical, biological, and epidemiological\nanalyses. For this purpose, we present a large-scale curated dataset of over\n152 million tweets, growing daily, related to COVID-19 chatter generated from\nJanuary 1st to April 4th at the time of writing. This open dataset will allow\nresearchers to conduct a number of research projects relating to the emotional\nand mental responses to social distancing measures, the identification of\nsources of misinformation, and the stratified measurement of sentiment towards\nthe pandemic in near real time.'}, 'authors': [{'name': 'Juan M. Banda'}, {'name': 'Ramya Tekumalla'}, {'name': 'Guanyu Wang'}, {'name': 'Jingyuan Yu'}, {'name': 'Tuo Liu'}, {'name': 'Yuning Ding'}, {'name': 'Katya Artemova'}, {'name': 'Elena Tutubalina'}, {'name': 'Gerardo Chowell'}], 'author_detail': {'name': 'Gerardo Chowell'}, 'author': 'Gerardo Chowell', 'arxiv_doi': '10.3390/epidemiologia2030024', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.3390/epidemiologia2030024', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.03688v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.03688v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '8 pages, 1 figure 2 table. Update: new version of paper with\n  up-to-date statistics and new co-authors', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
299,http://arxiv.org/abs/2004.05113v1,2020-04-07 02:57:35+00:00,2020-04-07 02:57:35+00:00,Automatically Assessing Quality of Online Health Articles,"[arxiv.Result.Author('Fariha Afsana'), arxiv.Result.Author('Muhammad Ashad Kabir'), arxiv.Result.Author('Naeemul Hassan'), arxiv.Result.Author('Manoranjan Paul')]","The information ecosystem today is overwhelmed by an unprecedented quantity
of data on versatile topics are with varied quality. However, the quality of
information disseminated in the field of medicine has been questioned as the
negative health consequences of health misinformation can be life-threatening.
There is currently no generic automated tool for evaluating the quality of
online health information spanned over a broad range. To address this gap, in
this paper, we applied a data mining approach to automatically assess the
quality of online health articles based on 10 quality criteria. We have
prepared a labeled dataset with 53012 features and applied different feature
selection methods to identify the best feature subset with which our trained
classifier achieved an accuracy of 84%-90% varied over 10 criteria. Our
semantic analysis of features shows the underpinning associations between the
selected features & assessment criteria and further rationalize our assessment
approach. Our findings will help in identifying high-quality health articles
and thus aiding users in shaping their opinion to make the right choice while
picking health-related help from online.",,,,cs.CY,"['cs.CY', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2004.05113v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.05113v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.05113v1,"{'id': 'http://arxiv.org/abs/2004.05113v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.05113v1', 'updated': '2020-04-07T02:57:35Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=7, tm_hour=2, tm_min=57, tm_sec=35, tm_wday=1, tm_yday=98, tm_isdst=0), 'published': '2020-04-07T02:57:35Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=7, tm_hour=2, tm_min=57, tm_sec=35, tm_wday=1, tm_yday=98, tm_isdst=0), 'title': 'Automatically Assessing Quality of Online Health Articles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatically Assessing Quality of Online Health Articles'}, 'summary': 'The information ecosystem today is overwhelmed by an unprecedented quantity\nof data on versatile topics are with varied quality. However, the quality of\ninformation disseminated in the field of medicine has been questioned as the\nnegative health consequences of health misinformation can be life-threatening.\nThere is currently no generic automated tool for evaluating the quality of\nonline health information spanned over a broad range. To address this gap, in\nthis paper, we applied a data mining approach to automatically assess the\nquality of online health articles based on 10 quality criteria. We have\nprepared a labeled dataset with 53012 features and applied different feature\nselection methods to identify the best feature subset with which our trained\nclassifier achieved an accuracy of 84%-90% varied over 10 criteria. Our\nsemantic analysis of features shows the underpinning associations between the\nselected features & assessment criteria and further rationalize our assessment\napproach. Our findings will help in identifying high-quality health articles\nand thus aiding users in shaping their opinion to make the right choice while\npicking health-related help from online.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The information ecosystem today is overwhelmed by an unprecedented quantity\nof data on versatile topics are with varied quality. However, the quality of\ninformation disseminated in the field of medicine has been questioned as the\nnegative health consequences of health misinformation can be life-threatening.\nThere is currently no generic automated tool for evaluating the quality of\nonline health information spanned over a broad range. To address this gap, in\nthis paper, we applied a data mining approach to automatically assess the\nquality of online health articles based on 10 quality criteria. We have\nprepared a labeled dataset with 53012 features and applied different feature\nselection methods to identify the best feature subset with which our trained\nclassifier achieved an accuracy of 84%-90% varied over 10 criteria. Our\nsemantic analysis of features shows the underpinning associations between the\nselected features & assessment criteria and further rationalize our assessment\napproach. Our findings will help in identifying high-quality health articles\nand thus aiding users in shaping their opinion to make the right choice while\npicking health-related help from online.'}, 'authors': [{'name': 'Fariha Afsana'}, {'name': 'Muhammad Ashad Kabir'}, {'name': 'Naeemul Hassan'}, {'name': 'Manoranjan Paul'}], 'author_detail': {'name': 'Manoranjan Paul'}, 'author': 'Manoranjan Paul', 'links': [{'href': 'http://arxiv.org/abs/2004.05113v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.05113v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
300,http://arxiv.org/abs/2004.01967v1,2020-04-04 16:21:13+00:00,2020-04-04 16:21:13+00:00,The Paradox of Information Access: Growing Isolation in the Age of Sharing,"[arxiv.Result.Author('Tarek Abdelzaher'), arxiv.Result.Author('Heng Ji'), arxiv.Result.Author('Jinyang Li'), arxiv.Result.Author('Chaoqi Yang'), arxiv.Result.Author('John Dellaverson'), arxiv.Result.Author('Lixia Zhang'), arxiv.Result.Author('Chao Xu'), arxiv.Result.Author('Boleslaw K. Szymanski')]","Modern online media, such as Twitter, Instagram, and YouTube, enable anyone
to become an information producer and to offer online content for potentially
global consumption. By increasing the amount of globally accessible real-time
information, today's ubiquitous producers contribute to a world, where an
individual consumes vanishingly smaller fractions of all produced content. In
general, consumers preferentially select information that closely matches their
individual views and values. The bias inherent in such selection is further
magnified by today's information curation services that maximize user
engagement (and thus service revenue) by filtering new content in accordance
with observed consumer preferences. Consequently, individuals get exposed to
increasingly narrower bands of the ideology spectrum. Societies get fragmented
into increasingly ideologically isolated enclaves. These enclaves (or
echo-chambers) then become vulnerable to misinformation spread, which in turn
further magnifies polarization and bias. We call this dynamic the paradox of
information access; a growing ideological fragmentation in the age of sharing.
This article describes the technical, economic, and socio-cognitive
contributors to this paradox, and explores research directions towards its
mitigation.","13 pages, 6 figures",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.01967v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.01967v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.01967v1,"{'id': 'http://arxiv.org/abs/2004.01967v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.01967v1', 'updated': '2020-04-04T16:21:13Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=4, tm_hour=16, tm_min=21, tm_sec=13, tm_wday=5, tm_yday=95, tm_isdst=0), 'published': '2020-04-04T16:21:13Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=4, tm_hour=16, tm_min=21, tm_sec=13, tm_wday=5, tm_yday=95, tm_isdst=0), 'title': 'The Paradox of Information Access: Growing Isolation in the Age of\n  Sharing', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Paradox of Information Access: Growing Isolation in the Age of\n  Sharing'}, 'summary': ""Modern online media, such as Twitter, Instagram, and YouTube, enable anyone\nto become an information producer and to offer online content for potentially\nglobal consumption. By increasing the amount of globally accessible real-time\ninformation, today's ubiquitous producers contribute to a world, where an\nindividual consumes vanishingly smaller fractions of all produced content. In\ngeneral, consumers preferentially select information that closely matches their\nindividual views and values. The bias inherent in such selection is further\nmagnified by today's information curation services that maximize user\nengagement (and thus service revenue) by filtering new content in accordance\nwith observed consumer preferences. Consequently, individuals get exposed to\nincreasingly narrower bands of the ideology spectrum. Societies get fragmented\ninto increasingly ideologically isolated enclaves. These enclaves (or\necho-chambers) then become vulnerable to misinformation spread, which in turn\nfurther magnifies polarization and bias. We call this dynamic the paradox of\ninformation access; a growing ideological fragmentation in the age of sharing.\nThis article describes the technical, economic, and socio-cognitive\ncontributors to this paradox, and explores research directions towards its\nmitigation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Modern online media, such as Twitter, Instagram, and YouTube, enable anyone\nto become an information producer and to offer online content for potentially\nglobal consumption. By increasing the amount of globally accessible real-time\ninformation, today's ubiquitous producers contribute to a world, where an\nindividual consumes vanishingly smaller fractions of all produced content. In\ngeneral, consumers preferentially select information that closely matches their\nindividual views and values. The bias inherent in such selection is further\nmagnified by today's information curation services that maximize user\nengagement (and thus service revenue) by filtering new content in accordance\nwith observed consumer preferences. Consequently, individuals get exposed to\nincreasingly narrower bands of the ideology spectrum. Societies get fragmented\ninto increasingly ideologically isolated enclaves. These enclaves (or\necho-chambers) then become vulnerable to misinformation spread, which in turn\nfurther magnifies polarization and bias. We call this dynamic the paradox of\ninformation access; a growing ideological fragmentation in the age of sharing.\nThis article describes the technical, economic, and socio-cognitive\ncontributors to this paradox, and explores research directions towards its\nmitigation.""}, 'authors': [{'name': 'Tarek Abdelzaher'}, {'name': 'Heng Ji'}, {'name': 'Jinyang Li'}, {'name': 'Chaoqi Yang'}, {'name': 'John Dellaverson'}, {'name': 'Lixia Zhang'}, {'name': 'Chao Xu'}, {'name': 'Boleslaw K. Szymanski'}], 'author_detail': {'name': 'Boleslaw K. Szymanski'}, 'author': 'Boleslaw K. Szymanski', 'arxiv_comment': '13 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2004.01967v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.01967v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
301,http://arxiv.org/abs/2004.01732v1,2020-04-03 18:26:33+00:00,2020-04-03 18:26:33+00:00,Leveraging Multi-Source Weak Social Supervision for Early Detection of Fake News,"[arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Guoqing Zheng'), arxiv.Result.Author('Yichuan Li'), arxiv.Result.Author('Subhabrata Mukherjee'), arxiv.Result.Author('Ahmed Hassan Awadallah'), arxiv.Result.Author('Scott Ruston'), arxiv.Result.Author('Huan Liu')]","Social media has greatly enabled people to participate in online activities
at an unprecedented rate. However, this unrestricted access also exacerbates
the spread of misinformation and fake news online which might cause confusion
and chaos unless being detected early for its mitigation. Given the rapidly
evolving nature of news events and the limited amount of annotated data,
state-of-the-art systems on fake news detection face challenges due to the lack
of large numbers of annotated training instances that are hard to come by for
early detection. In this work, we exploit multiple weak signals from different
sources given by user and content engagements (referred to as weak social
supervision), and their complementary utilities to detect fake news. We jointly
leverage the limited amount of clean data along with weak signals from social
engagements to train deep neural networks in a meta-learning framework to
estimate the quality of different weak instances. Experiments on realworld
datasets demonstrate that the proposed framework outperforms state-of-the-art
baselines for early detection of fake news without using any user engagements
at prediction time.","17 pages, 5 figures, 4 tables",,,cs.LG,"['cs.LG', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2004.01732v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.01732v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.01732v1,"{'id': 'http://arxiv.org/abs/2004.01732v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.01732v1', 'updated': '2020-04-03T18:26:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=3, tm_hour=18, tm_min=26, tm_sec=33, tm_wday=4, tm_yday=94, tm_isdst=0), 'published': '2020-04-03T18:26:33Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=3, tm_hour=18, tm_min=26, tm_sec=33, tm_wday=4, tm_yday=94, tm_isdst=0), 'title': 'Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News'}, 'summary': 'Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.'}, 'authors': [{'name': 'Kai Shu'}, {'name': 'Guoqing Zheng'}, {'name': 'Yichuan Li'}, {'name': 'Subhabrata Mukherjee'}, {'name': 'Ahmed Hassan Awadallah'}, {'name': 'Scott Ruston'}, {'name': 'Huan Liu'}], 'author_detail': {'name': 'Huan Liu'}, 'author': 'Huan Liu', 'arxiv_comment': '17 pages, 5 figures, 4 tables', 'links': [{'href': 'http://arxiv.org/abs/2004.01732v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.01732v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
302,http://arxiv.org/abs/2004.01106v2,2021-01-15 21:26:57+00:00,2020-04-02 16:10:34+00:00,The Paradox of Information Access: On Modeling Social-Media-Induced Polarization,"[arxiv.Result.Author('Chao Xu'), arxiv.Result.Author('Jinyang Li'), arxiv.Result.Author('Tarek Abdelzaher'), arxiv.Result.Author('Heng Ji'), arxiv.Result.Author('Boleslaw K. Szymanski'), arxiv.Result.Author('John Dellaverson')]","The paper develops a stochastic model of drift in human beliefs that shows
that today's sheer volume of accessible information, combined with consumers'
confirmation bias and natural preference to more outlying content, necessarily
lead to increased polarization. The model explains the paradox of growing
ideological fragmentation in the age of increased sharing. As social media,
search engines, and other real-time information sharing outlets purport to
facilitate access to information, a need for content filtering arises due to
the ensuing information overload. In general, consumers select information that
matches their individual views and values. The bias inherent in such selection
is echoed by today's information curation services that maximize user
engagement by filtering new content in accordance with observed consumer
preferences. Consequently, individuals get exposed to increasingly narrower
bands of the ideology spectrum, thus fragmenting society into increasingly
ideologically isolated enclaves. We call this dynamic the paradox of
information access. The model also suggests the disproportionate damage
attainable with a small infusion of well-positioned misinformation. The paper
describes the modeling methodology, and evaluates modeling results for
different population sizes and parameter settings.",An updated version of this preprint was submitted to IEEE TCNS,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2004.01106v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.01106v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.01106v2,"{'id': 'http://arxiv.org/abs/2004.01106v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.01106v2', 'updated': '2021-01-15T21:26:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=15, tm_hour=21, tm_min=26, tm_sec=57, tm_wday=4, tm_yday=15, tm_isdst=0), 'published': '2020-04-02T16:10:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=16, tm_min=10, tm_sec=34, tm_wday=3, tm_yday=93, tm_isdst=0), 'title': 'The Paradox of Information Access: On Modeling Social-Media-Induced\n  Polarization', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Paradox of Information Access: On Modeling Social-Media-Induced\n  Polarization'}, 'summary': ""The paper develops a stochastic model of drift in human beliefs that shows\nthat today's sheer volume of accessible information, combined with consumers'\nconfirmation bias and natural preference to more outlying content, necessarily\nlead to increased polarization. The model explains the paradox of growing\nideological fragmentation in the age of increased sharing. As social media,\nsearch engines, and other real-time information sharing outlets purport to\nfacilitate access to information, a need for content filtering arises due to\nthe ensuing information overload. In general, consumers select information that\nmatches their individual views and values. The bias inherent in such selection\nis echoed by today's information curation services that maximize user\nengagement by filtering new content in accordance with observed consumer\npreferences. Consequently, individuals get exposed to increasingly narrower\nbands of the ideology spectrum, thus fragmenting society into increasingly\nideologically isolated enclaves. We call this dynamic the paradox of\ninformation access. The model also suggests the disproportionate damage\nattainable with a small infusion of well-positioned misinformation. The paper\ndescribes the modeling methodology, and evaluates modeling results for\ndifferent population sizes and parameter settings."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The paper develops a stochastic model of drift in human beliefs that shows\nthat today's sheer volume of accessible information, combined with consumers'\nconfirmation bias and natural preference to more outlying content, necessarily\nlead to increased polarization. The model explains the paradox of growing\nideological fragmentation in the age of increased sharing. As social media,\nsearch engines, and other real-time information sharing outlets purport to\nfacilitate access to information, a need for content filtering arises due to\nthe ensuing information overload. In general, consumers select information that\nmatches their individual views and values. The bias inherent in such selection\nis echoed by today's information curation services that maximize user\nengagement by filtering new content in accordance with observed consumer\npreferences. Consequently, individuals get exposed to increasingly narrower\nbands of the ideology spectrum, thus fragmenting society into increasingly\nideologically isolated enclaves. We call this dynamic the paradox of\ninformation access. The model also suggests the disproportionate damage\nattainable with a small infusion of well-positioned misinformation. The paper\ndescribes the modeling methodology, and evaluates modeling results for\ndifferent population sizes and parameter settings.""}, 'authors': [{'name': 'Chao Xu'}, {'name': 'Jinyang Li'}, {'name': 'Tarek Abdelzaher'}, {'name': 'Heng Ji'}, {'name': 'Boleslaw K. Szymanski'}, {'name': 'John Dellaverson'}], 'author_detail': {'name': 'John Dellaverson'}, 'author': 'John Dellaverson', 'arxiv_comment': 'An updated version of this preprint was submitted to IEEE TCNS', 'links': [{'href': 'http://arxiv.org/abs/2004.01106v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.01106v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
303,http://arxiv.org/abs/2004.00777v1,2020-04-02 02:22:45+00:00,2020-04-02 02:22:45+00:00,Skepticism and rumor spreading: the role of spatial correlations,"[arxiv.Result.Author('Marco Antonio Amaral'), arxiv.Result.Author('W. G. Dantas'), arxiv.Result.Author('Jeferson J. Arenzon')]","Critical thinking and skepticism are fundamental mechanisms that one may use
to prevent the spreading of rumors, fake-news and misinformation. We consider a
simple model in which agents without previous contact with the rumor, being
skeptically oriented, may convince spreaders to stop their activity or, once
exposed to the rumor, decide not to propagate it as a consequence, for example,
of fact-checking. We extend a previous, mean-field analysis of the combined
effect of these two mechanisms, active and passive skepticism, to include
spatial correlations. This can be done either analytically, through the pair
approximation, or simulating an agent-based version on diverse networks. Our
results show that while in mean-field there is no coexistence between spreaders
and susceptibles (although, depending on the parameters, there may be
bistability depending on the initial conditions), when spatial correlations are
included, because of the protective effect of the isolation provided by removed
agents, coexistence is possible.","9 pages, 6 figures","Phys. Rev. E 101, 062418 (2020)",10.1103/PhysRevE.101.062418,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech', 'q-bio.PE']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevE.101.062418', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.00777v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00777v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00777v1,"{'id': 'http://arxiv.org/abs/2004.00777v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00777v1', 'updated': '2020-04-02T02:22:45Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=2, tm_min=22, tm_sec=45, tm_wday=3, tm_yday=93, tm_isdst=0), 'published': '2020-04-02T02:22:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=2, tm_min=22, tm_sec=45, tm_wday=3, tm_yday=93, tm_isdst=0), 'title': 'Skepticism and rumor spreading: the role of spatial correlations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Skepticism and rumor spreading: the role of spatial correlations'}, 'summary': 'Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.'}, 'authors': [{'name': 'Marco Antonio Amaral'}, {'name': 'W. G. Dantas'}, {'name': 'Jeferson J. Arenzon'}], 'author_detail': {'name': 'Jeferson J. Arenzon'}, 'author': 'Jeferson J. Arenzon', 'arxiv_doi': '10.1103/PhysRevE.101.062418', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevE.101.062418', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.00777v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00777v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '9 pages, 6 figures', 'arxiv_journal_ref': 'Phys. Rev. E 101, 062418 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.stat-mech', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
304,http://arxiv.org/abs/2004.00742v2,2020-11-19 00:01:44+00:00,2020-04-01 23:44:58+00:00,"#ArsonEmergency and Australia's ""Black Summer"": Polarisation and misinformation on social media","[arxiv.Result.Author('Derek Weber'), arxiv.Result.Author('Mehwish Nasim'), arxiv.Result.Author('Lucia Falzon'), arxiv.Result.Author('Lewis Mitchell')]","During the summer of 2019-20, while Australia suffered unprecedented
bushfires across the country, false narratives regarding arson and limited
backburning spread quickly on Twitter, particularly using the hashtag
#ArsonEmergency. Misinformation and bot- and troll-like behaviour were detected
and reported by social media researchers and the news soon reached mainstream
media. This paper examines the communication and behaviour of two polarised
online communities before and after news of the misinformation became public
knowledge. Specifically, the Supporter community actively engaged with others
to spread the hashtag, using a variety of news sources pushing the arson
narrative, while the Opposer community engaged less, retweeted more, and
focused its use of URLs to link to mainstream sources, debunking the narratives
and exposing the anomalous behaviour. This influenced the content of the
broader discussion. Bot analysis revealed the active accounts were
predominantly human, but behavioural and content analysis suggests Supporters
engaged in trolling, though both communities used aggressive language.","16 pages, 8 images, presented at the 2nd Multidisciplinary
  International Symposium on Disinformation in Open Online Media (MISDOOM
  2020), Leiden, The Netherlands. Published in: van Duijn M., Preuss M.,
  Spaiser V., Takes F., Verberne S. (eds) Disinformation in Open Online Media.
  MISDOOM 2020. Lecture Notes in Computer Science, vol 12259. Springer, Cham.
  https://doi.org/10.1007/978-3-030-61841-4_11",,10.1007/978-3-030-61841-4_11,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-61841-4_11', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2004.00742v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00742v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00742v2,"{'id': 'http://arxiv.org/abs/2004.00742v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00742v2', 'updated': '2020-11-19T00:01:44Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=19, tm_hour=0, tm_min=1, tm_sec=44, tm_wday=3, tm_yday=324, tm_isdst=0), 'published': '2020-04-01T23:44:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=1, tm_hour=23, tm_min=44, tm_sec=58, tm_wday=2, tm_yday=92, tm_isdst=0), 'title': '#ArsonEmergency and Australia\'s ""Black Summer"": Polarisation and\n  misinformation on social media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '#ArsonEmergency and Australia\'s ""Black Summer"": Polarisation and\n  misinformation on social media'}, 'summary': 'During the summer of 2019-20, while Australia suffered unprecedented\nbushfires across the country, false narratives regarding arson and limited\nbackburning spread quickly on Twitter, particularly using the hashtag\n#ArsonEmergency. Misinformation and bot- and troll-like behaviour were detected\nand reported by social media researchers and the news soon reached mainstream\nmedia. This paper examines the communication and behaviour of two polarised\nonline communities before and after news of the misinformation became public\nknowledge. Specifically, the Supporter community actively engaged with others\nto spread the hashtag, using a variety of news sources pushing the arson\nnarrative, while the Opposer community engaged less, retweeted more, and\nfocused its use of URLs to link to mainstream sources, debunking the narratives\nand exposing the anomalous behaviour. This influenced the content of the\nbroader discussion. Bot analysis revealed the active accounts were\npredominantly human, but behavioural and content analysis suggests Supporters\nengaged in trolling, though both communities used aggressive language.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'During the summer of 2019-20, while Australia suffered unprecedented\nbushfires across the country, false narratives regarding arson and limited\nbackburning spread quickly on Twitter, particularly using the hashtag\n#ArsonEmergency. Misinformation and bot- and troll-like behaviour were detected\nand reported by social media researchers and the news soon reached mainstream\nmedia. This paper examines the communication and behaviour of two polarised\nonline communities before and after news of the misinformation became public\nknowledge. Specifically, the Supporter community actively engaged with others\nto spread the hashtag, using a variety of news sources pushing the arson\nnarrative, while the Opposer community engaged less, retweeted more, and\nfocused its use of URLs to link to mainstream sources, debunking the narratives\nand exposing the anomalous behaviour. This influenced the content of the\nbroader discussion. Bot analysis revealed the active accounts were\npredominantly human, but behavioural and content analysis suggests Supporters\nengaged in trolling, though both communities used aggressive language.'}, 'authors': [{'name': 'Derek Weber'}, {'name': 'Mehwish Nasim'}, {'name': 'Lucia Falzon'}, {'name': 'Lewis Mitchell'}], 'author_detail': {'name': 'Lewis Mitchell'}, 'author': 'Lewis Mitchell', 'arxiv_doi': '10.1007/978-3-030-61841-4_11', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-61841-4_11', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2004.00742v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00742v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '16 pages, 8 images, presented at the 2nd Multidisciplinary\n  International Symposium on Disinformation in Open Online Media (MISDOOM\n  2020), Leiden, The Netherlands. Published in: van Duijn M., Preuss M.,\n  Spaiser V., Takes F., Verberne S. (eds) Disinformation in Open Online Media.\n  MISDOOM 2020. Lecture Notes in Computer Science, vol 12259. Springer, Cham.\n  https://doi.org/10.1007/978-3-030-61841-4_11', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
305,http://arxiv.org/abs/2004.00673v2,2020-04-21 20:50:30+00:00,2020-04-01 19:32:25+00:00,Hate multiverse spreads malicious COVID-19 content online beyond individual platform control,"[arxiv.Result.Author('N. Velásquez'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('Y. Lupu'), arxiv.Result.Author('R. Sear'), arxiv.Result.Author('N. Gabriel'), arxiv.Result.Author('O. Jha'), arxiv.Result.Author('B. Goldberg'), arxiv.Result.Author('N. F. Johnson')]","We show that malicious COVID-19 content, including hate speech,
disinformation, and misinformation, exploits the multiverse of online hate to
spread quickly beyond the control of any individual social media platform.
Machine learning topic analysis shows quantitatively how online hate
communities are weaponizing COVID-19, with topics evolving rapidly and content
becoming increasingly coherent. Our mathematical analysis provides a
generalized form of the public health R0 predicting the tipping point for
multiverse-wide viral spreading, which suggests new policy options to mitigate
the global spread of malicious COVID-19 content without relying on future
coordination between all online platforms.","Working paper. Feedback welcomed from the community to
  neiljohnson@gwu.edu",,,physics.soc-ph,"['physics.soc-ph', 'nlin.AO', 'physics.pop-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2004.00673v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00673v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00673v2,"{'id': 'http://arxiv.org/abs/2004.00673v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00673v2', 'updated': '2020-04-21T20:50:30Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=21, tm_hour=20, tm_min=50, tm_sec=30, tm_wday=1, tm_yday=112, tm_isdst=0), 'published': '2020-04-01T19:32:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=1, tm_hour=19, tm_min=32, tm_sec=25, tm_wday=2, tm_yday=92, tm_isdst=0), 'title': 'Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control'}, 'summary': 'We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.'}, 'authors': [{'name': 'N. Velásquez'}, {'name': 'R. Leahy'}, {'name': 'N. Johnson Restrepo'}, {'name': 'Y. Lupu'}, {'name': 'R. Sear'}, {'name': 'N. Gabriel'}, {'name': 'O. Jha'}, {'name': 'B. Goldberg'}, {'name': 'N. F. Johnson'}], 'author_detail': {'name': 'N. F. Johnson'}, 'author': 'N. F. Johnson', 'arxiv_comment': 'Working paper. Feedback welcomed from the community to\n  neiljohnson@gwu.edu', 'links': [{'href': 'http://arxiv.org/abs/2004.00673v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00673v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
306,http://arxiv.org/abs/2004.00005v1,2020-03-30 19:05:34+00:00,2020-03-30 19:05:34+00:00,Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish Internet,"[arxiv.Result.Author('Andrzej Jarynowski'), arxiv.Result.Author('Monika Wojta-Kempa'), arxiv.Result.Author('Vitaly Belik')]","We study the perception of COVID-2019 epidemic in Polish society using
quantitative analysis of its digital footprints on the Internet (on Twitter,
Google, YouTube, Wikipedia and electronic media represented by Event Registry)
from January 2020 to 12.03.2020 (before and after official introduction to
Poland on 04.03.2020). To this end we utilize data mining, social network
analysis, natural language processing techniques. Each examined internet
platform was analyzed for representativeness and composition of the target
group. We identified three temporal major cluster of the interest before
disease introduction on the topic COVID-2019: China- and Italy-related peaks on
all platforms, as well as a peak on social media related to the recent special
law on combating COVID-2019. Besides, there was a peak in interest on the day
of officially confirmed introduction as well as an exponential increase of
interest when the Polish government declared war against disease with a massive
mitigation program. From sociolingistic perspective, we found that concepts and
issues of threat, fear and prevention prevailed before introduction. After
introduction, practical concepts about disease and epidemic dominate. We have
found out that Twitter reflected the structural division of the Polish
political sphere. We were able to identify clear communities of governing
party, mainstream oppostition and protestant group and potential sources of
misinformation. We have also detected bluring boundaries between comminities
after disease introduction.",,,,cs.SI,"['cs.SI', 'physics.soc-ph', 'q-bio.PE']","[arxiv.Result.Link('http://arxiv.org/abs/2004.00005v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2004.00005v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2004.00005v1,"{'id': 'http://arxiv.org/abs/2004.00005v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2004.00005v1', 'updated': '2020-03-30T19:05:34Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=30, tm_hour=19, tm_min=5, tm_sec=34, tm_wday=0, tm_yday=90, tm_isdst=0), 'published': '2020-03-30T19:05:34Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=30, tm_hour=19, tm_min=5, tm_sec=34, tm_wday=0, tm_yday=90, tm_isdst=0), 'title': 'Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish\n  Internet', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish\n  Internet'}, 'summary': 'We study the perception of COVID-2019 epidemic in Polish society using\nquantitative analysis of its digital footprints on the Internet (on Twitter,\nGoogle, YouTube, Wikipedia and electronic media represented by Event Registry)\nfrom January 2020 to 12.03.2020 (before and after official introduction to\nPoland on 04.03.2020). To this end we utilize data mining, social network\nanalysis, natural language processing techniques. Each examined internet\nplatform was analyzed for representativeness and composition of the target\ngroup. We identified three temporal major cluster of the interest before\ndisease introduction on the topic COVID-2019: China- and Italy-related peaks on\nall platforms, as well as a peak on social media related to the recent special\nlaw on combating COVID-2019. Besides, there was a peak in interest on the day\nof officially confirmed introduction as well as an exponential increase of\ninterest when the Polish government declared war against disease with a massive\nmitigation program. From sociolingistic perspective, we found that concepts and\nissues of threat, fear and prevention prevailed before introduction. After\nintroduction, practical concepts about disease and epidemic dominate. We have\nfound out that Twitter reflected the structural division of the Polish\npolitical sphere. We were able to identify clear communities of governing\nparty, mainstream oppostition and protestant group and potential sources of\nmisinformation. We have also detected bluring boundaries between comminities\nafter disease introduction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We study the perception of COVID-2019 epidemic in Polish society using\nquantitative analysis of its digital footprints on the Internet (on Twitter,\nGoogle, YouTube, Wikipedia and electronic media represented by Event Registry)\nfrom January 2020 to 12.03.2020 (before and after official introduction to\nPoland on 04.03.2020). To this end we utilize data mining, social network\nanalysis, natural language processing techniques. Each examined internet\nplatform was analyzed for representativeness and composition of the target\ngroup. We identified three temporal major cluster of the interest before\ndisease introduction on the topic COVID-2019: China- and Italy-related peaks on\nall platforms, as well as a peak on social media related to the recent special\nlaw on combating COVID-2019. Besides, there was a peak in interest on the day\nof officially confirmed introduction as well as an exponential increase of\ninterest when the Polish government declared war against disease with a massive\nmitigation program. From sociolingistic perspective, we found that concepts and\nissues of threat, fear and prevention prevailed before introduction. After\nintroduction, practical concepts about disease and epidemic dominate. We have\nfound out that Twitter reflected the structural division of the Polish\npolitical sphere. We were able to identify clear communities of governing\nparty, mainstream oppostition and protestant group and potential sources of\nmisinformation. We have also detected bluring boundaries between comminities\nafter disease introduction.'}, 'authors': [{'name': 'Andrzej Jarynowski'}, {'name': 'Monika Wojta-Kempa'}, {'name': 'Vitaly Belik'}], 'author_detail': {'name': 'Vitaly Belik'}, 'author': 'Vitaly Belik', 'links': [{'href': 'http://arxiv.org/abs/2004.00005v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2004.00005v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
307,http://arxiv.org/abs/2003.13657v3,2020-04-02 16:32:15+00:00,2020-03-30 17:44:42+00:00,Analysing the Extent of Misinformation in Cancer Related Tweets,"[arxiv.Result.Author('Rakesh Bal'), arxiv.Result.Author('Sayan Sinha'), arxiv.Result.Author('Swastika Dutta'), arxiv.Result.Author('Rishabh Joshi'), arxiv.Result.Author('Sayan Ghosh'), arxiv.Result.Author('Ritam Dutt')]","Twitter has become one of the most sought after places to discuss a wide
variety of topics, including medically relevant issues such as cancer. This
helps spread awareness regarding the various causes, cures and prevention
methods of cancer. However, no proper analysis has been performed, which
discusses the validity of such claims. In this work, we aim to tackle the
misinformation spread in such platforms. We collect and present a dataset
regarding tweets which talk specifically about cancer and propose an
attention-based deep learning model for automated detection of misinformation
along with its spread. We then do a comparative analysis of the linguistic
variation in the text corresponding to misinformation and truth. This analysis
helps us gather relevant insights on various social aspects related to
misinformed tweets.","Proceedings of the 14th International Conference on Web and Social
  Media (ICWSM-20)","ICWSM 2020, 14, 924-928",,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2003.13657v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.13657v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.13657v3,"{'id': 'http://arxiv.org/abs/2003.13657v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.13657v3', 'updated': '2020-04-02T16:32:15Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=2, tm_hour=16, tm_min=32, tm_sec=15, tm_wday=3, tm_yday=93, tm_isdst=0), 'published': '2020-03-30T17:44:42Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=30, tm_hour=17, tm_min=44, tm_sec=42, tm_wday=0, tm_yday=90, tm_isdst=0), 'title': 'Analysing the Extent of Misinformation in Cancer Related Tweets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysing the Extent of Misinformation in Cancer Related Tweets'}, 'summary': 'Twitter has become one of the most sought after places to discuss a wide\nvariety of topics, including medically relevant issues such as cancer. This\nhelps spread awareness regarding the various causes, cures and prevention\nmethods of cancer. However, no proper analysis has been performed, which\ndiscusses the validity of such claims. In this work, we aim to tackle the\nmisinformation spread in such platforms. We collect and present a dataset\nregarding tweets which talk specifically about cancer and propose an\nattention-based deep learning model for automated detection of misinformation\nalong with its spread. We then do a comparative analysis of the linguistic\nvariation in the text corresponding to misinformation and truth. This analysis\nhelps us gather relevant insights on various social aspects related to\nmisinformed tweets.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Twitter has become one of the most sought after places to discuss a wide\nvariety of topics, including medically relevant issues such as cancer. This\nhelps spread awareness regarding the various causes, cures and prevention\nmethods of cancer. However, no proper analysis has been performed, which\ndiscusses the validity of such claims. In this work, we aim to tackle the\nmisinformation spread in such platforms. We collect and present a dataset\nregarding tweets which talk specifically about cancer and propose an\nattention-based deep learning model for automated detection of misinformation\nalong with its spread. We then do a comparative analysis of the linguistic\nvariation in the text corresponding to misinformation and truth. This analysis\nhelps us gather relevant insights on various social aspects related to\nmisinformed tweets.'}, 'authors': [{'name': 'Rakesh Bal'}, {'name': 'Sayan Sinha'}, {'name': 'Swastika Dutta'}, {'name': 'Rishabh Joshi'}, {'name': 'Sayan Ghosh'}, {'name': 'Ritam Dutt'}], 'author_detail': {'name': 'Ritam Dutt'}, 'author': 'Ritam Dutt', 'arxiv_comment': 'Proceedings of the 14th International Conference on Web and Social\n  Media (ICWSM-20)', 'arxiv_journal_ref': 'ICWSM 2020, 14, 924-928', 'links': [{'href': 'http://arxiv.org/abs/2003.13657v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.13657v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
308,http://arxiv.org/abs/2003.12309v4,2020-10-22 03:03:29+00:00,2020-03-26 09:48:24+00:00,COVID-19 on Social Media: Analyzing Misinformation in Twitter Conversations,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Sungyong Seo'), arxiv.Result.Author('Chuizheng Meng'), arxiv.Result.Author('Sirisha Rambhatla'), arxiv.Result.Author('Yan Liu')]","The ongoing Coronavirus (COVID-19) pandemic highlights the
inter-connectedness of our present-day globalized world. With social distancing
policies in place, virtual communication has become an important source of
(mis)information. As increasing number of people rely on social media platforms
for news, identifying misinformation and uncovering the nature of online
discourse around COVID-19 has emerged as a critical task. To this end, we
collected streaming data related to COVID-19 using the Twitter API, starting
March 1, 2020. We identified unreliable and misleading contents based on
fact-checking sources, and examined the narratives promoted in misinformation
tweets, along with the distribution of engagements with these tweets. In
addition, we provide examples of the spreading patterns of prominent
misinformation tweets. The analysis is presented and updated on a publically
accessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to
track the nature of online discourse and misinformation about COVID-19 on
Twitter from March 1 - June 5, 2020. The dashboard provides a daily list of
identified misinformation tweets, along with topics, sentiments, and emerging
trends in the COVID-19 Twitter discourse. The dashboard is provided to improve
visibility into the nature and quality of information shared online, and
provide real-time access to insights and information extracted from the
dataset.",,,,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2003.12309v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.12309v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.12309v4,"{'id': 'http://arxiv.org/abs/2003.12309v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.12309v4', 'updated': '2020-10-22T03:03:29Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=22, tm_hour=3, tm_min=3, tm_sec=29, tm_wday=3, tm_yday=296, tm_isdst=0), 'published': '2020-03-26T09:48:24Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=26, tm_hour=9, tm_min=48, tm_sec=24, tm_wday=3, tm_yday=86, tm_isdst=0), 'title': 'COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations'}, 'summary': 'The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.'}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Sungyong Seo'}, {'name': 'Chuizheng Meng'}, {'name': 'Sirisha Rambhatla'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'links': [{'href': 'http://arxiv.org/abs/2003.12309v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.12309v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
309,http://arxiv.org/abs/2003.11459v1,2020-03-23 23:43:02+00:00,2020-03-23 23:43:02+00:00,BaitWatcher: A lightweight web interface for the detection of incongruent news headlines,"[arxiv.Result.Author('Kunwoo Park'), arxiv.Result.Author('Taegyun Kim'), arxiv.Result.Author('Seunghyun Yoon'), arxiv.Result.Author('Meeyoung Cha'), arxiv.Result.Author('Kyomin Jung')]","In digital environments where substantial amounts of information are shared
online, news headlines play essential roles in the selection and diffusion of
news articles. Some news articles attract audience attention by showing
exaggerated or misleading headlines. This study addresses the \textit{headline
incongruity} problem, in which a news headline makes claims that are either
unrelated or opposite to the contents of the corresponding article. We present
\textit{BaitWatcher}, which is a lightweight web interface that guides readers
in estimating the likelihood of incongruence in news articles before clicking
on the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that
efficiently learns complex textual representations of a news headline and its
associated body text. For training the model, we construct a million scale
dataset of news articles, which we also release for broader research use. Based
on the results of a focus group interview, we discuss the importance of
developing an interpretable AI agent for the design of a better interface for
mitigating the effects of online misinformation.","24 pages (single column), 7 figures. This research article is
  published as a book chapter of \textit{Fake News, Disinformation, and
  Misinformation in Social Media-Emerging Research Challenges and
  Opportunities}. Springer, 2020. arXiv admin note: text overlap with
  arXiv:1811.07066",,10.1007/978-3-030-42699-6,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI', '68U15']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-030-42699-6', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2003.11459v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.11459v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.11459v1,"{'id': 'http://arxiv.org/abs/2003.11459v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.11459v1', 'updated': '2020-03-23T23:43:02Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=23, tm_hour=23, tm_min=43, tm_sec=2, tm_wday=0, tm_yday=83, tm_isdst=0), 'published': '2020-03-23T23:43:02Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=23, tm_hour=23, tm_min=43, tm_sec=2, tm_wday=0, tm_yday=83, tm_isdst=0), 'title': 'BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines'}, 'summary': 'In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.'}, 'authors': [{'name': 'Kunwoo Park'}, {'name': 'Taegyun Kim'}, {'name': 'Seunghyun Yoon'}, {'name': 'Meeyoung Cha'}, {'name': 'Kyomin Jung'}], 'author_detail': {'name': 'Kyomin Jung'}, 'author': 'Kyomin Jung', 'arxiv_doi': '10.1007/978-3-030-42699-6', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-030-42699-6', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2003.11459v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.11459v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '24 pages (single column), 7 figures. This research article is\n  published as a book chapter of \\textit{Fake News, Disinformation, and\n  Misinformation in Social Media-Emerging Research Challenges and\n  Opportunities}. Springer, 2020. arXiv admin note: text overlap with\n  arXiv:1811.07066', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68U15', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
310,http://arxiv.org/abs/2003.10359v1,2020-03-23 16:25:55+00:00,2020-03-23 16:25:55+00:00,Understanding the perception of COVID-19 policies by mining a multilanguage Twitter dataset,"[arxiv.Result.Author('Christian E. Lopez'), arxiv.Result.Author('Malolan Vasu'), arxiv.Result.Author('Caleb Gallemore')]","The objective of this work is to explore popular discourse about the COVID-19
pandemic and policies implemented to manage it. Using Natural Language
Processing, Text Mining, and Network Analysis to analyze corpus of tweets that
relate to the COVID-19 pandemic, we identify common responses to the pandemic
and how these responses differ across time. Moreover, insights as to how
information and misinformation were transmitted via Twitter, starting at the
early stages of this pandemic, are presented. Finally, this work introduces a
dataset of tweets collected from all over the world, in multiple languages,
dating back to January 22nd, when the total cases of reported COVID-19 were
below 600 worldwide. The insights presented in this work could help inform
decision makers in the face of future pandemics, and the dataset introduced can
be used to acquire valuable knowledge to help mitigate the COVID-19 pandemic.",https://github.com/lopezbec/COVID19_Tweets_Dataset,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2003.10359v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.10359v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.10359v1,"{'id': 'http://arxiv.org/abs/2003.10359v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.10359v1', 'updated': '2020-03-23T16:25:55Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=23, tm_hour=16, tm_min=25, tm_sec=55, tm_wday=0, tm_yday=83, tm_isdst=0), 'published': '2020-03-23T16:25:55Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=23, tm_hour=16, tm_min=25, tm_sec=55, tm_wday=0, tm_yday=83, tm_isdst=0), 'title': 'Understanding the perception of COVID-19 policies by mining a\n  multilanguage Twitter dataset', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding the perception of COVID-19 policies by mining a\n  multilanguage Twitter dataset'}, 'summary': 'The objective of this work is to explore popular discourse about the COVID-19\npandemic and policies implemented to manage it. Using Natural Language\nProcessing, Text Mining, and Network Analysis to analyze corpus of tweets that\nrelate to the COVID-19 pandemic, we identify common responses to the pandemic\nand how these responses differ across time. Moreover, insights as to how\ninformation and misinformation were transmitted via Twitter, starting at the\nearly stages of this pandemic, are presented. Finally, this work introduces a\ndataset of tweets collected from all over the world, in multiple languages,\ndating back to January 22nd, when the total cases of reported COVID-19 were\nbelow 600 worldwide. The insights presented in this work could help inform\ndecision makers in the face of future pandemics, and the dataset introduced can\nbe used to acquire valuable knowledge to help mitigate the COVID-19 pandemic.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The objective of this work is to explore popular discourse about the COVID-19\npandemic and policies implemented to manage it. Using Natural Language\nProcessing, Text Mining, and Network Analysis to analyze corpus of tweets that\nrelate to the COVID-19 pandemic, we identify common responses to the pandemic\nand how these responses differ across time. Moreover, insights as to how\ninformation and misinformation were transmitted via Twitter, starting at the\nearly stages of this pandemic, are presented. Finally, this work introduces a\ndataset of tweets collected from all over the world, in multiple languages,\ndating back to January 22nd, when the total cases of reported COVID-19 were\nbelow 600 worldwide. The insights presented in this work could help inform\ndecision makers in the face of future pandemics, and the dataset introduced can\nbe used to acquire valuable knowledge to help mitigate the COVID-19 pandemic.'}, 'authors': [{'name': 'Christian E. Lopez'}, {'name': 'Malolan Vasu'}, {'name': 'Caleb Gallemore'}], 'author_detail': {'name': 'Caleb Gallemore'}, 'author': 'Caleb Gallemore', 'arxiv_comment': 'https://github.com/lopezbec/COVID19_Tweets_Dataset', 'links': [{'href': 'http://arxiv.org/abs/2003.10359v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.10359v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
311,http://arxiv.org/abs/2003.08377v2,2020-04-09 13:24:29+00:00,2020-03-18 17:54:46+00:00,Network disruption: maximizing disagreement and polarization in social networks,"[arxiv.Result.Author('Mayee F. Chen'), arxiv.Result.Author('Miklos Z. Racz')]","Recent years have seen a marked increase in the spread of misinformation, a
phenomenon which has been accelerated and amplified by social media such as
Facebook and Twitter. While some actors spread misinformation to push a
specific agenda, it has also been widely documented that others aim to simply
disrupt the network by increasing disagreement and polarization across the
network and thereby destabilizing society. Popular social networks are also
vulnerable to large-scale attacks. Motivated by this reality, we introduce a
simple model of network disruption where an adversary can take over a limited
number of user profiles in a social network with the aim of maximizing
disagreement and/or polarization in the network.
  We investigate this model both theoretically and empirically. We show that
the adversary will always change the opinion of a taken-over profile to an
extreme in order to maximize disruption. We also prove that an adversary can
increase disagreement / polarization at most linearly in the number of user
profiles it takes over. Furthermore, we present a detailed empirical study of
several natural algorithms for the adversary on both synthetic networks and
real world (Reddit and Twitter) data sets. These show that even simple,
unsophisticated heuristics, such as targeting centrists, can disrupt a network
effectively, causing a large increase in disagreement / polarization. Studying
the problem of network disruption through the lens of an adversary thus
highlights the seriousness of the problem.","20 pages, 6 figures",,,cs.SI,"['cs.SI', 'cs.DS', 'cs.GT', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2003.08377v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.08377v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.08377v2,"{'id': 'http://arxiv.org/abs/2003.08377v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.08377v2', 'updated': '2020-04-09T13:24:29Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=9, tm_hour=13, tm_min=24, tm_sec=29, tm_wday=3, tm_yday=100, tm_isdst=0), 'published': '2020-03-18T17:54:46Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=18, tm_hour=17, tm_min=54, tm_sec=46, tm_wday=2, tm_yday=78, tm_isdst=0), 'title': 'Network disruption: maximizing disagreement and polarization in social\n  networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Network disruption: maximizing disagreement and polarization in social\n  networks'}, 'summary': 'Recent years have seen a marked increase in the spread of misinformation, a\nphenomenon which has been accelerated and amplified by social media such as\nFacebook and Twitter. While some actors spread misinformation to push a\nspecific agenda, it has also been widely documented that others aim to simply\ndisrupt the network by increasing disagreement and polarization across the\nnetwork and thereby destabilizing society. Popular social networks are also\nvulnerable to large-scale attacks. Motivated by this reality, we introduce a\nsimple model of network disruption where an adversary can take over a limited\nnumber of user profiles in a social network with the aim of maximizing\ndisagreement and/or polarization in the network.\n  We investigate this model both theoretically and empirically. We show that\nthe adversary will always change the opinion of a taken-over profile to an\nextreme in order to maximize disruption. We also prove that an adversary can\nincrease disagreement / polarization at most linearly in the number of user\nprofiles it takes over. Furthermore, we present a detailed empirical study of\nseveral natural algorithms for the adversary on both synthetic networks and\nreal world (Reddit and Twitter) data sets. These show that even simple,\nunsophisticated heuristics, such as targeting centrists, can disrupt a network\neffectively, causing a large increase in disagreement / polarization. Studying\nthe problem of network disruption through the lens of an adversary thus\nhighlights the seriousness of the problem.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have seen a marked increase in the spread of misinformation, a\nphenomenon which has been accelerated and amplified by social media such as\nFacebook and Twitter. While some actors spread misinformation to push a\nspecific agenda, it has also been widely documented that others aim to simply\ndisrupt the network by increasing disagreement and polarization across the\nnetwork and thereby destabilizing society. Popular social networks are also\nvulnerable to large-scale attacks. Motivated by this reality, we introduce a\nsimple model of network disruption where an adversary can take over a limited\nnumber of user profiles in a social network with the aim of maximizing\ndisagreement and/or polarization in the network.\n  We investigate this model both theoretically and empirically. We show that\nthe adversary will always change the opinion of a taken-over profile to an\nextreme in order to maximize disruption. We also prove that an adversary can\nincrease disagreement / polarization at most linearly in the number of user\nprofiles it takes over. Furthermore, we present a detailed empirical study of\nseveral natural algorithms for the adversary on both synthetic networks and\nreal world (Reddit and Twitter) data sets. These show that even simple,\nunsophisticated heuristics, such as targeting centrists, can disrupt a network\neffectively, causing a large increase in disagreement / polarization. Studying\nthe problem of network disruption through the lens of an adversary thus\nhighlights the seriousness of the problem.'}, 'authors': [{'name': 'Mayee F. Chen'}, {'name': 'Miklos Z. Racz'}], 'author_detail': {'name': 'Miklos Z. Racz'}, 'author': 'Miklos Z. Racz', 'arxiv_comment': '20 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/2003.08377v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.08377v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
312,http://arxiv.org/abs/2003.07595v1,2020-03-17 09:24:22+00:00,2020-03-17 09:24:22+00:00,FakeYou! -- A Gamified Approach for Building and Evaluating Resilience Against Fake News,"[arxiv.Result.Author('Lena Clever'), arxiv.Result.Author('Dennis Assenmacher'), arxiv.Result.Author('Kilian Müller'), arxiv.Result.Author('Moritz Vinzent Seiler'), arxiv.Result.Author('Dennis M. Riehle'), arxiv.Result.Author('Mike Preuss'), arxiv.Result.Author('Christian Grimme')]","Nowadays fake news are heavily discussed in public and political debates.
Even though the phenomenon of intended false information is rather old,
misinformation reaches a new level with the rise of the internet and
participatory platforms. Due to Facebook and Co., purposeful false information
- often called fake news - can be easily spread by everyone. Because of a high
data volatility and variety in content types (text, images,...) debunking of
fake news is a complex challenge. This is especially true for automated
approaches, which are prone to fail validating the veracity of the information.
This work focuses on an a gamified approach to strengthen the resilience of
consumers towards fake news. The game FakeYou motivates its players to
critically analyze headlines regarding their trustworthiness. Further, the game
follows a ""learning by doing strategy"": by generating own fake headlines, users
should experience the concepts of convincing fake headline formulations. We
introduce the game itself, as well as the underlying technical infrastructure.
A first evaluation study shows, that users tend to use specific stylistic
devices to generate fake news. Further, the results indicate, that creating
good fakes and identifying correct headlines are challenging and hard to learn.","accepted for Disinformation in Open Online Media - 2nd
  Multidisciplinary International Symposium, MISDOOM 2020",,,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/2003.07595v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07595v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07595v1,"{'id': 'http://arxiv.org/abs/2003.07595v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07595v1', 'updated': '2020-03-17T09:24:22Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=17, tm_hour=9, tm_min=24, tm_sec=22, tm_wday=1, tm_yday=77, tm_isdst=0), 'published': '2020-03-17T09:24:22Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=17, tm_hour=9, tm_min=24, tm_sec=22, tm_wday=1, tm_yday=77, tm_isdst=0), 'title': 'FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News'}, 'summary': 'Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a ""learning by doing strategy"": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a ""learning by doing strategy"": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.'}, 'authors': [{'name': 'Lena Clever'}, {'name': 'Dennis Assenmacher'}, {'name': 'Kilian Müller'}, {'name': 'Moritz Vinzent Seiler'}, {'name': 'Dennis M. Riehle'}, {'name': 'Mike Preuss'}, {'name': 'Christian Grimme'}], 'author_detail': {'name': 'Christian Grimme'}, 'author': 'Christian Grimme', 'arxiv_comment': 'accepted for Disinformation in Open Online Media - 2nd\n  Multidisciplinary International Symposium, MISDOOM 2020', 'links': [{'href': 'http://arxiv.org/abs/2003.07595v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07595v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
313,http://arxiv.org/abs/2003.07372v2,2020-06-02 18:35:00+00:00,2020-03-16 18:00:04+00:00,Tracking Social Media Discourse About the COVID-19 Pandemic: Development of a Public Coronavirus Twitter Data Set,"[arxiv.Result.Author('Emily Chen'), arxiv.Result.Author('Kristina Lerman'), arxiv.Result.Author('Emilio Ferrara')]","At the time of this writing, the novel coronavirus (COVID-19) pandemic
outbreak has already put tremendous strain on many countries' citizens,
resources and economies around the world. Social distancing measures, travel
bans, self-quarantines, and business closures are changing the very fabric of
societies worldwide. With people forced out of public spaces, much conversation
about these phenomena now occurs online, e.g., on social media platforms like
Twitter. In this paper, we describe a multilingual coronavirus (COVID-19)
Twitter dataset that we have been continuously collecting since January 22,
2020. We are making our dataset available to the research community
(https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our
contribution will enable the study of online conversation dynamics in the
context of a planetary-scale epidemic outbreak of unprecedented proportions and
implications. This dataset could also help track scientific coronavirus
misinformation and unverified rumors, or enable the understanding of fear and
panic -- and undoubtedly more. Ultimately, this dataset may contribute towards
enabling informed solutions and prescribing targeted policy interventions to
fight this global crisis.",,JMIR Public Health Surveill 2020;6(2):e19273,10.2196/19273,cs.SI,"['cs.SI', 'q-bio.PE']","[arxiv.Result.Link('http://dx.doi.org/10.2196/19273', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2003.07372v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07372v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07372v2,"{'id': 'http://arxiv.org/abs/2003.07372v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07372v2', 'updated': '2020-06-02T18:35:00Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=2, tm_hour=18, tm_min=35, tm_sec=0, tm_wday=1, tm_yday=154, tm_isdst=0), 'published': '2020-03-16T18:00:04Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=16, tm_hour=18, tm_min=0, tm_sec=4, tm_wday=0, tm_yday=76, tm_isdst=0), 'title': 'Tracking Social Media Discourse About the COVID-19 Pandemic: Development\n  of a Public Coronavirus Twitter Data Set', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Tracking Social Media Discourse About the COVID-19 Pandemic: Development\n  of a Public Coronavirus Twitter Data Set'}, 'summary': ""At the time of this writing, the novel coronavirus (COVID-19) pandemic\noutbreak has already put tremendous strain on many countries' citizens,\nresources and economies around the world. Social distancing measures, travel\nbans, self-quarantines, and business closures are changing the very fabric of\nsocieties worldwide. With people forced out of public spaces, much conversation\nabout these phenomena now occurs online, e.g., on social media platforms like\nTwitter. In this paper, we describe a multilingual coronavirus (COVID-19)\nTwitter dataset that we have been continuously collecting since January 22,\n2020. We are making our dataset available to the research community\n(https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our\ncontribution will enable the study of online conversation dynamics in the\ncontext of a planetary-scale epidemic outbreak of unprecedented proportions and\nimplications. This dataset could also help track scientific coronavirus\nmisinformation and unverified rumors, or enable the understanding of fear and\npanic -- and undoubtedly more. Ultimately, this dataset may contribute towards\nenabling informed solutions and prescribing targeted policy interventions to\nfight this global crisis."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""At the time of this writing, the novel coronavirus (COVID-19) pandemic\noutbreak has already put tremendous strain on many countries' citizens,\nresources and economies around the world. Social distancing measures, travel\nbans, self-quarantines, and business closures are changing the very fabric of\nsocieties worldwide. With people forced out of public spaces, much conversation\nabout these phenomena now occurs online, e.g., on social media platforms like\nTwitter. In this paper, we describe a multilingual coronavirus (COVID-19)\nTwitter dataset that we have been continuously collecting since January 22,\n2020. We are making our dataset available to the research community\n(https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our\ncontribution will enable the study of online conversation dynamics in the\ncontext of a planetary-scale epidemic outbreak of unprecedented proportions and\nimplications. This dataset could also help track scientific coronavirus\nmisinformation and unverified rumors, or enable the understanding of fear and\npanic -- and undoubtedly more. Ultimately, this dataset may contribute towards\nenabling informed solutions and prescribing targeted policy interventions to\nfight this global crisis.""}, 'authors': [{'name': 'Emily Chen'}, {'name': 'Kristina Lerman'}, {'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'arxiv_doi': '10.2196/19273', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.2196/19273', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2003.07372v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07372v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'JMIR Public Health Surveill 2020;6(2):e19273', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
314,http://arxiv.org/abs/2003.07074v3,2020-10-30 15:49:04+00:00,2020-03-16 08:51:40+00:00,A Machine Learning Application for Raising WASH Awareness in the Times of COVID-19 Pandemic,"[arxiv.Result.Author('Rohan Pandey'), arxiv.Result.Author('Vaibhav Gautam'), arxiv.Result.Author('Ridam Pal'), arxiv.Result.Author('Harsh Bandhey'), arxiv.Result.Author('Lovedeep Singh Dhingra'), arxiv.Result.Author('Himanshu Sharma'), arxiv.Result.Author('Chirag Jain'), arxiv.Result.Author('Kanav Bhagat'), arxiv.Result.Author('Arushi'), arxiv.Result.Author('Lajjaben Patel'), arxiv.Result.Author('Mudit Agarwal'), arxiv.Result.Author('Samprati Agrawal'), arxiv.Result.Author('Rishabh Jalan'), arxiv.Result.Author('Akshat Wadhwa'), arxiv.Result.Author('Ayush Garg'), arxiv.Result.Author('Vihaan Misra'), arxiv.Result.Author('Yashwin Agrawal'), arxiv.Result.Author('Bhavika Rana'), arxiv.Result.Author('Ponnurangam Kumaraguru'), arxiv.Result.Author('Tavpritesh Sethi')]","Background: The COVID-19 pandemic has uncovered the potential of digital
misinformation in shaping the health of nations. The deluge of unverified
information that spreads faster than the epidemic itself is an unprecedented
phenomenon that has put millions of lives in danger. Mitigating this Infodemic
requires strong health messaging systems that are engaging, vernacular,
scalable, effective and continuously learn the new patterns of misinformation.
  Objective: We created WashKaro, a multi-pronged intervention for mitigating
misinformation through conversational AI, machine translation and natural
language processing. WashKaro provides the right information matched against
WHO guidelines through AI, and delivers it in the right format in local
languages.
  Methods: We theorize (i) an NLP based AI engine that could continuously
incorporate user feedback to improve relevance of information, (ii) bite sized
audio in the local language to improve penetrance in a country with skewed
gender literacy ratios, and (iii) conversational but interactive AI engagement
with users towards an increased health awareness in the community. Results: A
total of 5026 people who downloaded the app during the study window, among
those 1545 were active users. Our study shows that 3.4 times more females
engaged with the App in Hindi as compared to males, the relevance of
AI-filtered news content doubled within 45 days of continuous machine learning,
and the prudence of integrated AI chatbot Satya increased thus proving the
usefulness of an mHealth platform to mitigate health misinformation.
  Conclusion: We conclude that a multi-pronged machine learning application
delivering vernacular bite-sized audios and conversational AI is an effective
approach to mitigate health misinformation.","14 pages, 7 figures",,,cs.CY,"['cs.CY', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2003.07074v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07074v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07074v3,"{'id': 'http://arxiv.org/abs/2003.07074v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07074v3', 'updated': '2020-10-30T15:49:04Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=30, tm_hour=15, tm_min=49, tm_sec=4, tm_wday=4, tm_yday=304, tm_isdst=0), 'published': '2020-03-16T08:51:40Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=16, tm_hour=8, tm_min=51, tm_sec=40, tm_wday=0, tm_yday=76, tm_isdst=0), 'title': 'A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic'}, 'summary': 'Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.'}, 'authors': [{'name': 'Rohan Pandey'}, {'name': 'Vaibhav Gautam'}, {'name': 'Ridam Pal'}, {'name': 'Harsh Bandhey'}, {'name': 'Lovedeep Singh Dhingra'}, {'name': 'Himanshu Sharma'}, {'name': 'Chirag Jain'}, {'name': 'Kanav Bhagat'}, {'name': 'Arushi'}, {'name': 'Lajjaben Patel'}, {'name': 'Mudit Agarwal'}, {'name': 'Samprati Agrawal'}, {'name': 'Rishabh Jalan'}, {'name': 'Akshat Wadhwa'}, {'name': 'Ayush Garg'}, {'name': 'Vihaan Misra'}, {'name': 'Yashwin Agrawal'}, {'name': 'Bhavika Rana'}, {'name': 'Ponnurangam Kumaraguru'}, {'name': 'Tavpritesh Sethi'}], 'author_detail': {'name': 'Tavpritesh Sethi'}, 'author': 'Tavpritesh Sethi', 'arxiv_comment': '14 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/2003.07074v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07074v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
315,http://arxiv.org/abs/2003.07192v4,2021-01-08 03:43:46+00:00,2020-03-12 18:37:19+00:00,Social Media and Misleading Information in a Democracy: A Mechanism Design Approach,"[arxiv.Result.Author('Aditya Dave'), arxiv.Result.Author('Ioannis Vasileios Chremos'), arxiv.Result.Author('Andreas A. Malikopoulos')]","In this paper, we present a resource allocation mechanism for the problem of
incentivizing filtering among a finite number of strategic social media
platforms. We consider the presence of a strategic government and private
knowledge of how misinformation affects the users of the social media
platforms. Our proposed mechanism incentivizes social media platforms to filter
misleading information efficiently, and thus indirectly prevents the spread of
fake news. In particular, we design an economically inspired mechanism that
strongly implements all generalized Nash equilibria for efficient filtering of
misleading information in the induced game. We show that our mechanism is
individually rational, budget balanced, while it has at least one equilibrium.
Finally, we show that for quasi-concave utilities and constraints, our
mechanism admits a generalized Nash equilibrium and implements a Pareto
efficient solution.",,,,cs.GT,"['cs.GT', 'cs.SY', 'eess.SY']","[arxiv.Result.Link('http://arxiv.org/abs/2003.07192v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.07192v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.07192v4,"{'id': 'http://arxiv.org/abs/2003.07192v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.07192v4', 'updated': '2021-01-08T03:43:46Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=8, tm_hour=3, tm_min=43, tm_sec=46, tm_wday=4, tm_yday=8, tm_isdst=0), 'published': '2020-03-12T18:37:19Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=12, tm_hour=18, tm_min=37, tm_sec=19, tm_wday=3, tm_yday=72, tm_isdst=0), 'title': 'Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach'}, 'summary': 'In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.'}, 'authors': [{'name': 'Aditya Dave'}, {'name': 'Ioannis Vasileios Chremos'}, {'name': 'Andreas A. Malikopoulos'}], 'author_detail': {'name': 'Andreas A. Malikopoulos'}, 'author': 'Andreas A. Malikopoulos', 'links': [{'href': 'http://arxiv.org/abs/2003.07192v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.07192v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
316,http://arxiv.org/abs/2003.05004v1,2020-03-10 21:14:17+00:00,2020-03-10 21:14:17+00:00,The COVID-19 Social Media Infodemic,"[arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Alessandro Galeazzi'), arxiv.Result.Author('Carlo Michele Valensise'), arxiv.Result.Author('Emanuele Brugnoli'), arxiv.Result.Author('Ana Lucia Schmidt'), arxiv.Result.Author('Paola Zola'), arxiv.Result.Author('Fabiana Zollo'), arxiv.Result.Author('Antonio Scala')]","We address the diffusion of information about the COVID-19 with a massive
data analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze
engagement and interest in the COVID-19 topic and provide a differential
assessment on the evolution of the discourse on a global scale for each
platform and their users. We fit information spreading with epidemic models
characterizing the basic reproduction numbers $R_0$ for each social media
platform. Moreover, we characterize information spreading from questionable
sources, finding different volumes of misinformation in each platform. However,
information from both reliable and questionable sources do not present
different spreading patterns. Finally, we provide platform-dependent numerical
estimates of rumors' amplification.",,"Sci Rep 10, 16598 (2020)",10.1038/s41598-020-73510-5,cs.SI,"['cs.SI', 'nlin.AO', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41598-020-73510-5', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2003.05004v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.05004v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.05004v1,"{'id': 'http://arxiv.org/abs/2003.05004v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.05004v1', 'updated': '2020-03-10T21:14:17Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=10, tm_hour=21, tm_min=14, tm_sec=17, tm_wday=1, tm_yday=70, tm_isdst=0), 'published': '2020-03-10T21:14:17Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=10, tm_hour=21, tm_min=14, tm_sec=17, tm_wday=1, tm_yday=70, tm_isdst=0), 'title': 'The COVID-19 Social Media Infodemic', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The COVID-19 Social Media Infodemic'}, 'summary': ""We address the diffusion of information about the COVID-19 with a massive\ndata analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze\nengagement and interest in the COVID-19 topic and provide a differential\nassessment on the evolution of the discourse on a global scale for each\nplatform and their users. We fit information spreading with epidemic models\ncharacterizing the basic reproduction numbers $R_0$ for each social media\nplatform. Moreover, we characterize information spreading from questionable\nsources, finding different volumes of misinformation in each platform. However,\ninformation from both reliable and questionable sources do not present\ndifferent spreading patterns. Finally, we provide platform-dependent numerical\nestimates of rumors' amplification."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We address the diffusion of information about the COVID-19 with a massive\ndata analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze\nengagement and interest in the COVID-19 topic and provide a differential\nassessment on the evolution of the discourse on a global scale for each\nplatform and their users. We fit information spreading with epidemic models\ncharacterizing the basic reproduction numbers $R_0$ for each social media\nplatform. Moreover, we characterize information spreading from questionable\nsources, finding different volumes of misinformation in each platform. However,\ninformation from both reliable and questionable sources do not present\ndifferent spreading patterns. Finally, we provide platform-dependent numerical\nestimates of rumors' amplification.""}, 'authors': [{'name': 'Matteo Cinelli'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Alessandro Galeazzi'}, {'name': 'Carlo Michele Valensise'}, {'name': 'Emanuele Brugnoli'}, {'name': 'Ana Lucia Schmidt'}, {'name': 'Paola Zola'}, {'name': 'Fabiana Zollo'}, {'name': 'Antonio Scala'}], 'author_detail': {'name': 'Antonio Scala'}, 'author': 'Antonio Scala', 'arxiv_doi': '10.1038/s41598-020-73510-5', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41598-020-73510-5', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2003.05004v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.05004v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Sci Rep 10, 16598 (2020)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
317,http://arxiv.org/abs/2003.00923v1,2020-03-02 14:07:56+00:00,2020-03-02 14:07:56+00:00,"Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business","[arxiv.Result.Author('Yelena Mejova'), arxiv.Result.Author('Kyriaki Kalimeri')]","In the age of social media, disasters and epidemics usher not only a
devastation and affliction in the physical world, but also prompt a deluge of
information, opinions, prognoses and advice to billions of internet users. The
coronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World
Health Organization warning of a possible ""infodemic"" of fake news. In this
study, we examine the alternative narratives around the coronavirus outbreak
through advertisements promoted on Facebook, the largest social media platform
in the US. Using the new Facebook Ads Library, we discover advertisers from
public health and non-profit sectors, alongside those from news media,
politics, and business, incorporating coronavirus into their messaging and
agenda. We find the virus used in political attacks, donation solicitations,
business promotion, stock market advice, and animal rights campaigning. Among
these, we find several instances of possible misinformation, ranging from
bioweapons conspiracy theories to unverifiable claims by politicians. As we
make the dataset available to the community, we hope the advertising domain
will become an important part of quality control for public health
communication and public discourse in general.",Preprint. Under Review,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/2003.00923v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.00923v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.00923v1,"{'id': 'http://arxiv.org/abs/2003.00923v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.00923v1', 'updated': '2020-03-02T14:07:56Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=2, tm_hour=14, tm_min=7, tm_sec=56, tm_wday=0, tm_yday=62, tm_isdst=0), 'published': '2020-03-02T14:07:56Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=2, tm_hour=14, tm_min=7, tm_sec=56, tm_wday=0, tm_yday=62, tm_isdst=0), 'title': 'Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business'}, 'summary': 'In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible ""infodemic"" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible ""infodemic"" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.'}, 'authors': [{'name': 'Yelena Mejova'}, {'name': 'Kyriaki Kalimeri'}], 'author_detail': {'name': 'Kyriaki Kalimeri'}, 'author': 'Kyriaki Kalimeri', 'arxiv_comment': 'Preprint. Under Review', 'links': [{'href': 'http://arxiv.org/abs/2003.00923v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.00923v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
318,http://arxiv.org/abs/2003.00056v3,2021-01-07 18:56:59+00:00,2020-02-28 20:35:58+00:00,Measuring Node Contribution to Community Structure with Modularity Vitality,"[arxiv.Result.Author('Thomas Magelinski'), arxiv.Result.Author('Mihovil Bartulovic'), arxiv.Result.Author('Kathleen M. Carley')]","Community-aware centrality is an emerging research area in network science
concerned with the importance of nodes in relation to community structure.
Measures are a function of a network's structure and a given partition.
Previous approaches extend classical centrality measures to account for
community structure with little connection to community detection theory. In
contrast, we propose cluster-quality vitality measures, i.e., modularity
vitality, a community-aware measure which is well-grounded in both centrality
and community detection theory. Modularity vitality quantifies positive and
negative contributions to community structure, which indicate a node's role as
a community bridge or hub. We derive a computationally efficient method of
calculating modularity vitality for all nodes in O(M + NC) time, where C is the
number of communities. We systematically fragment networks by removing central
nodes, and find that modularity vitality consistently outperforms existing
community-aware centrality measures. Modularity vitality is over 8 times more
effective than the next-best method on a million-node infrastructure network.
This result does not generalize to social media communication networks, which
exhibit extreme robustness to all community-aware centrality attacks. This
robustness suggests that user-based interventions to mitigate misinformation
diffusion will be ineffective. Finally, we demonstrate that modularity vitality
provides a new approach to community-deception.",Accepted to IEEE Transactions on Network Science and Engineering,,10.1109/TNSE.2020.3049068,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/TNSE.2020.3049068', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2003.00056v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2003.00056v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2003.00056v3,"{'id': 'http://arxiv.org/abs/2003.00056v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2003.00056v3', 'updated': '2021-01-07T18:56:59Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=18, tm_min=56, tm_sec=59, tm_wday=3, tm_yday=7, tm_isdst=0), 'published': '2020-02-28T20:35:58Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=28, tm_hour=20, tm_min=35, tm_sec=58, tm_wday=4, tm_yday=59, tm_isdst=0), 'title': 'Measuring Node Contribution to Community Structure with Modularity\n  Vitality', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Measuring Node Contribution to Community Structure with Modularity\n  Vitality'}, 'summary': ""Community-aware centrality is an emerging research area in network science\nconcerned with the importance of nodes in relation to community structure.\nMeasures are a function of a network's structure and a given partition.\nPrevious approaches extend classical centrality measures to account for\ncommunity structure with little connection to community detection theory. In\ncontrast, we propose cluster-quality vitality measures, i.e., modularity\nvitality, a community-aware measure which is well-grounded in both centrality\nand community detection theory. Modularity vitality quantifies positive and\nnegative contributions to community structure, which indicate a node's role as\na community bridge or hub. We derive a computationally efficient method of\ncalculating modularity vitality for all nodes in O(M + NC) time, where C is the\nnumber of communities. We systematically fragment networks by removing central\nnodes, and find that modularity vitality consistently outperforms existing\ncommunity-aware centrality measures. Modularity vitality is over 8 times more\neffective than the next-best method on a million-node infrastructure network.\nThis result does not generalize to social media communication networks, which\nexhibit extreme robustness to all community-aware centrality attacks. This\nrobustness suggests that user-based interventions to mitigate misinformation\ndiffusion will be ineffective. Finally, we demonstrate that modularity vitality\nprovides a new approach to community-deception."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Community-aware centrality is an emerging research area in network science\nconcerned with the importance of nodes in relation to community structure.\nMeasures are a function of a network's structure and a given partition.\nPrevious approaches extend classical centrality measures to account for\ncommunity structure with little connection to community detection theory. In\ncontrast, we propose cluster-quality vitality measures, i.e., modularity\nvitality, a community-aware measure which is well-grounded in both centrality\nand community detection theory. Modularity vitality quantifies positive and\nnegative contributions to community structure, which indicate a node's role as\na community bridge or hub. We derive a computationally efficient method of\ncalculating modularity vitality for all nodes in O(M + NC) time, where C is the\nnumber of communities. We systematically fragment networks by removing central\nnodes, and find that modularity vitality consistently outperforms existing\ncommunity-aware centrality measures. Modularity vitality is over 8 times more\neffective than the next-best method on a million-node infrastructure network.\nThis result does not generalize to social media communication networks, which\nexhibit extreme robustness to all community-aware centrality attacks. This\nrobustness suggests that user-based interventions to mitigate misinformation\ndiffusion will be ineffective. Finally, we demonstrate that modularity vitality\nprovides a new approach to community-deception.""}, 'authors': [{'name': 'Thomas Magelinski'}, {'name': 'Mihovil Bartulovic'}, {'name': 'Kathleen M. Carley'}], 'author_detail': {'name': 'Kathleen M. Carley'}, 'author': 'Kathleen M. Carley', 'arxiv_doi': '10.1109/TNSE.2020.3049068', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TNSE.2020.3049068', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2003.00056v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2003.00056v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted to IEEE Transactions on Network Science and Engineering', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
319,http://arxiv.org/abs/2002.10522v2,2020-03-04 16:07:57+00:00,2020-02-24 20:28:14+00:00,MIDMod-OSN: A Microscopic-level Information Diffusion Model for Online Social Networks,"[arxiv.Result.Author('Abiola Osho'), arxiv.Result.Author('Colin Goodman'), arxiv.Result.Author('George Amariucai')]","As online social networks continue to be commonly used for the dissemination
of information to the public, understanding the phenomena that govern
information diffusion is crucial for many security and safety-related
applications, such as maximizing information spread and misinformation
containment during crises and natural disasters. In this study, we hypothesize
that the features that contribute to information diffusion in online social
networks are significantly influenced by the type of event being studied. We
classify Twitter events as either informative or trending and then explore the
node-to-node influence dynamics associated with information spread. We build a
model based on Bayesian Logistic Regression for learning and prediction and
Random Forests for feature selection. Experimental results from real-world data
sets show that the proposed model outperforms state-of-the-art diffusion
prediction models, achieving 93% accuracy in informative events and 86% in
trending events. We observed that the models for informative and trending
events differ significantly, both in the diffusion process and in the user
features that govern the diffusion. Our findings show that followers play an
important role in the diffusion process and it is possible to use the diffusion
and OSN behavior of users for predicting the trending character of a message
without having to count the number of reactions.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/2002.10522v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.10522v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.10522v2,"{'id': 'http://arxiv.org/abs/2002.10522v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.10522v2', 'updated': '2020-03-04T16:07:57Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=4, tm_hour=16, tm_min=7, tm_sec=57, tm_wday=2, tm_yday=64, tm_isdst=0), 'published': '2020-02-24T20:28:14Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=24, tm_hour=20, tm_min=28, tm_sec=14, tm_wday=0, tm_yday=55, tm_isdst=0), 'title': 'MIDMod-OSN: A Microscopic-level Information Diffusion Model for Online\n  Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'MIDMod-OSN: A Microscopic-level Information Diffusion Model for Online\n  Social Networks'}, 'summary': 'As online social networks continue to be commonly used for the dissemination\nof information to the public, understanding the phenomena that govern\ninformation diffusion is crucial for many security and safety-related\napplications, such as maximizing information spread and misinformation\ncontainment during crises and natural disasters. In this study, we hypothesize\nthat the features that contribute to information diffusion in online social\nnetworks are significantly influenced by the type of event being studied. We\nclassify Twitter events as either informative or trending and then explore the\nnode-to-node influence dynamics associated with information spread. We build a\nmodel based on Bayesian Logistic Regression for learning and prediction and\nRandom Forests for feature selection. Experimental results from real-world data\nsets show that the proposed model outperforms state-of-the-art diffusion\nprediction models, achieving 93% accuracy in informative events and 86% in\ntrending events. We observed that the models for informative and trending\nevents differ significantly, both in the diffusion process and in the user\nfeatures that govern the diffusion. Our findings show that followers play an\nimportant role in the diffusion process and it is possible to use the diffusion\nand OSN behavior of users for predicting the trending character of a message\nwithout having to count the number of reactions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As online social networks continue to be commonly used for the dissemination\nof information to the public, understanding the phenomena that govern\ninformation diffusion is crucial for many security and safety-related\napplications, such as maximizing information spread and misinformation\ncontainment during crises and natural disasters. In this study, we hypothesize\nthat the features that contribute to information diffusion in online social\nnetworks are significantly influenced by the type of event being studied. We\nclassify Twitter events as either informative or trending and then explore the\nnode-to-node influence dynamics associated with information spread. We build a\nmodel based on Bayesian Logistic Regression for learning and prediction and\nRandom Forests for feature selection. Experimental results from real-world data\nsets show that the proposed model outperforms state-of-the-art diffusion\nprediction models, achieving 93% accuracy in informative events and 86% in\ntrending events. We observed that the models for informative and trending\nevents differ significantly, both in the diffusion process and in the user\nfeatures that govern the diffusion. Our findings show that followers play an\nimportant role in the diffusion process and it is possible to use the diffusion\nand OSN behavior of users for predicting the trending character of a message\nwithout having to count the number of reactions.'}, 'authors': [{'name': 'Abiola Osho'}, {'name': 'Colin Goodman'}, {'name': 'George Amariucai'}], 'author_detail': {'name': 'George Amariucai'}, 'author': 'George Amariucai', 'links': [{'href': 'http://arxiv.org/abs/2002.10522v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.10522v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
320,http://arxiv.org/abs/2002.11104v1,2020-02-24 20:04:54+00:00,2020-02-24 20:04:54+00:00,An Information Diffusion Approach to Rumor Propagation and Identification on Twitter,"[arxiv.Result.Author('Abiola Osho'), arxiv.Result.Author('Caden Waters'), arxiv.Result.Author('George Amariucai')]","With the increasing use of online social networks as a source of news and
information, the propensity for a rumor to disseminate widely and quickly poses
a great concern, especially in disaster situations where users do not have
enough time to fact-check posts before making the informed decision to react to
a post that appears to be credible. In this study, we explore the propagation
pattern of rumors on Twitter by exploring the dynamics of microscopic-level
misinformation spread, based on the latent message and user interaction
attributes. We perform supervised learning for feature selection and
prediction. Experimental results with real-world data sets give the models'
prediction accuracy at about 90\% for the diffusion of both True and False
topics. Our findings confirm that rumor cascades run deeper and that rumor
masked as news, and messages that incite fear, will diffuse faster than other
messages. We show that the models for True and False message propagation differ
significantly, both in the prediction parameters and in the message features
that govern the diffusion. Finally, we show that the diffusion pattern is an
important metric in identifying the credibility of a tweet.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2002.11104v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.11104v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.11104v1,"{'id': 'http://arxiv.org/abs/2002.11104v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.11104v1', 'updated': '2020-02-24T20:04:54Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=24, tm_hour=20, tm_min=4, tm_sec=54, tm_wday=0, tm_yday=55, tm_isdst=0), 'published': '2020-02-24T20:04:54Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=24, tm_hour=20, tm_min=4, tm_sec=54, tm_wday=0, tm_yday=55, tm_isdst=0), 'title': 'An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter'}, 'summary': ""With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.""}, 'authors': [{'name': 'Abiola Osho'}, {'name': 'Caden Waters'}, {'name': 'George Amariucai'}], 'author_detail': {'name': 'George Amariucai'}, 'author': 'George Amariucai', 'links': [{'href': 'http://arxiv.org/abs/2002.11104v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.11104v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
321,http://arxiv.org/abs/2002.11768v3,2020-12-12 05:15:18+00:00,2020-02-19 04:18:45+00:00,Attacking Neural Text Detectors,"[arxiv.Result.Author('Max Wolff'), arxiv.Result.Author('Stuart Wolff')]","Machine learning based language models have recently made significant
progress, which introduces a danger to spread misinformation. To combat this
potential danger, several methods have been proposed for detecting text written
by these language models. This paper presents two classes of black-box attacks
on these detectors, one which randomly replaces characters with homoglyphs, and
the other a simple scheme to purposefully misspell words. The homoglyph and
misspelling attacks decrease a popular neural text detector's recall on neural
text from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that
the attacks are transferable to other neural text detectors.","Accepted at the ICLR 2020 workshop ""Towards Trustworthy ML:
  Rethinking Security and Privacy for ML.""",,,cs.CR,"['cs.CR', 'cs.CL']","[arxiv.Result.Link('http://arxiv.org/abs/2002.11768v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.11768v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.11768v3,"{'id': 'http://arxiv.org/abs/2002.11768v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.11768v3', 'updated': '2020-12-12T05:15:18Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=12, tm_hour=5, tm_min=15, tm_sec=18, tm_wday=5, tm_yday=347, tm_isdst=0), 'published': '2020-02-19T04:18:45Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=18, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0), 'title': 'Attacking Neural Text Detectors', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Attacking Neural Text Detectors'}, 'summary': ""Machine learning based language models have recently made significant\nprogress, which introduces a danger to spread misinformation. To combat this\npotential danger, several methods have been proposed for detecting text written\nby these language models. This paper presents two classes of black-box attacks\non these detectors, one which randomly replaces characters with homoglyphs, and\nthe other a simple scheme to purposefully misspell words. The homoglyph and\nmisspelling attacks decrease a popular neural text detector's recall on neural\ntext from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that\nthe attacks are transferable to other neural text detectors."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Machine learning based language models have recently made significant\nprogress, which introduces a danger to spread misinformation. To combat this\npotential danger, several methods have been proposed for detecting text written\nby these language models. This paper presents two classes of black-box attacks\non these detectors, one which randomly replaces characters with homoglyphs, and\nthe other a simple scheme to purposefully misspell words. The homoglyph and\nmisspelling attacks decrease a popular neural text detector's recall on neural\ntext from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that\nthe attacks are transferable to other neural text detectors.""}, 'authors': [{'name': 'Max Wolff'}, {'name': 'Stuart Wolff'}], 'author_detail': {'name': 'Stuart Wolff'}, 'author': 'Stuart Wolff', 'arxiv_comment': 'Accepted at the ICLR 2020 workshop ""Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML.""', 'links': [{'href': 'http://arxiv.org/abs/2002.11768v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.11768v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
322,http://arxiv.org/abs/2002.07917v1,2020-02-18 22:56:40+00:00,2020-02-18 22:56:40+00:00,TIES: Temporal Interaction Embeddings For Enhancing Social Media Integrity At Facebook,"[arxiv.Result.Author('Nima Noorshams'), arxiv.Result.Author('Saurabh Verma'), arxiv.Result.Author('Aude Hofleitner')]","Since its inception, Facebook has become an integral part of the online
social community. People rely on Facebook to make connections with others and
build communities. As a result, it is paramount to protect the integrity of
such a rapidly growing network in a fast and scalable manner. In this paper, we
present our efforts to protect various social media entities at Facebook from
people who try to abuse our platform. We present a novel Temporal Interaction
EmbeddingS (TIES) model that is designed to capture rogue social interactions
and flag them for further suitable actions. TIES is a supervised, deep
learning, production ready model at Facebook-scale networks. Prior works on
integrity problems are mostly focused on capturing either only static or
certain dynamic features of social entities. In contrast, TIES can capture both
these variant behaviors in a unified model owing to the recent strides made in
the domains of graph embedding and deep sequential pattern learning. To show
the real-world impact of TIES, we present a few applications especially for
preventing spread of misinformation, fake account detection, and reducing ads
payment risks in order to enhance the platform's integrity.",Submitted to KDD 2020 applied DS track,,,cs.AI,"['cs.AI', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2002.07917v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.07917v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.07917v1,"{'id': 'http://arxiv.org/abs/2002.07917v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.07917v1', 'updated': '2020-02-18T22:56:40Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=56, tm_sec=40, tm_wday=1, tm_yday=49, tm_isdst=0), 'published': '2020-02-18T22:56:40Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=56, tm_sec=40, tm_wday=1, tm_yday=49, tm_isdst=0), 'title': 'TIES: Temporal Interaction Embeddings For Enhancing Social Media\n  Integrity At Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'TIES: Temporal Interaction Embeddings For Enhancing Social Media\n  Integrity At Facebook'}, 'summary': ""Since its inception, Facebook has become an integral part of the online\nsocial community. People rely on Facebook to make connections with others and\nbuild communities. As a result, it is paramount to protect the integrity of\nsuch a rapidly growing network in a fast and scalable manner. In this paper, we\npresent our efforts to protect various social media entities at Facebook from\npeople who try to abuse our platform. We present a novel Temporal Interaction\nEmbeddingS (TIES) model that is designed to capture rogue social interactions\nand flag them for further suitable actions. TIES is a supervised, deep\nlearning, production ready model at Facebook-scale networks. Prior works on\nintegrity problems are mostly focused on capturing either only static or\ncertain dynamic features of social entities. In contrast, TIES can capture both\nthese variant behaviors in a unified model owing to the recent strides made in\nthe domains of graph embedding and deep sequential pattern learning. To show\nthe real-world impact of TIES, we present a few applications especially for\npreventing spread of misinformation, fake account detection, and reducing ads\npayment risks in order to enhance the platform's integrity."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Since its inception, Facebook has become an integral part of the online\nsocial community. People rely on Facebook to make connections with others and\nbuild communities. As a result, it is paramount to protect the integrity of\nsuch a rapidly growing network in a fast and scalable manner. In this paper, we\npresent our efforts to protect various social media entities at Facebook from\npeople who try to abuse our platform. We present a novel Temporal Interaction\nEmbeddingS (TIES) model that is designed to capture rogue social interactions\nand flag them for further suitable actions. TIES is a supervised, deep\nlearning, production ready model at Facebook-scale networks. Prior works on\nintegrity problems are mostly focused on capturing either only static or\ncertain dynamic features of social entities. In contrast, TIES can capture both\nthese variant behaviors in a unified model owing to the recent strides made in\nthe domains of graph embedding and deep sequential pattern learning. To show\nthe real-world impact of TIES, we present a few applications especially for\npreventing spread of misinformation, fake account detection, and reducing ads\npayment risks in order to enhance the platform's integrity.""}, 'authors': [{'name': 'Nima Noorshams'}, {'name': 'Saurabh Verma'}, {'name': 'Aude Hofleitner'}], 'author_detail': {'name': 'Aude Hofleitner'}, 'author': 'Aude Hofleitner', 'arxiv_comment': 'Submitted to KDD 2020 applied DS track', 'links': [{'href': 'http://arxiv.org/abs/2002.07917v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.07917v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
323,http://arxiv.org/abs/2002.07111v1,2020-02-17 18:13:09+00:00,2020-02-17 18:13:09+00:00,Targeted Forgetting and False Memory Formation in Continual Learners through Adversarial Backdoor Attacks,"[arxiv.Result.Author('Muhammad Umer'), arxiv.Result.Author('Glenn Dawson'), arxiv.Result.Author('Robi Polikar')]","Artificial neural networks are well-known to be susceptible to catastrophic
forgetting when continually learning from sequences of tasks. Various continual
(or ""incremental"") learning approaches have been proposed to avoid catastrophic
forgetting, but they are typically adversary agnostic, i.e., they do not
consider the possibility of a malicious attack. In this effort, we explore the
vulnerability of Elastic Weight Consolidation (EWC), a popular continual
learning algorithm for avoiding catastrophic forgetting. We show that an
intelligent adversary can bypass the EWC's defenses, and instead cause gradual
and deliberate forgetting by introducing small amounts of misinformation to the
model during training. We demonstrate such an adversary's ability to assume
control of the model via injection of ""backdoor"" attack samples on both
permuted and split benchmark variants of the MNIST dataset. Importantly, once
the model has learned the adversarial misinformation, the adversary can then
control the amount of forgetting of any task. Equivalently, the malicious actor
can create a ""false memory"" about any task by inserting carefully-designed
backdoor samples to any fraction of the test instances of that task. Perhaps
most damaging, we show this vulnerability to be very acute; neural network
memory can be easily compromised with the addition of backdoor samples into as
little as 1% of the training data of even a single task.",,,,cs.LG,"['cs.LG', 'cs.AI', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/2002.07111v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.07111v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.07111v1,"{'id': 'http://arxiv.org/abs/2002.07111v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.07111v1', 'updated': '2020-02-17T18:13:09Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=13, tm_sec=9, tm_wday=0, tm_yday=48, tm_isdst=0), 'published': '2020-02-17T18:13:09Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=13, tm_sec=9, tm_wday=0, tm_yday=48, tm_isdst=0), 'title': 'Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks'}, 'summary': 'Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or ""incremental"") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC\'s defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary\'s ability to assume\ncontrol of the model via injection of ""backdoor"" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a ""false memory"" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or ""incremental"") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC\'s defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary\'s ability to assume\ncontrol of the model via injection of ""backdoor"" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a ""false memory"" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.'}, 'authors': [{'name': 'Muhammad Umer'}, {'name': 'Glenn Dawson'}, {'name': 'Robi Polikar'}], 'author_detail': {'name': 'Robi Polikar'}, 'author': 'Robi Polikar', 'links': [{'href': 'http://arxiv.org/abs/2002.07111v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.07111v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
324,http://arxiv.org/abs/2002.06567v1,2020-02-16 12:37:32+00:00,2020-02-16 12:37:32+00:00,The optimal edge for containing the spreading of SIS model,"[arxiv.Result.Author('Jiajun Xian'), arxiv.Result.Author('Dan Yang'), arxiv.Result.Author('Liming Pan'), arxiv.Result.Author('Wei Wang')]","Numerous real-world systems, for instance, the communication platforms and
transportation systems, can be abstracted into complex networks. Containing
spreading dynamics (e.g., epidemic transmission and misinformation propagation)
in networked systems is a hot topic in multiple fronts. Most of the previous
strategies are based on the immunization of nodes. However, sometimes, these
node--based strategies can be impractical. For instance, in the train
transportation networks, it is dramatic to isolating train stations for flu
prevention. On the contrary, temporarily suspending some connections between
stations is more acceptable. Thus, we pay attention to the edge-based
containing strategy. In this study, we develop a theoretical framework to find
the optimal edge for containing the spreading of the
susceptible-infected-susceptible model on complex networks. In specific, by
performing a perturbation method to the discrete-Markovian-chain equations of
the SIS model, we derive a formula that approximately provides the decremental
outbreak size after the deactivation of a certain edge in the network. Then, we
determine the optimal edge by simply choosing the one with the largest
decremental outbreak size. Note that our proposed theoretical framework
incorporates the information of both network structure and spreading dynamics.
Finally, we test the performance of our method by extensive numerical
simulations. Results demonstrate that our strategy always outperforms other
strategies based only on structural properties (degree or edge betweenness
centrality). The theoretical framework in this study can be extended to other
spreading models and offers inspirations for further investigations on
edge-based immunization strategies.",,,10.1088/1742-5468/ab780d,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1088/1742-5468/ab780d', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2002.06567v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.06567v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.06567v1,"{'id': 'http://arxiv.org/abs/2002.06567v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.06567v1', 'updated': '2020-02-16T12:37:32Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=37, tm_sec=32, tm_wday=6, tm_yday=47, tm_isdst=0), 'published': '2020-02-16T12:37:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=37, tm_sec=32, tm_wday=6, tm_yday=47, tm_isdst=0), 'title': 'The optimal edge for containing the spreading of SIS model', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The optimal edge for containing the spreading of SIS model'}, 'summary': 'Numerous real-world systems, for instance, the communication platforms and\ntransportation systems, can be abstracted into complex networks. Containing\nspreading dynamics (e.g., epidemic transmission and misinformation propagation)\nin networked systems is a hot topic in multiple fronts. Most of the previous\nstrategies are based on the immunization of nodes. However, sometimes, these\nnode--based strategies can be impractical. For instance, in the train\ntransportation networks, it is dramatic to isolating train stations for flu\nprevention. On the contrary, temporarily suspending some connections between\nstations is more acceptable. Thus, we pay attention to the edge-based\ncontaining strategy. In this study, we develop a theoretical framework to find\nthe optimal edge for containing the spreading of the\nsusceptible-infected-susceptible model on complex networks. In specific, by\nperforming a perturbation method to the discrete-Markovian-chain equations of\nthe SIS model, we derive a formula that approximately provides the decremental\noutbreak size after the deactivation of a certain edge in the network. Then, we\ndetermine the optimal edge by simply choosing the one with the largest\ndecremental outbreak size. Note that our proposed theoretical framework\nincorporates the information of both network structure and spreading dynamics.\nFinally, we test the performance of our method by extensive numerical\nsimulations. Results demonstrate that our strategy always outperforms other\nstrategies based only on structural properties (degree or edge betweenness\ncentrality). The theoretical framework in this study can be extended to other\nspreading models and offers inspirations for further investigations on\nedge-based immunization strategies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Numerous real-world systems, for instance, the communication platforms and\ntransportation systems, can be abstracted into complex networks. Containing\nspreading dynamics (e.g., epidemic transmission and misinformation propagation)\nin networked systems is a hot topic in multiple fronts. Most of the previous\nstrategies are based on the immunization of nodes. However, sometimes, these\nnode--based strategies can be impractical. For instance, in the train\ntransportation networks, it is dramatic to isolating train stations for flu\nprevention. On the contrary, temporarily suspending some connections between\nstations is more acceptable. Thus, we pay attention to the edge-based\ncontaining strategy. In this study, we develop a theoretical framework to find\nthe optimal edge for containing the spreading of the\nsusceptible-infected-susceptible model on complex networks. In specific, by\nperforming a perturbation method to the discrete-Markovian-chain equations of\nthe SIS model, we derive a formula that approximately provides the decremental\noutbreak size after the deactivation of a certain edge in the network. Then, we\ndetermine the optimal edge by simply choosing the one with the largest\ndecremental outbreak size. Note that our proposed theoretical framework\nincorporates the information of both network structure and spreading dynamics.\nFinally, we test the performance of our method by extensive numerical\nsimulations. Results demonstrate that our strategy always outperforms other\nstrategies based only on structural properties (degree or edge betweenness\ncentrality). The theoretical framework in this study can be extended to other\nspreading models and offers inspirations for further investigations on\nedge-based immunization strategies.'}, 'authors': [{'name': 'Jiajun Xian'}, {'name': 'Dan Yang'}, {'name': 'Liming Pan'}, {'name': 'Wei Wang'}], 'author_detail': {'name': 'Wei Wang'}, 'author': 'Wei Wang', 'arxiv_doi': '10.1088/1742-5468/ab780d', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1088/1742-5468/ab780d', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2002.06567v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.06567v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
325,http://arxiv.org/abs/2002.04494v2,2020-02-16 14:23:28+00:00,2020-02-11 15:49:32+00:00,The Rumour Mill: Making the Spread of Misinformation Explicit and Tangible,"[arxiv.Result.Author('Nanna Inie'), arxiv.Result.Author('Jeanette Falk Olesen'), arxiv.Result.Author('Leon Derczynski')]","Misinformation spread presents a technological and social threat to society.
With the advance of AI-based language models, automatically generated texts
have become difficult to identify and easy to create at scale. We present ""The
Rumour Mill"", a playful art piece, designed as a commentary on the spread of
rumours and automatically-generated misinformation. The mill is a tabletop
interactive machine, which invites a user to experience the process of creating
believable text by interacting with different tangible controls on the mill.
The user manipulates visible parameters to adjust the genre and type of an
automatically generated text rumour. The Rumour Mill is a physical
demonstration of the state of current technology and its ability to generate
and manipulate natural language text, and of the act of starting and spreading
rumours.",Accepted to CHI 2020 Interactivity,,10.1145/3334480.3383159,cs.CL,"['cs.CL', 'cs.HC']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3334480.3383159', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2002.04494v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.04494v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.04494v2,"{'id': 'http://arxiv.org/abs/2002.04494v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.04494v2', 'updated': '2020-02-16T14:23:28Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=23, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0), 'published': '2020-02-11T15:49:32Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=11, tm_hour=15, tm_min=49, tm_sec=32, tm_wday=1, tm_yday=42, tm_isdst=0), 'title': 'The Rumour Mill: Making the Spread of Misinformation Explicit and\n  Tangible', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Rumour Mill: Making the Spread of Misinformation Explicit and\n  Tangible'}, 'summary': 'Misinformation spread presents a technological and social threat to society.\nWith the advance of AI-based language models, automatically generated texts\nhave become difficult to identify and easy to create at scale. We present ""The\nRumour Mill"", a playful art piece, designed as a commentary on the spread of\nrumours and automatically-generated misinformation. The mill is a tabletop\ninteractive machine, which invites a user to experience the process of creating\nbelievable text by interacting with different tangible controls on the mill.\nThe user manipulates visible parameters to adjust the genre and type of an\nautomatically generated text rumour. The Rumour Mill is a physical\ndemonstration of the state of current technology and its ability to generate\nand manipulate natural language text, and of the act of starting and spreading\nrumours.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation spread presents a technological and social threat to society.\nWith the advance of AI-based language models, automatically generated texts\nhave become difficult to identify and easy to create at scale. We present ""The\nRumour Mill"", a playful art piece, designed as a commentary on the spread of\nrumours and automatically-generated misinformation. The mill is a tabletop\ninteractive machine, which invites a user to experience the process of creating\nbelievable text by interacting with different tangible controls on the mill.\nThe user manipulates visible parameters to adjust the genre and type of an\nautomatically generated text rumour. The Rumour Mill is a physical\ndemonstration of the state of current technology and its ability to generate\nand manipulate natural language text, and of the act of starting and spreading\nrumours.'}, 'authors': [{'name': 'Nanna Inie'}, {'name': 'Jeanette Falk Olesen'}, {'name': 'Leon Derczynski'}], 'author_detail': {'name': 'Leon Derczynski'}, 'author': 'Leon Derczynski', 'arxiv_doi': '10.1145/3334480.3383159', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3334480.3383159', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2002.04494v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.04494v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted to CHI 2020 Interactivity', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
326,http://arxiv.org/abs/2002.03438v1,2020-02-09 19:53:23+00:00,2020-02-09 19:53:23+00:00,Limits of Detecting Text Generated by Large-Scale Language Models,"[arxiv.Result.Author('Lav R. Varshney'), arxiv.Result.Author('Nitish Shirish Keskar'), arxiv.Result.Author('Richard Socher')]","Some consider large-scale language models that can generate long and coherent
pieces of text as dangerous, since they may be used in misinformation
campaigns. Here we formulate large-scale language model output detection as a
hypothesis testing problem to classify text as genuine or generated. We show
that error exponents for particular language models are bounded in terms of
their perplexity, a standard measure of language generation performance. Under
the assumption that human language is stationary and ergodic, the formulation
is extended from considering specific language models to considering maximum
likelihood language models, among the class of k-order Markov approximations;
error probabilities are characterized. Some discussion of incorporating
semantic side information is also given.",ITA 2020,,,cs.CL,"['cs.CL', 'cs.CY', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/2002.03438v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.03438v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.03438v1,"{'id': 'http://arxiv.org/abs/2002.03438v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.03438v1', 'updated': '2020-02-09T19:53:23Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=9, tm_hour=19, tm_min=53, tm_sec=23, tm_wday=6, tm_yday=40, tm_isdst=0), 'published': '2020-02-09T19:53:23Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=9, tm_hour=19, tm_min=53, tm_sec=23, tm_wday=6, tm_yday=40, tm_isdst=0), 'title': 'Limits of Detecting Text Generated by Large-Scale Language Models', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Limits of Detecting Text Generated by Large-Scale Language Models'}, 'summary': 'Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.'}, 'authors': [{'name': 'Lav R. Varshney'}, {'name': 'Nitish Shirish Keskar'}, {'name': 'Richard Socher'}], 'author_detail': {'name': 'Richard Socher'}, 'author': 'Richard Socher', 'arxiv_comment': 'ITA 2020', 'links': [{'href': 'http://arxiv.org/abs/2002.03438v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.03438v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
327,http://arxiv.org/abs/2002.00850v2,2020-02-06 14:30:49+00:00,2020-01-28 19:56:03+00:00,A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion Pattern Alone,"[arxiv.Result.Author('Nir Rosenfeld'), arxiv.Result.Author('Aron Szanto'), arxiv.Result.Author('David C. Parkes')]","Recent work in the domain of misinformation detection has leveraged rich
signals in the text and user identities associated with content on social
media. But text can be strategically manipulated and accounts reopened under
different aliases, suggesting that these approaches are inherently brittle. In
this work, we investigate an alternative modality that is naturally robust: the
pattern in which information propagates. Can the veracity of an unverified
rumor spreading online be discerned solely on the basis of its pattern of
diffusion through the social network?
  Using graph kernels to extract complex topological information from Twitter
cascade structures, we train accurate predictive models that are blind to
language, user identities, and time, demonstrating for the first time that such
""sanitized"" diffusion patterns are highly informative of veracity. Our results
indicate that, with proper aggregation, the collective sharing pattern of the
crowd may reveal powerful signals of rumor truth or falsehood, even in the
early stages of propagation.",Published at The Web Conference (WWW) 2020,,10.1145/3366423.3380180,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3366423.3380180', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2002.00850v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.00850v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.00850v2,"{'id': 'http://arxiv.org/abs/2002.00850v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.00850v2', 'updated': '2020-02-06T14:30:49Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=6, tm_hour=14, tm_min=30, tm_sec=49, tm_wday=3, tm_yday=37, tm_isdst=0), 'published': '2020-01-28T19:56:03Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=28, tm_hour=19, tm_min=56, tm_sec=3, tm_wday=1, tm_yday=28, tm_isdst=0), 'title': 'A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion\n  Pattern Alone', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion\n  Pattern Alone'}, 'summary': 'Recent work in the domain of misinformation detection has leveraged rich\nsignals in the text and user identities associated with content on social\nmedia. But text can be strategically manipulated and accounts reopened under\ndifferent aliases, suggesting that these approaches are inherently brittle. In\nthis work, we investigate an alternative modality that is naturally robust: the\npattern in which information propagates. Can the veracity of an unverified\nrumor spreading online be discerned solely on the basis of its pattern of\ndiffusion through the social network?\n  Using graph kernels to extract complex topological information from Twitter\ncascade structures, we train accurate predictive models that are blind to\nlanguage, user identities, and time, demonstrating for the first time that such\n""sanitized"" diffusion patterns are highly informative of veracity. Our results\nindicate that, with proper aggregation, the collective sharing pattern of the\ncrowd may reveal powerful signals of rumor truth or falsehood, even in the\nearly stages of propagation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent work in the domain of misinformation detection has leveraged rich\nsignals in the text and user identities associated with content on social\nmedia. But text can be strategically manipulated and accounts reopened under\ndifferent aliases, suggesting that these approaches are inherently brittle. In\nthis work, we investigate an alternative modality that is naturally robust: the\npattern in which information propagates. Can the veracity of an unverified\nrumor spreading online be discerned solely on the basis of its pattern of\ndiffusion through the social network?\n  Using graph kernels to extract complex topological information from Twitter\ncascade structures, we train accurate predictive models that are blind to\nlanguage, user identities, and time, demonstrating for the first time that such\n""sanitized"" diffusion patterns are highly informative of veracity. Our results\nindicate that, with proper aggregation, the collective sharing pattern of the\ncrowd may reveal powerful signals of rumor truth or falsehood, even in the\nearly stages of propagation.'}, 'authors': [{'name': 'Nir Rosenfeld'}, {'name': 'Aron Szanto'}, {'name': 'David C. Parkes'}], 'author_detail': {'name': 'David C. Parkes'}, 'author': 'David C. Parkes', 'arxiv_doi': '10.1145/3366423.3380180', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3366423.3380180', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2002.00850v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.00850v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Published at The Web Conference (WWW) 2020', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
328,http://arxiv.org/abs/2001.09545v1,2020-01-27 00:19:41+00:00,2020-01-27 00:19:41+00:00,aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption,[arxiv.Result.Author('Chiranjib Sur')],"Region visual features enhance the generative capability of the machines
based on features, however they lack proper interaction attentional perceptions
and thus ends up with biased or uncorrelated sentences or pieces of
misinformation. In this work, we propose Attribute Interaction-Tensor Product
Representation (aiTPR) which is a convenient way of gathering more information
through orthogonal combination and learning the interactions as physical
entities (tensors) and improving the captions. Compared to previous works,
where features are added up to undefined feature spaces, TPR helps in
maintaining sanity in combinations and orthogonality helps in defining familiar
spaces. We have introduced a new concept layer that defines the objects and
also their interactions that can play a crucial role in determination of
different descriptions. The interaction portions have contributed heavily for
better caption quality and has out-performed different previous works on this
domain and MSCOCO dataset. We introduced, for the first time, the notion of
combining regional image features and abstracted interaction likelihood
embedding for image captioning.",11 pages,,,cs.NE,"['cs.NE', 'cs.CV', 'cs.LG', 'cs.MM']","[arxiv.Result.Link('http://arxiv.org/abs/2001.09545v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.09545v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.09545v1,"{'id': 'http://arxiv.org/abs/2001.09545v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.09545v1', 'updated': '2020-01-27T00:19:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=27, tm_hour=0, tm_min=19, tm_sec=41, tm_wday=0, tm_yday=27, tm_isdst=0), 'published': '2020-01-27T00:19:41Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=27, tm_hour=0, tm_min=19, tm_sec=41, tm_wday=0, tm_yday=27, tm_isdst=0), 'title': 'aiTPR: Attribute Interaction-Tensor Product Representation for Image\n  Caption', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'aiTPR: Attribute Interaction-Tensor Product Representation for Image\n  Caption'}, 'summary': 'Region visual features enhance the generative capability of the machines\nbased on features, however they lack proper interaction attentional perceptions\nand thus ends up with biased or uncorrelated sentences or pieces of\nmisinformation. In this work, we propose Attribute Interaction-Tensor Product\nRepresentation (aiTPR) which is a convenient way of gathering more information\nthrough orthogonal combination and learning the interactions as physical\nentities (tensors) and improving the captions. Compared to previous works,\nwhere features are added up to undefined feature spaces, TPR helps in\nmaintaining sanity in combinations and orthogonality helps in defining familiar\nspaces. We have introduced a new concept layer that defines the objects and\nalso their interactions that can play a crucial role in determination of\ndifferent descriptions. The interaction portions have contributed heavily for\nbetter caption quality and has out-performed different previous works on this\ndomain and MSCOCO dataset. We introduced, for the first time, the notion of\ncombining regional image features and abstracted interaction likelihood\nembedding for image captioning.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Region visual features enhance the generative capability of the machines\nbased on features, however they lack proper interaction attentional perceptions\nand thus ends up with biased or uncorrelated sentences or pieces of\nmisinformation. In this work, we propose Attribute Interaction-Tensor Product\nRepresentation (aiTPR) which is a convenient way of gathering more information\nthrough orthogonal combination and learning the interactions as physical\nentities (tensors) and improving the captions. Compared to previous works,\nwhere features are added up to undefined feature spaces, TPR helps in\nmaintaining sanity in combinations and orthogonality helps in defining familiar\nspaces. We have introduced a new concept layer that defines the objects and\nalso their interactions that can play a crucial role in determination of\ndifferent descriptions. The interaction portions have contributed heavily for\nbetter caption quality and has out-performed different previous works on this\ndomain and MSCOCO dataset. We introduced, for the first time, the notion of\ncombining regional image features and abstracted interaction likelihood\nembedding for image captioning.'}, 'authors': [{'name': 'Chiranjib Sur'}], 'author_detail': {'name': 'Chiranjib Sur'}, 'author': 'Chiranjib Sur', 'arxiv_comment': '11 pages', 'links': [{'href': 'http://arxiv.org/abs/2001.09545v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.09545v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
329,http://arxiv.org/abs/2001.09473v1,2020-01-26 15:42:43+00:00,2020-01-26 15:42:43+00:00,"Information Credibility in the Social Web: Contexts, Approaches, and Open Issues","[arxiv.Result.Author('Gabriella Pasi'), arxiv.Result.Author('Marco Viviani')]","In the Social Web scenario, large amounts of User-Generated Content (UGC) are
diffused through social media often without almost any form of traditional
trusted intermediaries. Therefore, the risk of running into misinformation is
not negligible. For this reason, assessing and mining the credibility of online
information constitutes nowadays a fundamental research issue. Credibility,
also referred as believability, is a quality perceived by individuals, who are
not always able to discern, with their own cognitive capacities, genuine
information from fake one. Hence, in the last years, several approaches have
been proposed to automatically assess credibility in social media. Many of them
are based on data-driven models, i.e., they employ machine learning techniques
to identify misinformation, but recently also model-driven approaches are
emerging, as well as graph-based approaches focusing on credibility
propagation, and knowledge-based ones exploiting Semantic Web technologies.
Three of the main contexts in which the assessment of information credibility
has been investigated concern: (i) the detection of opinion spam in review
sites, (ii) the detection of fake news in microblogging, and (iii) the
credibility assessment of online health-related information. In this article,
the main issues connected to the evaluation of information credibility in the
Social Web, which are shared by the above-mentioned contexts, are discussed. A
concise survey of the approaches and methodologies that have been proposed in
recent years to address these issues is also presented.","Article accepted and presented at ITASEC 2020: Italian Conference on
  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/2001.09473v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.09473v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.09473v1,"{'id': 'http://arxiv.org/abs/2001.09473v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.09473v1', 'updated': '2020-01-26T15:42:43Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=26, tm_hour=15, tm_min=42, tm_sec=43, tm_wday=6, tm_yday=26, tm_isdst=0), 'published': '2020-01-26T15:42:43Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=26, tm_hour=15, tm_min=42, tm_sec=43, tm_wday=6, tm_yday=26, tm_isdst=0), 'title': 'Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues'}, 'summary': 'In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.'}, 'authors': [{'name': 'Gabriella Pasi'}, {'name': 'Marco Viviani'}], 'author_detail': {'name': 'Marco Viviani'}, 'author': 'Marco Viviani', 'arxiv_comment': 'Article accepted and presented at ITASEC 2020: Italian Conference on\n  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/', 'links': [{'href': 'http://arxiv.org/abs/2001.09473v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.09473v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
330,http://arxiv.org/abs/2001.04624v1,2020-01-14 04:50:47+00:00,2020-01-14 04:50:47+00:00,A Feature-Driven Approach for Identifying Pathogenic Social Media Accounts,"[arxiv.Result.Author('Hamidreza Alvari'), arxiv.Result.Author('Ghazaleh Beigi'), arxiv.Result.Author('Soumajyoti Sarkar'), arxiv.Result.Author('Scott W. Ruston'), arxiv.Result.Author('Steven R. Corman'), arxiv.Result.Author('Hasan Davulcu'), arxiv.Result.Author('Paulo Shakarian')]","Over the past few years, we have observed different media outlets' attempts
to shift public opinion by framing information to support a narrative that
facilitate their goals. Malicious users referred to as ""pathogenic social
media"" (PSM) accounts are more likely to amplify this phenomena by spreading
misinformation to viral proportions. Understanding the spread of misinformation
from account-level perspective is thus a pressing problem. In this work, we aim
to present a feature-driven approach to detect PSM accounts in social media.
Inspired by the literature, we set out to assess PSMs from three broad
perspectives: (1) user-related information (e.g., user activity, profile
characteristics), (2) source-related information (i.e., information linked via
URLs shared by users) and (3) content-related information (e.g., tweets
characteristics). For the user-related information, we investigate malicious
signals using causality analysis (i.e., if user is frequently a cause of viral
cascades) and profile characteristics (e.g., number of followers, etc.). For
the source-related information, we explore various malicious properties linked
to URLs (e.g., URL address, content of the associated website, etc.). Finally,
for the content-related information, we examine attributes (e.g., number of
hashtags, suspicious hashtags, etc.) from tweets posted by users. Experiments
on real-world Twitter data from different countries demonstrate the
effectiveness of the proposed approach in identifying PSM users.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/2001.04624v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.04624v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.04624v1,"{'id': 'http://arxiv.org/abs/2001.04624v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.04624v1', 'updated': '2020-01-14T04:50:47Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=14, tm_hour=4, tm_min=50, tm_sec=47, tm_wday=1, tm_yday=14, tm_isdst=0), 'published': '2020-01-14T04:50:47Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=14, tm_hour=4, tm_min=50, tm_sec=47, tm_wday=1, tm_yday=14, tm_isdst=0), 'title': 'A Feature-Driven Approach for Identifying Pathogenic Social Media\n  Accounts', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Feature-Driven Approach for Identifying Pathogenic Social Media\n  Accounts'}, 'summary': 'Over the past few years, we have observed different media outlets\' attempts\nto shift public opinion by framing information to support a narrative that\nfacilitate their goals. Malicious users referred to as ""pathogenic social\nmedia"" (PSM) accounts are more likely to amplify this phenomena by spreading\nmisinformation to viral proportions. Understanding the spread of misinformation\nfrom account-level perspective is thus a pressing problem. In this work, we aim\nto present a feature-driven approach to detect PSM accounts in social media.\nInspired by the literature, we set out to assess PSMs from three broad\nperspectives: (1) user-related information (e.g., user activity, profile\ncharacteristics), (2) source-related information (i.e., information linked via\nURLs shared by users) and (3) content-related information (e.g., tweets\ncharacteristics). For the user-related information, we investigate malicious\nsignals using causality analysis (i.e., if user is frequently a cause of viral\ncascades) and profile characteristics (e.g., number of followers, etc.). For\nthe source-related information, we explore various malicious properties linked\nto URLs (e.g., URL address, content of the associated website, etc.). Finally,\nfor the content-related information, we examine attributes (e.g., number of\nhashtags, suspicious hashtags, etc.) from tweets posted by users. Experiments\non real-world Twitter data from different countries demonstrate the\neffectiveness of the proposed approach in identifying PSM users.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Over the past few years, we have observed different media outlets\' attempts\nto shift public opinion by framing information to support a narrative that\nfacilitate their goals. Malicious users referred to as ""pathogenic social\nmedia"" (PSM) accounts are more likely to amplify this phenomena by spreading\nmisinformation to viral proportions. Understanding the spread of misinformation\nfrom account-level perspective is thus a pressing problem. In this work, we aim\nto present a feature-driven approach to detect PSM accounts in social media.\nInspired by the literature, we set out to assess PSMs from three broad\nperspectives: (1) user-related information (e.g., user activity, profile\ncharacteristics), (2) source-related information (i.e., information linked via\nURLs shared by users) and (3) content-related information (e.g., tweets\ncharacteristics). For the user-related information, we investigate malicious\nsignals using causality analysis (i.e., if user is frequently a cause of viral\ncascades) and profile characteristics (e.g., number of followers, etc.). For\nthe source-related information, we explore various malicious properties linked\nto URLs (e.g., URL address, content of the associated website, etc.). Finally,\nfor the content-related information, we examine attributes (e.g., number of\nhashtags, suspicious hashtags, etc.) from tweets posted by users. Experiments\non real-world Twitter data from different countries demonstrate the\neffectiveness of the proposed approach in identifying PSM users.'}, 'authors': [{'name': 'Hamidreza Alvari'}, {'name': 'Ghazaleh Beigi'}, {'name': 'Soumajyoti Sarkar'}, {'name': 'Scott W. Ruston'}, {'name': 'Steven R. Corman'}, {'name': 'Hasan Davulcu'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'links': [{'href': 'http://arxiv.org/abs/2001.04624v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.04624v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
331,http://arxiv.org/abs/2001.03231v2,2020-01-31 01:50:53+00:00,2020-01-09 21:45:25+00:00,Four Years in Review: Statistical Practices of Likert Scales in Human-Robot Interaction Studies,"[arxiv.Result.Author('Mariah L. Schrum'), arxiv.Result.Author('Michael Johnson'), arxiv.Result.Author('Muyleng Ghuy'), arxiv.Result.Author('Matthew C. Gombolay')]","As robots become more prevalent, the importance of the field of human-robot
interaction (HRI) grows accordingly. As such, we should endeavor to employ the
best statistical practices. Likert scales are commonly used metrics in HRI to
measure perceptions and attitudes. Due to misinformation or honest mistakes,
most HRI researchers do not adopt best practices when analyzing Likert data. We
conduct a review of psychometric literature to determine the current standard
for Likert scale design and analysis. Next, we conduct a survey of four years
of the International Conference on Human-Robot Interaction (2016 through 2019)
and report on incorrect statistical practices and design of Likert scales.
During these years, only 3 of the 110 papers applied proper statistical testing
to correctly-designed Likert scales. Our analysis suggests there are areas for
meaningful improvement in the design and testing of Likert scales. Lastly, we
provide recommendations to improve the accuracy of conclusions drawn from
Likert data.",,,10.1145/3319502.3378178,cs.HC,"['cs.HC', 'cs.RO', 'stat.AP', 'stat.ME']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3319502.3378178', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/2001.03231v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2001.03231v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2001.03231v2,"{'id': 'http://arxiv.org/abs/2001.03231v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/2001.03231v2', 'updated': '2020-01-31T01:50:53Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=31, tm_hour=1, tm_min=50, tm_sec=53, tm_wday=4, tm_yday=31, tm_isdst=0), 'published': '2020-01-09T21:45:25Z', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=9, tm_hour=21, tm_min=45, tm_sec=25, tm_wday=3, tm_yday=9, tm_isdst=0), 'title': 'Four Years in Review: Statistical Practices of Likert Scales in\n  Human-Robot Interaction Studies', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Four Years in Review: Statistical Practices of Likert Scales in\n  Human-Robot Interaction Studies'}, 'summary': 'As robots become more prevalent, the importance of the field of human-robot\ninteraction (HRI) grows accordingly. As such, we should endeavor to employ the\nbest statistical practices. Likert scales are commonly used metrics in HRI to\nmeasure perceptions and attitudes. Due to misinformation or honest mistakes,\nmost HRI researchers do not adopt best practices when analyzing Likert data. We\nconduct a review of psychometric literature to determine the current standard\nfor Likert scale design and analysis. Next, we conduct a survey of four years\nof the International Conference on Human-Robot Interaction (2016 through 2019)\nand report on incorrect statistical practices and design of Likert scales.\nDuring these years, only 3 of the 110 papers applied proper statistical testing\nto correctly-designed Likert scales. Our analysis suggests there are areas for\nmeaningful improvement in the design and testing of Likert scales. Lastly, we\nprovide recommendations to improve the accuracy of conclusions drawn from\nLikert data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As robots become more prevalent, the importance of the field of human-robot\ninteraction (HRI) grows accordingly. As such, we should endeavor to employ the\nbest statistical practices. Likert scales are commonly used metrics in HRI to\nmeasure perceptions and attitudes. Due to misinformation or honest mistakes,\nmost HRI researchers do not adopt best practices when analyzing Likert data. We\nconduct a review of psychometric literature to determine the current standard\nfor Likert scale design and analysis. Next, we conduct a survey of four years\nof the International Conference on Human-Robot Interaction (2016 through 2019)\nand report on incorrect statistical practices and design of Likert scales.\nDuring these years, only 3 of the 110 papers applied proper statistical testing\nto correctly-designed Likert scales. Our analysis suggests there are areas for\nmeaningful improvement in the design and testing of Likert scales. Lastly, we\nprovide recommendations to improve the accuracy of conclusions drawn from\nLikert data.'}, 'authors': [{'name': 'Mariah L. Schrum'}, {'name': 'Michael Johnson'}, {'name': 'Muyleng Ghuy'}, {'name': 'Matthew C. Gombolay'}], 'author_detail': {'name': 'Matthew C. Gombolay'}, 'author': 'Matthew C. Gombolay', 'arxiv_doi': '10.1145/3319502.3378178', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3319502.3378178', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2001.03231v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2001.03231v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
332,http://arxiv.org/abs/2002.00846v5,2021-04-04 22:02:29+00:00,2019-12-31 11:03:18+00:00,Evidence of disorientation towards immunization on online social media after contrasting political communication on vaccines. Results from an analysis of Twitter data in Italy,"[arxiv.Result.Author('Samantha Ajovalasit'), arxiv.Result.Author('Veronica Dorgali'), arxiv.Result.Author('Angelo Mazza'), arxiv.Result.Author(""Alberto D'Onofrio""), arxiv.Result.Author('Piero Manfredi')]","Background. In Italy, in recent years, vaccination coverage for key
immunizations as MMR has been declining to worryingly low levels. In 2017, the
Italian Gov't expanded the number of mandatory immunizations introducing
penalties to unvaccinated children's families. During the 2018 general
elections campaign, immunization policy entered the political debate with the
Gov't in charge blaming oppositions for fuelling vaccine scepticism. A new
Gov't established in 2018 temporarily relaxed penalties. Objectives and
Methods. Using a sentiment analysis on tweets posted in Italian during 2018, we
aimed to: (i) characterize the temporal flow of vaccines communication on
Twitter (ii) evaluate the polarity of vaccination opinions and usefulness of
Twitter data to estimate vaccination parameters, and (iii) investigate whether
the contrasting announcements at the highest political level might have
originated disorientation amongst the Italian public. Results. Vaccine-relevant
tweeters interactions peaked in response to main political events. Out of
retained tweets, 70.0% resulted favourable to vaccination, 16.5% unfavourable,
and 13.6% undecided, respectively. The smoothed time series of polarity
proportions exhibit frequent large changes in the favourable proportion,
enhanced by an up and down trend synchronized with the switch between gov't
suggesting evidence of disorientation among the public. Conclusion. The
reported evidence of disorientation documents that critical immunization
topics, should never be used for political consensus. This is especially true
given the increasing role of online social media as information source, which
might yield to social pressures eventually harmful for vaccine uptake, and is
worsened by the lack of institutional presence on Twitter, calling for efforts
to contrast misinformation and the ensuing spread of hesitancy.","17 pages, 5 figures",,,cs.SI,"['cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/2002.00846v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2002.00846v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/2002.00846v5,"{'id': 'http://arxiv.org/abs/2002.00846v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/2002.00846v5', 'updated': '2021-04-04T22:02:29Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=4, tm_hour=22, tm_min=2, tm_sec=29, tm_wday=6, tm_yday=94, tm_isdst=0), 'published': '2019-12-31T11:03:18Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=31, tm_hour=11, tm_min=3, tm_sec=18, tm_wday=1, tm_yday=365, tm_isdst=0), 'title': 'Evidence of disorientation towards immunization on online social media\n  after contrasting political communication on vaccines. Results from an\n  analysis of Twitter data in Italy', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evidence of disorientation towards immunization on online social media\n  after contrasting political communication on vaccines. Results from an\n  analysis of Twitter data in Italy'}, 'summary': ""Background. In Italy, in recent years, vaccination coverage for key\nimmunizations as MMR has been declining to worryingly low levels. In 2017, the\nItalian Gov't expanded the number of mandatory immunizations introducing\npenalties to unvaccinated children's families. During the 2018 general\nelections campaign, immunization policy entered the political debate with the\nGov't in charge blaming oppositions for fuelling vaccine scepticism. A new\nGov't established in 2018 temporarily relaxed penalties. Objectives and\nMethods. Using a sentiment analysis on tweets posted in Italian during 2018, we\naimed to: (i) characterize the temporal flow of vaccines communication on\nTwitter (ii) evaluate the polarity of vaccination opinions and usefulness of\nTwitter data to estimate vaccination parameters, and (iii) investigate whether\nthe contrasting announcements at the highest political level might have\noriginated disorientation amongst the Italian public. Results. Vaccine-relevant\ntweeters interactions peaked in response to main political events. Out of\nretained tweets, 70.0% resulted favourable to vaccination, 16.5% unfavourable,\nand 13.6% undecided, respectively. The smoothed time series of polarity\nproportions exhibit frequent large changes in the favourable proportion,\nenhanced by an up and down trend synchronized with the switch between gov't\nsuggesting evidence of disorientation among the public. Conclusion. The\nreported evidence of disorientation documents that critical immunization\ntopics, should never be used for political consensus. This is especially true\ngiven the increasing role of online social media as information source, which\nmight yield to social pressures eventually harmful for vaccine uptake, and is\nworsened by the lack of institutional presence on Twitter, calling for efforts\nto contrast misinformation and the ensuing spread of hesitancy."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Background. In Italy, in recent years, vaccination coverage for key\nimmunizations as MMR has been declining to worryingly low levels. In 2017, the\nItalian Gov't expanded the number of mandatory immunizations introducing\npenalties to unvaccinated children's families. During the 2018 general\nelections campaign, immunization policy entered the political debate with the\nGov't in charge blaming oppositions for fuelling vaccine scepticism. A new\nGov't established in 2018 temporarily relaxed penalties. Objectives and\nMethods. Using a sentiment analysis on tweets posted in Italian during 2018, we\naimed to: (i) characterize the temporal flow of vaccines communication on\nTwitter (ii) evaluate the polarity of vaccination opinions and usefulness of\nTwitter data to estimate vaccination parameters, and (iii) investigate whether\nthe contrasting announcements at the highest political level might have\noriginated disorientation amongst the Italian public. Results. Vaccine-relevant\ntweeters interactions peaked in response to main political events. Out of\nretained tweets, 70.0% resulted favourable to vaccination, 16.5% unfavourable,\nand 13.6% undecided, respectively. The smoothed time series of polarity\nproportions exhibit frequent large changes in the favourable proportion,\nenhanced by an up and down trend synchronized with the switch between gov't\nsuggesting evidence of disorientation among the public. Conclusion. The\nreported evidence of disorientation documents that critical immunization\ntopics, should never be used for political consensus. This is especially true\ngiven the increasing role of online social media as information source, which\nmight yield to social pressures eventually harmful for vaccine uptake, and is\nworsened by the lack of institutional presence on Twitter, calling for efforts\nto contrast misinformation and the ensuing spread of hesitancy.""}, 'authors': [{'name': 'Samantha Ajovalasit'}, {'name': 'Veronica Dorgali'}, {'name': 'Angelo Mazza'}, {'name': ""Alberto D'Onofrio""}, {'name': 'Piero Manfredi'}], 'author_detail': {'name': 'Piero Manfredi'}, 'arxiv_affiliation': 'University of Pisa', 'author': 'Piero Manfredi', 'arxiv_comment': '17 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/2002.00846v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2002.00846v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
333,http://arxiv.org/abs/1912.12999v3,2020-05-26 16:01:39+00:00,2019-12-30 16:44:41+00:00,AutoDiscern: Rating the Quality of Online Health Information with Hierarchical Encoder Attention-based Neural Networks,"[arxiv.Result.Author('Laura Kinkead'), arxiv.Result.Author('Ahmed Allam'), arxiv.Result.Author('Michael Krauthammer')]","Patients increasingly turn to search engines and online content before, or in
place of, talking with a health professional. Low quality health information,
which is common on the internet, presents risks to the patient in the form of
misinformation and a possibly poorer relationship with their physician. To
address this, the DISCERN criteria (developed at University of Oxford) are used
to evaluate the quality of online health information. However, patients are
unlikely to take the time to apply these criteria to the health websites they
visit. We built an automated implementation of the DISCERN instrument (Brief
version) using machine learning models. We compared the performance of a
traditional model (Random Forest) with that of a hierarchical encoder
attention-based neural network (HEA) model using two language embeddings, BERT
and BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores
across all criteria of 0.75 and 0.74, respectively, outperforming the Random
Forest model (average F1-macro = 0.69). Overall, the neural network based
models achieved 81% and 86% average accuracy at 100% and 80% coverage,
respectively, compared to 94% manual rating accuracy. The attention mechanism
implemented in the HEA architectures not only provided 'model explainability'
by identifying reasonable supporting sentences for the documents fulfilling the
Brief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the
same architecture without an attention mechanism. Our research suggests that it
is feasible to automate online health information quality assessment, which is
an important step towards empowering patients to become informed partners in
the healthcare process.",,,,cs.LG,"['cs.LG', 'cs.CL', 'cs.CY', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1912.12999v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.12999v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.12999v3,"{'id': 'http://arxiv.org/abs/1912.12999v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.12999v3', 'updated': '2020-05-26T16:01:39Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=26, tm_hour=16, tm_min=1, tm_sec=39, tm_wday=1, tm_yday=147, tm_isdst=0), 'published': '2019-12-30T16:44:41Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=30, tm_hour=16, tm_min=44, tm_sec=41, tm_wday=0, tm_yday=364, tm_isdst=0), 'title': 'AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks'}, 'summary': ""Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process.""}, 'authors': [{'name': 'Laura Kinkead'}, {'name': 'Ahmed Allam'}, {'name': 'Michael Krauthammer'}], 'author_detail': {'name': 'Michael Krauthammer'}, 'author': 'Michael Krauthammer', 'links': [{'href': 'http://arxiv.org/abs/1912.12999v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.12999v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
334,http://arxiv.org/abs/1912.08909v1,2019-12-18 21:56:24+00:00,2019-12-18 21:56:24+00:00,"Subgraph Classification, Clustering and Centrality for a Degree Asymmetric Twitter Based Graph Case Study: Suicidality","[arxiv.Result.Author('Keith Andrew'), arxiv.Result.Author('Eric Steinfelds'), arxiv.Result.Author('Karla M. Andrew'), arxiv.Result.Author('Kay Opalenik')]","We present some initial results from a case study in social media data
harvesting and visualization utilizing the tools and analytical features of
NodeXL applied to a degree asymmetric vertex graph set. We consider twitter
graphs harvested for topics related to suicidal ideation, suicide attempts,
self-harm and bullycide. While the twitter-sphere only captures a small and age
biased sample of communications it is a readily available public database for a
wealth of rich topics yielding a large sample set. All these topics gave rise
to highly asymmetric vertex degree graphs and all shared the same general
topological features. We find a strong preference for in degree vertex
information transfer with a 4:25 out degree to in degree vertex ratio with a
power law distribution. Overall there is a low global clustering coefficient
average of 0.038 and a graph clustering density of 0.00034 for
Clauset-Newman-Moore grouping with a maximum geodesic distance of 6.
Eigenvector centrality does not give any large central impact vertices and
betweenness centrality shows many bridging vertices indicating a sparse
community structure. Parts of speech sentiment scores show a strong asymmetry
of predominant negative scores for almost all word and word pairs with salience
greater than one. We used an Hoaxy analysis to check for deliberate
misinformation on these topics by a Twitter-Bot.","14 pages, 7 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1912.08909v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.08909v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.08909v1,"{'id': 'http://arxiv.org/abs/1912.08909v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.08909v1', 'updated': '2019-12-18T21:56:24Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=18, tm_hour=21, tm_min=56, tm_sec=24, tm_wday=2, tm_yday=352, tm_isdst=0), 'published': '2019-12-18T21:56:24Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=18, tm_hour=21, tm_min=56, tm_sec=24, tm_wday=2, tm_yday=352, tm_isdst=0), 'title': 'Subgraph Classification, Clustering and Centrality for a Degree\n  Asymmetric Twitter Based Graph Case Study: Suicidality', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Subgraph Classification, Clustering and Centrality for a Degree\n  Asymmetric Twitter Based Graph Case Study: Suicidality'}, 'summary': 'We present some initial results from a case study in social media data\nharvesting and visualization utilizing the tools and analytical features of\nNodeXL applied to a degree asymmetric vertex graph set. We consider twitter\ngraphs harvested for topics related to suicidal ideation, suicide attempts,\nself-harm and bullycide. While the twitter-sphere only captures a small and age\nbiased sample of communications it is a readily available public database for a\nwealth of rich topics yielding a large sample set. All these topics gave rise\nto highly asymmetric vertex degree graphs and all shared the same general\ntopological features. We find a strong preference for in degree vertex\ninformation transfer with a 4:25 out degree to in degree vertex ratio with a\npower law distribution. Overall there is a low global clustering coefficient\naverage of 0.038 and a graph clustering density of 0.00034 for\nClauset-Newman-Moore grouping with a maximum geodesic distance of 6.\nEigenvector centrality does not give any large central impact vertices and\nbetweenness centrality shows many bridging vertices indicating a sparse\ncommunity structure. Parts of speech sentiment scores show a strong asymmetry\nof predominant negative scores for almost all word and word pairs with salience\ngreater than one. We used an Hoaxy analysis to check for deliberate\nmisinformation on these topics by a Twitter-Bot.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We present some initial results from a case study in social media data\nharvesting and visualization utilizing the tools and analytical features of\nNodeXL applied to a degree asymmetric vertex graph set. We consider twitter\ngraphs harvested for topics related to suicidal ideation, suicide attempts,\nself-harm and bullycide. While the twitter-sphere only captures a small and age\nbiased sample of communications it is a readily available public database for a\nwealth of rich topics yielding a large sample set. All these topics gave rise\nto highly asymmetric vertex degree graphs and all shared the same general\ntopological features. We find a strong preference for in degree vertex\ninformation transfer with a 4:25 out degree to in degree vertex ratio with a\npower law distribution. Overall there is a low global clustering coefficient\naverage of 0.038 and a graph clustering density of 0.00034 for\nClauset-Newman-Moore grouping with a maximum geodesic distance of 6.\nEigenvector centrality does not give any large central impact vertices and\nbetweenness centrality shows many bridging vertices indicating a sparse\ncommunity structure. Parts of speech sentiment scores show a strong asymmetry\nof predominant negative scores for almost all word and word pairs with salience\ngreater than one. We used an Hoaxy analysis to check for deliberate\nmisinformation on these topics by a Twitter-Bot.'}, 'authors': [{'name': 'Keith Andrew'}, {'name': 'Eric Steinfelds'}, {'name': 'Karla M. Andrew'}, {'name': 'Kay Opalenik'}], 'author_detail': {'name': 'Kay Opalenik'}, 'author': 'Kay Opalenik', 'arxiv_comment': '14 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/1912.08909v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.08909v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
335,http://arxiv.org/abs/1912.06745v1,2019-12-13 23:32:38+00:00,2019-12-13 23:32:38+00:00,An Unsupervised Domain-Independent Framework for Automated Detection of Persuasion Tactics in Text,"[arxiv.Result.Author('Rahul Radhakrishnan Iyer'), arxiv.Result.Author('Katia Sycara')]","With the increasing growth of social media, people have started relying
heavily on the information shared therein to form opinions and make decisions.
While such a reliance is motivation for a variety of parties to promote
information, it also makes people vulnerable to exploitation by slander,
misinformation, terroristic and predatorial advances. In this work, we aim to
understand and detect such attempts at persuasion. Existing works on detecting
persuasion in text make use of lexical features for detecting persuasive
tactics, without taking advantage of the possible structures inherent in the
tactics used. We formulate the task as a multi-class classification problem and
propose an unsupervised, domain-independent machine learning framework for
detecting the type of persuasion used in text, which exploits the inherent
sentence structure present in the different persuasion tactics. Our work shows
promising results as compared to existing work.","19 pages, 8 Figures",,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1912.06745v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.06745v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.06745v1,"{'id': 'http://arxiv.org/abs/1912.06745v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.06745v1', 'updated': '2019-12-13T23:32:38Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=13, tm_hour=23, tm_min=32, tm_sec=38, tm_wday=4, tm_yday=347, tm_isdst=0), 'published': '2019-12-13T23:32:38Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=13, tm_hour=23, tm_min=32, tm_sec=38, tm_wday=4, tm_yday=347, tm_isdst=0), 'title': 'An Unsupervised Domain-Independent Framework for Automated Detection of\n  Persuasion Tactics in Text', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Unsupervised Domain-Independent Framework for Automated Detection of\n  Persuasion Tactics in Text'}, 'summary': 'With the increasing growth of social media, people have started relying\nheavily on the information shared therein to form opinions and make decisions.\nWhile such a reliance is motivation for a variety of parties to promote\ninformation, it also makes people vulnerable to exploitation by slander,\nmisinformation, terroristic and predatorial advances. In this work, we aim to\nunderstand and detect such attempts at persuasion. Existing works on detecting\npersuasion in text make use of lexical features for detecting persuasive\ntactics, without taking advantage of the possible structures inherent in the\ntactics used. We formulate the task as a multi-class classification problem and\npropose an unsupervised, domain-independent machine learning framework for\ndetecting the type of persuasion used in text, which exploits the inherent\nsentence structure present in the different persuasion tactics. Our work shows\npromising results as compared to existing work.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the increasing growth of social media, people have started relying\nheavily on the information shared therein to form opinions and make decisions.\nWhile such a reliance is motivation for a variety of parties to promote\ninformation, it also makes people vulnerable to exploitation by slander,\nmisinformation, terroristic and predatorial advances. In this work, we aim to\nunderstand and detect such attempts at persuasion. Existing works on detecting\npersuasion in text make use of lexical features for detecting persuasive\ntactics, without taking advantage of the possible structures inherent in the\ntactics used. We formulate the task as a multi-class classification problem and\npropose an unsupervised, domain-independent machine learning framework for\ndetecting the type of persuasion used in text, which exploits the inherent\nsentence structure present in the different persuasion tactics. Our work shows\npromising results as compared to existing work.'}, 'authors': [{'name': 'Rahul Radhakrishnan Iyer'}, {'name': 'Katia Sycara'}], 'author_detail': {'name': 'Katia Sycara'}, 'author': 'Katia Sycara', 'arxiv_comment': '19 pages, 8 Figures', 'links': [{'href': 'http://arxiv.org/abs/1912.06745v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.06745v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
336,http://arxiv.org/abs/1912.05603v1,2019-12-11 20:22:20+00:00,2019-12-11 20:22:20+00:00,A Novel Approach in Strategic Planning of Power Networks Against Physical Attacks,"[arxiv.Result.Author('Hamzeh Davarikia'), arxiv.Result.Author('Masoud Barati'), arxiv.Result.Author('Mustafa Al-Assad'), arxiv.Result.Author('Yupo Chan')]","The reported work points at developing a practical approach for power
transmission planners to secure power networks from potential deliberate
attacks. We study the interaction between a system planner (defender) and a
rational attacker who threatens the operation of the power grid. In addition to
the commonly used hardening strategy for protecting the network, a new sort of
resource is introduced under the deception concept. Feint and deception are
acknowledged as effective tools for misleading the attacker in strategic
planning. To this end, the defender deception is mathematically formulated by
releasing misinformation about his plan in the shared cognition-based model. To
reduce the risk of damage in case of deception failure, preemptive-goal
programming is utilized to prioritize the hardening strategy for the vital
components. Furthermore, the value of posturing is introduced which is the
benefits that the deception brings to the system. The problems are formulated
as tri-level mixed-integer linear programming and solved by the
constraint-and-column generation method. Comprehensive simulation studies
performed on WSCC 9-bus and IEEE 118-bus systems indicate how the defender will
save significant cost from protecting his network with posturing rather than
hardening and the proposed approach is a promising development to ensure the
secure operation of power networks.","Accepted to be published in Journal of Electric Power Systems
  Research, 2018",,,eess.SY,"['eess.SY', 'cs.SY', 'math.OC']","[arxiv.Result.Link('http://arxiv.org/abs/1912.05603v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.05603v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.05603v1,"{'id': 'http://arxiv.org/abs/1912.05603v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.05603v1', 'updated': '2019-12-11T20:22:20Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=11, tm_hour=20, tm_min=22, tm_sec=20, tm_wday=2, tm_yday=345, tm_isdst=0), 'published': '2019-12-11T20:22:20Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=11, tm_hour=20, tm_min=22, tm_sec=20, tm_wday=2, tm_yday=345, tm_isdst=0), 'title': 'A Novel Approach in Strategic Planning of Power Networks Against\n  Physical Attacks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Novel Approach in Strategic Planning of Power Networks Against\n  Physical Attacks'}, 'summary': 'The reported work points at developing a practical approach for power\ntransmission planners to secure power networks from potential deliberate\nattacks. We study the interaction between a system planner (defender) and a\nrational attacker who threatens the operation of the power grid. In addition to\nthe commonly used hardening strategy for protecting the network, a new sort of\nresource is introduced under the deception concept. Feint and deception are\nacknowledged as effective tools for misleading the attacker in strategic\nplanning. To this end, the defender deception is mathematically formulated by\nreleasing misinformation about his plan in the shared cognition-based model. To\nreduce the risk of damage in case of deception failure, preemptive-goal\nprogramming is utilized to prioritize the hardening strategy for the vital\ncomponents. Furthermore, the value of posturing is introduced which is the\nbenefits that the deception brings to the system. The problems are formulated\nas tri-level mixed-integer linear programming and solved by the\nconstraint-and-column generation method. Comprehensive simulation studies\nperformed on WSCC 9-bus and IEEE 118-bus systems indicate how the defender will\nsave significant cost from protecting his network with posturing rather than\nhardening and the proposed approach is a promising development to ensure the\nsecure operation of power networks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The reported work points at developing a practical approach for power\ntransmission planners to secure power networks from potential deliberate\nattacks. We study the interaction between a system planner (defender) and a\nrational attacker who threatens the operation of the power grid. In addition to\nthe commonly used hardening strategy for protecting the network, a new sort of\nresource is introduced under the deception concept. Feint and deception are\nacknowledged as effective tools for misleading the attacker in strategic\nplanning. To this end, the defender deception is mathematically formulated by\nreleasing misinformation about his plan in the shared cognition-based model. To\nreduce the risk of damage in case of deception failure, preemptive-goal\nprogramming is utilized to prioritize the hardening strategy for the vital\ncomponents. Furthermore, the value of posturing is introduced which is the\nbenefits that the deception brings to the system. The problems are formulated\nas tri-level mixed-integer linear programming and solved by the\nconstraint-and-column generation method. Comprehensive simulation studies\nperformed on WSCC 9-bus and IEEE 118-bus systems indicate how the defender will\nsave significant cost from protecting his network with posturing rather than\nhardening and the proposed approach is a promising development to ensure the\nsecure operation of power networks.'}, 'authors': [{'name': 'Hamzeh Davarikia'}, {'name': 'Masoud Barati'}, {'name': 'Mustafa Al-Assad'}, {'name': 'Yupo Chan'}], 'author_detail': {'name': 'Yupo Chan'}, 'author': 'Yupo Chan', 'arxiv_comment': 'Accepted to be published in Journal of Electric Power Systems\n  Research, 2018', 'links': [{'href': 'http://arxiv.org/abs/1912.05603v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.05603v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
337,http://arxiv.org/abs/1912.05238v1,2019-12-11 11:27:06+00:00,2019-12-11 11:27:06+00:00,BERT has a Moral Compass: Improvements of ethical and moral values of machines,"[arxiv.Result.Author('Patrick Schramowski'), arxiv.Result.Author('Cigdem Turan'), arxiv.Result.Author('Sophie Jentzsch'), arxiv.Result.Author('Constantin Rothkopf'), arxiv.Result.Author('Kristian Kersting')]","Allowing machines to choose whether to kill humans would be devastating for
world peace and security. But how do we equip machines with the ability to
learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying
machine learning to human texts can extract deontological ethical reasoning
about ""right"" and ""wrong"" conduct by calculating a moral bias score on a
sentence level using sentence embeddings. The machine learned that it is
objectionable to kill living beings, but it is fine to kill time; It is
essential to eat, yet one might not eat dirt; it is important to spread
information, yet one should not spread misinformation. However, the evaluated
moral bias was restricted to simple actions -- one verb -- and a ranking of
actions with surrounding context. Recently BERT ---and variants such as RoBERTa
and SBERT--- has set a new state-of-the-art performance for a wide range of NLP
tasks. But has BERT also a better moral compass? In this paper, we discuss and
show that this is indeed the case. Thus, recent improvements of language
representations also improve the representation of the underlying ethical and
moral values of the machine. We argue that through an advanced semantic
representation of text, BERT allows one to get better insights of moral and
ethical values implicitly represented in text. This enables the Moral Choice
Machine (MCM) to extract more accurate imprints of moral choices and ethical
values.",,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1912.05238v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.05238v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.05238v1,"{'id': 'http://arxiv.org/abs/1912.05238v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.05238v1', 'updated': '2019-12-11T11:27:06Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=11, tm_hour=11, tm_min=27, tm_sec=6, tm_wday=2, tm_yday=345, tm_isdst=0), 'published': '2019-12-11T11:27:06Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=11, tm_hour=11, tm_min=27, tm_sec=6, tm_wday=2, tm_yday=345, tm_isdst=0), 'title': 'BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines'}, 'summary': 'Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout ""right"" and ""wrong"" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout ""right"" and ""wrong"" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.'}, 'authors': [{'name': 'Patrick Schramowski'}, {'name': 'Cigdem Turan'}, {'name': 'Sophie Jentzsch'}, {'name': 'Constantin Rothkopf'}, {'name': 'Kristian Kersting'}], 'author_detail': {'name': 'Kristian Kersting'}, 'author': 'Kristian Kersting', 'links': [{'href': 'http://arxiv.org/abs/1912.05238v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.05238v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
338,http://arxiv.org/abs/1912.03481v1,2019-12-07 10:15:08+00:00,2019-12-07 10:15:08+00:00,A Multi-Feature Diffusion Model: Rumor Blocking in Social Networks,"[arxiv.Result.Author('Jianxiong Guo'), arxiv.Result.Author('Tiantian Chen'), arxiv.Result.Author('Weili Wu')]","Online social networks provide a convenient platform for the spread of
rumors, which could lead to serious aftermaths such as economic losses and
public panic. The classical rumor blocking problem aims to launch a set of
nodes as a positive cascade to compete with misinformation in order to limit
the spread of rumors. However, most of the related researches were based on
one-dimensional diffusion model. In reality, there are more than one feature
associated with an object. The user's impression on this object is determined
not just by one feature but by his/her overall evaluation on all of these
features. Thus, the influence spread of this object can be decomposed into the
spread of multiple features. Based on that, we propose a Multi-Feature
diffusion model (MF-model) in this paper, and a novel problem, Multi-Feature
Rumor Blocking (MFRB), is formulated on a multi-layer network structure
according to this model. To solve MFRB, we design a creative sampling method,
called Multi-Sampling, which can be applied to a multi-layer network structure.
Inspired by martingale analysis, the Revised-IMM algorithm is proposed, and
returns a satisfactory approximate solution to MFRB. Finally, we evaluate our
proposed algorithm by conducting experiments on real datasets, and show the
effectiveness and accuracy of the Revised-IMM algorithm and significantly
outperforms other baseline algorithms.",in IEEE/ACM Transactions on Networking,,10.1109/TNET.2020.3032893,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/TNET.2020.3032893', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1912.03481v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.03481v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.03481v1,"{'id': 'http://arxiv.org/abs/1912.03481v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.03481v1', 'updated': '2019-12-07T10:15:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=7, tm_hour=10, tm_min=15, tm_sec=8, tm_wday=5, tm_yday=341, tm_isdst=0), 'published': '2019-12-07T10:15:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=7, tm_hour=10, tm_min=15, tm_sec=8, tm_wday=5, tm_yday=341, tm_isdst=0), 'title': 'A Multi-Feature Diffusion Model: Rumor Blocking in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Multi-Feature Diffusion Model: Rumor Blocking in Social Networks'}, 'summary': ""Online social networks provide a convenient platform for the spread of\nrumors, which could lead to serious aftermaths such as economic losses and\npublic panic. The classical rumor blocking problem aims to launch a set of\nnodes as a positive cascade to compete with misinformation in order to limit\nthe spread of rumors. However, most of the related researches were based on\none-dimensional diffusion model. In reality, there are more than one feature\nassociated with an object. The user's impression on this object is determined\nnot just by one feature but by his/her overall evaluation on all of these\nfeatures. Thus, the influence spread of this object can be decomposed into the\nspread of multiple features. Based on that, we propose a Multi-Feature\ndiffusion model (MF-model) in this paper, and a novel problem, Multi-Feature\nRumor Blocking (MFRB), is formulated on a multi-layer network structure\naccording to this model. To solve MFRB, we design a creative sampling method,\ncalled Multi-Sampling, which can be applied to a multi-layer network structure.\nInspired by martingale analysis, the Revised-IMM algorithm is proposed, and\nreturns a satisfactory approximate solution to MFRB. Finally, we evaluate our\nproposed algorithm by conducting experiments on real datasets, and show the\neffectiveness and accuracy of the Revised-IMM algorithm and significantly\noutperforms other baseline algorithms."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online social networks provide a convenient platform for the spread of\nrumors, which could lead to serious aftermaths such as economic losses and\npublic panic. The classical rumor blocking problem aims to launch a set of\nnodes as a positive cascade to compete with misinformation in order to limit\nthe spread of rumors. However, most of the related researches were based on\none-dimensional diffusion model. In reality, there are more than one feature\nassociated with an object. The user's impression on this object is determined\nnot just by one feature but by his/her overall evaluation on all of these\nfeatures. Thus, the influence spread of this object can be decomposed into the\nspread of multiple features. Based on that, we propose a Multi-Feature\ndiffusion model (MF-model) in this paper, and a novel problem, Multi-Feature\nRumor Blocking (MFRB), is formulated on a multi-layer network structure\naccording to this model. To solve MFRB, we design a creative sampling method,\ncalled Multi-Sampling, which can be applied to a multi-layer network structure.\nInspired by martingale analysis, the Revised-IMM algorithm is proposed, and\nreturns a satisfactory approximate solution to MFRB. Finally, we evaluate our\nproposed algorithm by conducting experiments on real datasets, and show the\neffectiveness and accuracy of the Revised-IMM algorithm and significantly\noutperforms other baseline algorithms.""}, 'authors': [{'name': 'Jianxiong Guo'}, {'name': 'Tiantian Chen'}, {'name': 'Weili Wu'}], 'author_detail': {'name': 'Weili Wu'}, 'author': 'Weili Wu', 'arxiv_doi': '10.1109/TNET.2020.3032893', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TNET.2020.3032893', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1912.03481v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.03481v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'in IEEE/ACM Transactions on Networking', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
339,http://arxiv.org/abs/1911.12069v2,2021-04-22 09:51:53+00:00,2019-11-27 10:41:19+00:00,SpoC: Spoofing Camera Fingerprints,"[arxiv.Result.Author('Davide Cozzolino'), arxiv.Result.Author('Justus Thies'), arxiv.Result.Author('Andreas Rössler'), arxiv.Result.Author('Matthias Nießner'), arxiv.Result.Author('Luisa Verdoliva')]","Thanks to the fast progress in synthetic media generation, creating realistic
false images has become very easy. Such images can be used to wrap ""rich"" fake
news with enhanced credibility, spawning a new wave of high-impact, high-risk
misinformation campaigns. Therefore, there is a fast-growing interest in
reliable detectors of manipulated media. The most powerful detectors, to date,
rely on the subtle traces left by any device on all images acquired by it. In
particular, due to proprietary in-camera processes, like demosaicing or
compression, each camera model leaves trademark traces that can be exploited
for forensic analyses. The absence or distortion of such traces in the target
image is a strong hint of manipulation. In this paper, we challenge such
detectors to gain better insight into their vulnerabilities. This is an
important study in order to build better forgery detectors able to face
malicious attacks. Our proposal consists of a GAN-based approach that injects
camera traces into synthetic images. Given a GAN-generated image, we insert the
traces of a specific camera model into it and deceive state-of-the-art
detectors into believing the image was acquired by that model. Likewise, we
deceive independent detectors of synthetic GAN images into believing the image
is real. Experiments prove the effectiveness of the proposed method in a wide
array of conditions. Moreover, no prior information on the attacked detectors
is needed, but only sample images from the target camera.",,,,cs.CV,"['cs.CV', 'cs.CR', 'cs.LG', 'eess.IV']","[arxiv.Result.Link('http://arxiv.org/abs/1911.12069v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.12069v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.12069v2,"{'id': 'http://arxiv.org/abs/1911.12069v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.12069v2', 'updated': '2021-04-22T09:51:53Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=22, tm_hour=9, tm_min=51, tm_sec=53, tm_wday=3, tm_yday=112, tm_isdst=0), 'published': '2019-11-27T10:41:19Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=10, tm_min=41, tm_sec=19, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'SpoC: Spoofing Camera Fingerprints', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SpoC: Spoofing Camera Fingerprints'}, 'summary': 'Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap ""rich"" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap ""rich"" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.'}, 'authors': [{'name': 'Davide Cozzolino'}, {'name': 'Justus Thies'}, {'name': 'Andreas Rössler'}, {'name': 'Matthias Nießner'}, {'name': 'Luisa Verdoliva'}], 'author_detail': {'name': 'Luisa Verdoliva'}, 'author': 'Luisa Verdoliva', 'links': [{'href': 'http://arxiv.org/abs/1911.12069v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.12069v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
340,http://arxiv.org/abs/1911.11920v1,2019-11-27 02:33:24+00:00,2019-11-27 02:33:24+00:00,Warning Signs in Communicating the Machine Learning Detection Results of Misinformation with Individuals,[arxiv.Result.Author('Limeng Cui')],"With the prevalence of misinformation online, researchers have focused on
developing various machine learning algorithms to detect fake news. However,
users' perception of machine learning outcomes and related behaviors have been
widely ignored. Hence, this paper proposed to bridge this gap by studying how
to pass the detection results of machine learning to the users, and aid their
decisions in handling misinformation. An online experiment was conducted, to
evaluate the effect of the proposed machine learning warning sign against a
control condition. We examined participants' detection and sharing of news. The
data showed that warning sign's effects on participants' trust toward the fake
news were not significant. However, we found that people's uncertainty about
the authenticity of the news dropped with the presence of the machine learning
warning sign. We also found that social media experience had effects on users'
trust toward the fake news, and age and social media experience had effects on
users' sharing decision. Therefore, the results indicate that there are many
factors worth studying that affect people's trust in the news. Moreover, the
warning sign in communicating machine learning detection results is different
from ordinary warnings and needs more detailed research and design. These
findings hold important implications for the design of machine learning
warnings.",,,,cs.HC,"['cs.HC', 'H.5.2']","[arxiv.Result.Link('http://arxiv.org/abs/1911.11920v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.11920v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.11920v1,"{'id': 'http://arxiv.org/abs/1911.11920v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.11920v1', 'updated': '2019-11-27T02:33:24Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=2, tm_min=33, tm_sec=24, tm_wday=2, tm_yday=331, tm_isdst=0), 'published': '2019-11-27T02:33:24Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=27, tm_hour=2, tm_min=33, tm_sec=24, tm_wday=2, tm_yday=331, tm_isdst=0), 'title': 'Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals'}, 'summary': ""With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.""}, 'authors': [{'name': 'Limeng Cui'}], 'author_detail': {'name': 'Limeng Cui'}, 'author': 'Limeng Cui', 'links': [{'href': 'http://arxiv.org/abs/1911.11920v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.11920v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
341,http://arxiv.org/abs/1912.08926v1,2019-11-25 03:55:55+00:00,2019-11-25 03:55:55+00:00,Rumor Detection and Classification for Twitter Data,"[arxiv.Result.Author('Sardar Hamidian'), arxiv.Result.Author('Mona T Diab')]","With the pervasiveness of online media data as a source of information
verifying the validity of this information is becoming even more important yet
quite challenging. Rumors spread a large quantity of misinformation on
microblogs. In this study we address two common issues within the context of
microblog social media. First we detect rumors as a type of misinformation
propagation and next we go beyond detection to perform the task of rumor
classification. WE explore the problem using a standard data set. We devise
novel features and study their impact on the task. We experiment with various
levels of preprocessing as a precursor of the classification as well as
grouping of features. We achieve and f-measure of over 0.82 in RDC task in
mixed rumors data set and 84 percent in a single rumor data set using a
two-step classification approach.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1912.08926v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.08926v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.08926v1,"{'id': 'http://arxiv.org/abs/1912.08926v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.08926v1', 'updated': '2019-11-25T03:55:55Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=25, tm_hour=3, tm_min=55, tm_sec=55, tm_wday=0, tm_yday=329, tm_isdst=0), 'published': '2019-11-25T03:55:55Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=25, tm_hour=3, tm_min=55, tm_sec=55, tm_wday=0, tm_yday=329, tm_isdst=0), 'title': 'Rumor Detection and Classification for Twitter Data', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Rumor Detection and Classification for Twitter Data'}, 'summary': 'With the pervasiveness of online media data as a source of information\nverifying the validity of this information is becoming even more important yet\nquite challenging. Rumors spread a large quantity of misinformation on\nmicroblogs. In this study we address two common issues within the context of\nmicroblog social media. First we detect rumors as a type of misinformation\npropagation and next we go beyond detection to perform the task of rumor\nclassification. WE explore the problem using a standard data set. We devise\nnovel features and study their impact on the task. We experiment with various\nlevels of preprocessing as a precursor of the classification as well as\ngrouping of features. We achieve and f-measure of over 0.82 in RDC task in\nmixed rumors data set and 84 percent in a single rumor data set using a\ntwo-step classification approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the pervasiveness of online media data as a source of information\nverifying the validity of this information is becoming even more important yet\nquite challenging. Rumors spread a large quantity of misinformation on\nmicroblogs. In this study we address two common issues within the context of\nmicroblog social media. First we detect rumors as a type of misinformation\npropagation and next we go beyond detection to perform the task of rumor\nclassification. WE explore the problem using a standard data set. We devise\nnovel features and study their impact on the task. We experiment with various\nlevels of preprocessing as a precursor of the classification as well as\ngrouping of features. We achieve and f-measure of over 0.82 in RDC task in\nmixed rumors data set and 84 percent in a single rumor data set using a\ntwo-step classification approach.'}, 'authors': [{'name': 'Sardar Hamidian'}, {'name': 'Mona T Diab'}], 'author_detail': {'name': 'Mona T Diab'}, 'author': 'Mona T Diab', 'links': [{'href': 'http://arxiv.org/abs/1912.08926v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.08926v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
342,http://arxiv.org/abs/1911.10130v1,2019-11-22 16:35:37+00:00,2019-11-22 16:35:37+00:00,A Data Set of Internet Claims and Comparison of their Sentiments with Credibility,"[arxiv.Result.Author('Amey Parundekar'), arxiv.Result.Author('Susan Elias'), arxiv.Result.Author('Ashwin Ashok')]","In this modern era, communication has become faster and easier. This means
fallacious information can spread as fast as reality. Considering the damage
that fake news kindles on the psychology of people and the fact that such news
proliferates faster than truth, we need to study the phenomenon that helps
spread fake news. An unbiased data set that depends on reality for rating news
is necessary to construct predictive models for its classification. This paper
describes the methodology to create such a data set. We collect our data from
snopes.com which is a fact-checking organization. Furthermore, we intend to
create this data set not only for classification of the news but also to find
patterns that reason the intent behind misinformation. We also formally define
an Internet Claim, its credibility, and the sentiment behind such a claim. We
try to realize the relationship between the sentiment of a claim with its
credibility. This relationship pours light on the bigger picture behind the
propagation of misinformation. We pave the way for further research based on
the methodology described in this paper to create the data set and usage of
predictive modeling along with research-based on psychology/mentality of people
to understand why fake news spreads much faster than reality.","8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact
  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,
  Alaska",,,cs.IR,"['cs.IR', 'cs.CL', 'H.3.3, I.2.7', 'H.3.3; I.2.7']","[arxiv.Result.Link('http://arxiv.org/abs/1911.10130v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.10130v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.10130v1,"{'id': 'http://arxiv.org/abs/1911.10130v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.10130v1', 'updated': '2019-11-22T16:35:37Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=22, tm_hour=16, tm_min=35, tm_sec=37, tm_wday=4, tm_yday=326, tm_isdst=0), 'published': '2019-11-22T16:35:37Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=22, tm_hour=16, tm_min=35, tm_sec=37, tm_wday=4, tm_yday=326, tm_isdst=0), 'title': 'A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility'}, 'summary': 'In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.'}, 'authors': [{'name': 'Amey Parundekar'}, {'name': 'Susan Elias'}, {'name': 'Ashwin Ashok'}], 'author_detail': {'name': 'Ashwin Ashok'}, 'author': 'Ashwin Ashok', 'arxiv_comment': '8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact\n  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,\n  Alaska', 'links': [{'href': 'http://arxiv.org/abs/1911.10130v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.10130v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.3, I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.3; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
343,http://arxiv.org/abs/1912.01708v1,2019-11-20 23:32:59+00:00,2019-11-20 23:32:59+00:00,Celebrating Three Decades of Worldwide Stock Market Manipulation,[arxiv.Result.Author('Bruce Knuteson')],"As the decade turns, we reflect on nearly thirty years of successful
manipulation of the world's public equity markets. This reflection highlights a
few of the key enabling ingredients and lessons learned along the way. A
quantitative understanding of market impact and its decay, which we cover
briefly, lets you move long-term market prices to your advantage at acceptable
cost. Hiding your footprints turns out to be less important than moving prices
in the direction most people want them to move. Widespread (if misplaced) trust
of market prices -- buttressed by overestimates of the cost of manipulation and
underestimates of the benefits to certain market participants -- makes price
manipulation a particularly valuable and profitable tool. Of the many recent
stories heralding the dawn of the present golden age of misinformation, the
manipulation leading to the remarkable increase in the market capitalization of
the world's publicly traded companies over the past three decades is among the
best.",8 pages,,,q-fin.GN,"['q-fin.GN', 'econ.GN', 'q-fin.EC', 'q-fin.TR']","[arxiv.Result.Link('http://arxiv.org/abs/1912.01708v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1912.01708v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1912.01708v1,"{'id': 'http://arxiv.org/abs/1912.01708v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1912.01708v1', 'updated': '2019-11-20T23:32:59Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=20, tm_hour=23, tm_min=32, tm_sec=59, tm_wday=2, tm_yday=324, tm_isdst=0), 'published': '2019-11-20T23:32:59Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=20, tm_hour=23, tm_min=32, tm_sec=59, tm_wday=2, tm_yday=324, tm_isdst=0), 'title': 'Celebrating Three Decades of Worldwide Stock Market Manipulation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Celebrating Three Decades of Worldwide Stock Market Manipulation'}, 'summary': ""As the decade turns, we reflect on nearly thirty years of successful\nmanipulation of the world's public equity markets. This reflection highlights a\nfew of the key enabling ingredients and lessons learned along the way. A\nquantitative understanding of market impact and its decay, which we cover\nbriefly, lets you move long-term market prices to your advantage at acceptable\ncost. Hiding your footprints turns out to be less important than moving prices\nin the direction most people want them to move. Widespread (if misplaced) trust\nof market prices -- buttressed by overestimates of the cost of manipulation and\nunderestimates of the benefits to certain market participants -- makes price\nmanipulation a particularly valuable and profitable tool. Of the many recent\nstories heralding the dawn of the present golden age of misinformation, the\nmanipulation leading to the remarkable increase in the market capitalization of\nthe world's publicly traded companies over the past three decades is among the\nbest."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As the decade turns, we reflect on nearly thirty years of successful\nmanipulation of the world's public equity markets. This reflection highlights a\nfew of the key enabling ingredients and lessons learned along the way. A\nquantitative understanding of market impact and its decay, which we cover\nbriefly, lets you move long-term market prices to your advantage at acceptable\ncost. Hiding your footprints turns out to be less important than moving prices\nin the direction most people want them to move. Widespread (if misplaced) trust\nof market prices -- buttressed by overestimates of the cost of manipulation and\nunderestimates of the benefits to certain market participants -- makes price\nmanipulation a particularly valuable and profitable tool. Of the many recent\nstories heralding the dawn of the present golden age of misinformation, the\nmanipulation leading to the remarkable increase in the market capitalization of\nthe world's publicly traded companies over the past three decades is among the\nbest.""}, 'authors': [{'name': 'Bruce Knuteson'}], 'author_detail': {'name': 'Bruce Knuteson'}, 'author': 'Bruce Knuteson', 'arxiv_comment': '8 pages', 'links': [{'href': 'http://arxiv.org/abs/1912.01708v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1912.01708v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.TR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
344,http://arxiv.org/abs/1911.07100v1,2019-11-16 21:13:33+00:00,2019-11-16 21:13:33+00:00,Defending Against Model Stealing Attacks with Adaptive Misinformation,"[arxiv.Result.Author('Sanjay Kariyappa'), arxiv.Result.Author('Moinuddin K Qureshi')]","Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which
allows a data-limited adversary with no knowledge of the training dataset to
clone the functionality of a target model, just by using black-box query
access. Such attacks are typically carried out by querying the target model
using inputs that are synthetically generated or sampled from a surrogate
dataset to construct a labeled dataset. The adversary can use this labeled
dataset to train a clone model, which achieves a classification accuracy
comparable to that of the target model. We propose ""Adaptive Misinformation"" to
defend against such model stealing attacks. We identify that all existing model
stealing attacks invariably query the target model with Out-Of-Distribution
(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our
defense substantially degrades the accuracy of the attacker's clone model (by
up to 40%), while minimally impacting the accuracy (<0.5%) for benign users.
Compared to existing defenses, our defense has a significantly better security
vs accuracy trade-off and incurs minimal computational overhead.",,,,stat.ML,"['stat.ML', 'cs.CR', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1911.07100v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.07100v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.07100v1,"{'id': 'http://arxiv.org/abs/1911.07100v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.07100v1', 'updated': '2019-11-16T21:13:33Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=16, tm_hour=21, tm_min=13, tm_sec=33, tm_wday=5, tm_yday=320, tm_isdst=0), 'published': '2019-11-16T21:13:33Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=16, tm_hour=21, tm_min=13, tm_sec=33, tm_wday=5, tm_yday=320, tm_isdst=0), 'title': 'Defending Against Model Stealing Attacks with Adaptive Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Defending Against Model Stealing Attacks with Adaptive Misinformation'}, 'summary': 'Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose ""Adaptive Misinformation"" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker\'s clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose ""Adaptive Misinformation"" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker\'s clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.'}, 'authors': [{'name': 'Sanjay Kariyappa'}, {'name': 'Moinuddin K Qureshi'}], 'author_detail': {'name': 'Moinuddin K Qureshi'}, 'author': 'Moinuddin K Qureshi', 'links': [{'href': 'http://arxiv.org/abs/1911.07100v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.07100v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
345,http://arxiv.org/abs/1911.05825v1,2019-11-13 21:49:17+00:00,2019-11-13 21:49:17+00:00,Trustworthy Misinformation Mitigation with Soft Information Nudging,"[arxiv.Result.Author('Benjamin D. Horne'), arxiv.Result.Author('Maurício Gruppi'), arxiv.Result.Author('Sibel Adalı')]","Research in combating misinformation reports many negative results: facts may
not change minds, especially if they come from sources that are not trusted.
Individuals can disregard and justify lies told by trusted sources. This
problem is made even worse by social recommendation algorithms which help
amplify conspiracy theories and information confirming one's own biases due to
companies' efforts to optimize for clicks and watch time over individuals' own
values and public good. As a result, more nuanced voices and facts are drowned
out by a continuous erosion of trust in better information sources. Most
misinformation mitigation techniques assume that discrediting, filtering, or
demoting low veracity information will help news consumers make better
information decisions. However, these negative results indicate that some news
consumers, particularly extreme or conspiracy news consumers will not be
helped.
  We argue that, given this background, technology solutions to combating
misinformation should not simply seek facts or discredit bad news sources, but
instead use more subtle nudges towards better information consumption. Repeated
exposure to such nudges can help promote trust in better information sources
and also improve societal outcomes in the long run. In this article, we will
talk about technological solutions that can help us in developing such an
approach, and introduce one such model called Trust Nudging.",Published at IEEE TPS 2019,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1911.05825v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.05825v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.05825v1,"{'id': 'http://arxiv.org/abs/1911.05825v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.05825v1', 'updated': '2019-11-13T21:49:17Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=13, tm_hour=21, tm_min=49, tm_sec=17, tm_wday=2, tm_yday=317, tm_isdst=0), 'published': '2019-11-13T21:49:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=13, tm_hour=21, tm_min=49, tm_sec=17, tm_wday=2, tm_yday=317, tm_isdst=0), 'title': 'Trustworthy Misinformation Mitigation with Soft Information Nudging', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trustworthy Misinformation Mitigation with Soft Information Nudging'}, 'summary': ""Research in combating misinformation reports many negative results: facts may\nnot change minds, especially if they come from sources that are not trusted.\nIndividuals can disregard and justify lies told by trusted sources. This\nproblem is made even worse by social recommendation algorithms which help\namplify conspiracy theories and information confirming one's own biases due to\ncompanies' efforts to optimize for clicks and watch time over individuals' own\nvalues and public good. As a result, more nuanced voices and facts are drowned\nout by a continuous erosion of trust in better information sources. Most\nmisinformation mitigation techniques assume that discrediting, filtering, or\ndemoting low veracity information will help news consumers make better\ninformation decisions. However, these negative results indicate that some news\nconsumers, particularly extreme or conspiracy news consumers will not be\nhelped.\n  We argue that, given this background, technology solutions to combating\nmisinformation should not simply seek facts or discredit bad news sources, but\ninstead use more subtle nudges towards better information consumption. Repeated\nexposure to such nudges can help promote trust in better information sources\nand also improve societal outcomes in the long run. In this article, we will\ntalk about technological solutions that can help us in developing such an\napproach, and introduce one such model called Trust Nudging."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Research in combating misinformation reports many negative results: facts may\nnot change minds, especially if they come from sources that are not trusted.\nIndividuals can disregard and justify lies told by trusted sources. This\nproblem is made even worse by social recommendation algorithms which help\namplify conspiracy theories and information confirming one's own biases due to\ncompanies' efforts to optimize for clicks and watch time over individuals' own\nvalues and public good. As a result, more nuanced voices and facts are drowned\nout by a continuous erosion of trust in better information sources. Most\nmisinformation mitigation techniques assume that discrediting, filtering, or\ndemoting low veracity information will help news consumers make better\ninformation decisions. However, these negative results indicate that some news\nconsumers, particularly extreme or conspiracy news consumers will not be\nhelped.\n  We argue that, given this background, technology solutions to combating\nmisinformation should not simply seek facts or discredit bad news sources, but\ninstead use more subtle nudges towards better information consumption. Repeated\nexposure to such nudges can help promote trust in better information sources\nand also improve societal outcomes in the long run. In this article, we will\ntalk about technological solutions that can help us in developing such an\napproach, and introduce one such model called Trust Nudging.""}, 'authors': [{'name': 'Benjamin D. Horne'}, {'name': 'Maurício Gruppi'}, {'name': 'Sibel Adalı'}], 'author_detail': {'name': 'Sibel Adalı'}, 'author': 'Sibel Adalı', 'arxiv_comment': 'Published at IEEE TPS 2019', 'links': [{'href': 'http://arxiv.org/abs/1911.05825v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.05825v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
346,http://arxiv.org/abs/1911.00643v1,2019-11-02 04:06:30+00:00,2019-11-02 04:06:30+00:00,Credibility-based Fake News Detection,"[arxiv.Result.Author('Niraj Sitaula'), arxiv.Result.Author('Chilukuri K. Mohan'), arxiv.Result.Author('Jennifer Grygiel'), arxiv.Result.Author('Xinyi Zhou'), arxiv.Result.Author('Reza Zafarani')]","Fake news can significantly misinform people who often rely on online sources
and social media for their information. Current research on fake news detection
has mostly focused on analyzing fake news content and how it propagates on a
network of users. In this paper, we emphasize the detection of fake news by
assessing its credibility. By analyzing public fake news data, we show that
information on news sources (and authors) can be a strong indicator of
credibility. Our findings suggest that an author's history of association with
fake news, and the number of authors of a news article, can play a significant
role in detecting fake news. Our approach can help improve traditional fake
news detection methods, wherein content features are often used to detect fake
news.",,,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1911.00643v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1911.00643v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1911.00643v1,"{'id': 'http://arxiv.org/abs/1911.00643v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1911.00643v1', 'updated': '2019-11-02T04:06:30Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=2, tm_hour=4, tm_min=6, tm_sec=30, tm_wday=5, tm_yday=306, tm_isdst=0), 'published': '2019-11-02T04:06:30Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=2, tm_hour=4, tm_min=6, tm_sec=30, tm_wday=5, tm_yday=306, tm_isdst=0), 'title': 'Credibility-based Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Credibility-based Fake News Detection'}, 'summary': ""Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.""}, 'authors': [{'name': 'Niraj Sitaula'}, {'name': 'Chilukuri K. Mohan'}, {'name': 'Jennifer Grygiel'}, {'name': 'Xinyi Zhou'}, {'name': 'Reza Zafarani'}], 'author_detail': {'name': 'Reza Zafarani'}, 'author': 'Reza Zafarani', 'links': [{'href': 'http://arxiv.org/abs/1911.00643v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1911.00643v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
347,http://arxiv.org/abs/1910.07130v5,2020-09-02 02:01:28+00:00,2019-10-16 02:05:26+00:00,SCG: Spotting Coordinated Groups in Social Media,"[arxiv.Result.Author('Junhao Wang'), arxiv.Result.Author('Sacha Levy'), arxiv.Result.Author('Ren Wang'), arxiv.Result.Author('Aayushi Kulshrestha'), arxiv.Result.Author('Reihaneh Rabbany')]","Recent events have led to a burgeoning awareness on the misuse of social
media sites to affect political events, sway public opinion, and confuse the
voters. Such serious, hostile mass manipulation has motivated a large body of
works on bots/troll detection and fake news detection, which mostly focus on
classifying at the user level based on the content generated by the users. In
this study, we jointly analyze the connections among the users, as well as the
content generated by them to Spot Coordinated Groups (SCG), sets of users that
are likely to be organized towards impacting the general discourse. Given their
tiny size (relative to the whole data), detecting these groups is
computationally hard. Our proposed method detects these tiny-clusters
effectively and efficiently. We deploy our SCG method to summarize and explain
the coordinated groups on Twitter around the 2019 Canadian Federal Elections,
by analyzing over 60 thousand user accounts with 3.4 million followership
connections, and 1.3 million unique hashtags in the content of their tweets.
The users in the detected coordinated groups are over 4x more likely to get
suspended, whereas the hashtags which characterize their creed are linked to
misinformation campaigns.",,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1910.07130v5', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.07130v5', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.07130v5,"{'id': 'http://arxiv.org/abs/1910.07130v5', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.07130v5', 'updated': '2020-09-02T02:01:28Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=9, tm_mday=2, tm_hour=2, tm_min=1, tm_sec=28, tm_wday=2, tm_yday=246, tm_isdst=0), 'published': '2019-10-16T02:05:26Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=16, tm_hour=2, tm_min=5, tm_sec=26, tm_wday=2, tm_yday=289, tm_isdst=0), 'title': 'SCG: Spotting Coordinated Groups in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'SCG: Spotting Coordinated Groups in Social Media'}, 'summary': 'Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.'}, 'authors': [{'name': 'Junhao Wang'}, {'name': 'Sacha Levy'}, {'name': 'Ren Wang'}, {'name': 'Aayushi Kulshrestha'}, {'name': 'Reihaneh Rabbany'}], 'author_detail': {'name': 'Reihaneh Rabbany'}, 'author': 'Reihaneh Rabbany', 'links': [{'href': 'http://arxiv.org/abs/1910.07130v5', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.07130v5', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
348,http://arxiv.org/abs/1910.02223v1,2019-10-05 06:48:23+00:00,2019-10-05 06:48:23+00:00,A Machine Learning Analysis of the Features in Deceptive and Credible News,[arxiv.Result.Author('Qi Jia Sun')],"Fake news is a type of pervasive propaganda that spreads misinformation
online, taking advantage of social media's extensive reach to manipulate public
perception. Over the past three years, fake news has become a focal discussion
point in the media due to its impact on the 2016 U.S. presidential election.
Fake news can have severe real-world implications: in 2016, a man walked into a
pizzeria carrying a rifle because he read that Hillary Clinton was harboring
children as sex slaves. This project presents a high accuracy (87%) machine
learning classifier that determines the validity of news based on the word
distributions and specific linguistic and stylistic differences in the first
few sentences of an article. This can help readers identify the validity of an
article by looking for specific features in the opening lines aiding them in
making informed decisions. Using a dataset of 2,107 articles from 30 different
websites, this project establishes an understanding of the variations between
fake and credible news by examining the model, dataset, and features. This
classifier appears to use the differences in word distribution, levels of tone
authenticity, and frequency of adverbs, adjectives, and nouns. The
differentiation in the features of these articles can be used to improve future
classifiers. This classifier can also be further applied directly to browsers
as a Google Chrome extension or as a filter for social media outlets or news
websites to reduce the spread of misinformation.",,,,cs.CL,"['cs.CL', 'J.5.5']","[arxiv.Result.Link('http://arxiv.org/abs/1910.02223v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.02223v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.02223v1,"{'id': 'http://arxiv.org/abs/1910.02223v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.02223v1', 'updated': '2019-10-05T06:48:23Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=6, tm_min=48, tm_sec=23, tm_wday=5, tm_yday=278, tm_isdst=0), 'published': '2019-10-05T06:48:23Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=6, tm_min=48, tm_sec=23, tm_wday=5, tm_yday=278, tm_isdst=0), 'title': 'A Machine Learning Analysis of the Features in Deceptive and Credible\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Machine Learning Analysis of the Features in Deceptive and Credible\n  News'}, 'summary': ""Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.""}, 'authors': [{'name': 'Qi Jia Sun'}], 'author_detail': {'name': 'Qi Jia Sun'}, 'author': 'Qi Jia Sun', 'links': [{'href': 'http://arxiv.org/abs/1910.02223v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.02223v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'J.5.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
349,http://arxiv.org/abs/1910.02202v1,2019-10-05 03:23:45+00:00,2019-10-05 03:23:45+00:00,Learning from Fact-checkers: Analysis and Generation of Fact-checking Language,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","In fighting against fake news, many fact-checking systems comprised of
human-based fact-checking sites (e.g., snopes.com and politifact.com) and
automatic detection systems have been developed in recent years. However,
online users still keep sharing fake news even when it has been debunked. It
means that early fake news detection may be insufficient and we need another
complementary approach to mitigate the spread of misinformation. In this paper,
we introduce a novel application of text generation for combating fake news. In
particular, we (1) leverage online users named \emph{fact-checkers}, who cite
fact-checking sites as credible evidences to fact-check information in public
discourse; (2) analyze linguistic characteristics of fact-checking tweets; and
(3) propose and build a deep learning framework to generate responses with
fact-checking intention to increase the fact-checkers' engagement in
fact-checking activities. Our analysis reveals that the fact-checkers tend to
refute misinformation and use formal language (e.g. few swear words and
Internet slangs). Our framework successfully generates relevant responses, and
outperforms competing models by achieving up to 30\% improvements. Our
qualitative study also confirms that the superiority of our generated responses
compared with responses generated from the existing models.",SIGIR 2019,,,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1910.02202v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.02202v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.02202v1,"{'id': 'http://arxiv.org/abs/1910.02202v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.02202v1', 'updated': '2019-10-05T03:23:45Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=3, tm_min=23, tm_sec=45, tm_wday=5, tm_yday=278, tm_isdst=0), 'published': '2019-10-05T03:23:45Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=5, tm_hour=3, tm_min=23, tm_sec=45, tm_wday=5, tm_yday=278, tm_isdst=0), 'title': 'Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language'}, 'summary': ""In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.""}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'SIGIR 2019', 'links': [{'href': 'http://arxiv.org/abs/1910.02202v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.02202v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
350,http://arxiv.org/abs/1910.02103v1,2019-10-04 18:45:09+00:00,2019-10-04 18:45:09+00:00,Health Wars and Beyond: The Rapidly Expanding and Efficient Network Insurgency Interlinking Local and Global Online Crowds of Distrust,"[arxiv.Result.Author('N. F. Johnson'), arxiv.Result.Author('N. Velasquez'), arxiv.Result.Author('N. Johnson Restrepo'), arxiv.Result.Author('R. Leahy'), arxiv.Result.Author('N. Gabriel'), arxiv.Result.Author('S. Wuchty'), arxiv.Result.Author('D. Broniatowski')]","We present preliminary results on the online war surrounding distrust of
expertise in medical science -- specifically, the issue of vaccinations. While
distrust and misinformation in politics can damage democratic elections, in the
medical context it may also endanger lives through missed vaccinations and DIY
cancer cures. We find that this online health war has evolved into a highly
efficient network insurgency with direct inter-crowd links across countries,
continents and cultures. The online anti-vax crowds (referred to as Red) now
appear better positioned to groom new recruits (Green) than those supporting
established expertise (Blue). We also present preliminary results from a
mathematically-grounded, crowd-based analysis of the war's evolution, which
offers an explanation for how Red seems to be turning the tide on Blue.",Working paper. Comments welcome,,,physics.soc-ph,"['physics.soc-ph', 'physics.med-ph', 'physics.pop-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1910.02103v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.02103v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.02103v1,"{'id': 'http://arxiv.org/abs/1910.02103v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.02103v1', 'updated': '2019-10-04T18:45:09Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=4, tm_hour=18, tm_min=45, tm_sec=9, tm_wday=4, tm_yday=277, tm_isdst=0), 'published': '2019-10-04T18:45:09Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=4, tm_hour=18, tm_min=45, tm_sec=9, tm_wday=4, tm_yday=277, tm_isdst=0), 'title': 'Health Wars and Beyond: The Rapidly Expanding and Efficient Network\n  Insurgency Interlinking Local and Global Online Crowds of Distrust', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Health Wars and Beyond: The Rapidly Expanding and Efficient Network\n  Insurgency Interlinking Local and Global Online Crowds of Distrust'}, 'summary': ""We present preliminary results on the online war surrounding distrust of\nexpertise in medical science -- specifically, the issue of vaccinations. While\ndistrust and misinformation in politics can damage democratic elections, in the\nmedical context it may also endanger lives through missed vaccinations and DIY\ncancer cures. We find that this online health war has evolved into a highly\nefficient network insurgency with direct inter-crowd links across countries,\ncontinents and cultures. The online anti-vax crowds (referred to as Red) now\nappear better positioned to groom new recruits (Green) than those supporting\nestablished expertise (Blue). We also present preliminary results from a\nmathematically-grounded, crowd-based analysis of the war's evolution, which\noffers an explanation for how Red seems to be turning the tide on Blue."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""We present preliminary results on the online war surrounding distrust of\nexpertise in medical science -- specifically, the issue of vaccinations. While\ndistrust and misinformation in politics can damage democratic elections, in the\nmedical context it may also endanger lives through missed vaccinations and DIY\ncancer cures. We find that this online health war has evolved into a highly\nefficient network insurgency with direct inter-crowd links across countries,\ncontinents and cultures. The online anti-vax crowds (referred to as Red) now\nappear better positioned to groom new recruits (Green) than those supporting\nestablished expertise (Blue). We also present preliminary results from a\nmathematically-grounded, crowd-based analysis of the war's evolution, which\noffers an explanation for how Red seems to be turning the tide on Blue.""}, 'authors': [{'name': 'N. F. Johnson'}, {'name': 'N. Velasquez'}, {'name': 'N. Johnson Restrepo'}, {'name': 'R. Leahy'}, {'name': 'N. Gabriel'}, {'name': 'S. Wuchty'}, {'name': 'D. Broniatowski'}], 'author_detail': {'name': 'D. Broniatowski'}, 'author': 'D. Broniatowski', 'arxiv_comment': 'Working paper. Comments welcome', 'links': [{'href': 'http://arxiv.org/abs/1910.02103v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.02103v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.med-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
351,http://arxiv.org/abs/1910.01160v2,2019-11-05 20:45:25+00:00,2019-10-02 18:47:17+00:00,Identifying Nuances in Fake News vs. Satire: Using Semantic and Linguistic Cues,"[arxiv.Result.Author('Or Levi'), arxiv.Result.Author('Pedram Hosseini'), arxiv.Result.Author('Mona Diab'), arxiv.Result.Author('David A. Broniatowski')]","The blurry line between nefarious fake news and protected-speech satire has
been a notorious struggle for social media platforms. Further to the efforts of
reducing exposure to misinformation on social media, purveyors of fake news
have begun to masquerade as satire sites to avoid being demoted. In this work,
we address the challenge of automatically classifying fake news versus satire.
Previous work have studied whether fake news and satire can be distinguished
based on language differences. Contrary to fake news, satire stories are
usually humorous and carry some political or social message. We hypothesize
that these nuances could be identified using semantic and linguistic cues.
Consequently, we train a machine learning method using semantic representation,
with a state-of-the-art contextual language model, and with linguistic features
based on textual coherence metrics. Empirical evaluation attests to the merits
of our approach compared to the language-based baseline and sheds light on the
nuances between fake news and satire. As avenues for future work, we consider
studying additional linguistic features related to the humor aspect, and
enriching the data with current news events, to help identify a political or
social message.","Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):
  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019",,10.18653/v1/D19-5004,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.18653/v1/D19-5004', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1910.01160v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.01160v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.01160v2,"{'id': 'http://arxiv.org/abs/1910.01160v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.01160v2', 'updated': '2019-11-05T20:45:25Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=11, tm_mday=5, tm_hour=20, tm_min=45, tm_sec=25, tm_wday=1, tm_yday=309, tm_isdst=0), 'published': '2019-10-02T18:47:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=2, tm_hour=18, tm_min=47, tm_sec=17, tm_wday=2, tm_yday=275, tm_isdst=0), 'title': 'Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues'}, 'summary': 'The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.'}, 'authors': [{'name': 'Or Levi'}, {'name': 'Pedram Hosseini'}, {'name': 'Mona Diab'}, {'name': 'David A. Broniatowski'}], 'author_detail': {'name': 'David A. Broniatowski'}, 'author': 'David A. Broniatowski', 'arxiv_doi': '10.18653/v1/D19-5004', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.18653/v1/D19-5004', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1910.01160v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.01160v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019', 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
352,http://arxiv.org/abs/1910.00655v2,2020-06-01 15:32:26+00:00,2019-10-01 20:27:51+00:00,Descendant distributions for the impact of mutant contagion on networks,"[arxiv.Result.Author('Jonas S. Juul'), arxiv.Result.Author('Steven H. Strogatz')]","Contagion, broadly construed, refers to anything that can spread infectiously
from peer to peer. Examples include communicable diseases, rumors,
misinformation, ideas, innovations, bank failures, and electrical blackouts.
Sometimes, as in the 1918 Spanish flu epidemic, a contagion mutates at some
point as it spreads through a network. Here, using a simple
susceptible-infected (SI) model of contagion, we explore the downstream impact
of a single mutation event. Assuming that this mutation occurs at a random node
in the contact network, we calculate the distribution of the number of
""descendants,"" $d$, downstream from the initial ""Patient Zero"" mutant. We find
that the tail of the distribution decays as $d^{-2}$ for complete graphs,
random graphs, small-world networks, networks with block-like structure, and
other infinite-dimensional networks. This prediction agrees with the observed
statistics of memes propagating and mutating on Facebook, and is expected to
hold for other effectively infinite-dimensional networks, such as the global
human contact network. In a wider context, our approach suggests a possible
starting point for a mesoscopic theory of contagion. Such a theory would focus
on the paths traced by a spreading contagion, thereby furnishing an
intermediate level of description between that of individual nodes and the
total infected population. We anticipate that contagion pathways will hold
valuable lessons, given their role as the conduits through which single
mutations, innovations, or failures can sweep through a network as a whole.","24 pages, 6 figures","Phys. Rev. Research 2, 033005 (2020)",10.1103/PhysRevResearch.2.033005,physics.soc-ph,"['physics.soc-ph', 'q-bio.PE']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevResearch.2.033005', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1910.00655v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.00655v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.00655v2,"{'id': 'http://arxiv.org/abs/1910.00655v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.00655v2', 'updated': '2020-06-01T15:32:26Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=1, tm_hour=15, tm_min=32, tm_sec=26, tm_wday=0, tm_yday=153, tm_isdst=0), 'published': '2019-10-01T20:27:51Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=1, tm_hour=20, tm_min=27, tm_sec=51, tm_wday=1, tm_yday=274, tm_isdst=0), 'title': 'Descendant distributions for the impact of mutant contagion on networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Descendant distributions for the impact of mutant contagion on networks'}, 'summary': 'Contagion, broadly construed, refers to anything that can spread infectiously\nfrom peer to peer. Examples include communicable diseases, rumors,\nmisinformation, ideas, innovations, bank failures, and electrical blackouts.\nSometimes, as in the 1918 Spanish flu epidemic, a contagion mutates at some\npoint as it spreads through a network. Here, using a simple\nsusceptible-infected (SI) model of contagion, we explore the downstream impact\nof a single mutation event. Assuming that this mutation occurs at a random node\nin the contact network, we calculate the distribution of the number of\n""descendants,"" $d$, downstream from the initial ""Patient Zero"" mutant. We find\nthat the tail of the distribution decays as $d^{-2}$ for complete graphs,\nrandom graphs, small-world networks, networks with block-like structure, and\nother infinite-dimensional networks. This prediction agrees with the observed\nstatistics of memes propagating and mutating on Facebook, and is expected to\nhold for other effectively infinite-dimensional networks, such as the global\nhuman contact network. In a wider context, our approach suggests a possible\nstarting point for a mesoscopic theory of contagion. Such a theory would focus\non the paths traced by a spreading contagion, thereby furnishing an\nintermediate level of description between that of individual nodes and the\ntotal infected population. We anticipate that contagion pathways will hold\nvaluable lessons, given their role as the conduits through which single\nmutations, innovations, or failures can sweep through a network as a whole.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Contagion, broadly construed, refers to anything that can spread infectiously\nfrom peer to peer. Examples include communicable diseases, rumors,\nmisinformation, ideas, innovations, bank failures, and electrical blackouts.\nSometimes, as in the 1918 Spanish flu epidemic, a contagion mutates at some\npoint as it spreads through a network. Here, using a simple\nsusceptible-infected (SI) model of contagion, we explore the downstream impact\nof a single mutation event. Assuming that this mutation occurs at a random node\nin the contact network, we calculate the distribution of the number of\n""descendants,"" $d$, downstream from the initial ""Patient Zero"" mutant. We find\nthat the tail of the distribution decays as $d^{-2}$ for complete graphs,\nrandom graphs, small-world networks, networks with block-like structure, and\nother infinite-dimensional networks. This prediction agrees with the observed\nstatistics of memes propagating and mutating on Facebook, and is expected to\nhold for other effectively infinite-dimensional networks, such as the global\nhuman contact network. In a wider context, our approach suggests a possible\nstarting point for a mesoscopic theory of contagion. Such a theory would focus\non the paths traced by a spreading contagion, thereby furnishing an\nintermediate level of description between that of individual nodes and the\ntotal infected population. We anticipate that contagion pathways will hold\nvaluable lessons, given their role as the conduits through which single\nmutations, innovations, or failures can sweep through a network as a whole.'}, 'authors': [{'name': 'Jonas S. Juul'}, {'name': 'Steven H. Strogatz'}], 'author_detail': {'name': 'Steven H. Strogatz'}, 'author': 'Steven H. Strogatz', 'arxiv_doi': '10.1103/PhysRevResearch.2.033005', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevResearch.2.033005', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1910.00655v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.00655v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '24 pages, 6 figures', 'arxiv_journal_ref': 'Phys. Rev. Research 2, 033005 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
353,http://arxiv.org/abs/1910.00531v2,2019-10-03 19:43:53+00:00,2019-10-01 16:32:59+00:00,On the Influence of Twitter Trolls during the 2016 US Presidential Election,"[arxiv.Result.Author('Nikos Salamanos'), arxiv.Result.Author('Michael J. Jensen'), arxiv.Result.Author('Xinlei He'), arxiv.Result.Author('Yang Chen'), arxiv.Result.Author('Michael Sirivianos')]","It is a widely accepted fact that state-sponsored Twitter accounts operated
during the 2016 US presidential election spreading millions of tweets with
misinformation and inflammatory political content. Whether these social media
campaigns of the so-called ""troll"" accounts were able to manipulate public
opinion is still in question. Here we aim to quantify the influence of troll
accounts and the impact they had on Twitter by analyzing 152.5 million tweets
from 9.9 million users, including 822 troll accounts. The data collected during
the US election campaign, contain original troll tweets before they were
deleted by Twitter. From these data, we constructed a very large interaction
graph; a directed graph of 9.3 million nodes and 169.9 million edges. Recently,
Twitter released datasets on the misinformation campaigns of 8,275
state-sponsored accounts linked to Russia, Iran and Venezuela as part of the
investigation on the foreign interference in the 2016 US election. These data
serve as ground-truth identifier of troll users in our dataset. Using graph
analysis techniques we qualify the diffusion cascades of web and media context
that have been shared by the troll accounts. We present strong evidence that
authentic users were the source of the viral cascades. Although the trolls were
participating in the viral cascades, they did not have a leading role in them
and only four troll accounts were truly influential.","With this version, we are correcting an error in the Acknowledgments
  regarding the research funding that supports this work. The correct one is
  the European Union's Horizon 2020 Research and Innovation program under the
  Cybersecurity CONCORDIA project (Grant Agreement No. 830927)",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1910.00531v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.00531v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.00531v2,"{'id': 'http://arxiv.org/abs/1910.00531v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.00531v2', 'updated': '2019-10-03T19:43:53Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=3, tm_hour=19, tm_min=43, tm_sec=53, tm_wday=3, tm_yday=276, tm_isdst=0), 'published': '2019-10-01T16:32:59Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=1, tm_hour=16, tm_min=32, tm_sec=59, tm_wday=1, tm_yday=274, tm_isdst=0), 'title': 'On the Influence of Twitter Trolls during the 2016 US Presidential\n  Election', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the Influence of Twitter Trolls during the 2016 US Presidential\n  Election'}, 'summary': 'It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called ""troll"" accounts were able to manipulate public\nopinion is still in question. Here we aim to quantify the influence of troll\naccounts and the impact they had on Twitter by analyzing 152.5 million tweets\nfrom 9.9 million users, including 822 troll accounts. The data collected during\nthe US election campaign, contain original troll tweets before they were\ndeleted by Twitter. From these data, we constructed a very large interaction\ngraph; a directed graph of 9.3 million nodes and 169.9 million edges. Recently,\nTwitter released datasets on the misinformation campaigns of 8,275\nstate-sponsored accounts linked to Russia, Iran and Venezuela as part of the\ninvestigation on the foreign interference in the 2016 US election. These data\nserve as ground-truth identifier of troll users in our dataset. Using graph\nanalysis techniques we qualify the diffusion cascades of web and media context\nthat have been shared by the troll accounts. We present strong evidence that\nauthentic users were the source of the viral cascades. Although the trolls were\nparticipating in the viral cascades, they did not have a leading role in them\nand only four troll accounts were truly influential.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called ""troll"" accounts were able to manipulate public\nopinion is still in question. Here we aim to quantify the influence of troll\naccounts and the impact they had on Twitter by analyzing 152.5 million tweets\nfrom 9.9 million users, including 822 troll accounts. The data collected during\nthe US election campaign, contain original troll tweets before they were\ndeleted by Twitter. From these data, we constructed a very large interaction\ngraph; a directed graph of 9.3 million nodes and 169.9 million edges. Recently,\nTwitter released datasets on the misinformation campaigns of 8,275\nstate-sponsored accounts linked to Russia, Iran and Venezuela as part of the\ninvestigation on the foreign interference in the 2016 US election. These data\nserve as ground-truth identifier of troll users in our dataset. Using graph\nanalysis techniques we qualify the diffusion cascades of web and media context\nthat have been shared by the troll accounts. We present strong evidence that\nauthentic users were the source of the viral cascades. Although the trolls were\nparticipating in the viral cascades, they did not have a leading role in them\nand only four troll accounts were truly influential.'}, 'authors': [{'name': 'Nikos Salamanos'}, {'name': 'Michael J. Jensen'}, {'name': 'Xinlei He'}, {'name': 'Yang Chen'}, {'name': 'Michael Sirivianos'}], 'author_detail': {'name': 'Michael Sirivianos'}, 'author': 'Michael Sirivianos', 'arxiv_comment': ""With this version, we are correcting an error in the Acknowledgments\n  regarding the research funding that supports this work. The correct one is\n  the European Union's Horizon 2020 Research and Innovation program under the\n  Cybersecurity CONCORDIA project (Grant Agreement No. 830927)"", 'links': [{'href': 'http://arxiv.org/abs/1910.00531v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.00531v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
354,http://arxiv.org/abs/1910.01458v1,2019-09-19 21:48:03+00:00,2019-09-19 21:48:03+00:00,Attention Based Neural Architecture for Rumor Detection with Author Context Awareness,"[arxiv.Result.Author('Sansiri Tarnpradab'), arxiv.Result.Author('Kien A. Hua')]","The prevalence of social media has made information sharing possible across
the globe. The downside, unfortunately, is the wide spread of misinformation.
Methods applied in most previous rumor classifiers give an equal weight, or
attention, to words in the microblog, and do not take the context beyond
microblog contents into account; therefore, the accuracy becomes plateaued. In
this research, we propose an ensemble neural architecture to detect rumor on
Twitter. The architecture incorporates word attention and context from the
author to enhance the classification performance. In particular, the word-level
attention mechanism enables the architecture to put more emphasis on important
words when constructing the text representation. To derive further context,
microblog posts composed by individual authors are exploited since they can
reflect style and characteristics in spreading information, which are
significant cues to help classify whether the shared content is rumor or
legitimate news. The experiment on the real-world Twitter dataset collected
from two well-known rumor tracking websites demonstrates promising results.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1910.01458v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1910.01458v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1910.01458v1,"{'id': 'http://arxiv.org/abs/1910.01458v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1910.01458v1', 'updated': '2019-09-19T21:48:03Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=19, tm_hour=21, tm_min=48, tm_sec=3, tm_wday=3, tm_yday=262, tm_isdst=0), 'published': '2019-09-19T21:48:03Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=19, tm_hour=21, tm_min=48, tm_sec=3, tm_wday=3, tm_yday=262, tm_isdst=0), 'title': 'Attention Based Neural Architecture for Rumor Detection with Author\n  Context Awareness', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Attention Based Neural Architecture for Rumor Detection with Author\n  Context Awareness'}, 'summary': 'The prevalence of social media has made information sharing possible across\nthe globe. The downside, unfortunately, is the wide spread of misinformation.\nMethods applied in most previous rumor classifiers give an equal weight, or\nattention, to words in the microblog, and do not take the context beyond\nmicroblog contents into account; therefore, the accuracy becomes plateaued. In\nthis research, we propose an ensemble neural architecture to detect rumor on\nTwitter. The architecture incorporates word attention and context from the\nauthor to enhance the classification performance. In particular, the word-level\nattention mechanism enables the architecture to put more emphasis on important\nwords when constructing the text representation. To derive further context,\nmicroblog posts composed by individual authors are exploited since they can\nreflect style and characteristics in spreading information, which are\nsignificant cues to help classify whether the shared content is rumor or\nlegitimate news. The experiment on the real-world Twitter dataset collected\nfrom two well-known rumor tracking websites demonstrates promising results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The prevalence of social media has made information sharing possible across\nthe globe. The downside, unfortunately, is the wide spread of misinformation.\nMethods applied in most previous rumor classifiers give an equal weight, or\nattention, to words in the microblog, and do not take the context beyond\nmicroblog contents into account; therefore, the accuracy becomes plateaued. In\nthis research, we propose an ensemble neural architecture to detect rumor on\nTwitter. The architecture incorporates word attention and context from the\nauthor to enhance the classification performance. In particular, the word-level\nattention mechanism enables the architecture to put more emphasis on important\nwords when constructing the text representation. To derive further context,\nmicroblog posts composed by individual authors are exploited since they can\nreflect style and characteristics in spreading information, which are\nsignificant cues to help classify whether the shared content is rumor or\nlegitimate news. The experiment on the real-world Twitter dataset collected\nfrom two well-known rumor tracking websites demonstrates promising results.'}, 'authors': [{'name': 'Sansiri Tarnpradab'}, {'name': 'Kien A. Hua'}], 'author_detail': {'name': 'Kien A. Hua'}, 'author': 'Kien A. Hua', 'links': [{'href': 'http://arxiv.org/abs/1910.01458v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1910.01458v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
355,http://arxiv.org/abs/1909.08740v2,2019-09-23 14:51:16+00:00,2019-09-18 23:53:24+00:00,Can WhatsApp Counter Misinformation by Limiting Message Forwarding?,"[arxiv.Result.Author('Philipe de Freitas Melo'), arxiv.Result.Author('Carolina Coimbra Vieira'), arxiv.Result.Author('Kiran Garimella'), arxiv.Result.Author('Pedro O. S. Vaz de Melo'), arxiv.Result.Author('Fabrício Benevenuto')]","WhatsApp is the most popular messaging app in the world. The closed nature of
the app, in addition to the ease of transferring multimedia and sharing
information to large-scale groups make WhatsApp unique among other platforms,
where an anonymous encrypted messages can become viral, reaching multiple users
in a short period of time. The personal feeling and immediacy of messages
directly delivered to the user's phone on WhatsApp was extensively abused to
spread unfounded rumors and create misinformation campaigns during recent
elections in Brazil and India. WhatsApp has been deploying measures to mitigate
this problem, such as reducing the limit for forwarding a message to at most
five users at once. Despite the welcomed effort to counter the problem, there
is no evidence so far on the real effectiveness of such restrictions. In this
work, we propose a methodology to evaluate the effectiveness of such measures
on the spreading of misinformation circulating on WhatsApp. We use an
epidemiological model and real data gathered from WhatsApp in Brazil, India and
Indonesia to assess the impact of limiting virality features in this kind of
network. Our results suggest that the current efforts deployed by WhatsApp can
offer significant delays on the information spread, but they are ineffective in
blocking the propagation of misinformation campaigns through public groups when
the content has a high viral nature.",12 pages,,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1909.08740v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.08740v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.08740v2,"{'id': 'http://arxiv.org/abs/1909.08740v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.08740v2', 'updated': '2019-09-23T14:51:16Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=23, tm_hour=14, tm_min=51, tm_sec=16, tm_wday=0, tm_yday=266, tm_isdst=0), 'published': '2019-09-18T23:53:24Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=18, tm_hour=23, tm_min=53, tm_sec=24, tm_wday=2, tm_yday=261, tm_isdst=0), 'title': 'Can WhatsApp Counter Misinformation by Limiting Message Forwarding?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Can WhatsApp Counter Misinformation by Limiting Message Forwarding?'}, 'summary': ""WhatsApp is the most popular messaging app in the world. The closed nature of\nthe app, in addition to the ease of transferring multimedia and sharing\ninformation to large-scale groups make WhatsApp unique among other platforms,\nwhere an anonymous encrypted messages can become viral, reaching multiple users\nin a short period of time. The personal feeling and immediacy of messages\ndirectly delivered to the user's phone on WhatsApp was extensively abused to\nspread unfounded rumors and create misinformation campaigns during recent\nelections in Brazil and India. WhatsApp has been deploying measures to mitigate\nthis problem, such as reducing the limit for forwarding a message to at most\nfive users at once. Despite the welcomed effort to counter the problem, there\nis no evidence so far on the real effectiveness of such restrictions. In this\nwork, we propose a methodology to evaluate the effectiveness of such measures\non the spreading of misinformation circulating on WhatsApp. We use an\nepidemiological model and real data gathered from WhatsApp in Brazil, India and\nIndonesia to assess the impact of limiting virality features in this kind of\nnetwork. Our results suggest that the current efforts deployed by WhatsApp can\noffer significant delays on the information spread, but they are ineffective in\nblocking the propagation of misinformation campaigns through public groups when\nthe content has a high viral nature."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""WhatsApp is the most popular messaging app in the world. The closed nature of\nthe app, in addition to the ease of transferring multimedia and sharing\ninformation to large-scale groups make WhatsApp unique among other platforms,\nwhere an anonymous encrypted messages can become viral, reaching multiple users\nin a short period of time. The personal feeling and immediacy of messages\ndirectly delivered to the user's phone on WhatsApp was extensively abused to\nspread unfounded rumors and create misinformation campaigns during recent\nelections in Brazil and India. WhatsApp has been deploying measures to mitigate\nthis problem, such as reducing the limit for forwarding a message to at most\nfive users at once. Despite the welcomed effort to counter the problem, there\nis no evidence so far on the real effectiveness of such restrictions. In this\nwork, we propose a methodology to evaluate the effectiveness of such measures\non the spreading of misinformation circulating on WhatsApp. We use an\nepidemiological model and real data gathered from WhatsApp in Brazil, India and\nIndonesia to assess the impact of limiting virality features in this kind of\nnetwork. Our results suggest that the current efforts deployed by WhatsApp can\noffer significant delays on the information spread, but they are ineffective in\nblocking the propagation of misinformation campaigns through public groups when\nthe content has a high viral nature.""}, 'authors': [{'name': 'Philipe de Freitas Melo'}, {'name': 'Carolina Coimbra Vieira'}, {'name': 'Kiran Garimella'}, {'name': 'Pedro O. S. Vaz de Melo'}, {'name': 'Fabrício Benevenuto'}], 'author_detail': {'name': 'Fabrício Benevenuto'}, 'author': 'Fabrício Benevenuto', 'arxiv_comment': '12 pages', 'links': [{'href': 'http://arxiv.org/abs/1909.08740v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.08740v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
356,http://arxiv.org/abs/1909.06122v3,2020-07-16 06:44:53+00:00,2019-09-13 10:08:44+00:00,FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized Fake Faces,"[arxiv.Result.Author('Run Wang'), arxiv.Result.Author('Felix Juefei-Xu'), arxiv.Result.Author('Lei Ma'), arxiv.Result.Author('Xiaofei Xie'), arxiv.Result.Author('Yihao Huang'), arxiv.Result.Author('Jian Wang'), arxiv.Result.Author('Yang Liu')]","In recent years, generative adversarial networks (GANs) and its variants have
achieved unprecedented success in image synthesis. They are widely adopted in
synthesizing facial images which brings potential security concerns to humans
as the fakes spread and fuel the misinformation. However, robust detectors of
these AI-synthesized fake faces are still in their infancy and are not ready to
fully tackle this emerging challenge. In this work, we propose a novel
approach, named FakeSpotter, based on monitoring neuron behaviors to spot
AI-synthesized fake faces. The studies on neuron coverage and interactions have
successfully shown that they can be served as testing criteria for deep
learning systems, especially under the settings of being exposed to adversarial
attacks. Here, we conjecture that monitoring neuron behavior can also serve as
an asset in detecting fake faces since layer-by-layer neuron activation
patterns may capture more subtle features that are important for the fake
detector. Experimental results on detecting four types of fake faces
synthesized with the state-of-the-art GANs and evading four perturbation
attacks show the effectiveness and robustness of our approach.","Accepted to IJCAI 2020; SOLE copyright holder is IJCAI (international
  Joint Conferences on Artificial Intelligence), all rights reserved.
  https://www.ijcai.org/Proceedings/2020/333",,,cs.CR,"['cs.CR', 'cs.CV', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1909.06122v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.06122v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.06122v3,"{'id': 'http://arxiv.org/abs/1909.06122v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.06122v3', 'updated': '2020-07-16T06:44:53Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=7, tm_mday=16, tm_hour=6, tm_min=44, tm_sec=53, tm_wday=3, tm_yday=198, tm_isdst=0), 'published': '2019-09-13T10:08:44Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=13, tm_hour=10, tm_min=8, tm_sec=44, tm_wday=4, tm_yday=256, tm_isdst=0), 'title': 'FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized\n  Fake Faces', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized\n  Fake Faces'}, 'summary': 'In recent years, generative adversarial networks (GANs) and its variants have\nachieved unprecedented success in image synthesis. They are widely adopted in\nsynthesizing facial images which brings potential security concerns to humans\nas the fakes spread and fuel the misinformation. However, robust detectors of\nthese AI-synthesized fake faces are still in their infancy and are not ready to\nfully tackle this emerging challenge. In this work, we propose a novel\napproach, named FakeSpotter, based on monitoring neuron behaviors to spot\nAI-synthesized fake faces. The studies on neuron coverage and interactions have\nsuccessfully shown that they can be served as testing criteria for deep\nlearning systems, especially under the settings of being exposed to adversarial\nattacks. Here, we conjecture that monitoring neuron behavior can also serve as\nan asset in detecting fake faces since layer-by-layer neuron activation\npatterns may capture more subtle features that are important for the fake\ndetector. Experimental results on detecting four types of fake faces\nsynthesized with the state-of-the-art GANs and evading four perturbation\nattacks show the effectiveness and robustness of our approach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, generative adversarial networks (GANs) and its variants have\nachieved unprecedented success in image synthesis. They are widely adopted in\nsynthesizing facial images which brings potential security concerns to humans\nas the fakes spread and fuel the misinformation. However, robust detectors of\nthese AI-synthesized fake faces are still in their infancy and are not ready to\nfully tackle this emerging challenge. In this work, we propose a novel\napproach, named FakeSpotter, based on monitoring neuron behaviors to spot\nAI-synthesized fake faces. The studies on neuron coverage and interactions have\nsuccessfully shown that they can be served as testing criteria for deep\nlearning systems, especially under the settings of being exposed to adversarial\nattacks. Here, we conjecture that monitoring neuron behavior can also serve as\nan asset in detecting fake faces since layer-by-layer neuron activation\npatterns may capture more subtle features that are important for the fake\ndetector. Experimental results on detecting four types of fake faces\nsynthesized with the state-of-the-art GANs and evading four perturbation\nattacks show the effectiveness and robustness of our approach.'}, 'authors': [{'name': 'Run Wang'}, {'name': 'Felix Juefei-Xu'}, {'name': 'Lei Ma'}, {'name': 'Xiaofei Xie'}, {'name': 'Yihao Huang'}, {'name': 'Jian Wang'}, {'name': 'Yang Liu'}], 'author_detail': {'name': 'Yang Liu'}, 'author': 'Yang Liu', 'arxiv_comment': 'Accepted to IJCAI 2020; SOLE copyright holder is IJCAI (international\n  Joint Conferences on Artificial Intelligence), all rights reserved.\n  https://www.ijcai.org/Proceedings/2020/333', 'links': [{'href': 'http://arxiv.org/abs/1909.06122v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.06122v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
357,http://arxiv.org/abs/1909.05838v1,2019-09-12 17:44:15+00:00,2019-09-12 17:44:15+00:00,Multilingual Multimodal Digital Deception Detection and Disinformation Spread across Social Platforms,"[arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Ellyn Ayton'), arxiv.Result.Author('Josh Mendoza'), arxiv.Result.Author('Svitlana Volkova')]","Our main contribution in this work is novel results of multilingual models
that go beyond typical applications of rumor or misinformation detection in
English social news content to identify fine-grained classes of digital
deception across multiple languages (e.g. Russian, Spanish, etc.). In addition,
we present models for multimodal deception detection from images and text and
discuss the limitations of image only and text only models. Finally, we
elaborate on the ongoing work on measuring deceptive content (in particular
disinformation) spread across social platforms.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1909.05838v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.05838v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.05838v1,"{'id': 'http://arxiv.org/abs/1909.05838v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.05838v1', 'updated': '2019-09-12T17:44:15Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=12, tm_hour=17, tm_min=44, tm_sec=15, tm_wday=3, tm_yday=255, tm_isdst=0), 'published': '2019-09-12T17:44:15Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=12, tm_hour=17, tm_min=44, tm_sec=15, tm_wday=3, tm_yday=255, tm_isdst=0), 'title': 'Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms'}, 'summary': 'Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.'}, 'authors': [{'name': 'Maria Glenski'}, {'name': 'Ellyn Ayton'}, {'name': 'Josh Mendoza'}, {'name': 'Svitlana Volkova'}], 'author_detail': {'name': 'Svitlana Volkova'}, 'author': 'Svitlana Volkova', 'links': [{'href': 'http://arxiv.org/abs/1909.05838v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.05838v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
358,http://arxiv.org/abs/1909.03654v1,2019-09-09 06:45:07+00:00,2019-09-09 06:45:07+00:00,The Future of Misinformation Detection: New Perspectives and Trends,"[arxiv.Result.Author('Bin Guo'), arxiv.Result.Author('Yasan Ding'), arxiv.Result.Author('Lina Yao'), arxiv.Result.Author('Yunji Liang'), arxiv.Result.Author('Zhiwen Yu')]","The massive spread of misinformation in social networks has become a global
risk, implicitly influencing public opinion and threatening social/political
development. Misinformation detection (MID) has thus become a surging research
topic in recent years. As a promising and rapid developing research field, we
find that many efforts have been paid to new research problems and approaches
of MID. Therefore, it is necessary to give a comprehensive review of the new
research trends of MID. We first give a brief review of the literature history
of MID, based on which we present several new research challenges and
techniques of it, including early detection, detection by multimodal data
fusion, and explanatory detection. We further investigate the extraction and
usage of various crowd intelligence in MID, which paves a promising way to
tackle MID challenges. Finally, we give our own views on the open issues and
future research directions of MID, such as model adaptivity/generality to new
events, embracing of novel machine learning models, explanatory detection
models, and so on.",Submitted to ACM Computing Surveys,,,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1909.03654v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.03654v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.03654v1,"{'id': 'http://arxiv.org/abs/1909.03654v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.03654v1', 'updated': '2019-09-09T06:45:07Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=9, tm_hour=6, tm_min=45, tm_sec=7, tm_wday=0, tm_yday=252, tm_isdst=0), 'published': '2019-09-09T06:45:07Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=9, tm_hour=6, tm_min=45, tm_sec=7, tm_wday=0, tm_yday=252, tm_isdst=0), 'title': 'The Future of Misinformation Detection: New Perspectives and Trends', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Future of Misinformation Detection: New Perspectives and Trends'}, 'summary': 'The massive spread of misinformation in social networks has become a global\nrisk, implicitly influencing public opinion and threatening social/political\ndevelopment. Misinformation detection (MID) has thus become a surging research\ntopic in recent years. As a promising and rapid developing research field, we\nfind that many efforts have been paid to new research problems and approaches\nof MID. Therefore, it is necessary to give a comprehensive review of the new\nresearch trends of MID. We first give a brief review of the literature history\nof MID, based on which we present several new research challenges and\ntechniques of it, including early detection, detection by multimodal data\nfusion, and explanatory detection. We further investigate the extraction and\nusage of various crowd intelligence in MID, which paves a promising way to\ntackle MID challenges. Finally, we give our own views on the open issues and\nfuture research directions of MID, such as model adaptivity/generality to new\nevents, embracing of novel machine learning models, explanatory detection\nmodels, and so on.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The massive spread of misinformation in social networks has become a global\nrisk, implicitly influencing public opinion and threatening social/political\ndevelopment. Misinformation detection (MID) has thus become a surging research\ntopic in recent years. As a promising and rapid developing research field, we\nfind that many efforts have been paid to new research problems and approaches\nof MID. Therefore, it is necessary to give a comprehensive review of the new\nresearch trends of MID. We first give a brief review of the literature history\nof MID, based on which we present several new research challenges and\ntechniques of it, including early detection, detection by multimodal data\nfusion, and explanatory detection. We further investigate the extraction and\nusage of various crowd intelligence in MID, which paves a promising way to\ntackle MID challenges. Finally, we give our own views on the open issues and\nfuture research directions of MID, such as model adaptivity/generality to new\nevents, embracing of novel machine learning models, explanatory detection\nmodels, and so on.'}, 'authors': [{'name': 'Bin Guo'}, {'name': 'Yasan Ding'}, {'name': 'Lina Yao'}, {'name': 'Yunji Liang'}, {'name': 'Zhiwen Yu'}], 'author_detail': {'name': 'Zhiwen Yu'}, 'author': 'Zhiwen Yu', 'arxiv_comment': 'Submitted to ACM Computing Surveys', 'links': [{'href': 'http://arxiv.org/abs/1909.03654v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.03654v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
359,http://arxiv.org/abs/1909.01543v1,2019-09-04 03:41:44+00:00,2019-09-04 03:41:44+00:00,Towards Automatic Detection of Misinformation in Online Medical Videos,"[arxiv.Result.Author('Rui Hou'), arxiv.Result.Author('Verónica Pérez-Rosas'), arxiv.Result.Author('Stacy Loeb'), arxiv.Result.Author('Rada Mihalcea')]","Recent years have witnessed a significant increase in the online sharing of
medical information, with videos representing a large fraction of such online
sources. Previous studies have however shown that more than half of the
health-related videos on platforms such as YouTube contain misleading
information and biases. Hence, it is crucial to build computational tools that
can help evaluate the quality of these videos so that users can obtain accurate
information to help inform their decisions. In this study, we focus on the
automatic detection of misinformation in YouTube videos. We select prostate
cancer videos as our entry point to tackle this problem. The contribution of
this paper is twofold. First, we introduce a new dataset consisting of 250
videos related to prostate cancer manually annotated for misinformation.
Second, we explore the use of linguistic, acoustic, and user engagement
features for the development of classification models to identify
misinformation. Using a series of ablation experiments, we show that we can
build automatic models with accuracies of up to 74%, corresponding to a 76.5%
precision and 73.2% recall for misinformative instances.",,,,cs.LG,"['cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1909.01543v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.01543v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.01543v1,"{'id': 'http://arxiv.org/abs/1909.01543v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.01543v1', 'updated': '2019-09-04T03:41:44Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=3, tm_min=41, tm_sec=44, tm_wday=2, tm_yday=247, tm_isdst=0), 'published': '2019-09-04T03:41:44Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=4, tm_hour=3, tm_min=41, tm_sec=44, tm_wday=2, tm_yday=247, tm_isdst=0), 'title': 'Towards Automatic Detection of Misinformation in Online Medical Videos', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Towards Automatic Detection of Misinformation in Online Medical Videos'}, 'summary': 'Recent years have witnessed a significant increase in the online sharing of\nmedical information, with videos representing a large fraction of such online\nsources. Previous studies have however shown that more than half of the\nhealth-related videos on platforms such as YouTube contain misleading\ninformation and biases. Hence, it is crucial to build computational tools that\ncan help evaluate the quality of these videos so that users can obtain accurate\ninformation to help inform their decisions. In this study, we focus on the\nautomatic detection of misinformation in YouTube videos. We select prostate\ncancer videos as our entry point to tackle this problem. The contribution of\nthis paper is twofold. First, we introduce a new dataset consisting of 250\nvideos related to prostate cancer manually annotated for misinformation.\nSecond, we explore the use of linguistic, acoustic, and user engagement\nfeatures for the development of classification models to identify\nmisinformation. Using a series of ablation experiments, we show that we can\nbuild automatic models with accuracies of up to 74%, corresponding to a 76.5%\nprecision and 73.2% recall for misinformative instances.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed a significant increase in the online sharing of\nmedical information, with videos representing a large fraction of such online\nsources. Previous studies have however shown that more than half of the\nhealth-related videos on platforms such as YouTube contain misleading\ninformation and biases. Hence, it is crucial to build computational tools that\ncan help evaluate the quality of these videos so that users can obtain accurate\ninformation to help inform their decisions. In this study, we focus on the\nautomatic detection of misinformation in YouTube videos. We select prostate\ncancer videos as our entry point to tackle this problem. The contribution of\nthis paper is twofold. First, we introduce a new dataset consisting of 250\nvideos related to prostate cancer manually annotated for misinformation.\nSecond, we explore the use of linguistic, acoustic, and user engagement\nfeatures for the development of classification models to identify\nmisinformation. Using a series of ablation experiments, we show that we can\nbuild automatic models with accuracies of up to 74%, corresponding to a 76.5%\nprecision and 73.2% recall for misinformative instances.'}, 'authors': [{'name': 'Rui Hou'}, {'name': 'Verónica Pérez-Rosas'}, {'name': 'Stacy Loeb'}, {'name': 'Rada Mihalcea'}], 'author_detail': {'name': 'Rada Mihalcea'}, 'author': 'Rada Mihalcea', 'links': [{'href': 'http://arxiv.org/abs/1909.01543v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.01543v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
360,http://arxiv.org/abs/1909.00397v1,2019-09-01 13:32:08+00:00,2019-09-01 13:32:08+00:00,Misinformation spreading on correlated multiplex networks,"[arxiv.Result.Author('Jiajun Xian'), arxiv.Result.Author('Dan Yang'), arxiv.Result.Author('Liming Pan'), arxiv.Result.Author('Wei Wang'), arxiv.Result.Author('Zhen Wang')]","The numerous expanding online social networks offer fast channels for
misinformation spreading, which could have a serious impact on socioeconomic
systems. Researchers across multiple areas have paid attention to this issue
with a view of addressing it. However, no systematical theoretical study has
been performed to date on observing misinformation spreading on correlated
multiplex networks. In this study, we propose a multiplex network-based
misinformation spreading model, considering the fact that each individual can
obtain misinformation from multiple platforms. Subsequently, we develop a
heterogeneous edge-base compartmental theory to comprehend the spreading
dynamics of our proposed model. In addition, we establish an analytical method
based on stability analysis to obtain the misinformation outbreak threshold. On
the basis of these theories, we finally analyze the influence of different
dynamical and structural parameters on the misinformation spreading dynamics.
Results show that the misinformation outbreak size $R(\infty)$ grows
continuously with the effective transmission probability $\beta$ once $\beta$
exceeds a certain value, that is, the outbreak threshold $\beta_c$. A large
average degrees, strong degree heterogeneity, or positive inter-layer
correlation will reduce $\beta_c$, accelerating the outbreak of misinformation.
Besides, increasing the degree heterogeneity or a more positive inter-layer
correlation will both enlarge (reduce) $R(\infty)$ for small (large) values of
$\beta$. Our systematic theoretical analysis results agree well with the
numerical simulation results. Our proposed model and accurate theoretical
analysis will serve as a useful framework to understand and predict the
spreading dynamics of misinformation on multiplex networks, and thereby pave
the way to address this serious issue.",,,10.1063/1.5121394,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1063/1.5121394', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1909.00397v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1909.00397v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1909.00397v1,"{'id': 'http://arxiv.org/abs/1909.00397v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1909.00397v1', 'updated': '2019-09-01T13:32:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=1, tm_hour=13, tm_min=32, tm_sec=8, tm_wday=6, tm_yday=244, tm_isdst=0), 'published': '2019-09-01T13:32:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=1, tm_hour=13, tm_min=32, tm_sec=8, tm_wday=6, tm_yday=244, tm_isdst=0), 'title': 'Misinformation spreading on correlated multiplex networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation spreading on correlated multiplex networks'}, 'summary': 'The numerous expanding online social networks offer fast channels for\nmisinformation spreading, which could have a serious impact on socioeconomic\nsystems. Researchers across multiple areas have paid attention to this issue\nwith a view of addressing it. However, no systematical theoretical study has\nbeen performed to date on observing misinformation spreading on correlated\nmultiplex networks. In this study, we propose a multiplex network-based\nmisinformation spreading model, considering the fact that each individual can\nobtain misinformation from multiple platforms. Subsequently, we develop a\nheterogeneous edge-base compartmental theory to comprehend the spreading\ndynamics of our proposed model. In addition, we establish an analytical method\nbased on stability analysis to obtain the misinformation outbreak threshold. On\nthe basis of these theories, we finally analyze the influence of different\ndynamical and structural parameters on the misinformation spreading dynamics.\nResults show that the misinformation outbreak size $R(\\infty)$ grows\ncontinuously with the effective transmission probability $\\beta$ once $\\beta$\nexceeds a certain value, that is, the outbreak threshold $\\beta_c$. A large\naverage degrees, strong degree heterogeneity, or positive inter-layer\ncorrelation will reduce $\\beta_c$, accelerating the outbreak of misinformation.\nBesides, increasing the degree heterogeneity or a more positive inter-layer\ncorrelation will both enlarge (reduce) $R(\\infty)$ for small (large) values of\n$\\beta$. Our systematic theoretical analysis results agree well with the\nnumerical simulation results. Our proposed model and accurate theoretical\nanalysis will serve as a useful framework to understand and predict the\nspreading dynamics of misinformation on multiplex networks, and thereby pave\nthe way to address this serious issue.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The numerous expanding online social networks offer fast channels for\nmisinformation spreading, which could have a serious impact on socioeconomic\nsystems. Researchers across multiple areas have paid attention to this issue\nwith a view of addressing it. However, no systematical theoretical study has\nbeen performed to date on observing misinformation spreading on correlated\nmultiplex networks. In this study, we propose a multiplex network-based\nmisinformation spreading model, considering the fact that each individual can\nobtain misinformation from multiple platforms. Subsequently, we develop a\nheterogeneous edge-base compartmental theory to comprehend the spreading\ndynamics of our proposed model. In addition, we establish an analytical method\nbased on stability analysis to obtain the misinformation outbreak threshold. On\nthe basis of these theories, we finally analyze the influence of different\ndynamical and structural parameters on the misinformation spreading dynamics.\nResults show that the misinformation outbreak size $R(\\infty)$ grows\ncontinuously with the effective transmission probability $\\beta$ once $\\beta$\nexceeds a certain value, that is, the outbreak threshold $\\beta_c$. A large\naverage degrees, strong degree heterogeneity, or positive inter-layer\ncorrelation will reduce $\\beta_c$, accelerating the outbreak of misinformation.\nBesides, increasing the degree heterogeneity or a more positive inter-layer\ncorrelation will both enlarge (reduce) $R(\\infty)$ for small (large) values of\n$\\beta$. Our systematic theoretical analysis results agree well with the\nnumerical simulation results. Our proposed model and accurate theoretical\nanalysis will serve as a useful framework to understand and predict the\nspreading dynamics of misinformation on multiplex networks, and thereby pave\nthe way to address this serious issue.'}, 'authors': [{'name': 'Jiajun Xian'}, {'name': 'Dan Yang'}, {'name': 'Liming Pan'}, {'name': 'Wei Wang'}, {'name': 'Zhen Wang'}], 'author_detail': {'name': 'Zhen Wang'}, 'author': 'Zhen Wang', 'arxiv_doi': '10.1063/1.5121394', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1063/1.5121394', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1909.00397v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1909.00397v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
361,http://arxiv.org/abs/1908.09805v2,2020-02-20 18:32:33+00:00,2019-08-26 17:23:22+00:00,The Limitations of Stylometry for Detecting Machine-Generated Fake News,"[arxiv.Result.Author('Tal Schuster'), arxiv.Result.Author('Roei Schuster'), arxiv.Result.Author('Darsh J Shah'), arxiv.Result.Author('Regina Barzilay')]","Recent developments in neural language models (LMs) have raised concerns
about their potential misuse for automatically spreading misinformation. In
light of these concerns, several studies have proposed to detect
machine-generated fake news by capturing their stylistic differences from
human-written text. These approaches, broadly termed stylometry, have found
success in source attribution and misinformation detection in human-written
texts. However, in this work, we show that stylometry is limited against
machine-generated misinformation. While humans speak differently when trying to
deceive, LMs generate stylistically consistent text, regardless of underlying
motive. Thus, though stylometry can successfully prevent impersonation by
identifying text provenance, it fails to distinguish legitimate LM applications
from those that introduce false information. We create two benchmarks
demonstrating the stylistic similarity between malicious and legitimate uses of
LMs, employed in auto-completion and editing-assistance settings. Our findings
highlight the need for non-stylometry approaches in detecting machine-generated
misinformation, and open up the discussion on the desired evaluation
benchmarks.","Accepted for Computational Linguistics journal (squib). Previously
  posted with title ""Are We Safe Yet? The Limitations of Distributional
  Features for Fake News Detection""",,,cs.CL,"['cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1908.09805v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.09805v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.09805v2,"{'id': 'http://arxiv.org/abs/1908.09805v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.09805v2', 'updated': '2020-02-20T18:32:33Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=32, tm_sec=33, tm_wday=3, tm_yday=51, tm_isdst=0), 'published': '2019-08-26T17:23:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=26, tm_hour=17, tm_min=23, tm_sec=22, tm_wday=0, tm_yday=238, tm_isdst=0), 'title': 'The Limitations of Stylometry for Detecting Machine-Generated Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Limitations of Stylometry for Detecting Machine-Generated Fake News'}, 'summary': 'Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.'}, 'authors': [{'name': 'Tal Schuster'}, {'name': 'Roei Schuster'}, {'name': 'Darsh J Shah'}, {'name': 'Regina Barzilay'}], 'author_detail': {'name': 'Regina Barzilay'}, 'author': 'Regina Barzilay', 'arxiv_comment': 'Accepted for Computational Linguistics journal (squib). Previously\n  posted with title ""Are We Safe Yet? The Limitations of Distributional\n  Features for Fake News Detection""', 'links': [{'href': 'http://arxiv.org/abs/1908.09805v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.09805v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
362,http://arxiv.org/abs/1908.05992v1,2019-08-16 14:43:13+00:00,2019-08-16 14:43:13+00:00,Homophily on social networks changes evolutionary advantage in competitive information diffusion,"[arxiv.Result.Author('Longzhao Liu'), arxiv.Result.Author('Xin Wang'), arxiv.Result.Author('Yi Zheng'), arxiv.Result.Author('Wenyi Fang'), arxiv.Result.Author('Shaoting Tang'), arxiv.Result.Author('Zhiming Zheng')]","Competitive information diffusion on large-scale social networks reveals
fundamental characteristics of rumor contagions and has profound influence on
public opinion formation. There has been growing interest in exploring
dynamical mechanisms of the competing evolutions recently. Nevertheless, the
impacts of population homophily, which determines powerful collective human
behaviors, remains unclear. In this paper, we incorporate homophily effects
into a modified competitive ignorant-spreader-ignorant (SIS) rumor diffusion
model with generalized population preference. Using microscopic Markov chain
approach, we first derive the phase diagram of competing diffusion results and
examine how competitive information spreads and evolves on social networks. We
then explore the detailed effects of homophily, which is modeled by a rewiring
mechanism. Results show that homophily promotes the formation of divided ""echo
chambers"" and protects the disadvantaged information from extinction, which
further changes or even reverses the evolutionary advantage, i.e., the
difference of final proportions of the competitive information. We highlight
the conclusion that the reversals may happen only when the initially
disadvantaged information has stronger transmission ability, owning diffusion
advantage over the other one. Our framework provides profound insight into
competing dynamics with population homophily, which may pave ways for further
controlling misinformation and guiding public belief systems. Moreover, the
reversing condition sheds light on designing effective competing strategies in
many real scenarios.",,,10.1088/1367-2630/ab623c,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1088/1367-2630/ab623c', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1908.05992v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.05992v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.05992v1,"{'id': 'http://arxiv.org/abs/1908.05992v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.05992v1', 'updated': '2019-08-16T14:43:13Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=16, tm_hour=14, tm_min=43, tm_sec=13, tm_wday=4, tm_yday=228, tm_isdst=0), 'published': '2019-08-16T14:43:13Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=16, tm_hour=14, tm_min=43, tm_sec=13, tm_wday=4, tm_yday=228, tm_isdst=0), 'title': 'Homophily on social networks changes evolutionary advantage in\n  competitive information diffusion', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Homophily on social networks changes evolutionary advantage in\n  competitive information diffusion'}, 'summary': 'Competitive information diffusion on large-scale social networks reveals\nfundamental characteristics of rumor contagions and has profound influence on\npublic opinion formation. There has been growing interest in exploring\ndynamical mechanisms of the competing evolutions recently. Nevertheless, the\nimpacts of population homophily, which determines powerful collective human\nbehaviors, remains unclear. In this paper, we incorporate homophily effects\ninto a modified competitive ignorant-spreader-ignorant (SIS) rumor diffusion\nmodel with generalized population preference. Using microscopic Markov chain\napproach, we first derive the phase diagram of competing diffusion results and\nexamine how competitive information spreads and evolves on social networks. We\nthen explore the detailed effects of homophily, which is modeled by a rewiring\nmechanism. Results show that homophily promotes the formation of divided ""echo\nchambers"" and protects the disadvantaged information from extinction, which\nfurther changes or even reverses the evolutionary advantage, i.e., the\ndifference of final proportions of the competitive information. We highlight\nthe conclusion that the reversals may happen only when the initially\ndisadvantaged information has stronger transmission ability, owning diffusion\nadvantage over the other one. Our framework provides profound insight into\ncompeting dynamics with population homophily, which may pave ways for further\ncontrolling misinformation and guiding public belief systems. Moreover, the\nreversing condition sheds light on designing effective competing strategies in\nmany real scenarios.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Competitive information diffusion on large-scale social networks reveals\nfundamental characteristics of rumor contagions and has profound influence on\npublic opinion formation. There has been growing interest in exploring\ndynamical mechanisms of the competing evolutions recently. Nevertheless, the\nimpacts of population homophily, which determines powerful collective human\nbehaviors, remains unclear. In this paper, we incorporate homophily effects\ninto a modified competitive ignorant-spreader-ignorant (SIS) rumor diffusion\nmodel with generalized population preference. Using microscopic Markov chain\napproach, we first derive the phase diagram of competing diffusion results and\nexamine how competitive information spreads and evolves on social networks. We\nthen explore the detailed effects of homophily, which is modeled by a rewiring\nmechanism. Results show that homophily promotes the formation of divided ""echo\nchambers"" and protects the disadvantaged information from extinction, which\nfurther changes or even reverses the evolutionary advantage, i.e., the\ndifference of final proportions of the competitive information. We highlight\nthe conclusion that the reversals may happen only when the initially\ndisadvantaged information has stronger transmission ability, owning diffusion\nadvantage over the other one. Our framework provides profound insight into\ncompeting dynamics with population homophily, which may pave ways for further\ncontrolling misinformation and guiding public belief systems. Moreover, the\nreversing condition sheds light on designing effective competing strategies in\nmany real scenarios.'}, 'authors': [{'name': 'Longzhao Liu'}, {'name': 'Xin Wang'}, {'name': 'Yi Zheng'}, {'name': 'Wenyi Fang'}, {'name': 'Shaoting Tang'}, {'name': 'Zhiming Zheng'}], 'author_detail': {'name': 'Zhiming Zheng'}, 'author': 'Zhiming Zheng', 'arxiv_doi': '10.1088/1367-2630/ab623c', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1088/1367-2630/ab623c', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1908.05992v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.05992v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
363,http://arxiv.org/abs/1908.01760v1,2019-08-05 17:59:44+00:00,2019-08-05 17:59:44+00:00,The Myths of Our Time: Fake News,"[arxiv.Result.Author('Vít Růžička'), arxiv.Result.Author('Eunsu Kang'), arxiv.Result.Author('David Gordon'), arxiv.Result.Author('Ankita Patel'), arxiv.Result.Author('Jacqui Fashimpaur'), arxiv.Result.Author('Manzil Zaheer')]","While the purpose of most fake news is misinformation and political
propaganda, our team sees it as a new type of myth that is created by people in
the age of internet identities and artificial intelligence. Seeking insights on
the fear and desire hidden underneath these modified or generated stories, we
use machine learning methods to generate fake articles and present them in the
form of an online news blog. This paper aims to share the details of our
pipeline and the techniques used for full generation of fake news, from dataset
collection to presentation as a media art project on the internet.","5 pages, 5 figures, in proceedings of International Symposium on
  Electronic Art 2019 (ISEA)","Proceedings of International Symposium on Electronic Art 2019
  (ISEA), pages 494-498",,cs.LG,"['cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1908.01760v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.01760v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.01760v1,"{'id': 'http://arxiv.org/abs/1908.01760v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.01760v1', 'updated': '2019-08-05T17:59:44Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=5, tm_hour=17, tm_min=59, tm_sec=44, tm_wday=0, tm_yday=217, tm_isdst=0), 'published': '2019-08-05T17:59:44Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=5, tm_hour=17, tm_min=59, tm_sec=44, tm_wday=0, tm_yday=217, tm_isdst=0), 'title': 'The Myths of Our Time: Fake News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Myths of Our Time: Fake News'}, 'summary': 'While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.'}, 'authors': [{'name': 'Vít Růžička'}, {'name': 'Eunsu Kang'}, {'name': 'David Gordon'}, {'name': 'Ankita Patel'}, {'name': 'Jacqui Fashimpaur'}, {'name': 'Manzil Zaheer'}], 'author_detail': {'name': 'Manzil Zaheer'}, 'author': 'Manzil Zaheer', 'arxiv_comment': '5 pages, 5 figures, in proceedings of International Symposium on\n  Electronic Art 2019 (ISEA)', 'arxiv_journal_ref': 'Proceedings of International Symposium on Electronic Art 2019\n  (ISEA), pages 494-498', 'links': [{'href': 'http://arxiv.org/abs/1908.01760v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.01760v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
364,http://arxiv.org/abs/1908.00153v2,2019-08-29 00:46:25+00:00,2019-08-01 00:28:57+00:00,Hateful People or Hateful Bots? Detection and Characterization of Bots Spreading Religious Hatred in Arabic Social Media,"[arxiv.Result.Author('Nuha Albadi'), arxiv.Result.Author('Maram Kurdi'), arxiv.Result.Author('Shivakant Mishra')]","Arabic Twitter space is crawling with bots that fuel political feuds, spread
misinformation, and proliferate sectarian rhetoric. While efforts have long
existed to analyze and detect English bots, Arabic bot detection and
characterization remains largely understudied. In this work, we contribute new
insights into the role of bots in spreading religious hatred on Arabic Twitter
and introduce a novel regression model that can accurately identify Arabic
language bots. Our assessment shows that existing tools that are highly
accurate in detecting English bots don't perform as well on Arabic bots. We
identify the possible reasons for this poor performance, perform a thorough
analysis of linguistic, content, behavioral and network features, and report on
the most informative features that distinguish Arabic bots from humans as well
as the differences between Arabic and English bots. Our results mark an
important step toward understanding the behavior of malicious bots on Arabic
Twitter and pave the way for a more effective Arabic bot detection tools.",,"Proc. ACM Hum.-Comput. Interact. 3, CSCW: Article 61 (2019)",10.1145/3359163,cs.SI,"['cs.SI', 'cs.CL']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3359163', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1908.00153v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1908.00153v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1908.00153v2,"{'id': 'http://arxiv.org/abs/1908.00153v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1908.00153v2', 'updated': '2019-08-29T00:46:25Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=29, tm_hour=0, tm_min=46, tm_sec=25, tm_wday=3, tm_yday=241, tm_isdst=0), 'published': '2019-08-01T00:28:57Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=8, tm_mday=1, tm_hour=0, tm_min=28, tm_sec=57, tm_wday=3, tm_yday=213, tm_isdst=0), 'title': 'Hateful People or Hateful Bots? Detection and Characterization of Bots\n  Spreading Religious Hatred in Arabic Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hateful People or Hateful Bots? Detection and Characterization of Bots\n  Spreading Religious Hatred in Arabic Social Media'}, 'summary': ""Arabic Twitter space is crawling with bots that fuel political feuds, spread\nmisinformation, and proliferate sectarian rhetoric. While efforts have long\nexisted to analyze and detect English bots, Arabic bot detection and\ncharacterization remains largely understudied. In this work, we contribute new\ninsights into the role of bots in spreading religious hatred on Arabic Twitter\nand introduce a novel regression model that can accurately identify Arabic\nlanguage bots. Our assessment shows that existing tools that are highly\naccurate in detecting English bots don't perform as well on Arabic bots. We\nidentify the possible reasons for this poor performance, perform a thorough\nanalysis of linguistic, content, behavioral and network features, and report on\nthe most informative features that distinguish Arabic bots from humans as well\nas the differences between Arabic and English bots. Our results mark an\nimportant step toward understanding the behavior of malicious bots on Arabic\nTwitter and pave the way for a more effective Arabic bot detection tools."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Arabic Twitter space is crawling with bots that fuel political feuds, spread\nmisinformation, and proliferate sectarian rhetoric. While efforts have long\nexisted to analyze and detect English bots, Arabic bot detection and\ncharacterization remains largely understudied. In this work, we contribute new\ninsights into the role of bots in spreading religious hatred on Arabic Twitter\nand introduce a novel regression model that can accurately identify Arabic\nlanguage bots. Our assessment shows that existing tools that are highly\naccurate in detecting English bots don't perform as well on Arabic bots. We\nidentify the possible reasons for this poor performance, perform a thorough\nanalysis of linguistic, content, behavioral and network features, and report on\nthe most informative features that distinguish Arabic bots from humans as well\nas the differences between Arabic and English bots. Our results mark an\nimportant step toward understanding the behavior of malicious bots on Arabic\nTwitter and pave the way for a more effective Arabic bot detection tools.""}, 'authors': [{'name': 'Nuha Albadi'}, {'name': 'Maram Kurdi'}, {'name': 'Shivakant Mishra'}], 'author_detail': {'name': 'Shivakant Mishra'}, 'author': 'Shivakant Mishra', 'arxiv_doi': '10.1145/3359163', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3359163', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1908.00153v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1908.00153v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Proc. ACM Hum.-Comput. Interact. 3, CSCW: Article 61 (2019)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
365,http://arxiv.org/abs/1907.11543v2,2019-07-29 03:14:27+00:00,2019-07-26 12:52:57+00:00,Entropy-Regularized Stochastic Games,"[arxiv.Result.Author('Yagiz Savas'), arxiv.Result.Author('Mohamadreza Ahmadi'), arxiv.Result.Author('Takashi Tanaka'), arxiv.Result.Author('Ufuk Topcu')]","In two-player zero-sum stochastic games, where two competing players make
decisions under uncertainty, a pair of optimal strategies is traditionally
described by Nash equilibrium and computed under the assumption that the
players have perfect information about the stochastic transition model of the
environment. However, implementing such strategies may make the players
vulnerable to unforeseen changes in the environment. In this paper, we
introduce entropy-regularized stochastic games where each player aims to
maximize the causal entropy of its strategy in addition to its expected payoff.
The regularization term balances each player's rationality with its belief
about the level of misinformation about the transition model. We consider both
entropy-regularized $N$-stage and entropy-regularized discounted stochastic
games, and establish the existence of a value in both games. Moreover, we prove
the sufficiency of Markovian and stationary mixed strategies to attain the
value, respectively, in $N$-stage and discounted games. Finally, we present
algorithms, which are based on convex optimization problems, to compute the
optimal strategies. In a numerical example, we demonstrate the proposed method
on a motion planning scenario and illustrate the effect of the regularization
term on the expected payoff.",Corrected typos,,,math.OC,['math.OC'],"[arxiv.Result.Link('http://arxiv.org/abs/1907.11543v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.11543v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.11543v2,"{'id': 'http://arxiv.org/abs/1907.11543v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.11543v2', 'updated': '2019-07-29T03:14:27Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=29, tm_hour=3, tm_min=14, tm_sec=27, tm_wday=0, tm_yday=210, tm_isdst=0), 'published': '2019-07-26T12:52:57Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=26, tm_hour=12, tm_min=52, tm_sec=57, tm_wday=4, tm_yday=207, tm_isdst=0), 'title': 'Entropy-Regularized Stochastic Games', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Entropy-Regularized Stochastic Games'}, 'summary': ""In two-player zero-sum stochastic games, where two competing players make\ndecisions under uncertainty, a pair of optimal strategies is traditionally\ndescribed by Nash equilibrium and computed under the assumption that the\nplayers have perfect information about the stochastic transition model of the\nenvironment. However, implementing such strategies may make the players\nvulnerable to unforeseen changes in the environment. In this paper, we\nintroduce entropy-regularized stochastic games where each player aims to\nmaximize the causal entropy of its strategy in addition to its expected payoff.\nThe regularization term balances each player's rationality with its belief\nabout the level of misinformation about the transition model. We consider both\nentropy-regularized $N$-stage and entropy-regularized discounted stochastic\ngames, and establish the existence of a value in both games. Moreover, we prove\nthe sufficiency of Markovian and stationary mixed strategies to attain the\nvalue, respectively, in $N$-stage and discounted games. Finally, we present\nalgorithms, which are based on convex optimization problems, to compute the\noptimal strategies. In a numerical example, we demonstrate the proposed method\non a motion planning scenario and illustrate the effect of the regularization\nterm on the expected payoff."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In two-player zero-sum stochastic games, where two competing players make\ndecisions under uncertainty, a pair of optimal strategies is traditionally\ndescribed by Nash equilibrium and computed under the assumption that the\nplayers have perfect information about the stochastic transition model of the\nenvironment. However, implementing such strategies may make the players\nvulnerable to unforeseen changes in the environment. In this paper, we\nintroduce entropy-regularized stochastic games where each player aims to\nmaximize the causal entropy of its strategy in addition to its expected payoff.\nThe regularization term balances each player's rationality with its belief\nabout the level of misinformation about the transition model. We consider both\nentropy-regularized $N$-stage and entropy-regularized discounted stochastic\ngames, and establish the existence of a value in both games. Moreover, we prove\nthe sufficiency of Markovian and stationary mixed strategies to attain the\nvalue, respectively, in $N$-stage and discounted games. Finally, we present\nalgorithms, which are based on convex optimization problems, to compute the\noptimal strategies. In a numerical example, we demonstrate the proposed method\non a motion planning scenario and illustrate the effect of the regularization\nterm on the expected payoff.""}, 'authors': [{'name': 'Yagiz Savas'}, {'name': 'Mohamadreza Ahmadi'}, {'name': 'Takashi Tanaka'}, {'name': 'Ufuk Topcu'}], 'author_detail': {'name': 'Ufuk Topcu'}, 'author': 'Ufuk Topcu', 'arxiv_comment': 'Corrected typos', 'links': [{'href': 'http://arxiv.org/abs/1907.11543v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.11543v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
366,http://arxiv.org/abs/1907.08043v1,2019-07-18 13:38:22+00:00,2019-07-18 13:38:22+00:00,Embedding Climate Change Engagement in Astronomy Education and Research,"[arxiv.Result.Author('Kathryn Williamson'), arxiv.Result.Author('Travis A. Rector'), arxiv.Result.Author('James Lowenthal')]","This White Paper is a call to action for astronomers to respond to climate
change with a large structural transition within our profession. Many
astronomers are deeply concerned about climate change and act upon it in their
personal and professional lives, and many organizations within astronomy have
incorporated incremental changes. We need a collective impact model to better
network and grow our efforts so that we can achieve results that are on the
scale appropriate to address climate change at the necessary level indicated by
scientific research; e.g., becoming carbon neutral by 2050. We need to
implement strategies within two primary drivers of our field: (1) Education and
Outreach, and (2) Research Practices and Infrastructure. (1) In the classroom
and through public talks, astronomers reach a large audience. Astronomy is
closely connected to the science of climate change, and it is arguably the most
important topic we include in our curriculum. Due to misinformation and
disinformation, climate change communication is different than for other areas
of science. We therefore need to expand our communication and implement
effective strategies, for which there is now a considerable body of research.
(2) On a per-person basis astronomers have an outsized carbon impact. There are
numerous ways we can reduce our footprint; e.g., in the design and operation of
telescope facilities and in the optimization and reduction of travel.
Fortunately, many of these solutions are win-win scenarios, e.g., increasing
the online presence of conferences will reduce the carbon footprint while
increasing participation, especially for astronomers working with fewer
financial resources. Astronomers have an obligation to act on climate change in
every way possible, and we need to do it now. In this White Paper, we outline a
plan for collective impact using a Networked Improvement Community (NIC)
approach.","Submitted as a State of the Profession White Paper for the Astro2020
  Decadal Survey (10 pages, 1 figure)",,,astro-ph.IM,"['astro-ph.IM', 'physics.ed-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1907.08043v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.08043v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.08043v1,"{'id': 'http://arxiv.org/abs/1907.08043v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.08043v1', 'updated': '2019-07-18T13:38:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=38, tm_sec=22, tm_wday=3, tm_yday=199, tm_isdst=0), 'published': '2019-07-18T13:38:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=38, tm_sec=22, tm_wday=3, tm_yday=199, tm_isdst=0), 'title': 'Embedding Climate Change Engagement in Astronomy Education and Research', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Embedding Climate Change Engagement in Astronomy Education and Research'}, 'summary': 'This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.'}, 'authors': [{'name': 'Kathryn Williamson'}, {'name': 'Travis A. Rector'}, {'name': 'James Lowenthal'}], 'author_detail': {'name': 'James Lowenthal'}, 'author': 'James Lowenthal', 'arxiv_comment': 'Submitted as a State of the Profession White Paper for the Astro2020\n  Decadal Survey (10 pages, 1 figure)', 'links': [{'href': 'http://arxiv.org/abs/1907.08043v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.08043v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.ed-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
367,http://arxiv.org/abs/1907.06130v2,2020-04-12 01:01:00+00:00,2019-07-13 21:12:08+00:00,Manipulating the Online Marketplace of Ideas,"[arxiv.Result.Author('Xiaodan Lou'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Social media, the modern marketplace of ideas, is vulnerable to manipulation.
Deceptive inauthentic actors impersonate humans to amplify misinformation and
influence public opinions. Little is known about the large-scale consequences
of such operations, due to the ethical challenges posed by online experiments
that manipulate human behavior. Here we introduce a model of information
spreading where agents prefer quality information but have limited attention.
We evaluate the impact of manipulation strategies aimed at degrading the
overall quality of the information ecosystem. The model reproduces empirical
patterns about amplification of low-quality information. We find that
infiltrating a critical fraction of the network is more damaging than
generating attention-grabbing content or targeting influentials. We discuss
countermeasures suggested by these insights to increase the resilience of
social media users to manipulation, and legal issues arising from regulations
aimed at protecting human speech from suppression by inauthentic actors.","25 pages, 8 figures, 80 references",,,cs.CY,"['cs.CY', 'cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1907.06130v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.06130v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.06130v2,"{'id': 'http://arxiv.org/abs/1907.06130v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.06130v2', 'updated': '2020-04-12T01:01:00Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=4, tm_mday=12, tm_hour=1, tm_min=1, tm_sec=0, tm_wday=6, tm_yday=103, tm_isdst=0), 'published': '2019-07-13T21:12:08Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=13, tm_hour=21, tm_min=12, tm_sec=8, tm_wday=5, tm_yday=194, tm_isdst=0), 'title': 'Manipulating the Online Marketplace of Ideas', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Manipulating the Online Marketplace of Ideas'}, 'summary': 'Social media, the modern marketplace of ideas, is vulnerable to manipulation.\nDeceptive inauthentic actors impersonate humans to amplify misinformation and\ninfluence public opinions. Little is known about the large-scale consequences\nof such operations, due to the ethical challenges posed by online experiments\nthat manipulate human behavior. Here we introduce a model of information\nspreading where agents prefer quality information but have limited attention.\nWe evaluate the impact of manipulation strategies aimed at degrading the\noverall quality of the information ecosystem. The model reproduces empirical\npatterns about amplification of low-quality information. We find that\ninfiltrating a critical fraction of the network is more damaging than\ngenerating attention-grabbing content or targeting influentials. We discuss\ncountermeasures suggested by these insights to increase the resilience of\nsocial media users to manipulation, and legal issues arising from regulations\naimed at protecting human speech from suppression by inauthentic actors.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media, the modern marketplace of ideas, is vulnerable to manipulation.\nDeceptive inauthentic actors impersonate humans to amplify misinformation and\ninfluence public opinions. Little is known about the large-scale consequences\nof such operations, due to the ethical challenges posed by online experiments\nthat manipulate human behavior. Here we introduce a model of information\nspreading where agents prefer quality information but have limited attention.\nWe evaluate the impact of manipulation strategies aimed at degrading the\noverall quality of the information ecosystem. The model reproduces empirical\npatterns about amplification of low-quality information. We find that\ninfiltrating a critical fraction of the network is more damaging than\ngenerating attention-grabbing content or targeting influentials. We discuss\ncountermeasures suggested by these insights to increase the resilience of\nsocial media users to manipulation, and legal issues arising from regulations\naimed at protecting human speech from suppression by inauthentic actors.'}, 'authors': [{'name': 'Xiaodan Lou'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_comment': '25 pages, 8 figures, 80 references', 'links': [{'href': 'http://arxiv.org/abs/1907.06130v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.06130v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
368,http://arxiv.org/abs/1907.04191v2,2019-07-11 15:44:50+00:00,2019-07-08 11:44:25+00:00,Belief places and spaces: Mapping cognitive environments,"[arxiv.Result.Author('Philip Feldman'), arxiv.Result.Author('Aaron Dant'), arxiv.Result.Author('Wayne Lutters')]","Beliefs are not facts, but they are factive - they feel like facts. This
property is what can make misinformation dangerous. Being able to deliberately
navigate through a landscape of often conflicting factive statements is
difficult when there is no way to show the relationships between them without
incorporating the information in linear, narrative forms. In this paper, we
present a mechanism to produce maps of belief places, where populations agree
on salient features of fictional environments, and belief spaces, where
subgroups have related but distinct perspectives. Using a model developed using
agent-based simulation, we show that by observing the repeated behaviors of
human participants in the same social context, it is possible to build maps
that show the shared narrative environment overlaid with traces that show
unique, individual or subgroup perspectives. Our contribution is a
proof-of-concept system, based on the affordances of fantasy tabletop
role-playing games, which support multiple groups interacting with the same
dungeon in a controlled, online environment. The techniques used in this
process are mathematically straightforward, and should be generalizable to
auto-generating larger-scale maps of belief spaces from other corpora, such as
discussions on social media.","19 pages, 9 figure. arXiv admin note: text overlap with
  arXiv:1904.05216",,,cs.HC,"['cs.HC', 'cs.SI', 'H.1.2; H.3.3; H.3.5; H.4.3; H.5.3']","[arxiv.Result.Link('http://arxiv.org/abs/1907.04191v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.04191v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.04191v2,"{'id': 'http://arxiv.org/abs/1907.04191v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.04191v2', 'updated': '2019-07-11T15:44:50Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=11, tm_hour=15, tm_min=44, tm_sec=50, tm_wday=3, tm_yday=192, tm_isdst=0), 'published': '2019-07-08T11:44:25Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=8, tm_hour=11, tm_min=44, tm_sec=25, tm_wday=0, tm_yday=189, tm_isdst=0), 'title': 'Belief places and spaces: Mapping cognitive environments', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Belief places and spaces: Mapping cognitive environments'}, 'summary': 'Beliefs are not facts, but they are factive - they feel like facts. This\nproperty is what can make misinformation dangerous. Being able to deliberately\nnavigate through a landscape of often conflicting factive statements is\ndifficult when there is no way to show the relationships between them without\nincorporating the information in linear, narrative forms. In this paper, we\npresent a mechanism to produce maps of belief places, where populations agree\non salient features of fictional environments, and belief spaces, where\nsubgroups have related but distinct perspectives. Using a model developed using\nagent-based simulation, we show that by observing the repeated behaviors of\nhuman participants in the same social context, it is possible to build maps\nthat show the shared narrative environment overlaid with traces that show\nunique, individual or subgroup perspectives. Our contribution is a\nproof-of-concept system, based on the affordances of fantasy tabletop\nrole-playing games, which support multiple groups interacting with the same\ndungeon in a controlled, online environment. The techniques used in this\nprocess are mathematically straightforward, and should be generalizable to\nauto-generating larger-scale maps of belief spaces from other corpora, such as\ndiscussions on social media.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Beliefs are not facts, but they are factive - they feel like facts. This\nproperty is what can make misinformation dangerous. Being able to deliberately\nnavigate through a landscape of often conflicting factive statements is\ndifficult when there is no way to show the relationships between them without\nincorporating the information in linear, narrative forms. In this paper, we\npresent a mechanism to produce maps of belief places, where populations agree\non salient features of fictional environments, and belief spaces, where\nsubgroups have related but distinct perspectives. Using a model developed using\nagent-based simulation, we show that by observing the repeated behaviors of\nhuman participants in the same social context, it is possible to build maps\nthat show the shared narrative environment overlaid with traces that show\nunique, individual or subgroup perspectives. Our contribution is a\nproof-of-concept system, based on the affordances of fantasy tabletop\nrole-playing games, which support multiple groups interacting with the same\ndungeon in a controlled, online environment. The techniques used in this\nprocess are mathematically straightforward, and should be generalizable to\nauto-generating larger-scale maps of belief spaces from other corpora, such as\ndiscussions on social media.'}, 'authors': [{'name': 'Philip Feldman'}, {'name': 'Aaron Dant'}, {'name': 'Wayne Lutters'}], 'author_detail': {'name': 'Wayne Lutters'}, 'author': 'Wayne Lutters', 'arxiv_comment': '19 pages, 9 figure. arXiv admin note: text overlap with\n  arXiv:1904.05216', 'links': [{'href': 'http://arxiv.org/abs/1907.04191v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.04191v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.1.2; H.3.3; H.3.5; H.4.3; H.5.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
369,http://arxiv.org/abs/1907.03588v1,2019-07-05 17:16:14+00:00,2019-07-05 17:16:14+00:00,A New Approach to Distributed Hypothesis Testing and Non-Bayesian Learning: Improved Learning Rate and Byzantine-Resilience,"[arxiv.Result.Author('Aritra Mitra'), arxiv.Result.Author('John A. Richards'), arxiv.Result.Author('Shreyas Sundaram')]","We study a setting where a group of agents, each receiving partially
informative private signals, seek to collaboratively learn the true underlying
state of the world (from a finite set of hypotheses) that generates their joint
observation profiles. To solve this problem, we propose a distributed learning
rule that differs fundamentally from existing approaches, in that it does not
employ any form of ""belief-averaging"". Instead, agents update their beliefs
based on a min-rule. Under standard assumptions on the observation model and
the network structure, we establish that each agent learns the truth
asymptotically almost surely. As our main contribution, we prove that with
probability 1, each false hypothesis is ruled out by every agent exponentially
fast at a network-independent rate that is strictly larger than existing rates.
We then develop a computationally-efficient variant of our learning rule that
is provably resilient to agents who do not behave as expected (as represented
by a Byzantine adversary model) and deliberately try to spread misinformation.",arXiv admin note: text overlap with arXiv:1903.05817,,,eess.SY,"['eess.SY', 'cs.IT', 'cs.LG', 'cs.SY', 'math.IT']","[arxiv.Result.Link('http://arxiv.org/abs/1907.03588v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.03588v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.03588v1,"{'id': 'http://arxiv.org/abs/1907.03588v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.03588v1', 'updated': '2019-07-05T17:16:14Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=5, tm_hour=17, tm_min=16, tm_sec=14, tm_wday=4, tm_yday=186, tm_isdst=0), 'published': '2019-07-05T17:16:14Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=5, tm_hour=17, tm_min=16, tm_sec=14, tm_wday=4, tm_yday=186, tm_isdst=0), 'title': 'A New Approach to Distributed Hypothesis Testing and Non-Bayesian\n  Learning: Improved Learning Rate and Byzantine-Resilience', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A New Approach to Distributed Hypothesis Testing and Non-Bayesian\n  Learning: Improved Learning Rate and Byzantine-Resilience'}, 'summary': 'We study a setting where a group of agents, each receiving partially\ninformative private signals, seek to collaboratively learn the true underlying\nstate of the world (from a finite set of hypotheses) that generates their joint\nobservation profiles. To solve this problem, we propose a distributed learning\nrule that differs fundamentally from existing approaches, in that it does not\nemploy any form of ""belief-averaging"". Instead, agents update their beliefs\nbased on a min-rule. Under standard assumptions on the observation model and\nthe network structure, we establish that each agent learns the truth\nasymptotically almost surely. As our main contribution, we prove that with\nprobability 1, each false hypothesis is ruled out by every agent exponentially\nfast at a network-independent rate that is strictly larger than existing rates.\nWe then develop a computationally-efficient variant of our learning rule that\nis provably resilient to agents who do not behave as expected (as represented\nby a Byzantine adversary model) and deliberately try to spread misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We study a setting where a group of agents, each receiving partially\ninformative private signals, seek to collaboratively learn the true underlying\nstate of the world (from a finite set of hypotheses) that generates their joint\nobservation profiles. To solve this problem, we propose a distributed learning\nrule that differs fundamentally from existing approaches, in that it does not\nemploy any form of ""belief-averaging"". Instead, agents update their beliefs\nbased on a min-rule. Under standard assumptions on the observation model and\nthe network structure, we establish that each agent learns the truth\nasymptotically almost surely. As our main contribution, we prove that with\nprobability 1, each false hypothesis is ruled out by every agent exponentially\nfast at a network-independent rate that is strictly larger than existing rates.\nWe then develop a computationally-efficient variant of our learning rule that\nis provably resilient to agents who do not behave as expected (as represented\nby a Byzantine adversary model) and deliberately try to spread misinformation.'}, 'authors': [{'name': 'Aritra Mitra'}, {'name': 'John A. Richards'}, {'name': 'Shreyas Sundaram'}], 'author_detail': {'name': 'Shreyas Sundaram'}, 'author': 'Shreyas Sundaram', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1903.05817', 'links': [{'href': 'http://arxiv.org/abs/1907.03588v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.03588v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
370,http://arxiv.org/abs/1907.00435v2,2019-09-13 18:04:08+00:00,2019-06-30 19:14:17+00:00,YouTube Chatter: Understanding Online Comments Discourse on Misinformative and Political YouTube Videos,"[arxiv.Result.Author('Aarash Heydari'), arxiv.Result.Author('Janny Zhang'), arxiv.Result.Author('Shaan Appel'), arxiv.Result.Author('Xinyi Wu'), arxiv.Result.Author('Gireeja Ranade')]","We conduct a preliminary analysis of comments on political YouTube content
containing misinformation in comparison to comments on trustworthy or
apolitical videos, labelling the bias and factual ratings of our channels
according to Media Bias Fact Check where applicable. One of our most
interesting discoveries is that especially-polarized or misinformative
political channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,
and Questionable Source) generate 7.5x more comments per view and 10.42x more
replies per view than apolitical or Pro-Science channels; in particular,
Conspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments
per view and 11.0x more replies per view than apolitical and Pro-Science
channels. We also compared average thread lengths, average comment lengths, and
profanity rates across channels, and present simple machine learning
classifiers for predicting the bias category of a video based on these
statistics.","32 pages, 23 figures. Primary contributors: Aarash Heydari and Janny
  Zhang. These authors contributed equally to the work",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1907.00435v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1907.00435v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1907.00435v2,"{'id': 'http://arxiv.org/abs/1907.00435v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1907.00435v2', 'updated': '2019-09-13T18:04:08Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=13, tm_hour=18, tm_min=4, tm_sec=8, tm_wday=4, tm_yday=256, tm_isdst=0), 'published': '2019-06-30T19:14:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=30, tm_hour=19, tm_min=14, tm_sec=17, tm_wday=6, tm_yday=181, tm_isdst=0), 'title': 'YouTube Chatter: Understanding Online Comments Discourse on\n  Misinformative and Political YouTube Videos', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'YouTube Chatter: Understanding Online Comments Discourse on\n  Misinformative and Political YouTube Videos'}, 'summary': 'We conduct a preliminary analysis of comments on political YouTube content\ncontaining misinformation in comparison to comments on trustworthy or\napolitical videos, labelling the bias and factual ratings of our channels\naccording to Media Bias Fact Check where applicable. One of our most\ninteresting discoveries is that especially-polarized or misinformative\npolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,\nand Questionable Source) generate 7.5x more comments per view and 10.42x more\nreplies per view than apolitical or Pro-Science channels; in particular,\nConspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments\nper view and 11.0x more replies per view than apolitical and Pro-Science\nchannels. We also compared average thread lengths, average comment lengths, and\nprofanity rates across channels, and present simple machine learning\nclassifiers for predicting the bias category of a video based on these\nstatistics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We conduct a preliminary analysis of comments on political YouTube content\ncontaining misinformation in comparison to comments on trustworthy or\napolitical videos, labelling the bias and factual ratings of our channels\naccording to Media Bias Fact Check where applicable. One of our most\ninteresting discoveries is that especially-polarized or misinformative\npolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,\nand Questionable Source) generate 7.5x more comments per view and 10.42x more\nreplies per view than apolitical or Pro-Science channels; in particular,\nConspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments\nper view and 11.0x more replies per view than apolitical and Pro-Science\nchannels. We also compared average thread lengths, average comment lengths, and\nprofanity rates across channels, and present simple machine learning\nclassifiers for predicting the bias category of a video based on these\nstatistics.'}, 'authors': [{'name': 'Aarash Heydari'}, {'name': 'Janny Zhang'}, {'name': 'Shaan Appel'}, {'name': 'Xinyi Wu'}, {'name': 'Gireeja Ranade'}], 'author_detail': {'name': 'Gireeja Ranade'}, 'author': 'Gireeja Ranade', 'arxiv_comment': '32 pages, 23 figures. Primary contributors: Aarash Heydari and Janny\n  Zhang. These authors contributed equally to the work', 'links': [{'href': 'http://arxiv.org/abs/1907.00435v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1907.00435v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
371,http://arxiv.org/abs/1906.12325v2,2020-02-27 16:05:21+00:00,2019-06-28 17:27:35+00:00,Modeling echo chambers and polarization dynamics in social networks,"[arxiv.Result.Author('Fabian Baumann'), arxiv.Result.Author('Philipp Lorenz-Spreen'), arxiv.Result.Author('Igor M. Sokolov'), arxiv.Result.Author('Michele Starnini')]","Echo chambers and opinion polarization recently quantified in several
sociopolitical contexts and across different social media, raise concerns on
their potential impact on the spread of misinformation and on openness of
debates. Despite increasing efforts, the dynamics leading to the emergence of
these phenomena stay unclear. We propose a model that introduces the dynamics
of radicalization, as a reinforcing mechanism driving the evolution to extreme
opinions from moderate initial conditions. Inspired by empirical findings on
social interaction dynamics, we consider agents characterized by heterogeneous
activities and homophily. We show that the transition between a global
consensus and emerging radicalized states is mostly governed by social
influence and by the controversialness of the topic discussed. Compared with
empirical data of polarized debates on Twitter, the model qualitatively
reproduces the observed relation between users' engagement and opinions, as
well as opinion segregation in the interaction network. Our findings shed light
on the mechanisms that may lie at the core of the emergence of echo chambers
and polarization in social media.",,"Phys. Rev. Lett. 124, 048301 (2020)",10.1103/PhysRevLett.124.048301,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1103/PhysRevLett.124.048301', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1906.12325v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.12325v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.12325v2,"{'id': 'http://arxiv.org/abs/1906.12325v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.12325v2', 'updated': '2020-02-27T16:05:21Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=27, tm_hour=16, tm_min=5, tm_sec=21, tm_wday=3, tm_yday=58, tm_isdst=0), 'published': '2019-06-28T17:27:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=28, tm_hour=17, tm_min=27, tm_sec=35, tm_wday=4, tm_yday=179, tm_isdst=0), 'title': 'Modeling echo chambers and polarization dynamics in social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Modeling echo chambers and polarization dynamics in social networks'}, 'summary': ""Echo chambers and opinion polarization recently quantified in several\nsociopolitical contexts and across different social media, raise concerns on\ntheir potential impact on the spread of misinformation and on openness of\ndebates. Despite increasing efforts, the dynamics leading to the emergence of\nthese phenomena stay unclear. We propose a model that introduces the dynamics\nof radicalization, as a reinforcing mechanism driving the evolution to extreme\nopinions from moderate initial conditions. Inspired by empirical findings on\nsocial interaction dynamics, we consider agents characterized by heterogeneous\nactivities and homophily. We show that the transition between a global\nconsensus and emerging radicalized states is mostly governed by social\ninfluence and by the controversialness of the topic discussed. Compared with\nempirical data of polarized debates on Twitter, the model qualitatively\nreproduces the observed relation between users' engagement and opinions, as\nwell as opinion segregation in the interaction network. Our findings shed light\non the mechanisms that may lie at the core of the emergence of echo chambers\nand polarization in social media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Echo chambers and opinion polarization recently quantified in several\nsociopolitical contexts and across different social media, raise concerns on\ntheir potential impact on the spread of misinformation and on openness of\ndebates. Despite increasing efforts, the dynamics leading to the emergence of\nthese phenomena stay unclear. We propose a model that introduces the dynamics\nof radicalization, as a reinforcing mechanism driving the evolution to extreme\nopinions from moderate initial conditions. Inspired by empirical findings on\nsocial interaction dynamics, we consider agents characterized by heterogeneous\nactivities and homophily. We show that the transition between a global\nconsensus and emerging radicalized states is mostly governed by social\ninfluence and by the controversialness of the topic discussed. Compared with\nempirical data of polarized debates on Twitter, the model qualitatively\nreproduces the observed relation between users' engagement and opinions, as\nwell as opinion segregation in the interaction network. Our findings shed light\non the mechanisms that may lie at the core of the emergence of echo chambers\nand polarization in social media.""}, 'authors': [{'name': 'Fabian Baumann'}, {'name': 'Philipp Lorenz-Spreen'}, {'name': 'Igor M. Sokolov'}, {'name': 'Michele Starnini'}], 'author_detail': {'name': 'Michele Starnini'}, 'author': 'Michele Starnini', 'arxiv_doi': '10.1103/PhysRevLett.124.048301', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1103/PhysRevLett.124.048301', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1906.12325v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.12325v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Phys. Rev. Lett. 124, 048301 (2020)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
372,http://arxiv.org/abs/1906.10365v4,2020-08-04 20:26:08+00:00,2019-06-25 07:47:00+00:00,Emotion Cognizance Improves Health Fake News Identification,"[arxiv.Result.Author('Anoop K'), arxiv.Result.Author('Deepak P'), arxiv.Result.Author('Lajish V L')]","Identifying misinformation is increasingly being recognized as an important
computational task with high potential social impact. Misinformation and fake
contents are injected into almost every domain of news including politics,
health, science, business, etc., among which, the fakeness in health domain
pose serious adverse effects to scare or harm the society. Misinformation
contains scientific claims or content from social media exaggerated with strong
emotion content to attract eyeballs. In this paper, we consider the utility of
the affective character of news articles for fake news identification in the
health domain and present evidence that emotion cognizant representations are
significantly more suited for the task. We outline a technique to leverage
emotion intensity lexicons to develop emotionized text representations, and
evaluate the utility of such a representation for identifying fake news
relating to health in various supervised and unsupervised scenarios. The
consistent and significant empirical gains that we observe over a range of
technique types and parameter settings establish the utility of the emotional
information in news articles, an often overlooked aspect, for the task of
misinformation identification in the health domain.","In Proceedings of 24th International Database Engineering &
  Applications Symposium (IDEAS 2020), Incheon, Korea",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1906.10365v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1906.10365v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1906.10365v4,"{'id': 'http://arxiv.org/abs/1906.10365v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1906.10365v4', 'updated': '2020-08-04T20:26:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=4, tm_hour=20, tm_min=26, tm_sec=8, tm_wday=1, tm_yday=217, tm_isdst=0), 'published': '2019-06-25T07:47:00Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=25, tm_hour=7, tm_min=47, tm_sec=0, tm_wday=1, tm_yday=176, tm_isdst=0), 'title': 'Emotion Cognizance Improves Health Fake News Identification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Emotion Cognizance Improves Health Fake News Identification'}, 'summary': 'Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.'}, 'authors': [{'name': 'Anoop K'}, {'name': 'Deepak P'}, {'name': 'Lajish V L'}], 'author_detail': {'name': 'Lajish V L'}, 'author': 'Lajish V L', 'arxiv_comment': 'In Proceedings of 24th International Database Engineering &\n  Applications Symposium (IDEAS 2020), Incheon, Korea', 'links': [{'href': 'http://arxiv.org/abs/1906.10365v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1906.10365v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
373,http://arxiv.org/abs/1905.05305v1,2019-05-13 22:27:59+00:00,2019-05-13 22:27:59+00:00,Consequential Ranking Algorithms and Long-term Welfare,"[arxiv.Result.Author('Behzad Tabibian'), arxiv.Result.Author('Vicenç Gómez'), arxiv.Result.Author('Abir De'), arxiv.Result.Author('Bernhard Schölkopf'), arxiv.Result.Author('Manuel Gomez Rodriguez')]","Ranking models are typically designed to provide rankings that optimize some
measure of immediate utility to the users. As a result, they have been unable
to anticipate an increasing number of undesirable long-term consequences of
their proposed rankings, from fueling the spread of misinformation and
increasing polarization to degrading social discourse. Can we design ranking
models that understand the consequences of their proposed rankings and, more
importantly, are able to avoid the undesirable ones? In this paper, we first
introduce a joint representation of rankings and user dynamics using Markov
decision processes. Then, we show that this representation greatly simplifies
the construction of consequential ranking models that trade off the immediate
utility and the long-term welfare. In particular, we can obtain optimal
consequential rankings just by applying weighted sampling on the rankings
provided by models that maximize measures of immediate utility. However, in
practice, such a strategy may be inefficient and impractical, specially in high
dimensional scenarios. To overcome this, we introduce an efficient
gradient-based algorithm to learn parameterized consequential ranking models
that effectively approximate optimal ones. We showcase our methodology using
synthetic and real data gathered from Reddit and show that ranking models
derived using our methodology provide ranks that may mitigate the spread of
misinformation and improve the civility of online discussions.",,,,cs.LG,"['cs.LG', 'cs.IR', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1905.05305v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.05305v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.05305v1,"{'id': 'http://arxiv.org/abs/1905.05305v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.05305v1', 'updated': '2019-05-13T22:27:59Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=13, tm_hour=22, tm_min=27, tm_sec=59, tm_wday=0, tm_yday=133, tm_isdst=0), 'published': '2019-05-13T22:27:59Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=13, tm_hour=22, tm_min=27, tm_sec=59, tm_wday=0, tm_yday=133, tm_isdst=0), 'title': 'Consequential Ranking Algorithms and Long-term Welfare', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Consequential Ranking Algorithms and Long-term Welfare'}, 'summary': 'Ranking models are typically designed to provide rankings that optimize some\nmeasure of immediate utility to the users. As a result, they have been unable\nto anticipate an increasing number of undesirable long-term consequences of\ntheir proposed rankings, from fueling the spread of misinformation and\nincreasing polarization to degrading social discourse. Can we design ranking\nmodels that understand the consequences of their proposed rankings and, more\nimportantly, are able to avoid the undesirable ones? In this paper, we first\nintroduce a joint representation of rankings and user dynamics using Markov\ndecision processes. Then, we show that this representation greatly simplifies\nthe construction of consequential ranking models that trade off the immediate\nutility and the long-term welfare. In particular, we can obtain optimal\nconsequential rankings just by applying weighted sampling on the rankings\nprovided by models that maximize measures of immediate utility. However, in\npractice, such a strategy may be inefficient and impractical, specially in high\ndimensional scenarios. To overcome this, we introduce an efficient\ngradient-based algorithm to learn parameterized consequential ranking models\nthat effectively approximate optimal ones. We showcase our methodology using\nsynthetic and real data gathered from Reddit and show that ranking models\nderived using our methodology provide ranks that may mitigate the spread of\nmisinformation and improve the civility of online discussions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Ranking models are typically designed to provide rankings that optimize some\nmeasure of immediate utility to the users. As a result, they have been unable\nto anticipate an increasing number of undesirable long-term consequences of\ntheir proposed rankings, from fueling the spread of misinformation and\nincreasing polarization to degrading social discourse. Can we design ranking\nmodels that understand the consequences of their proposed rankings and, more\nimportantly, are able to avoid the undesirable ones? In this paper, we first\nintroduce a joint representation of rankings and user dynamics using Markov\ndecision processes. Then, we show that this representation greatly simplifies\nthe construction of consequential ranking models that trade off the immediate\nutility and the long-term welfare. In particular, we can obtain optimal\nconsequential rankings just by applying weighted sampling on the rankings\nprovided by models that maximize measures of immediate utility. However, in\npractice, such a strategy may be inefficient and impractical, specially in high\ndimensional scenarios. To overcome this, we introduce an efficient\ngradient-based algorithm to learn parameterized consequential ranking models\nthat effectively approximate optimal ones. We showcase our methodology using\nsynthetic and real data gathered from Reddit and show that ranking models\nderived using our methodology provide ranks that may mitigate the spread of\nmisinformation and improve the civility of online discussions.'}, 'authors': [{'name': 'Behzad Tabibian'}, {'name': 'Vicenç Gómez'}, {'name': 'Abir De'}, {'name': 'Bernhard Schölkopf'}, {'name': 'Manuel Gomez Rodriguez'}], 'author_detail': {'name': 'Manuel Gomez Rodriguez'}, 'author': 'Manuel Gomez Rodriguez', 'links': [{'href': 'http://arxiv.org/abs/1905.05305v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.05305v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
374,http://arxiv.org/abs/1905.04260v1,2019-05-10 17:00:40+00:00,2019-05-10 17:00:40+00:00,Check-It: A Plugin for Detecting and Reducing the Spread of Fake News and Misinformation on the Web,"[arxiv.Result.Author('Demetris Paschalides'), arxiv.Result.Author('Alexandros Kornilakis'), arxiv.Result.Author('Chrysovalantis Christodoulou'), arxiv.Result.Author('Rafael Andreou'), arxiv.Result.Author('George Pallis'), arxiv.Result.Author('Marios D. Dikaiakos'), arxiv.Result.Author('Evangelos Markatos')]","Over the past few years, we have been witnessing the rise of misinformation
on the Web. People fall victims of fake news during their daily lives and
assist their further propagation knowingly and inadvertently. There have been
many initiatives that are trying to mitigate the damage caused by fake news,
focusing on signals from either domain flag-lists, online social networks or
artificial intelligence. In this work, we present Check-It, a system that
combines, in an intelligent way, a variety of signals into a pipeline for fake
news identification. Check-It is developed as a web browser plugin with the
objective of efficient and timely fake news detection, respecting the user's
privacy. Experimental results show that Check-It is able to outperform the
state-of-the-art methods. On a dataset, consisting of 9 millions of articles
labeled as fake and real, Check-It obtains classification accuracies that
exceed 99%.","8 pages, 6 figures,",,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1905.04260v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.04260v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.04260v1,"{'id': 'http://arxiv.org/abs/1905.04260v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.04260v1', 'updated': '2019-05-10T17:00:40Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=10, tm_hour=17, tm_min=0, tm_sec=40, tm_wday=4, tm_yday=130, tm_isdst=0), 'published': '2019-05-10T17:00:40Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=10, tm_hour=17, tm_min=0, tm_sec=40, tm_wday=4, tm_yday=130, tm_isdst=0), 'title': 'Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web'}, 'summary': ""Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.""}, 'authors': [{'name': 'Demetris Paschalides'}, {'name': 'Alexandros Kornilakis'}, {'name': 'Chrysovalantis Christodoulou'}, {'name': 'Rafael Andreou'}, {'name': 'George Pallis'}, {'name': 'Marios D. Dikaiakos'}, {'name': 'Evangelos Markatos'}], 'author_detail': {'name': 'Evangelos Markatos'}, 'author': 'Evangelos Markatos', 'arxiv_comment': '8 pages, 6 figures,', 'links': [{'href': 'http://arxiv.org/abs/1905.04260v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.04260v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
375,http://arxiv.org/abs/1905.00957v1,2019-05-02 20:50:22+00:00,2019-05-02 20:50:22+00:00,A Topic-Agnostic Approach for Identifying Fake News Pages,"[arxiv.Result.Author('Sonia Castelo'), arxiv.Result.Author('Thais Almeida'), arxiv.Result.Author('Anas Elghafari'), arxiv.Result.Author('Aécio Santos'), arxiv.Result.Author('Kien Pham'), arxiv.Result.Author('Eduardo Nakamura'), arxiv.Result.Author('Juliana Freire')]","Fake news and misinformation have been increasingly used to manipulate
popular opinion and influence political processes. To better understand fake
news, how they are propagated, and how to counter their effect, it is necessary
to first identify them. Recently, approaches have been proposed to
automatically classify articles as fake based on their content. An important
challenge for these approaches comes from the dynamic nature of news: as new
political events are covered, topics and discourse constantly change and thus,
a classifier trained using content from articles published at a given time is
likely to become ineffective in the future. To address this challenge, we
propose a topic-agnostic (TAG) classification strategy that uses linguistic and
web-markup features to identify fake news pages. We report experimental results
using multiple data sets which show that our approach attains high accuracy in
the identification of fake news, even as topics evolve over time.","Accepted for publication in the Companion Proceedings of the 2019
  World Wide Web Conference (WWW'19 Companion). Presented in the 2019
  International Workshop on Misinformation, Computational Fact-Checking and
  Credible Web (MisinfoWorkshop2019). 6 pages",,10.1145/3308560.3316739,cs.CL,"['cs.CL', 'cs.IR', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3308560.3316739', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1905.00957v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.00957v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.00957v1,"{'id': 'http://arxiv.org/abs/1905.00957v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.00957v1', 'updated': '2019-05-02T20:50:22Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=20, tm_min=50, tm_sec=22, tm_wday=3, tm_yday=122, tm_isdst=0), 'published': '2019-05-02T20:50:22Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=20, tm_min=50, tm_sec=22, tm_wday=3, tm_yday=122, tm_isdst=0), 'title': 'A Topic-Agnostic Approach for Identifying Fake News Pages', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Topic-Agnostic Approach for Identifying Fake News Pages'}, 'summary': 'Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.'}, 'authors': [{'name': 'Sonia Castelo'}, {'name': 'Thais Almeida'}, {'name': 'Anas Elghafari'}, {'name': 'Aécio Santos'}, {'name': 'Kien Pham'}, {'name': 'Eduardo Nakamura'}, {'name': 'Juliana Freire'}], 'author_detail': {'name': 'Juliana Freire'}, 'author': 'Juliana Freire', 'arxiv_doi': '10.1145/3308560.3316739', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3308560.3316739', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1905.00957v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.00957v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""Accepted for publication in the Companion Proceedings of the 2019\n  World Wide Web Conference (WWW'19 Companion). Presented in the 2019\n  International Workshop on Misinformation, Computational Fact-Checking and\n  Credible Web (MisinfoWorkshop2019). 6 pages"", 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
376,http://arxiv.org/abs/1905.00582v3,2019-05-16 06:56:55+00:00,2019-05-02 06:06:25+00:00,Recurrent Convolutional Strategies for Face Manipulation Detection in Videos,"[arxiv.Result.Author('Ekraam Sabir'), arxiv.Result.Author('Jiaxin Cheng'), arxiv.Result.Author('Ayush Jaiswal'), arxiv.Result.Author('Wael AbdAlmageed'), arxiv.Result.Author('Iacopo Masi'), arxiv.Result.Author('Prem Natarajan')]","The spread of misinformation through synthetically generated yet realistic
images and videos has become a significant problem, calling for robust
manipulation detection methods. Despite the predominant effort of detecting
face manipulation in still images, less attention has been paid to the
identification of tampered faces in videos by taking advantage of the temporal
information present in the stream. Recurrent convolutional models are a class
of deep learning models which have proven effective at exploiting the temporal
information from image streams across domains. We thereby distill the best
strategy for combining variations in these models along with domain specific
face preprocessing techniques through extensive experimentation to obtain
state-of-the-art performance on publicly available video-based facial
manipulation benchmarks. Specifically, we attempt to detect Deepfake, Face2Face
and FaceSwap tampered faces in video streams. Evaluation is performed on the
recently introduced FaceForensics++ dataset, improving the previous
state-of-the-art by up to 4.55% in accuracy.","To appear at Workshop on Applications of Computer Vision and Pattern
  Recognition to Media Forensics at CVPR 2019",,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1905.00582v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1905.00582v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1905.00582v3,"{'id': 'http://arxiv.org/abs/1905.00582v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1905.00582v3', 'updated': '2019-05-16T06:56:55Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=16, tm_hour=6, tm_min=56, tm_sec=55, tm_wday=3, tm_yday=136, tm_isdst=0), 'published': '2019-05-02T06:06:25Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=2, tm_hour=6, tm_min=6, tm_sec=25, tm_wday=3, tm_yday=122, tm_isdst=0), 'title': 'Recurrent Convolutional Strategies for Face Manipulation Detection in\n  Videos', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recurrent Convolutional Strategies for Face Manipulation Detection in\n  Videos'}, 'summary': 'The spread of misinformation through synthetically generated yet realistic\nimages and videos has become a significant problem, calling for robust\nmanipulation detection methods. Despite the predominant effort of detecting\nface manipulation in still images, less attention has been paid to the\nidentification of tampered faces in videos by taking advantage of the temporal\ninformation present in the stream. Recurrent convolutional models are a class\nof deep learning models which have proven effective at exploiting the temporal\ninformation from image streams across domains. We thereby distill the best\nstrategy for combining variations in these models along with domain specific\nface preprocessing techniques through extensive experimentation to obtain\nstate-of-the-art performance on publicly available video-based facial\nmanipulation benchmarks. Specifically, we attempt to detect Deepfake, Face2Face\nand FaceSwap tampered faces in video streams. Evaluation is performed on the\nrecently introduced FaceForensics++ dataset, improving the previous\nstate-of-the-art by up to 4.55% in accuracy.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of misinformation through synthetically generated yet realistic\nimages and videos has become a significant problem, calling for robust\nmanipulation detection methods. Despite the predominant effort of detecting\nface manipulation in still images, less attention has been paid to the\nidentification of tampered faces in videos by taking advantage of the temporal\ninformation present in the stream. Recurrent convolutional models are a class\nof deep learning models which have proven effective at exploiting the temporal\ninformation from image streams across domains. We thereby distill the best\nstrategy for combining variations in these models along with domain specific\nface preprocessing techniques through extensive experimentation to obtain\nstate-of-the-art performance on publicly available video-based facial\nmanipulation benchmarks. Specifically, we attempt to detect Deepfake, Face2Face\nand FaceSwap tampered faces in video streams. Evaluation is performed on the\nrecently introduced FaceForensics++ dataset, improving the previous\nstate-of-the-art by up to 4.55% in accuracy.'}, 'authors': [{'name': 'Ekraam Sabir'}, {'name': 'Jiaxin Cheng'}, {'name': 'Ayush Jaiswal'}, {'name': 'Wael AbdAlmageed'}, {'name': 'Iacopo Masi'}, {'name': 'Prem Natarajan'}], 'author_detail': {'name': 'Prem Natarajan'}, 'author': 'Prem Natarajan', 'arxiv_comment': 'To appear at Workshop on Applications of Computer Vision and Pattern\n  Recognition to Media Forensics at CVPR 2019', 'links': [{'href': 'http://arxiv.org/abs/1905.00582v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1905.00582v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
377,http://arxiv.org/abs/1904.10801v1,2019-04-24 13:25:46+00:00,2019-04-24 13:25:46+00:00,Containing misinformation spreading in temporal social networks,"[arxiv.Result.Author('Wei Wang'), arxiv.Result.Author('Yuanhui Ma'), arxiv.Result.Author('Tao Wu'), arxiv.Result.Author('Yang Dai'), arxiv.Result.Author('Xingshu Chen'), arxiv.Result.Author('Lidia A. Braunstein')]","Many researchers from a variety of fields including computer science, network
science and mathematics have focused on how to contain the outbreaks of
Internet misinformation that threaten social systems and undermine societal
health. Most research on this topic treats the connections among individuals as
static, but these connections change in time, and thus social networks are also
temporal networks. Currently there is no theoretical approach to the problem of
containing misinformation outbreaks in temporal networks. We thus propose a
misinformation spreading model for temporal networks and describe it using a
new theoretical approach. We propose a heuristic-containing (HC) strategy based
on optimizing final outbreak size that outperforms simplified strategies such
as those that are random-containing (RC) and targeted-containing (TC). We
verify the effectiveness of our HC strategy on both artificial and real-world
networks by performing extensive numerical simulations and theoretical
analyses. We find that the HC strategy greatly increases the outbreak threshold
and decreases the final outbreak threshold.","22 pages, 9 figures","Chaos, (2019)",10.1063/1.5114853,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1063/1.5114853', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1904.10801v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.10801v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.10801v1,"{'id': 'http://arxiv.org/abs/1904.10801v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.10801v1', 'updated': '2019-04-24T13:25:46Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=24, tm_hour=13, tm_min=25, tm_sec=46, tm_wday=2, tm_yday=114, tm_isdst=0), 'published': '2019-04-24T13:25:46Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=24, tm_hour=13, tm_min=25, tm_sec=46, tm_wday=2, tm_yday=114, tm_isdst=0), 'title': 'Containing misinformation spreading in temporal social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Containing misinformation spreading in temporal social networks'}, 'summary': 'Many researchers from a variety of fields including computer science, network\nscience and mathematics have focused on how to contain the outbreaks of\nInternet misinformation that threaten social systems and undermine societal\nhealth. Most research on this topic treats the connections among individuals as\nstatic, but these connections change in time, and thus social networks are also\ntemporal networks. Currently there is no theoretical approach to the problem of\ncontaining misinformation outbreaks in temporal networks. We thus propose a\nmisinformation spreading model for temporal networks and describe it using a\nnew theoretical approach. We propose a heuristic-containing (HC) strategy based\non optimizing final outbreak size that outperforms simplified strategies such\nas those that are random-containing (RC) and targeted-containing (TC). We\nverify the effectiveness of our HC strategy on both artificial and real-world\nnetworks by performing extensive numerical simulations and theoretical\nanalyses. We find that the HC strategy greatly increases the outbreak threshold\nand decreases the final outbreak threshold.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Many researchers from a variety of fields including computer science, network\nscience and mathematics have focused on how to contain the outbreaks of\nInternet misinformation that threaten social systems and undermine societal\nhealth. Most research on this topic treats the connections among individuals as\nstatic, but these connections change in time, and thus social networks are also\ntemporal networks. Currently there is no theoretical approach to the problem of\ncontaining misinformation outbreaks in temporal networks. We thus propose a\nmisinformation spreading model for temporal networks and describe it using a\nnew theoretical approach. We propose a heuristic-containing (HC) strategy based\non optimizing final outbreak size that outperforms simplified strategies such\nas those that are random-containing (RC) and targeted-containing (TC). We\nverify the effectiveness of our HC strategy on both artificial and real-world\nnetworks by performing extensive numerical simulations and theoretical\nanalyses. We find that the HC strategy greatly increases the outbreak threshold\nand decreases the final outbreak threshold.'}, 'authors': [{'name': 'Wei Wang'}, {'name': 'Yuanhui Ma'}, {'name': 'Tao Wu'}, {'name': 'Yang Dai'}, {'name': 'Xingshu Chen'}, {'name': 'Lidia A. Braunstein'}], 'author_detail': {'name': 'Lidia A. Braunstein'}, 'author': 'Lidia A. Braunstein', 'arxiv_doi': '10.1063/1.5114853', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1063/1.5114853', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1904.10801v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.10801v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '22 pages, 9 figures', 'arxiv_journal_ref': 'Chaos, (2019)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
378,http://arxiv.org/abs/1904.05386v2,2019-10-20 19:30:09+00:00,2019-04-10 18:42:45+00:00,"Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger Technologies and Blockchain to Combat Digital Deception and Counterfeit Reality","[arxiv.Result.Author('Paula Fraga-Lamas'), arxiv.Result.Author('Tiago M. Fernández-Caramés')]","The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda
and post-truth, often referred to as fake news, raises concerns over the role
of Internet and social media in modern democratic societies. Due to its rapid
and widespread diffusion, digital deception has not only an individual or
societal cost (e.g., to hamper the integrity of elections), but it can lead to
significant economic losses (e.g., to affect stock market performance) or to
risks to national security. Blockchain and other Distributed Ledger
Technologies (DLTs) guarantee the provenance, authenticity and traceability of
data by providing a transparent, immutable and verifiable record of
transactions while creating a peer-to-peer secure platform for storing and
exchanging information. This overview aims to explore the potential of DLTs and
blockchain to combat digital deception, reviewing initiatives that are
currently under development and identifying their main current challenges.
Moreover, some recommendations are enumerated to guide future researchers on
issues that will have to be tackled to face fake news, disinformation and
deepfakes, as an integral part of strengthening the resilience against
cyber-threats on today's online media.",Updated version,,,cs.CY,"['cs.CY', 'cs.CR']","[arxiv.Result.Link('http://arxiv.org/abs/1904.05386v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.05386v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.05386v2,"{'id': 'http://arxiv.org/abs/1904.05386v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.05386v2', 'updated': '2019-10-20T19:30:09Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=20, tm_hour=19, tm_min=30, tm_sec=9, tm_wday=6, tm_yday=293, tm_isdst=0), 'published': '2019-04-10T18:42:45Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=10, tm_hour=18, tm_min=42, tm_sec=45, tm_wday=2, tm_yday=100, tm_isdst=0), 'title': 'Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality'}, 'summary': ""The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.""}, 'authors': [{'name': 'Paula Fraga-Lamas'}, {'name': 'Tiago M. Fernández-Caramés'}], 'author_detail': {'name': 'Tiago M. Fernández-Caramés'}, 'author': 'Tiago M. Fernández-Caramés', 'arxiv_comment': 'Updated version', 'links': [{'href': 'http://arxiv.org/abs/1904.05386v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.05386v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
379,http://arxiv.org/abs/1904.02037v1,2019-04-03 14:46:44+00:00,2019-04-03 14:46:44+00:00,Automated Fact Checking in the News Room,"[arxiv.Result.Author('Sebastião Miranda'), arxiv.Result.Author('David Nogueira'), arxiv.Result.Author('Afonso Mendes'), arxiv.Result.Author('Andreas Vlachos'), arxiv.Result.Author('Andrew Secker'), arxiv.Result.Author('Rebecca Garrett'), arxiv.Result.Author('Jeff Mitchel'), arxiv.Result.Author('Zita Marinho')]","Fact checking is an essential task in journalism; its importance has been
highlighted due to recently increased concerns and efforts in combating
misinformation. In this paper, we present an automated fact-checking platform
which given a claim, it retrieves relevant textual evidence from a document
collection, predicts whether each piece of evidence supports or refutes the
claim, and returns a final verdict. We describe the architecture of the system
and the user interface, focusing on the choices made to improve its
user-friendliness and transparency. We conduct a user study of the
fact-checking platform in a journalistic setting: we integrated it with a
collection of news articles and provide an evaluation of the platform using
feedback from journalists in their workflow. We found that the predictions of
our platform were correct 58\% of the time, and 59\% of the returned evidence
was relevant.",,WEBCONF 2019,,cs.CL,"['cs.CL', 'cs.IR']","[arxiv.Result.Link('http://arxiv.org/abs/1904.02037v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1904.02037v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1904.02037v1,"{'id': 'http://arxiv.org/abs/1904.02037v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1904.02037v1', 'updated': '2019-04-03T14:46:44Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=3, tm_hour=14, tm_min=46, tm_sec=44, tm_wday=2, tm_yday=93, tm_isdst=0), 'published': '2019-04-03T14:46:44Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=3, tm_hour=14, tm_min=46, tm_sec=44, tm_wday=2, tm_yday=93, tm_isdst=0), 'title': 'Automated Fact Checking in the News Room', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automated Fact Checking in the News Room'}, 'summary': 'Fact checking is an essential task in journalism; its importance has been\nhighlighted due to recently increased concerns and efforts in combating\nmisinformation. In this paper, we present an automated fact-checking platform\nwhich given a claim, it retrieves relevant textual evidence from a document\ncollection, predicts whether each piece of evidence supports or refutes the\nclaim, and returns a final verdict. We describe the architecture of the system\nand the user interface, focusing on the choices made to improve its\nuser-friendliness and transparency. We conduct a user study of the\nfact-checking platform in a journalistic setting: we integrated it with a\ncollection of news articles and provide an evaluation of the platform using\nfeedback from journalists in their workflow. We found that the predictions of\nour platform were correct 58\\% of the time, and 59\\% of the returned evidence\nwas relevant.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact checking is an essential task in journalism; its importance has been\nhighlighted due to recently increased concerns and efforts in combating\nmisinformation. In this paper, we present an automated fact-checking platform\nwhich given a claim, it retrieves relevant textual evidence from a document\ncollection, predicts whether each piece of evidence supports or refutes the\nclaim, and returns a final verdict. We describe the architecture of the system\nand the user interface, focusing on the choices made to improve its\nuser-friendliness and transparency. We conduct a user study of the\nfact-checking platform in a journalistic setting: we integrated it with a\ncollection of news articles and provide an evaluation of the platform using\nfeedback from journalists in their workflow. We found that the predictions of\nour platform were correct 58\\% of the time, and 59\\% of the returned evidence\nwas relevant.'}, 'authors': [{'name': 'Sebastião Miranda'}, {'name': 'David Nogueira'}, {'name': 'Afonso Mendes'}, {'name': 'Andreas Vlachos'}, {'name': 'Andrew Secker'}, {'name': 'Rebecca Garrett'}, {'name': 'Jeff Mitchel'}, {'name': 'Zita Marinho'}], 'author_detail': {'name': 'Zita Marinho'}, 'author': 'Zita Marinho', 'arxiv_journal_ref': 'WEBCONF 2019', 'links': [{'href': 'http://arxiv.org/abs/1904.02037v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1904.02037v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
380,http://arxiv.org/abs/1903.11452v3,2020-08-20 20:19:03+00:00,2019-03-27 14:28:17+00:00,Lexical convergence and collective identities on Facebook,"[arxiv.Result.Author('Emanuele Brugnoli'), arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Fabiana Zollo'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Antonio Scala')]","Recent studies, targeting Facebook, showed the tendency of users to interact
with information adhering to their preferred narrative and to ignore dissenting
information. Primarily driven by confirmation bias, users tend to join
polarized clusters where they cooperate to reinforce a like-minded system of
beliefs, thus facilitating fake news and misinformation cascades. To gain a
deeper understanding of these phenomena, in this work we analyze the lexicons
used by the communities of users emerging on Facebook around verified and
unverified contents. We show how the lexical approach provides important
insights about the kind of information processed by the two communities of
users and about their overall sentiment. Furthermore, by focusing on comment
threads, we observe a strong positive correlation between the lexical
convergence of co-commenters and their number of interactions, which in turns
suggests that such a trend could be a proxy for the emergence of collective
identities and polarization in opinion dynamics.","11 pages, 9 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph', '91F20']","[arxiv.Result.Link('http://arxiv.org/abs/1903.11452v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.11452v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.11452v3,"{'id': 'http://arxiv.org/abs/1903.11452v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.11452v3', 'updated': '2020-08-20T20:19:03Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=8, tm_mday=20, tm_hour=20, tm_min=19, tm_sec=3, tm_wday=3, tm_yday=233, tm_isdst=0), 'published': '2019-03-27T14:28:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=27, tm_hour=14, tm_min=28, tm_sec=17, tm_wday=2, tm_yday=86, tm_isdst=0), 'title': 'Lexical convergence and collective identities on Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Lexical convergence and collective identities on Facebook'}, 'summary': 'Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.'}, 'authors': [{'name': 'Emanuele Brugnoli'}, {'name': 'Matteo Cinelli'}, {'name': 'Fabiana Zollo'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Antonio Scala'}], 'author_detail': {'name': 'Antonio Scala'}, 'author': 'Antonio Scala', 'arxiv_comment': '11 pages, 9 figures', 'links': [{'href': 'http://arxiv.org/abs/1903.11452v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.11452v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '91F20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
381,http://arxiv.org/abs/1903.08404v1,2019-03-20 09:40:19+00:00,2019-03-20 09:40:19+00:00,Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences for Fact-Checking,"[arxiv.Result.Author('Casper Hansen'), arxiv.Result.Author('Christian Hansen'), arxiv.Result.Author('Stephen Alstrup'), arxiv.Result.Author('Jakob Grue Simonsen'), arxiv.Result.Author('Christina Lioma')]","Automatic fact-checking systems detect misinformation, such as fake news, by
(i) selecting check-worthy sentences for fact-checking, (ii) gathering related
information to the sentences, and (iii) inferring the factuality of the
sentences. Most prior research on (i) uses hand-crafted features to select
check-worthy sentences, and does not explicitly account for the recent finding
that the top weighted terms in both check-worthy and non-check-worthy sentences
are actually overlapping [15]. Motivated by this, we present a neural
check-worthiness sentence ranking model that represents each word in a sentence
by \textit{both} its embedding (aiming to capture its semantics) and its
syntactic dependencies (aiming to capture its role in modifying the semantics
of other terms in the sentence). Our model is an end-to-end trainable neural
network for check-worthiness ranking, which is trained on large amounts of
unlabelled data through weak supervision. Thorough experimental evaluation
against state of the art baselines, with and without weak supervision, shows
our model to be superior at all times (+13% in MAP and +28% at various
Precision cut-offs from the best baseline with statistical significance).
Empirical analysis of the use of weak supervision, word embedding pretraining
on domain-specific data, and the use of syntactic dependencies of our model
reveals that check-worthy sentences contain notably more identical syntactic
dependencies than non-check-worthy sentences.",6 pages,In Companion Proceedings of the 2019 World Wide Web Conference,,cs.IR,"['cs.IR', 'cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1903.08404v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.08404v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.08404v1,"{'id': 'http://arxiv.org/abs/1903.08404v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.08404v1', 'updated': '2019-03-20T09:40:19Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=20, tm_hour=9, tm_min=40, tm_sec=19, tm_wday=2, tm_yday=79, tm_isdst=0), 'published': '2019-03-20T09:40:19Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=20, tm_hour=9, tm_min=40, tm_sec=19, tm_wday=2, tm_yday=79, tm_isdst=0), 'title': 'Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking'}, 'summary': 'Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.'}, 'authors': [{'name': 'Casper Hansen'}, {'name': 'Christian Hansen'}, {'name': 'Stephen Alstrup'}, {'name': 'Jakob Grue Simonsen'}, {'name': 'Christina Lioma'}], 'author_detail': {'name': 'Christina Lioma'}, 'author': 'Christina Lioma', 'arxiv_comment': '6 pages', 'arxiv_journal_ref': 'In Companion Proceedings of the 2019 World Wide Web Conference', 'links': [{'href': 'http://arxiv.org/abs/1903.08404v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.08404v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
382,http://arxiv.org/abs/1903.07219v2,2021-02-18 11:31:57+00:00,2019-03-18 01:15:48+00:00,Automatically applying a credibility appraisal tool to track vaccination-related communications shared on social media,"[arxiv.Result.Author('Zubair Shah'), arxiv.Result.Author('Didi Surian'), arxiv.Result.Author('Amalie Dyda'), arxiv.Result.Author('Enrico Coiera'), arxiv.Result.Author('Kenneth D. Mandl'), arxiv.Result.Author('Adam G. Dunn')]","Background:
  Tools used to appraise the credibility of health information are
time-consuming to apply and require context-specific expertise, limiting their
use for quickly identifying and mitigating the spread of misinformation as it
emerges. Our aim was to estimate the proportion of vaccination-related posts on
Twitter are likely to be misinformation, and how unevenly exposure to
misinformation was distributed among Twitter users.
  Methods:
  Sampling from 144,878 vaccination-related web pages shared on Twitter between
January 2017 and March 2018, we used a seven-point checklist adapted from two
validated tools to appraise the credibility of a small subset of 474. These
were used to train several classifiers (random forest, support vector machines,
and a recurrent neural network with transfer learning), using the text from a
web page to predict whether the information satisfies each of the seven
criteria.
  Results:
  Applying the best performing classifier to the 144,878 web pages, we found
that 14.4% of relevant posts to text-based communications were linked to
webpages of low credibility and made up 9.2% of all potential
vaccination-related exposures. However, the 100 most popular links to
misinformation were potentially seen by between 2 million and 80 million
Twitter users, and for a substantial sub-population of Twitter users engaging
with vaccination-related information, links to misinformation appear to
dominate the vaccination-related information to which they were exposed.
  Conclusions:
  We proposed a new method for automatically appraising the credibility of
webpages based on a combination of validated checklist tools. The results
suggest that an automatic credibility appraisal tool can be used to find
populations at higher risk of exposure to misinformation or applied proactively
to add friction to the sharing of low credibility vaccination information.","8 Pages, 5 Figures",https://www.jmir.org/2019/11/e14007,10.2196/14007,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.2196/14007', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1903.07219v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.07219v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.07219v2,"{'id': 'http://arxiv.org/abs/1903.07219v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.07219v2', 'updated': '2021-02-18T11:31:57Z', 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=31, tm_sec=57, tm_wday=3, tm_yday=49, tm_isdst=0), 'published': '2019-03-18T01:15:48Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=18, tm_hour=1, tm_min=15, tm_sec=48, tm_wday=0, tm_yday=77, tm_isdst=0), 'title': 'Automatically applying a credibility appraisal tool to track\n  vaccination-related communications shared on social media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automatically applying a credibility appraisal tool to track\n  vaccination-related communications shared on social media'}, 'summary': 'Background:\n  Tools used to appraise the credibility of health information are\ntime-consuming to apply and require context-specific expertise, limiting their\nuse for quickly identifying and mitigating the spread of misinformation as it\nemerges. Our aim was to estimate the proportion of vaccination-related posts on\nTwitter are likely to be misinformation, and how unevenly exposure to\nmisinformation was distributed among Twitter users.\n  Methods:\n  Sampling from 144,878 vaccination-related web pages shared on Twitter between\nJanuary 2017 and March 2018, we used a seven-point checklist adapted from two\nvalidated tools to appraise the credibility of a small subset of 474. These\nwere used to train several classifiers (random forest, support vector machines,\nand a recurrent neural network with transfer learning), using the text from a\nweb page to predict whether the information satisfies each of the seven\ncriteria.\n  Results:\n  Applying the best performing classifier to the 144,878 web pages, we found\nthat 14.4% of relevant posts to text-based communications were linked to\nwebpages of low credibility and made up 9.2% of all potential\nvaccination-related exposures. However, the 100 most popular links to\nmisinformation were potentially seen by between 2 million and 80 million\nTwitter users, and for a substantial sub-population of Twitter users engaging\nwith vaccination-related information, links to misinformation appear to\ndominate the vaccination-related information to which they were exposed.\n  Conclusions:\n  We proposed a new method for automatically appraising the credibility of\nwebpages based on a combination of validated checklist tools. The results\nsuggest that an automatic credibility appraisal tool can be used to find\npopulations at higher risk of exposure to misinformation or applied proactively\nto add friction to the sharing of low credibility vaccination information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Background:\n  Tools used to appraise the credibility of health information are\ntime-consuming to apply and require context-specific expertise, limiting their\nuse for quickly identifying and mitigating the spread of misinformation as it\nemerges. Our aim was to estimate the proportion of vaccination-related posts on\nTwitter are likely to be misinformation, and how unevenly exposure to\nmisinformation was distributed among Twitter users.\n  Methods:\n  Sampling from 144,878 vaccination-related web pages shared on Twitter between\nJanuary 2017 and March 2018, we used a seven-point checklist adapted from two\nvalidated tools to appraise the credibility of a small subset of 474. These\nwere used to train several classifiers (random forest, support vector machines,\nand a recurrent neural network with transfer learning), using the text from a\nweb page to predict whether the information satisfies each of the seven\ncriteria.\n  Results:\n  Applying the best performing classifier to the 144,878 web pages, we found\nthat 14.4% of relevant posts to text-based communications were linked to\nwebpages of low credibility and made up 9.2% of all potential\nvaccination-related exposures. However, the 100 most popular links to\nmisinformation were potentially seen by between 2 million and 80 million\nTwitter users, and for a substantial sub-population of Twitter users engaging\nwith vaccination-related information, links to misinformation appear to\ndominate the vaccination-related information to which they were exposed.\n  Conclusions:\n  We proposed a new method for automatically appraising the credibility of\nwebpages based on a combination of validated checklist tools. The results\nsuggest that an automatic credibility appraisal tool can be used to find\npopulations at higher risk of exposure to misinformation or applied proactively\nto add friction to the sharing of low credibility vaccination information.'}, 'authors': [{'name': 'Zubair Shah'}, {'name': 'Didi Surian'}, {'name': 'Amalie Dyda'}, {'name': 'Enrico Coiera'}, {'name': 'Kenneth D. Mandl'}, {'name': 'Adam G. Dunn'}], 'author_detail': {'name': 'Adam G. Dunn'}, 'author': 'Adam G. Dunn', 'arxiv_doi': '10.2196/14007', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.2196/14007', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1903.07219v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.07219v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '8 Pages, 5 Figures', 'arxiv_journal_ref': 'https://www.jmir.org/2019/11/e14007', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
383,http://arxiv.org/abs/1903.07136v1,2019-03-17 17:37:39+00:00,2019-03-17 17:37:39+00:00,Human-Misinformation interaction: Understanding the interdisciplinary approach needed to computationally combat false information,[arxiv.Result.Author('Alireza Karduni')],"The prevalence of new technologies and social media has amplified the effects
of misinformation on our societies. Thus, it is necessary to create
computational tools to mitigate their effects effectively. This study aims to
provide a critical overview of computational approaches concerned with
combating misinformation. To this aim, I offer an overview of scholarly
definitions of misinformation. I adopt a framework for studying misinformation
that suggests paying attention to the source, content, and consumers as the
three main elements involved in the process of misinformation and I provide an
overview of literature from disciplines of psychology, media studies, and
cognitive sciences that deal with each of these elements. Using the framework,
I overview the existing computational methods that deal with 1) misinformation
detection and fact-checking using Content 2) Identifying untrustworthy Sources
and social bots, and 3) Consumer-facing tools and methods aiming to make humans
resilient to misinformation. I find that the vast majority of works in computer
science and information technology is concerned with the crucial tasks of
detection and verification of content and sources of misinformation. Moreover,
I find that computational research focusing on Consumers of Misinformation in
Human-Computer Interaction (HCI) and related fields are very sparse and often
do not deal with the subtleties of this process. The majority of existing
interfaces and systems are less concerned with the usability of the tools
rather than the robustness and accuracy of the detection methods. Using this
survey, I call for an interdisciplinary approach towards human-misinformation
interaction that focuses on building methods and tools that robustly deal with
such complex psychological/social phenomena.","21 pages, 2 figures",,,cs.HC,"['cs.HC', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1903.07136v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.07136v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.07136v1,"{'id': 'http://arxiv.org/abs/1903.07136v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.07136v1', 'updated': '2019-03-17T17:37:39Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=17, tm_hour=17, tm_min=37, tm_sec=39, tm_wday=6, tm_yday=76, tm_isdst=0), 'published': '2019-03-17T17:37:39Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=17, tm_hour=17, tm_min=37, tm_sec=39, tm_wday=6, tm_yday=76, tm_isdst=0), 'title': 'Human-Misinformation interaction: Understanding the interdisciplinary\n  approach needed to computationally combat false information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Human-Misinformation interaction: Understanding the interdisciplinary\n  approach needed to computationally combat false information'}, 'summary': 'The prevalence of new technologies and social media has amplified the effects\nof misinformation on our societies. Thus, it is necessary to create\ncomputational tools to mitigate their effects effectively. This study aims to\nprovide a critical overview of computational approaches concerned with\ncombating misinformation. To this aim, I offer an overview of scholarly\ndefinitions of misinformation. I adopt a framework for studying misinformation\nthat suggests paying attention to the source, content, and consumers as the\nthree main elements involved in the process of misinformation and I provide an\noverview of literature from disciplines of psychology, media studies, and\ncognitive sciences that deal with each of these elements. Using the framework,\nI overview the existing computational methods that deal with 1) misinformation\ndetection and fact-checking using Content 2) Identifying untrustworthy Sources\nand social bots, and 3) Consumer-facing tools and methods aiming to make humans\nresilient to misinformation. I find that the vast majority of works in computer\nscience and information technology is concerned with the crucial tasks of\ndetection and verification of content and sources of misinformation. Moreover,\nI find that computational research focusing on Consumers of Misinformation in\nHuman-Computer Interaction (HCI) and related fields are very sparse and often\ndo not deal with the subtleties of this process. The majority of existing\ninterfaces and systems are less concerned with the usability of the tools\nrather than the robustness and accuracy of the detection methods. Using this\nsurvey, I call for an interdisciplinary approach towards human-misinformation\ninteraction that focuses on building methods and tools that robustly deal with\nsuch complex psychological/social phenomena.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The prevalence of new technologies and social media has amplified the effects\nof misinformation on our societies. Thus, it is necessary to create\ncomputational tools to mitigate their effects effectively. This study aims to\nprovide a critical overview of computational approaches concerned with\ncombating misinformation. To this aim, I offer an overview of scholarly\ndefinitions of misinformation. I adopt a framework for studying misinformation\nthat suggests paying attention to the source, content, and consumers as the\nthree main elements involved in the process of misinformation and I provide an\noverview of literature from disciplines of psychology, media studies, and\ncognitive sciences that deal with each of these elements. Using the framework,\nI overview the existing computational methods that deal with 1) misinformation\ndetection and fact-checking using Content 2) Identifying untrustworthy Sources\nand social bots, and 3) Consumer-facing tools and methods aiming to make humans\nresilient to misinformation. I find that the vast majority of works in computer\nscience and information technology is concerned with the crucial tasks of\ndetection and verification of content and sources of misinformation. Moreover,\nI find that computational research focusing on Consumers of Misinformation in\nHuman-Computer Interaction (HCI) and related fields are very sparse and often\ndo not deal with the subtleties of this process. The majority of existing\ninterfaces and systems are less concerned with the usability of the tools\nrather than the robustness and accuracy of the detection methods. Using this\nsurvey, I call for an interdisciplinary approach towards human-misinformation\ninteraction that focuses on building methods and tools that robustly deal with\nsuch complex psychological/social phenomena.'}, 'authors': [{'name': 'Alireza Karduni'}], 'author_detail': {'name': 'Alireza Karduni'}, 'author': 'Alireza Karduni', 'arxiv_comment': '21 pages, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/1903.07136v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.07136v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
384,http://arxiv.org/abs/1903.01780v1,2019-03-05 12:10:11+00:00,2019-03-05 12:10:11+00:00,Trust and Trustworthiness in Social Recommender Systems,"[arxiv.Result.Author('Taha Hassan'), arxiv.Result.Author('D. Scott McCrickard')]","The prevalence of misinformation on online social media has tangible
empirical connections to increasing political polarization and partisan
antipathy in the United States. Ranking algorithms for social recommendation
often encode broad assumptions about network structure (like homophily) and
group cognition (like, social action is largely imitative). Assumptions like
these can be na\""ive and exclusionary in the era of fake news and ideological
uniformity towards the political poles. We examine these assumptions with aid
from the user-centric framework of trustworthiness in social recommendation.
The constituent dimensions of trustworthiness (diversity, transparency,
explainability, disruption) highlight new opportunities for discouraging
dogmatization and building decision-aware, transparent news recommender
systems.",WWW '19 FATES,,,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/1903.01780v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.01780v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.01780v1,"{'id': 'http://arxiv.org/abs/1903.01780v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.01780v1', 'updated': '2019-03-05T12:10:11Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=12, tm_min=10, tm_sec=11, tm_wday=1, tm_yday=64, tm_isdst=0), 'published': '2019-03-05T12:10:11Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=12, tm_min=10, tm_sec=11, tm_wday=1, tm_yday=64, tm_isdst=0), 'title': 'Trust and Trustworthiness in Social Recommender Systems', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trust and Trustworthiness in Social Recommender Systems'}, 'summary': 'The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\""ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\""ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.'}, 'authors': [{'name': 'Taha Hassan'}, {'name': 'D. Scott McCrickard'}], 'author_detail': {'name': 'D. Scott McCrickard'}, 'author': 'D. Scott McCrickard', 'arxiv_comment': ""WWW '19 FATES"", 'links': [{'href': 'http://arxiv.org/abs/1903.01780v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.01780v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
385,http://arxiv.org/abs/1903.01693v1,2019-03-05 06:25:05+00:00,2019-03-05 06:25:05+00:00,Less is More: Semi-Supervised Causal Inference for Detecting Pathogenic Users in Social Media,"[arxiv.Result.Author('Hamidreza Alvari'), arxiv.Result.Author('Elham Shaabani'), arxiv.Result.Author('Soumajyoti Sarkar'), arxiv.Result.Author('Ghazaleh Beigi'), arxiv.Result.Author('Paulo Shakarian')]","Recent years have witnessed a surge of manipulation of public opinion and
political events by malicious social media actors. These users are referred to
as ""Pathogenic Social Media (PSM)"" accounts. PSMs are key users in spreading
misinformation in social media to viral proportions. These accounts can be
either controlled by real users or automated bots. Identification of PSMs is
thus of utmost importance for social media authorities. The burden usually
falls to automatic approaches that can identify these accounts and protect
social media reputation. However, lack of sufficient labeled examples for
devising and training sophisticated approaches to combat these accounts is
still one of the foremost challenges facing social media firms. In contrast,
unlabeled data is abundant and cheap to obtain thanks to massive user-generated
data. In this paper, we propose a semi-supervised causal inference PSM
detection framework, SemiPsm, to compensate for the lack of labeled data. In
particular, the proposed method leverages unlabeled data in the form of
manifold regularization and only relies on cascade information. This is in
contrast to the existing approaches that use exhaustive feature engineering
(e.g., profile information, network structure, etc.). Evidence from empirical
experiments on a real-world ISIS-related dataset from Twitter suggests
promising results of utilizing unlabeled instances for detecting PSMs.",Companion Proceedings of the 2019 World Wide Web Conference,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1903.01693v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.01693v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.01693v1,"{'id': 'http://arxiv.org/abs/1903.01693v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.01693v1', 'updated': '2019-03-05T06:25:05Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=6, tm_min=25, tm_sec=5, tm_wday=1, tm_yday=64, tm_isdst=0), 'published': '2019-03-05T06:25:05Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=5, tm_hour=6, tm_min=25, tm_sec=5, tm_wday=1, tm_yday=64, tm_isdst=0), 'title': 'Less is More: Semi-Supervised Causal Inference for Detecting Pathogenic\n  Users in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Less is More: Semi-Supervised Causal Inference for Detecting Pathogenic\n  Users in Social Media'}, 'summary': 'Recent years have witnessed a surge of manipulation of public opinion and\npolitical events by malicious social media actors. These users are referred to\nas ""Pathogenic Social Media (PSM)"" accounts. PSMs are key users in spreading\nmisinformation in social media to viral proportions. These accounts can be\neither controlled by real users or automated bots. Identification of PSMs is\nthus of utmost importance for social media authorities. The burden usually\nfalls to automatic approaches that can identify these accounts and protect\nsocial media reputation. However, lack of sufficient labeled examples for\ndevising and training sophisticated approaches to combat these accounts is\nstill one of the foremost challenges facing social media firms. In contrast,\nunlabeled data is abundant and cheap to obtain thanks to massive user-generated\ndata. In this paper, we propose a semi-supervised causal inference PSM\ndetection framework, SemiPsm, to compensate for the lack of labeled data. In\nparticular, the proposed method leverages unlabeled data in the form of\nmanifold regularization and only relies on cascade information. This is in\ncontrast to the existing approaches that use exhaustive feature engineering\n(e.g., profile information, network structure, etc.). Evidence from empirical\nexperiments on a real-world ISIS-related dataset from Twitter suggests\npromising results of utilizing unlabeled instances for detecting PSMs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent years have witnessed a surge of manipulation of public opinion and\npolitical events by malicious social media actors. These users are referred to\nas ""Pathogenic Social Media (PSM)"" accounts. PSMs are key users in spreading\nmisinformation in social media to viral proportions. These accounts can be\neither controlled by real users or automated bots. Identification of PSMs is\nthus of utmost importance for social media authorities. The burden usually\nfalls to automatic approaches that can identify these accounts and protect\nsocial media reputation. However, lack of sufficient labeled examples for\ndevising and training sophisticated approaches to combat these accounts is\nstill one of the foremost challenges facing social media firms. In contrast,\nunlabeled data is abundant and cheap to obtain thanks to massive user-generated\ndata. In this paper, we propose a semi-supervised causal inference PSM\ndetection framework, SemiPsm, to compensate for the lack of labeled data. In\nparticular, the proposed method leverages unlabeled data in the form of\nmanifold regularization and only relies on cascade information. This is in\ncontrast to the existing approaches that use exhaustive feature engineering\n(e.g., profile information, network structure, etc.). Evidence from empirical\nexperiments on a real-world ISIS-related dataset from Twitter suggests\npromising results of utilizing unlabeled instances for detecting PSMs.'}, 'authors': [{'name': 'Hamidreza Alvari'}, {'name': 'Elham Shaabani'}, {'name': 'Soumajyoti Sarkar'}, {'name': 'Ghazaleh Beigi'}, {'name': 'Paulo Shakarian'}], 'author_detail': {'name': 'Paulo Shakarian'}, 'author': 'Paulo Shakarian', 'arxiv_comment': 'Companion Proceedings of the 2019 World Wide Web Conference', 'links': [{'href': 'http://arxiv.org/abs/1903.01693v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.01693v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
386,http://arxiv.org/abs/1903.04887v2,2019-12-05 20:29:36+00:00,2019-03-04 22:23:33+00:00,QuickStop: A Markov Optimal Stopping Approach for Quickest Misinformation Detection,"[arxiv.Result.Author('Honghao Wei'), arxiv.Result.Author('Xiaohan Kang'), arxiv.Result.Author('Weina Wang'), arxiv.Result.Author('Lei Ying')]","This paper combines data-driven and model-driven methods for real-time
misinformation detection. Our algorithm, named QuickStop, is an optimal
stopping algorithm based on a probabilistic information spreading model
obtained from labeled data. The algorithm consists of an offline machine
learning algorithm for learning the probabilistic information spreading model
and an online optimal stopping algorithm to detect misinformation. The online
detection algorithm has both low computational and memory complexities. Our
numerical evaluations with a real-world dataset show that QuickStop outperforms
existing misinformation detection algorithms in terms of both accuracy and
detection time (number of observations needed for detection). Our evaluations
with synthetic data further show that QuickStop is robust to (offline) learning
errors.",,,,cs.SI,"['cs.SI', 'cs.LG', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1903.04887v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.04887v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.04887v2,"{'id': 'http://arxiv.org/abs/1903.04887v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.04887v2', 'updated': '2019-12-05T20:29:36Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=5, tm_hour=20, tm_min=29, tm_sec=36, tm_wday=3, tm_yday=339, tm_isdst=0), 'published': '2019-03-04T22:23:33Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=4, tm_hour=22, tm_min=23, tm_sec=33, tm_wday=0, tm_yday=63, tm_isdst=0), 'title': 'QuickStop: A Markov Optimal Stopping Approach for Quickest\n  Misinformation Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'QuickStop: A Markov Optimal Stopping Approach for Quickest\n  Misinformation Detection'}, 'summary': 'This paper combines data-driven and model-driven methods for real-time\nmisinformation detection. Our algorithm, named QuickStop, is an optimal\nstopping algorithm based on a probabilistic information spreading model\nobtained from labeled data. The algorithm consists of an offline machine\nlearning algorithm for learning the probabilistic information spreading model\nand an online optimal stopping algorithm to detect misinformation. The online\ndetection algorithm has both low computational and memory complexities. Our\nnumerical evaluations with a real-world dataset show that QuickStop outperforms\nexisting misinformation detection algorithms in terms of both accuracy and\ndetection time (number of observations needed for detection). Our evaluations\nwith synthetic data further show that QuickStop is robust to (offline) learning\nerrors.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper combines data-driven and model-driven methods for real-time\nmisinformation detection. Our algorithm, named QuickStop, is an optimal\nstopping algorithm based on a probabilistic information spreading model\nobtained from labeled data. The algorithm consists of an offline machine\nlearning algorithm for learning the probabilistic information spreading model\nand an online optimal stopping algorithm to detect misinformation. The online\ndetection algorithm has both low computational and memory complexities. Our\nnumerical evaluations with a real-world dataset show that QuickStop outperforms\nexisting misinformation detection algorithms in terms of both accuracy and\ndetection time (number of observations needed for detection). Our evaluations\nwith synthetic data further show that QuickStop is robust to (offline) learning\nerrors.'}, 'authors': [{'name': 'Honghao Wei'}, {'name': 'Xiaohan Kang'}, {'name': 'Weina Wang'}, {'name': 'Lei Ying'}], 'author_detail': {'name': 'Lei Ying'}, 'author': 'Lei Ying', 'links': [{'href': 'http://arxiv.org/abs/1903.04887v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.04887v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
387,http://arxiv.org/abs/1903.00788v3,2019-04-09 21:17:49+00:00,2019-03-02 23:14:58+00:00,AIRD: Adversarial Learning Framework for Image Repurposing Detection,"[arxiv.Result.Author('Ayush Jaiswal'), arxiv.Result.Author('Yue Wu'), arxiv.Result.Author('Wael AbdAlmageed'), arxiv.Result.Author('Iacopo Masi'), arxiv.Result.Author('Premkumar Natarajan')]","Image repurposing is a commonly used method for spreading misinformation on
social media and online forums, which involves publishing untampered images
with modified metadata to create rumors and further propaganda. While manual
verification is possible, given vast amounts of verified knowledge available on
the internet, the increasing prevalence and ease of this form of semantic
manipulation call for the development of robust automatic ways of assessing the
semantic integrity of multimedia data. In this paper, we present a novel method
for image repurposing detection that is based on the real-world adversarial
interplay between a bad actor who repurposes images with counterfeit metadata
and a watchdog who verifies the semantic consistency between images and their
accompanying metadata, where both players have access to a reference dataset of
verified content, which they can use to achieve their goals. The proposed
method exhibits state-of-the-art performance on location-identity,
subject-identity and painting-artist verification, showing its efficacy across
a diverse set of scenarios.","Camera-ready version for the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR), 2019",,,cs.CV,"['cs.CV', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1903.00788v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1903.00788v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1903.00788v3,"{'id': 'http://arxiv.org/abs/1903.00788v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1903.00788v3', 'updated': '2019-04-09T21:17:49Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=9, tm_hour=21, tm_min=17, tm_sec=49, tm_wday=1, tm_yday=99, tm_isdst=0), 'published': '2019-03-02T23:14:58Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=2, tm_hour=23, tm_min=14, tm_sec=58, tm_wday=5, tm_yday=61, tm_isdst=0), 'title': 'AIRD: Adversarial Learning Framework for Image Repurposing Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'AIRD: Adversarial Learning Framework for Image Repurposing Detection'}, 'summary': 'Image repurposing is a commonly used method for spreading misinformation on\nsocial media and online forums, which involves publishing untampered images\nwith modified metadata to create rumors and further propaganda. While manual\nverification is possible, given vast amounts of verified knowledge available on\nthe internet, the increasing prevalence and ease of this form of semantic\nmanipulation call for the development of robust automatic ways of assessing the\nsemantic integrity of multimedia data. In this paper, we present a novel method\nfor image repurposing detection that is based on the real-world adversarial\ninterplay between a bad actor who repurposes images with counterfeit metadata\nand a watchdog who verifies the semantic consistency between images and their\naccompanying metadata, where both players have access to a reference dataset of\nverified content, which they can use to achieve their goals. The proposed\nmethod exhibits state-of-the-art performance on location-identity,\nsubject-identity and painting-artist verification, showing its efficacy across\na diverse set of scenarios.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Image repurposing is a commonly used method for spreading misinformation on\nsocial media and online forums, which involves publishing untampered images\nwith modified metadata to create rumors and further propaganda. While manual\nverification is possible, given vast amounts of verified knowledge available on\nthe internet, the increasing prevalence and ease of this form of semantic\nmanipulation call for the development of robust automatic ways of assessing the\nsemantic integrity of multimedia data. In this paper, we present a novel method\nfor image repurposing detection that is based on the real-world adversarial\ninterplay between a bad actor who repurposes images with counterfeit metadata\nand a watchdog who verifies the semantic consistency between images and their\naccompanying metadata, where both players have access to a reference dataset of\nverified content, which they can use to achieve their goals. The proposed\nmethod exhibits state-of-the-art performance on location-identity,\nsubject-identity and painting-artist verification, showing its efficacy across\na diverse set of scenarios.'}, 'authors': [{'name': 'Ayush Jaiswal'}, {'name': 'Yue Wu'}, {'name': 'Wael AbdAlmageed'}, {'name': 'Iacopo Masi'}, {'name': 'Premkumar Natarajan'}], 'author_detail': {'name': 'Premkumar Natarajan'}, 'author': 'Premkumar Natarajan', 'arxiv_comment': 'Camera-ready version for the IEEE Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2019', 'links': [{'href': 'http://arxiv.org/abs/1903.00788v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1903.00788v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
388,http://arxiv.org/abs/1902.09197v2,2019-06-07 23:36:43+00:00,2019-02-25 11:20:23+00:00,Message Distortion in Information Cascades,"[arxiv.Result.Author('Manoel Horta Ribeiro'), arxiv.Result.Author('Kristina Gligorić'), arxiv.Result.Author('Robert West')]","Information diffusion is usually modeled as a process in which immutable
pieces of information propagate over a network. In reality, however, messages
are not immutable, but may be morphed with every step, potentially entailing
large cumulative distortions. This process may lead to misinformation even in
the absence of malevolent actors, and understanding it is crucial for modeling
and improving online information systems. Here, we perform a controlled,
crowdsourced experiment in which we simulate the propagation of information
from medical research papers. Starting from the original abstracts, crowd
workers iteratively shorten previously produced summaries to increasingly
smaller lengths. We also collect control summaries where the original abstract
is compressed directly to the final target length. Comparing cascades to
controls allows us to separate the effect of the length constraint from that of
accumulated distortion. Via careful manual coding, we annotate lexical and
semantic units in the medical abstracts and track them along cascades. We find
that iterative summarization has a negative impact due to the accumulation of
error, but that high-quality intermediate summaries result in less distorted
messages than in the control case. Different types of information behave
differently; in particular, the conclusion of a medical abstract (i.e., its key
message) is distorted most. Finally, we compare abstractive with extractive
summaries, finding that the latter are less prone to semantic distortion.
Overall, this work is a first step in studying information cascades without the
assumption that disseminated content is immutable, with implications on our
understanding of the role of word-of-mouth effects on the misreporting of
science.",Presented at TheWebConf 2019,,10.1145/3308558.3313531,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/3308558.3313531', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1902.09197v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.09197v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.09197v2,"{'id': 'http://arxiv.org/abs/1902.09197v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.09197v2', 'updated': '2019-06-07T23:36:43Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=7, tm_hour=23, tm_min=36, tm_sec=43, tm_wday=4, tm_yday=158, tm_isdst=0), 'published': '2019-02-25T11:20:23Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=25, tm_hour=11, tm_min=20, tm_sec=23, tm_wday=0, tm_yday=56, tm_isdst=0), 'title': 'Message Distortion in Information Cascades', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Message Distortion in Information Cascades'}, 'summary': 'Information diffusion is usually modeled as a process in which immutable\npieces of information propagate over a network. In reality, however, messages\nare not immutable, but may be morphed with every step, potentially entailing\nlarge cumulative distortions. This process may lead to misinformation even in\nthe absence of malevolent actors, and understanding it is crucial for modeling\nand improving online information systems. Here, we perform a controlled,\ncrowdsourced experiment in which we simulate the propagation of information\nfrom medical research papers. Starting from the original abstracts, crowd\nworkers iteratively shorten previously produced summaries to increasingly\nsmaller lengths. We also collect control summaries where the original abstract\nis compressed directly to the final target length. Comparing cascades to\ncontrols allows us to separate the effect of the length constraint from that of\naccumulated distortion. Via careful manual coding, we annotate lexical and\nsemantic units in the medical abstracts and track them along cascades. We find\nthat iterative summarization has a negative impact due to the accumulation of\nerror, but that high-quality intermediate summaries result in less distorted\nmessages than in the control case. Different types of information behave\ndifferently; in particular, the conclusion of a medical abstract (i.e., its key\nmessage) is distorted most. Finally, we compare abstractive with extractive\nsummaries, finding that the latter are less prone to semantic distortion.\nOverall, this work is a first step in studying information cascades without the\nassumption that disseminated content is immutable, with implications on our\nunderstanding of the role of word-of-mouth effects on the misreporting of\nscience.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Information diffusion is usually modeled as a process in which immutable\npieces of information propagate over a network. In reality, however, messages\nare not immutable, but may be morphed with every step, potentially entailing\nlarge cumulative distortions. This process may lead to misinformation even in\nthe absence of malevolent actors, and understanding it is crucial for modeling\nand improving online information systems. Here, we perform a controlled,\ncrowdsourced experiment in which we simulate the propagation of information\nfrom medical research papers. Starting from the original abstracts, crowd\nworkers iteratively shorten previously produced summaries to increasingly\nsmaller lengths. We also collect control summaries where the original abstract\nis compressed directly to the final target length. Comparing cascades to\ncontrols allows us to separate the effect of the length constraint from that of\naccumulated distortion. Via careful manual coding, we annotate lexical and\nsemantic units in the medical abstracts and track them along cascades. We find\nthat iterative summarization has a negative impact due to the accumulation of\nerror, but that high-quality intermediate summaries result in less distorted\nmessages than in the control case. Different types of information behave\ndifferently; in particular, the conclusion of a medical abstract (i.e., its key\nmessage) is distorted most. Finally, we compare abstractive with extractive\nsummaries, finding that the latter are less prone to semantic distortion.\nOverall, this work is a first step in studying information cascades without the\nassumption that disseminated content is immutable, with implications on our\nunderstanding of the role of word-of-mouth effects on the misreporting of\nscience.'}, 'authors': [{'name': 'Manoel Horta Ribeiro'}, {'name': 'Kristina Gligorić'}, {'name': 'Robert West'}], 'author_detail': {'name': 'Robert West'}, 'author': 'Robert West', 'arxiv_doi': '10.1145/3308558.3313531', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3308558.3313531', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1902.09197v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.09197v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Presented at TheWebConf 2019', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
389,http://arxiv.org/abs/1902.02580v2,2019-06-14 09:51:50+00:00,2019-02-07 12:00:35+00:00,The few-get-richer: a surprising consequence of popularity-based rankings,"[arxiv.Result.Author('Fabrizio Germano'), arxiv.Result.Author('Vicenç Gómez'), arxiv.Result.Author('Gaël Le Mens')]","Ranking algorithms play a crucial role in online platforms ranging from
search engines to recommender systems. In this paper, we identify a surprising
consequence of popularity-based rankings: the fewer the items reporting a given
signal, the higher the share of the overall traffic they collectively attract.
This few-get-richer effect emerges in settings where there are few distinct
classes of items (e.g., left-leaning news sources versus right-leaning news
sources), and items are ranked based on their popularity. We demonstrate
analytically that the few-get-richer effect emerges when people tend to click
on top-ranked items and have heterogeneous preferences for the classes of
items. Using simulations, we analyze how the strength of the effect changes
with assumptions about the setting and human behavior. We also test our
predictions experimentally in an online experiment with human participants. Our
findings have important implications to understand the spread of
misinformation.","7 pages, 3 figures, 1 table, Proceedings of The Web Conference (WWW
  2019)",,,cs.IR,"['cs.IR', 'cs.CY', 'cs.LG', 'H.1; H.3.3; G.3']","[arxiv.Result.Link('http://arxiv.org/abs/1902.02580v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1902.02580v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1902.02580v2,"{'id': 'http://arxiv.org/abs/1902.02580v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1902.02580v2', 'updated': '2019-06-14T09:51:50Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=6, tm_mday=14, tm_hour=9, tm_min=51, tm_sec=50, tm_wday=4, tm_yday=165, tm_isdst=0), 'published': '2019-02-07T12:00:35Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=7, tm_hour=12, tm_min=0, tm_sec=35, tm_wday=3, tm_yday=38, tm_isdst=0), 'title': 'The few-get-richer: a surprising consequence of popularity-based\n  rankings', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The few-get-richer: a surprising consequence of popularity-based\n  rankings'}, 'summary': 'Ranking algorithms play a crucial role in online platforms ranging from\nsearch engines to recommender systems. In this paper, we identify a surprising\nconsequence of popularity-based rankings: the fewer the items reporting a given\nsignal, the higher the share of the overall traffic they collectively attract.\nThis few-get-richer effect emerges in settings where there are few distinct\nclasses of items (e.g., left-leaning news sources versus right-leaning news\nsources), and items are ranked based on their popularity. We demonstrate\nanalytically that the few-get-richer effect emerges when people tend to click\non top-ranked items and have heterogeneous preferences for the classes of\nitems. Using simulations, we analyze how the strength of the effect changes\nwith assumptions about the setting and human behavior. We also test our\npredictions experimentally in an online experiment with human participants. Our\nfindings have important implications to understand the spread of\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Ranking algorithms play a crucial role in online platforms ranging from\nsearch engines to recommender systems. In this paper, we identify a surprising\nconsequence of popularity-based rankings: the fewer the items reporting a given\nsignal, the higher the share of the overall traffic they collectively attract.\nThis few-get-richer effect emerges in settings where there are few distinct\nclasses of items (e.g., left-leaning news sources versus right-leaning news\nsources), and items are ranked based on their popularity. We demonstrate\nanalytically that the few-get-richer effect emerges when people tend to click\non top-ranked items and have heterogeneous preferences for the classes of\nitems. Using simulations, we analyze how the strength of the effect changes\nwith assumptions about the setting and human behavior. We also test our\npredictions experimentally in an online experiment with human participants. Our\nfindings have important implications to understand the spread of\nmisinformation.'}, 'authors': [{'name': 'Fabrizio Germano'}, {'name': 'Vicenç Gómez'}, {'name': 'Gaël Le Mens'}], 'author_detail': {'name': 'Gaël Le Mens'}, 'author': 'Gaël Le Mens', 'arxiv_comment': '7 pages, 3 figures, 1 table, Proceedings of The Web Conference (WWW\n  2019)', 'links': [{'href': 'http://arxiv.org/abs/1902.02580v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1902.02580v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.1; H.3.3; G.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
390,http://arxiv.org/abs/1901.07920v3,2019-04-17 14:32:32+00:00,2019-01-23 14:42:47+00:00,"The Junk News Aggregator: Examining junk news posted on Facebook, starting with the 2018 US Midterm Elections","[arxiv.Result.Author('Dimitra Liotsiou'), arxiv.Result.Author('Bence Kollanyi'), arxiv.Result.Author('Philip N. Howard')]","In recent years, the phenomenon of online misinformation and junk news
circulating on social media has come to constitute an important and widespread
problem affecting public life online across the globe, particularly around
important political events such as elections. At the same time, there have been
calls for more transparency around misinformation on social media platforms, as
many of the most popular social media platforms function as ""walled gardens,""
where it is impossible for researchers and the public to readily examine the
scale and nature of misinformation activity as it unfolds on the platforms. In
order to help address this, we present the Junk News Aggregator, a publicly
available interactive web tool, which allows anyone to examine, in near
real-time, all of the public content posted to Facebook by important junk news
sources in the US. It allows the public to gain access to and examine the
latest articles posted on Facebook (the most popular social media platform in
the US and one where content is not readily accessible at scale from the open
Web), as well as organise them by time, news publisher, and keywords of
interest, and sort them based on all eight engagement metrics available on
Facebook. Therefore, the Aggregator allows the public to gain insights on the
volume, content, key themes, and types and volumes of engagement received by
content posted by junk news publishers, in near real-time, hence opening up and
offering transparency in these activities as they unfold, at scale across the
top most popular junk news publishers. In this way, the Aggregator can help
increase transparency around the nature, volume, and engagement with junk news
on social media, and serve as a media literacy tool for the public.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.07920v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.07920v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.07920v3,"{'id': 'http://arxiv.org/abs/1901.07920v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.07920v3', 'updated': '2019-04-17T14:32:32Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=17, tm_hour=14, tm_min=32, tm_sec=32, tm_wday=2, tm_yday=107, tm_isdst=0), 'published': '2019-01-23T14:42:47Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=23, tm_hour=14, tm_min=42, tm_sec=47, tm_wday=2, tm_yday=23, tm_isdst=0), 'title': 'The Junk News Aggregator: Examining junk news posted on Facebook,\n  starting with the 2018 US Midterm Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Junk News Aggregator: Examining junk news posted on Facebook,\n  starting with the 2018 US Midterm Elections'}, 'summary': 'In recent years, the phenomenon of online misinformation and junk news\ncirculating on social media has come to constitute an important and widespread\nproblem affecting public life online across the globe, particularly around\nimportant political events such as elections. At the same time, there have been\ncalls for more transparency around misinformation on social media platforms, as\nmany of the most popular social media platforms function as ""walled gardens,""\nwhere it is impossible for researchers and the public to readily examine the\nscale and nature of misinformation activity as it unfolds on the platforms. In\norder to help address this, we present the Junk News Aggregator, a publicly\navailable interactive web tool, which allows anyone to examine, in near\nreal-time, all of the public content posted to Facebook by important junk news\nsources in the US. It allows the public to gain access to and examine the\nlatest articles posted on Facebook (the most popular social media platform in\nthe US and one where content is not readily accessible at scale from the open\nWeb), as well as organise them by time, news publisher, and keywords of\ninterest, and sort them based on all eight engagement metrics available on\nFacebook. Therefore, the Aggregator allows the public to gain insights on the\nvolume, content, key themes, and types and volumes of engagement received by\ncontent posted by junk news publishers, in near real-time, hence opening up and\noffering transparency in these activities as they unfold, at scale across the\ntop most popular junk news publishers. In this way, the Aggregator can help\nincrease transparency around the nature, volume, and engagement with junk news\non social media, and serve as a media literacy tool for the public.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, the phenomenon of online misinformation and junk news\ncirculating on social media has come to constitute an important and widespread\nproblem affecting public life online across the globe, particularly around\nimportant political events such as elections. At the same time, there have been\ncalls for more transparency around misinformation on social media platforms, as\nmany of the most popular social media platforms function as ""walled gardens,""\nwhere it is impossible for researchers and the public to readily examine the\nscale and nature of misinformation activity as it unfolds on the platforms. In\norder to help address this, we present the Junk News Aggregator, a publicly\navailable interactive web tool, which allows anyone to examine, in near\nreal-time, all of the public content posted to Facebook by important junk news\nsources in the US. It allows the public to gain access to and examine the\nlatest articles posted on Facebook (the most popular social media platform in\nthe US and one where content is not readily accessible at scale from the open\nWeb), as well as organise them by time, news publisher, and keywords of\ninterest, and sort them based on all eight engagement metrics available on\nFacebook. Therefore, the Aggregator allows the public to gain insights on the\nvolume, content, key themes, and types and volumes of engagement received by\ncontent posted by junk news publishers, in near real-time, hence opening up and\noffering transparency in these activities as they unfold, at scale across the\ntop most popular junk news publishers. In this way, the Aggregator can help\nincrease transparency around the nature, volume, and engagement with junk news\non social media, and serve as a media literacy tool for the public.'}, 'authors': [{'name': 'Dimitra Liotsiou'}, {'name': 'Bence Kollanyi'}, {'name': 'Philip N. Howard'}], 'author_detail': {'name': 'Philip N. Howard'}, 'author': 'Philip N. Howard', 'links': [{'href': 'http://arxiv.org/abs/1901.07920v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.07920v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
391,http://arxiv.org/abs/1901.06437v1,2019-01-18 22:57:09+00:00,2019-01-18 22:57:09+00:00,Combating Fake News: A Survey on Identification and Mitigation Techniques,"[arxiv.Result.Author('Karishma Sharma'), arxiv.Result.Author('Feng Qian'), arxiv.Result.Author('He Jiang'), arxiv.Result.Author('Natali Ruchansky'), arxiv.Result.Author('Ming Zhang'), arxiv.Result.Author('Yan Liu')]","The proliferation of fake news on social media has opened up new directions
of research for timely identification and containment of fake news, and
mitigation of its widespread impact on public opinion. While much of the
earlier research was focused on identification of fake news based on its
contents or by exploiting users' engagements with the news on social media,
there has been a rising interest in proactive intervention strategies to
counter the spread of misinformation and its impact on society. In this survey,
we describe the modern-day problem of fake news and, in particular, highlight
the technical challenges associated with it. We discuss existing methods and
techniques applicable to both identification and mitigation, with a focus on
the significant advances in each method and their advantages and limitations.
In addition, research has often been limited by the quality of existing
datasets and their specific application contexts. To alleviate this problem, we
comprehensively compile and summarize characteristic features of available
datasets. Furthermore, we outline new directions of research to facilitate
future development of effective and interdisciplinary solutions.",,"ACM Transactions on Intelligent Systems and Technology, 2019",,cs.LG,"['cs.LG', 'cs.AI', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1901.06437v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.06437v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.06437v1,"{'id': 'http://arxiv.org/abs/1901.06437v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.06437v1', 'updated': '2019-01-18T22:57:09Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=18, tm_hour=22, tm_min=57, tm_sec=9, tm_wday=4, tm_yday=18, tm_isdst=0), 'published': '2019-01-18T22:57:09Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=18, tm_hour=22, tm_min=57, tm_sec=9, tm_wday=4, tm_yday=18, tm_isdst=0), 'title': 'Combating Fake News: A Survey on Identification and Mitigation\n  Techniques', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Fake News: A Survey on Identification and Mitigation\n  Techniques'}, 'summary': ""The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.""}, 'authors': [{'name': 'Karishma Sharma'}, {'name': 'Feng Qian'}, {'name': 'He Jiang'}, {'name': 'Natali Ruchansky'}, {'name': 'Ming Zhang'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_journal_ref': 'ACM Transactions on Intelligent Systems and Technology, 2019', 'links': [{'href': 'http://arxiv.org/abs/1901.06437v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.06437v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
392,http://arxiv.org/abs/1901.05149v2,2019-12-20 20:56:38+00:00,2019-01-16 06:24:37+00:00,Beyond Uniform Reverse Sampling: A Hybrid Sampling Technique for Misinformation Prevention,"[arxiv.Result.Author('Gunagmo Tong'), arxiv.Result.Author('Ding-Zhu Du')]","Online misinformation has been considered as one of the top global risks as
it may cause serious consequences such as economic damages and public panic.
The misinformation prevention problem aims at generating a positive cascade
with appropriate seed nodes in order to compete against the misinformation. In
this paper, we study the misinformation prevention problem under the prominent
independent cascade model. Due to the #P-hardness in computing influence, the
core problem is to design effective sampling methods to estimate the function
value. The main contribution of this paper is a novel sampling method.
Different from the classic reverse sampling technique which treats all nodes
equally and samples the node uniformly, the proposed method proceeds with a
hybrid sampling process which is able to attach high weights to the users who
are prone to be affected by the misinformation. Consequently, the new sampling
method is more powerful in generating effective samples used for computing seed
nodes for the positive cascade. Based on the new hybrid sample technique, we
design an algorithm offering a $(1-1/e-\epsilon)$-approximation. We
experimentally evaluate the proposed method on extensive datasets and show that
it significantly outperforms the state-of-the-art solutions.","New parameter estimation methods have been proposed to fix an error
  in the previous version",,,cs.SI,"['cs.SI', 'cs.DS']","[arxiv.Result.Link('http://arxiv.org/abs/1901.05149v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.05149v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.05149v2,"{'id': 'http://arxiv.org/abs/1901.05149v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.05149v2', 'updated': '2019-12-20T20:56:38Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=12, tm_mday=20, tm_hour=20, tm_min=56, tm_sec=38, tm_wday=4, tm_yday=354, tm_isdst=0), 'published': '2019-01-16T06:24:37Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=16, tm_hour=6, tm_min=24, tm_sec=37, tm_wday=2, tm_yday=16, tm_isdst=0), 'title': 'Beyond Uniform Reverse Sampling: A Hybrid Sampling Technique for\n  Misinformation Prevention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Beyond Uniform Reverse Sampling: A Hybrid Sampling Technique for\n  Misinformation Prevention'}, 'summary': 'Online misinformation has been considered as one of the top global risks as\nit may cause serious consequences such as economic damages and public panic.\nThe misinformation prevention problem aims at generating a positive cascade\nwith appropriate seed nodes in order to compete against the misinformation. In\nthis paper, we study the misinformation prevention problem under the prominent\nindependent cascade model. Due to the #P-hardness in computing influence, the\ncore problem is to design effective sampling methods to estimate the function\nvalue. The main contribution of this paper is a novel sampling method.\nDifferent from the classic reverse sampling technique which treats all nodes\nequally and samples the node uniformly, the proposed method proceeds with a\nhybrid sampling process which is able to attach high weights to the users who\nare prone to be affected by the misinformation. Consequently, the new sampling\nmethod is more powerful in generating effective samples used for computing seed\nnodes for the positive cascade. Based on the new hybrid sample technique, we\ndesign an algorithm offering a $(1-1/e-\\epsilon)$-approximation. We\nexperimentally evaluate the proposed method on extensive datasets and show that\nit significantly outperforms the state-of-the-art solutions.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online misinformation has been considered as one of the top global risks as\nit may cause serious consequences such as economic damages and public panic.\nThe misinformation prevention problem aims at generating a positive cascade\nwith appropriate seed nodes in order to compete against the misinformation. In\nthis paper, we study the misinformation prevention problem under the prominent\nindependent cascade model. Due to the #P-hardness in computing influence, the\ncore problem is to design effective sampling methods to estimate the function\nvalue. The main contribution of this paper is a novel sampling method.\nDifferent from the classic reverse sampling technique which treats all nodes\nequally and samples the node uniformly, the proposed method proceeds with a\nhybrid sampling process which is able to attach high weights to the users who\nare prone to be affected by the misinformation. Consequently, the new sampling\nmethod is more powerful in generating effective samples used for computing seed\nnodes for the positive cascade. Based on the new hybrid sample technique, we\ndesign an algorithm offering a $(1-1/e-\\epsilon)$-approximation. We\nexperimentally evaluate the proposed method on extensive datasets and show that\nit significantly outperforms the state-of-the-art solutions.'}, 'authors': [{'name': 'Gunagmo Tong'}, {'name': 'Ding-Zhu Du'}], 'author_detail': {'name': 'Ding-Zhu Du'}, 'author': 'Ding-Zhu Du', 'arxiv_comment': 'New parameter estimation methods have been proposed to fix an error\n  in the previous version', 'links': [{'href': 'http://arxiv.org/abs/1901.05149v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.05149v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
393,http://arxiv.org/abs/1901.03688v2,2019-07-17 17:38:29+00:00,2019-01-11 18:49:28+00:00,Quantifying echo chamber effects in information spreading over political communication networks,"[arxiv.Result.Author('Wesley Cota'), arxiv.Result.Author('Silvio C. Ferreira'), arxiv.Result.Author('Romualdo Pastor-Satorras'), arxiv.Result.Author('Michele Starnini')]","Echo chambers in online social networks, in which users prefer to interact
only with ideologically-aligned peers, are believed to facilitate
misinformation spreading and contribute to radicalize political discourse. In
this paper, we gauge the effects of echo chambers in information spreading
phenomena over political communication networks. Mining 12 million Twitter
messages, we reconstruct a network in which users interchange opinions related
to the impeachment of the former Brazilian President Dilma Rousseff. We define
a continuous {political position} parameter, independent of the network's
structure, that allows to quantify the presence of echo chambers in the
strongly connected component of the network, reflected in two well-separated
communities of similar sizes with opposite views of the impeachment process. By
means of simple spreading models, we show that the capability of users in
propagating the content they produce, measured by the associated spreadability,
strongly depends on their attitude. Users expressing pro-impeachment sentiments
are capable to transmit information, on average, to a larger audience than
users expressing anti-impeachment sentiments. Furthermore, the users'
spreadability is correlated to the diversity, in terms of political position,
of the audience reached. Our method can be exploited to identify the presence
of echo chambers and their effects across different contexts and shed light
upon the mechanisms allowing to break echo chambers.","9 pages, 4 figures. Supplementary Information available as ancillary
  file","EPJ Data Sci. 8, 35 (2019)",10.1140/epjds/s13688-019-0213-9,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1140/epjds/s13688-019-0213-9', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1901.03688v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.03688v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.03688v2,"{'id': 'http://arxiv.org/abs/1901.03688v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.03688v2', 'updated': '2019-07-17T17:38:29Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=17, tm_hour=17, tm_min=38, tm_sec=29, tm_wday=2, tm_yday=198, tm_isdst=0), 'published': '2019-01-11T18:49:28Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=11, tm_hour=18, tm_min=49, tm_sec=28, tm_wday=4, tm_yday=11, tm_isdst=0), 'title': 'Quantifying echo chamber effects in information spreading over political\n  communication networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Quantifying echo chamber effects in information spreading over political\n  communication networks'}, 'summary': ""Echo chambers in online social networks, in which users prefer to interact\nonly with ideologically-aligned peers, are believed to facilitate\nmisinformation spreading and contribute to radicalize political discourse. In\nthis paper, we gauge the effects of echo chambers in information spreading\nphenomena over political communication networks. Mining 12 million Twitter\nmessages, we reconstruct a network in which users interchange opinions related\nto the impeachment of the former Brazilian President Dilma Rousseff. We define\na continuous {political position} parameter, independent of the network's\nstructure, that allows to quantify the presence of echo chambers in the\nstrongly connected component of the network, reflected in two well-separated\ncommunities of similar sizes with opposite views of the impeachment process. By\nmeans of simple spreading models, we show that the capability of users in\npropagating the content they produce, measured by the associated spreadability,\nstrongly depends on their attitude. Users expressing pro-impeachment sentiments\nare capable to transmit information, on average, to a larger audience than\nusers expressing anti-impeachment sentiments. Furthermore, the users'\nspreadability is correlated to the diversity, in terms of political position,\nof the audience reached. Our method can be exploited to identify the presence\nof echo chambers and their effects across different contexts and shed light\nupon the mechanisms allowing to break echo chambers."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Echo chambers in online social networks, in which users prefer to interact\nonly with ideologically-aligned peers, are believed to facilitate\nmisinformation spreading and contribute to radicalize political discourse. In\nthis paper, we gauge the effects of echo chambers in information spreading\nphenomena over political communication networks. Mining 12 million Twitter\nmessages, we reconstruct a network in which users interchange opinions related\nto the impeachment of the former Brazilian President Dilma Rousseff. We define\na continuous {political position} parameter, independent of the network's\nstructure, that allows to quantify the presence of echo chambers in the\nstrongly connected component of the network, reflected in two well-separated\ncommunities of similar sizes with opposite views of the impeachment process. By\nmeans of simple spreading models, we show that the capability of users in\npropagating the content they produce, measured by the associated spreadability,\nstrongly depends on their attitude. Users expressing pro-impeachment sentiments\nare capable to transmit information, on average, to a larger audience than\nusers expressing anti-impeachment sentiments. Furthermore, the users'\nspreadability is correlated to the diversity, in terms of political position,\nof the audience reached. Our method can be exploited to identify the presence\nof echo chambers and their effects across different contexts and shed light\nupon the mechanisms allowing to break echo chambers.""}, 'authors': [{'name': 'Wesley Cota'}, {'name': 'Silvio C. Ferreira'}, {'name': 'Romualdo Pastor-Satorras'}, {'name': 'Michele Starnini'}], 'author_detail': {'name': 'Michele Starnini'}, 'author': 'Michele Starnini', 'arxiv_doi': '10.1140/epjds/s13688-019-0213-9', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1140/epjds/s13688-019-0213-9', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1901.03688v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.03688v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '9 pages, 4 figures. Supplementary Information available as ancillary\n  file', 'arxiv_journal_ref': 'EPJ Data Sci. 8, 35 (2019)', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
394,http://arxiv.org/abs/1901.02156v1,2019-01-08 05:11:17+00:00,2019-01-08 05:11:17+00:00,Influence Minimization Under Budget and Matroid Constraints: Extended Version,"[arxiv.Result.Author('Sourav Medya'), arxiv.Result.Author('Arlei Silva'), arxiv.Result.Author('Ambuj Singh')]","Recently, online social networks have become major battlegrounds for
political campaigns, viral marketing, and the dissemination of news. As a
consequence, ''bad actors'' are increasingly exploiting these platforms,
becoming a key challenge for their administrators, businesses and the society
in general. The spread of fake news is a classical example of the abuse of
social networks by these actors. While some have advocated for stricter
policies to control the spread of misinformation in social networks, this often
happens in detriment of their democratic and organic structure. In this paper
we study how to limit the influence of a target set of users in a network via
the removal of a few edges. The idea is to control the diffusion processes
while minimizing the amount of disturbance in the network structure.
  We formulate the influence limitation problem in a data-driven fashion, by
taking into account past propagation traces. Moreover, we consider two types of
constraints over the set of edge removals, a budget constraint and also a, more
general, set of matroid constraints. These problems lead to interesting
challenges in terms of algorithm design. For instance, we are able to show that
influence limitation is APX-hard and propose deterministic and probabilistic
approximation algorithms for the budgeted and matroid version of the problem,
respectively. Our experiments show that the proposed solutions outperform the
baselines by up to 40%.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.02156v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.02156v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.02156v1,"{'id': 'http://arxiv.org/abs/1901.02156v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.02156v1', 'updated': '2019-01-08T05:11:17Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=8, tm_hour=5, tm_min=11, tm_sec=17, tm_wday=1, tm_yday=8, tm_isdst=0), 'published': '2019-01-08T05:11:17Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=8, tm_hour=5, tm_min=11, tm_sec=17, tm_wday=1, tm_yday=8, tm_isdst=0), 'title': 'Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version'}, 'summary': ""Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%.""}, 'authors': [{'name': 'Sourav Medya'}, {'name': 'Arlei Silva'}, {'name': 'Ambuj Singh'}], 'author_detail': {'name': 'Ambuj Singh'}, 'author': 'Ambuj Singh', 'links': [{'href': 'http://arxiv.org/abs/1901.02156v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.02156v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
395,http://arxiv.org/abs/1901.01911v1,2019-01-07 16:38:16+00:00,2019-01-07 16:38:16+00:00,Stance Classification for Rumour Analysis in Twitter: Exploiting Affective Information and Conversation Structure,"[arxiv.Result.Author('Endang Wahyu Pamungkas'), arxiv.Result.Author('Valerio Basile'), arxiv.Result.Author('Viviana Patti')]","Analysing how people react to rumours associated with news in social media is
an important task to prevent the spreading of misinformation, which is nowadays
widely recognized as a dangerous tendency. In social media conversations, users
show different stances and attitudes towards rumourous stories. Some users take
a definite stance, supporting or denying the rumour at issue, while others just
comment it, or ask for additional evidence related to the veracity of the
rumour. On this line, a new shared task has been proposed at SemEval-2017 (Task
8, SubTask A), which is focused on rumour stance classification in English
tweets. The goal is predicting user stance towards emerging rumours in Twitter,
in terms of supporting, denying, querying, or commenting the original rumour,
looking at the conversation threads originated by the rumour. This paper
describes a new approach to this task, where the use of conversation-based and
affective-based features, covering different facets of affect, has been
explored. Our classification model outperforms the best-performing systems for
stance classification at SemEval-2017 Task 8, showing the effectiveness of the
feature set proposed.","To appear in Proceedings of the 2nd International Workshop on Rumours
  and Deception in Social Media (RDSM), co-located with CIKM 2018, Turin,
  Italy, October 2018",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.01911v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.01911v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.01911v1,"{'id': 'http://arxiv.org/abs/1901.01911v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.01911v1', 'updated': '2019-01-07T16:38:16Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=7, tm_hour=16, tm_min=38, tm_sec=16, tm_wday=0, tm_yday=7, tm_isdst=0), 'published': '2019-01-07T16:38:16Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=7, tm_hour=16, tm_min=38, tm_sec=16, tm_wday=0, tm_yday=7, tm_isdst=0), 'title': 'Stance Classification for Rumour Analysis in Twitter: Exploiting\n  Affective Information and Conversation Structure', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stance Classification for Rumour Analysis in Twitter: Exploiting\n  Affective Information and Conversation Structure'}, 'summary': 'Analysing how people react to rumours associated with news in social media is\nan important task to prevent the spreading of misinformation, which is nowadays\nwidely recognized as a dangerous tendency. In social media conversations, users\nshow different stances and attitudes towards rumourous stories. Some users take\na definite stance, supporting or denying the rumour at issue, while others just\ncomment it, or ask for additional evidence related to the veracity of the\nrumour. On this line, a new shared task has been proposed at SemEval-2017 (Task\n8, SubTask A), which is focused on rumour stance classification in English\ntweets. The goal is predicting user stance towards emerging rumours in Twitter,\nin terms of supporting, denying, querying, or commenting the original rumour,\nlooking at the conversation threads originated by the rumour. This paper\ndescribes a new approach to this task, where the use of conversation-based and\naffective-based features, covering different facets of affect, has been\nexplored. Our classification model outperforms the best-performing systems for\nstance classification at SemEval-2017 Task 8, showing the effectiveness of the\nfeature set proposed.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analysing how people react to rumours associated with news in social media is\nan important task to prevent the spreading of misinformation, which is nowadays\nwidely recognized as a dangerous tendency. In social media conversations, users\nshow different stances and attitudes towards rumourous stories. Some users take\na definite stance, supporting or denying the rumour at issue, while others just\ncomment it, or ask for additional evidence related to the veracity of the\nrumour. On this line, a new shared task has been proposed at SemEval-2017 (Task\n8, SubTask A), which is focused on rumour stance classification in English\ntweets. The goal is predicting user stance towards emerging rumours in Twitter,\nin terms of supporting, denying, querying, or commenting the original rumour,\nlooking at the conversation threads originated by the rumour. This paper\ndescribes a new approach to this task, where the use of conversation-based and\naffective-based features, covering different facets of affect, has been\nexplored. Our classification model outperforms the best-performing systems for\nstance classification at SemEval-2017 Task 8, showing the effectiveness of the\nfeature set proposed.'}, 'authors': [{'name': 'Endang Wahyu Pamungkas'}, {'name': 'Valerio Basile'}, {'name': 'Viviana Patti'}], 'author_detail': {'name': 'Viviana Patti'}, 'author': 'Viviana Patti', 'arxiv_comment': 'To appear in Proceedings of the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM), co-located with CIKM 2018, Turin,\n  Italy, October 2018', 'links': [{'href': 'http://arxiv.org/abs/1901.01911v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.01911v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
396,http://arxiv.org/abs/1901.01464v1,2019-01-05 20:23:02+00:00,2019-01-05 20:23:02+00:00,The Value of Misinformation and Disinformation,"[arxiv.Result.Author('Yanling Chang'), arxiv.Result.Author('Matthew F. Keblis'), arxiv.Result.Author('Ran Li'), arxiv.Result.Author('Eleftherios Iakovou'), arxiv.Result.Author('Chelsea C. White III')]","Information is a critical dimension in warfare. Inaccurate information such
as misinformation or disinformation further complicates military operations. In
this paper, we examine the value of misinformation and disinformation to a
military leader who through investment in people, programs and technology is
able to affect the accuracy of information communicated between other actors.
We model the problem as a partially observable stochastic game with three
agents, a leader and two followers. We determine the value to the leader of
misinformation or disinformation being communicated between two (i) adversarial
followers and (ii) allied followers. We demonstrate that only under certain
conditions, the prevalent intuition that the leader would benefit from less
(more) accurate communication between adversarial (allied) followers is valid.
We analyzed why the intuition may fail and show a holistic paradigm taking into
account both the reward structures and policies of agents is necessary in order
to correctly determine the value of misinformation and disinformation. Our
research identifies efficient targeted investments to affect the accuracy of
information communicated between followers to the leader's advantage.",,,,math.OC,['math.OC'],"[arxiv.Result.Link('http://arxiv.org/abs/1901.01464v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1901.01464v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1901.01464v1,"{'id': 'http://arxiv.org/abs/1901.01464v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1901.01464v1', 'updated': '2019-01-05T20:23:02Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=5, tm_hour=20, tm_min=23, tm_sec=2, tm_wday=5, tm_yday=5, tm_isdst=0), 'published': '2019-01-05T20:23:02Z', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=5, tm_hour=20, tm_min=23, tm_sec=2, tm_wday=5, tm_yday=5, tm_isdst=0), 'title': 'The Value of Misinformation and Disinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Value of Misinformation and Disinformation'}, 'summary': ""Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage.""}, 'authors': [{'name': 'Yanling Chang'}, {'name': 'Matthew F. Keblis'}, {'name': 'Ran Li'}, {'name': 'Eleftherios Iakovou'}, {'name': 'Chelsea C. White III'}], 'author_detail': {'name': 'Chelsea C. White III'}, 'author': 'Chelsea C. White III', 'links': [{'href': 'http://arxiv.org/abs/1901.01464v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1901.01464v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
397,http://arxiv.org/abs/1812.11535v1,2018-12-30 13:53:44+00:00,2018-12-30 13:53:44+00:00,Group based Centrality for Immunization of Complex Networks,"[arxiv.Result.Author('Chandni Saxena'), arxiv.Result.Author('M. N. Doja'), arxiv.Result.Author('Tanvir Ahmad')]","Network immunization is an extensively recognized issue in several domains
like virtual network security, public health and social media, to deal with the
problem of node inoculation so as to minimize the transmission through the
links existed in these networks. We aim to identify top ranked nodes to
immunize networks, leading to control the outbreak of epidemics or
misinformation. We consider group based centrality and define a heuristic
objective criteria to establish the target of key nodes finding in network
which if immunized result in essential network vulnerability. We propose a
group based game theoretic payoff division approach, by employing Shapley value
to assign the surplus acquired by participating nodes in different groups
through the positional power and functional influence over other nodes. We tag
these key nodes as Shapley Value based Information Delimiters (SVID).
Experiments on empirical data sets and model networks establish the efficacy of
our proposed approach and acknowledge performance of node inoculation to
delimit contagion outbreak.",,"Physica A: Statistical Mechanics and its Applications Volume 508,
  15 October 2018, Pages 35-47",10.1016/j.physa.2018.05.107,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.physa.2018.05.107', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1812.11535v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.11535v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.11535v1,"{'id': 'http://arxiv.org/abs/1812.11535v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.11535v1', 'updated': '2018-12-30T13:53:44Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=30, tm_hour=13, tm_min=53, tm_sec=44, tm_wday=6, tm_yday=364, tm_isdst=0), 'published': '2018-12-30T13:53:44Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=30, tm_hour=13, tm_min=53, tm_sec=44, tm_wday=6, tm_yday=364, tm_isdst=0), 'title': 'Group based Centrality for Immunization of Complex Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Group based Centrality for Immunization of Complex Networks'}, 'summary': 'Network immunization is an extensively recognized issue in several domains\nlike virtual network security, public health and social media, to deal with the\nproblem of node inoculation so as to minimize the transmission through the\nlinks existed in these networks. We aim to identify top ranked nodes to\nimmunize networks, leading to control the outbreak of epidemics or\nmisinformation. We consider group based centrality and define a heuristic\nobjective criteria to establish the target of key nodes finding in network\nwhich if immunized result in essential network vulnerability. We propose a\ngroup based game theoretic payoff division approach, by employing Shapley value\nto assign the surplus acquired by participating nodes in different groups\nthrough the positional power and functional influence over other nodes. We tag\nthese key nodes as Shapley Value based Information Delimiters (SVID).\nExperiments on empirical data sets and model networks establish the efficacy of\nour proposed approach and acknowledge performance of node inoculation to\ndelimit contagion outbreak.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Network immunization is an extensively recognized issue in several domains\nlike virtual network security, public health and social media, to deal with the\nproblem of node inoculation so as to minimize the transmission through the\nlinks existed in these networks. We aim to identify top ranked nodes to\nimmunize networks, leading to control the outbreak of epidemics or\nmisinformation. We consider group based centrality and define a heuristic\nobjective criteria to establish the target of key nodes finding in network\nwhich if immunized result in essential network vulnerability. We propose a\ngroup based game theoretic payoff division approach, by employing Shapley value\nto assign the surplus acquired by participating nodes in different groups\nthrough the positional power and functional influence over other nodes. We tag\nthese key nodes as Shapley Value based Information Delimiters (SVID).\nExperiments on empirical data sets and model networks establish the efficacy of\nour proposed approach and acknowledge performance of node inoculation to\ndelimit contagion outbreak.'}, 'authors': [{'name': 'Chandni Saxena'}, {'name': 'M. N. Doja'}, {'name': 'Tanvir Ahmad'}], 'author_detail': {'name': 'Tanvir Ahmad'}, 'author': 'Tanvir Ahmad', 'arxiv_doi': '10.1016/j.physa.2018.05.107', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.physa.2018.05.107', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1812.11535v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.11535v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Physica A: Statistical Mechanics and its Applications Volume 508,\n  15 October 2018, Pages 35-47', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
398,http://arxiv.org/abs/1812.10508v1,2018-12-26 19:31:32+00:00,2018-12-26 19:31:32+00:00,A blockchain based Secure and Trusted framework for Information Propagation on Online Social Networks,"[arxiv.Result.Author('Md Arquam'), arxiv.Result.Author('Anurag Singh'), arxiv.Result.Author('Rajesh Sharma')]","The online social networks facilitate naturally for the users to share
information. On these platforms, each user shares information based on his or
her interests. The particular information being shared by a user may be
legitimate or fake. Sometimes a misinformation, propagated by users and group
can create chaos or in some cases, might leads to cases of riots. Nowadays the
third party like ALT news and Cobrapost check the information authenticity, but
it takes too much time to validate the news. Therefore, a robust and new system
is required to check the information authenticity within the network, to stop
the propagation of misinformation. In this paper, we propose a blockchain based
framework for sharing the information securely at the peer level. In the
blockchain model, a chain is created by combining blocks of information. Each
node of network propagates the information based on its credibility to its peer
nodes. The credibility of a node will vary according to the respective
information. Trust is calculated between sender and receiver in two ways:(i)
Local trust used for sharing information at the peer level and (ii) global
trust is used for a credibility check of each user in the network. We evaluate
our framework using real dataset derived from Facebook. Our approach achieves
an accuracy of 83% which shows the effectiveness of our proposed framework.",,"Social Network Analysis and Mining volume 11, Article number: 49
  (2021)",10.1007/s13278-021-00754-y,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1007/s13278-021-00754-y', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1812.10508v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.10508v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.10508v1,"{'id': 'http://arxiv.org/abs/1812.10508v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.10508v1', 'updated': '2018-12-26T19:31:32Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=26, tm_hour=19, tm_min=31, tm_sec=32, tm_wday=2, tm_yday=360, tm_isdst=0), 'published': '2018-12-26T19:31:32Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=26, tm_hour=19, tm_min=31, tm_sec=32, tm_wday=2, tm_yday=360, tm_isdst=0), 'title': 'A blockchain based Secure and Trusted framework for Information\n  Propagation on Online Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A blockchain based Secure and Trusted framework for Information\n  Propagation on Online Social Networks'}, 'summary': 'The online social networks facilitate naturally for the users to share\ninformation. On these platforms, each user shares information based on his or\nher interests. The particular information being shared by a user may be\nlegitimate or fake. Sometimes a misinformation, propagated by users and group\ncan create chaos or in some cases, might leads to cases of riots. Nowadays the\nthird party like ALT news and Cobrapost check the information authenticity, but\nit takes too much time to validate the news. Therefore, a robust and new system\nis required to check the information authenticity within the network, to stop\nthe propagation of misinformation. In this paper, we propose a blockchain based\nframework for sharing the information securely at the peer level. In the\nblockchain model, a chain is created by combining blocks of information. Each\nnode of network propagates the information based on its credibility to its peer\nnodes. The credibility of a node will vary according to the respective\ninformation. Trust is calculated between sender and receiver in two ways:(i)\nLocal trust used for sharing information at the peer level and (ii) global\ntrust is used for a credibility check of each user in the network. We evaluate\nour framework using real dataset derived from Facebook. Our approach achieves\nan accuracy of 83% which shows the effectiveness of our proposed framework.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The online social networks facilitate naturally for the users to share\ninformation. On these platforms, each user shares information based on his or\nher interests. The particular information being shared by a user may be\nlegitimate or fake. Sometimes a misinformation, propagated by users and group\ncan create chaos or in some cases, might leads to cases of riots. Nowadays the\nthird party like ALT news and Cobrapost check the information authenticity, but\nit takes too much time to validate the news. Therefore, a robust and new system\nis required to check the information authenticity within the network, to stop\nthe propagation of misinformation. In this paper, we propose a blockchain based\nframework for sharing the information securely at the peer level. In the\nblockchain model, a chain is created by combining blocks of information. Each\nnode of network propagates the information based on its credibility to its peer\nnodes. The credibility of a node will vary according to the respective\ninformation. Trust is calculated between sender and receiver in two ways:(i)\nLocal trust used for sharing information at the peer level and (ii) global\ntrust is used for a credibility check of each user in the network. We evaluate\nour framework using real dataset derived from Facebook. Our approach achieves\nan accuracy of 83% which shows the effectiveness of our proposed framework.'}, 'authors': [{'name': 'Md Arquam'}, {'name': 'Anurag Singh'}, {'name': 'Rajesh Sharma'}], 'author_detail': {'name': 'Rajesh Sharma'}, 'author': 'Rajesh Sharma', 'arxiv_doi': '10.1007/s13278-021-00754-y', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s13278-021-00754-y', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1812.10508v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.10508v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Social Network Analysis and Mining volume 11, Article number: 49\n  (2021)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
399,http://arxiv.org/abs/1812.09383v2,2019-01-03 14:35:55+00:00,2018-12-21 21:46:34+00:00,"Technology-Enabled Disinformation: Summary, Lessons, and Recommendations","[arxiv.Result.Author('John Akers'), arxiv.Result.Author('Gagan Bansal'), arxiv.Result.Author('Gabriel Cadamuro'), arxiv.Result.Author('Christine Chen'), arxiv.Result.Author('Quanze Chen'), arxiv.Result.Author('Lucy Lin'), arxiv.Result.Author('Phoebe Mulcaire'), arxiv.Result.Author('Rajalakshmi Nandakumar'), arxiv.Result.Author('Matthew Rockett'), arxiv.Result.Author('Lucy Simko'), arxiv.Result.Author('John Toman'), arxiv.Result.Author('Tongshuang Wu'), arxiv.Result.Author('Eric Zeng'), arxiv.Result.Author('Bill Zorn'), arxiv.Result.Author('Franziska Roesner')]","Technology is increasingly used -- unintentionally (misinformation) or
intentionally (disinformation) -- to spread false information at scale, with
potentially broad-reaching societal effects. For example, technology enables
increasingly realistic false images and videos, and hyper-personal targeting
means different people may see different versions of reality. This report is
the culmination of a PhD-level special topics course
(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &
Engineering at the University of Washington's Paul G. Allen School in the fall
of 2018. The goals of this course were to study (1) how technologies and
today's technical platforms enable and support the creation and spread of such
mis- and disinformation, as well as (2) how technical approaches could be used
to mitigate these issues. In this report, we summarize the space of
technology-enabled mis- and disinformation based on our investigations, and
then surface our lessons and recommendations for technologists, researchers,
platform designers, policymakers, and users.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1812.09383v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.09383v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.09383v2,"{'id': 'http://arxiv.org/abs/1812.09383v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.09383v2', 'updated': '2019-01-03T14:35:55Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=3, tm_hour=14, tm_min=35, tm_sec=55, tm_wday=3, tm_yday=3, tm_isdst=0), 'published': '2018-12-21T21:46:34Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=21, tm_hour=21, tm_min=46, tm_sec=34, tm_wday=4, tm_yday=355, tm_isdst=0), 'title': 'Technology-Enabled Disinformation: Summary, Lessons, and Recommendations', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Technology-Enabled Disinformation: Summary, Lessons, and Recommendations'}, 'summary': ""Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users.""}, 'authors': [{'name': 'John Akers'}, {'name': 'Gagan Bansal'}, {'name': 'Gabriel Cadamuro'}, {'name': 'Christine Chen'}, {'name': 'Quanze Chen'}, {'name': 'Lucy Lin'}, {'name': 'Phoebe Mulcaire'}, {'name': 'Rajalakshmi Nandakumar'}, {'name': 'Matthew Rockett'}, {'name': 'Lucy Simko'}, {'name': 'John Toman'}, {'name': 'Tongshuang Wu'}, {'name': 'Eric Zeng'}, {'name': 'Bill Zorn'}, {'name': 'Franziska Roesner'}], 'author_detail': {'name': 'Franziska Roesner'}, 'author': 'Franziska Roesner', 'links': [{'href': 'http://arxiv.org/abs/1812.09383v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.09383v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
400,http://arxiv.org/abs/1812.06156v1,2018-12-14 20:38:25+00:00,2018-12-14 20:38:25+00:00,Trollslayer: Crowdsourcing and Characterization of Abusive Birds in Twitter,"[arxiv.Result.Author('Alvaro Garcia-Recuero'), arxiv.Result.Author('Aneta Morawin'), arxiv.Result.Author('Gareth Tyson')]","As of today, abuse is a pressing issue to participants and administrators of
Online Social Networks (OSN). Abuse in Twitter can spawn from arguments
generated for influencing outcomes of a political election, the use of bots to
automatically spread misinformation, and generally speaking, activities that
deny, disrupt, degrade or deceive other participants and, or the network. Given
the difficulty in finding and accessing a large enough sample of abuse ground
truth from the Twitter platform, we built and deployed a custom crawler that we
use to judiciously collect a new dataset from the Twitter platform with the aim
of characterizing the nature of abusive users, a.k.a abusive birds, in the
wild. We provide a comprehensive set of features based on users' attributes, as
well as social-graph metadata. The former includes metadata about the account
itself, while the latter is computed from the social graph among the sender and
the receiver of each message. Attribute-based features are useful to
characterize user's accounts in OSN, while graph-based features can reveal the
dynamics of information dissemination across the network. In particular, we
derive the Jaccard index as a key feature to reveal the benign or malicious
nature of directed messages in Twitter. To the best of our knowledge, we are
the first to propose such a similarity metric to characterize abuse in Twitter.",SNAMS 2018,,10.1109/SNAMS.2018.8554898,cs.CY,"['cs.CY', 'cs.CR', 'cs.DC']","[arxiv.Result.Link('http://dx.doi.org/10.1109/SNAMS.2018.8554898', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1812.06156v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.06156v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.06156v1,"{'id': 'http://arxiv.org/abs/1812.06156v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.06156v1', 'updated': '2018-12-14T20:38:25Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=14, tm_hour=20, tm_min=38, tm_sec=25, tm_wday=4, tm_yday=348, tm_isdst=0), 'published': '2018-12-14T20:38:25Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=14, tm_hour=20, tm_min=38, tm_sec=25, tm_wday=4, tm_yday=348, tm_isdst=0), 'title': 'Trollslayer: Crowdsourcing and Characterization of Abusive Birds in\n  Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trollslayer: Crowdsourcing and Characterization of Abusive Birds in\n  Twitter'}, 'summary': ""As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter.""}, 'authors': [{'name': 'Alvaro Garcia-Recuero'}, {'name': 'Aneta Morawin'}, {'name': 'Gareth Tyson'}], 'author_detail': {'name': 'Gareth Tyson'}, 'author': 'Gareth Tyson', 'arxiv_doi': '10.1109/SNAMS.2018.8554898', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/SNAMS.2018.8554898', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1812.06156v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.06156v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'SNAMS 2018', 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
401,http://arxiv.org/abs/1812.04478v4,2020-03-17 13:02:14+00:00,2018-12-11 15:45:10+00:00,Socratrees: Exploring the Design of Argument Technology for Layman Users,[arxiv.Result.Author('Steven Jeuris')],"Terms like 'misinformation', 'fake news', and 'echo chambers' permeate
current discussions on the state of the Internet. We believe a lack of
technological support to evaluate, contest, and reason about information
online---as opposed to merely disseminating it---lies at the root of these
problems. Several argument technologies support such functionality, but have
seen limited use outside of niche communities. Most research systems
overemphasize argument analysis and structure, standing in stark contrast with
the informal dialectical nature of everyday argumentation. Conversely,
non-academic systems overlook important implications for design which can be
derived from theory. In this paper, we present the design of a system aiming to
strike a balance between structured argumentation and ease of use. Socratrees
is a website for collaborative argumentative discussion targeting layman users,
but includes sophisticated community guidelines and novel features inspired by
informal logic. During an exploratory study, we evaluate the usefulness of our
imposed structure on argumentation and investigate how users perceive it.
Contributing to arguments remains a complex task, but most users learned to do
so effectively with minimal guidance and all recognized that the structure of
Socratrees may improve online discussion and results in a clearer overview of
arguments.","Rejected several times, primarily on the basis of needing a larger
  study. While trying to obtain funding for this (this project has received no
  funding so far), leaving this out here for now",,,cs.HC,"['cs.HC', 'cs.CY', 'H.5.4']","[arxiv.Result.Link('http://arxiv.org/abs/1812.04478v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.04478v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.04478v4,"{'id': 'http://arxiv.org/abs/1812.04478v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.04478v4', 'updated': '2020-03-17T13:02:14Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=3, tm_mday=17, tm_hour=13, tm_min=2, tm_sec=14, tm_wday=1, tm_yday=77, tm_isdst=0), 'published': '2018-12-11T15:45:10Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=11, tm_hour=15, tm_min=45, tm_sec=10, tm_wday=1, tm_yday=345, tm_isdst=0), 'title': 'Socratrees: Exploring the Design of Argument Technology for Layman Users', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Socratrees: Exploring the Design of Argument Technology for Layman Users'}, 'summary': ""Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments.""}, 'authors': [{'name': 'Steven Jeuris'}], 'author_detail': {'name': 'Steven Jeuris'}, 'author': 'Steven Jeuris', 'arxiv_comment': 'Rejected several times, primarily on the basis of needing a larger\n  study. While trying to obtain funding for this (this project has received no\n  funding so far), leaving this out here for now', 'links': [{'href': 'http://arxiv.org/abs/1812.04478v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.04478v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
402,http://arxiv.org/abs/1812.03533v1,2018-12-09 17:53:08+00:00,2018-12-09 17:53:08+00:00,"Propagation from Deceptive News Sources: Who Shares, How Much, How Evenly, and How Quickly?","[arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Tim Weninger'), arxiv.Result.Author('Svitlana Volkova')]","As people rely on social media as their primary sources of news, the spread
of misinformation has become a significant concern. In this large-scale study
of news in social media we analyze eleven million posts and investigate
propagation behavior of users that directly interact with news accounts
identified as spreading trusted versus malicious content. Unlike previous work,
which looks at specific rumors, topics, or events, we consider all content
propagated by various news sources. Moreover, we analyze and contrast
population versus sub-population behaviour (by demographics) when spreading
misinformation, and distinguish between two types of propagation, i.e., direct
retweets and mentions. Our evaluation examines how evenly, how many, how
quickly, and which users propagate content from various types of news sources
on Twitter.
  Our analysis has identified several key differences in propagation behavior
from trusted versus suspicious news sources. These include high inequity in the
diffusion rate based on the source of disinformation, with a small group of
highly active users responsible for the majority of disinformation spread
overall and within each demographic. Analysis by demographics showed that users
with lower annual income and education share more from disinformation sources
compared to their counterparts. News content is shared significantly more
quickly from trusted, conspiracy, and disinformation sources compared to
clickbait and propaganda. Older users propagate news from trusted sources more
quickly than younger users, but they share from suspicious sources after longer
delays. Finally, users who interact with clickbait and conspiracy sources are
likely to share from propaganda accounts, but not the other way around.","12 pages, 6 figures, 7 tables, published in IEEE TCSS December 2018","IEEE Transactions on Computational Social Systems ( Volume: 5 ,
  Issue: 4 , Dec. 2018 )",10.1109/TCSS.2018.2881071,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1109/TCSS.2018.2881071', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1812.03533v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.03533v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.03533v1,"{'id': 'http://arxiv.org/abs/1812.03533v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.03533v1', 'updated': '2018-12-09T17:53:08Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=9, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=6, tm_yday=343, tm_isdst=0), 'published': '2018-12-09T17:53:08Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=9, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=6, tm_yday=343, tm_isdst=0), 'title': 'Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?'}, 'summary': 'As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.'}, 'authors': [{'name': 'Maria Glenski'}, {'name': 'Tim Weninger'}, {'name': 'Svitlana Volkova'}], 'author_detail': {'name': 'Svitlana Volkova'}, 'author': 'Svitlana Volkova', 'arxiv_doi': '10.1109/TCSS.2018.2881071', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TCSS.2018.2881071', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1812.03533v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.03533v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '12 pages, 6 figures, 7 tables, published in IEEE TCSS December 2018', 'arxiv_journal_ref': 'IEEE Transactions on Computational Social Systems ( Volume: 5 ,\n  Issue: 4 , Dec. 2018 )', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
403,http://arxiv.org/abs/1812.02655v1,2018-12-06 16:45:00+00:00,2018-12-06 16:45:00+00:00,Feature Analysis for Assessing the Quality of Wikipedia Articles through Supervised Classification,"[arxiv.Result.Author('Elias Bassani'), arxiv.Result.Author('Marco Viviani')]","Nowadays, thanks to Web 2.0 technologies, people have the possibility to
generate and spread contents on different social media in a very easy way. In
this context, the evaluation of the quality of the information that is
available online is becoming more and more a crucial issue. In fact, a constant
flow of contents is generated every day by often unknown sources, which are not
certified by traditional authoritative entities. This requires the development
of appropriate methodologies that can evaluate in a systematic way these
contents, based on `objective' aspects connected with them. This would help
individuals, who nowadays tend to increasingly form their opinions based on
what they read online and on social media, to come into contact with
information that is actually useful and verified. Wikipedia is nowadays one of
the biggest online resources on which users rely as a source of information.
The amount of collaboratively generated content that is sent to the online
encyclopedia every day can let to the possible creation of low-quality articles
(and, consequently, misinformation) if not properly monitored and revised. For
this reason, in this paper, the problem of automatically assessing the quality
of Wikipedia articles is considered. In particular, the focus is on the
analysis of hand-crafted features that can be employed by supervised machine
learning techniques to perform the classification of Wikipedia articles on
qualitative bases. With respect to prior literature, a wider set of
characteristics connected to Wikipedia articles are taken into account and
illustrated in detail. Evaluations are performed by considering a labeled
dataset provided in a prior work, and different supervised machine learning
algorithms, which produced encouraging results with respect to the considered
features.",,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1812.02655v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1812.02655v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1812.02655v1,"{'id': 'http://arxiv.org/abs/1812.02655v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1812.02655v1', 'updated': '2018-12-06T16:45:00Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=6, tm_hour=16, tm_min=45, tm_sec=0, tm_wday=3, tm_yday=340, tm_isdst=0), 'published': '2018-12-06T16:45:00Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=6, tm_hour=16, tm_min=45, tm_sec=0, tm_wday=3, tm_yday=340, tm_isdst=0), 'title': 'Feature Analysis for Assessing the Quality of Wikipedia Articles through\n  Supervised Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Feature Analysis for Assessing the Quality of Wikipedia Articles through\n  Supervised Classification'}, 'summary': ""Nowadays, thanks to Web 2.0 technologies, people have the possibility to\ngenerate and spread contents on different social media in a very easy way. In\nthis context, the evaluation of the quality of the information that is\navailable online is becoming more and more a crucial issue. In fact, a constant\nflow of contents is generated every day by often unknown sources, which are not\ncertified by traditional authoritative entities. This requires the development\nof appropriate methodologies that can evaluate in a systematic way these\ncontents, based on `objective' aspects connected with them. This would help\nindividuals, who nowadays tend to increasingly form their opinions based on\nwhat they read online and on social media, to come into contact with\ninformation that is actually useful and verified. Wikipedia is nowadays one of\nthe biggest online resources on which users rely as a source of information.\nThe amount of collaboratively generated content that is sent to the online\nencyclopedia every day can let to the possible creation of low-quality articles\n(and, consequently, misinformation) if not properly monitored and revised. For\nthis reason, in this paper, the problem of automatically assessing the quality\nof Wikipedia articles is considered. In particular, the focus is on the\nanalysis of hand-crafted features that can be employed by supervised machine\nlearning techniques to perform the classification of Wikipedia articles on\nqualitative bases. With respect to prior literature, a wider set of\ncharacteristics connected to Wikipedia articles are taken into account and\nillustrated in detail. Evaluations are performed by considering a labeled\ndataset provided in a prior work, and different supervised machine learning\nalgorithms, which produced encouraging results with respect to the considered\nfeatures."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Nowadays, thanks to Web 2.0 technologies, people have the possibility to\ngenerate and spread contents on different social media in a very easy way. In\nthis context, the evaluation of the quality of the information that is\navailable online is becoming more and more a crucial issue. In fact, a constant\nflow of contents is generated every day by often unknown sources, which are not\ncertified by traditional authoritative entities. This requires the development\nof appropriate methodologies that can evaluate in a systematic way these\ncontents, based on `objective' aspects connected with them. This would help\nindividuals, who nowadays tend to increasingly form their opinions based on\nwhat they read online and on social media, to come into contact with\ninformation that is actually useful and verified. Wikipedia is nowadays one of\nthe biggest online resources on which users rely as a source of information.\nThe amount of collaboratively generated content that is sent to the online\nencyclopedia every day can let to the possible creation of low-quality articles\n(and, consequently, misinformation) if not properly monitored and revised. For\nthis reason, in this paper, the problem of automatically assessing the quality\nof Wikipedia articles is considered. In particular, the focus is on the\nanalysis of hand-crafted features that can be employed by supervised machine\nlearning techniques to perform the classification of Wikipedia articles on\nqualitative bases. With respect to prior literature, a wider set of\ncharacteristics connected to Wikipedia articles are taken into account and\nillustrated in detail. Evaluations are performed by considering a labeled\ndataset provided in a prior work, and different supervised machine learning\nalgorithms, which produced encouraging results with respect to the considered\nfeatures.""}, 'authors': [{'name': 'Elias Bassani'}, {'name': 'Marco Viviani'}], 'author_detail': {'name': 'Marco Viviani'}, 'author': 'Marco Viviani', 'links': [{'href': 'http://arxiv.org/abs/1812.02655v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1812.02655v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
404,http://arxiv.org/abs/1811.12349v2,2018-12-04 16:15:25+00:00,2018-11-29 17:54:49+00:00,Combating Fake News with Interpretable News Feed Algorithms,"[arxiv.Result.Author('Sina Mohseni'), arxiv.Result.Author('Eric Ragan')]","Nowadays, artificial intelligence algorithms are used for targeted and
personalized content distribution in the large scale as part of the intense
competition for attention in the digital media environment. Unfortunately,
targeted information dissemination may result in intellectual isolation and
discrimination. Further, as demonstrated in recent political events in the US
and EU, malicious bots and social media users can create and propagate targeted
`fake news' content in different forms for political gains. From the other
direction, fake news detection algorithms attempt to combat such problems by
identifying misinformation and fraudulent user profiles. This paper reviews
common news feed algorithms as well as methods for fake news detection, and we
discuss how news feed algorithms could be misused to promote falsified content,
affect news diversity, or impact credibility. We review how news feed
algorithms and recommender engines can enable confirmation bias to isolate
users to certain news sources and affecting the perception of reality. As a
potential solution for increasing user awareness of how content is selected or
sorted, we argue for the use of interpretable and explainable news feed
algorithms. We discuss how improved user awareness and system transparency
could mitigate unwanted outcomes of echo chambers and bubble filters in social
media.",,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1811.12349v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.12349v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.12349v2,"{'id': 'http://arxiv.org/abs/1811.12349v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.12349v2', 'updated': '2018-12-04T16:15:25Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=12, tm_mday=4, tm_hour=16, tm_min=15, tm_sec=25, tm_wday=1, tm_yday=338, tm_isdst=0), 'published': '2018-11-29T17:54:49Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=29, tm_hour=17, tm_min=54, tm_sec=49, tm_wday=3, tm_yday=333, tm_isdst=0), 'title': 'Combating Fake News with Interpretable News Feed Algorithms', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combating Fake News with Interpretable News Feed Algorithms'}, 'summary': ""Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.""}, 'authors': [{'name': 'Sina Mohseni'}, {'name': 'Eric Ragan'}], 'author_detail': {'name': 'Eric Ragan'}, 'author': 'Eric Ragan', 'links': [{'href': 'http://arxiv.org/abs/1811.12349v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.12349v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
405,http://arxiv.org/abs/1811.09729v3,2019-09-11 18:29:06+00:00,2018-11-24 00:06:10+00:00,"Generate, Segment and Refine: Towards Generic Manipulation Segmentation","[arxiv.Result.Author('Peng Zhou'), arxiv.Result.Author('Bor-Chun Chen'), arxiv.Result.Author('Xintong Han'), arxiv.Result.Author('Mahyar Najibi'), arxiv.Result.Author('Abhinav Shrivastava'), arxiv.Result.Author('Ser Nam Lim'), arxiv.Result.Author('Larry S. Davis')]","Detecting manipulated images has become a significant emerging challenge. The
advent of image sharing platforms and the easy availability of advanced photo
editing software have resulted in a large quantities of manipulated images
being shared on the internet. While the intent behind such manipulations varies
widely, concerns on the spread of fake news and misinformation is growing.
Current state of the art methods for detecting these manipulated images suffers
from the lack of training data due to the laborious labeling process. We
address this problem in this paper, for which we introduce a manipulated image
generation process that creates true positives using currently available
datasets. Drawing from traditional work on image blending, we propose a novel
generator for creating such examples. In addition, we also propose to further
create examples that force the algorithm to focus on boundary artifacts during
training. Strong experimental results validate our proposal.",,AAAI-2020,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.09729v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.09729v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.09729v3,"{'id': 'http://arxiv.org/abs/1811.09729v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.09729v3', 'updated': '2019-09-11T18:29:06Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=11, tm_hour=18, tm_min=29, tm_sec=6, tm_wday=2, tm_yday=254, tm_isdst=0), 'published': '2018-11-24T00:06:10Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=24, tm_hour=0, tm_min=6, tm_sec=10, tm_wday=5, tm_yday=328, tm_isdst=0), 'title': 'Generate, Segment and Refine: Towards Generic Manipulation Segmentation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Generate, Segment and Refine: Towards Generic Manipulation Segmentation'}, 'summary': 'Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.'}, 'authors': [{'name': 'Peng Zhou'}, {'name': 'Bor-Chun Chen'}, {'name': 'Xintong Han'}, {'name': 'Mahyar Najibi'}, {'name': 'Abhinav Shrivastava'}, {'name': 'Ser Nam Lim'}, {'name': 'Larry S. Davis'}], 'author_detail': {'name': 'Larry S. Davis'}, 'author': 'Larry S. Davis', 'arxiv_journal_ref': 'AAAI-2020', 'links': [{'href': 'http://arxiv.org/abs/1811.09729v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.09729v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
406,http://arxiv.org/abs/1811.07039v1,2018-11-16 21:37:59+00:00,2018-11-16 21:37:59+00:00,Combining Fact Extraction and Verification with Neural Semantic Matching Networks,"[arxiv.Result.Author('Yixin Nie'), arxiv.Result.Author('Haonan Chen'), arxiv.Result.Author('Mohit Bansal')]","The increasing concern with misinformation has stimulated research efforts on
automatic fact checking. The recently-released FEVER dataset introduced a
benchmark fact-verification task in which a system is asked to verify a claim
using evidential sentences from Wikipedia documents. In this paper, we present
a connected system consisting of three homogeneous neural semantic matching
models that conduct document retrieval, sentence selection, and claim
verification jointly for fact extraction and verification. For evidence
retrieval (document retrieval and sentence selection), unlike traditional
vector space IR models in which queries and sources are matched in some
pre-designed term vector space, we develop neural models to perform deep
semantic matching from raw textual input, assuming no intermediate term
representation and no access to structured external knowledge bases. We also
show that Pageview frequency can also help improve the performance of evidence
retrieval results, that later can be matched by using our neural semantic
matching network. For claim verification, unlike previous approaches that
simply feed upstream retrieved evidence and the claim to a natural language
inference (NLI) model, we further enhance the NLI model by providing it with
internal semantic relatedness scores (hence integrating it with the evidence
retrieval modules) and ontological WordNet features. Experiments on the FEVER
dataset indicate that (1) our neural semantic matching method outperforms
popular TF-IDF and encoder models, by significant margins on all evidence
retrieval metrics, (2) the additional relatedness score and WordNet features
improve the NLI model via better semantic awareness, and (3) by formalizing all
three subtasks as a similar semantic matching problem and improving on all
three stages, the complete model is able to achieve the state-of-the-art
results on the FEVER test set.",AAAI 2019,,,cs.CL,"['cs.CL', 'cs.AI']","[arxiv.Result.Link('http://arxiv.org/abs/1811.07039v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.07039v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.07039v1,"{'id': 'http://arxiv.org/abs/1811.07039v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.07039v1', 'updated': '2018-11-16T21:37:59Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=16, tm_hour=21, tm_min=37, tm_sec=59, tm_wday=4, tm_yday=320, tm_isdst=0), 'published': '2018-11-16T21:37:59Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=16, tm_hour=21, tm_min=37, tm_sec=59, tm_wday=4, tm_yday=320, tm_isdst=0), 'title': 'Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks'}, 'summary': 'The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.'}, 'authors': [{'name': 'Yixin Nie'}, {'name': 'Haonan Chen'}, {'name': 'Mohit Bansal'}], 'author_detail': {'name': 'Mohit Bansal'}, 'author': 'Mohit Bansal', 'arxiv_comment': 'AAAI 2019', 'links': [{'href': 'http://arxiv.org/abs/1811.07039v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.07039v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
407,http://arxiv.org/abs/1811.07031v1,2018-11-16 20:57:37+00:00,2018-11-16 20:57:37+00:00,Improving Rotated Text Detection with Rotation Region Proposal Networks,"[arxiv.Result.Author('Jing Huang'), arxiv.Result.Author('Viswanath Sivakumar'), arxiv.Result.Author('Mher Mnatsakanyan'), arxiv.Result.Author('Guan Pang')]","A significant number of images shared on social media platforms such as
Facebook and Instagram contain text in various forms. It's increasingly
becoming commonplace for bad actors to share misinformation, hate speech or
other kinds of harmful content as text overlaid on images on such platforms. A
scene-text understanding system should hence be able to handle text in various
orientations that the adversary might use. Moreover, such a system can be
incorporated into screen readers used to aid the visually impaired. In this
work, we extend the scene-text extraction system at Facebook, Rosetta, to
efficiently handle text in various orientations. Specifically, we incorporate
the Rotation Region Proposal Networks (RRPN) in our text extraction pipeline
and offer practical suggestions for building and deploying a model for
detecting and recognizing text in arbitrary orientations efficiently.
Experimental results show a significant improvement on detecting rotated text.",,,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.07031v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.07031v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.07031v1,"{'id': 'http://arxiv.org/abs/1811.07031v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.07031v1', 'updated': '2018-11-16T20:57:37Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=16, tm_hour=20, tm_min=57, tm_sec=37, tm_wday=4, tm_yday=320, tm_isdst=0), 'published': '2018-11-16T20:57:37Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=16, tm_hour=20, tm_min=57, tm_sec=37, tm_wday=4, tm_yday=320, tm_isdst=0), 'title': 'Improving Rotated Text Detection with Rotation Region Proposal Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Improving Rotated Text Detection with Rotation Region Proposal Networks'}, 'summary': ""A significant number of images shared on social media platforms such as\nFacebook and Instagram contain text in various forms. It's increasingly\nbecoming commonplace for bad actors to share misinformation, hate speech or\nother kinds of harmful content as text overlaid on images on such platforms. A\nscene-text understanding system should hence be able to handle text in various\norientations that the adversary might use. Moreover, such a system can be\nincorporated into screen readers used to aid the visually impaired. In this\nwork, we extend the scene-text extraction system at Facebook, Rosetta, to\nefficiently handle text in various orientations. Specifically, we incorporate\nthe Rotation Region Proposal Networks (RRPN) in our text extraction pipeline\nand offer practical suggestions for building and deploying a model for\ndetecting and recognizing text in arbitrary orientations efficiently.\nExperimental results show a significant improvement on detecting rotated text."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""A significant number of images shared on social media platforms such as\nFacebook and Instagram contain text in various forms. It's increasingly\nbecoming commonplace for bad actors to share misinformation, hate speech or\nother kinds of harmful content as text overlaid on images on such platforms. A\nscene-text understanding system should hence be able to handle text in various\norientations that the adversary might use. Moreover, such a system can be\nincorporated into screen readers used to aid the visually impaired. In this\nwork, we extend the scene-text extraction system at Facebook, Rosetta, to\nefficiently handle text in various orientations. Specifically, we incorporate\nthe Rotation Region Proposal Networks (RRPN) in our text extraction pipeline\nand offer practical suggestions for building and deploying a model for\ndetecting and recognizing text in arbitrary orientations efficiently.\nExperimental results show a significant improvement on detecting rotated text.""}, 'authors': [{'name': 'Jing Huang'}, {'name': 'Viswanath Sivakumar'}, {'name': 'Mher Mnatsakanyan'}, {'name': 'Guan Pang'}], 'author_detail': {'name': 'Guan Pang'}, 'author': 'Guan Pang', 'links': [{'href': 'http://arxiv.org/abs/1811.07031v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.07031v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
408,http://arxiv.org/abs/1811.04670v1,2018-11-12 11:40:09+00:00,2018-11-12 11:40:09+00:00,A Deep Ensemble Framework for Fake News Detection and Classification,"[arxiv.Result.Author('Arjun Roy'), arxiv.Result.Author('Kingshuk Basak'), arxiv.Result.Author('Asif Ekbal'), arxiv.Result.Author('Pushpak Bhattacharyya')]","Fake news, rumor, incorrect information, and misinformation detection are
nowadays crucial issues as these might have serious consequences for our social
fabrics. The rate of such information is increasing rapidly due to the
availability of enormous web information sources including social media feeds,
news blogs, online newspapers etc.
  In this paper, we develop various deep learning models for detecting fake
news and classifying them into the pre-defined fine-grained categories.
  At first, we develop models based on Convolutional Neural Network (CNN) and
Bi-directional Long Short Term Memory (Bi-LSTM) networks. The representations
obtained from these two models are fed into a Multi-layer Perceptron Model
(MLP) for the final classification. Our experiments on a benchmark dataset show
promising results with an overall accuracy of 44.87\%, which outperforms the
current state of the art.","6 pages, 1 figure, accepted as a short paper in Web Intelligence 2018
  (https://webintelligence2018.com/accepted-papers.html), title changed from
  {""Going Deep to Detect Liars"" Detecting Fake News using Deep Learning} to {A
  Deep Ensemble Framework for Fake News Detection and Classification} as per
  reviewers suggestion",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.04670v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.04670v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.04670v1,"{'id': 'http://arxiv.org/abs/1811.04670v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.04670v1', 'updated': '2018-11-12T11:40:09Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=12, tm_hour=11, tm_min=40, tm_sec=9, tm_wday=0, tm_yday=316, tm_isdst=0), 'published': '2018-11-12T11:40:09Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=12, tm_hour=11, tm_min=40, tm_sec=9, tm_wday=0, tm_yday=316, tm_isdst=0), 'title': 'A Deep Ensemble Framework for Fake News Detection and Classification', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Deep Ensemble Framework for Fake News Detection and Classification'}, 'summary': 'Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.'}, 'authors': [{'name': 'Arjun Roy'}, {'name': 'Kingshuk Basak'}, {'name': 'Asif Ekbal'}, {'name': 'Pushpak Bhattacharyya'}], 'author_detail': {'name': 'Pushpak Bhattacharyya'}, 'author': 'Pushpak Bhattacharyya', 'arxiv_comment': '6 pages, 1 figure, accepted as a short paper in Web Intelligence 2018\n  (https://webintelligence2018.com/accepted-papers.html), title changed from\n  {""Going Deep to Detect Liars"" Detecting Fake News using Deep Learning} to {A\n  Deep Ensemble Framework for Fake News Detection and Classification} as per\n  reviewers suggestion', 'links': [{'href': 'http://arxiv.org/abs/1811.04670v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.04670v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
409,http://arxiv.org/abs/1811.01806v1,2018-11-05 15:43:45+00:00,2018-11-05 15:43:45+00:00,"Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of User Engagement and Challenges","[arxiv.Result.Author('Md Mahfuzul Haque'), arxiv.Result.Author('Mohammad Yousuf'), arxiv.Result.Author('Zahedur Arman'), arxiv.Result.Author('Md Main Uddin Rony'), arxiv.Result.Author('Ahmed Shatil Alam'), arxiv.Result.Author('Kazi Mehedi Hasan'), arxiv.Result.Author('Md Khadimul Islam'), arxiv.Result.Author('Naeemul Hassan')]","Fake news and misinformation spread in developing countries as fast as they
do in developed countries with increasing penetration of the internet and
social media. However, fighting misinformation is more difficult in developing
countries where resources and necessary technologies are scarce. This study
provides an understanding of the challenges various fact-checking initiatives
face in three South Asian countries--Bangladesh, India, and Nepal. In-depth
interviews were conducted with senior editors of six fact-checking initiatives.
Challenges identified include lack of resources, technologies, and political
pressure. An analysis of Facebook pages of these initiatives shows increasing
user engagement with their posts.",,,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1811.01806v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1811.01806v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1811.01806v1,"{'id': 'http://arxiv.org/abs/1811.01806v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1811.01806v1', 'updated': '2018-11-05T15:43:45Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=5, tm_hour=15, tm_min=43, tm_sec=45, tm_wday=0, tm_yday=309, tm_isdst=0), 'published': '2018-11-05T15:43:45Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=5, tm_hour=15, tm_min=43, tm_sec=45, tm_wday=0, tm_yday=309, tm_isdst=0), 'title': 'Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges'}, 'summary': 'Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.'}, 'authors': [{'name': 'Md Mahfuzul Haque'}, {'name': 'Mohammad Yousuf'}, {'name': 'Zahedur Arman'}, {'name': 'Md Main Uddin Rony'}, {'name': 'Ahmed Shatil Alam'}, {'name': 'Kazi Mehedi Hasan'}, {'name': 'Md Khadimul Islam'}, {'name': 'Naeemul Hassan'}], 'author_detail': {'name': 'Naeemul Hassan'}, 'author': 'Naeemul Hassan', 'links': [{'href': 'http://arxiv.org/abs/1811.01806v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1811.01806v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
410,http://arxiv.org/abs/1810.06973v2,2018-10-17 09:09:06+00:00,2018-10-16 13:18:22+00:00,Opinion Dynamics via Search Engines (and other Algorithmic Gatekeepers),"[arxiv.Result.Author('Fabrizio Germano'), arxiv.Result.Author('Francesco Sobbrio')]","Ranking algorithms are the information gatekeepers of the Internet era. We
develop a stylized model to study the effects of ranking algorithms on opinion
dynamics. We consider a search engine that uses an algorithm based on
popularity and on personalization. We find that popularity-based rankings
generate an advantage of the fewer effect: fewer websites reporting a given
signal attract relatively more traffic overall. This highlights a novel,
ranking-driven channel that explains the diffusion of misinformation, as
websites reporting incorrect information may attract an amplified amount of
traffic precisely because they are few. Furthermore, when individuals provide
sufficiently positive feedback to the ranking algorithm, popularity-based
rankings tend to aggregate information while personalization acts in the
opposite direction.",,,,cs.SI,"['cs.SI', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/1810.06973v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1810.06973v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1810.06973v2,"{'id': 'http://arxiv.org/abs/1810.06973v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1810.06973v2', 'updated': '2018-10-17T09:09:06Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=17, tm_hour=9, tm_min=9, tm_sec=6, tm_wday=2, tm_yday=290, tm_isdst=0), 'published': '2018-10-16T13:18:22Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=16, tm_hour=13, tm_min=18, tm_sec=22, tm_wday=1, tm_yday=289, tm_isdst=0), 'title': 'Opinion Dynamics via Search Engines (and other Algorithmic Gatekeepers)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Opinion Dynamics via Search Engines (and other Algorithmic Gatekeepers)'}, 'summary': 'Ranking algorithms are the information gatekeepers of the Internet era. We\ndevelop a stylized model to study the effects of ranking algorithms on opinion\ndynamics. We consider a search engine that uses an algorithm based on\npopularity and on personalization. We find that popularity-based rankings\ngenerate an advantage of the fewer effect: fewer websites reporting a given\nsignal attract relatively more traffic overall. This highlights a novel,\nranking-driven channel that explains the diffusion of misinformation, as\nwebsites reporting incorrect information may attract an amplified amount of\ntraffic precisely because they are few. Furthermore, when individuals provide\nsufficiently positive feedback to the ranking algorithm, popularity-based\nrankings tend to aggregate information while personalization acts in the\nopposite direction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Ranking algorithms are the information gatekeepers of the Internet era. We\ndevelop a stylized model to study the effects of ranking algorithms on opinion\ndynamics. We consider a search engine that uses an algorithm based on\npopularity and on personalization. We find that popularity-based rankings\ngenerate an advantage of the fewer effect: fewer websites reporting a given\nsignal attract relatively more traffic overall. This highlights a novel,\nranking-driven channel that explains the diffusion of misinformation, as\nwebsites reporting incorrect information may attract an amplified amount of\ntraffic precisely because they are few. Furthermore, when individuals provide\nsufficiently positive feedback to the ranking algorithm, popularity-based\nrankings tend to aggregate information while personalization acts in the\nopposite direction.'}, 'authors': [{'name': 'Fabrizio Germano'}, {'name': 'Francesco Sobbrio'}], 'author_detail': {'name': 'Francesco Sobbrio'}, 'author': 'Francesco Sobbrio', 'links': [{'href': 'http://arxiv.org/abs/1810.06973v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1810.06973v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
411,http://arxiv.org/abs/1809.06486v2,2018-09-20 20:49:08+00:00,2018-09-18 00:22:26+00:00,On Misinformation Containment in Online Social Networks,"[arxiv.Result.Author('Guangmo Tong'), arxiv.Result.Author('Weili Wu'), arxiv.Result.Author('Ding-Zhu Du')]","The widespread online misinformation could cause public panic and serious
economic damages. The misinformation containment problem aims at limiting the
spread of misinformation in online social networks by launching competing
campaigns. Motivated by realistic scenarios, we present the first analysis of
the misinformation containment problem for the case when an arbitrary number of
cascades are allowed. This paper makes four contributions. First, we provide a
formal model for multi-cascade diffusion and introduce an important concept
called as cascade priority. Second, we show that the misinformation containment
problem cannot be approximated within a factor of
$\Omega(2^{\log^{1-\epsilon}n^4})$ in polynomial time unless $NP \subseteq
DTIME(n^{\polylog{n}})$. Third, we introduce several types of cascade priority
that are frequently seen in real social networks. Finally, we design novel
algorithms for solving the misinformation containment problem. The
effectiveness of the proposed algorithm is supported by encouraging
experimental results.",NIPS 2018,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1809.06486v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.06486v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.06486v2,"{'id': 'http://arxiv.org/abs/1809.06486v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.06486v2', 'updated': '2018-09-20T20:49:08Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=20, tm_hour=20, tm_min=49, tm_sec=8, tm_wday=3, tm_yday=263, tm_isdst=0), 'published': '2018-09-18T00:22:26Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=18, tm_hour=0, tm_min=22, tm_sec=26, tm_wday=1, tm_yday=261, tm_isdst=0), 'title': 'On Misinformation Containment in Online Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On Misinformation Containment in Online Social Networks'}, 'summary': 'The widespread online misinformation could cause public panic and serious\neconomic damages. The misinformation containment problem aims at limiting the\nspread of misinformation in online social networks by launching competing\ncampaigns. Motivated by realistic scenarios, we present the first analysis of\nthe misinformation containment problem for the case when an arbitrary number of\ncascades are allowed. This paper makes four contributions. First, we provide a\nformal model for multi-cascade diffusion and introduce an important concept\ncalled as cascade priority. Second, we show that the misinformation containment\nproblem cannot be approximated within a factor of\n$\\Omega(2^{\\log^{1-\\epsilon}n^4})$ in polynomial time unless $NP \\subseteq\nDTIME(n^{\\polylog{n}})$. Third, we introduce several types of cascade priority\nthat are frequently seen in real social networks. Finally, we design novel\nalgorithms for solving the misinformation containment problem. The\neffectiveness of the proposed algorithm is supported by encouraging\nexperimental results.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The widespread online misinformation could cause public panic and serious\neconomic damages. The misinformation containment problem aims at limiting the\nspread of misinformation in online social networks by launching competing\ncampaigns. Motivated by realistic scenarios, we present the first analysis of\nthe misinformation containment problem for the case when an arbitrary number of\ncascades are allowed. This paper makes four contributions. First, we provide a\nformal model for multi-cascade diffusion and introduce an important concept\ncalled as cascade priority. Second, we show that the misinformation containment\nproblem cannot be approximated within a factor of\n$\\Omega(2^{\\log^{1-\\epsilon}n^4})$ in polynomial time unless $NP \\subseteq\nDTIME(n^{\\polylog{n}})$. Third, we introduce several types of cascade priority\nthat are frequently seen in real social networks. Finally, we design novel\nalgorithms for solving the misinformation containment problem. The\neffectiveness of the proposed algorithm is supported by encouraging\nexperimental results.'}, 'authors': [{'name': 'Guangmo Tong'}, {'name': 'Weili Wu'}, {'name': 'Ding-Zhu Du'}], 'author_detail': {'name': 'Ding-Zhu Du'}, 'author': 'Ding-Zhu Du', 'arxiv_comment': 'NIPS 2018', 'links': [{'href': 'http://arxiv.org/abs/1809.06486v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.06486v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
412,http://arxiv.org/abs/1809.06416v1,2018-09-17 19:51:18+00:00,2018-09-17 19:51:18+00:00,DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning,"[arxiv.Result.Author('Kashyap Popat'), arxiv.Result.Author('Subhabrata Mukherjee'), arxiv.Result.Author('Andrew Yates'), arxiv.Result.Author('Gerhard Weikum')]","Misinformation such as fake news is one of the big challenges of our society.
Research on automated fact-checking has proposed methods based on supervised
learning, but these approaches do not consider external evidence apart from
labeled training instances. Recent approaches counter this deficit by
considering external sources related to a claim. However, these methods require
substantial feature modeling and rich lexicons. This paper overcomes these
limitations of prior work with an end-to-end model for evidence-aware
credibility assessment of arbitrary textual claims, without any human
intervention. It presents a neural network model that judiciously aggregates
signals from external evidence articles, the language of these articles and the
trustworthiness of their sources. It also derives informative features for
generating user-comprehensible explanations that makes the neural network
predictions transparent to the end-user. Experiments with four datasets and
ablation studies show the strength of our method.",EMNLP 2018,,,cs.CL,"['cs.CL', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1809.06416v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.06416v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.06416v1,"{'id': 'http://arxiv.org/abs/1809.06416v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.06416v1', 'updated': '2018-09-17T19:51:18Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=17, tm_hour=19, tm_min=51, tm_sec=18, tm_wday=0, tm_yday=260, tm_isdst=0), 'published': '2018-09-17T19:51:18Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=17, tm_hour=19, tm_min=51, tm_sec=18, tm_wday=0, tm_yday=260, tm_isdst=0), 'title': 'DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning'}, 'summary': 'Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.'}, 'authors': [{'name': 'Kashyap Popat'}, {'name': 'Subhabrata Mukherjee'}, {'name': 'Andrew Yates'}, {'name': 'Gerhard Weikum'}], 'author_detail': {'name': 'Gerhard Weikum'}, 'author': 'Gerhard Weikum', 'arxiv_comment': 'EMNLP 2018', 'links': [{'href': 'http://arxiv.org/abs/1809.06416v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.06416v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
413,http://arxiv.org/abs/1809.05901v1,2018-09-16 15:49:14+00:00,2018-09-16 15:49:14+00:00,Trends in the Diffusion of Misinformation on Social Media,"[arxiv.Result.Author('Hunt Allcott'), arxiv.Result.Author('Matthew Gentzkow'), arxiv.Result.Author('Chuan Yu')]","We measure trends in the diffusion of misinformation on Facebook and Twitter
between January 2015 and July 2018. We focus on stories from 570 sites that
have been identified as producers of false stories. Interactions with these
sites on both Facebook and Twitter rose steadily through the end of 2016.
Interactions then fell sharply on Facebook while they continued to rise on
Twitter, with the ratio of Facebook engagements to Twitter shares falling by
approximately 60 percent. We see no similar pattern for other news, business,
or culture sites, where interactions have been relatively stable over time and
have followed similar trends on the two platforms both before and after the
election.",,,,cs.SI,"['cs.SI', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Link('http://arxiv.org/abs/1809.05901v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.05901v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.05901v1,"{'id': 'http://arxiv.org/abs/1809.05901v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.05901v1', 'updated': '2018-09-16T15:49:14Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=16, tm_hour=15, tm_min=49, tm_sec=14, tm_wday=6, tm_yday=259, tm_isdst=0), 'published': '2018-09-16T15:49:14Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=16, tm_hour=15, tm_min=49, tm_sec=14, tm_wday=6, tm_yday=259, tm_isdst=0), 'title': 'Trends in the Diffusion of Misinformation on Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trends in the Diffusion of Misinformation on Social Media'}, 'summary': 'We measure trends in the diffusion of misinformation on Facebook and Twitter\nbetween January 2015 and July 2018. We focus on stories from 570 sites that\nhave been identified as producers of false stories. Interactions with these\nsites on both Facebook and Twitter rose steadily through the end of 2016.\nInteractions then fell sharply on Facebook while they continued to rise on\nTwitter, with the ratio of Facebook engagements to Twitter shares falling by\napproximately 60 percent. We see no similar pattern for other news, business,\nor culture sites, where interactions have been relatively stable over time and\nhave followed similar trends on the two platforms both before and after the\nelection.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We measure trends in the diffusion of misinformation on Facebook and Twitter\nbetween January 2015 and July 2018. We focus on stories from 570 sites that\nhave been identified as producers of false stories. Interactions with these\nsites on both Facebook and Twitter rose steadily through the end of 2016.\nInteractions then fell sharply on Facebook while they continued to rise on\nTwitter, with the ratio of Facebook engagements to Twitter shares falling by\napproximately 60 percent. We see no similar pattern for other news, business,\nor culture sites, where interactions have been relatively stable over time and\nhave followed similar trends on the two platforms both before and after the\nelection.'}, 'authors': [{'name': 'Hunt Allcott'}, {'name': 'Matthew Gentzkow'}, {'name': 'Chuan Yu'}], 'author_detail': {'name': 'Chuan Yu'}, 'author': 'Chuan Yu', 'links': [{'href': 'http://arxiv.org/abs/1809.05901v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.05901v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
414,http://arxiv.org/abs/1809.05521v2,2018-11-21 00:22:24+00:00,2018-09-14 17:46:58+00:00,Defending Elections Against Malicious Spread of Misinformation,"[arxiv.Result.Author('Bryan Wilder'), arxiv.Result.Author('Yevgeniy Vorobeychik')]","The integrity of democratic elections depends on voters' access to accurate
information. However, modern media environments, which are dominated by social
media, provide malicious actors with unprecedented ability to manipulate
elections via misinformation, such as fake news. We study a zero-sum game
between an attacker, who attempts to subvert an election by propagating a fake
new story or other misinformation over a set of advertising channels, and a
defender who attempts to limit the attacker's impact. Computing an equilibrium
in this game is challenging as even the pure strategy sets of players are
exponential. Nevertheless, we give provable polynomial-time approximation
algorithms for computing the defender's minimax optimal strategy across a range
of settings, encompassing different population structures as well as models of
the information available to each player. Experimental results confirm that our
algorithms provide near-optimal defender strategies and showcase variations in
the difficulty of defending elections depending on the resources and knowledge
available to the defender.",Full version of paper accepted to AAAI 2019,,,cs.GT,"['cs.GT', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1809.05521v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.05521v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.05521v2,"{'id': 'http://arxiv.org/abs/1809.05521v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.05521v2', 'updated': '2018-11-21T00:22:24Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=11, tm_mday=21, tm_hour=0, tm_min=22, tm_sec=24, tm_wday=2, tm_yday=325, tm_isdst=0), 'published': '2018-09-14T17:46:58Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=14, tm_hour=17, tm_min=46, tm_sec=58, tm_wday=4, tm_yday=257, tm_isdst=0), 'title': 'Defending Elections Against Malicious Spread of Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Defending Elections Against Malicious Spread of Misinformation'}, 'summary': ""The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender.""}, 'authors': [{'name': 'Bryan Wilder'}, {'name': 'Yevgeniy Vorobeychik'}], 'author_detail': {'name': 'Yevgeniy Vorobeychik'}, 'author': 'Yevgeniy Vorobeychik', 'arxiv_comment': 'Full version of paper accepted to AAAI 2019', 'links': [{'href': 'http://arxiv.org/abs/1809.05521v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.05521v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
415,http://arxiv.org/abs/1809.00557v1,2018-09-03 11:27:28+00:00,2018-09-03 11:27:28+00:00,Fake Cures: User-centric Modeling of Health Misinformation in Social Media,"[arxiv.Result.Author('Amira Ghenai'), arxiv.Result.Author('Yelena Mejova')]","Social media's unfettered access has made it an important venue for health
discussion and a resource for patients and their loved ones. However, the
quality of the information available, as well as the motivations of its
posters, has been questioned. This work examines the individuals on social
media that are posting questionable health-related information, and in
particular promoting cancer treatments which have been shown to be ineffective
(making it a kind of misinformation, willful or not). Using a multi-stage user
selection process, we study 4,212 Twitter users who have posted about one of
139 such ""treatments"", and compare them to a baseline of users generally
interested in cancer. Considering features capturing user attributes, writing
style, and sentiment, we build a classifier which is able to identify users
prone to propagate such misinformation at an accuracy of over 90%, providing a
potential tool for public health officials to identify such individuals for
preventive intervention.","ACM Conference on Computer Supported Cooperative Work and Social
  Computing (CSCW) 2018",,,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1809.00557v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1809.00557v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1809.00557v1,"{'id': 'http://arxiv.org/abs/1809.00557v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1809.00557v1', 'updated': '2018-09-03T11:27:28Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=3, tm_hour=11, tm_min=27, tm_sec=28, tm_wday=0, tm_yday=246, tm_isdst=0), 'published': '2018-09-03T11:27:28Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=3, tm_hour=11, tm_min=27, tm_sec=28, tm_wday=0, tm_yday=246, tm_isdst=0), 'title': 'Fake Cures: User-centric Modeling of Health Misinformation in Social\n  Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake Cures: User-centric Modeling of Health Misinformation in Social\n  Media'}, 'summary': 'Social media\'s unfettered access has made it an important venue for health\ndiscussion and a resource for patients and their loved ones. However, the\nquality of the information available, as well as the motivations of its\nposters, has been questioned. This work examines the individuals on social\nmedia that are posting questionable health-related information, and in\nparticular promoting cancer treatments which have been shown to be ineffective\n(making it a kind of misinformation, willful or not). Using a multi-stage user\nselection process, we study 4,212 Twitter users who have posted about one of\n139 such ""treatments"", and compare them to a baseline of users generally\ninterested in cancer. Considering features capturing user attributes, writing\nstyle, and sentiment, we build a classifier which is able to identify users\nprone to propagate such misinformation at an accuracy of over 90%, providing a\npotential tool for public health officials to identify such individuals for\npreventive intervention.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media\'s unfettered access has made it an important venue for health\ndiscussion and a resource for patients and their loved ones. However, the\nquality of the information available, as well as the motivations of its\nposters, has been questioned. This work examines the individuals on social\nmedia that are posting questionable health-related information, and in\nparticular promoting cancer treatments which have been shown to be ineffective\n(making it a kind of misinformation, willful or not). Using a multi-stage user\nselection process, we study 4,212 Twitter users who have posted about one of\n139 such ""treatments"", and compare them to a baseline of users generally\ninterested in cancer. Considering features capturing user attributes, writing\nstyle, and sentiment, we build a classifier which is able to identify users\nprone to propagate such misinformation at an accuracy of over 90%, providing a\npotential tool for public health officials to identify such individuals for\npreventive intervention.'}, 'authors': [{'name': 'Amira Ghenai'}, {'name': 'Yelena Mejova'}], 'author_detail': {'name': 'Yelena Mejova'}, 'author': 'Yelena Mejova', 'arxiv_comment': 'ACM Conference on Computer Supported Cooperative Work and Social\n  Computing (CSCW) 2018', 'links': [{'href': 'http://arxiv.org/abs/1809.00557v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1809.00557v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
416,http://arxiv.org/abs/1808.08524v2,2020-01-21 17:41:41+00:00,2018-08-26 09:46:47+00:00,"When facts fail: Bias, polarisation and truth in social networks","[arxiv.Result.Author('Orowa Sikder'), arxiv.Result.Author('Robert E. Smith'), arxiv.Result.Author('Pierpaolo Vivo'), arxiv.Result.Author('Giacomo Livan')]","Online social networks provide users with unprecedented opportunities to
engage with diverse opinions. At the same time, they enable confirmation bias
on large scales by empowering individuals to self-select narratives they want
to be exposed to. A precise understanding of such tradeoffs is still largely
missing. We introduce a social learning model where most participants in a
network update their beliefs unbiasedly based on new information, while a
minority of participants reject information that is incongruent with their
preexisting beliefs. This simple mechanism generates permanent opinion
polarization and cascade dynamics, and accounts for the aforementioned tradeoff
between confirmation bias and social connectivity through analytic results. We
investigate the model's predictions empirically using US county-level data on
the impact of Internet access on the formation of beliefs about global warming.
We conclude by discussing policy implications of our model, highlighting the
downsides of debunking and suggesting alternative strategies to contrast
misinformation.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1808.08524v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.08524v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.08524v2,"{'id': 'http://arxiv.org/abs/1808.08524v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.08524v2', 'updated': '2020-01-21T17:41:41Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=21, tm_hour=17, tm_min=41, tm_sec=41, tm_wday=1, tm_yday=21, tm_isdst=0), 'published': '2018-08-26T09:46:47Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=26, tm_hour=9, tm_min=46, tm_sec=47, tm_wday=6, tm_yday=238, tm_isdst=0), 'title': 'When facts fail: Bias, polarisation and truth in social networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'When facts fail: Bias, polarisation and truth in social networks'}, 'summary': ""Online social networks provide users with unprecedented opportunities to\nengage with diverse opinions. At the same time, they enable confirmation bias\non large scales by empowering individuals to self-select narratives they want\nto be exposed to. A precise understanding of such tradeoffs is still largely\nmissing. We introduce a social learning model where most participants in a\nnetwork update their beliefs unbiasedly based on new information, while a\nminority of participants reject information that is incongruent with their\npreexisting beliefs. This simple mechanism generates permanent opinion\npolarization and cascade dynamics, and accounts for the aforementioned tradeoff\nbetween confirmation bias and social connectivity through analytic results. We\ninvestigate the model's predictions empirically using US county-level data on\nthe impact of Internet access on the formation of beliefs about global warming.\nWe conclude by discussing policy implications of our model, highlighting the\ndownsides of debunking and suggesting alternative strategies to contrast\nmisinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online social networks provide users with unprecedented opportunities to\nengage with diverse opinions. At the same time, they enable confirmation bias\non large scales by empowering individuals to self-select narratives they want\nto be exposed to. A precise understanding of such tradeoffs is still largely\nmissing. We introduce a social learning model where most participants in a\nnetwork update their beliefs unbiasedly based on new information, while a\nminority of participants reject information that is incongruent with their\npreexisting beliefs. This simple mechanism generates permanent opinion\npolarization and cascade dynamics, and accounts for the aforementioned tradeoff\nbetween confirmation bias and social connectivity through analytic results. We\ninvestigate the model's predictions empirically using US county-level data on\nthe impact of Internet access on the formation of beliefs about global warming.\nWe conclude by discussing policy implications of our model, highlighting the\ndownsides of debunking and suggesting alternative strategies to contrast\nmisinformation.""}, 'authors': [{'name': 'Orowa Sikder'}, {'name': 'Robert E. Smith'}, {'name': 'Pierpaolo Vivo'}, {'name': 'Giacomo Livan'}], 'author_detail': {'name': 'Giacomo Livan'}, 'author': 'Giacomo Livan', 'links': [{'href': 'http://arxiv.org/abs/1808.08524v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.08524v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
417,http://arxiv.org/abs/1808.05927v1,2018-08-17 16:47:52+00:00,2018-08-17 16:47:52+00:00,Characterizing the public perception of WhatsApp through the lens of media,"[arxiv.Result.Author('Josemar Alves Caetano'), arxiv.Result.Author('Gabriel Magno'), arxiv.Result.Author('Evandro Cunha'), arxiv.Result.Author('Wagner Meira Jr.'), arxiv.Result.Author('Humberto T. Marques-Neto'), arxiv.Result.Author('Virgilio Almeida')]","WhatsApp is, as of 2018, a significant component of the global information
and communication infrastructure, especially in developing countries. However,
probably due to its strong end-to-end encryption, WhatsApp became an attractive
place for the dissemination of misinformation, extremism and other forms of
undesirable behavior. In this paper, we investigate the public perception of
WhatsApp through the lens of media. We analyze two large datasets of news and
show the kind of content that is being associated with WhatsApp in different
regions of the world and over time. Our analyses include the examination of
named entities, general vocabulary, and topics addressed in news articles that
mention WhatsApp, as well as the polarity of these texts. Among other results,
we demonstrate that the vocabulary and topics around the term ""whatsapp"" in the
media have been changing over the years and in 2018 concentrate on matters
related to misinformation, politics and criminal scams. More generally, our
findings are useful to understand the impact that tools like WhatsApp play in
the contemporary society and how they are seen by the communities themselves.","Accepted as a full paper at the 2nd International Workshop on Rumours
  and Deception in Social Media (RDSM 2018), co-located with CIKM 2018 in
  Turin. Please cite the RDSM version",,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1808.05927v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.05927v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.05927v1,"{'id': 'http://arxiv.org/abs/1808.05927v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.05927v1', 'updated': '2018-08-17T16:47:52Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=17, tm_hour=16, tm_min=47, tm_sec=52, tm_wday=4, tm_yday=229, tm_isdst=0), 'published': '2018-08-17T16:47:52Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=17, tm_hour=16, tm_min=47, tm_sec=52, tm_wday=4, tm_yday=229, tm_isdst=0), 'title': 'Characterizing the public perception of WhatsApp through the lens of\n  media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Characterizing the public perception of WhatsApp through the lens of\n  media'}, 'summary': 'WhatsApp is, as of 2018, a significant component of the global information\nand communication infrastructure, especially in developing countries. However,\nprobably due to its strong end-to-end encryption, WhatsApp became an attractive\nplace for the dissemination of misinformation, extremism and other forms of\nundesirable behavior. In this paper, we investigate the public perception of\nWhatsApp through the lens of media. We analyze two large datasets of news and\nshow the kind of content that is being associated with WhatsApp in different\nregions of the world and over time. Our analyses include the examination of\nnamed entities, general vocabulary, and topics addressed in news articles that\nmention WhatsApp, as well as the polarity of these texts. Among other results,\nwe demonstrate that the vocabulary and topics around the term ""whatsapp"" in the\nmedia have been changing over the years and in 2018 concentrate on matters\nrelated to misinformation, politics and criminal scams. More generally, our\nfindings are useful to understand the impact that tools like WhatsApp play in\nthe contemporary society and how they are seen by the communities themselves.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'WhatsApp is, as of 2018, a significant component of the global information\nand communication infrastructure, especially in developing countries. However,\nprobably due to its strong end-to-end encryption, WhatsApp became an attractive\nplace for the dissemination of misinformation, extremism and other forms of\nundesirable behavior. In this paper, we investigate the public perception of\nWhatsApp through the lens of media. We analyze two large datasets of news and\nshow the kind of content that is being associated with WhatsApp in different\nregions of the world and over time. Our analyses include the examination of\nnamed entities, general vocabulary, and topics addressed in news articles that\nmention WhatsApp, as well as the polarity of these texts. Among other results,\nwe demonstrate that the vocabulary and topics around the term ""whatsapp"" in the\nmedia have been changing over the years and in 2018 concentrate on matters\nrelated to misinformation, politics and criminal scams. More generally, our\nfindings are useful to understand the impact that tools like WhatsApp play in\nthe contemporary society and how they are seen by the communities themselves.'}, 'authors': [{'name': 'Josemar Alves Caetano'}, {'name': 'Gabriel Magno'}, {'name': 'Evandro Cunha'}, {'name': 'Wagner Meira Jr.'}, {'name': 'Humberto T. Marques-Neto'}, {'name': 'Virgilio Almeida'}], 'author_detail': {'name': 'Virgilio Almeida'}, 'author': 'Virgilio Almeida', 'arxiv_comment': 'Accepted as a full paper at the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM 2018), co-located with CIKM 2018 in\n  Turin. Please cite the RDSM version', 'links': [{'href': 'http://arxiv.org/abs/1808.05927v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.05927v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
418,http://arxiv.org/abs/1808.04671v2,2019-09-10 09:42:39+00:00,2018-08-14 13:15:51+00:00,Sea of Lights: Practical Device-to-Device Security Bootstrapping in the Dark,"[arxiv.Result.Author('Flor Álvarez'), arxiv.Result.Author('Max Kolhagen'), arxiv.Result.Author('Matthias Hollick')]","Practical solutions to bootstrap security in today's information and
communication systems critically depend on centralized services for
authentication as well as key and trust management. This is particularly true
for mobile users. Identity providers such as Google or Facebook have active
user bases of two billion each, and the subscriber number of mobile operators
exceeds five billion unique users as of early 2018. If these centralized
services go completely `dark' due to natural or man made disasters, large scale
blackouts, or country-wide censorship, the users are left without practical
solutions to bootstrap security on their mobile devices. Existing distributed
solutions, for instance, the so-called web-of-trust are not sufficiently
lightweight. Furthermore, they support neither cross-application on mobile
devices nor strong protection of key material using hardware security modules.
We propose Sea of Lights(SoL), a practical lightweight scheme for bootstrapping
device-to-device security wirelessly, thus, enabling secure distributed
self-organized networks. It is tailored to operate `in the dark' and provides
strong protection of key material as well as an intuitive means to build a
lightweight web-of-trust. SoL is particularly well suited for local or urban
operation in scenarios such as the coordination of emergency response, where it
helps containing/limiting the spreading of misinformation. As a proof of
concept, we implement SoL in the Android platform and hence test its
feasibility on real mobile devices. We further evaluate its key performance
aspects using simulation.",,,10.1109/LCN.2018.8638102,cs.NI,"['cs.NI', 'cs.CR', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1109/LCN.2018.8638102', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1808.04671v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1808.04671v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1808.04671v2,"{'id': 'http://arxiv.org/abs/1808.04671v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1808.04671v2', 'updated': '2019-09-10T09:42:39Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=9, tm_mday=10, tm_hour=9, tm_min=42, tm_sec=39, tm_wday=1, tm_yday=253, tm_isdst=0), 'published': '2018-08-14T13:15:51Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=14, tm_hour=13, tm_min=15, tm_sec=51, tm_wday=1, tm_yday=226, tm_isdst=0), 'title': 'Sea of Lights: Practical Device-to-Device Security Bootstrapping in the\n  Dark', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sea of Lights: Practical Device-to-Device Security Bootstrapping in the\n  Dark'}, 'summary': ""Practical solutions to bootstrap security in today's information and\ncommunication systems critically depend on centralized services for\nauthentication as well as key and trust management. This is particularly true\nfor mobile users. Identity providers such as Google or Facebook have active\nuser bases of two billion each, and the subscriber number of mobile operators\nexceeds five billion unique users as of early 2018. If these centralized\nservices go completely `dark' due to natural or man made disasters, large scale\nblackouts, or country-wide censorship, the users are left without practical\nsolutions to bootstrap security on their mobile devices. Existing distributed\nsolutions, for instance, the so-called web-of-trust are not sufficiently\nlightweight. Furthermore, they support neither cross-application on mobile\ndevices nor strong protection of key material using hardware security modules.\nWe propose Sea of Lights(SoL), a practical lightweight scheme for bootstrapping\ndevice-to-device security wirelessly, thus, enabling secure distributed\nself-organized networks. It is tailored to operate `in the dark' and provides\nstrong protection of key material as well as an intuitive means to build a\nlightweight web-of-trust. SoL is particularly well suited for local or urban\noperation in scenarios such as the coordination of emergency response, where it\nhelps containing/limiting the spreading of misinformation. As a proof of\nconcept, we implement SoL in the Android platform and hence test its\nfeasibility on real mobile devices. We further evaluate its key performance\naspects using simulation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Practical solutions to bootstrap security in today's information and\ncommunication systems critically depend on centralized services for\nauthentication as well as key and trust management. This is particularly true\nfor mobile users. Identity providers such as Google or Facebook have active\nuser bases of two billion each, and the subscriber number of mobile operators\nexceeds five billion unique users as of early 2018. If these centralized\nservices go completely `dark' due to natural or man made disasters, large scale\nblackouts, or country-wide censorship, the users are left without practical\nsolutions to bootstrap security on their mobile devices. Existing distributed\nsolutions, for instance, the so-called web-of-trust are not sufficiently\nlightweight. Furthermore, they support neither cross-application on mobile\ndevices nor strong protection of key material using hardware security modules.\nWe propose Sea of Lights(SoL), a practical lightweight scheme for bootstrapping\ndevice-to-device security wirelessly, thus, enabling secure distributed\nself-organized networks. It is tailored to operate `in the dark' and provides\nstrong protection of key material as well as an intuitive means to build a\nlightweight web-of-trust. SoL is particularly well suited for local or urban\noperation in scenarios such as the coordination of emergency response, where it\nhelps containing/limiting the spreading of misinformation. As a proof of\nconcept, we implement SoL in the Android platform and hence test its\nfeasibility on real mobile devices. We further evaluate its key performance\naspects using simulation.""}, 'authors': [{'name': 'Flor Álvarez'}, {'name': 'Max Kolhagen'}, {'name': 'Matthias Hollick'}], 'author_detail': {'name': 'Matthias Hollick'}, 'author': 'Matthias Hollick', 'arxiv_doi': '10.1109/LCN.2018.8638102', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/LCN.2018.8638102', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1808.04671v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1808.04671v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
419,http://arxiv.org/abs/1807.09739v2,2019-03-17 18:37:34+00:00,2018-07-25 17:36:25+00:00,Vulnerable to Misinformation? Verifi!,"[arxiv.Result.Author('Alireza Karduni'), arxiv.Result.Author('Isaac Cho'), arxiv.Result.Author('Ryan Wesslen'), arxiv.Result.Author('Sashank Santhanam'), arxiv.Result.Author('Svitlana Volkova'), arxiv.Result.Author('Dustin Arendt'), arxiv.Result.Author('Samira Shaikh'), arxiv.Result.Author('Wenwen Dou')]","We present Verifi2, a visual analytic system to support the investigation of
misinformation on social media. On the one hand, social media platforms empower
individuals and organizations by democratizing the sharing of information. On
the other hand, even well-informed and experienced social media users are
vulnerable to misinformation. To address the issue, various models and studies
have emerged from multiple disciplines to detect and understand the effects of
misinformation. However, there is still a lack of intuitive and accessible
tools that help social media users distinguish misinformation from verified
news. In this paper, we present Verifi2, a visual analytic system that uses
state-of-the-art computational methods to highlight salient features from text,
social network, and images. By exploring news on a source level through
multiple coordinated views in Verifi2, users can interact with the complex
dimensions that characterize misinformation and contrast how real and
suspicious news outlets differ on these dimensions. To evaluate Verifi2, we
conduct interviews with experts in digital media, journalism, education,
psychology, and computing who study misinformation. Our interviews show
promising potential for Verifi2 to serve as an educational tool on
misinformation. Furthermore, our interview results highlight the complexity of
the problem of combating misinformation and call for more work from the
visualization community.","11 pages, 7 figures",,,cs.HC,"['cs.HC', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1807.09739v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.09739v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.09739v2,"{'id': 'http://arxiv.org/abs/1807.09739v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.09739v2', 'updated': '2019-03-17T18:37:34Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=3, tm_mday=17, tm_hour=18, tm_min=37, tm_sec=34, tm_wday=6, tm_yday=76, tm_isdst=0), 'published': '2018-07-25T17:36:25Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=25, tm_hour=17, tm_min=36, tm_sec=25, tm_wday=2, tm_yday=206, tm_isdst=0), 'title': 'Vulnerable to Misinformation? Verifi!', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Vulnerable to Misinformation? Verifi!'}, 'summary': 'We present Verifi2, a visual analytic system to support the investigation of\nmisinformation on social media. On the one hand, social media platforms empower\nindividuals and organizations by democratizing the sharing of information. On\nthe other hand, even well-informed and experienced social media users are\nvulnerable to misinformation. To address the issue, various models and studies\nhave emerged from multiple disciplines to detect and understand the effects of\nmisinformation. However, there is still a lack of intuitive and accessible\ntools that help social media users distinguish misinformation from verified\nnews. In this paper, we present Verifi2, a visual analytic system that uses\nstate-of-the-art computational methods to highlight salient features from text,\nsocial network, and images. By exploring news on a source level through\nmultiple coordinated views in Verifi2, users can interact with the complex\ndimensions that characterize misinformation and contrast how real and\nsuspicious news outlets differ on these dimensions. To evaluate Verifi2, we\nconduct interviews with experts in digital media, journalism, education,\npsychology, and computing who study misinformation. Our interviews show\npromising potential for Verifi2 to serve as an educational tool on\nmisinformation. Furthermore, our interview results highlight the complexity of\nthe problem of combating misinformation and call for more work from the\nvisualization community.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We present Verifi2, a visual analytic system to support the investigation of\nmisinformation on social media. On the one hand, social media platforms empower\nindividuals and organizations by democratizing the sharing of information. On\nthe other hand, even well-informed and experienced social media users are\nvulnerable to misinformation. To address the issue, various models and studies\nhave emerged from multiple disciplines to detect and understand the effects of\nmisinformation. However, there is still a lack of intuitive and accessible\ntools that help social media users distinguish misinformation from verified\nnews. In this paper, we present Verifi2, a visual analytic system that uses\nstate-of-the-art computational methods to highlight salient features from text,\nsocial network, and images. By exploring news on a source level through\nmultiple coordinated views in Verifi2, users can interact with the complex\ndimensions that characterize misinformation and contrast how real and\nsuspicious news outlets differ on these dimensions. To evaluate Verifi2, we\nconduct interviews with experts in digital media, journalism, education,\npsychology, and computing who study misinformation. Our interviews show\npromising potential for Verifi2 to serve as an educational tool on\nmisinformation. Furthermore, our interview results highlight the complexity of\nthe problem of combating misinformation and call for more work from the\nvisualization community.'}, 'authors': [{'name': 'Alireza Karduni'}, {'name': 'Isaac Cho'}, {'name': 'Ryan Wesslen'}, {'name': 'Sashank Santhanam'}, {'name': 'Svitlana Volkova'}, {'name': 'Dustin Arendt'}, {'name': 'Samira Shaikh'}, {'name': 'Wenwen Dou'}], 'author_detail': {'name': 'Wenwen Dou'}, 'author': 'Wenwen Dou', 'arxiv_comment': '11 pages, 7 figures', 'links': [{'href': 'http://arxiv.org/abs/1807.09739v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.09739v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
420,http://arxiv.org/abs/1807.06926v1,2018-07-18 13:41:57+00:00,2018-07-18 13:41:57+00:00,"Fake news as we feel it: perception and conceptualization of the term ""fake news"" in the media","[arxiv.Result.Author('Evandro Cunha'), arxiv.Result.Author('Gabriel Magno'), arxiv.Result.Author('Josemar Caetano'), arxiv.Result.Author('Douglas Teixeira'), arxiv.Result.Author('Virgilio Almeida')]","In this article, we quantitatively analyze how the term ""fake news"" is being
shaped in news media in recent years. We study the perception and the
conceptualization of this term in the traditional media using eight years of
data collected from news outlets based in 20 countries. Our results not only
corroborate previous indications of a high increase in the usage of the
expression ""fake news"", but also show contextual changes around this expression
after the United States presidential election of 2016. Among other results, we
found changes in the related vocabulary, in the mentioned entities, in the
surrounding topics and in the contextual polarity around the term ""fake news"",
suggesting that this expression underwent a change in perception and
conceptualization after 2016. These outcomes expand the understandings on the
usage of the term ""fake news"", helping to comprehend and more accurately
characterize this relevant social phenomenon linked to misinformation and
manipulation.","Accepted as a full paper at the 10th International Conference on
  Social Informatics (SocInfo 2018). Please cite the SocInfo version",,,cs.CL,"['cs.CL', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1807.06926v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.06926v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.06926v1,"{'id': 'http://arxiv.org/abs/1807.06926v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.06926v1', 'updated': '2018-07-18T13:41:57Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=41, tm_sec=57, tm_wday=2, tm_yday=199, tm_isdst=0), 'published': '2018-07-18T13:41:57Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=18, tm_hour=13, tm_min=41, tm_sec=57, tm_wday=2, tm_yday=199, tm_isdst=0), 'title': 'Fake news as we feel it: perception and conceptualization of the term\n  ""fake news"" in the media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake news as we feel it: perception and conceptualization of the term\n  ""fake news"" in the media'}, 'summary': 'In this article, we quantitatively analyze how the term ""fake news"" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression ""fake news"", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term ""fake news"",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term ""fake news"", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this article, we quantitatively analyze how the term ""fake news"" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression ""fake news"", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term ""fake news"",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term ""fake news"", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.'}, 'authors': [{'name': 'Evandro Cunha'}, {'name': 'Gabriel Magno'}, {'name': 'Josemar Caetano'}, {'name': 'Douglas Teixeira'}, {'name': 'Virgilio Almeida'}], 'author_detail': {'name': 'Virgilio Almeida'}, 'author': 'Virgilio Almeida', 'arxiv_comment': 'Accepted as a full paper at the 10th International Conference on\n  Social Informatics (SocInfo 2018). Please cite the SocInfo version', 'links': [{'href': 'http://arxiv.org/abs/1807.06926v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.06926v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
421,http://arxiv.org/abs/1807.05327v1,2018-07-14 03:33:36+00:00,2018-07-14 03:33:36+00:00,How Humans versus Bots React to Deceptive and Trusted News Sources: A Case Study of Active Users,"[arxiv.Result.Author('Maria Glenski'), arxiv.Result.Author('Tim Weninger'), arxiv.Result.Author('Svitlana Volkova')]","Society's reliance on social media as a primary source of news has spawned a
renewed focus on the spread of misinformation. In this work, we identify the
differences in how social media accounts identified as bots react to news
sources of varying credibility, regardless of the veracity of the content those
sources have shared. We analyze bot and human responses annotated using a
fine-grained model that labels responses as being an answer, appreciation,
agreement, disagreement, an elaboration, humor, or a negative reaction. We
present key findings of our analysis into the prevalence of bots, the variety
and speed of bot and human reactions, and the disparity in authorship of
reaction tweets between these two sub-populations. We observe that bots are
responsible for 9-15% of the reactions to sources of any given type but
comprise only 7-10% of accounts responsible for reaction-tweets; trusted news
sources have the highest proportion of humans who reacted; bots respond with
significantly shorter delays than humans when posting answer-reactions in
response to sources identified as propaganda. Finally, we report significantly
different inequality levels in reaction rates for accounts identified as bots
vs not.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1807.05327v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.05327v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.05327v1,"{'id': 'http://arxiv.org/abs/1807.05327v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.05327v1', 'updated': '2018-07-14T03:33:36Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=14, tm_hour=3, tm_min=33, tm_sec=36, tm_wday=5, tm_yday=195, tm_isdst=0), 'published': '2018-07-14T03:33:36Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=14, tm_hour=3, tm_min=33, tm_sec=36, tm_wday=5, tm_yday=195, tm_isdst=0), 'title': 'How Humans versus Bots React to Deceptive and Trusted News Sources: A\n  Case Study of Active Users', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'How Humans versus Bots React to Deceptive and Trusted News Sources: A\n  Case Study of Active Users'}, 'summary': ""Society's reliance on social media as a primary source of news has spawned a\nrenewed focus on the spread of misinformation. In this work, we identify the\ndifferences in how social media accounts identified as bots react to news\nsources of varying credibility, regardless of the veracity of the content those\nsources have shared. We analyze bot and human responses annotated using a\nfine-grained model that labels responses as being an answer, appreciation,\nagreement, disagreement, an elaboration, humor, or a negative reaction. We\npresent key findings of our analysis into the prevalence of bots, the variety\nand speed of bot and human reactions, and the disparity in authorship of\nreaction tweets between these two sub-populations. We observe that bots are\nresponsible for 9-15% of the reactions to sources of any given type but\ncomprise only 7-10% of accounts responsible for reaction-tweets; trusted news\nsources have the highest proportion of humans who reacted; bots respond with\nsignificantly shorter delays than humans when posting answer-reactions in\nresponse to sources identified as propaganda. Finally, we report significantly\ndifferent inequality levels in reaction rates for accounts identified as bots\nvs not."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Society's reliance on social media as a primary source of news has spawned a\nrenewed focus on the spread of misinformation. In this work, we identify the\ndifferences in how social media accounts identified as bots react to news\nsources of varying credibility, regardless of the veracity of the content those\nsources have shared. We analyze bot and human responses annotated using a\nfine-grained model that labels responses as being an answer, appreciation,\nagreement, disagreement, an elaboration, humor, or a negative reaction. We\npresent key findings of our analysis into the prevalence of bots, the variety\nand speed of bot and human reactions, and the disparity in authorship of\nreaction tweets between these two sub-populations. We observe that bots are\nresponsible for 9-15% of the reactions to sources of any given type but\ncomprise only 7-10% of accounts responsible for reaction-tweets; trusted news\nsources have the highest proportion of humans who reacted; bots respond with\nsignificantly shorter delays than humans when posting answer-reactions in\nresponse to sources identified as propaganda. Finally, we report significantly\ndifferent inequality levels in reaction rates for accounts identified as bots\nvs not.""}, 'authors': [{'name': 'Maria Glenski'}, {'name': 'Tim Weninger'}, {'name': 'Svitlana Volkova'}], 'author_detail': {'name': 'Svitlana Volkova'}, 'author': 'Svitlana Volkova', 'links': [{'href': 'http://arxiv.org/abs/1807.05327v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.05327v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
422,http://arxiv.org/abs/1807.01162v2,2020-01-13 04:35:08+00:00,2018-07-01 18:58:59+00:00,Reverse Prevention Sampling for Misinformation Mitigation in Social Networks,"[arxiv.Result.Author('Michael Simpson'), arxiv.Result.Author('Venkatesh Srinivasan'), arxiv.Result.Author('Alex Thomo')]","In this work, we consider misinformation propagating through a social network
and study the problem of its prevention. In this problem, a ""bad"" campaign
starts propagating from a set of seed nodes in the network and we use the
notion of a limiting (or ""good"") campaign to counteract the effect of
misinformation. The goal is to identify a set of $k$ users that need to be
convinced to adopt the limiting campaign so as to minimize the number of people
that adopt the ""bad"" campaign at the end of both propagation processes.
  This work presents \emph{RPS} (Reverse Prevention Sampling), an algorithm
that provides a scalable solution to the misinformation mitigation problem. Our
theoretical analysis shows that \emph{RPS} runs in $O((k + l)(n + m)(\frac{1}{1
- \gamma}) \log n / \epsilon^2 )$ expected time and returns a $(1 - 1/e -
\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where
$\gamma$ is a typically small network parameter and $l$ is a confidence
parameter). The time complexity of \emph{RPS} substantially improves upon the
previously best-known algorithms that run in time $\Omega(m n k \cdot
POLY(\epsilon^{-1}))$. We experimentally evaluate \emph{RPS} on large datasets
and show that it outperforms the state-of-the-art solution by several orders of
magnitude in terms of running time. This demonstrates that misinformation
mitigation can be made practical while still offering strong theoretical
guarantees.","arXiv admin note: text overlap with arXiv:1404.0900, arXiv:1212.0884
  by other authors",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1807.01162v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1807.01162v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1807.01162v2,"{'id': 'http://arxiv.org/abs/1807.01162v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1807.01162v2', 'updated': '2020-01-13T04:35:08Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=1, tm_mday=13, tm_hour=4, tm_min=35, tm_sec=8, tm_wday=0, tm_yday=13, tm_isdst=0), 'published': '2018-07-01T18:58:59Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=1, tm_hour=18, tm_min=58, tm_sec=59, tm_wday=6, tm_yday=182, tm_isdst=0), 'title': 'Reverse Prevention Sampling for Misinformation Mitigation in Social\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Reverse Prevention Sampling for Misinformation Mitigation in Social\n  Networks'}, 'summary': 'In this work, we consider misinformation propagating through a social network\nand study the problem of its prevention. In this problem, a ""bad"" campaign\nstarts propagating from a set of seed nodes in the network and we use the\nnotion of a limiting (or ""good"") campaign to counteract the effect of\nmisinformation. The goal is to identify a set of $k$ users that need to be\nconvinced to adopt the limiting campaign so as to minimize the number of people\nthat adopt the ""bad"" campaign at the end of both propagation processes.\n  This work presents \\emph{RPS} (Reverse Prevention Sampling), an algorithm\nthat provides a scalable solution to the misinformation mitigation problem. Our\ntheoretical analysis shows that \\emph{RPS} runs in $O((k + l)(n + m)(\\frac{1}{1\n- \\gamma}) \\log n / \\epsilon^2 )$ expected time and returns a $(1 - 1/e -\n\\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where\n$\\gamma$ is a typically small network parameter and $l$ is a confidence\nparameter). The time complexity of \\emph{RPS} substantially improves upon the\npreviously best-known algorithms that run in time $\\Omega(m n k \\cdot\nPOLY(\\epsilon^{-1}))$. We experimentally evaluate \\emph{RPS} on large datasets\nand show that it outperforms the state-of-the-art solution by several orders of\nmagnitude in terms of running time. This demonstrates that misinformation\nmitigation can be made practical while still offering strong theoretical\nguarantees.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this work, we consider misinformation propagating through a social network\nand study the problem of its prevention. In this problem, a ""bad"" campaign\nstarts propagating from a set of seed nodes in the network and we use the\nnotion of a limiting (or ""good"") campaign to counteract the effect of\nmisinformation. The goal is to identify a set of $k$ users that need to be\nconvinced to adopt the limiting campaign so as to minimize the number of people\nthat adopt the ""bad"" campaign at the end of both propagation processes.\n  This work presents \\emph{RPS} (Reverse Prevention Sampling), an algorithm\nthat provides a scalable solution to the misinformation mitigation problem. Our\ntheoretical analysis shows that \\emph{RPS} runs in $O((k + l)(n + m)(\\frac{1}{1\n- \\gamma}) \\log n / \\epsilon^2 )$ expected time and returns a $(1 - 1/e -\n\\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where\n$\\gamma$ is a typically small network parameter and $l$ is a confidence\nparameter). The time complexity of \\emph{RPS} substantially improves upon the\npreviously best-known algorithms that run in time $\\Omega(m n k \\cdot\nPOLY(\\epsilon^{-1}))$. We experimentally evaluate \\emph{RPS} on large datasets\nand show that it outperforms the state-of-the-art solution by several orders of\nmagnitude in terms of running time. This demonstrates that misinformation\nmitigation can be made practical while still offering strong theoretical\nguarantees.'}, 'authors': [{'name': 'Michael Simpson'}, {'name': 'Venkatesh Srinivasan'}, {'name': 'Alex Thomo'}], 'author_detail': {'name': 'Alex Thomo'}, 'author': 'Alex Thomo', 'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1404.0900, arXiv:1212.0884\n  by other authors', 'links': [{'href': 'http://arxiv.org/abs/1807.01162v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1807.01162v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
423,http://arxiv.org/abs/1806.07687v2,2018-09-05 12:47:39+00:00,2018-06-20 12:13:53+00:00,"Automated Fact Checking: Task formulations, methods and future directions","[arxiv.Result.Author('James Thorne'), arxiv.Result.Author('Andreas Vlachos')]","The recently increased focus on misinformation has stimulated research in
fact checking, the task of assessing the truthfulness of a claim. Research in
automating this task has been conducted in a variety of disciplines including
natural language processing, machine learning, knowledge representation,
databases, and journalism. While there has been substantial progress, relevant
papers and articles have been published in research communities that are often
unaware of each other and use inconsistent terminology, thus impeding
understanding and further progress. In this paper we survey automated fact
checking research stemming from natural language processing and related
disciplines, unifying the task formulations and methodologies across papers and
authors. Furthermore, we highlight the use of evidence as an important
distinguishing factor among them cutting across task formulations and methods.
We conclude with proposing avenues for future NLP research on automated fact
checking.","Published at the 27th International Conference on Computational
  Linguistics (COLING 2018)",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1806.07687v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.07687v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.07687v2,"{'id': 'http://arxiv.org/abs/1806.07687v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.07687v2', 'updated': '2018-09-05T12:47:39Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=5, tm_hour=12, tm_min=47, tm_sec=39, tm_wday=2, tm_yday=248, tm_isdst=0), 'published': '2018-06-20T12:13:53Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=20, tm_hour=12, tm_min=13, tm_sec=53, tm_wday=2, tm_yday=171, tm_isdst=0), 'title': 'Automated Fact Checking: Task formulations, methods and future\n  directions', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automated Fact Checking: Task formulations, methods and future\n  directions'}, 'summary': 'The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.'}, 'authors': [{'name': 'James Thorne'}, {'name': 'Andreas Vlachos'}], 'author_detail': {'name': 'Andreas Vlachos'}, 'author': 'Andreas Vlachos', 'arxiv_comment': 'Published at the 27th International Conference on Computational\n  Linguistics (COLING 2018)', 'links': [{'href': 'http://arxiv.org/abs/1806.07687v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.07687v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
424,http://arxiv.org/abs/1806.07516v2,2019-10-09 22:04:46+00:00,2018-06-20 01:26:21+00:00,The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake News,"[arxiv.Result.Author('Nguyen Vo'), arxiv.Result.Author('Kyumin Lee')]","A large body of research work and efforts have been focused on detecting fake
news and building online fact-check systems in order to debunk fake news as
soon as possible. Despite the existence of these systems, fake news is still
wildly shared by online users. It indicates that these systems may not be fully
utilized. After detecting fake news, what is the next step to stop people from
sharing it? How can we improve the utilization of these fact-check systems? To
fill this gap, in this paper, we (i) collect and analyze online users called
guardians, who correct misinformation and fake news in online discussions by
referring fact-checking URLs; and (ii) propose a novel fact-checking URL
recommendation model to encourage the guardians to engage more in fact-checking
activities. We found that the guardians usually took less than one day to reply
to claims in online conversations and took another day to spread verified
information to hundreds of millions of followers. Our proposed recommendation
model outperformed four state-of-the-art models by 11%~33%. Our source code and
dataset are available at https://github.com/nguyenvo09/CombatingFakeNews.",SIGIR 2018,,,cs.IR,"['cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1806.07516v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.07516v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.07516v2,"{'id': 'http://arxiv.org/abs/1806.07516v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.07516v2', 'updated': '2019-10-09T22:04:46Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=9, tm_hour=22, tm_min=4, tm_sec=46, tm_wday=2, tm_yday=282, tm_isdst=0), 'published': '2018-06-20T01:26:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=20, tm_hour=1, tm_min=26, tm_sec=21, tm_wday=2, tm_yday=171, tm_isdst=0), 'title': 'The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News'}, 'summary': 'A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.'}, 'authors': [{'name': 'Nguyen Vo'}, {'name': 'Kyumin Lee'}], 'author_detail': {'name': 'Kyumin Lee'}, 'author': 'Kyumin Lee', 'arxiv_comment': 'SIGIR 2018', 'links': [{'href': 'http://arxiv.org/abs/1806.07516v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.07516v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
425,http://arxiv.org/abs/1806.02720v1,2018-06-07 15:09:57+00:00,2018-06-07 15:09:57+00:00,"Anchored in a Data Storm: How Anchoring Bias Can Affect User Strategy, Confidence, and Decisions in Visual Analytics","[arxiv.Result.Author('Ryan Wesslen'), arxiv.Result.Author('Sashank Santhanam'), arxiv.Result.Author('Alireza Karduni'), arxiv.Result.Author('Isaac Cho'), arxiv.Result.Author('Samira Shaikh'), arxiv.Result.Author('Wenwen Dou')]","Cognitive biases have been shown to lead to faulty decision-making. Recent
research has demonstrated that the effect of cognitive biases, anchoring bias
in particular, transfers to information visualization and visual analytics.
However, it is still unclear how users of visual interfaces can be anchored and
the impact of anchoring on user performance and decision-making process. To
investigate, we performed two rounds of between-subjects, in-laboratory
experiments with 94 participants to analyze the effect of visual anchors and
strategy cues in decision-making with a visual analytic system that employs
coordinated multiple view design. The decision-making task is identifying
misinformation from Twitter news accounts. Participants were randomly assigned
one of three treatment groups (including control) in which participant training
processes were modified. Our findings reveal that strategy cues and visual
anchors (scenario videos) can significantly affect user activity, speed,
confidence, and, under certain circumstances, accuracy. We discuss the
implications of our experiment results on training users how to use a newly
developed visual interface. We call for more careful consideration into how
visualization designers and researchers train users to avoid unintentionally
anchoring users and thus affecting the end result.",,,,cs.HC,['cs.HC'],"[arxiv.Result.Link('http://arxiv.org/abs/1806.02720v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.02720v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.02720v1,"{'id': 'http://arxiv.org/abs/1806.02720v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.02720v1', 'updated': '2018-06-07T15:09:57Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=7, tm_hour=15, tm_min=9, tm_sec=57, tm_wday=3, tm_yday=158, tm_isdst=0), 'published': '2018-06-07T15:09:57Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=7, tm_hour=15, tm_min=9, tm_sec=57, tm_wday=3, tm_yday=158, tm_isdst=0), 'title': 'Anchored in a Data Storm: How Anchoring Bias Can Affect User Strategy,\n  Confidence, and Decisions in Visual Analytics', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Anchored in a Data Storm: How Anchoring Bias Can Affect User Strategy,\n  Confidence, and Decisions in Visual Analytics'}, 'summary': 'Cognitive biases have been shown to lead to faulty decision-making. Recent\nresearch has demonstrated that the effect of cognitive biases, anchoring bias\nin particular, transfers to information visualization and visual analytics.\nHowever, it is still unclear how users of visual interfaces can be anchored and\nthe impact of anchoring on user performance and decision-making process. To\ninvestigate, we performed two rounds of between-subjects, in-laboratory\nexperiments with 94 participants to analyze the effect of visual anchors and\nstrategy cues in decision-making with a visual analytic system that employs\ncoordinated multiple view design. The decision-making task is identifying\nmisinformation from Twitter news accounts. Participants were randomly assigned\none of three treatment groups (including control) in which participant training\nprocesses were modified. Our findings reveal that strategy cues and visual\nanchors (scenario videos) can significantly affect user activity, speed,\nconfidence, and, under certain circumstances, accuracy. We discuss the\nimplications of our experiment results on training users how to use a newly\ndeveloped visual interface. We call for more careful consideration into how\nvisualization designers and researchers train users to avoid unintentionally\nanchoring users and thus affecting the end result.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cognitive biases have been shown to lead to faulty decision-making. Recent\nresearch has demonstrated that the effect of cognitive biases, anchoring bias\nin particular, transfers to information visualization and visual analytics.\nHowever, it is still unclear how users of visual interfaces can be anchored and\nthe impact of anchoring on user performance and decision-making process. To\ninvestigate, we performed two rounds of between-subjects, in-laboratory\nexperiments with 94 participants to analyze the effect of visual anchors and\nstrategy cues in decision-making with a visual analytic system that employs\ncoordinated multiple view design. The decision-making task is identifying\nmisinformation from Twitter news accounts. Participants were randomly assigned\none of three treatment groups (including control) in which participant training\nprocesses were modified. Our findings reveal that strategy cues and visual\nanchors (scenario videos) can significantly affect user activity, speed,\nconfidence, and, under certain circumstances, accuracy. We discuss the\nimplications of our experiment results on training users how to use a newly\ndeveloped visual interface. We call for more careful consideration into how\nvisualization designers and researchers train users to avoid unintentionally\nanchoring users and thus affecting the end result.'}, 'authors': [{'name': 'Ryan Wesslen'}, {'name': 'Sashank Santhanam'}, {'name': 'Alireza Karduni'}, {'name': 'Isaac Cho'}, {'name': 'Samira Shaikh'}, {'name': 'Wenwen Dou'}], 'author_detail': {'name': 'Wenwen Dou'}, 'author': 'Wenwen Dou', 'links': [{'href': 'http://arxiv.org/abs/1806.02720v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.02720v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
426,http://arxiv.org/abs/1806.09541v1,2018-06-06 10:47:20+00:00,2018-06-06 10:47:20+00:00,"Technology, Propaganda, and the Limits of Human Intellect",[arxiv.Result.Author('Panagiotis Metaxas')],"""Fake news"" is a recent phenomenon, but misinformation and propaganda are
not. Our new communication technologies make it easy for us to be exposed to
high volumes of true, false, irrelevant, and unprovable information. Future AI
is expected to amplify the problem even more. At the same time, our brains are
reaching their limits in handling information. How should we respond to
propaganda? Technology can help, but relying on it alone will not suffice in
the long term. We also need ethical policies, laws, regulations, and trusted
authorities, including fact-checkers. However, we will not solve the problem
without the active engagement of the educated citizen. Epistemological
education, recognition of self biases and protection of our channels of
communication and trusted networks are all needed to overcome the problem and
continue our progress as democratic societies.",12 pages,,,cs.GL,"['cs.GL', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1806.09541v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1806.09541v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1806.09541v1,"{'id': 'http://arxiv.org/abs/1806.09541v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1806.09541v1', 'updated': '2018-06-06T10:47:20Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=6, tm_hour=10, tm_min=47, tm_sec=20, tm_wday=2, tm_yday=157, tm_isdst=0), 'published': '2018-06-06T10:47:20Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=6, tm_hour=10, tm_min=47, tm_sec=20, tm_wday=2, tm_yday=157, tm_isdst=0), 'title': 'Technology, Propaganda, and the Limits of Human Intellect', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Technology, Propaganda, and the Limits of Human Intellect'}, 'summary': '""Fake news"" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Fake news"" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.'}, 'authors': [{'name': 'Panagiotis Metaxas'}], 'author_detail': {'name': 'Panagiotis Metaxas'}, 'author': 'Panagiotis Metaxas', 'arxiv_comment': '12 pages', 'links': [{'href': 'http://arxiv.org/abs/1806.09541v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1806.09541v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
427,http://arxiv.org/abs/1805.11303v1,2018-05-29 08:34:53+00:00,2018-05-29 08:34:53+00:00,Trust-based dynamic linear threshold models for non-competitive and competitive influence propagation,"[arxiv.Result.Author('Antonio Caliò'), arxiv.Result.Author('Andrea Tagarelli')]","What are the key-features that enable an information diffusion model to
explain the inherent dynamic, and often competitive, nature of real-world
propagation phenomena? In this paper we aim to answer this question by
proposing a novel class of diffusion models, inspired by the classic Linear
Threshold model, and built around the following aspects: trust/distrust in the
user relationships, which is leveraged to model different effects of social
influence on the decisions taken by an individual; changes in adopting one or
alternative information items; hesitation towards adopting an information item
over time; latency in the propagation; time horizon for the unfolding of the
diffusion process; and multiple cascades of information that might occur
competitively. To the best of our knowledge, the above aspects have never been
unified into the same LT-based diffusion model. We also define different
strategies for the selection of the initial influencers to simulate
non-competitive and competitive diffusion scenarios, particularly related to
the problem of limitation of misinformation spread. Results on publicly
available networks have shown the meaningfulness and uniqueness of our models.","Accepted (May 5, 2018) at the IEEE TrustCom/BigDataSE 2018 Conference",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1805.11303v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1805.11303v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1805.11303v1,"{'id': 'http://arxiv.org/abs/1805.11303v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.11303v1', 'updated': '2018-05-29T08:34:53Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=29, tm_hour=8, tm_min=34, tm_sec=53, tm_wday=1, tm_yday=149, tm_isdst=0), 'published': '2018-05-29T08:34:53Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=29, tm_hour=8, tm_min=34, tm_sec=53, tm_wday=1, tm_yday=149, tm_isdst=0), 'title': 'Trust-based dynamic linear threshold models for non-competitive and\n  competitive influence propagation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Trust-based dynamic linear threshold models for non-competitive and\n  competitive influence propagation'}, 'summary': 'What are the key-features that enable an information diffusion model to\nexplain the inherent dynamic, and often competitive, nature of real-world\npropagation phenomena? In this paper we aim to answer this question by\nproposing a novel class of diffusion models, inspired by the classic Linear\nThreshold model, and built around the following aspects: trust/distrust in the\nuser relationships, which is leveraged to model different effects of social\ninfluence on the decisions taken by an individual; changes in adopting one or\nalternative information items; hesitation towards adopting an information item\nover time; latency in the propagation; time horizon for the unfolding of the\ndiffusion process; and multiple cascades of information that might occur\ncompetitively. To the best of our knowledge, the above aspects have never been\nunified into the same LT-based diffusion model. We also define different\nstrategies for the selection of the initial influencers to simulate\nnon-competitive and competitive diffusion scenarios, particularly related to\nthe problem of limitation of misinformation spread. Results on publicly\navailable networks have shown the meaningfulness and uniqueness of our models.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What are the key-features that enable an information diffusion model to\nexplain the inherent dynamic, and often competitive, nature of real-world\npropagation phenomena? In this paper we aim to answer this question by\nproposing a novel class of diffusion models, inspired by the classic Linear\nThreshold model, and built around the following aspects: trust/distrust in the\nuser relationships, which is leveraged to model different effects of social\ninfluence on the decisions taken by an individual; changes in adopting one or\nalternative information items; hesitation towards adopting an information item\nover time; latency in the propagation; time horizon for the unfolding of the\ndiffusion process; and multiple cascades of information that might occur\ncompetitively. To the best of our knowledge, the above aspects have never been\nunified into the same LT-based diffusion model. We also define different\nstrategies for the selection of the initial influencers to simulate\nnon-competitive and competitive diffusion scenarios, particularly related to\nthe problem of limitation of misinformation spread. Results on publicly\navailable networks have shown the meaningfulness and uniqueness of our models.'}, 'authors': [{'name': 'Antonio Caliò'}, {'name': 'Andrea Tagarelli'}], 'author_detail': {'name': 'Andrea Tagarelli'}, 'author': 'Andrea Tagarelli', 'arxiv_comment': 'Accepted (May 5, 2018) at the IEEE TrustCom/BigDataSE 2018 Conference', 'links': [{'href': 'http://arxiv.org/abs/1805.11303v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.11303v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
428,http://arxiv.org/abs/1805.08030v1,2018-05-21 13:01:56+00:00,2018-05-21 13:01:56+00:00,Polarization Rank: A Study on European News Consumption on Facebook,"[arxiv.Result.Author('Ana Lucía Schmidt'), arxiv.Result.Author('Fabiana Zollo'), arxiv.Result.Author('Antonio Scala'), arxiv.Result.Author('Walter Quattrociocchi')]","The advent of WWW changed the way we can produce and access information.
Recent studies showed that users tend to select information that is consistent
with their system of beliefs, forming polarized groups of like-minded people
around shared narratives where dissenting information is ignored. In this
environment, users cooperate to frame and reinforce their shared narrative
making any attempt at debunking inefficient. Such a configuration occurs even
in the consumption of news online, and considering that 63% of users access
news directly form social media, one hypothesis is that more polarization
allows for further spreading of misinformation. Along this path, we focus on
the polarization of users around news outlets on Facebook in different European
countries (Italy, France, Spain and Germany). First, we compare the pages'
posting behavior and the users' interacting patterns across countries and
observe different posting, liking and commenting rates. Second, we explore the
tendency of users to interact with different pages (i.e., selective exposure)
and the emergence of polarized communities generated around specific pages.
Then, we introduce a new metric -- i.e., polarization rank -- to measure
polarization of communities for each country. We find that Italy is the most
polarized country, followed by France, Germany and lastly Spain. Finally, we
present a variation of the Bounded Confidence Model to simulate the emergence
of these communities by considering the users' engagement and trust on the
news. Our findings suggest that trust in information broadcaster plays a
pivotal role against polarization of users online.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1805.08030v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1805.08030v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1805.08030v1,"{'id': 'http://arxiv.org/abs/1805.08030v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.08030v1', 'updated': '2018-05-21T13:01:56Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=21, tm_hour=13, tm_min=1, tm_sec=56, tm_wday=0, tm_yday=141, tm_isdst=0), 'published': '2018-05-21T13:01:56Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=21, tm_hour=13, tm_min=1, tm_sec=56, tm_wday=0, tm_yday=141, tm_isdst=0), 'title': 'Polarization Rank: A Study on European News Consumption on Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Polarization Rank: A Study on European News Consumption on Facebook'}, 'summary': ""The advent of WWW changed the way we can produce and access information.\nRecent studies showed that users tend to select information that is consistent\nwith their system of beliefs, forming polarized groups of like-minded people\naround shared narratives where dissenting information is ignored. In this\nenvironment, users cooperate to frame and reinforce their shared narrative\nmaking any attempt at debunking inefficient. Such a configuration occurs even\nin the consumption of news online, and considering that 63% of users access\nnews directly form social media, one hypothesis is that more polarization\nallows for further spreading of misinformation. Along this path, we focus on\nthe polarization of users around news outlets on Facebook in different European\ncountries (Italy, France, Spain and Germany). First, we compare the pages'\nposting behavior and the users' interacting patterns across countries and\nobserve different posting, liking and commenting rates. Second, we explore the\ntendency of users to interact with different pages (i.e., selective exposure)\nand the emergence of polarized communities generated around specific pages.\nThen, we introduce a new metric -- i.e., polarization rank -- to measure\npolarization of communities for each country. We find that Italy is the most\npolarized country, followed by France, Germany and lastly Spain. Finally, we\npresent a variation of the Bounded Confidence Model to simulate the emergence\nof these communities by considering the users' engagement and trust on the\nnews. Our findings suggest that trust in information broadcaster plays a\npivotal role against polarization of users online."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The advent of WWW changed the way we can produce and access information.\nRecent studies showed that users tend to select information that is consistent\nwith their system of beliefs, forming polarized groups of like-minded people\naround shared narratives where dissenting information is ignored. In this\nenvironment, users cooperate to frame and reinforce their shared narrative\nmaking any attempt at debunking inefficient. Such a configuration occurs even\nin the consumption of news online, and considering that 63% of users access\nnews directly form social media, one hypothesis is that more polarization\nallows for further spreading of misinformation. Along this path, we focus on\nthe polarization of users around news outlets on Facebook in different European\ncountries (Italy, France, Spain and Germany). First, we compare the pages'\nposting behavior and the users' interacting patterns across countries and\nobserve different posting, liking and commenting rates. Second, we explore the\ntendency of users to interact with different pages (i.e., selective exposure)\nand the emergence of polarized communities generated around specific pages.\nThen, we introduce a new metric -- i.e., polarization rank -- to measure\npolarization of communities for each country. We find that Italy is the most\npolarized country, followed by France, Germany and lastly Spain. Finally, we\npresent a variation of the Bounded Confidence Model to simulate the emergence\nof these communities by considering the users' engagement and trust on the\nnews. Our findings suggest that trust in information broadcaster plays a\npivotal role against polarization of users online.""}, 'authors': [{'name': 'Ana Lucía Schmidt'}, {'name': 'Fabiana Zollo'}, {'name': 'Antonio Scala'}, {'name': 'Walter Quattrociocchi'}], 'author_detail': {'name': 'Walter Quattrociocchi'}, 'author': 'Walter Quattrociocchi', 'links': [{'href': 'http://arxiv.org/abs/1805.08030v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.08030v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
429,http://arxiv.org/abs/1805.05999v2,2018-05-17 09:33:35+00:00,2018-05-15 19:09:41+00:00,Agent Based Rumor Spreading in a scale-free network,"[arxiv.Result.Author('Mattia Mazzoli'), arxiv.Result.Author('Tullio Re'), arxiv.Result.Author('Roberto Bertilone'), arxiv.Result.Author('Marco Maggiora'), arxiv.Result.Author('Jacopo Pellegrino')]","In the last years, the study of rumor spreading on social networks produced a
lot of interest among the scientific community, expecially due to the role of
social networks in the last political events. The goal of this work is to
reproduce real-like diffusions of information and misinformation in a
scale-free network using a multi-agent-based model. The data concerning the
virtual spreading are easily obtainable, in particular the diffusion of
information during the announcement for the discovery of the Higgs Boson on
Twitter was recorded and investigated in detail. We made some assumptions on
the micro behavior of our agents and registered the effects in a statistical
analysis replying the real data diffusion. Then, we studied an hypotetical
response to a misinformation diffusion adding debunking agents and trying to
model a critic response from the agents using real data from a hoax regarding
the Occupy Wall Street movement. After tuning our model to reproduce these
results, we measured some network properties and proved the emergence of
substantially separated structures like echochambers, independently from the
network size scale, i.e. with one hundred, one thousand and ten thousand
agents.",,,,cs.MA,"['cs.MA', 'cs.SI', '68T42']","[arxiv.Result.Link('http://arxiv.org/abs/1805.05999v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1805.05999v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1805.05999v2,"{'id': 'http://arxiv.org/abs/1805.05999v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.05999v2', 'updated': '2018-05-17T09:33:35Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=17, tm_hour=9, tm_min=33, tm_sec=35, tm_wday=3, tm_yday=137, tm_isdst=0), 'published': '2018-05-15T19:09:41Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=15, tm_hour=19, tm_min=9, tm_sec=41, tm_wday=1, tm_yday=135, tm_isdst=0), 'title': 'Agent Based Rumor Spreading in a scale-free network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Agent Based Rumor Spreading in a scale-free network'}, 'summary': 'In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.'}, 'authors': [{'name': 'Mattia Mazzoli'}, {'name': 'Tullio Re'}, {'name': 'Roberto Bertilone'}, {'name': 'Marco Maggiora'}, {'name': 'Jacopo Pellegrino'}], 'author_detail': {'name': 'Jacopo Pellegrino'}, 'author': 'Jacopo Pellegrino', 'links': [{'href': 'http://arxiv.org/abs/1805.05999v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.05999v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T42', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
430,http://arxiv.org/abs/1805.04698v1,2018-05-12 11:05:11+00:00,2018-05-12 11:05:11+00:00,Bitcoin Risk Modeling with Blockchain Graphs,"[arxiv.Result.Author('Cuneyt Akcora'), arxiv.Result.Author('Matthew Dixon'), arxiv.Result.Author('Yulia Gel'), arxiv.Result.Author('Murat Kantarcioglu')]","A key challenge for Bitcoin cryptocurrency holders, such as startups using
ICOs to raise funding, is managing their FX risk. Specifically, a misinformed
decision to convert Bitcoin to fiat currency could, by itself, cost USD
millions.
  In contrast to financial exchanges, Blockchain based crypto-currencies expose
the entire transaction history to the public. By processing all transactions,
we model the network with a high fidelity graph so that it is possible to
characterize how the flow of information in the network evolves over time. We
demonstrate how this data representation permits a new form of microstructure
modeling - with the emphasis on the topological network structures to study the
role of users, entities and their interactions in formation and dynamics of
crypto-currency investment risk. In particular, we identify certain sub-graphs
('chainlets') that exhibit predictive influence on Bitcoin price and
volatility, and characterize the types of chainlets that signify extreme
losses.","JEL Classification: C58, C63, G18",,,q-fin.RM,['q-fin.RM'],"[arxiv.Result.Link('http://arxiv.org/abs/1805.04698v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1805.04698v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1805.04698v1,"{'id': 'http://arxiv.org/abs/1805.04698v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1805.04698v1', 'updated': '2018-05-12T11:05:11Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=12, tm_hour=11, tm_min=5, tm_sec=11, tm_wday=5, tm_yday=132, tm_isdst=0), 'published': '2018-05-12T11:05:11Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=12, tm_hour=11, tm_min=5, tm_sec=11, tm_wday=5, tm_yday=132, tm_isdst=0), 'title': 'Bitcoin Risk Modeling with Blockchain Graphs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Bitcoin Risk Modeling with Blockchain Graphs'}, 'summary': ""A key challenge for Bitcoin cryptocurrency holders, such as startups using\nICOs to raise funding, is managing their FX risk. Specifically, a misinformed\ndecision to convert Bitcoin to fiat currency could, by itself, cost USD\nmillions.\n  In contrast to financial exchanges, Blockchain based crypto-currencies expose\nthe entire transaction history to the public. By processing all transactions,\nwe model the network with a high fidelity graph so that it is possible to\ncharacterize how the flow of information in the network evolves over time. We\ndemonstrate how this data representation permits a new form of microstructure\nmodeling - with the emphasis on the topological network structures to study the\nrole of users, entities and their interactions in formation and dynamics of\ncrypto-currency investment risk. In particular, we identify certain sub-graphs\n('chainlets') that exhibit predictive influence on Bitcoin price and\nvolatility, and characterize the types of chainlets that signify extreme\nlosses."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""A key challenge for Bitcoin cryptocurrency holders, such as startups using\nICOs to raise funding, is managing their FX risk. Specifically, a misinformed\ndecision to convert Bitcoin to fiat currency could, by itself, cost USD\nmillions.\n  In contrast to financial exchanges, Blockchain based crypto-currencies expose\nthe entire transaction history to the public. By processing all transactions,\nwe model the network with a high fidelity graph so that it is possible to\ncharacterize how the flow of information in the network evolves over time. We\ndemonstrate how this data representation permits a new form of microstructure\nmodeling - with the emphasis on the topological network structures to study the\nrole of users, entities and their interactions in formation and dynamics of\ncrypto-currency investment risk. In particular, we identify certain sub-graphs\n('chainlets') that exhibit predictive influence on Bitcoin price and\nvolatility, and characterize the types of chainlets that signify extreme\nlosses.""}, 'authors': [{'name': 'Cuneyt Akcora'}, {'name': 'Matthew Dixon'}, {'name': 'Yulia Gel'}, {'name': 'Murat Kantarcioglu'}], 'author_detail': {'name': 'Murat Kantarcioglu'}, 'author': 'Murat Kantarcioglu', 'arxiv_comment': 'JEL Classification: C58, C63, G18', 'links': [{'href': 'http://arxiv.org/abs/1805.04698v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1805.04698v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'q-fin.RM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-fin.RM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
431,http://arxiv.org/abs/1804.06196v1,2018-04-17 12:25:39+00:00,2018-04-17 12:25:39+00:00,Demystifying Deception Technology:A Survey,"[arxiv.Result.Author('Daniel Fraunholz'), arxiv.Result.Author('Simon Duque Anton'), arxiv.Result.Author('Christoph Lipps'), arxiv.Result.Author('Daniel Reti'), arxiv.Result.Author('Daniel Krohmer'), arxiv.Result.Author('Frederic Pohl'), arxiv.Result.Author('Matthias Tammen'), arxiv.Result.Author('Hans Dieter Schotten')]","Deception boosts security for systems and components by denial, deceit,
misinformation, camouflage and obfuscation. In this work an extensive overview
of the deception technology environment is presented. Taxonomies, theoretical
backgrounds, psychological aspects as well as concepts, implementations, legal
aspects and ethics are discussed and compared.","25 pages, 169 references",,,cs.CR,['cs.CR'],"[arxiv.Result.Link('http://arxiv.org/abs/1804.06196v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1804.06196v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1804.06196v1,"{'id': 'http://arxiv.org/abs/1804.06196v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1804.06196v1', 'updated': '2018-04-17T12:25:39Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=17, tm_hour=12, tm_min=25, tm_sec=39, tm_wday=1, tm_yday=107, tm_isdst=0), 'published': '2018-04-17T12:25:39Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=17, tm_hour=12, tm_min=25, tm_sec=39, tm_wday=1, tm_yday=107, tm_isdst=0), 'title': 'Demystifying Deception Technology:A Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Demystifying Deception Technology:A Survey'}, 'summary': 'Deception boosts security for systems and components by denial, deceit,\nmisinformation, camouflage and obfuscation. In this work an extensive overview\nof the deception technology environment is presented. Taxonomies, theoretical\nbackgrounds, psychological aspects as well as concepts, implementations, legal\naspects and ethics are discussed and compared.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deception boosts security for systems and components by denial, deceit,\nmisinformation, camouflage and obfuscation. In this work an extensive overview\nof the deception technology environment is presented. Taxonomies, theoretical\nbackgrounds, psychological aspects as well as concepts, implementations, legal\naspects and ethics are discussed and compared.'}, 'authors': [{'name': 'Daniel Fraunholz'}, {'name': 'Simon Duque Anton'}, {'name': 'Christoph Lipps'}, {'name': 'Daniel Reti'}, {'name': 'Daniel Krohmer'}, {'name': 'Frederic Pohl'}, {'name': 'Matthias Tammen'}, {'name': 'Hans Dieter Schotten'}], 'author_detail': {'name': 'Hans Dieter Schotten'}, 'author': 'Hans Dieter Schotten', 'arxiv_comment': '25 pages, 169 references', 'links': [{'href': 'http://arxiv.org/abs/1804.06196v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1804.06196v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
432,http://arxiv.org/abs/1803.10124v4,2018-08-16 13:21:58+00:00,2018-03-27 15:12:01+00:00,Sampling the News Producers: A Large News and Feature Data Set for the Study of the Complex Media Landscape,"[arxiv.Result.Author('Benjamin D. Horne'), arxiv.Result.Author('William Dron'), arxiv.Result.Author('Sara Khedr'), arxiv.Result.Author('Sibel Adali')]","The complexity and diversity of today's media landscape provides many
challenges for researchers studying news producers. These producers use many
different strategies to get their message believed by readers through the
writing styles they employ, by repetition across different media sources with
or without attribution, as well as other mechanisms that are yet to be studied
deeply. To better facilitate systematic studies in this area, we present a
large political news data set, containing over 136K news articles, from 92 news
sources, collected over 7 months of 2017. These news sources are carefully
chosen to include well-established and mainstream sources, maliciously fake
sources, satire sources, and hyper-partisan political blogs. In addition to
each article we compute 130 content-based and social media engagement features
drawn from a wide range of literature on political bias, persuasion, and
misinformation. With the release of the data set, we also provide the source
code for feature computation. In this paper, we discuss the first release of
the data set and demonstrate 4 use cases of the data and features: news
characterization, engagement characterization, news attribution and content
copying, and discovering news narratives.","Published at ICWSM 2018. Dataset:
  https://github.com/BenjaminDHorne/NELA2017-Dataset-v1 Feature Code:
  https://github.com/BenjaminDHorne/Language-Features-for-News",,,cs.CY,['cs.CY'],"[arxiv.Result.Link('http://arxiv.org/abs/1803.10124v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1803.10124v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1803.10124v4,"{'id': 'http://arxiv.org/abs/1803.10124v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1803.10124v4', 'updated': '2018-08-16T13:21:58Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=8, tm_mday=16, tm_hour=13, tm_min=21, tm_sec=58, tm_wday=3, tm_yday=228, tm_isdst=0), 'published': '2018-03-27T15:12:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=27, tm_hour=15, tm_min=12, tm_sec=1, tm_wday=1, tm_yday=86, tm_isdst=0), 'title': 'Sampling the News Producers: A Large News and Feature Data Set for the\n  Study of the Complex Media Landscape', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Sampling the News Producers: A Large News and Feature Data Set for the\n  Study of the Complex Media Landscape'}, 'summary': ""The complexity and diversity of today's media landscape provides many\nchallenges for researchers studying news producers. These producers use many\ndifferent strategies to get their message believed by readers through the\nwriting styles they employ, by repetition across different media sources with\nor without attribution, as well as other mechanisms that are yet to be studied\ndeeply. To better facilitate systematic studies in this area, we present a\nlarge political news data set, containing over 136K news articles, from 92 news\nsources, collected over 7 months of 2017. These news sources are carefully\nchosen to include well-established and mainstream sources, maliciously fake\nsources, satire sources, and hyper-partisan political blogs. In addition to\neach article we compute 130 content-based and social media engagement features\ndrawn from a wide range of literature on political bias, persuasion, and\nmisinformation. With the release of the data set, we also provide the source\ncode for feature computation. In this paper, we discuss the first release of\nthe data set and demonstrate 4 use cases of the data and features: news\ncharacterization, engagement characterization, news attribution and content\ncopying, and discovering news narratives."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The complexity and diversity of today's media landscape provides many\nchallenges for researchers studying news producers. These producers use many\ndifferent strategies to get their message believed by readers through the\nwriting styles they employ, by repetition across different media sources with\nor without attribution, as well as other mechanisms that are yet to be studied\ndeeply. To better facilitate systematic studies in this area, we present a\nlarge political news data set, containing over 136K news articles, from 92 news\nsources, collected over 7 months of 2017. These news sources are carefully\nchosen to include well-established and mainstream sources, maliciously fake\nsources, satire sources, and hyper-partisan political blogs. In addition to\neach article we compute 130 content-based and social media engagement features\ndrawn from a wide range of literature on political bias, persuasion, and\nmisinformation. With the release of the data set, we also provide the source\ncode for feature computation. In this paper, we discuss the first release of\nthe data set and demonstrate 4 use cases of the data and features: news\ncharacterization, engagement characterization, news attribution and content\ncopying, and discovering news narratives.""}, 'authors': [{'name': 'Benjamin D. Horne'}, {'name': 'William Dron'}, {'name': 'Sara Khedr'}, {'name': 'Sibel Adali'}], 'author_detail': {'name': 'Sibel Adali'}, 'author': 'Sibel Adali', 'arxiv_comment': 'Published at ICWSM 2018. Dataset:\n  https://github.com/BenjaminDHorne/NELA2017-Dataset-v1 Feature Code:\n  https://github.com/BenjaminDHorne/Language-Features-for-News', 'links': [{'href': 'http://arxiv.org/abs/1803.10124v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1803.10124v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
433,http://arxiv.org/abs/1802.04291v1,2018-02-12 19:00:18+00:00,2018-02-12 19:00:18+00:00,Analyzing the Digital Traces of Political Manipulation: The 2016 Russian Interference Twitter Campaign,"[arxiv.Result.Author('Adam Badawy'), arxiv.Result.Author('Emilio Ferrara'), arxiv.Result.Author('Kristina Lerman')]","Until recently, social media was seen to promote democratic discourse on
social and political issues. However, this powerful communication platform has
come under scrutiny for allowing hostile actors to exploit online discussions
in an attempt to manipulate public opinion. A case in point is the ongoing U.S.
Congress' investigation of Russian interference in the 2016 U.S. election
campaign, with Russia accused of using trolls (malicious accounts created to
manipulate) and bots to spread misinformation and politically biased
information. In this study, we explore the effects of this manipulation
campaign, taking a closer look at users who re-shared the posts produced on
Twitter by the Russian troll accounts publicly disclosed by U.S. Congress
investigation. We collected a dataset with over 43 million election-related
posts shared on Twitter between September 16 and October 21, 2016, by about 5.7
million distinct users. This dataset included accounts associated with the
identified Russian trolls. We use label propagation to infer the ideology of
all users based on the news sources they shared. This method enables us to
classify a large number of users as liberal or conservative with precision and
recall above 90%. Conservatives retweeted Russian trolls about 31 times more
often than liberals and produced 36x more tweets. Additionally, most retweets
of troll content originated from two Southern states: Tennessee and Texas.
Using state-of-the-art bot detection techniques, we estimated that about 4.9%
and 6.2% of liberal and conservative users respectively were bots. Text
analysis on the content shared by trolls reveals that they had a mostly
conservative, pro-Trump agenda. Although an ideologically broad swath of
Twitter users was exposed to Russian Trolls in the period leading up to the
2016 U.S. Presidential election, it was mainly conservatives who helped amplify
their message.",,"2018 IEEE/ACM International Conference on Advances in Social
  Networks Analysis and Mining (ASONAM), Barcelona, Spain, 2018, pp. 258-265",10.1109/ASONAM.2018.8508646,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1109/ASONAM.2018.8508646', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1802.04291v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.04291v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.04291v1,"{'id': 'http://arxiv.org/abs/1802.04291v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.04291v1', 'updated': '2018-02-12T19:00:18Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=12, tm_hour=19, tm_min=0, tm_sec=18, tm_wday=0, tm_yday=43, tm_isdst=0), 'published': '2018-02-12T19:00:18Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=12, tm_hour=19, tm_min=0, tm_sec=18, tm_wday=0, tm_yday=43, tm_isdst=0), 'title': 'Analyzing the Digital Traces of Political Manipulation: The 2016 Russian\n  Interference Twitter Campaign', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analyzing the Digital Traces of Political Manipulation: The 2016 Russian\n  Interference Twitter Campaign'}, 'summary': ""Until recently, social media was seen to promote democratic discourse on\nsocial and political issues. However, this powerful communication platform has\ncome under scrutiny for allowing hostile actors to exploit online discussions\nin an attempt to manipulate public opinion. A case in point is the ongoing U.S.\nCongress' investigation of Russian interference in the 2016 U.S. election\ncampaign, with Russia accused of using trolls (malicious accounts created to\nmanipulate) and bots to spread misinformation and politically biased\ninformation. In this study, we explore the effects of this manipulation\ncampaign, taking a closer look at users who re-shared the posts produced on\nTwitter by the Russian troll accounts publicly disclosed by U.S. Congress\ninvestigation. We collected a dataset with over 43 million election-related\nposts shared on Twitter between September 16 and October 21, 2016, by about 5.7\nmillion distinct users. This dataset included accounts associated with the\nidentified Russian trolls. We use label propagation to infer the ideology of\nall users based on the news sources they shared. This method enables us to\nclassify a large number of users as liberal or conservative with precision and\nrecall above 90%. Conservatives retweeted Russian trolls about 31 times more\noften than liberals and produced 36x more tweets. Additionally, most retweets\nof troll content originated from two Southern states: Tennessee and Texas.\nUsing state-of-the-art bot detection techniques, we estimated that about 4.9%\nand 6.2% of liberal and conservative users respectively were bots. Text\nanalysis on the content shared by trolls reveals that they had a mostly\nconservative, pro-Trump agenda. Although an ideologically broad swath of\nTwitter users was exposed to Russian Trolls in the period leading up to the\n2016 U.S. Presidential election, it was mainly conservatives who helped amplify\ntheir message."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Until recently, social media was seen to promote democratic discourse on\nsocial and political issues. However, this powerful communication platform has\ncome under scrutiny for allowing hostile actors to exploit online discussions\nin an attempt to manipulate public opinion. A case in point is the ongoing U.S.\nCongress' investigation of Russian interference in the 2016 U.S. election\ncampaign, with Russia accused of using trolls (malicious accounts created to\nmanipulate) and bots to spread misinformation and politically biased\ninformation. In this study, we explore the effects of this manipulation\ncampaign, taking a closer look at users who re-shared the posts produced on\nTwitter by the Russian troll accounts publicly disclosed by U.S. Congress\ninvestigation. We collected a dataset with over 43 million election-related\nposts shared on Twitter between September 16 and October 21, 2016, by about 5.7\nmillion distinct users. This dataset included accounts associated with the\nidentified Russian trolls. We use label propagation to infer the ideology of\nall users based on the news sources they shared. This method enables us to\nclassify a large number of users as liberal or conservative with precision and\nrecall above 90%. Conservatives retweeted Russian trolls about 31 times more\noften than liberals and produced 36x more tweets. Additionally, most retweets\nof troll content originated from two Southern states: Tennessee and Texas.\nUsing state-of-the-art bot detection techniques, we estimated that about 4.9%\nand 6.2% of liberal and conservative users respectively were bots. Text\nanalysis on the content shared by trolls reveals that they had a mostly\nconservative, pro-Trump agenda. Although an ideologically broad swath of\nTwitter users was exposed to Russian Trolls in the period leading up to the\n2016 U.S. Presidential election, it was mainly conservatives who helped amplify\ntheir message.""}, 'authors': [{'name': 'Adam Badawy'}, {'name': 'Emilio Ferrara'}, {'name': 'Kristina Lerman'}], 'author_detail': {'name': 'Kristina Lerman'}, 'author': 'Kristina Lerman', 'arxiv_doi': '10.1109/ASONAM.2018.8508646', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/ASONAM.2018.8508646', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1802.04291v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.04291v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': '2018 IEEE/ACM International Conference on Advances in Social\n  Networks Analysis and Mining (ASONAM), Barcelona, Spain, 2018, pp. 258-265', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
434,http://arxiv.org/abs/1802.03573v1,2018-02-10 12:22:59+00:00,2018-02-10 12:22:59+00:00,"Social Media, News and Political Information during the US Election: Was Polarizing Content Concentrated in Swing States?","[arxiv.Result.Author('Philip N. Howard'), arxiv.Result.Author('Bence Kollanyi'), arxiv.Result.Author('Samantha Bradshaw'), arxiv.Result.Author('Lisa-Maria Neudert')]","US voters shared large volumes of polarizing political news and information
in the form of links to content from Russian, WikiLeaks and junk news sources.
Was this low quality political information distributed evenly around the
country, or concentrated in swing states and particular parts of the country?
In this data memo we apply a tested dictionary of sources about political news
and information being shared over Twitter over a ten day period around the 2016
Presidential Election. Using self-reported location information, we place a
third of users by state and create a simple index for the distribution of
polarizing content around the country. We find that (1) nationally, Twitter
users got more misinformation, polarizing and conspiratorial content than
professionally produced news. (2) Users in some states, however, shared more
polarizing political news and information than users in other states. (3)
Average levels of misinformation were higher in swing states than in
uncontested states, even when weighted for the relative size of the user
population in each state. We conclude with some observations about the impact
of strategically disseminated polarizing information on public life.",Data Memo,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1802.03573v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.03573v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.03573v1,"{'id': 'http://arxiv.org/abs/1802.03573v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.03573v1', 'updated': '2018-02-10T12:22:59Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=10, tm_hour=12, tm_min=22, tm_sec=59, tm_wday=5, tm_yday=41, tm_isdst=0), 'published': '2018-02-10T12:22:59Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=10, tm_hour=12, tm_min=22, tm_sec=59, tm_wday=5, tm_yday=41, tm_isdst=0), 'title': 'Social Media, News and Political Information during the US Election: Was\n  Polarizing Content Concentrated in Swing States?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Media, News and Political Information during the US Election: Was\n  Polarizing Content Concentrated in Swing States?'}, 'summary': 'US voters shared large volumes of polarizing political news and information\nin the form of links to content from Russian, WikiLeaks and junk news sources.\nWas this low quality political information distributed evenly around the\ncountry, or concentrated in swing states and particular parts of the country?\nIn this data memo we apply a tested dictionary of sources about political news\nand information being shared over Twitter over a ten day period around the 2016\nPresidential Election. Using self-reported location information, we place a\nthird of users by state and create a simple index for the distribution of\npolarizing content around the country. We find that (1) nationally, Twitter\nusers got more misinformation, polarizing and conspiratorial content than\nprofessionally produced news. (2) Users in some states, however, shared more\npolarizing political news and information than users in other states. (3)\nAverage levels of misinformation were higher in swing states than in\nuncontested states, even when weighted for the relative size of the user\npopulation in each state. We conclude with some observations about the impact\nof strategically disseminated polarizing information on public life.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'US voters shared large volumes of polarizing political news and information\nin the form of links to content from Russian, WikiLeaks and junk news sources.\nWas this low quality political information distributed evenly around the\ncountry, or concentrated in swing states and particular parts of the country?\nIn this data memo we apply a tested dictionary of sources about political news\nand information being shared over Twitter over a ten day period around the 2016\nPresidential Election. Using self-reported location information, we place a\nthird of users by state and create a simple index for the distribution of\npolarizing content around the country. We find that (1) nationally, Twitter\nusers got more misinformation, polarizing and conspiratorial content than\nprofessionally produced news. (2) Users in some states, however, shared more\npolarizing political news and information than users in other states. (3)\nAverage levels of misinformation were higher in swing states than in\nuncontested states, even when weighted for the relative size of the user\npopulation in each state. We conclude with some observations about the impact\nof strategically disseminated polarizing information on public life.'}, 'authors': [{'name': 'Philip N. Howard'}, {'name': 'Bence Kollanyi'}, {'name': 'Samantha Bradshaw'}, {'name': 'Lisa-Maria Neudert'}], 'author_detail': {'name': 'Lisa-Maria Neudert'}, 'author': 'Lisa-Maria Neudert', 'arxiv_comment': 'Data Memo', 'links': [{'href': 'http://arxiv.org/abs/1802.03573v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.03573v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
435,http://arxiv.org/abs/1802.03572v1,2018-02-10 12:16:12+00:00,2018-02-10 12:16:12+00:00,Junk News on Military Affairs and National Security: Social Media Disinformation Campaigns Against US Military Personnel and Veterans,"[arxiv.Result.Author('John D. Gallacher'), arxiv.Result.Author('Vlad Barash'), arxiv.Result.Author('Philip N. Howard'), arxiv.Result.Author('John Kelly')]","Social media provides political news and information for both active duty
military personnel and veterans. We analyze the subgroups of Twitter and
Facebook users who spend time consuming junk news from websites that target US
military personnel and veterans with conspiracy theories, misinformation, and
other forms of junk news about military affairs and national security issues.
(1) Over Twitter we find that there are significant and persistent interactions
between current and former military personnel and a broad network of extremist,
Russia-focused, and international conspiracy subgroups. (2) Over Facebook, we
find significant and persistent interactions between public pages for military
and veterans and subgroups dedicated to political conspiracy, and both sides of
the political spectrum. (3) Over Facebook, the users who are most interested in
conspiracy theories and the political right seem to be distributing the most
junk news, whereas users who are either in the military or are veterans are
among the most sophisticated news consumers, and share very little junk news
through the network.",Data Memo,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1802.03572v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.03572v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.03572v1,"{'id': 'http://arxiv.org/abs/1802.03572v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.03572v1', 'updated': '2018-02-10T12:16:12Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=10, tm_hour=12, tm_min=16, tm_sec=12, tm_wday=5, tm_yday=41, tm_isdst=0), 'published': '2018-02-10T12:16:12Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=10, tm_hour=12, tm_min=16, tm_sec=12, tm_wday=5, tm_yday=41, tm_isdst=0), 'title': 'Junk News on Military Affairs and National Security: Social Media\n  Disinformation Campaigns Against US Military Personnel and Veterans', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Junk News on Military Affairs and National Security: Social Media\n  Disinformation Campaigns Against US Military Personnel and Veterans'}, 'summary': 'Social media provides political news and information for both active duty\nmilitary personnel and veterans. We analyze the subgroups of Twitter and\nFacebook users who spend time consuming junk news from websites that target US\nmilitary personnel and veterans with conspiracy theories, misinformation, and\nother forms of junk news about military affairs and national security issues.\n(1) Over Twitter we find that there are significant and persistent interactions\nbetween current and former military personnel and a broad network of extremist,\nRussia-focused, and international conspiracy subgroups. (2) Over Facebook, we\nfind significant and persistent interactions between public pages for military\nand veterans and subgroups dedicated to political conspiracy, and both sides of\nthe political spectrum. (3) Over Facebook, the users who are most interested in\nconspiracy theories and the political right seem to be distributing the most\njunk news, whereas users who are either in the military or are veterans are\namong the most sophisticated news consumers, and share very little junk news\nthrough the network.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media provides political news and information for both active duty\nmilitary personnel and veterans. We analyze the subgroups of Twitter and\nFacebook users who spend time consuming junk news from websites that target US\nmilitary personnel and veterans with conspiracy theories, misinformation, and\nother forms of junk news about military affairs and national security issues.\n(1) Over Twitter we find that there are significant and persistent interactions\nbetween current and former military personnel and a broad network of extremist,\nRussia-focused, and international conspiracy subgroups. (2) Over Facebook, we\nfind significant and persistent interactions between public pages for military\nand veterans and subgroups dedicated to political conspiracy, and both sides of\nthe political spectrum. (3) Over Facebook, the users who are most interested in\nconspiracy theories and the political right seem to be distributing the most\njunk news, whereas users who are either in the military or are veterans are\namong the most sophisticated news consumers, and share very little junk news\nthrough the network.'}, 'authors': [{'name': 'John D. Gallacher'}, {'name': 'Vlad Barash'}, {'name': 'Philip N. Howard'}, {'name': 'John Kelly'}], 'author_detail': {'name': 'John Kelly'}, 'author': 'John Kelly', 'arxiv_comment': 'Data Memo', 'links': [{'href': 'http://arxiv.org/abs/1802.03572v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.03572v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
436,http://arxiv.org/abs/1802.01400v1,2018-02-05 14:17:21+00:00,2018-02-05 14:17:21+00:00,Polarization and Fake News: Early Warning of Potential Misinformation Targets,"[arxiv.Result.Author('Michela Del Vicario'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Antonio Scala'), arxiv.Result.Author('Fabiana Zollo')]","Users polarization and confirmation bias play a key role in misinformation
spreading on online social media. Our aim is to use this information to
determine in advance potential targets for hoaxes and fake news. In this paper,
we introduce a general framework for promptly identifying polarizing content on
social media and, thus, ""predicting"" future fake news topics. We validate the
performances of the proposed methodology on a massive Italian Facebook dataset,
showing that we are able to identify topics that are susceptible to
misinformation with 77% accuracy. Moreover, such information may be embedded as
a new feature in an additional classifier able to recognize fake news with 91%
accuracy. The novelty of our approach consists in taking into account a series
of characteristics related to users behavior on online social media, making a
first, important step towards the smoothing of polarization and the mitigation
of misinformation phenomena.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1802.01400v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.01400v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.01400v1,"{'id': 'http://arxiv.org/abs/1802.01400v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.01400v1', 'updated': '2018-02-05T14:17:21Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=5, tm_hour=14, tm_min=17, tm_sec=21, tm_wday=0, tm_yday=36, tm_isdst=0), 'published': '2018-02-05T14:17:21Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=5, tm_hour=14, tm_min=17, tm_sec=21, tm_wday=0, tm_yday=36, tm_isdst=0), 'title': 'Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets'}, 'summary': 'Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, ""predicting"" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, ""predicting"" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.'}, 'authors': [{'name': 'Michela Del Vicario'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Antonio Scala'}, {'name': 'Fabiana Zollo'}], 'author_detail': {'name': 'Fabiana Zollo'}, 'author': 'Fabiana Zollo', 'links': [{'href': 'http://arxiv.org/abs/1802.01400v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.01400v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
437,http://arxiv.org/abs/1801.09223v2,2018-04-10 05:22:23+00:00,2018-01-28 13:08:43+00:00,Probability Mass Exclusions and the Directed Components of Pointwise Mutual Information,"[arxiv.Result.Author('Conor Finn'), arxiv.Result.Author('Joseph T Lizier')]","This paper examines how an event from one random variable provides pointwise
mutual information about an event from another variable via probability mass
exclusions. We start by introducing probability mass diagrams, which provide a
visual representation of how a prior distribution is transformed to a posterior
distribution through exclusions. With the aid of these diagrams, we identify
two distinct types of probability mass exclusions---namely informative and
misinformative exclusions. Then, motivated by Fano's derivation of the
pointwise mutual information, we propose four postulates which aim to decompose
the pointwise mutual information into two separate informational components: a
non-negative term associated with the informative exclusion and a non-positive
term associated with the misinformative exclusions. This yields a novel
derivation of a familiar decomposition of the pointwise mutual information into
entropic components. We conclude by discussing the relevance of considering
information in terms of probability mass exclusions to the ongoing effort to
decompose multivariate information.","6 pages, 7 figures",,10.3390/e20110826,cs.IT,"['cs.IT', 'math.IT', '94A15, 94A17']","[arxiv.Result.Link('http://dx.doi.org/10.3390/e20110826', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1801.09223v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1801.09223v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1801.09223v2,"{'id': 'http://arxiv.org/abs/1801.09223v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1801.09223v2', 'updated': '2018-04-10T05:22:23Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=4, tm_mday=10, tm_hour=5, tm_min=22, tm_sec=23, tm_wday=1, tm_yday=100, tm_isdst=0), 'published': '2018-01-28T13:08:43Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=28, tm_hour=13, tm_min=8, tm_sec=43, tm_wday=6, tm_yday=28, tm_isdst=0), 'title': 'Probability Mass Exclusions and the Directed Components of Pointwise\n  Mutual Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Probability Mass Exclusions and the Directed Components of Pointwise\n  Mutual Information'}, 'summary': ""This paper examines how an event from one random variable provides pointwise\nmutual information about an event from another variable via probability mass\nexclusions. We start by introducing probability mass diagrams, which provide a\nvisual representation of how a prior distribution is transformed to a posterior\ndistribution through exclusions. With the aid of these diagrams, we identify\ntwo distinct types of probability mass exclusions---namely informative and\nmisinformative exclusions. Then, motivated by Fano's derivation of the\npointwise mutual information, we propose four postulates which aim to decompose\nthe pointwise mutual information into two separate informational components: a\nnon-negative term associated with the informative exclusion and a non-positive\nterm associated with the misinformative exclusions. This yields a novel\nderivation of a familiar decomposition of the pointwise mutual information into\nentropic components. We conclude by discussing the relevance of considering\ninformation in terms of probability mass exclusions to the ongoing effort to\ndecompose multivariate information."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper examines how an event from one random variable provides pointwise\nmutual information about an event from another variable via probability mass\nexclusions. We start by introducing probability mass diagrams, which provide a\nvisual representation of how a prior distribution is transformed to a posterior\ndistribution through exclusions. With the aid of these diagrams, we identify\ntwo distinct types of probability mass exclusions---namely informative and\nmisinformative exclusions. Then, motivated by Fano's derivation of the\npointwise mutual information, we propose four postulates which aim to decompose\nthe pointwise mutual information into two separate informational components: a\nnon-negative term associated with the informative exclusion and a non-positive\nterm associated with the misinformative exclusions. This yields a novel\nderivation of a familiar decomposition of the pointwise mutual information into\nentropic components. We conclude by discussing the relevance of considering\ninformation in terms of probability mass exclusions to the ongoing effort to\ndecompose multivariate information.""}, 'authors': [{'name': 'Conor Finn'}, {'name': 'Joseph T Lizier'}], 'author_detail': {'name': 'Joseph T Lizier'}, 'author': 'Joseph T Lizier', 'arxiv_doi': '10.3390/e20110826', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.3390/e20110826', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1801.09223v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1801.09223v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '6 pages, 7 figures', 'arxiv_primary_category': {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '94A15, 94A17', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
438,http://arxiv.org/abs/1802.06887v1,2018-01-23 17:50:37+00:00,2018-01-23 17:50:37+00:00,A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the Internet of Battlefield Things (IoBT),"[arxiv.Result.Author('Nof Abuzainab'), arxiv.Result.Author('Walid Saad')]","In this paper, the problem of misinformation propagation is studied for an
Internet of Battlefield Things (IoBT) system in which an attacker seeks to
inject false information in the IoBT nodes in order to compromise the IoBT
operations. In the considered model, each IoBT node seeks to counter the
misinformation attack by finding the optimal probability of accepting a given
information that minimizes its cost at each time instant. The cost is expressed
in terms of the quality of information received as well as the infection cost.
The problem is formulated as a mean-field game with multiclass agents which is
suitable to model a massive heterogeneous IoBT system. For this game, the
mean-field equilibrium is characterized, and an algorithm based on the forward
backward sweep method is proposed to find the mean-field equilibrium. Then, the
finite IoBT case is considered, and the conditions of convergence of the Nash
equilibria in the finite case to the mean-field equilibrium are presented.
Numerical results show that the proposed scheme can achieve a 1.2-fold increase
in the quality of information (QoI) compared to a baseline scheme in which the
IoBT nodes are always transmitting. The results also show that the proposed
scheme can reduce the proportion of infected nodes by 99% compared to the
baseline.",,,,cs.GT,['cs.GT'],"[arxiv.Result.Link('http://arxiv.org/abs/1802.06887v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1802.06887v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1802.06887v1,"{'id': 'http://arxiv.org/abs/1802.06887v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1802.06887v1', 'updated': '2018-01-23T17:50:37Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=23, tm_hour=17, tm_min=50, tm_sec=37, tm_wday=1, tm_yday=23, tm_isdst=0), 'published': '2018-01-23T17:50:37Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=23, tm_hour=17, tm_min=50, tm_sec=37, tm_wday=1, tm_yday=23, tm_isdst=0), 'title': 'A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the\n  Internet of Battlefield Things (IoBT)', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the\n  Internet of Battlefield Things (IoBT)'}, 'summary': 'In this paper, the problem of misinformation propagation is studied for an\nInternet of Battlefield Things (IoBT) system in which an attacker seeks to\ninject false information in the IoBT nodes in order to compromise the IoBT\noperations. In the considered model, each IoBT node seeks to counter the\nmisinformation attack by finding the optimal probability of accepting a given\ninformation that minimizes its cost at each time instant. The cost is expressed\nin terms of the quality of information received as well as the infection cost.\nThe problem is formulated as a mean-field game with multiclass agents which is\nsuitable to model a massive heterogeneous IoBT system. For this game, the\nmean-field equilibrium is characterized, and an algorithm based on the forward\nbackward sweep method is proposed to find the mean-field equilibrium. Then, the\nfinite IoBT case is considered, and the conditions of convergence of the Nash\nequilibria in the finite case to the mean-field equilibrium are presented.\nNumerical results show that the proposed scheme can achieve a 1.2-fold increase\nin the quality of information (QoI) compared to a baseline scheme in which the\nIoBT nodes are always transmitting. The results also show that the proposed\nscheme can reduce the proportion of infected nodes by 99% compared to the\nbaseline.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, the problem of misinformation propagation is studied for an\nInternet of Battlefield Things (IoBT) system in which an attacker seeks to\ninject false information in the IoBT nodes in order to compromise the IoBT\noperations. In the considered model, each IoBT node seeks to counter the\nmisinformation attack by finding the optimal probability of accepting a given\ninformation that minimizes its cost at each time instant. The cost is expressed\nin terms of the quality of information received as well as the infection cost.\nThe problem is formulated as a mean-field game with multiclass agents which is\nsuitable to model a massive heterogeneous IoBT system. For this game, the\nmean-field equilibrium is characterized, and an algorithm based on the forward\nbackward sweep method is proposed to find the mean-field equilibrium. Then, the\nfinite IoBT case is considered, and the conditions of convergence of the Nash\nequilibria in the finite case to the mean-field equilibrium are presented.\nNumerical results show that the proposed scheme can achieve a 1.2-fold increase\nin the quality of information (QoI) compared to a baseline scheme in which the\nIoBT nodes are always transmitting. The results also show that the proposed\nscheme can reduce the proportion of infected nodes by 99% compared to the\nbaseline.'}, 'authors': [{'name': 'Nof Abuzainab'}, {'name': 'Walid Saad'}], 'author_detail': {'name': 'Walid Saad'}, 'author': 'Walid Saad', 'links': [{'href': 'http://arxiv.org/abs/1802.06887v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1802.06887v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
439,http://arxiv.org/abs/1801.06122v1,2018-01-18 16:54:01+00:00,2018-01-18 16:54:01+00:00,Anatomy of an online misinformation network,"[arxiv.Result.Author('Chengcheng Shao'), arxiv.Result.Author('Pik-Mai Hui'), arxiv.Result.Author('Lei Wang'), arxiv.Result.Author('Xinwen Jiang'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Giovanni Luca Ciampaglia')]","Massive amounts of fake news and conspiratorial content have spread over
social media before and after the 2016 US Presidential Elections despite
intense fact-checking efforts. How do the spread of misinformation and
fact-checking compete? What are the structural and dynamic characteristics of
the core of the misinformation diffusion network, and who are its main
purveyors? How to reduce the overall amount of misinformation? To explore these
questions we built Hoaxy, an open platform that enables large-scale, systematic
studies of how misinformation and fact-checking spread and compete on Twitter.
Hoaxy filters public tweets that include links to unverified claims or
fact-checking articles. We perform k-core decomposition on a diffusion network
obtained from two million retweets produced by several hundred thousand
accounts over the six months before the election. As we move from the periphery
to the core of the network, fact-checking nearly disappears, while social bots
proliferate. The number of users in the main core reaches equilibrium around
the time of the election, with limited churn and increasingly dense
connections. We conclude by quantifying how effectively the network can be
disrupted by penalizing the most central nodes. These findings provide a first
look at the anatomy of a massive online misinformation diffusion network.","28 pages, 11 figures, submitted to PLOS ONE","PLoS ONE, 13(4): e0196087. 2018",10.1371/journal.pone.0196087,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0196087', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1801.06122v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1801.06122v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1801.06122v1,"{'id': 'http://arxiv.org/abs/1801.06122v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1801.06122v1', 'updated': '2018-01-18T16:54:01Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=18, tm_hour=16, tm_min=54, tm_sec=1, tm_wday=3, tm_yday=18, tm_isdst=0), 'published': '2018-01-18T16:54:01Z', 'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=18, tm_hour=16, tm_min=54, tm_sec=1, tm_wday=3, tm_yday=18, tm_isdst=0), 'title': 'Anatomy of an online misinformation network', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Anatomy of an online misinformation network'}, 'summary': 'Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.'}, 'authors': [{'name': 'Chengcheng Shao'}, {'name': 'Pik-Mai Hui'}, {'name': 'Lei Wang'}, {'name': 'Xinwen Jiang'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}, {'name': 'Giovanni Luca Ciampaglia'}], 'author_detail': {'name': 'Giovanni Luca Ciampaglia'}, 'author': 'Giovanni Luca Ciampaglia', 'arxiv_doi': '10.1371/journal.pone.0196087', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0196087', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1801.06122v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1801.06122v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '28 pages, 11 figures, submitted to PLOS ONE', 'arxiv_journal_ref': 'PLoS ONE, 13(4): e0196087. 2018', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
440,http://arxiv.org/abs/1712.06919v1,2017-12-19 13:39:37+00:00,2017-12-19 13:39:37+00:00,A Production Oriented Approach for Vandalism Detection in Wikidata - The Buffaloberry Vandalism Detector at WSDM Cup 2017,"[arxiv.Result.Author('Rafael Crescenzi'), arxiv.Result.Author('Marcelo Fernandez'), arxiv.Result.Author('Federico A. Garcia Calabria'), arxiv.Result.Author('Pablo Albani'), arxiv.Result.Author('Diego Tauziet'), arxiv.Result.Author('Adriana Baravalle'), arxiv.Result.Author(""Andrés Sebastián D'Ambrosio"")]","Wikidata is a free and open knowledge base from the Wikimedia Foundation,
that not only acts as a central storage of structured data for other projects
of the organization, but also for a growing array of information systems,
including search engines. Like Wikipedia, Wikidata's content can be created and
edited by anyone; which is the main source of its strength, but also allows for
malicious users to vandalize it, risking the spreading of misinformation
through all the systems that rely on it as a source of structured facts. Our
task at the WSDM Cup 2017 was to come up with a fast and reliable prediction
system that narrows down suspicious edits for human revision. Elaborating on
previous works by Heindorf et al. we were able to outperform all other
contestants, while incorporating new interesting features, unifying the
programming language used to only Python and refactoring the feature extractor
into a simpler and more compact code base.","Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956",,,cs.IR,"['cs.IR', 'H.3']","[arxiv.Result.Link('http://arxiv.org/abs/1712.06919v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1712.06919v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1712.06919v1,"{'id': 'http://arxiv.org/abs/1712.06919v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1712.06919v1', 'updated': '2017-12-19T13:39:37Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=19, tm_hour=13, tm_min=39, tm_sec=37, tm_wday=1, tm_yday=353, tm_isdst=0), 'published': '2017-12-19T13:39:37Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=19, tm_hour=13, tm_min=39, tm_sec=37, tm_wday=1, tm_yday=353, tm_isdst=0), 'title': 'A Production Oriented Approach for Vandalism Detection in Wikidata - The\n  Buffaloberry Vandalism Detector at WSDM Cup 2017', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Production Oriented Approach for Vandalism Detection in Wikidata - The\n  Buffaloberry Vandalism Detector at WSDM Cup 2017'}, 'summary': ""Wikidata is a free and open knowledge base from the Wikimedia Foundation,\nthat not only acts as a central storage of structured data for other projects\nof the organization, but also for a growing array of information systems,\nincluding search engines. Like Wikipedia, Wikidata's content can be created and\nedited by anyone; which is the main source of its strength, but also allows for\nmalicious users to vandalize it, risking the spreading of misinformation\nthrough all the systems that rely on it as a source of structured facts. Our\ntask at the WSDM Cup 2017 was to come up with a fast and reliable prediction\nsystem that narrows down suspicious edits for human revision. Elaborating on\nprevious works by Heindorf et al. we were able to outperform all other\ncontestants, while incorporating new interesting features, unifying the\nprogramming language used to only Python and refactoring the feature extractor\ninto a simpler and more compact code base."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Wikidata is a free and open knowledge base from the Wikimedia Foundation,\nthat not only acts as a central storage of structured data for other projects\nof the organization, but also for a growing array of information systems,\nincluding search engines. Like Wikipedia, Wikidata's content can be created and\nedited by anyone; which is the main source of its strength, but also allows for\nmalicious users to vandalize it, risking the spreading of misinformation\nthrough all the systems that rely on it as a source of structured facts. Our\ntask at the WSDM Cup 2017 was to come up with a fast and reliable prediction\nsystem that narrows down suspicious edits for human revision. Elaborating on\nprevious works by Heindorf et al. we were able to outperform all other\ncontestants, while incorporating new interesting features, unifying the\nprogramming language used to only Python and refactoring the feature extractor\ninto a simpler and more compact code base.""}, 'authors': [{'name': 'Rafael Crescenzi'}, {'name': 'Marcelo Fernandez'}, {'name': 'Federico A. Garcia Calabria'}, {'name': 'Pablo Albani'}, {'name': 'Diego Tauziet'}, {'name': 'Adriana Baravalle'}, {'name': ""Andrés Sebastián D'Ambrosio""}], 'author_detail': {'name': ""Andrés Sebastián D'Ambrosio""}, 'arxiv_affiliation': 'Austral University', 'author': ""Andrés Sebastián D'Ambrosio"", 'arxiv_comment': 'Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956', 'links': [{'href': 'http://arxiv.org/abs/1712.06919v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1712.06919v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
441,http://arxiv.org/abs/1712.06414v1,2017-11-29 21:40:29+00:00,2017-11-29 21:40:29+00:00,The Wisdom of Polarized Crowds,"[arxiv.Result.Author('Feng Shi'), arxiv.Result.Author('Misha Teplitskiy'), arxiv.Result.Author('Eamon Duede'), arxiv.Result.Author('James Evans')]","As political polarization in the United States continues to rise, the
question of whether polarized individuals can fruitfully cooperate becomes
pressing. Although diversity of individual perspectives typically leads to
superior team performance on complex tasks, strong political perspectives have
been associated with conflict, misinformation and a reluctance to engage with
people and perspectives beyond one's echo chamber. It is unclear whether
self-selected teams of politically diverse individuals will create higher or
lower quality outcomes. In this paper, we explore the effect of team political
composition on performance through analysis of millions of edits to Wikipedia's
Political, Social Issues, and Science articles. We measure editors' political
alignments by their contributions to conservative versus liberal articles. A
survey of editors validates that those who primarily edit liberal articles
identify more strongly with the Democratic party and those who edit
conservative ones with the Republican party. Our analysis then reveals that
polarized teams---those consisting of a balanced set of politically diverse
editors---create articles of higher quality than politically homogeneous teams.
The effect appears most strongly in Wikipedia's Political articles, but is also
observed in Social Issues and even Science articles. Analysis of article ""talk
pages"" reveals that politically polarized teams engage in longer, more
constructive, competitive, and substantively focused but linguistically diverse
debates than political moderates. More intense use of Wikipedia policies by
politically diverse teams suggests institutional design principles to help
unleash the power of politically polarized teams.",,Nature Human Behavior. 2019,10.1038/s41562-019-0541-6,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY', 'cs.DL', 'stat.AP']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41562-019-0541-6', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1712.06414v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1712.06414v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1712.06414v1,"{'id': 'http://arxiv.org/abs/1712.06414v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1712.06414v1', 'updated': '2017-11-29T21:40:29Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=29, tm_hour=21, tm_min=40, tm_sec=29, tm_wday=2, tm_yday=333, tm_isdst=0), 'published': '2017-11-29T21:40:29Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=29, tm_hour=21, tm_min=40, tm_sec=29, tm_wday=2, tm_yday=333, tm_isdst=0), 'title': 'The Wisdom of Polarized Crowds', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Wisdom of Polarized Crowds'}, 'summary': 'As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one\'s echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia\'s\nPolitical, Social Issues, and Science articles. We measure editors\' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia\'s Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article ""talk\npages"" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one\'s echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia\'s\nPolitical, Social Issues, and Science articles. We measure editors\' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia\'s Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article ""talk\npages"" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.'}, 'authors': [{'name': 'Feng Shi'}, {'name': 'Misha Teplitskiy'}, {'name': 'Eamon Duede'}, {'name': 'James Evans'}], 'author_detail': {'name': 'James Evans'}, 'author': 'James Evans', 'arxiv_doi': '10.1038/s41562-019-0541-6', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41562-019-0541-6', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1712.06414v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1712.06414v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Nature Human Behavior. 2019', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
442,http://arxiv.org/abs/1711.09918v1,2017-11-27 19:00:08+00:00,2017-11-27 19:00:08+00:00,Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation,"[arxiv.Result.Author('Jooyeon Kim'), arxiv.Result.Author('Behzad Tabibian'), arxiv.Result.Author('Alice Oh'), arxiv.Result.Author('Bernhard Schoelkopf'), arxiv.Result.Author('Manuel Gomez-Rodriguez')]","Online social networking sites are experimenting with the following
crowd-powered procedure to reduce the spread of fake news and misinformation:
whenever a user is exposed to a story through her feed, she can flag the story
as misinformation and, if the story receives enough flags, it is sent to a
trusted third party for fact checking. If this party identifies the story as
misinformation, it is marked as disputed. However, given the uncertain number
of exposures, the high cost of fact checking, and the trade-off between flags
and exposures, the above mentioned procedure requires careful reasoning and
smart algorithms which, to the best of our knowledge, do not exist to date.
  In this paper, we first introduce a flexible representation of the above
procedure using the framework of marked temporal point processes. Then, we
develop a scalable online algorithm, Curb, to select which stories to send for
fact checking and when to do so to efficiently reduce the spread of
misinformation with provable guarantees. In doing so, we need to solve a novel
stochastic optimal control problem for stochastic differential equations with
jumps, which is of independent interest. Experiments on two real-world datasets
gathered from Twitter and Weibo show that our algorithm may be able to
effectively reduce the spread of fake news and misinformation.","To appear at the 11th ACM International Conference on Web Search and
  Data Mining (WSDM 2018)",,,cs.SI,"['cs.SI', 'cs.HC', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1711.09918v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.09918v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.09918v1,"{'id': 'http://arxiv.org/abs/1711.09918v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.09918v1', 'updated': '2017-11-27T19:00:08Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=27, tm_hour=19, tm_min=0, tm_sec=8, tm_wday=0, tm_yday=331, tm_isdst=0), 'published': '2017-11-27T19:00:08Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=27, tm_hour=19, tm_min=0, tm_sec=8, tm_wday=0, tm_yday=331, tm_isdst=0), 'title': 'Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation'}, 'summary': 'Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.'}, 'authors': [{'name': 'Jooyeon Kim'}, {'name': 'Behzad Tabibian'}, {'name': 'Alice Oh'}, {'name': 'Bernhard Schoelkopf'}, {'name': 'Manuel Gomez-Rodriguez'}], 'author_detail': {'name': 'Manuel Gomez-Rodriguez'}, 'author': 'Manuel Gomez-Rodriguez', 'arxiv_comment': 'To appear at the 11th ACM International Conference on Web Search and\n  Data Mining (WSDM 2018)', 'links': [{'href': 'http://arxiv.org/abs/1711.09918v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.09918v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
443,http://arxiv.org/abs/1711.09025v2,2018-03-02 16:57:43+00:00,2017-11-24 15:53:37+00:00,Fake News Detection in Social Networks via Crowd Signals,"[arxiv.Result.Author('Sebastian Tschiatschek'), arxiv.Result.Author('Adish Singla'), arxiv.Result.Author('Manuel Gomez Rodriguez'), arxiv.Result.Author('Arpit Merchant'), arxiv.Result.Author('Andreas Krause')]","Our work considers leveraging crowd signals for detecting fake news and is
motivated by tools recently introduced by Facebook that enable users to flag
fake news. By aggregating users' flags, our goal is to select a small subset of
news every day, send them to an expert (e.g., via a third-party fact-checking
organization), and stop the spread of news identified as fake by an expert. The
main objective of our work is to minimize the spread of misinformation by
stopping the propagation of fake news in the network. It is especially
challenging to achieve this objective as it requires detecting fake news with
high-confidence as quickly as possible. We show that in order to leverage
users' flags efficiently, it is crucial to learn about users' flagging
accuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian
inference for detecting fake news and jointly learns about users' flagging
accuracy over time. Our algorithm employs posterior sampling to actively trade
off exploitation (selecting news that maximize the objective value at a given
epoch) and exploration (selecting news that maximize the value of information
towards learning about users' flagging accuracy). We demonstrate the
effectiveness of our approach via extensive experiments and show the power of
leveraging community signals for fake news detection.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1711.09025v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.09025v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.09025v2,"{'id': 'http://arxiv.org/abs/1711.09025v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.09025v2', 'updated': '2018-03-02T16:57:43Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=2, tm_hour=16, tm_min=57, tm_sec=43, tm_wday=4, tm_yday=61, tm_isdst=0), 'published': '2017-11-24T15:53:37Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=24, tm_hour=15, tm_min=53, tm_sec=37, tm_wday=4, tm_yday=328, tm_isdst=0), 'title': 'Fake News Detection in Social Networks via Crowd Signals', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Fake News Detection in Social Networks via Crowd Signals'}, 'summary': ""Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.""}, 'authors': [{'name': 'Sebastian Tschiatschek'}, {'name': 'Adish Singla'}, {'name': 'Manuel Gomez Rodriguez'}, {'name': 'Arpit Merchant'}, {'name': 'Andreas Krause'}], 'author_detail': {'name': 'Andreas Krause'}, 'author': 'Andreas Krause', 'links': [{'href': 'http://arxiv.org/abs/1711.09025v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.09025v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
444,http://arxiv.org/abs/1711.08615v1,2017-11-23 08:36:17+00:00,2017-11-23 08:36:17+00:00,Controlling Elections through Social Influence,"[arxiv.Result.Author('Bryan Wilder'), arxiv.Result.Author('Yevgeniy Vorobeychik')]","Election control considers the problem of an adversary who attempts to tamper
with a voting process, in order to either ensure that their favored candidate
wins (constructive control) or another candidate loses (destructive control).
As online social networks have become significant sources of information for
potential voters, a new tool in an attacker's arsenal is to effect control by
harnessing social influence, for example, by spreading fake news and other
forms of misinformation through online social media.
  We consider the computational problem of election control via social
influence, studying the conditions under which finding good adversarial
strategies is computationally feasible. We consider two objectives for the
adversary in both the constructive and destructive control settings:
probability and margin of victory (POV and MOV, respectively). We present
several strong negative results, showing, for example, that the problem of
maximizing POV is inapproximable for any constant factor. On the other hand, we
present approximation algorithms which provide somewhat weaker approximation
guarantees, such as bicriteria approximations for the POV objective and
constant-factor approximations for MOV. Finally, we present mixed integer
programming formulations for these problems. Experimental results show that our
approximation algorithms often find near-optimal control strategies, indicating
that election control through social influence is a salient threat to election
integrity.","19 pages, 2 figures",,,cs.MA,"['cs.MA', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1711.08615v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.08615v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.08615v1,"{'id': 'http://arxiv.org/abs/1711.08615v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.08615v1', 'updated': '2017-11-23T08:36:17Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=23, tm_hour=8, tm_min=36, tm_sec=17, tm_wday=3, tm_yday=327, tm_isdst=0), 'published': '2017-11-23T08:36:17Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=23, tm_hour=8, tm_min=36, tm_sec=17, tm_wday=3, tm_yday=327, tm_isdst=0), 'title': 'Controlling Elections through Social Influence', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Controlling Elections through Social Influence'}, 'summary': ""Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.""}, 'authors': [{'name': 'Bryan Wilder'}, {'name': 'Yevgeniy Vorobeychik'}], 'author_detail': {'name': 'Yevgeniy Vorobeychik'}, 'author': 'Yevgeniy Vorobeychik', 'arxiv_comment': '19 pages, 2 figures', 'links': [{'href': 'http://arxiv.org/abs/1711.08615v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.08615v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
445,http://arxiv.org/abs/1711.07412v2,2017-12-01 20:06:56+00:00,2017-11-20 17:01:20+00:00,Distributed Rumor Blocking with Multiple Positive Cascades,"[arxiv.Result.Author('Guangmo Amo Tong'), arxiv.Result.Author('Weili Wu'), arxiv.Result.Author('Ding-Zhu Du')]","Misinformation and rumor can spread rapidly and widely through online social
networks and therefore rumor controlling has become a critical issue. It is
often assumed that there is a single authority whose goal is to minimize the
spread of rumor by generating a positive cascade. In this paper, we study a
more realistic scenario when there are multiple positive cascades generated by
different agents. For the multiple-cascade diffusion, we propose the P2P
independent cascade (PIC) model for private social communications. The main
part of this paper is an analysis of the rumor blocking effect (i.e. the number
of the users activated by rumor) when the agents non-cooperatively generate the
positive cascades. We show that the rumor blocking effect provided by the Nash
equilibrium will not be arbitrarily worse even if the positive cascades are
generated non-cooperatively. In addition, we give a discussion on how the
cascade priority and activation order affect the rumor blocking problem. We
experimentally examine the Nash equilibrium of the proposed games by
simulations done on real social network structures.",under review,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1711.07412v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.07412v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.07412v2,"{'id': 'http://arxiv.org/abs/1711.07412v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.07412v2', 'updated': '2017-12-01T20:06:56Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=1, tm_hour=20, tm_min=6, tm_sec=56, tm_wday=4, tm_yday=335, tm_isdst=0), 'published': '2017-11-20T17:01:20Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=20, tm_hour=17, tm_min=1, tm_sec=20, tm_wday=0, tm_yday=324, tm_isdst=0), 'title': 'Distributed Rumor Blocking with Multiple Positive Cascades', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Distributed Rumor Blocking with Multiple Positive Cascades'}, 'summary': 'Misinformation and rumor can spread rapidly and widely through online social\nnetworks and therefore rumor controlling has become a critical issue. It is\noften assumed that there is a single authority whose goal is to minimize the\nspread of rumor by generating a positive cascade. In this paper, we study a\nmore realistic scenario when there are multiple positive cascades generated by\ndifferent agents. For the multiple-cascade diffusion, we propose the P2P\nindependent cascade (PIC) model for private social communications. The main\npart of this paper is an analysis of the rumor blocking effect (i.e. the number\nof the users activated by rumor) when the agents non-cooperatively generate the\npositive cascades. We show that the rumor blocking effect provided by the Nash\nequilibrium will not be arbitrarily worse even if the positive cascades are\ngenerated non-cooperatively. In addition, we give a discussion on how the\ncascade priority and activation order affect the rumor blocking problem. We\nexperimentally examine the Nash equilibrium of the proposed games by\nsimulations done on real social network structures.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation and rumor can spread rapidly and widely through online social\nnetworks and therefore rumor controlling has become a critical issue. It is\noften assumed that there is a single authority whose goal is to minimize the\nspread of rumor by generating a positive cascade. In this paper, we study a\nmore realistic scenario when there are multiple positive cascades generated by\ndifferent agents. For the multiple-cascade diffusion, we propose the P2P\nindependent cascade (PIC) model for private social communications. The main\npart of this paper is an analysis of the rumor blocking effect (i.e. the number\nof the users activated by rumor) when the agents non-cooperatively generate the\npositive cascades. We show that the rumor blocking effect provided by the Nash\nequilibrium will not be arbitrarily worse even if the positive cascades are\ngenerated non-cooperatively. In addition, we give a discussion on how the\ncascade priority and activation order affect the rumor blocking problem. We\nexperimentally examine the Nash equilibrium of the proposed games by\nsimulations done on real social network structures.'}, 'authors': [{'name': 'Guangmo Amo Tong'}, {'name': 'Weili Wu'}, {'name': 'Ding-Zhu Du'}], 'author_detail': {'name': 'Ding-Zhu Du'}, 'author': 'Ding-Zhu Du', 'arxiv_comment': 'under review', 'links': [{'href': 'http://arxiv.org/abs/1711.07412v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.07412v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
446,http://arxiv.org/abs/1711.00726v2,2018-09-07 00:44:22+00:00,2017-11-02 15:49:47+00:00,A Comprehensive Low and High-level Feature Analysis for Early Rumor Detection on Twitter,[arxiv.Result.Author('Tu Ngoc Nguyen')],"Recent work have done a good job in modeling rumors and detecting them over
microblog streams. However, the performance of their automatic approaches are
not relatively high when looking early in the diffusion. A first intuition is
that, at early stage, most of the aggregated rumor features (e.g., propagation
features) are not mature and distinctive enough. The objective of rumor
debunking in microblogs, however, are to detect these misinformation as early
as possible. In this work, we leverage neural models in learning the hidden
representations of individual rumor-related tweets at the very beginning of a
rumor. Our extensive experiments show that the resulting signal improves our
classification performance over time, significantly within the first 10 hours.
To deepen the understanding of these low and high-level features in
contributing to the model performance over time, we conduct an extensive study
on a wide range of high impact rumor features for the 48 hours range. The end
model that engages these features are shown to be competitive, reaches over 90%
accuracy and out-performs strong baselines in our carefully cured dataset.","CIKM 2017 Workshop on Interpretable Data Mining - Bridging the Gap
  between Shallow and Deep Models (IDM 2017). arXiv admin note: substantial
  text overlap with arXiv:1709.04402",,,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Link('http://arxiv.org/abs/1711.00726v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.00726v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.00726v2,"{'id': 'http://arxiv.org/abs/1711.00726v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.00726v2', 'updated': '2018-09-07T00:44:22Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=9, tm_mday=7, tm_hour=0, tm_min=44, tm_sec=22, tm_wday=4, tm_yday=250, tm_isdst=0), 'published': '2017-11-02T15:49:47Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=2, tm_hour=15, tm_min=49, tm_sec=47, tm_wday=3, tm_yday=306, tm_isdst=0), 'title': 'A Comprehensive Low and High-level Feature Analysis for Early Rumor\n  Detection on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A Comprehensive Low and High-level Feature Analysis for Early Rumor\n  Detection on Twitter'}, 'summary': 'Recent work have done a good job in modeling rumors and detecting them over\nmicroblog streams. However, the performance of their automatic approaches are\nnot relatively high when looking early in the diffusion. A first intuition is\nthat, at early stage, most of the aggregated rumor features (e.g., propagation\nfeatures) are not mature and distinctive enough. The objective of rumor\ndebunking in microblogs, however, are to detect these misinformation as early\nas possible. In this work, we leverage neural models in learning the hidden\nrepresentations of individual rumor-related tweets at the very beginning of a\nrumor. Our extensive experiments show that the resulting signal improves our\nclassification performance over time, significantly within the first 10 hours.\nTo deepen the understanding of these low and high-level features in\ncontributing to the model performance over time, we conduct an extensive study\non a wide range of high impact rumor features for the 48 hours range. The end\nmodel that engages these features are shown to be competitive, reaches over 90%\naccuracy and out-performs strong baselines in our carefully cured dataset.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Recent work have done a good job in modeling rumors and detecting them over\nmicroblog streams. However, the performance of their automatic approaches are\nnot relatively high when looking early in the diffusion. A first intuition is\nthat, at early stage, most of the aggregated rumor features (e.g., propagation\nfeatures) are not mature and distinctive enough. The objective of rumor\ndebunking in microblogs, however, are to detect these misinformation as early\nas possible. In this work, we leverage neural models in learning the hidden\nrepresentations of individual rumor-related tweets at the very beginning of a\nrumor. Our extensive experiments show that the resulting signal improves our\nclassification performance over time, significantly within the first 10 hours.\nTo deepen the understanding of these low and high-level features in\ncontributing to the model performance over time, we conduct an extensive study\non a wide range of high impact rumor features for the 48 hours range. The end\nmodel that engages these features are shown to be competitive, reaches over 90%\naccuracy and out-performs strong baselines in our carefully cured dataset.'}, 'authors': [{'name': 'Tu Ngoc Nguyen'}], 'author_detail': {'name': 'Tu Ngoc Nguyen'}, 'author': 'Tu Ngoc Nguyen', 'arxiv_comment': 'CIKM 2017 Workshop on Interpretable Data Mining - Bridging the Gap\n  between Shallow and Deep Models (IDM 2017). arXiv admin note: substantial\n  text overlap with arXiv:1709.04402', 'links': [{'href': 'http://arxiv.org/abs/1711.00726v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.00726v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
447,http://arxiv.org/abs/1711.00715v1,2017-10-31 18:52:28+00:00,2017-10-31 18:52:28+00:00,Related Fact Checks: a tool for combating fake news,[arxiv.Result.Author('Sreya Guha')],"The emergence of ""Fake News"" and misinformation via online news and social
media has spurred an interest in computational tools to combat this phenomenon.
In this paper we present a new ""Related Fact Checks"" service, which can help a
reader critically evaluate an article and make a judgment on its veracity by
bringing up fact checks that are relevant to the article. We describe the core
technical problems that need to be solved in building a ""Related Fact Checks""
service, and present results from an evaluation of an implementation.",,,,cs.IR,"['cs.IR', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1711.00715v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1711.00715v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1711.00715v1,"{'id': 'http://arxiv.org/abs/1711.00715v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1711.00715v1', 'updated': '2017-10-31T18:52:28Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=10, tm_mday=31, tm_hour=18, tm_min=52, tm_sec=28, tm_wday=1, tm_yday=304, tm_isdst=0), 'published': '2017-10-31T18:52:28Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=10, tm_mday=31, tm_hour=18, tm_min=52, tm_sec=28, tm_wday=1, tm_yday=304, tm_isdst=0), 'title': 'Related Fact Checks: a tool for combating fake news', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Related Fact Checks: a tool for combating fake news'}, 'summary': 'The emergence of ""Fake News"" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new ""Related Fact Checks"" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a ""Related Fact Checks""\nservice, and present results from an evaluation of an implementation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The emergence of ""Fake News"" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new ""Related Fact Checks"" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a ""Related Fact Checks""\nservice, and present results from an evaluation of an implementation.'}, 'authors': [{'name': 'Sreya Guha'}], 'author_detail': {'name': 'Sreya Guha'}, 'author': 'Sreya Guha', 'links': [{'href': 'http://arxiv.org/abs/1711.00715v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1711.00715v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
448,http://arxiv.org/abs/1708.08151v2,2017-09-08 02:37:16+00:00,2017-08-27 23:00:27+00:00,Automated Crowdturfing Attacks and Defenses in Online Review Systems,"[arxiv.Result.Author('Yuanshun Yao'), arxiv.Result.Author('Bimal Viswanath'), arxiv.Result.Author('Jenna Cryan'), arxiv.Result.Author('Haitao Zheng'), arxiv.Result.Author('Ben Y. Zhao')]","Malicious crowdsourcing forums are gaining traction as sources of spreading
misinformation online, but are limited by the costs of hiring and managing
human workers. In this paper, we identify a new class of attacks that leverage
deep learning language models (Recurrent Neural Networks or RNNs) to automate
the generation of fake online reviews for products and services. Not only are
these attacks cheap and therefore more scalable, but they can control rate of
content output to eliminate the signature burstiness that makes crowdsourced
campaigns easy to detect.
  Using Yelp reviews as an example platform, we show how a two phased review
generation and customization attack can produce reviews that are
indistinguishable by state-of-the-art statistical detectors. We conduct a
survey-based user study to show these reviews not only evade human detection,
but also score high on ""usefulness"" metrics by users. Finally, we develop novel
automated defenses against these attacks, by leveraging the lossy
transformation introduced by the RNN training and generation cycle. We consider
countermeasures against our mechanisms, show that they produce unattractive
cost-benefit tradeoffs for attackers, and that they can be further curtailed by
simple constraints imposed by online service providers.",,,,cs.CR,"['cs.CR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1708.08151v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.08151v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.08151v2,"{'id': 'http://arxiv.org/abs/1708.08151v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.08151v2', 'updated': '2017-09-08T02:37:16Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=9, tm_mday=8, tm_hour=2, tm_min=37, tm_sec=16, tm_wday=4, tm_yday=251, tm_isdst=0), 'published': '2017-08-27T23:00:27Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=27, tm_hour=23, tm_min=0, tm_sec=27, tm_wday=6, tm_yday=239, tm_isdst=0), 'title': 'Automated Crowdturfing Attacks and Defenses in Online Review Systems', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Automated Crowdturfing Attacks and Defenses in Online Review Systems'}, 'summary': 'Malicious crowdsourcing forums are gaining traction as sources of spreading\nmisinformation online, but are limited by the costs of hiring and managing\nhuman workers. In this paper, we identify a new class of attacks that leverage\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\nthe generation of fake online reviews for products and services. Not only are\nthese attacks cheap and therefore more scalable, but they can control rate of\ncontent output to eliminate the signature burstiness that makes crowdsourced\ncampaigns easy to detect.\n  Using Yelp reviews as an example platform, we show how a two phased review\ngeneration and customization attack can produce reviews that are\nindistinguishable by state-of-the-art statistical detectors. We conduct a\nsurvey-based user study to show these reviews not only evade human detection,\nbut also score high on ""usefulness"" metrics by users. Finally, we develop novel\nautomated defenses against these attacks, by leveraging the lossy\ntransformation introduced by the RNN training and generation cycle. We consider\ncountermeasures against our mechanisms, show that they produce unattractive\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\nsimple constraints imposed by online service providers.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Malicious crowdsourcing forums are gaining traction as sources of spreading\nmisinformation online, but are limited by the costs of hiring and managing\nhuman workers. In this paper, we identify a new class of attacks that leverage\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\nthe generation of fake online reviews for products and services. Not only are\nthese attacks cheap and therefore more scalable, but they can control rate of\ncontent output to eliminate the signature burstiness that makes crowdsourced\ncampaigns easy to detect.\n  Using Yelp reviews as an example platform, we show how a two phased review\ngeneration and customization attack can produce reviews that are\nindistinguishable by state-of-the-art statistical detectors. We conduct a\nsurvey-based user study to show these reviews not only evade human detection,\nbut also score high on ""usefulness"" metrics by users. Finally, we develop novel\nautomated defenses against these attacks, by leveraging the lossy\ntransformation introduced by the RNN training and generation cycle. We consider\ncountermeasures against our mechanisms, show that they produce unattractive\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\nsimple constraints imposed by online service providers.'}, 'authors': [{'name': 'Yuanshun Yao'}, {'name': 'Bimal Viswanath'}, {'name': 'Jenna Cryan'}, {'name': 'Haitao Zheng'}, {'name': 'Ben Y. Zhao'}], 'author_detail': {'name': 'Ben Y. Zhao'}, 'author': 'Ben Y. Zhao', 'links': [{'href': 'http://arxiv.org/abs/1708.08151v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.08151v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
449,http://arxiv.org/abs/1708.07239v1,2017-08-24 01:07:21+00:00,2017-08-24 01:07:21+00:00,Finding Streams in Knowledge Graphs to Support Fact Checking,"[arxiv.Result.Author('Prashant Shiralkar'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Giovanni Luca Ciampaglia')]","The volume and velocity of information that gets generated online limits
current journalistic practices to fact-check claims at the same rate.
Computational approaches for fact checking may be the key to help mitigate the
risks of massive misinformation spread. Such approaches can be designed to not
only be scalable and effective at assessing veracity of dubious claims, but
also to boost a human fact checker's productivity by surfacing relevant facts
and patterns to aid their analysis. To this end, we present a novel,
unsupervised network-flow based approach to determine the truthfulness of a
statement of fact expressed in the form of a (subject, predicate, object)
triple. We view a knowledge graph of background information about real-world
entities as a flow network, and knowledge as a fluid, abstract commodity. We
show that computational fact checking of such a triple then amounts to finding
a ""knowledge stream"" that emanates from the subject node and flows toward the
object node through paths connecting them. Evaluation on a range of real-world
and hand-crafted datasets of facts related to entertainment, business, sports,
geography and more reveals that this network-flow model can be very effective
in discerning true statements from false ones, outperforming existing
algorithms on many test cases. Moreover, the model is expressive in its ability
to automatically discover several useful path patterns and surface relevant
facts that may help a human fact checker corroborate or refute a claim.",Extended version of the paper in proceedings of ICDM 2017,,,cs.AI,"['cs.AI', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1708.07239v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.07239v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.07239v1,"{'id': 'http://arxiv.org/abs/1708.07239v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.07239v1', 'updated': '2017-08-24T01:07:21Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=24, tm_hour=1, tm_min=7, tm_sec=21, tm_wday=3, tm_yday=236, tm_isdst=0), 'published': '2017-08-24T01:07:21Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=24, tm_hour=1, tm_min=7, tm_sec=21, tm_wday=3, tm_yday=236, tm_isdst=0), 'title': 'Finding Streams in Knowledge Graphs to Support Fact Checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Finding Streams in Knowledge Graphs to Support Fact Checking'}, 'summary': 'The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker\'s productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na ""knowledge stream"" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker\'s productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na ""knowledge stream"" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.'}, 'authors': [{'name': 'Prashant Shiralkar'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}, {'name': 'Giovanni Luca Ciampaglia'}], 'author_detail': {'name': 'Giovanni Luca Ciampaglia'}, 'author': 'Giovanni Luca Ciampaglia', 'arxiv_comment': 'Extended version of the paper in proceedings of ICDM 2017', 'links': [{'href': 'http://arxiv.org/abs/1708.07239v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.07239v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
450,http://arxiv.org/abs/1708.02763v2,2018-01-04 07:51:52+00:00,2017-08-09 08:54:54+00:00,Has the Online Discussion Been Manipulated? Quantifying Online Discussion Authenticity within Online Social Media,"[arxiv.Result.Author('Aviad Elyashar'), arxiv.Result.Author('Jorge Bendahan'), arxiv.Result.Author('Rami Puzis')]","Online social media (OSM) has a enormous influence in today's world. Some
individuals view OSM as fertile ground for abuse and use it to disseminate
misinformation and political propaganda, slander competitors, and spread spam.
The crowdturfing industry employs large numbers of bots and human workers to
manipulate OSM and misrepresent public opinion. The detection of online
discussion topics manipulated by OSM \emph{abusers} is an emerging issue
attracting significant attention. In this paper, we propose an approach for
quantifying the authenticity of online discussions based on the similarity of
OSM accounts participating in the discussion to known abusers and legitimate
accounts. Our method uses several similarity functions for the analysis and
classification of OSM accounts. The proposed methods are demonstrated using
Twitter data collected for this study and previously published \emph{Arabic
honeypot dataset}. The former includes manually labeled accounts and abusers
who participated in crowdturfing platforms. Evaluation of the topic's
authenticity, derived from account similarity functions, shows that the
suggested approach is effective for discriminating between topics that were
strongly promoted by abusers and topics that attracted authentic public
interest.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1708.02763v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1708.02763v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1708.02763v2,"{'id': 'http://arxiv.org/abs/1708.02763v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1708.02763v2', 'updated': '2018-01-04T07:51:52Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=4, tm_hour=7, tm_min=51, tm_sec=52, tm_wday=3, tm_yday=4, tm_isdst=0), 'published': '2017-08-09T08:54:54Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=8, tm_mday=9, tm_hour=8, tm_min=54, tm_sec=54, tm_wday=2, tm_yday=221, tm_isdst=0), 'title': 'Has the Online Discussion Been Manipulated? Quantifying Online\n  Discussion Authenticity within Online Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Has the Online Discussion Been Manipulated? Quantifying Online\n  Discussion Authenticity within Online Social Media'}, 'summary': ""Online social media (OSM) has a enormous influence in today's world. Some\nindividuals view OSM as fertile ground for abuse and use it to disseminate\nmisinformation and political propaganda, slander competitors, and spread spam.\nThe crowdturfing industry employs large numbers of bots and human workers to\nmanipulate OSM and misrepresent public opinion. The detection of online\ndiscussion topics manipulated by OSM \\emph{abusers} is an emerging issue\nattracting significant attention. In this paper, we propose an approach for\nquantifying the authenticity of online discussions based on the similarity of\nOSM accounts participating in the discussion to known abusers and legitimate\naccounts. Our method uses several similarity functions for the analysis and\nclassification of OSM accounts. The proposed methods are demonstrated using\nTwitter data collected for this study and previously published \\emph{Arabic\nhoneypot dataset}. The former includes manually labeled accounts and abusers\nwho participated in crowdturfing platforms. Evaluation of the topic's\nauthenticity, derived from account similarity functions, shows that the\nsuggested approach is effective for discriminating between topics that were\nstrongly promoted by abusers and topics that attracted authentic public\ninterest."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online social media (OSM) has a enormous influence in today's world. Some\nindividuals view OSM as fertile ground for abuse and use it to disseminate\nmisinformation and political propaganda, slander competitors, and spread spam.\nThe crowdturfing industry employs large numbers of bots and human workers to\nmanipulate OSM and misrepresent public opinion. The detection of online\ndiscussion topics manipulated by OSM \\emph{abusers} is an emerging issue\nattracting significant attention. In this paper, we propose an approach for\nquantifying the authenticity of online discussions based on the similarity of\nOSM accounts participating in the discussion to known abusers and legitimate\naccounts. Our method uses several similarity functions for the analysis and\nclassification of OSM accounts. The proposed methods are demonstrated using\nTwitter data collected for this study and previously published \\emph{Arabic\nhoneypot dataset}. The former includes manually labeled accounts and abusers\nwho participated in crowdturfing platforms. Evaluation of the topic's\nauthenticity, derived from account similarity functions, shows that the\nsuggested approach is effective for discriminating between topics that were\nstrongly promoted by abusers and topics that attracted authentic public\ninterest.""}, 'authors': [{'name': 'Aviad Elyashar'}, {'name': 'Jorge Bendahan'}, {'name': 'Rami Puzis'}], 'author_detail': {'name': 'Rami Puzis'}, 'author': 'Rami Puzis', 'links': [{'href': 'http://arxiv.org/abs/1708.02763v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1708.02763v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
451,http://arxiv.org/abs/1707.09939v1,2017-07-31 16:20:31+00:00,2017-07-31 16:20:31+00:00,An Analysis of the Twitter Discussion on the 2016 Austrian Presidential Elections,"[arxiv.Result.Author('Ema Kušen'), arxiv.Result.Author('Mark Strembeck')]","In this paper, we provide a systematic analysis of the Twitter discussion on
the 2016 Austrian presidential elections. In particular, we extracted and
analyzed a data-set consisting of 343645 Twitter messages related to the 2016
Austrian presidential elections. Our analysis combines methods from network
science, sentiment analysis, as well as bot detection. Among other things, we
found that: a) the winner of the election (Alexander Van der Bellen) was
considerably more popular and influential on Twitter than his opponent, b) the
Twitter followers of Van der Bellen substantially participated in the spread of
misinformation about him, c) there was a clear polarization in terms of the
sentiments spread by Twitter followers of the two presidential candidates, d)
the in-degree and out-degree distributions of the underlying communication
network are heavy-tailed, and e) compared to other recent events, such as the
2016 Brexit referendum or the 2016 US presidential elections, only a very small
number of bots participated in the Twitter discussion on the 2016 Austrian
presidential election.",,,,cs.SI,"['cs.SI', 'G.2.2; I.2.7; J.4']","[arxiv.Result.Link('http://arxiv.org/abs/1707.09939v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1707.09939v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1707.09939v1,"{'id': 'http://arxiv.org/abs/1707.09939v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1707.09939v1', 'updated': '2017-07-31T16:20:31Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=31, tm_hour=16, tm_min=20, tm_sec=31, tm_wday=0, tm_yday=212, tm_isdst=0), 'published': '2017-07-31T16:20:31Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=31, tm_hour=16, tm_min=20, tm_sec=31, tm_wday=0, tm_yday=212, tm_isdst=0), 'title': 'An Analysis of the Twitter Discussion on the 2016 Austrian Presidential\n  Elections', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Analysis of the Twitter Discussion on the 2016 Austrian Presidential\n  Elections'}, 'summary': 'In this paper, we provide a systematic analysis of the Twitter discussion on\nthe 2016 Austrian presidential elections. In particular, we extracted and\nanalyzed a data-set consisting of 343645 Twitter messages related to the 2016\nAustrian presidential elections. Our analysis combines methods from network\nscience, sentiment analysis, as well as bot detection. Among other things, we\nfound that: a) the winner of the election (Alexander Van der Bellen) was\nconsiderably more popular and influential on Twitter than his opponent, b) the\nTwitter followers of Van der Bellen substantially participated in the spread of\nmisinformation about him, c) there was a clear polarization in terms of the\nsentiments spread by Twitter followers of the two presidential candidates, d)\nthe in-degree and out-degree distributions of the underlying communication\nnetwork are heavy-tailed, and e) compared to other recent events, such as the\n2016 Brexit referendum or the 2016 US presidential elections, only a very small\nnumber of bots participated in the Twitter discussion on the 2016 Austrian\npresidential election.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In this paper, we provide a systematic analysis of the Twitter discussion on\nthe 2016 Austrian presidential elections. In particular, we extracted and\nanalyzed a data-set consisting of 343645 Twitter messages related to the 2016\nAustrian presidential elections. Our analysis combines methods from network\nscience, sentiment analysis, as well as bot detection. Among other things, we\nfound that: a) the winner of the election (Alexander Van der Bellen) was\nconsiderably more popular and influential on Twitter than his opponent, b) the\nTwitter followers of Van der Bellen substantially participated in the spread of\nmisinformation about him, c) there was a clear polarization in terms of the\nsentiments spread by Twitter followers of the two presidential candidates, d)\nthe in-degree and out-degree distributions of the underlying communication\nnetwork are heavy-tailed, and e) compared to other recent events, such as the\n2016 Brexit referendum or the 2016 US presidential elections, only a very small\nnumber of bots participated in the Twitter discussion on the 2016 Austrian\npresidential election.'}, 'authors': [{'name': 'Ema Kušen'}, {'name': 'Mark Strembeck'}], 'author_detail': {'name': 'Mark Strembeck'}, 'author': 'Mark Strembeck', 'links': [{'href': 'http://arxiv.org/abs/1707.09939v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1707.09939v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'G.2.2; I.2.7; J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
452,http://arxiv.org/abs/1707.07592v4,2018-05-24 23:18:12+00:00,2017-07-24 14:53:36+00:00,The spread of low-credibility content by social bots,"[arxiv.Result.Author('Chengcheng Shao'), arxiv.Result.Author('Giovanni Luca Ciampaglia'), arxiv.Result.Author('Onur Varol'), arxiv.Result.Author('Kaicheng Yang'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","The massive spread of digital misinformation has been identified as a major
global risk and has been alleged to influence elections and threaten
democracies. Communication, cognitive, social, and computer scientists are
engaged in efforts to study the complex causes for the viral diffusion of
misinformation online and to develop solutions, while search and social media
platforms are beginning to deploy countermeasures. With few exceptions, these
efforts have been mainly informed by anecdotal evidence rather than systematic
data. Here we analyze 14 million messages spreading 400 thousand articles on
Twitter during and following the 2016 U.S. presidential campaign and election.
We find evidence that social bots played a disproportionate role in amplifying
low-credibility content. Accounts that actively spread articles from
low-credibility sources are significantly more likely to be bots. Automated
accounts are particularly active in amplifying content in the very early
spreading moments, before an article goes viral. Bots also target users with
many followers through replies and mentions. Humans are vulnerable to this
manipulation, retweeting bots who post links to low-credibility content.
Successful low-credibility sources are heavily supported by social bots. These
results suggest that curbing social bots may be an effective strategy for
mitigating the spread of online misinformation.","41 pages, 20 figures, 3 tables","Nature Communications, 9: 4787, 2018",10.1038/s41467-018-06930-7,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1038/s41467-018-06930-7', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1707.07592v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1707.07592v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1707.07592v4,"{'id': 'http://arxiv.org/abs/1707.07592v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1707.07592v4', 'updated': '2018-05-24T23:18:12Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=24, tm_hour=23, tm_min=18, tm_sec=12, tm_wday=3, tm_yday=144, tm_isdst=0), 'published': '2017-07-24T14:53:36Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=24, tm_hour=14, tm_min=53, tm_sec=36, tm_wday=0, tm_yday=205, tm_isdst=0), 'title': 'The spread of low-credibility content by social bots', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of low-credibility content by social bots'}, 'summary': 'The massive spread of digital misinformation has been identified as a major\nglobal risk and has been alleged to influence elections and threaten\ndemocracies. Communication, cognitive, social, and computer scientists are\nengaged in efforts to study the complex causes for the viral diffusion of\nmisinformation online and to develop solutions, while search and social media\nplatforms are beginning to deploy countermeasures. With few exceptions, these\nefforts have been mainly informed by anecdotal evidence rather than systematic\ndata. Here we analyze 14 million messages spreading 400 thousand articles on\nTwitter during and following the 2016 U.S. presidential campaign and election.\nWe find evidence that social bots played a disproportionate role in amplifying\nlow-credibility content. Accounts that actively spread articles from\nlow-credibility sources are significantly more likely to be bots. Automated\naccounts are particularly active in amplifying content in the very early\nspreading moments, before an article goes viral. Bots also target users with\nmany followers through replies and mentions. Humans are vulnerable to this\nmanipulation, retweeting bots who post links to low-credibility content.\nSuccessful low-credibility sources are heavily supported by social bots. These\nresults suggest that curbing social bots may be an effective strategy for\nmitigating the spread of online misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The massive spread of digital misinformation has been identified as a major\nglobal risk and has been alleged to influence elections and threaten\ndemocracies. Communication, cognitive, social, and computer scientists are\nengaged in efforts to study the complex causes for the viral diffusion of\nmisinformation online and to develop solutions, while search and social media\nplatforms are beginning to deploy countermeasures. With few exceptions, these\nefforts have been mainly informed by anecdotal evidence rather than systematic\ndata. Here we analyze 14 million messages spreading 400 thousand articles on\nTwitter during and following the 2016 U.S. presidential campaign and election.\nWe find evidence that social bots played a disproportionate role in amplifying\nlow-credibility content. Accounts that actively spread articles from\nlow-credibility sources are significantly more likely to be bots. Automated\naccounts are particularly active in amplifying content in the very early\nspreading moments, before an article goes viral. Bots also target users with\nmany followers through replies and mentions. Humans are vulnerable to this\nmanipulation, retweeting bots who post links to low-credibility content.\nSuccessful low-credibility sources are heavily supported by social bots. These\nresults suggest that curbing social bots may be an effective strategy for\nmitigating the spread of online misinformation.'}, 'authors': [{'name': 'Chengcheng Shao'}, {'name': 'Giovanni Luca Ciampaglia'}, {'name': 'Onur Varol'}, {'name': 'Kaicheng Yang'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1038/s41467-018-06930-7', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1038/s41467-018-06930-7', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1707.07592v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1707.07592v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '41 pages, 20 figures, 3 tables', 'arxiv_journal_ref': 'Nature Communications, 9: 4787, 2018', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
453,http://arxiv.org/abs/1707.03778v1,2017-07-12 15:55:20+00:00,2017-07-12 15:55:20+00:00,Catching Zika Fever: Application of Crowdsourcing and Machine Learning for Tracking Health Misinformation on Twitter,"[arxiv.Result.Author('Amira Ghenai'), arxiv.Result.Author('Yelena Mejova')]","In February 2016, World Health Organization declared the Zika outbreak a
Public Health Emergency of International Concern. With developing evidence it
can cause birth defects, and the Summer Olympics coming up in the worst
affected country, Brazil, the virus caught fire on social media. In this work,
use Zika as a case study in building a tool for tracking the misinformation
around health concerns on Twitter. We collect more than 13 million tweets --
spanning the initial reports in February 2016 and the Summer Olympics --
regarding the Zika outbreak and track rumors outlined by the World Health
Organization and Snopes fact checking website. The tool pipeline, which
incorporates health professionals, crowdsourcing, and machine learning, allows
us to capture health-related rumors around the world, as well as clarification
campaigns by reputable health organizations. In the case of Zika, we discover
an extremely bursty behavior of rumor-related topics, and show that, once the
questionable topic is detected, it is possible to identify rumor-bearing tweets
using automated techniques. Thus, we illustrate insights the proposed tools
provide into potentially harmful information on social media, allowing public
health researchers and practitioners to respond with a targeted and timely
action.","11 pages, 7 figures, short version to be published in the Fifth IEEE
  International Conference on Healthcare Informatics (ICHI 2017)",,,cs.SI,"['cs.SI', 'cs.CY', '68P20', 'H.2.8; H.3.3; I.2.7; J.3']","[arxiv.Result.Link('http://arxiv.org/abs/1707.03778v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1707.03778v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1707.03778v1,"{'id': 'http://arxiv.org/abs/1707.03778v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1707.03778v1', 'updated': '2017-07-12T15:55:20Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=12, tm_hour=15, tm_min=55, tm_sec=20, tm_wday=2, tm_yday=193, tm_isdst=0), 'published': '2017-07-12T15:55:20Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=12, tm_hour=15, tm_min=55, tm_sec=20, tm_wday=2, tm_yday=193, tm_isdst=0), 'title': 'Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter'}, 'summary': 'In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.'}, 'authors': [{'name': 'Amira Ghenai'}, {'name': 'Yelena Mejova'}], 'author_detail': {'name': 'Yelena Mejova'}, 'author': 'Yelena Mejova', 'arxiv_comment': '11 pages, 7 figures, short version to be published in the Fifth IEEE\n  International Conference on Healthcare Informatics (ICHI 2017)', 'links': [{'href': 'http://arxiv.org/abs/1707.03778v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1707.03778v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68P20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.2.8; H.3.3; I.2.7; J.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
454,http://arxiv.org/abs/1707.03264v2,2018-05-21 10:31:40+00:00,2017-07-11 13:44:51+00:00,A simple but tough-to-beat baseline for the Fake News Challenge stance detection task,"[arxiv.Result.Author('Benjamin Riedel'), arxiv.Result.Author('Isabelle Augenstein'), arxiv.Result.Author('Georgios P. Spithourakis'), arxiv.Result.Author('Sebastian Riedel')]","Identifying public misinformation is a complicated and challenging task. An
important part of checking the veracity of a specific claim is to evaluate the
stance different news sources take towards the assertion. Automatic stance
evaluation, i.e. stance detection, would arguably facilitate the process of
fact checking. In this paper, we present our stance detection system which
claimed third place in Stage 1 of the Fake News Challenge. Despite our
straightforward approach, our system performs at a competitive level with the
complex ensembles of the top two winning teams. We therefore propose our system
as the 'simple but tough-to-beat baseline' for the Fake News Challenge stance
detection task.","6 pages, 1 figure, 3 tables; additional reference and details added,
  typos and wording corrected",,,cs.CL,['cs.CL'],"[arxiv.Result.Link('http://arxiv.org/abs/1707.03264v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1707.03264v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1707.03264v2,"{'id': 'http://arxiv.org/abs/1707.03264v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1707.03264v2', 'updated': '2018-05-21T10:31:40Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=21, tm_hour=10, tm_min=31, tm_sec=40, tm_wday=0, tm_yday=141, tm_isdst=0), 'published': '2017-07-11T13:44:51Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=11, tm_hour=13, tm_min=44, tm_sec=51, tm_wday=1, tm_yday=192, tm_isdst=0), 'title': 'A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task'}, 'summary': ""Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.""}, 'authors': [{'name': 'Benjamin Riedel'}, {'name': 'Isabelle Augenstein'}, {'name': 'Georgios P. Spithourakis'}, {'name': 'Sebastian Riedel'}], 'author_detail': {'name': 'Sebastian Riedel'}, 'author': 'Sebastian Riedel', 'arxiv_comment': '6 pages, 1 figure, 3 tables; additional reference and details added,\n  typos and wording corrected', 'links': [{'href': 'http://arxiv.org/abs/1707.03264v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1707.03264v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
455,http://arxiv.org/abs/1706.09494v2,2017-07-08 13:28:55+00:00,2017-06-28 21:54:16+00:00,Misinformation spreading on Facebook,"[arxiv.Result.Author('Fabiana Zollo'), arxiv.Result.Author('Walter Quattrociocchi')]","Social media are pervaded by unsubstantiated or untruthful rumors, that
contribute to the alarming phenomenon of misinformation. The widespread
presence of a heterogeneous mass of information sources may affect the
mechanisms behind the formation of public opinion. Such a scenario is a florid
environment for digital wildfires when combined with functional illiteracy,
information overload, and confirmation bias. In this essay, we focus on a
collection of works aiming at providing quantitative evidence about the
cognitive determinants behind misinformation and rumor spreading. We account
for users' behavior with respect to two distinct narratives: a) conspiracy and
b) scientific information sources. In particular, we analyze Facebook data on a
time span of five years in both the Italian and the US context, and measure
users' response to i) information consistent with one's narrative, ii) troll
contents, and iii) dissenting information e.g., debunking attempts. Our
findings suggest that users tend to a) join polarized communities sharing a
common narrative (echo chambers), b) acquire information confirming their
beliefs (confirmation bias) even if containing false claims, and c) ignore
dissenting information.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1706.09494v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1706.09494v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1706.09494v2,"{'id': 'http://arxiv.org/abs/1706.09494v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1706.09494v2', 'updated': '2017-07-08T13:28:55Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=8, tm_hour=13, tm_min=28, tm_sec=55, tm_wday=5, tm_yday=189, tm_isdst=0), 'published': '2017-06-28T21:54:16Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=28, tm_hour=21, tm_min=54, tm_sec=16, tm_wday=2, tm_yday=179, tm_isdst=0), 'title': 'Misinformation spreading on Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation spreading on Facebook'}, 'summary': ""Social media are pervaded by unsubstantiated or untruthful rumors, that\ncontribute to the alarming phenomenon of misinformation. The widespread\npresence of a heterogeneous mass of information sources may affect the\nmechanisms behind the formation of public opinion. Such a scenario is a florid\nenvironment for digital wildfires when combined with functional illiteracy,\ninformation overload, and confirmation bias. In this essay, we focus on a\ncollection of works aiming at providing quantitative evidence about the\ncognitive determinants behind misinformation and rumor spreading. We account\nfor users' behavior with respect to two distinct narratives: a) conspiracy and\nb) scientific information sources. In particular, we analyze Facebook data on a\ntime span of five years in both the Italian and the US context, and measure\nusers' response to i) information consistent with one's narrative, ii) troll\ncontents, and iii) dissenting information e.g., debunking attempts. Our\nfindings suggest that users tend to a) join polarized communities sharing a\ncommon narrative (echo chambers), b) acquire information confirming their\nbeliefs (confirmation bias) even if containing false claims, and c) ignore\ndissenting information."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media are pervaded by unsubstantiated or untruthful rumors, that\ncontribute to the alarming phenomenon of misinformation. The widespread\npresence of a heterogeneous mass of information sources may affect the\nmechanisms behind the formation of public opinion. Such a scenario is a florid\nenvironment for digital wildfires when combined with functional illiteracy,\ninformation overload, and confirmation bias. In this essay, we focus on a\ncollection of works aiming at providing quantitative evidence about the\ncognitive determinants behind misinformation and rumor spreading. We account\nfor users' behavior with respect to two distinct narratives: a) conspiracy and\nb) scientific information sources. In particular, we analyze Facebook data on a\ntime span of five years in both the Italian and the US context, and measure\nusers' response to i) information consistent with one's narrative, ii) troll\ncontents, and iii) dissenting information e.g., debunking attempts. Our\nfindings suggest that users tend to a) join polarized communities sharing a\ncommon narrative (echo chambers), b) acquire information confirming their\nbeliefs (confirmation bias) even if containing false claims, and c) ignore\ndissenting information.""}, 'authors': [{'name': 'Fabiana Zollo'}, {'name': 'Walter Quattrociocchi'}], 'author_detail': {'name': 'Walter Quattrociocchi'}, 'author': 'Walter Quattrociocchi', 'links': [{'href': 'http://arxiv.org/abs/1706.09494v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1706.09494v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
456,http://arxiv.org/abs/1706.06314v1,2017-06-20 08:36:56+00:00,2017-06-20 08:36:56+00:00,Mining Significant Microblogs for Misinformation Identification: An Attention-based Approach,"[arxiv.Result.Author('Qiang Liu'), arxiv.Result.Author('Feng Yu'), arxiv.Result.Author('Shu Wu'), arxiv.Result.Author('Liang Wang')]","With the rapid growth of social media, massive misinformation is also
spreading widely on social media, such as microblog, and bring negative effects
to human life. Nowadays, automatic misinformation identification has drawn
attention from academic and industrial communities. For an event on social
media usually consists of multiple microblogs, current methods are mainly based
on global statistical features. However, information on social media is full of
noisy and outliers, which should be alleviated. Moreover, most of microblogs
about an event have little contribution to the identification of
misinformation, where useful information can be easily overwhelmed by useless
information. Thus, it is important to mine significant microblogs for a
reliable misinformation identification method. In this paper, we propose an
Attention-based approach for Identification of Misinformation (AIM). Based on
the attention mechanism, AIM can select microblogs with largest attention
values for misinformation identification. The attention mechanism in AIM
contains two parts: content attention and dynamic attention. Content attention
is calculated based textual features of each microblog. Dynamic attention is
related to the time interval between the posting time of a microblog and the
beginning of the event. To evaluate AIM, we conduct a series of experiments on
the Weibo dataset and the Twitter dataset, and the experimental results show
that the proposed AIM model outperforms the state-of-the-art methods.",,,,cs.IR,"['cs.IR', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1706.06314v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1706.06314v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1706.06314v1,"{'id': 'http://arxiv.org/abs/1706.06314v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1706.06314v1', 'updated': '2017-06-20T08:36:56Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=20, tm_hour=8, tm_min=36, tm_sec=56, tm_wday=1, tm_yday=171, tm_isdst=0), 'published': '2017-06-20T08:36:56Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=20, tm_hour=8, tm_min=36, tm_sec=56, tm_wday=1, tm_yday=171, tm_isdst=0), 'title': 'Mining Significant Microblogs for Misinformation Identification: An\n  Attention-based Approach', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Mining Significant Microblogs for Misinformation Identification: An\n  Attention-based Approach'}, 'summary': 'With the rapid growth of social media, massive misinformation is also\nspreading widely on social media, such as microblog, and bring negative effects\nto human life. Nowadays, automatic misinformation identification has drawn\nattention from academic and industrial communities. For an event on social\nmedia usually consists of multiple microblogs, current methods are mainly based\non global statistical features. However, information on social media is full of\nnoisy and outliers, which should be alleviated. Moreover, most of microblogs\nabout an event have little contribution to the identification of\nmisinformation, where useful information can be easily overwhelmed by useless\ninformation. Thus, it is important to mine significant microblogs for a\nreliable misinformation identification method. In this paper, we propose an\nAttention-based approach for Identification of Misinformation (AIM). Based on\nthe attention mechanism, AIM can select microblogs with largest attention\nvalues for misinformation identification. The attention mechanism in AIM\ncontains two parts: content attention and dynamic attention. Content attention\nis calculated based textual features of each microblog. Dynamic attention is\nrelated to the time interval between the posting time of a microblog and the\nbeginning of the event. To evaluate AIM, we conduct a series of experiments on\nthe Weibo dataset and the Twitter dataset, and the experimental results show\nthat the proposed AIM model outperforms the state-of-the-art methods.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'With the rapid growth of social media, massive misinformation is also\nspreading widely on social media, such as microblog, and bring negative effects\nto human life. Nowadays, automatic misinformation identification has drawn\nattention from academic and industrial communities. For an event on social\nmedia usually consists of multiple microblogs, current methods are mainly based\non global statistical features. However, information on social media is full of\nnoisy and outliers, which should be alleviated. Moreover, most of microblogs\nabout an event have little contribution to the identification of\nmisinformation, where useful information can be easily overwhelmed by useless\ninformation. Thus, it is important to mine significant microblogs for a\nreliable misinformation identification method. In this paper, we propose an\nAttention-based approach for Identification of Misinformation (AIM). Based on\nthe attention mechanism, AIM can select microblogs with largest attention\nvalues for misinformation identification. The attention mechanism in AIM\ncontains two parts: content attention and dynamic attention. Content attention\nis calculated based textual features of each microblog. Dynamic attention is\nrelated to the time interval between the posting time of a microblog and the\nbeginning of the event. To evaluate AIM, we conduct a series of experiments on\nthe Weibo dataset and the Twitter dataset, and the experimental results show\nthat the proposed AIM model outperforms the state-of-the-art methods.'}, 'authors': [{'name': 'Qiang Liu'}, {'name': 'Feng Yu'}, {'name': 'Shu Wu'}, {'name': 'Liang Wang'}], 'author_detail': {'name': 'Liang Wang'}, 'author': 'Liang Wang', 'links': [{'href': 'http://arxiv.org/abs/1706.06314v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1706.06314v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
457,http://arxiv.org/abs/1706.05924v2,2017-07-17 17:17:37+00:00,2017-06-19 13:26:41+00:00,"""Everything I Disagree With is #FakeNews"": Correlating Political Polarization and Spread of Misinformation","[arxiv.Result.Author('Manoel Horta Ribeiro'), arxiv.Result.Author('Pedro H. Calais'), arxiv.Result.Author('Virgílio A. F. Almeida'), arxiv.Result.Author('Wagner Meira Jr')]","An important challenge in the process of tracking and detecting the
dissemination of misinformation is to understand the political gap between
people that engage with the so called ""fake news"". A possible factor
responsible for this gap is opinion polarization, which may prompt the general
public to classify content that they disagree or want to discredit as fake. In
this work, we study the relationship between political polarization and content
reported by Twitter users as related to ""fake news"". We investigate how
polarization may create distinct narratives on what misinformation actually is.
We perform our study based on two datasets collected from Twitter. The first
dataset contains tweets about US politics in general, from which we compute the
degree of polarization of each user towards the Republican and Democratic
Party. In the second dataset, we collect tweets and URLs that co-occurred with
""fake news"" related keywords and hashtags, such as #FakeNews and
#AlternativeFact, as well as reactions towards such tweets and URLs. We then
analyze the relationship between polarization and what is perceived as
misinformation, and whether users are designating information that they
disagree as fake. Our results show an increase in the polarization of users and
URLs associated with fake-news keywords and hashtags, when compared to
information not labeled as ""fake news"". We discuss the impact of our findings
on the challenges of tracking ""fake news"" in the ongoing battle against
misinformation.","8 pages, 10 figures, to be presented at DS+J Workshop @ KDD'17",,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1706.05924v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1706.05924v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1706.05924v2,"{'id': 'http://arxiv.org/abs/1706.05924v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1706.05924v2', 'updated': '2017-07-17T17:17:37Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=7, tm_mday=17, tm_hour=17, tm_min=17, tm_sec=37, tm_wday=0, tm_yday=198, tm_isdst=0), 'published': '2017-06-19T13:26:41Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=19, tm_hour=13, tm_min=26, tm_sec=41, tm_wday=0, tm_yday=170, tm_isdst=0), 'title': '""Everything I Disagree With is #FakeNews"": Correlating Political\n  Polarization and Spread of Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""Everything I Disagree With is #FakeNews"": Correlating Political\n  Polarization and Spread of Misinformation'}, 'summary': 'An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called ""fake news"". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to ""fake news"". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n""fake news"" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as ""fake news"". We discuss the impact of our findings\non the challenges of tracking ""fake news"" in the ongoing battle against\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called ""fake news"". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to ""fake news"". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n""fake news"" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as ""fake news"". We discuss the impact of our findings\non the challenges of tracking ""fake news"" in the ongoing battle against\nmisinformation.'}, 'authors': [{'name': 'Manoel Horta Ribeiro'}, {'name': 'Pedro H. Calais'}, {'name': 'Virgílio A. F. Almeida'}, {'name': 'Wagner Meira Jr'}], 'author_detail': {'name': 'Wagner Meira Jr'}, 'author': 'Wagner Meira Jr', 'arxiv_comment': ""8 pages, 10 figures, to be presented at DS+J Workshop @ KDD'17"", 'links': [{'href': 'http://arxiv.org/abs/1706.05924v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1706.05924v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
458,http://arxiv.org/abs/1706.03019v1,2017-06-09 16:21:46+00:00,2017-06-09 16:21:46+00:00,Understanding Information Spreading in Social Media during Hurricane Sandy: User Activity and Network Properties,"[arxiv.Result.Author('Arif Mohaimin Sadri'), arxiv.Result.Author('Samiul Hasan'), arxiv.Result.Author('Satish V. Ukkusuri'), arxiv.Result.Author('Manuel Cebrian')]","Many people use social media to seek information during disasters while
lacking access to traditional information sources. In this study, we analyze
Twitter data to understand information spreading activities of social media
users during hurricane Sandy. We create multiple subgraphs of Twitter users
based on activity levels and analyze network properties of the subgraphs. We
observe that user information sharing activity follows a power-law distribution
suggesting the existence of few highly active nodes in disseminating
information and many other nodes being less active. We also observe close
enough connected components and isolates at all levels of activity, and
networks become less transitive, but more assortative for larger subgraphs. We
also analyze the association between user activities and characteristics that
may influence user behavior to spread information during a crisis. Users become
more active in spreading information if they are centrally placed in the
network, less eccentric, and have higher degrees. Our analysis provides
insights on how to exploit user characteristics and network properties to
spread information or limit the spreading of misinformation during a crisis
event.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1706.03019v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1706.03019v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1706.03019v1,"{'id': 'http://arxiv.org/abs/1706.03019v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1706.03019v1', 'updated': '2017-06-09T16:21:46Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=9, tm_hour=16, tm_min=21, tm_sec=46, tm_wday=4, tm_yday=160, tm_isdst=0), 'published': '2017-06-09T16:21:46Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=9, tm_hour=16, tm_min=21, tm_sec=46, tm_wday=4, tm_yday=160, tm_isdst=0), 'title': 'Understanding Information Spreading in Social Media during Hurricane\n  Sandy: User Activity and Network Properties', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Understanding Information Spreading in Social Media during Hurricane\n  Sandy: User Activity and Network Properties'}, 'summary': 'Many people use social media to seek information during disasters while\nlacking access to traditional information sources. In this study, we analyze\nTwitter data to understand information spreading activities of social media\nusers during hurricane Sandy. We create multiple subgraphs of Twitter users\nbased on activity levels and analyze network properties of the subgraphs. We\nobserve that user information sharing activity follows a power-law distribution\nsuggesting the existence of few highly active nodes in disseminating\ninformation and many other nodes being less active. We also observe close\nenough connected components and isolates at all levels of activity, and\nnetworks become less transitive, but more assortative for larger subgraphs. We\nalso analyze the association between user activities and characteristics that\nmay influence user behavior to spread information during a crisis. Users become\nmore active in spreading information if they are centrally placed in the\nnetwork, less eccentric, and have higher degrees. Our analysis provides\ninsights on how to exploit user characteristics and network properties to\nspread information or limit the spreading of misinformation during a crisis\nevent.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Many people use social media to seek information during disasters while\nlacking access to traditional information sources. In this study, we analyze\nTwitter data to understand information spreading activities of social media\nusers during hurricane Sandy. We create multiple subgraphs of Twitter users\nbased on activity levels and analyze network properties of the subgraphs. We\nobserve that user information sharing activity follows a power-law distribution\nsuggesting the existence of few highly active nodes in disseminating\ninformation and many other nodes being less active. We also observe close\nenough connected components and isolates at all levels of activity, and\nnetworks become less transitive, but more assortative for larger subgraphs. We\nalso analyze the association between user activities and characteristics that\nmay influence user behavior to spread information during a crisis. Users become\nmore active in spreading information if they are centrally placed in the\nnetwork, less eccentric, and have higher degrees. Our analysis provides\ninsights on how to exploit user characteristics and network properties to\nspread information or limit the spreading of misinformation during a crisis\nevent.'}, 'authors': [{'name': 'Arif Mohaimin Sadri'}, {'name': 'Samiul Hasan'}, {'name': 'Satish V. Ukkusuri'}, {'name': 'Manuel Cebrian'}], 'author_detail': {'name': 'Manuel Cebrian'}, 'author': 'Manuel Cebrian', 'links': [{'href': 'http://arxiv.org/abs/1706.03019v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1706.03019v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
459,http://arxiv.org/abs/1705.11187v1,2017-05-31 17:33:31+00:00,2017-05-31 17:33:31+00:00,U-Phylogeny: Undirected Provenance Graph Construction in the Wild,"[arxiv.Result.Author('Aparna Bharati'), arxiv.Result.Author('Daniel Moreira'), arxiv.Result.Author('Allan Pinto'), arxiv.Result.Author('Joel Brogan'), arxiv.Result.Author('Kevin Bowyer'), arxiv.Result.Author('Patrick Flynn'), arxiv.Result.Author('Walter Scheirer'), arxiv.Result.Author('Anderson Rocha')]","Deriving relationships between images and tracing back their history of
modifications are at the core of Multimedia Phylogeny solutions, which aim to
combat misinformation through doctored visual media. Nonetheless, most recent
image phylogeny solutions cannot properly address cases of forged composite
images with multiple donors, an area known as multiple parenting phylogeny
(MPP). This paper presents a preliminary undirected graph construction solution
for MPP, without any strict assumptions. The algorithm is underpinned by robust
image representative keypoints and different geometric consistency checks among
matching regions in both images to provide regions of interest for direct
comparison. The paper introduces a novel technique to geometrically filter the
most promising matches as well as to aid in the shared region localization
task. The strength of the approach is corroborated by experiments with
real-world cases, with and without image distractors (unrelated cases).","5 pages, Accepted in International Conference on Image Processing,
  2017",,,cs.CV,['cs.CV'],"[arxiv.Result.Link('http://arxiv.org/abs/1705.11187v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1705.11187v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1705.11187v1,"{'id': 'http://arxiv.org/abs/1705.11187v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1705.11187v1', 'updated': '2017-05-31T17:33:31Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=33, tm_sec=31, tm_wday=2, tm_yday=151, tm_isdst=0), 'published': '2017-05-31T17:33:31Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=31, tm_hour=17, tm_min=33, tm_sec=31, tm_wday=2, tm_yday=151, tm_isdst=0), 'title': 'U-Phylogeny: Undirected Provenance Graph Construction in the Wild', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'U-Phylogeny: Undirected Provenance Graph Construction in the Wild'}, 'summary': 'Deriving relationships between images and tracing back their history of\nmodifications are at the core of Multimedia Phylogeny solutions, which aim to\ncombat misinformation through doctored visual media. Nonetheless, most recent\nimage phylogeny solutions cannot properly address cases of forged composite\nimages with multiple donors, an area known as multiple parenting phylogeny\n(MPP). This paper presents a preliminary undirected graph construction solution\nfor MPP, without any strict assumptions. The algorithm is underpinned by robust\nimage representative keypoints and different geometric consistency checks among\nmatching regions in both images to provide regions of interest for direct\ncomparison. The paper introduces a novel technique to geometrically filter the\nmost promising matches as well as to aid in the shared region localization\ntask. The strength of the approach is corroborated by experiments with\nreal-world cases, with and without image distractors (unrelated cases).', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Deriving relationships between images and tracing back their history of\nmodifications are at the core of Multimedia Phylogeny solutions, which aim to\ncombat misinformation through doctored visual media. Nonetheless, most recent\nimage phylogeny solutions cannot properly address cases of forged composite\nimages with multiple donors, an area known as multiple parenting phylogeny\n(MPP). This paper presents a preliminary undirected graph construction solution\nfor MPP, without any strict assumptions. The algorithm is underpinned by robust\nimage representative keypoints and different geometric consistency checks among\nmatching regions in both images to provide regions of interest for direct\ncomparison. The paper introduces a novel technique to geometrically filter the\nmost promising matches as well as to aid in the shared region localization\ntask. The strength of the approach is corroborated by experiments with\nreal-world cases, with and without image distractors (unrelated cases).'}, 'authors': [{'name': 'Aparna Bharati'}, {'name': 'Daniel Moreira'}, {'name': 'Allan Pinto'}, {'name': 'Joel Brogan'}, {'name': 'Kevin Bowyer'}, {'name': 'Patrick Flynn'}, {'name': 'Walter Scheirer'}, {'name': 'Anderson Rocha'}], 'author_detail': {'name': 'Anderson Rocha'}, 'author': 'Anderson Rocha', 'arxiv_comment': '5 pages, Accepted in International Conference on Image Processing,\n  2017', 'links': [{'href': 'http://arxiv.org/abs/1705.11187v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1705.11187v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
460,http://arxiv.org/abs/1705.02522v1,2017-05-06 19:38:33+00:00,2017-05-06 19:38:33+00:00,People on Drugs: Credibility of User Statements in Health Communities,"[arxiv.Result.Author('Subhabrata Mukherjee'), arxiv.Result.Author('Gerhard Weikum'), arxiv.Result.Author('Cristian Danescu-Niculescu-Mizil')]","Online health communities are a valuable source of information for patients
and physicians. However, such user-generated resources are often plagued by
inaccuracies and misinformation. In this work we propose a method for
automatically establishing the credibility of user-generated medical statements
and the trustworthiness of their authors by exploiting linguistic cues and
distant supervision from expert sources. To this end we introduce a
probabilistic graphical model that jointly learns user trustworthiness,
statement credibility, and language objectivity. We apply this methodology to
the task of extracting rare or unknown side-effects of medical drugs --- this
being one of the problems where large scale non-expert data has the potential
to complement expert medical knowledge. We show that our method can reliably
extract side-effects and filter out false statements, while identifying
trustworthy users that are likely to contribute valuable medical information.",,,,cs.AI,"['cs.AI', 'cs.CL', 'cs.IR', 'cs.SI', 'stat.ML']","[arxiv.Result.Link('http://arxiv.org/abs/1705.02522v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1705.02522v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1705.02522v1,"{'id': 'http://arxiv.org/abs/1705.02522v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1705.02522v1', 'updated': '2017-05-06T19:38:33Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=6, tm_hour=19, tm_min=38, tm_sec=33, tm_wday=5, tm_yday=126, tm_isdst=0), 'published': '2017-05-06T19:38:33Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=6, tm_hour=19, tm_min=38, tm_sec=33, tm_wday=5, tm_yday=126, tm_isdst=0), 'title': 'People on Drugs: Credibility of User Statements in Health Communities', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'People on Drugs: Credibility of User Statements in Health Communities'}, 'summary': 'Online health communities are a valuable source of information for patients\nand physicians. However, such user-generated resources are often plagued by\ninaccuracies and misinformation. In this work we propose a method for\nautomatically establishing the credibility of user-generated medical statements\nand the trustworthiness of their authors by exploiting linguistic cues and\ndistant supervision from expert sources. To this end we introduce a\nprobabilistic graphical model that jointly learns user trustworthiness,\nstatement credibility, and language objectivity. We apply this methodology to\nthe task of extracting rare or unknown side-effects of medical drugs --- this\nbeing one of the problems where large scale non-expert data has the potential\nto complement expert medical knowledge. We show that our method can reliably\nextract side-effects and filter out false statements, while identifying\ntrustworthy users that are likely to contribute valuable medical information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online health communities are a valuable source of information for patients\nand physicians. However, such user-generated resources are often plagued by\ninaccuracies and misinformation. In this work we propose a method for\nautomatically establishing the credibility of user-generated medical statements\nand the trustworthiness of their authors by exploiting linguistic cues and\ndistant supervision from expert sources. To this end we introduce a\nprobabilistic graphical model that jointly learns user trustworthiness,\nstatement credibility, and language objectivity. We apply this methodology to\nthe task of extracting rare or unknown side-effects of medical drugs --- this\nbeing one of the problems where large scale non-expert data has the potential\nto complement expert medical knowledge. We show that our method can reliably\nextract side-effects and filter out false statements, while identifying\ntrustworthy users that are likely to contribute valuable medical information.'}, 'authors': [{'name': 'Subhabrata Mukherjee'}, {'name': 'Gerhard Weikum'}, {'name': 'Cristian Danescu-Niculescu-Mizil'}], 'author_detail': {'name': 'Cristian Danescu-Niculescu-Mizil'}, 'author': 'Cristian Danescu-Niculescu-Mizil', 'links': [{'href': 'http://arxiv.org/abs/1705.02522v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1705.02522v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
461,http://arxiv.org/abs/1705.01213v1,2017-05-03 01:03:23+00:00,2017-05-03 01:03:23+00:00,Informative and misinformative interactions in a school of fish,"[arxiv.Result.Author('Emanuele Crosato'), arxiv.Result.Author('Li Jiang'), arxiv.Result.Author('Valentin Lecheval'), arxiv.Result.Author('Joseph T. Lizier'), arxiv.Result.Author('X. Rosalind Wang'), arxiv.Result.Author('Pierre Tichit'), arxiv.Result.Author('Guy Theraulaz'), arxiv.Result.Author('Mikhail Prokopenko')]","It is generally accepted that, when moving in groups, animals process
information to coordinate their motion. Recent studies have begun to apply
rigorous methods based on Information Theory to quantify such distributed
computation. Following this perspective, we use transfer entropy to quantify
dynamic information flows locally in space and time across a school of fish
during directional changes around a circular tank, i.e. U-turns. This analysis
reveals peaks in information flows during collective U-turns and identifies two
different flows: an informative flow (positive transfer entropy) based on fish
that have already turned about fish that are turning, and a misinformative flow
(negative transfer entropy) based on fish that have not turned yet about fish
that are turning. We also reveal that the information flows are related to
relative position and alignment between fish, and identify spatial patterns of
information and misinformation cascades. This study offers several
methodological contributions and we expect further application of these
methodologies to reveal intricacies of self-organisation in other animal groups
and active matter in general.",,,,q-bio.QM,"['q-bio.QM', 'cs.IT', 'math.IT', 'nlin.AO']","[arxiv.Result.Link('http://arxiv.org/abs/1705.01213v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1705.01213v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1705.01213v1,"{'id': 'http://arxiv.org/abs/1705.01213v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1705.01213v1', 'updated': '2017-05-03T01:03:23Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=3, tm_hour=1, tm_min=3, tm_sec=23, tm_wday=2, tm_yday=123, tm_isdst=0), 'published': '2017-05-03T01:03:23Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=3, tm_hour=1, tm_min=3, tm_sec=23, tm_wday=2, tm_yday=123, tm_isdst=0), 'title': 'Informative and misinformative interactions in a school of fish', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Informative and misinformative interactions in a school of fish'}, 'summary': 'It is generally accepted that, when moving in groups, animals process\ninformation to coordinate their motion. Recent studies have begun to apply\nrigorous methods based on Information Theory to quantify such distributed\ncomputation. Following this perspective, we use transfer entropy to quantify\ndynamic information flows locally in space and time across a school of fish\nduring directional changes around a circular tank, i.e. U-turns. This analysis\nreveals peaks in information flows during collective U-turns and identifies two\ndifferent flows: an informative flow (positive transfer entropy) based on fish\nthat have already turned about fish that are turning, and a misinformative flow\n(negative transfer entropy) based on fish that have not turned yet about fish\nthat are turning. We also reveal that the information flows are related to\nrelative position and alignment between fish, and identify spatial patterns of\ninformation and misinformation cascades. This study offers several\nmethodological contributions and we expect further application of these\nmethodologies to reveal intricacies of self-organisation in other animal groups\nand active matter in general.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'It is generally accepted that, when moving in groups, animals process\ninformation to coordinate their motion. Recent studies have begun to apply\nrigorous methods based on Information Theory to quantify such distributed\ncomputation. Following this perspective, we use transfer entropy to quantify\ndynamic information flows locally in space and time across a school of fish\nduring directional changes around a circular tank, i.e. U-turns. This analysis\nreveals peaks in information flows during collective U-turns and identifies two\ndifferent flows: an informative flow (positive transfer entropy) based on fish\nthat have already turned about fish that are turning, and a misinformative flow\n(negative transfer entropy) based on fish that have not turned yet about fish\nthat are turning. We also reveal that the information flows are related to\nrelative position and alignment between fish, and identify spatial patterns of\ninformation and misinformation cascades. This study offers several\nmethodological contributions and we expect further application of these\nmethodologies to reveal intricacies of self-organisation in other animal groups\nand active matter in general.'}, 'authors': [{'name': 'Emanuele Crosato'}, {'name': 'Li Jiang'}, {'name': 'Valentin Lecheval'}, {'name': 'Joseph T. Lizier'}, {'name': 'X. Rosalind Wang'}, {'name': 'Pierre Tichit'}, {'name': 'Guy Theraulaz'}, {'name': 'Mikhail Prokopenko'}], 'author_detail': {'name': 'Mikhail Prokopenko'}, 'author': 'Mikhail Prokopenko', 'links': [{'href': 'http://arxiv.org/abs/1705.01213v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1705.01213v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.AO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
462,http://arxiv.org/abs/1704.07506v1,2017-04-25 01:20:40+00:00,2017-04-25 01:20:40+00:00,Some Like it Hoax: Automated Fake News Detection in Social Networks,"[arxiv.Result.Author('Eugenio Tacchini'), arxiv.Result.Author('Gabriele Ballarin'), arxiv.Result.Author('Marco L. Della Vedova'), arxiv.Result.Author('Stefano Moret'), arxiv.Result.Author('Luca de Alfaro')]","In recent years, the reliability of information on the Internet has emerged
as a crucial issue of modern society. Social network sites (SNSs) have
revolutionized the way in which information is spread by allowing users to
freely share content. As a consequence, SNSs are also increasingly used as
vectors for the diffusion of misinformation and hoaxes. The amount of
disseminated information and the rapidity of its diffusion make it practically
impossible to assess reliability in a timely manner, highlighting the need for
automatic hoax detection systems.
  As a contribution towards this objective, we show that Facebook posts can be
classified with high accuracy as hoaxes or non-hoaxes on the basis of the users
who ""liked"" them. We present two classification techniques, one based on
logistic regression, the other on a novel adaptation of boolean crowdsourcing
algorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,
we obtain classification accuracies exceeding 99% even when the training set
contains less than 1% of the posts. We further show that our techniques are
robust: they work even when we restrict our attention to the users who like
both hoax and non-hoax posts. These results suggest that mapping the diffusion
pattern of information can be a useful component of automatic hoax detection
systems.",,"Proceedings of the Second Workshop on Data Science for Social Good
  (SoGood), Skopje, Macedonia, 2017. CEUR Workshop Proceedings Volume 1960,
  2017",,cs.LG,"['cs.LG', 'cs.HC', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1704.07506v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1704.07506v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1704.07506v1,"{'id': 'http://arxiv.org/abs/1704.07506v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1704.07506v1', 'updated': '2017-04-25T01:20:40Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=4, tm_mday=25, tm_hour=1, tm_min=20, tm_sec=40, tm_wday=1, tm_yday=115, tm_isdst=0), 'published': '2017-04-25T01:20:40Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=4, tm_mday=25, tm_hour=1, tm_min=20, tm_sec=40, tm_wday=1, tm_yday=115, tm_isdst=0), 'title': 'Some Like it Hoax: Automated Fake News Detection in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Some Like it Hoax: Automated Fake News Detection in Social Networks'}, 'summary': 'In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho ""liked"" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho ""liked"" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.'}, 'authors': [{'name': 'Eugenio Tacchini'}, {'name': 'Gabriele Ballarin'}, {'name': 'Marco L. Della Vedova'}, {'name': 'Stefano Moret'}, {'name': 'Luca de Alfaro'}], 'author_detail': {'name': 'Luca de Alfaro'}, 'author': 'Luca de Alfaro', 'arxiv_journal_ref': 'Proceedings of the Second Workshop on Data Science for Social Good\n  (SoGood), Skopje, Macedonia, 2017. CEUR Workshop Proceedings Volume 1960,\n  2017', 'links': [{'href': 'http://arxiv.org/abs/1704.07506v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1704.07506v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
463,http://arxiv.org/abs/1704.04579v1,2017-04-15 04:47:25+00:00,2017-04-15 04:47:25+00:00,Evaluating Quality of Chatbots and Intelligent Conversational Agents,"[arxiv.Result.Author('Nicole M. Radziwill'), arxiv.Result.Author('Morgan C. Benton')]","Chatbots are one class of intelligent, conversational software agents
activated by natural language input (which can be in the form of text, voice,
or both). They provide conversational output in response, and if commanded, can
sometimes also execute tasks. Although chatbot technologies have existed since
the 1960s and have influenced user interface development in games since the
early 1980s, chatbots are now easier to train and implement. This is due to
plentiful open source code, widely available development platforms, and
implementation options via Software as a Service (SaaS). In addition to
enhancing customer experiences and supporting learning, chatbots can also be
used to engineer social harm - that is, to spread rumors and misinformation, or
attack people for posting their thoughts and opinions online. This paper
presents a literature review of quality issues and attributes as they relate to
the contemporary issue of chatbot development and implementation. Finally,
quality assessment approaches are reviewed, and a quality assessment method
based on these attributes and the Analytic Hierarchy Process (AHP) is proposed
and examined.","Software Quality Professional, June 2017",,,cs.CY,"['cs.CY', 'cs.SE']","[arxiv.Result.Link('http://arxiv.org/abs/1704.04579v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1704.04579v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1704.04579v1,"{'id': 'http://arxiv.org/abs/1704.04579v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1704.04579v1', 'updated': '2017-04-15T04:47:25Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=4, tm_mday=15, tm_hour=4, tm_min=47, tm_sec=25, tm_wday=5, tm_yday=105, tm_isdst=0), 'published': '2017-04-15T04:47:25Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=4, tm_mday=15, tm_hour=4, tm_min=47, tm_sec=25, tm_wday=5, tm_yday=105, tm_isdst=0), 'title': 'Evaluating Quality of Chatbots and Intelligent Conversational Agents', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Evaluating Quality of Chatbots and Intelligent Conversational Agents'}, 'summary': 'Chatbots are one class of intelligent, conversational software agents\nactivated by natural language input (which can be in the form of text, voice,\nor both). They provide conversational output in response, and if commanded, can\nsometimes also execute tasks. Although chatbot technologies have existed since\nthe 1960s and have influenced user interface development in games since the\nearly 1980s, chatbots are now easier to train and implement. This is due to\nplentiful open source code, widely available development platforms, and\nimplementation options via Software as a Service (SaaS). In addition to\nenhancing customer experiences and supporting learning, chatbots can also be\nused to engineer social harm - that is, to spread rumors and misinformation, or\nattack people for posting their thoughts and opinions online. This paper\npresents a literature review of quality issues and attributes as they relate to\nthe contemporary issue of chatbot development and implementation. Finally,\nquality assessment approaches are reviewed, and a quality assessment method\nbased on these attributes and the Analytic Hierarchy Process (AHP) is proposed\nand examined.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Chatbots are one class of intelligent, conversational software agents\nactivated by natural language input (which can be in the form of text, voice,\nor both). They provide conversational output in response, and if commanded, can\nsometimes also execute tasks. Although chatbot technologies have existed since\nthe 1960s and have influenced user interface development in games since the\nearly 1980s, chatbots are now easier to train and implement. This is due to\nplentiful open source code, widely available development platforms, and\nimplementation options via Software as a Service (SaaS). In addition to\nenhancing customer experiences and supporting learning, chatbots can also be\nused to engineer social harm - that is, to spread rumors and misinformation, or\nattack people for posting their thoughts and opinions online. This paper\npresents a literature review of quality issues and attributes as they relate to\nthe contemporary issue of chatbot development and implementation. Finally,\nquality assessment approaches are reviewed, and a quality assessment method\nbased on these attributes and the Analytic Hierarchy Process (AHP) is proposed\nand examined.'}, 'authors': [{'name': 'Nicole M. Radziwill'}, {'name': 'Morgan C. Benton'}], 'author_detail': {'name': 'Morgan C. Benton'}, 'author': 'Morgan C. Benton', 'arxiv_comment': 'Software Quality Professional, June 2017', 'links': [{'href': 'http://arxiv.org/abs/1704.04579v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1704.04579v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
464,http://arxiv.org/abs/1704.02406v2,2017-06-27 01:56:01+00:00,2017-04-08 00:12:10+00:00,Impact of misinformation in temporal network epidemiology,"[arxiv.Result.Author('Petter Holme'), arxiv.Result.Author('Luis E C Rocha')]","We investigate the impact of misinformation about the contact structure on
the ability to predict disease outbreaks. We base our study on 31 empirical
temporal networks and tune the frequencies in errors in the node identities or
timestamps of contacts. We find that for both these spreading scenarios, the
maximal misprediction of both the outbreak size and time to extinction follows
an stretched exponential convergence as a function of the error frequency. We
furthermore determine the temporal-network structural factors influencing the
parameters of this convergence.",,Net Sci 7 (2019) 52-69,10.1017/nws.2018.28,q-bio.PE,['q-bio.PE'],"[arxiv.Result.Link('http://dx.doi.org/10.1017/nws.2018.28', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1704.02406v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1704.02406v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1704.02406v2,"{'id': 'http://arxiv.org/abs/1704.02406v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1704.02406v2', 'updated': '2017-06-27T01:56:01Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=27, tm_hour=1, tm_min=56, tm_sec=1, tm_wday=1, tm_yday=178, tm_isdst=0), 'published': '2017-04-08T00:12:10Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=4, tm_mday=8, tm_hour=0, tm_min=12, tm_sec=10, tm_wday=5, tm_yday=98, tm_isdst=0), 'title': 'Impact of misinformation in temporal network epidemiology', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Impact of misinformation in temporal network epidemiology'}, 'summary': 'We investigate the impact of misinformation about the contact structure on\nthe ability to predict disease outbreaks. We base our study on 31 empirical\ntemporal networks and tune the frequencies in errors in the node identities or\ntimestamps of contacts. We find that for both these spreading scenarios, the\nmaximal misprediction of both the outbreak size and time to extinction follows\nan stretched exponential convergence as a function of the error frequency. We\nfurthermore determine the temporal-network structural factors influencing the\nparameters of this convergence.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'We investigate the impact of misinformation about the contact structure on\nthe ability to predict disease outbreaks. We base our study on 31 empirical\ntemporal networks and tune the frequencies in errors in the node identities or\ntimestamps of contacts. We find that for both these spreading scenarios, the\nmaximal misprediction of both the outbreak size and time to extinction follows\nan stretched exponential convergence as a function of the error frequency. We\nfurthermore determine the temporal-network structural factors influencing the\nparameters of this convergence.'}, 'authors': [{'name': 'Petter Holme'}, {'name': 'Luis E C Rocha'}], 'author_detail': {'name': 'Luis E C Rocha'}, 'author': 'Luis E C Rocha', 'arxiv_doi': '10.1017/nws.2018.28', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1017/nws.2018.28', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1704.02406v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1704.02406v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Net Sci 7 (2019) 52-69', 'arxiv_primary_category': {'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-bio.PE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
465,http://arxiv.org/abs/1703.06988v1,2017-03-20 22:19:22+00:00,2017-03-20 22:19:22+00:00,The Fake News Spreading Plague: Was it Preventable?,"[arxiv.Result.Author('Eni Mustafaraj'), arxiv.Result.Author('Panagiotis Takis Metaxas')]","In 2010, a paper entitled ""From Obscurity to Prominence in Minutes: Political
Speech and Real-time search"" won the Best Paper Prize of the Web Science 2010
Conference. Among its findings were the discovery and documentation of what was
termed a ""Twitter-bomb"", an organized effort to spread misinformation about the
democratic candidate Martha Coakley through anonymous Twitter accounts. In this
paper, after summarizing the details of that event, we outline the recipe of
how social networks are used to spread misinformation. One of the most
important steps in such a recipe is the ""infiltration"" of a community of users
who are already engaged in conversations about a topic, to use them as organic
spreaders of misinformation in their extended subnetworks. Then, we take this
misinformation spreading recipe and indicate how it was successfully used to
spread fake news during the 2016 U.S. Presidential Election. The main
differences between the scenarios are the use of Facebook instead of Twitter,
and the respective motivations (in 2010: political influence; in 2016:
financial benefit through online advertising). After situating these events in
the broader context of exploiting the Web, we seize this opportunity to address
limitations of the reach of research findings and to start a conversation about
how communities of researchers can increase their impact on real-world societal
issues.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1703.06988v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1703.06988v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1703.06988v1,"{'id': 'http://arxiv.org/abs/1703.06988v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1703.06988v1', 'updated': '2017-03-20T22:19:22Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=20, tm_hour=22, tm_min=19, tm_sec=22, tm_wday=0, tm_yday=79, tm_isdst=0), 'published': '2017-03-20T22:19:22Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=20, tm_hour=22, tm_min=19, tm_sec=22, tm_wday=0, tm_yday=79, tm_isdst=0), 'title': 'The Fake News Spreading Plague: Was it Preventable?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Fake News Spreading Plague: Was it Preventable?'}, 'summary': 'In 2010, a paper entitled ""From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search"" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a ""Twitter-bomb"", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the ""infiltration"" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'In 2010, a paper entitled ""From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search"" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a ""Twitter-bomb"", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the ""infiltration"" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.'}, 'authors': [{'name': 'Eni Mustafaraj'}, {'name': 'Panagiotis Takis Metaxas'}], 'author_detail': {'name': 'Panagiotis Takis Metaxas'}, 'author': 'Panagiotis Takis Metaxas', 'links': [{'href': 'http://arxiv.org/abs/1703.06988v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1703.06988v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
466,http://arxiv.org/abs/1703.06959v4,2017-09-03 22:05:42+00:00,2017-03-20 20:33:32+00:00,CSI: A Hybrid Deep Model for Fake News Detection,"[arxiv.Result.Author('Natali Ruchansky'), arxiv.Result.Author('Sungyong Seo'), arxiv.Result.Author('Yan Liu')]","The topic of fake news has drawn attention both from the public and the
academic communities. Such misinformation has the potential of affecting public
opinion, providing an opportunity for malicious parties to manipulate the
outcomes of public events such as elections. Because such high stakes are at
play, automatically detecting fake news is an important, yet challenging
problem that is not yet well understood. Nevertheless, there are three
generally agreed upon characteristics of fake news: the text of an article, the
user response it receives, and the source users promoting it. Existing work has
largely focused on tailoring solutions to one particular characteristic which
has limited their success and generality. In this work, we propose a model that
combines all three characteristics for a more accurate and automated
prediction. Specifically, we incorporate the behavior of both parties, users
and articles, and the group behavior of users who propagate fake news.
Motivated by the three characteristics, we propose a model called CSI which is
composed of three modules: Capture, Score, and Integrate. The first module is
based on the response and text; it uses a Recurrent Neural Network to capture
the temporal pattern of user activity on a given article. The second module
learns the source characteristic based on the behavior of users, and the two
are integrated with the third module to classify an article as fake or not.
Experimental analysis on real-world data demonstrates that CSI achieves higher
accuracy than existing models, and extracts meaningful latent representations
of both users and articles.","In Proceedings of the 26th ACM International Conference on
  Information and Knowledge Management (CIKM) 2017",,10.1145/3132847.3132877,cs.LG,"['cs.LG', 'cs.SI']","[arxiv.Result.Link('http://dx.doi.org/10.1145/3132847.3132877', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1703.06959v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1703.06959v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1703.06959v4,"{'id': 'http://arxiv.org/abs/1703.06959v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1703.06959v4', 'updated': '2017-09-03T22:05:42Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=9, tm_mday=3, tm_hour=22, tm_min=5, tm_sec=42, tm_wday=6, tm_yday=246, tm_isdst=0), 'published': '2017-03-20T20:33:32Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=3, tm_mday=20, tm_hour=20, tm_min=33, tm_sec=32, tm_wday=0, tm_yday=79, tm_isdst=0), 'title': 'CSI: A Hybrid Deep Model for Fake News Detection', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'CSI: A Hybrid Deep Model for Fake News Detection'}, 'summary': 'The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.'}, 'authors': [{'name': 'Natali Ruchansky'}, {'name': 'Sungyong Seo'}, {'name': 'Yan Liu'}], 'author_detail': {'name': 'Yan Liu'}, 'author': 'Yan Liu', 'arxiv_doi': '10.1145/3132847.3132877', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3132847.3132877', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1703.06959v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1703.06959v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'In Proceedings of the 26th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2017', 'arxiv_primary_category': {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
467,http://arxiv.org/abs/1702.06016v2,2017-06-16 10:14:10+00:00,2017-02-20 15:35:27+00:00,"Public discourse and news consumption on online social media: A quantitative, cross-platform analysis of the Italian Referendum","[arxiv.Result.Author('Michela Del Vicario'), arxiv.Result.Author('Sabrina Gaito'), arxiv.Result.Author('Walter Quattrociocchi'), arxiv.Result.Author('Matteo Zignani'), arxiv.Result.Author('Fabiana Zollo')]","The rising attention to the spreading of fake news and unsubstantiated rumors
on online social media and the pivotal role played by confirmation bias led
researchers to investigate different aspects of the phenomenon. Experimental
evidence showed that confirmatory information gets accepted even if containing
deliberately false claims while dissenting information is mainly ignored or
might even increase group polarization. It seems reasonable that, to address
misinformation problem properly, we have to understand the main determinants
behind content consumption and the emergence of narratives on online social
media. In this paper we address such a challenge by focusing on the discussion
around the Italian Constitutional Referendum by conducting a quantitative,
cross-platform analysis on both Facebook public pages and Twitter accounts. We
observe the spontaneous emergence of well-separated communities on both
platforms. Such a segregation is completely spontaneous, since no
categorization of contents was performed a priori. By exploring the dynamics
behind the discussion, we find that users tend to restrict their attention to a
specific set of Facebook pages/Twitter accounts. Finally, taking advantage of
automatic topic extraction and sentiment analysis techniques, we are able to
identify the most controversial topics inside and across both platforms. We
measure the distance between how a certain topic is presented in the
posts/tweets and the related emotional response of users. Our results provide
interesting insights for the understanding of the evolution of the core
narratives behind different echo chambers and for the early detection of
massive viral phenomena around false claims.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1702.06016v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1702.06016v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1702.06016v2,"{'id': 'http://arxiv.org/abs/1702.06016v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1702.06016v2', 'updated': '2017-06-16T10:14:10Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=6, tm_mday=16, tm_hour=10, tm_min=14, tm_sec=10, tm_wday=4, tm_yday=167, tm_isdst=0), 'published': '2017-02-20T15:35:27Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=35, tm_sec=27, tm_wday=0, tm_yday=51, tm_isdst=0), 'title': 'Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum'}, 'summary': 'The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.'}, 'authors': [{'name': 'Michela Del Vicario'}, {'name': 'Sabrina Gaito'}, {'name': 'Walter Quattrociocchi'}, {'name': 'Matteo Zignani'}, {'name': 'Fabiana Zollo'}], 'author_detail': {'name': 'Fabiana Zollo'}, 'author': 'Fabiana Zollo', 'links': [{'href': 'http://arxiv.org/abs/1702.06016v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1702.06016v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
468,http://arxiv.org/abs/1702.01591v2,2017-02-20 16:11:20+00:00,2017-02-06 12:28:27+00:00,The Partial Entropy Decomposition: Decomposing multivariate entropy and mutual information via pointwise common surprisal,[arxiv.Result.Author('Robin A. A. Ince')],"Obtaining meaningful quantitative descriptions of the statistical dependence
within multivariate systems is a difficult open problem. Recently, the Partial
Information Decomposition (PID) was proposed to decompose mutual information
(MI) about a target variable into components which are redundant, unique and
synergistic within different subsets of predictor variables. Here, we propose
to apply the elegant formalism of the PID to multivariate entropy, resulting in
a Partial Entropy Decomposition (PED). We implement the PED with an entropy
redundancy measure based on pointwise common surprisal; a natural definition
which is closely related to the definition of MI. We show how this approach can
reveal the dyadic vs triadic generative structure of multivariate systems that
are indistinguishable with classical Shannon measures. The entropy perspective
also shows that misinformation is synergistic entropy and hence that MI itself
includes both redundant and synergistic effects. We show the relationships
between the PED and MI in two predictors, and derive two alternative
information decompositions which we illustrate on several example systems. This
reveals that in entropy terms, univariate predictor MI is not a proper subset
of the joint MI, and we suggest this previously unrecognised fact explains in
part why obtaining a consistent PID has proven difficult. The PED also allows
separate quantification of mechanistic redundancy (related to the function of
the system) versus source redundancy (arising from dependencies between
inputs); an important distinction which no existing methods can address. The
new perspective provided by the PED helps to clarify some of the difficulties
encountered with the PID approach and the resulting decompositions provide
useful tools for practical data analysis across a wide range of application
areas.","Added Section 3.7 (Quantifying source vs mechanistic redundancy) and
  Section 3.8 (Shared entropy as a measure of dependence: pure mutual
  information) and updated abstract, results, and discussion accordingly",,,cs.IT,"['cs.IT', 'math.IT', 'math.ST', 'q-bio.NC', 'q-bio.QM', 'stat.ME', 'stat.TH']","[arxiv.Result.Link('http://arxiv.org/abs/1702.01591v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1702.01591v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1702.01591v2,"{'id': 'http://arxiv.org/abs/1702.01591v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1702.01591v2', 'updated': '2017-02-20T16:11:20Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=11, tm_sec=20, tm_wday=0, tm_yday=51, tm_isdst=0), 'published': '2017-02-06T12:28:27Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=2, tm_mday=6, tm_hour=12, tm_min=28, tm_sec=27, tm_wday=0, tm_yday=37, tm_isdst=0), 'title': 'The Partial Entropy Decomposition: Decomposing multivariate entropy and\n  mutual information via pointwise common surprisal', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The Partial Entropy Decomposition: Decomposing multivariate entropy and\n  mutual information via pointwise common surprisal'}, 'summary': 'Obtaining meaningful quantitative descriptions of the statistical dependence\nwithin multivariate systems is a difficult open problem. Recently, the Partial\nInformation Decomposition (PID) was proposed to decompose mutual information\n(MI) about a target variable into components which are redundant, unique and\nsynergistic within different subsets of predictor variables. Here, we propose\nto apply the elegant formalism of the PID to multivariate entropy, resulting in\na Partial Entropy Decomposition (PED). We implement the PED with an entropy\nredundancy measure based on pointwise common surprisal; a natural definition\nwhich is closely related to the definition of MI. We show how this approach can\nreveal the dyadic vs triadic generative structure of multivariate systems that\nare indistinguishable with classical Shannon measures. The entropy perspective\nalso shows that misinformation is synergistic entropy and hence that MI itself\nincludes both redundant and synergistic effects. We show the relationships\nbetween the PED and MI in two predictors, and derive two alternative\ninformation decompositions which we illustrate on several example systems. This\nreveals that in entropy terms, univariate predictor MI is not a proper subset\nof the joint MI, and we suggest this previously unrecognised fact explains in\npart why obtaining a consistent PID has proven difficult. The PED also allows\nseparate quantification of mechanistic redundancy (related to the function of\nthe system) versus source redundancy (arising from dependencies between\ninputs); an important distinction which no existing methods can address. The\nnew perspective provided by the PED helps to clarify some of the difficulties\nencountered with the PID approach and the resulting decompositions provide\nuseful tools for practical data analysis across a wide range of application\nareas.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Obtaining meaningful quantitative descriptions of the statistical dependence\nwithin multivariate systems is a difficult open problem. Recently, the Partial\nInformation Decomposition (PID) was proposed to decompose mutual information\n(MI) about a target variable into components which are redundant, unique and\nsynergistic within different subsets of predictor variables. Here, we propose\nto apply the elegant formalism of the PID to multivariate entropy, resulting in\na Partial Entropy Decomposition (PED). We implement the PED with an entropy\nredundancy measure based on pointwise common surprisal; a natural definition\nwhich is closely related to the definition of MI. We show how this approach can\nreveal the dyadic vs triadic generative structure of multivariate systems that\nare indistinguishable with classical Shannon measures. The entropy perspective\nalso shows that misinformation is synergistic entropy and hence that MI itself\nincludes both redundant and synergistic effects. We show the relationships\nbetween the PED and MI in two predictors, and derive two alternative\ninformation decompositions which we illustrate on several example systems. This\nreveals that in entropy terms, univariate predictor MI is not a proper subset\nof the joint MI, and we suggest this previously unrecognised fact explains in\npart why obtaining a consistent PID has proven difficult. The PED also allows\nseparate quantification of mechanistic redundancy (related to the function of\nthe system) versus source redundancy (arising from dependencies between\ninputs); an important distinction which no existing methods can address. The\nnew perspective provided by the PED helps to clarify some of the difficulties\nencountered with the PID approach and the resulting decompositions provide\nuseful tools for practical data analysis across a wide range of application\nareas.'}, 'authors': [{'name': 'Robin A. A. Ince'}], 'author_detail': {'name': 'Robin A. A. Ince'}, 'author': 'Robin A. A. Ince', 'arxiv_comment': 'Added Section 3.7 (Quantifying source vs mechanistic redundancy) and\n  Section 3.8 (Shared entropy as a measure of dependence: pure mutual\n  information) and updated abstract, results, and discussion accordingly', 'links': [{'href': 'http://arxiv.org/abs/1702.01591v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1702.01591v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.ST', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
469,http://arxiv.org/abs/1701.07490v1,2017-01-17 18:52:22+00:00,2017-01-17 18:52:22+00:00,"What Are People Tweeting about Zika? An Exploratory Study Concerning Symptoms, Treatment, Transmission, and Prevention","[arxiv.Result.Author('Michele Miller'), arxiv.Result.Author('Dr. Tanvi Banerjee'), arxiv.Result.Author('RoopTeja Muppalla'), arxiv.Result.Author('Dr. William Romine'), arxiv.Result.Author('Dr. Amit Sheth')]","The purpose of this study was to do a dataset distribution analysis, a
classification performance analysis, and a topical analysis concerning what
people are tweeting about four disease characteristics: symptoms, transmission,
prevention, and treatment. A combination of natural language processing and
machine learning techniques were used to determine what people are tweeting
about Zika. Specifically, a two-stage classifier system was built to find
relevant tweets on Zika, and then categorize these into the four disease
categories. Tweets in each disease category were then examined using latent
dirichlet allocation (LDA) to determine the five main tweet topics for each
disease characteristic. Results 1,234,605 tweets were collected. Tweets by
males and females were similar (28% and 23% respectively). The classifier
performed well on the training and test data for relevancy (F=0.87 and 0.99
respectively) and disease characteristics (F=0.79 and 0.90 respectively). Five
topics for each category were found and discussed with a focus on the symptoms
category. Through this process, we demonstrate how misinformation can be
discovered so that public health officials can respond to the tweets with
misinformation.",,,,cs.SI,"['cs.SI', 'q-bio.OT']","[arxiv.Result.Link('http://arxiv.org/abs/1701.07490v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1701.07490v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1701.07490v1,"{'id': 'http://arxiv.org/abs/1701.07490v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1701.07490v1', 'updated': '2017-01-17T18:52:22Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=1, tm_mday=17, tm_hour=18, tm_min=52, tm_sec=22, tm_wday=1, tm_yday=17, tm_isdst=0), 'published': '2017-01-17T18:52:22Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=1, tm_mday=17, tm_hour=18, tm_min=52, tm_sec=22, tm_wday=1, tm_yday=17, tm_isdst=0), 'title': 'What Are People Tweeting about Zika? An Exploratory Study Concerning\n  Symptoms, Treatment, Transmission, and Prevention', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'What Are People Tweeting about Zika? An Exploratory Study Concerning\n  Symptoms, Treatment, Transmission, and Prevention'}, 'summary': 'The purpose of this study was to do a dataset distribution analysis, a\nclassification performance analysis, and a topical analysis concerning what\npeople are tweeting about four disease characteristics: symptoms, transmission,\nprevention, and treatment. A combination of natural language processing and\nmachine learning techniques were used to determine what people are tweeting\nabout Zika. Specifically, a two-stage classifier system was built to find\nrelevant tweets on Zika, and then categorize these into the four disease\ncategories. Tweets in each disease category were then examined using latent\ndirichlet allocation (LDA) to determine the five main tweet topics for each\ndisease characteristic. Results 1,234,605 tweets were collected. Tweets by\nmales and females were similar (28% and 23% respectively). The classifier\nperformed well on the training and test data for relevancy (F=0.87 and 0.99\nrespectively) and disease characteristics (F=0.79 and 0.90 respectively). Five\ntopics for each category were found and discussed with a focus on the symptoms\ncategory. Through this process, we demonstrate how misinformation can be\ndiscovered so that public health officials can respond to the tweets with\nmisinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The purpose of this study was to do a dataset distribution analysis, a\nclassification performance analysis, and a topical analysis concerning what\npeople are tweeting about four disease characteristics: symptoms, transmission,\nprevention, and treatment. A combination of natural language processing and\nmachine learning techniques were used to determine what people are tweeting\nabout Zika. Specifically, a two-stage classifier system was built to find\nrelevant tweets on Zika, and then categorize these into the four disease\ncategories. Tweets in each disease category were then examined using latent\ndirichlet allocation (LDA) to determine the five main tweet topics for each\ndisease characteristic. Results 1,234,605 tweets were collected. Tweets by\nmales and females were similar (28% and 23% respectively). The classifier\nperformed well on the training and test data for relevancy (F=0.87 and 0.99\nrespectively) and disease characteristics (F=0.79 and 0.90 respectively). Five\ntopics for each category were found and discussed with a focus on the symptoms\ncategory. Through this process, we demonstrate how misinformation can be\ndiscovered so that public health officials can respond to the tweets with\nmisinformation.'}, 'authors': [{'name': 'Michele Miller'}, {'name': 'Dr. Tanvi Banerjee'}, {'name': 'RoopTeja Muppalla'}, {'name': 'Dr. William Romine'}, {'name': 'Dr. Amit Sheth'}], 'author_detail': {'name': 'Dr. Amit Sheth'}, 'author': 'Dr. Amit Sheth', 'links': [{'href': 'http://arxiv.org/abs/1701.07490v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1701.07490v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.OT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
470,http://arxiv.org/abs/1701.04221v1,2017-01-16 09:59:45+00:00,2017-01-16 09:59:45+00:00,It's Always April Fools' Day! On the Difficulty of Social Network Misinformation Classification via Propagation Features,"[arxiv.Result.Author('Mauro Conti'), arxiv.Result.Author('Daniele Lain'), arxiv.Result.Author('Riccardo Lazzeretti'), arxiv.Result.Author('Giulio Lovisotto'), arxiv.Result.Author('Walter Quattrociocchi')]","Given the huge impact that Online Social Networks (OSN) had in the way people
get informed and form their opinion, they became an attractive playground for
malicious entities that want to spread misinformation, and leverage their
effect. In fact, misinformation easily spreads on OSN and is a huge threat for
modern society, possibly influencing also the outcome of elections, or even
putting people's life at risk (e.g., spreading ""anti-vaccines"" misinformation).
Therefore, it is of paramount importance for our society to have some sort of
""validation"" on information spreading through OSN. The need for a wide-scale
validation would greatly benefit from automatic tools.
  In this paper, we show that it is difficult to carry out an automatic
classification of misinformation considering only structural properties of
content propagation cascades. We focus on structural properties, because they
would be inherently difficult to be manipulated, with the the aim of
circumventing classification systems. To support our claim, we carry out an
extensive evaluation on Facebook posts belonging to conspiracy theories (as
representative of misinformation), and scientific news (representative of
fact-checked content). Our findings show that conspiracy content actually
reverberates in a way which is hard to distinguish from the one scientific
content does: for the classification mechanisms we investigated, classification
F1-score never exceeds 0.65 during content propagation stages, and is still
less than 0.7 even after propagation is complete.","10 pages, 5 figures",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1701.04221v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1701.04221v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1701.04221v1,"{'id': 'http://arxiv.org/abs/1701.04221v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1701.04221v1', 'updated': '2017-01-16T09:59:45Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=1, tm_mday=16, tm_hour=9, tm_min=59, tm_sec=45, tm_wday=0, tm_yday=16, tm_isdst=0), 'published': '2017-01-16T09:59:45Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=1, tm_mday=16, tm_hour=9, tm_min=59, tm_sec=45, tm_wday=0, tm_yday=16, tm_isdst=0), 'title': ""It's Always April Fools' Day! On the Difficulty of Social Network\n  Misinformation Classification via Propagation Features"", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""It's Always April Fools' Day! On the Difficulty of Social Network\n  Misinformation Classification via Propagation Features""}, 'summary': 'Given the huge impact that Online Social Networks (OSN) had in the way people\nget informed and form their opinion, they became an attractive playground for\nmalicious entities that want to spread misinformation, and leverage their\neffect. In fact, misinformation easily spreads on OSN and is a huge threat for\nmodern society, possibly influencing also the outcome of elections, or even\nputting people\'s life at risk (e.g., spreading ""anti-vaccines"" misinformation).\nTherefore, it is of paramount importance for our society to have some sort of\n""validation"" on information spreading through OSN. The need for a wide-scale\nvalidation would greatly benefit from automatic tools.\n  In this paper, we show that it is difficult to carry out an automatic\nclassification of misinformation considering only structural properties of\ncontent propagation cascades. We focus on structural properties, because they\nwould be inherently difficult to be manipulated, with the the aim of\ncircumventing classification systems. To support our claim, we carry out an\nextensive evaluation on Facebook posts belonging to conspiracy theories (as\nrepresentative of misinformation), and scientific news (representative of\nfact-checked content). Our findings show that conspiracy content actually\nreverberates in a way which is hard to distinguish from the one scientific\ncontent does: for the classification mechanisms we investigated, classification\nF1-score never exceeds 0.65 during content propagation stages, and is still\nless than 0.7 even after propagation is complete.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Given the huge impact that Online Social Networks (OSN) had in the way people\nget informed and form their opinion, they became an attractive playground for\nmalicious entities that want to spread misinformation, and leverage their\neffect. In fact, misinformation easily spreads on OSN and is a huge threat for\nmodern society, possibly influencing also the outcome of elections, or even\nputting people\'s life at risk (e.g., spreading ""anti-vaccines"" misinformation).\nTherefore, it is of paramount importance for our society to have some sort of\n""validation"" on information spreading through OSN. The need for a wide-scale\nvalidation would greatly benefit from automatic tools.\n  In this paper, we show that it is difficult to carry out an automatic\nclassification of misinformation considering only structural properties of\ncontent propagation cascades. We focus on structural properties, because they\nwould be inherently difficult to be manipulated, with the the aim of\ncircumventing classification systems. To support our claim, we carry out an\nextensive evaluation on Facebook posts belonging to conspiracy theories (as\nrepresentative of misinformation), and scientific news (representative of\nfact-checked content). Our findings show that conspiracy content actually\nreverberates in a way which is hard to distinguish from the one scientific\ncontent does: for the classification mechanisms we investigated, classification\nF1-score never exceeds 0.65 during content propagation stages, and is still\nless than 0.7 even after propagation is complete.'}, 'authors': [{'name': 'Mauro Conti'}, {'name': 'Daniele Lain'}, {'name': 'Riccardo Lazzeretti'}, {'name': 'Giulio Lovisotto'}, {'name': 'Walter Quattrociocchi'}], 'author_detail': {'name': 'Walter Quattrociocchi'}, 'author': 'Walter Quattrociocchi', 'arxiv_comment': '10 pages, 5 figures', 'links': [{'href': 'http://arxiv.org/abs/1701.04221v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1701.04221v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
471,http://arxiv.org/abs/1701.02694v4,2019-01-10 18:03:21+00:00,2017-01-10 17:16:46+00:00,Limited individual attention and online virality of low-quality information,"[arxiv.Result.Author('Xiaoyan Qiu'), arxiv.Result.Author('Diego F. M. Oliveira'), arxiv.Result.Author('Alireza Sahami Shirazi'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Social media are massive marketplaces where ideas and news compete for our
attention. Previous studies have shown that quality is not a necessary
condition for online virality and that knowledge about peer choices can distort
the relationship between quality and popularity. However, these results do not
explain the viral spread of low-quality information, such as the digital
misinformation that threatens our democracy. We investigate quality
discrimination in a stylized model of online social network, where individual
agents prefer quality information, but have behavioral limitations in managing
a heavy flow of information. We measure the relationship between the quality of
an idea and its likelihood to become prevalent at the system level. We find
that both information overload and limited attention contribute to a
degradation in the market's discriminative power. A good tradeoff between
discriminative power and diversity of information is possible according to the
model. However, calibration with empirical data characterizing information load
and finite attention in real social media reveals a weak correlation between
quality and popularity of information. In these realistic conditions, the model
predicts that high-quality information has little advantage over low-quality
information.","The original paper was retracted (see
  http://doi.org/10.1038/s41562-017-0132). This is a corrected version of the
  preprint",,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1701.02694v4', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1701.02694v4', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1701.02694v4,"{'id': 'http://arxiv.org/abs/1701.02694v4', 'guidislink': True, 'link': 'http://arxiv.org/abs/1701.02694v4', 'updated': '2019-01-10T18:03:21Z', 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=1, tm_mday=10, tm_hour=18, tm_min=3, tm_sec=21, tm_wday=3, tm_yday=10, tm_isdst=0), 'published': '2017-01-10T17:16:46Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=1, tm_mday=10, tm_hour=17, tm_min=16, tm_sec=46, tm_wday=1, tm_yday=10, tm_isdst=0), 'title': 'Limited individual attention and online virality of low-quality\n  information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Limited individual attention and online virality of low-quality\n  information'}, 'summary': ""Social media are massive marketplaces where ideas and news compete for our\nattention. Previous studies have shown that quality is not a necessary\ncondition for online virality and that knowledge about peer choices can distort\nthe relationship between quality and popularity. However, these results do not\nexplain the viral spread of low-quality information, such as the digital\nmisinformation that threatens our democracy. We investigate quality\ndiscrimination in a stylized model of online social network, where individual\nagents prefer quality information, but have behavioral limitations in managing\na heavy flow of information. We measure the relationship between the quality of\nan idea and its likelihood to become prevalent at the system level. We find\nthat both information overload and limited attention contribute to a\ndegradation in the market's discriminative power. A good tradeoff between\ndiscriminative power and diversity of information is possible according to the\nmodel. However, calibration with empirical data characterizing information load\nand finite attention in real social media reveals a weak correlation between\nquality and popularity of information. In these realistic conditions, the model\npredicts that high-quality information has little advantage over low-quality\ninformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media are massive marketplaces where ideas and news compete for our\nattention. Previous studies have shown that quality is not a necessary\ncondition for online virality and that knowledge about peer choices can distort\nthe relationship between quality and popularity. However, these results do not\nexplain the viral spread of low-quality information, such as the digital\nmisinformation that threatens our democracy. We investigate quality\ndiscrimination in a stylized model of online social network, where individual\nagents prefer quality information, but have behavioral limitations in managing\na heavy flow of information. We measure the relationship between the quality of\nan idea and its likelihood to become prevalent at the system level. We find\nthat both information overload and limited attention contribute to a\ndegradation in the market's discriminative power. A good tradeoff between\ndiscriminative power and diversity of information is possible according to the\nmodel. However, calibration with empirical data characterizing information load\nand finite attention in real social media reveals a weak correlation between\nquality and popularity of information. In these realistic conditions, the model\npredicts that high-quality information has little advantage over low-quality\ninformation.""}, 'authors': [{'name': 'Xiaoyan Qiu'}, {'name': 'Diego F. M. Oliveira'}, {'name': 'Alireza Sahami Shirazi'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_comment': 'The original paper was retracted (see\n  http://doi.org/10.1038/s41562-017-0132). This is a corrected version of the\n  preprint', 'links': [{'href': 'http://arxiv.org/abs/1701.02694v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1701.02694v4', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
472,http://arxiv.org/abs/1701.02368v3,2017-11-08 19:22:57+00:00,2017-01-09 21:57:38+00:00,An Efficient Randomized Algorithm for Rumor Blocking in Online Social Networks,"[arxiv.Result.Author('Guangmo Tong'), arxiv.Result.Author('Weili Wu'), arxiv.Result.Author('Ling Guo'), arxiv.Result.Author('Deying Li'), arxiv.Result.Author('Cong Liu'), arxiv.Result.Author('Bin Liu'), arxiv.Result.Author('Ding-Zhu Du')]","Social networks allow rapid spread of ideas and innovations while the
negative information can also propagate widely. When the cascades with
different opinions reaching the same user, the cascade arriving first is the
most likely to be taken by the user. Therefore, once misinformation or rumor is
detected, a natural containment method is to introduce a positive cascade
competing against the rumor. Given a budget $k$, the rumor blocking problem
asks for $k$ seed users to trigger the spread of the positive cascade such that
the number of the users who are not influenced by rumor can be maximized. The
prior works have shown that the rumor blocking problem can be approximated
within a factor of $(1-1/e-\delta)$ by a classic greedy algorithm combined with
Monte Carlo simulation with the running time of $O(\frac{k^3mn\ln
n}{\delta^2})$, where $n$ and $m$ are the number of users and edges,
respectively. Unfortunately, the Monte-Carlo-simulation-based methods are
extremely time consuming and the existing algorithms either trade performance
guarantees for practical efficiency or vice versa. In this paper, we present a
randomized algorithm which runs in $O(\frac{km\ln n}{\delta^2})$ expected time
and provides a $(1-1/e-\delta)$-approximation with a high probability. The
experimentally results on both the real-world and synthetic social networks
have shown that the proposed randomized rumor blocking algorithm is much more
efficient than the state-of-the-art method and it is able to find the seed
nodes which are effective in limiting the spread of rumor.","This is the full version which fixes an error in the conference
  version",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1701.02368v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1701.02368v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1701.02368v3,"{'id': 'http://arxiv.org/abs/1701.02368v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1701.02368v3', 'updated': '2017-11-08T19:22:57Z', 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=8, tm_hour=19, tm_min=22, tm_sec=57, tm_wday=2, tm_yday=312, tm_isdst=0), 'published': '2017-01-09T21:57:38Z', 'published_parsed': time.struct_time(tm_year=2017, tm_mon=1, tm_mday=9, tm_hour=21, tm_min=57, tm_sec=38, tm_wday=0, tm_yday=9, tm_isdst=0), 'title': 'An Efficient Randomized Algorithm for Rumor Blocking in Online Social\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'An Efficient Randomized Algorithm for Rumor Blocking in Online Social\n  Networks'}, 'summary': 'Social networks allow rapid spread of ideas and innovations while the\nnegative information can also propagate widely. When the cascades with\ndifferent opinions reaching the same user, the cascade arriving first is the\nmost likely to be taken by the user. Therefore, once misinformation or rumor is\ndetected, a natural containment method is to introduce a positive cascade\ncompeting against the rumor. Given a budget $k$, the rumor blocking problem\nasks for $k$ seed users to trigger the spread of the positive cascade such that\nthe number of the users who are not influenced by rumor can be maximized. The\nprior works have shown that the rumor blocking problem can be approximated\nwithin a factor of $(1-1/e-\\delta)$ by a classic greedy algorithm combined with\nMonte Carlo simulation with the running time of $O(\\frac{k^3mn\\ln\nn}{\\delta^2})$, where $n$ and $m$ are the number of users and edges,\nrespectively. Unfortunately, the Monte-Carlo-simulation-based methods are\nextremely time consuming and the existing algorithms either trade performance\nguarantees for practical efficiency or vice versa. In this paper, we present a\nrandomized algorithm which runs in $O(\\frac{km\\ln n}{\\delta^2})$ expected time\nand provides a $(1-1/e-\\delta)$-approximation with a high probability. The\nexperimentally results on both the real-world and synthetic social networks\nhave shown that the proposed randomized rumor blocking algorithm is much more\nefficient than the state-of-the-art method and it is able to find the seed\nnodes which are effective in limiting the spread of rumor.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social networks allow rapid spread of ideas and innovations while the\nnegative information can also propagate widely. When the cascades with\ndifferent opinions reaching the same user, the cascade arriving first is the\nmost likely to be taken by the user. Therefore, once misinformation or rumor is\ndetected, a natural containment method is to introduce a positive cascade\ncompeting against the rumor. Given a budget $k$, the rumor blocking problem\nasks for $k$ seed users to trigger the spread of the positive cascade such that\nthe number of the users who are not influenced by rumor can be maximized. The\nprior works have shown that the rumor blocking problem can be approximated\nwithin a factor of $(1-1/e-\\delta)$ by a classic greedy algorithm combined with\nMonte Carlo simulation with the running time of $O(\\frac{k^3mn\\ln\nn}{\\delta^2})$, where $n$ and $m$ are the number of users and edges,\nrespectively. Unfortunately, the Monte-Carlo-simulation-based methods are\nextremely time consuming and the existing algorithms either trade performance\nguarantees for practical efficiency or vice versa. In this paper, we present a\nrandomized algorithm which runs in $O(\\frac{km\\ln n}{\\delta^2})$ expected time\nand provides a $(1-1/e-\\delta)$-approximation with a high probability. The\nexperimentally results on both the real-world and synthetic social networks\nhave shown that the proposed randomized rumor blocking algorithm is much more\nefficient than the state-of-the-art method and it is able to find the seed\nnodes which are effective in limiting the spread of rumor.'}, 'authors': [{'name': 'Guangmo Tong'}, {'name': 'Weili Wu'}, {'name': 'Ling Guo'}, {'name': 'Deying Li'}, {'name': 'Cong Liu'}, {'name': 'Bin Liu'}, {'name': 'Ding-Zhu Du'}], 'author_detail': {'name': 'Ding-Zhu Du'}, 'author': 'Ding-Zhu Du', 'arxiv_comment': 'This is the full version which fixes an error in the conference\n  version', 'links': [{'href': 'http://arxiv.org/abs/1701.02368v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1701.02368v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
473,http://arxiv.org/abs/1611.06314v1,2016-11-19 06:22:50+00:00,2016-11-19 06:22:50+00:00,Determining the Veracity of Rumours on Twitter,"[arxiv.Result.Author('Georgios Giasemidis'), arxiv.Result.Author('Colin Singleton'), arxiv.Result.Author('Ioannis Agrafiotis'), arxiv.Result.Author('Jason R. C. Nurse'), arxiv.Result.Author('Alan Pilgrim'), arxiv.Result.Author('Chris Willis'), arxiv.Result.Author('Danica Vukadinovic Greetham')]","While social networks can provide an ideal platform for up-to-date
information from individuals across the world, it has also proved to be a place
where rumours fester and accidental or deliberate misinformation often emerges.
In this article, we aim to support the task of making sense from social media
data, and specifically, seek to build an autonomous message-classifier that
filters relevant and trustworthy information from Twitter. For our work, we
collected about 100 million public tweets, including users' past tweets, from
which we identified 72 rumours (41 true, 31 false). We considered over 80
trustworthiness measures including the authors' profile and past behaviour, the
social network connections (graphs), and the content of tweets themselves. We
ran modern machine-learning classifiers over those measures to produce
trustworthiness scores at various time windows from the outbreak of the rumour.
Such time-windows were key as they allowed useful insight into the progression
of the rumours. From our findings, we identified that our model was
significantly more accurate than similar studies in the literature. We also
identified critical attributes of the data that give rise to the
trustworthiness scores assigned. Finally we developed a software demonstration
that provides a visual user interface to allow the user to examine the
analysis.","21 pages, 6 figures, 2 tables","SocInfo 2016, Part I, LNCS 10046, pp. 185-205, 2016",10.1007/978-3-319-47880-7_12,cs.SI,"['cs.SI', 'stat.ML']","[arxiv.Result.Link('http://dx.doi.org/10.1007/978-3-319-47880-7_12', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1611.06314v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1611.06314v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1611.06314v1,"{'id': 'http://arxiv.org/abs/1611.06314v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1611.06314v1', 'updated': '2016-11-19T06:22:50Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=11, tm_mday=19, tm_hour=6, tm_min=22, tm_sec=50, tm_wday=5, tm_yday=324, tm_isdst=0), 'published': '2016-11-19T06:22:50Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=11, tm_mday=19, tm_hour=6, tm_min=22, tm_sec=50, tm_wday=5, tm_yday=324, tm_isdst=0), 'title': 'Determining the Veracity of Rumours on Twitter', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Determining the Veracity of Rumours on Twitter'}, 'summary': ""While social networks can provide an ideal platform for up-to-date\ninformation from individuals across the world, it has also proved to be a place\nwhere rumours fester and accidental or deliberate misinformation often emerges.\nIn this article, we aim to support the task of making sense from social media\ndata, and specifically, seek to build an autonomous message-classifier that\nfilters relevant and trustworthy information from Twitter. For our work, we\ncollected about 100 million public tweets, including users' past tweets, from\nwhich we identified 72 rumours (41 true, 31 false). We considered over 80\ntrustworthiness measures including the authors' profile and past behaviour, the\nsocial network connections (graphs), and the content of tweets themselves. We\nran modern machine-learning classifiers over those measures to produce\ntrustworthiness scores at various time windows from the outbreak of the rumour.\nSuch time-windows were key as they allowed useful insight into the progression\nof the rumours. From our findings, we identified that our model was\nsignificantly more accurate than similar studies in the literature. We also\nidentified critical attributes of the data that give rise to the\ntrustworthiness scores assigned. Finally we developed a software demonstration\nthat provides a visual user interface to allow the user to examine the\nanalysis."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""While social networks can provide an ideal platform for up-to-date\ninformation from individuals across the world, it has also proved to be a place\nwhere rumours fester and accidental or deliberate misinformation often emerges.\nIn this article, we aim to support the task of making sense from social media\ndata, and specifically, seek to build an autonomous message-classifier that\nfilters relevant and trustworthy information from Twitter. For our work, we\ncollected about 100 million public tweets, including users' past tweets, from\nwhich we identified 72 rumours (41 true, 31 false). We considered over 80\ntrustworthiness measures including the authors' profile and past behaviour, the\nsocial network connections (graphs), and the content of tweets themselves. We\nran modern machine-learning classifiers over those measures to produce\ntrustworthiness scores at various time windows from the outbreak of the rumour.\nSuch time-windows were key as they allowed useful insight into the progression\nof the rumours. From our findings, we identified that our model was\nsignificantly more accurate than similar studies in the literature. We also\nidentified critical attributes of the data that give rise to the\ntrustworthiness scores assigned. Finally we developed a software demonstration\nthat provides a visual user interface to allow the user to examine the\nanalysis.""}, 'authors': [{'name': 'Georgios Giasemidis'}, {'name': 'Colin Singleton'}, {'name': 'Ioannis Agrafiotis'}, {'name': 'Jason R. C. Nurse'}, {'name': 'Alan Pilgrim'}, {'name': 'Chris Willis'}, {'name': 'Danica Vukadinovic Greetham'}], 'author_detail': {'name': 'Danica Vukadinovic Greetham'}, 'author': 'Danica Vukadinovic Greetham', 'arxiv_doi': '10.1007/978-3-319-47880-7_12', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-319-47880-7_12', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1611.06314v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1611.06314v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '21 pages, 6 figures, 2 tables', 'arxiv_journal_ref': 'SocInfo 2016, Part I, LNCS 10046, pp. 185-205, 2016', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
474,http://arxiv.org/abs/1610.07772v1,2016-10-25 07:56:43+00:00,2016-10-25 07:56:43+00:00,Visual Themes and Sentiment on Social Networks To Aid First Responders During Crisis Events,"[arxiv.Result.Author('Prateek Dewan'), arxiv.Result.Author('Varun Bharadhwaj'), arxiv.Result.Author('Aditi Mithal'), arxiv.Result.Author('Anshuman Suri'), arxiv.Result.Author('Ponnurangam Kumaraguru')]","Online Social Networks explode with activity whenever a crisis event takes
place. Most content generated as part of this activity is a mixture of text and
images, and is particularly useful for first responders to identify popular
topics of interest and gauge the pulse and sentiment of citizens. While
multiple researchers have used text to identify, analyze and measure themes and
public sentiment during such events, little work has explored visual themes
floating on networks in the form of images, and the sentiment inspired by them.
Given the potential of visual content for influencing users' thoughts and
emotions, we perform a large scale analysis to compare popular themes and
sentiment across images and textual content posted on Facebook during the
terror attacks that took place in Paris in 2015. Using state-of-the-art image
summarization techniques, we discovered multiple visual themes which were
popular in images, but were not identifiable through text. We uncovered
instances of misinformation and false flag (conspiracy) theories among popular
image themes, which were not prominent in user generated textual content, and
can be of particular inter- est to first responders. Our analysis also revealed
that while textual content posted after the attacks reflected negative
sentiment, images inspired positive sentiment. To the best of our knowledge,
this is the first large scale study of images posted on social networks during
a crisis event.",8+1 pages,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1610.07772v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1610.07772v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1610.07772v1,"{'id': 'http://arxiv.org/abs/1610.07772v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1610.07772v1', 'updated': '2016-10-25T07:56:43Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=10, tm_mday=25, tm_hour=7, tm_min=56, tm_sec=43, tm_wday=1, tm_yday=299, tm_isdst=0), 'published': '2016-10-25T07:56:43Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=10, tm_mday=25, tm_hour=7, tm_min=56, tm_sec=43, tm_wday=1, tm_yday=299, tm_isdst=0), 'title': 'Visual Themes and Sentiment on Social Networks To Aid First Responders\n  During Crisis Events', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Visual Themes and Sentiment on Social Networks To Aid First Responders\n  During Crisis Events'}, 'summary': ""Online Social Networks explode with activity whenever a crisis event takes\nplace. Most content generated as part of this activity is a mixture of text and\nimages, and is particularly useful for first responders to identify popular\ntopics of interest and gauge the pulse and sentiment of citizens. While\nmultiple researchers have used text to identify, analyze and measure themes and\npublic sentiment during such events, little work has explored visual themes\nfloating on networks in the form of images, and the sentiment inspired by them.\nGiven the potential of visual content for influencing users' thoughts and\nemotions, we perform a large scale analysis to compare popular themes and\nsentiment across images and textual content posted on Facebook during the\nterror attacks that took place in Paris in 2015. Using state-of-the-art image\nsummarization techniques, we discovered multiple visual themes which were\npopular in images, but were not identifiable through text. We uncovered\ninstances of misinformation and false flag (conspiracy) theories among popular\nimage themes, which were not prominent in user generated textual content, and\ncan be of particular inter- est to first responders. Our analysis also revealed\nthat while textual content posted after the attacks reflected negative\nsentiment, images inspired positive sentiment. To the best of our knowledge,\nthis is the first large scale study of images posted on social networks during\na crisis event."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Online Social Networks explode with activity whenever a crisis event takes\nplace. Most content generated as part of this activity is a mixture of text and\nimages, and is particularly useful for first responders to identify popular\ntopics of interest and gauge the pulse and sentiment of citizens. While\nmultiple researchers have used text to identify, analyze and measure themes and\npublic sentiment during such events, little work has explored visual themes\nfloating on networks in the form of images, and the sentiment inspired by them.\nGiven the potential of visual content for influencing users' thoughts and\nemotions, we perform a large scale analysis to compare popular themes and\nsentiment across images and textual content posted on Facebook during the\nterror attacks that took place in Paris in 2015. Using state-of-the-art image\nsummarization techniques, we discovered multiple visual themes which were\npopular in images, but were not identifiable through text. We uncovered\ninstances of misinformation and false flag (conspiracy) theories among popular\nimage themes, which were not prominent in user generated textual content, and\ncan be of particular inter- est to first responders. Our analysis also revealed\nthat while textual content posted after the attacks reflected negative\nsentiment, images inspired positive sentiment. To the best of our knowledge,\nthis is the first large scale study of images posted on social networks during\na crisis event.""}, 'authors': [{'name': 'Prateek Dewan'}, {'name': 'Varun Bharadhwaj'}, {'name': 'Aditi Mithal'}, {'name': 'Anshuman Suri'}, {'name': 'Ponnurangam Kumaraguru'}], 'author_detail': {'name': 'Ponnurangam Kumaraguru'}, 'author': 'Ponnurangam Kumaraguru', 'arxiv_comment': '8+1 pages', 'links': [{'href': 'http://arxiv.org/abs/1610.07772v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1610.07772v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
475,http://arxiv.org/abs/1610.04170v2,2018-01-17 17:44:51+00:00,2016-10-13 16:48:45+00:00,Network segregation in a model of misinformation and fact checking,"[arxiv.Result.Author('Marcella Tambuscio'), arxiv.Result.Author('Diego F. M. Oliveira'), arxiv.Result.Author('Giovanni Luca Ciampaglia'), arxiv.Result.Author('Giancarlo Ruffo')]","Misinformation under the form of rumor, hoaxes, and conspiracy theories
spreads on social media at alarming rates. One hypothesis is that, since social
media are shaped by homophily, belief in misinformation may be more likely to
thrive on those social circles that are segregated from the rest of the
network. One possible antidote is fact checking which, in some cases, is known
to stop rumors from spreading further. However, fact checking may also backfire
and reinforce the belief in a hoax. Here we take into account the combination
of network segregation, finite memory and attention, and fact-checking efforts.
We consider a compartmental model of two interacting epidemic processes over a
network that is segregated between gullible and skeptic users. Extensive
simulation and mean-field analysis show that a more segregated network
facilitates the spread of a hoax only at low forgetting rates, but has no
effect when agents forget at faster rates. This finding may inform the
development of mitigation techniques and overall inform on the risks of
uncontrolled misinformation online.",,J Comput Soc Sc (2018) 1: 261,10.1007/s42001-018-0018-9,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1007/s42001-018-0018-9', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1610.04170v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1610.04170v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1610.04170v2,"{'id': 'http://arxiv.org/abs/1610.04170v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1610.04170v2', 'updated': '2018-01-17T17:44:51Z', 'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=17, tm_hour=17, tm_min=44, tm_sec=51, tm_wday=2, tm_yday=17, tm_isdst=0), 'published': '2016-10-13T16:48:45Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=10, tm_mday=13, tm_hour=16, tm_min=48, tm_sec=45, tm_wday=3, tm_yday=287, tm_isdst=0), 'title': 'Network segregation in a model of misinformation and fact checking', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Network segregation in a model of misinformation and fact checking'}, 'summary': 'Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.'}, 'authors': [{'name': 'Marcella Tambuscio'}, {'name': 'Diego F. M. Oliveira'}, {'name': 'Giovanni Luca Ciampaglia'}, {'name': 'Giancarlo Ruffo'}], 'author_detail': {'name': 'Giancarlo Ruffo'}, 'author': 'Giancarlo Ruffo', 'arxiv_doi': '10.1007/s42001-018-0018-9', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s42001-018-0018-9', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1610.04170v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1610.04170v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'J Comput Soc Sc (2018) 1: 261', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
476,http://arxiv.org/abs/1609.09435v1,2016-09-29 17:31:44+00:00,2016-09-29 17:31:44+00:00,On the statistical properties of viral misinformation in online social media,[arxiv.Result.Author('Alessandro Bessi')],"The massive diffusion of online social media allows for the rapid and
uncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,
and false news. Such an impressive amount of misinformation can influence
policy preferences and encourage behaviors strongly divergent from recommended
practices. In this paper, we study the statistical properties of viral
misinformation in online social media. By means of methods belonging to Extreme
Value Theory, we show that the number of extremely viral posts over time
follows a homogeneous Poisson process, and that the interarrival times between
such posts are independent and identically distributed, following an
exponential distribution. Moreover, we characterize the uncertainty around the
rate parameter of the Poisson process through Bayesian methods. Finally, we are
able to derive the predictive posterior probability distribution of the number
of posts exceeding a certain threshold of shares over a finite interval of
time.",,,10.1016/j.physa.2016.11.012,cs.SI,"['cs.SI', 'physics.soc-ph', 'stat.AP']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.physa.2016.11.012', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1609.09435v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1609.09435v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1609.09435v1,"{'id': 'http://arxiv.org/abs/1609.09435v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1609.09435v1', 'updated': '2016-09-29T17:31:44Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=9, tm_mday=29, tm_hour=17, tm_min=31, tm_sec=44, tm_wday=3, tm_yday=273, tm_isdst=0), 'published': '2016-09-29T17:31:44Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=9, tm_mday=29, tm_hour=17, tm_min=31, tm_sec=44, tm_wday=3, tm_yday=273, tm_isdst=0), 'title': 'On the statistical properties of viral misinformation in online social\n  media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'On the statistical properties of viral misinformation in online social\n  media'}, 'summary': 'The massive diffusion of online social media allows for the rapid and\nuncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,\nand false news. Such an impressive amount of misinformation can influence\npolicy preferences and encourage behaviors strongly divergent from recommended\npractices. In this paper, we study the statistical properties of viral\nmisinformation in online social media. By means of methods belonging to Extreme\nValue Theory, we show that the number of extremely viral posts over time\nfollows a homogeneous Poisson process, and that the interarrival times between\nsuch posts are independent and identically distributed, following an\nexponential distribution. Moreover, we characterize the uncertainty around the\nrate parameter of the Poisson process through Bayesian methods. Finally, we are\nable to derive the predictive posterior probability distribution of the number\nof posts exceeding a certain threshold of shares over a finite interval of\ntime.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The massive diffusion of online social media allows for the rapid and\nuncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,\nand false news. Such an impressive amount of misinformation can influence\npolicy preferences and encourage behaviors strongly divergent from recommended\npractices. In this paper, we study the statistical properties of viral\nmisinformation in online social media. By means of methods belonging to Extreme\nValue Theory, we show that the number of extremely viral posts over time\nfollows a homogeneous Poisson process, and that the interarrival times between\nsuch posts are independent and identically distributed, following an\nexponential distribution. Moreover, we characterize the uncertainty around the\nrate parameter of the Poisson process through Bayesian methods. Finally, we are\nable to derive the predictive posterior probability distribution of the number\nof posts exceeding a certain threshold of shares over a finite interval of\ntime.'}, 'authors': [{'name': 'Alessandro Bessi'}], 'author_detail': {'name': 'Alessandro Bessi'}, 'author': 'Alessandro Bessi', 'arxiv_doi': '10.1016/j.physa.2016.11.012', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.physa.2016.11.012', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1609.09435v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1609.09435v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
477,http://arxiv.org/abs/1606.04721v1,2016-06-15 11:08:24+00:00,2016-06-15 11:08:24+00:00,Personality Traits and Echo Chambers on Facebook,[arxiv.Result.Author('Alessandro Bessi')],"In online social networks, users tend to select information that adhere to
their system of beliefs and to form polarized groups of like minded people.
Polarization as well as its effects on online social interactions have been
extensively investigated. Still, the relation between group formation and
personality traits remains unclear. A better understanding of the cognitive and
psychological determinants of online social dynamics might help to design more
efficient communication strategies and to challenge the digital misinformation
threat. In this work, we focus on users commenting posts published by US
Facebook pages supporting scientific and conspiracy-like narratives, and we
classify the personality traits of those users according to their online
behavior. We show that different and conflicting communities are populated by
users showing similar psychological profiles, and that the dominant personality
model is the same in both scientific and conspiracy echo chambers. Moreover, we
observe that the permanence within echo chambers slightly shapes users'
psychological profiles. Our results suggest that the presence of specific
personality traits in individuals lead to their considerable involvement in
supporting narratives inside virtual echo chambers.",,,,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY', 'cs.HC']","[arxiv.Result.Link('http://arxiv.org/abs/1606.04721v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1606.04721v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1606.04721v1,"{'id': 'http://arxiv.org/abs/1606.04721v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1606.04721v1', 'updated': '2016-06-15T11:08:24Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=6, tm_mday=15, tm_hour=11, tm_min=8, tm_sec=24, tm_wday=2, tm_yday=167, tm_isdst=0), 'published': '2016-06-15T11:08:24Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=6, tm_mday=15, tm_hour=11, tm_min=8, tm_sec=24, tm_wday=2, tm_yday=167, tm_isdst=0), 'title': 'Personality Traits and Echo Chambers on Facebook', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Personality Traits and Echo Chambers on Facebook'}, 'summary': ""In online social networks, users tend to select information that adhere to\ntheir system of beliefs and to form polarized groups of like minded people.\nPolarization as well as its effects on online social interactions have been\nextensively investigated. Still, the relation between group formation and\npersonality traits remains unclear. A better understanding of the cognitive and\npsychological determinants of online social dynamics might help to design more\nefficient communication strategies and to challenge the digital misinformation\nthreat. In this work, we focus on users commenting posts published by US\nFacebook pages supporting scientific and conspiracy-like narratives, and we\nclassify the personality traits of those users according to their online\nbehavior. We show that different and conflicting communities are populated by\nusers showing similar psychological profiles, and that the dominant personality\nmodel is the same in both scientific and conspiracy echo chambers. Moreover, we\nobserve that the permanence within echo chambers slightly shapes users'\npsychological profiles. Our results suggest that the presence of specific\npersonality traits in individuals lead to their considerable involvement in\nsupporting narratives inside virtual echo chambers."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""In online social networks, users tend to select information that adhere to\ntheir system of beliefs and to form polarized groups of like minded people.\nPolarization as well as its effects on online social interactions have been\nextensively investigated. Still, the relation between group formation and\npersonality traits remains unclear. A better understanding of the cognitive and\npsychological determinants of online social dynamics might help to design more\nefficient communication strategies and to challenge the digital misinformation\nthreat. In this work, we focus on users commenting posts published by US\nFacebook pages supporting scientific and conspiracy-like narratives, and we\nclassify the personality traits of those users according to their online\nbehavior. We show that different and conflicting communities are populated by\nusers showing similar psychological profiles, and that the dominant personality\nmodel is the same in both scientific and conspiracy echo chambers. Moreover, we\nobserve that the permanence within echo chambers slightly shapes users'\npsychological profiles. Our results suggest that the presence of specific\npersonality traits in individuals lead to their considerable involvement in\nsupporting narratives inside virtual echo chambers.""}, 'authors': [{'name': 'Alessandro Bessi'}], 'author_detail': {'name': 'Alessandro Bessi'}, 'author': 'Alessandro Bessi', 'links': [{'href': 'http://arxiv.org/abs/1606.04721v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1606.04721v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
478,http://arxiv.org/abs/1603.01511v1,2016-03-04 15:59:06+00:00,2016-03-04 15:59:06+00:00,Hoaxy: A Platform for Tracking Online Misinformation,"[arxiv.Result.Author('Chengcheng Shao'), arxiv.Result.Author('Giovanni Luca Ciampaglia'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Massive amounts of misinformation have been observed to spread in
uncontrolled fashion across social media. Examples include rumors, hoaxes, fake
news, and conspiracy theories. At the same time, several journalistic
organizations devote significant efforts to high-quality fact checking of
online claims. The resulting information cascades contain instances of both
accurate and inaccurate information, unfold over multiple time scales, and
often reach audiences of considerable size. All these factors pose challenges
for the study of the social dynamics of online news sharing. Here we introduce
Hoaxy, a platform for the collection, detection, and analysis of online
misinformation and its related fact-checking efforts. We discuss the design of
the platform and present a preliminary analysis of a sample of public tweets
containing both fake news and fact checking. We find that, in the aggregate,
the sharing of fact-checking content typically lags that of misinformation by
10--20 hours. Moreover, fake news are dominated by very active users, while
fact checking is a more grass-roots activity. With the increasing risks
connected to massive online misinformation, social news observatories have the
potential to help researchers, journalists, and the general public understand
the dynamics of real and fake news sharing.","6 pages, 6 figures, submitted to Third Workshop on Social News On the
  Web",,10.1145/2872518.2890098,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1145/2872518.2890098', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1603.01511v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1603.01511v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1603.01511v1,"{'id': 'http://arxiv.org/abs/1603.01511v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1603.01511v1', 'updated': '2016-03-04T15:59:06Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=3, tm_mday=4, tm_hour=15, tm_min=59, tm_sec=6, tm_wday=4, tm_yday=64, tm_isdst=0), 'published': '2016-03-04T15:59:06Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=3, tm_mday=4, tm_hour=15, tm_min=59, tm_sec=6, tm_wday=4, tm_yday=64, tm_isdst=0), 'title': 'Hoaxy: A Platform for Tracking Online Misinformation', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Hoaxy: A Platform for Tracking Online Misinformation'}, 'summary': 'Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.'}, 'authors': [{'name': 'Chengcheng Shao'}, {'name': 'Giovanni Luca Ciampaglia'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1145/2872518.2890098', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/2872518.2890098', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1603.01511v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1603.01511v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '6 pages, 6 figures, submitted to Third Workshop on Social News On the\n  Web', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
479,http://arxiv.org/abs/1602.00975v1,2016-02-02 15:29:42+00:00,2016-02-02 15:29:42+00:00,BotOrNot: A System to Evaluate Social Bots,"[arxiv.Result.Author('Clayton A. Davis'), arxiv.Result.Author('Onur Varol'), arxiv.Result.Author('Emilio Ferrara'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","While most online social media accounts are controlled by humans, these
platforms also host automated agents called social bots or sybil accounts.
Recent literature reported on cases of social bots imitating humans to
manipulate discussions, alter the popularity of users, pollute content and
spread misinformation, and even perform terrorist propaganda and recruitment
actions. Here we present BotOrNot, a publicly-available service that leverages
more than one thousand features to evaluate the extent to which a Twitter
account exhibits similarity to the known characteristics of social bots. Since
its release in May 2014, BotOrNot has served over one million requests via our
website and APIs.","2 pages, 2 figures, WWW Developers Day","Proceedings of the 25th International Conference Companion on
  World Wide Web (pp. 273-274). 2016",10.1145/2872518.2889302,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://dx.doi.org/10.1145/2872518.2889302', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1602.00975v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1602.00975v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1602.00975v1,"{'id': 'http://arxiv.org/abs/1602.00975v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1602.00975v1', 'updated': '2016-02-02T15:29:42Z', 'updated_parsed': time.struct_time(tm_year=2016, tm_mon=2, tm_mday=2, tm_hour=15, tm_min=29, tm_sec=42, tm_wday=1, tm_yday=33, tm_isdst=0), 'published': '2016-02-02T15:29:42Z', 'published_parsed': time.struct_time(tm_year=2016, tm_mon=2, tm_mday=2, tm_hour=15, tm_min=29, tm_sec=42, tm_wday=1, tm_yday=33, tm_isdst=0), 'title': 'BotOrNot: A System to Evaluate Social Bots', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'BotOrNot: A System to Evaluate Social Bots'}, 'summary': 'While most online social media accounts are controlled by humans, these\nplatforms also host automated agents called social bots or sybil accounts.\nRecent literature reported on cases of social bots imitating humans to\nmanipulate discussions, alter the popularity of users, pollute content and\nspread misinformation, and even perform terrorist propaganda and recruitment\nactions. Here we present BotOrNot, a publicly-available service that leverages\nmore than one thousand features to evaluate the extent to which a Twitter\naccount exhibits similarity to the known characteristics of social bots. Since\nits release in May 2014, BotOrNot has served over one million requests via our\nwebsite and APIs.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'While most online social media accounts are controlled by humans, these\nplatforms also host automated agents called social bots or sybil accounts.\nRecent literature reported on cases of social bots imitating humans to\nmanipulate discussions, alter the popularity of users, pollute content and\nspread misinformation, and even perform terrorist propaganda and recruitment\nactions. Here we present BotOrNot, a publicly-available service that leverages\nmore than one thousand features to evaluate the extent to which a Twitter\naccount exhibits similarity to the known characteristics of social bots. Since\nits release in May 2014, BotOrNot has served over one million requests via our\nwebsite and APIs.'}, 'authors': [{'name': 'Clayton A. Davis'}, {'name': 'Onur Varol'}, {'name': 'Emilio Ferrara'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1145/2872518.2889302', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/2872518.2889302', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1602.00975v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1602.00975v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '2 pages, 2 figures, WWW Developers Day', 'arxiv_journal_ref': 'Proceedings of the 25th International Conference Companion on\n  World Wide Web (pp. 273-274). 2016', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
480,http://arxiv.org/abs/1512.00770v2,2020-02-26 15:11:48+00:00,2015-12-02 16:43:40+00:00,Bayesian Social Influence in the Online Realm,"[arxiv.Result.Author('Przemyslaw A. Grabowicz'), arxiv.Result.Author('Francisco Romero-Ferrero'), arxiv.Result.Author('Theo Lins'), arxiv.Result.Author('Fabrício Benevenuto'), arxiv.Result.Author('Krishna P. Gummadi'), arxiv.Result.Author('Gonzalo G. de Polavieja')]","Our opinions, which things we like or dislike, depend on the opinions of
those around us. Nowadays, we are influenced by the opinions of online
strangers, expressed in comments and ratings on online platforms. Here, we
perform novel ""academic A/B testing"" experiments with over 2,500 participants
to measure the extent of that influence. In our experiments, the participants
watch and evaluate videos on mirror proxies of YouTube and Vimeo. We control
the comments and ratings that are shown underneath each of these videos. Our
study shows that from 5$\%$ up to 40$\%$ of subjects adopt the majority opinion
of strangers expressed in the comments. Using Bayes' theorem, we derive a
flexible and interpretable family of models of social influence, in which each
individual forms posterior opinions stochastically following a logit model. The
variants of our mixture model that maximize Akaike information criterion
represent two sub-populations, i.e., non-influenceable and influenceable
individuals. The prior opinions of the non-influenceable individuals are
strongly correlated with the external opinions and have low standard error,
whereas the prior opinions of influenceable individuals have high standard
error and become correlated with the external opinions due to social influence.
Our findings suggest that opinions are random variables updated via Bayes' rule
whose standard deviation is correlated with opinion influenceability. Based on
these findings, we discuss how to hinder opinion manipulation and
misinformation diffusion in the online realm.","15 pages, 22 figures",,,physics.soc-ph,"['physics.soc-ph', 'cs.CY', 'cs.SI', 'physics.data-an', 'H.1.2; I.2.11; J.4']","[arxiv.Result.Link('http://arxiv.org/abs/1512.00770v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1512.00770v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1512.00770v2,"{'id': 'http://arxiv.org/abs/1512.00770v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1512.00770v2', 'updated': '2020-02-26T15:11:48Z', 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=26, tm_hour=15, tm_min=11, tm_sec=48, tm_wday=2, tm_yday=57, tm_isdst=0), 'published': '2015-12-02T16:43:40Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=12, tm_mday=2, tm_hour=16, tm_min=43, tm_sec=40, tm_wday=2, tm_yday=336, tm_isdst=0), 'title': 'Bayesian Social Influence in the Online Realm', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Bayesian Social Influence in the Online Realm'}, 'summary': 'Our opinions, which things we like or dislike, depend on the opinions of\nthose around us. Nowadays, we are influenced by the opinions of online\nstrangers, expressed in comments and ratings on online platforms. Here, we\nperform novel ""academic A/B testing"" experiments with over 2,500 participants\nto measure the extent of that influence. In our experiments, the participants\nwatch and evaluate videos on mirror proxies of YouTube and Vimeo. We control\nthe comments and ratings that are shown underneath each of these videos. Our\nstudy shows that from 5$\\%$ up to 40$\\%$ of subjects adopt the majority opinion\nof strangers expressed in the comments. Using Bayes\' theorem, we derive a\nflexible and interpretable family of models of social influence, in which each\nindividual forms posterior opinions stochastically following a logit model. The\nvariants of our mixture model that maximize Akaike information criterion\nrepresent two sub-populations, i.e., non-influenceable and influenceable\nindividuals. The prior opinions of the non-influenceable individuals are\nstrongly correlated with the external opinions and have low standard error,\nwhereas the prior opinions of influenceable individuals have high standard\nerror and become correlated with the external opinions due to social influence.\nOur findings suggest that opinions are random variables updated via Bayes\' rule\nwhose standard deviation is correlated with opinion influenceability. Based on\nthese findings, we discuss how to hinder opinion manipulation and\nmisinformation diffusion in the online realm.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Our opinions, which things we like or dislike, depend on the opinions of\nthose around us. Nowadays, we are influenced by the opinions of online\nstrangers, expressed in comments and ratings on online platforms. Here, we\nperform novel ""academic A/B testing"" experiments with over 2,500 participants\nto measure the extent of that influence. In our experiments, the participants\nwatch and evaluate videos on mirror proxies of YouTube and Vimeo. We control\nthe comments and ratings that are shown underneath each of these videos. Our\nstudy shows that from 5$\\%$ up to 40$\\%$ of subjects adopt the majority opinion\nof strangers expressed in the comments. Using Bayes\' theorem, we derive a\nflexible and interpretable family of models of social influence, in which each\nindividual forms posterior opinions stochastically following a logit model. The\nvariants of our mixture model that maximize Akaike information criterion\nrepresent two sub-populations, i.e., non-influenceable and influenceable\nindividuals. The prior opinions of the non-influenceable individuals are\nstrongly correlated with the external opinions and have low standard error,\nwhereas the prior opinions of influenceable individuals have high standard\nerror and become correlated with the external opinions due to social influence.\nOur findings suggest that opinions are random variables updated via Bayes\' rule\nwhose standard deviation is correlated with opinion influenceability. Based on\nthese findings, we discuss how to hinder opinion manipulation and\nmisinformation diffusion in the online realm.'}, 'authors': [{'name': 'Przemyslaw A. Grabowicz'}, {'name': 'Francisco Romero-Ferrero'}, {'name': 'Theo Lins'}, {'name': 'Fabrício Benevenuto'}, {'name': 'Krishna P. Gummadi'}, {'name': 'Gonzalo G. de Polavieja'}], 'author_detail': {'name': 'Gonzalo G. de Polavieja'}, 'author': 'Gonzalo G. de Polavieja', 'arxiv_comment': '15 pages, 22 figures', 'links': [{'href': 'http://arxiv.org/abs/1512.00770v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1512.00770v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.1.2; I.2.11; J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
481,http://arxiv.org/abs/1508.02079v1,2015-08-09 20:14:09+00:00,2015-08-09 20:14:09+00:00,Facts and Fabrications about Ebola: A Twitter Based Study,"[arxiv.Result.Author('Janani Kalyanam'), arxiv.Result.Author('Sumithra Velupillai'), arxiv.Result.Author('Son Doan'), arxiv.Result.Author('Mike Conway'), arxiv.Result.Author('Gert Lanckriet')]","Microblogging websites like Twitter have been shown to be immensely useful
for spreading information on a global scale within seconds. The detrimental
effect, however, of such platforms is that misinformation and rumors are also
as likely to spread on the network as credible, verified information. From a
public health standpoint, the spread of misinformation creates unnecessary
panic for the public. We recently witnessed several such scenarios during the
outbreak of Ebola in 2014 [14, 1]. In order to effectively counter the medical
misinformation in a timely manner, our goal here is to study the nature of such
misinformation and rumors in the United States during fall 2014 when a handful
of Ebola cases were confirmed in North America. It is a well known convention
on Twitter to use hashtags to give context to a Twitter message (a tweet). In
this study, we collected approximately 47M tweets from the Twitter streaming
API related to Ebola. Based on hashtags, we propose a method to classify the
tweets into two sets: credible and speculative. We analyze these two sets and
study how they differ in terms of a number of features extracted from the
Twitter API. In conclusion, we infer several interesting differences between
the two sets. We outline further potential directions to using this material
for monitoring and separating speculative tweets from credible ones, to enable
improved public health information.",Appears in SIGKDD BigCHat Workshop 2015,,,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://arxiv.org/abs/1508.02079v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1508.02079v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1508.02079v1,"{'id': 'http://arxiv.org/abs/1508.02079v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1508.02079v1', 'updated': '2015-08-09T20:14:09Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=8, tm_mday=9, tm_hour=20, tm_min=14, tm_sec=9, tm_wday=6, tm_yday=221, tm_isdst=0), 'published': '2015-08-09T20:14:09Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=8, tm_mday=9, tm_hour=20, tm_min=14, tm_sec=9, tm_wday=6, tm_yday=221, tm_isdst=0), 'title': 'Facts and Fabrications about Ebola: A Twitter Based Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Facts and Fabrications about Ebola: A Twitter Based Study'}, 'summary': 'Microblogging websites like Twitter have been shown to be immensely useful\nfor spreading information on a global scale within seconds. The detrimental\neffect, however, of such platforms is that misinformation and rumors are also\nas likely to spread on the network as credible, verified information. From a\npublic health standpoint, the spread of misinformation creates unnecessary\npanic for the public. We recently witnessed several such scenarios during the\noutbreak of Ebola in 2014 [14, 1]. In order to effectively counter the medical\nmisinformation in a timely manner, our goal here is to study the nature of such\nmisinformation and rumors in the United States during fall 2014 when a handful\nof Ebola cases were confirmed in North America. It is a well known convention\non Twitter to use hashtags to give context to a Twitter message (a tweet). In\nthis study, we collected approximately 47M tweets from the Twitter streaming\nAPI related to Ebola. Based on hashtags, we propose a method to classify the\ntweets into two sets: credible and speculative. We analyze these two sets and\nstudy how they differ in terms of a number of features extracted from the\nTwitter API. In conclusion, we infer several interesting differences between\nthe two sets. We outline further potential directions to using this material\nfor monitoring and separating speculative tweets from credible ones, to enable\nimproved public health information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Microblogging websites like Twitter have been shown to be immensely useful\nfor spreading information on a global scale within seconds. The detrimental\neffect, however, of such platforms is that misinformation and rumors are also\nas likely to spread on the network as credible, verified information. From a\npublic health standpoint, the spread of misinformation creates unnecessary\npanic for the public. We recently witnessed several such scenarios during the\noutbreak of Ebola in 2014 [14, 1]. In order to effectively counter the medical\nmisinformation in a timely manner, our goal here is to study the nature of such\nmisinformation and rumors in the United States during fall 2014 when a handful\nof Ebola cases were confirmed in North America. It is a well known convention\non Twitter to use hashtags to give context to a Twitter message (a tweet). In\nthis study, we collected approximately 47M tweets from the Twitter streaming\nAPI related to Ebola. Based on hashtags, we propose a method to classify the\ntweets into two sets: credible and speculative. We analyze these two sets and\nstudy how they differ in terms of a number of features extracted from the\nTwitter API. In conclusion, we infer several interesting differences between\nthe two sets. We outline further potential directions to using this material\nfor monitoring and separating speculative tweets from credible ones, to enable\nimproved public health information.'}, 'authors': [{'name': 'Janani Kalyanam'}, {'name': 'Sumithra Velupillai'}, {'name': 'Son Doan'}, {'name': 'Mike Conway'}, {'name': 'Gert Lanckriet'}], 'author_detail': {'name': 'Gert Lanckriet'}, 'author': 'Gert Lanckriet', 'arxiv_comment': 'Appears in SIGKDD BigCHat Workshop 2015', 'links': [{'href': 'http://arxiv.org/abs/1508.02079v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1508.02079v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
482,http://arxiv.org/abs/1507.07109v1,2015-07-25 15:13:34+00:00,2015-07-25 15:13:34+00:00,Political Bots and the Manipulation of Public Opinion in Venezuela,"[arxiv.Result.Author('Michelle Forelle'), arxiv.Result.Author('Phil Howard'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Saiph Savage')]","Social and political bots have a small but strategic role in Venezuelan
political conversations. These automated scripts generate content through
social media platforms and then interact with people. In this preliminary study
on the use of political bots in Venezuela, we analyze the tweeting, following
and retweeting patterns for the accounts of prominent Venezuelan politicians
and prominent Venezuelan bots. We find that bots generate a very small
proportion of all the traffic about political life in Venezuela. Bots are used
to retweet content from Venezuelan politicians but the effect is subtle in that
less than 10 percent of all retweets come from bot-related platforms.
Nonetheless, we find that the most active bots are those used by Venezuela's
radical opposition. Bots are pretending to be political leaders, government
agencies and political parties more than citizens. Finally, bots are promoting
innocuous political events more than attacking opponents or spreading
misinformation.","8 pages, 3 figures",,,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph', 'H.5.3']","[arxiv.Result.Link('http://arxiv.org/abs/1507.07109v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1507.07109v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1507.07109v1,"{'id': 'http://arxiv.org/abs/1507.07109v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1507.07109v1', 'updated': '2015-07-25T15:13:34Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=7, tm_mday=25, tm_hour=15, tm_min=13, tm_sec=34, tm_wday=5, tm_yday=206, tm_isdst=0), 'published': '2015-07-25T15:13:34Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=7, tm_mday=25, tm_hour=15, tm_min=13, tm_sec=34, tm_wday=5, tm_yday=206, tm_isdst=0), 'title': 'Political Bots and the Manipulation of Public Opinion in Venezuela', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Political Bots and the Manipulation of Public Opinion in Venezuela'}, 'summary': ""Social and political bots have a small but strategic role in Venezuelan\npolitical conversations. These automated scripts generate content through\nsocial media platforms and then interact with people. In this preliminary study\non the use of political bots in Venezuela, we analyze the tweeting, following\nand retweeting patterns for the accounts of prominent Venezuelan politicians\nand prominent Venezuelan bots. We find that bots generate a very small\nproportion of all the traffic about political life in Venezuela. Bots are used\nto retweet content from Venezuelan politicians but the effect is subtle in that\nless than 10 percent of all retweets come from bot-related platforms.\nNonetheless, we find that the most active bots are those used by Venezuela's\nradical opposition. Bots are pretending to be political leaders, government\nagencies and political parties more than citizens. Finally, bots are promoting\ninnocuous political events more than attacking opponents or spreading\nmisinformation."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social and political bots have a small but strategic role in Venezuelan\npolitical conversations. These automated scripts generate content through\nsocial media platforms and then interact with people. In this preliminary study\non the use of political bots in Venezuela, we analyze the tweeting, following\nand retweeting patterns for the accounts of prominent Venezuelan politicians\nand prominent Venezuelan bots. We find that bots generate a very small\nproportion of all the traffic about political life in Venezuela. Bots are used\nto retweet content from Venezuelan politicians but the effect is subtle in that\nless than 10 percent of all retweets come from bot-related platforms.\nNonetheless, we find that the most active bots are those used by Venezuela's\nradical opposition. Bots are pretending to be political leaders, government\nagencies and political parties more than citizens. Finally, bots are promoting\ninnocuous political events more than attacking opponents or spreading\nmisinformation.""}, 'authors': [{'name': 'Michelle Forelle'}, {'name': 'Phil Howard'}, {'name': 'Andrés Monroy-Hernández'}, {'name': 'Saiph Savage'}], 'author_detail': {'name': 'Saiph Savage'}, 'author': 'Saiph Savage', 'arxiv_comment': '8 pages, 3 figures', 'links': [{'href': 'http://arxiv.org/abs/1507.07109v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1507.07109v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
483,http://arxiv.org/abs/1503.03752v2,2015-03-13 03:46:26+00:00,2015-03-12 14:50:52+00:00,Manipulation and abuse on social media,[arxiv.Result.Author('Emilio Ferrara')],"The computer science research community has became increasingly interested in
the study of social media due to their pervasiveness in the everyday life of
millions of individuals. Methodological questions and technical challenges
abound as more and more data from social platforms become available for
analysis. This data deluge not only yields the unprecedented opportunity to
unravel questions about online individuals' behavior at scale, but also allows
to explore the potential perils that the massive adoption of social media
brings to our society. These communication channels provide plenty of
incentives (both economical and social) and opportunities for abuse. As social
media activity became increasingly intertwined with the events in the offline
world, individuals and organizations have found ways to exploit these platforms
to spread misinformation, to attack and smear others, or to deceive and
manipulate. During crises, social media have been effectively used for
emergency response, but fear-mongering actions have also triggered mass
hysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt
social media for propaganda and recruitment. Synthetic activity and social bots
have been used to coordinate orchestrated astroturf campaigns, to manipulate
political elections and the stock market. The lack of effective content
verification systems on many of these platforms, including Twitter and
Facebook, rises concerns when younger users become exposed to cyber-bulling,
harassment, or hate speech, inducing risks like depression and suicide. This
article illustrates some of the recent advances facing these issues and
discusses what it remains to be done, including the challenges to address in
the future to make social media a more useful and accessible, safer and
healthier environment for all users.","ACM SIGWEB Newsletter, Spring 2015",,10.1145/2749279.2749283,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1145/2749279.2749283', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1503.03752v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1503.03752v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1503.03752v2,"{'id': 'http://arxiv.org/abs/1503.03752v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1503.03752v2', 'updated': '2015-03-13T03:46:26Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=3, tm_mday=13, tm_hour=3, tm_min=46, tm_sec=26, tm_wday=4, tm_yday=72, tm_isdst=0), 'published': '2015-03-12T14:50:52Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=3, tm_mday=12, tm_hour=14, tm_min=50, tm_sec=52, tm_wday=3, tm_yday=71, tm_isdst=0), 'title': 'Manipulation and abuse on social media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Manipulation and abuse on social media'}, 'summary': ""The computer science research community has became increasingly interested in\nthe study of social media due to their pervasiveness in the everyday life of\nmillions of individuals. Methodological questions and technical challenges\nabound as more and more data from social platforms become available for\nanalysis. This data deluge not only yields the unprecedented opportunity to\nunravel questions about online individuals' behavior at scale, but also allows\nto explore the potential perils that the massive adoption of social media\nbrings to our society. These communication channels provide plenty of\nincentives (both economical and social) and opportunities for abuse. As social\nmedia activity became increasingly intertwined with the events in the offline\nworld, individuals and organizations have found ways to exploit these platforms\nto spread misinformation, to attack and smear others, or to deceive and\nmanipulate. During crises, social media have been effectively used for\nemergency response, but fear-mongering actions have also triggered mass\nhysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt\nsocial media for propaganda and recruitment. Synthetic activity and social bots\nhave been used to coordinate orchestrated astroturf campaigns, to manipulate\npolitical elections and the stock market. The lack of effective content\nverification systems on many of these platforms, including Twitter and\nFacebook, rises concerns when younger users become exposed to cyber-bulling,\nharassment, or hate speech, inducing risks like depression and suicide. This\narticle illustrates some of the recent advances facing these issues and\ndiscusses what it remains to be done, including the challenges to address in\nthe future to make social media a more useful and accessible, safer and\nhealthier environment for all users."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The computer science research community has became increasingly interested in\nthe study of social media due to their pervasiveness in the everyday life of\nmillions of individuals. Methodological questions and technical challenges\nabound as more and more data from social platforms become available for\nanalysis. This data deluge not only yields the unprecedented opportunity to\nunravel questions about online individuals' behavior at scale, but also allows\nto explore the potential perils that the massive adoption of social media\nbrings to our society. These communication channels provide plenty of\nincentives (both economical and social) and opportunities for abuse. As social\nmedia activity became increasingly intertwined with the events in the offline\nworld, individuals and organizations have found ways to exploit these platforms\nto spread misinformation, to attack and smear others, or to deceive and\nmanipulate. During crises, social media have been effectively used for\nemergency response, but fear-mongering actions have also triggered mass\nhysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt\nsocial media for propaganda and recruitment. Synthetic activity and social bots\nhave been used to coordinate orchestrated astroturf campaigns, to manipulate\npolitical elections and the stock market. The lack of effective content\nverification systems on many of these platforms, including Twitter and\nFacebook, rises concerns when younger users become exposed to cyber-bulling,\nharassment, or hate speech, inducing risks like depression and suicide. This\narticle illustrates some of the recent advances facing these issues and\ndiscusses what it remains to be done, including the challenges to address in\nthe future to make social media a more useful and accessible, safer and\nhealthier environment for all users.""}, 'authors': [{'name': 'Emilio Ferrara'}], 'author_detail': {'name': 'Emilio Ferrara'}, 'author': 'Emilio Ferrara', 'arxiv_doi': '10.1145/2749279.2749283', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/2749279.2749283', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1503.03752v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1503.03752v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'ACM SIGWEB Newsletter, Spring 2015', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
484,http://arxiv.org/abs/1502.07162v3,2015-10-28 20:36:49+00:00,2015-02-25 13:29:17+00:00,Measuring Online Social Bubbles,"[arxiv.Result.Author('Dimitar Nikolov'), arxiv.Result.Author('Diego F. M. Oliveira'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Social media have quickly become a prevalent channel to access information,
spread ideas, and influence opinions. However, it has been suggested that
social and algorithmic filtering may cause exposure to less diverse points of
view, and even foster polarization and misinformation. Here we explore and
validate this hypothesis quantitatively for the first time, at the collective
and individual levels, by mining three massive datasets of web traffic, search
logs, and Twitter posts. Our analysis shows that collectively, people access
information from a significantly narrower spectrum of sources through social
media and email, compared to search. The significance of this finding for
individual exposure is revealed by investigating the relationship between the
diversity of information sources experienced by users at the collective and
individual level. There is a strong correlation between collective and
individual diversity, supporting the notion that when we use social media we
find ourselves inside ""social bubbles"". Our results could lead to a deeper
understanding of how technology biases our exposure to new information.",,,,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1502.07162v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1502.07162v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1502.07162v3,"{'id': 'http://arxiv.org/abs/1502.07162v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/1502.07162v3', 'updated': '2015-10-28T20:36:49Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=10, tm_mday=28, tm_hour=20, tm_min=36, tm_sec=49, tm_wday=2, tm_yday=301, tm_isdst=0), 'published': '2015-02-25T13:29:17Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=2, tm_mday=25, tm_hour=13, tm_min=29, tm_sec=17, tm_wday=2, tm_yday=56, tm_isdst=0), 'title': 'Measuring Online Social Bubbles', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Measuring Online Social Bubbles'}, 'summary': 'Social media have quickly become a prevalent channel to access information,\nspread ideas, and influence opinions. However, it has been suggested that\nsocial and algorithmic filtering may cause exposure to less diverse points of\nview, and even foster polarization and misinformation. Here we explore and\nvalidate this hypothesis quantitatively for the first time, at the collective\nand individual levels, by mining three massive datasets of web traffic, search\nlogs, and Twitter posts. Our analysis shows that collectively, people access\ninformation from a significantly narrower spectrum of sources through social\nmedia and email, compared to search. The significance of this finding for\nindividual exposure is revealed by investigating the relationship between the\ndiversity of information sources experienced by users at the collective and\nindividual level. There is a strong correlation between collective and\nindividual diversity, supporting the notion that when we use social media we\nfind ourselves inside ""social bubbles"". Our results could lead to a deeper\nunderstanding of how technology biases our exposure to new information.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social media have quickly become a prevalent channel to access information,\nspread ideas, and influence opinions. However, it has been suggested that\nsocial and algorithmic filtering may cause exposure to less diverse points of\nview, and even foster polarization and misinformation. Here we explore and\nvalidate this hypothesis quantitatively for the first time, at the collective\nand individual levels, by mining three massive datasets of web traffic, search\nlogs, and Twitter posts. Our analysis shows that collectively, people access\ninformation from a significantly narrower spectrum of sources through social\nmedia and email, compared to search. The significance of this finding for\nindividual exposure is revealed by investigating the relationship between the\ndiversity of information sources experienced by users at the collective and\nindividual level. There is a strong correlation between collective and\nindividual diversity, supporting the notion that when we use social media we\nfind ourselves inside ""social bubbles"". Our results could lead to a deeper\nunderstanding of how technology biases our exposure to new information.'}, 'authors': [{'name': 'Dimitar Nikolov'}, {'name': 'Diego F. M. Oliveira'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'links': [{'href': 'http://arxiv.org/abs/1502.07162v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1502.07162v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
485,http://arxiv.org/abs/1501.03471v1,2015-01-14 20:18:21+00:00,2015-01-14 20:18:21+00:00,Computational fact checking from knowledge networks,"[arxiv.Result.Author('Giovanni Luca Ciampaglia'), arxiv.Result.Author('Prashant Shiralkar'), arxiv.Result.Author('Luis M. Rocha'), arxiv.Result.Author('Johan Bollen'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Alessandro Flammini')]","Traditional fact checking by expert journalists cannot keep up with the
enormous volume of information that is now generated online. Computational fact
checking may significantly enhance our ability to evaluate the veracity of
dubious information. Here we show that the complexities of human fact checking
can be approximated quite well by finding the shortest path between concept
nodes under properly defined semantic proximity metrics on knowledge graphs.
Framed as a network problem this approach is feasible with efficient
computational techniques. We evaluate this approach by examining tens of
thousands of claims related to history, entertainment, geography, and
biographical information using a public knowledge graph extracted from
Wikipedia. Statements independently known to be true consistently receive
higher support via our method than do false ones. These findings represent a
significant step toward scalable computational fact-checking methods that may
one day mitigate the spread of harmful misinformation.",,,10.1371/journal.pone.0128193,cs.CY,"['cs.CY', 'cs.SI', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1371/journal.pone.0128193', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1501.03471v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1501.03471v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1501.03471v1,"{'id': 'http://arxiv.org/abs/1501.03471v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1501.03471v1', 'updated': '2015-01-14T20:18:21Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=1, tm_mday=14, tm_hour=20, tm_min=18, tm_sec=21, tm_wday=2, tm_yday=14, tm_isdst=0), 'published': '2015-01-14T20:18:21Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=1, tm_mday=14, tm_hour=20, tm_min=18, tm_sec=21, tm_wday=2, tm_yday=14, tm_isdst=0), 'title': 'Computational fact checking from knowledge networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Computational fact checking from knowledge networks'}, 'summary': 'Traditional fact checking by expert journalists cannot keep up with the\nenormous volume of information that is now generated online. Computational fact\nchecking may significantly enhance our ability to evaluate the veracity of\ndubious information. Here we show that the complexities of human fact checking\ncan be approximated quite well by finding the shortest path between concept\nnodes under properly defined semantic proximity metrics on knowledge graphs.\nFramed as a network problem this approach is feasible with efficient\ncomputational techniques. We evaluate this approach by examining tens of\nthousands of claims related to history, entertainment, geography, and\nbiographical information using a public knowledge graph extracted from\nWikipedia. Statements independently known to be true consistently receive\nhigher support via our method than do false ones. These findings represent a\nsignificant step toward scalable computational fact-checking methods that may\none day mitigate the spread of harmful misinformation.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Traditional fact checking by expert journalists cannot keep up with the\nenormous volume of information that is now generated online. Computational fact\nchecking may significantly enhance our ability to evaluate the veracity of\ndubious information. Here we show that the complexities of human fact checking\ncan be approximated quite well by finding the shortest path between concept\nnodes under properly defined semantic proximity metrics on knowledge graphs.\nFramed as a network problem this approach is feasible with efficient\ncomputational techniques. We evaluate this approach by examining tens of\nthousands of claims related to history, entertainment, geography, and\nbiographical information using a public knowledge graph extracted from\nWikipedia. Statements independently known to be true consistently receive\nhigher support via our method than do false ones. These findings represent a\nsignificant step toward scalable computational fact-checking methods that may\none day mitigate the spread of harmful misinformation.'}, 'authors': [{'name': 'Giovanni Luca Ciampaglia'}, {'name': 'Prashant Shiralkar'}, {'name': 'Luis M. Rocha'}, {'name': 'Johan Bollen'}, {'name': 'Filippo Menczer'}, {'name': 'Alessandro Flammini'}], 'author_detail': {'name': 'Alessandro Flammini'}, 'author': 'Alessandro Flammini', 'arxiv_doi': '10.1371/journal.pone.0128193', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1371/journal.pone.0128193', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1501.03471v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1501.03471v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
486,http://arxiv.org/abs/1501.00994v1,2015-01-05 21:00:51+00:00,2015-01-05 21:00:51+00:00,"Online Reputation and Polling Systems: Data Incest, Social Learning and Revealed Preferences","[arxiv.Result.Author('Vikram Krishnamurthy'), arxiv.Result.Author('William Hoiles')]","This paper considers online reputation and polling systems where individuals
make recommendations based on their private observations and recommendations of
friends. Such interaction of individuals and their social influence is modelled
as social learning on a directed acyclic graph. Data incest (misinformation
propagation) occurs due to unintentional re-use of identical actions in the
for- mation of public belief in social learning; the information gathered by
each agent is mistakenly considered to be independent. This results in
overconfidence and bias in estimates of the state. Necessary and sufficient
conditions are given on the structure of information exchange graph to mitigate
data incest. Incest removal algorithms are presented. Experimental results on
human subjects are presented to illustrate the effect of social influence and
data incest on decision making. These experimental results indicate that social
learning protocols require careful design to handle and mitigate data incest.
The incest removal algorithms are illustrated in an expectation polling system
where participants in a poll respond with a summary of their friends' beliefs.
Finally, the principle of revealed preferences arising in micro-economics
theory is used to parse Twitter datasets to determine if social sensors are
utility maximizers and then determine their utility functions.",arXiv admin note: substantial text overlap with arXiv:1412.4171,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1501.00994v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1501.00994v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1501.00994v1,"{'id': 'http://arxiv.org/abs/1501.00994v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1501.00994v1', 'updated': '2015-01-05T21:00:51Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=1, tm_mday=5, tm_hour=21, tm_min=0, tm_sec=51, tm_wday=0, tm_yday=5, tm_isdst=0), 'published': '2015-01-05T21:00:51Z', 'published_parsed': time.struct_time(tm_year=2015, tm_mon=1, tm_mday=5, tm_hour=21, tm_min=0, tm_sec=51, tm_wday=0, tm_yday=5, tm_isdst=0), 'title': 'Online Reputation and Polling Systems: Data Incest, Social Learning and\n  Revealed Preferences', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Online Reputation and Polling Systems: Data Incest, Social Learning and\n  Revealed Preferences'}, 'summary': ""This paper considers online reputation and polling systems where individuals\nmake recommendations based on their private observations and recommendations of\nfriends. Such interaction of individuals and their social influence is modelled\nas social learning on a directed acyclic graph. Data incest (misinformation\npropagation) occurs due to unintentional re-use of identical actions in the\nfor- mation of public belief in social learning; the information gathered by\neach agent is mistakenly considered to be independent. This results in\noverconfidence and bias in estimates of the state. Necessary and sufficient\nconditions are given on the structure of information exchange graph to mitigate\ndata incest. Incest removal algorithms are presented. Experimental results on\nhuman subjects are presented to illustrate the effect of social influence and\ndata incest on decision making. These experimental results indicate that social\nlearning protocols require careful design to handle and mitigate data incest.\nThe incest removal algorithms are illustrated in an expectation polling system\nwhere participants in a poll respond with a summary of their friends' beliefs.\nFinally, the principle of revealed preferences arising in micro-economics\ntheory is used to parse Twitter datasets to determine if social sensors are\nutility maximizers and then determine their utility functions."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""This paper considers online reputation and polling systems where individuals\nmake recommendations based on their private observations and recommendations of\nfriends. Such interaction of individuals and their social influence is modelled\nas social learning on a directed acyclic graph. Data incest (misinformation\npropagation) occurs due to unintentional re-use of identical actions in the\nfor- mation of public belief in social learning; the information gathered by\neach agent is mistakenly considered to be independent. This results in\noverconfidence and bias in estimates of the state. Necessary and sufficient\nconditions are given on the structure of information exchange graph to mitigate\ndata incest. Incest removal algorithms are presented. Experimental results on\nhuman subjects are presented to illustrate the effect of social influence and\ndata incest on decision making. These experimental results indicate that social\nlearning protocols require careful design to handle and mitigate data incest.\nThe incest removal algorithms are illustrated in an expectation polling system\nwhere participants in a poll respond with a summary of their friends' beliefs.\nFinally, the principle of revealed preferences arising in micro-economics\ntheory is used to parse Twitter datasets to determine if social sensors are\nutility maximizers and then determine their utility functions.""}, 'authors': [{'name': 'Vikram Krishnamurthy'}, {'name': 'William Hoiles'}], 'author_detail': {'name': 'William Hoiles'}, 'author': 'William Hoiles', 'arxiv_comment': 'arXiv admin note: substantial text overlap with arXiv:1412.4171', 'links': [{'href': 'http://arxiv.org/abs/1501.00994v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1501.00994v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
487,http://arxiv.org/abs/1411.3550v1,2014-11-13 14:21:00+00:00,2014-11-13 14:21:00+00:00,Investigating Rumor Propagation with TwitterTrails,"[arxiv.Result.Author('Samantha Finn'), arxiv.Result.Author('Panagiotis Takis Metaxas'), arxiv.Result.Author('Eni Mustafaraj')]","Social media have become part of modern news reporting, used by journalists
to spread information and find sources, or as a news source by individuals. The
quest for prominence and recognition on social media sites like Twitter can
sometimes eclipse accuracy and lead to the spread of false information. As a
way to study and react to this trend, we introduce {\sc TwitterTrails}, an
interactive, web-based tool ({\tt twittertrails.com}) that allows users to
investigate the origin and propagation characteristics of a rumor and its
refutation, if any, on Twitter. Visualizations of burst activity, propagation
timeline, retweet and co-retweeted networks help its users trace the spread of
a story. Within minutes {\sc TwitterTrails} will collect relevant tweets and
automatically answer several important questions regarding a rumor: its
originator, burst characteristics, propagators and main actors according to the
audience. In addition, it will compute and report the rumor's level of
visibility and, as an example of the power of crowdsourcing, the audience's
skepticism towards it which correlates with the rumor's credibility. We
envision {\sc TwitterTrails} as valuable tool for individual use, but we
especially for amateur and professional journalists investigating recent and
breaking stories. Further, its expanding collection of investigated rumors can
be used to answer questions regarding the amount and success of misinformation
on Twitter.","10 pages, 8 figures, under review",,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1411.3550v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1411.3550v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1411.3550v1,"{'id': 'http://arxiv.org/abs/1411.3550v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1411.3550v1', 'updated': '2014-11-13T14:21:00Z', 'updated_parsed': time.struct_time(tm_year=2014, tm_mon=11, tm_mday=13, tm_hour=14, tm_min=21, tm_sec=0, tm_wday=3, tm_yday=317, tm_isdst=0), 'published': '2014-11-13T14:21:00Z', 'published_parsed': time.struct_time(tm_year=2014, tm_mon=11, tm_mday=13, tm_hour=14, tm_min=21, tm_sec=0, tm_wday=3, tm_yday=317, tm_isdst=0), 'title': 'Investigating Rumor Propagation with TwitterTrails', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Investigating Rumor Propagation with TwitterTrails'}, 'summary': ""Social media have become part of modern news reporting, used by journalists\nto spread information and find sources, or as a news source by individuals. The\nquest for prominence and recognition on social media sites like Twitter can\nsometimes eclipse accuracy and lead to the spread of false information. As a\nway to study and react to this trend, we introduce {\\sc TwitterTrails}, an\ninteractive, web-based tool ({\\tt twittertrails.com}) that allows users to\ninvestigate the origin and propagation characteristics of a rumor and its\nrefutation, if any, on Twitter. Visualizations of burst activity, propagation\ntimeline, retweet and co-retweeted networks help its users trace the spread of\na story. Within minutes {\\sc TwitterTrails} will collect relevant tweets and\nautomatically answer several important questions regarding a rumor: its\noriginator, burst characteristics, propagators and main actors according to the\naudience. In addition, it will compute and report the rumor's level of\nvisibility and, as an example of the power of crowdsourcing, the audience's\nskepticism towards it which correlates with the rumor's credibility. We\nenvision {\\sc TwitterTrails} as valuable tool for individual use, but we\nespecially for amateur and professional journalists investigating recent and\nbreaking stories. Further, its expanding collection of investigated rumors can\nbe used to answer questions regarding the amount and success of misinformation\non Twitter."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""Social media have become part of modern news reporting, used by journalists\nto spread information and find sources, or as a news source by individuals. The\nquest for prominence and recognition on social media sites like Twitter can\nsometimes eclipse accuracy and lead to the spread of false information. As a\nway to study and react to this trend, we introduce {\\sc TwitterTrails}, an\ninteractive, web-based tool ({\\tt twittertrails.com}) that allows users to\ninvestigate the origin and propagation characteristics of a rumor and its\nrefutation, if any, on Twitter. Visualizations of burst activity, propagation\ntimeline, retweet and co-retweeted networks help its users trace the spread of\na story. Within minutes {\\sc TwitterTrails} will collect relevant tweets and\nautomatically answer several important questions regarding a rumor: its\noriginator, burst characteristics, propagators and main actors according to the\naudience. In addition, it will compute and report the rumor's level of\nvisibility and, as an example of the power of crowdsourcing, the audience's\nskepticism towards it which correlates with the rumor's credibility. We\nenvision {\\sc TwitterTrails} as valuable tool for individual use, but we\nespecially for amateur and professional journalists investigating recent and\nbreaking stories. Further, its expanding collection of investigated rumors can\nbe used to answer questions regarding the amount and success of misinformation\non Twitter.""}, 'authors': [{'name': 'Samantha Finn'}, {'name': 'Panagiotis Takis Metaxas'}, {'name': 'Eni Mustafaraj'}], 'author_detail': {'name': 'Eni Mustafaraj'}, 'author': 'Eni Mustafaraj', 'arxiv_comment': '10 pages, 8 figures, under review', 'links': [{'href': 'http://arxiv.org/abs/1411.3550v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1411.3550v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
488,http://arxiv.org/abs/1411.2893v1,2014-11-11 17:34:13+00:00,2014-11-11 17:34:13+00:00,Viral Misinformation: The Role of Homophily and Polarization,"[arxiv.Result.Author('Aris Anagnostopoulos'), arxiv.Result.Author('Alessandro Bessi'), arxiv.Result.Author('Guido Caldarelli'), arxiv.Result.Author('Michela Del Vicario'), arxiv.Result.Author('Fabio Petroni'), arxiv.Result.Author('Antonio Scala'), arxiv.Result.Author('Fabiana Zollo'), arxiv.Result.Author('Walter Quattrociocchi')]","The spreading of unsubstantiated rumors on online social networks (OSN)
either unintentionally or intentionally (e.g., for political reasons or even
trolling) can have serious consequences such as in the recent case of rumors
about Ebola causing disruption to health-care workers. Here we show that
indicators aimed at quantifying information consumption patterns might provide
important insights about the virality of false claims. In particular, we
address the driving forces behind the popularity of contents by analyzing a
sample of 1.2M Facebook Italian users consuming different (and opposite) types
of information (science and conspiracy news). We show that users' engagement
across different contents correlates with the number of friends having similar
consumption patterns (homophily), indicating the area in the social network
where certain types of contents are more likely to spread. Then, we test
diffusion patterns on an external sample of $4,709$ intentional satirical false
claims showing that neither the presence of hubs (structural properties) nor
the most active users (influencers) are prevalent in viral phenomena. Instead,
we found out that in an environment where misinformation is pervasive, users'
aggregation around shared beliefs may make the usual exposure to conspiracy
stories (polarization) a determinant for the virality of false information.","Misinformation, Virality, Attention Patterns",,,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1411.2893v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1411.2893v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1411.2893v1,"{'id': 'http://arxiv.org/abs/1411.2893v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1411.2893v1', 'updated': '2014-11-11T17:34:13Z', 'updated_parsed': time.struct_time(tm_year=2014, tm_mon=11, tm_mday=11, tm_hour=17, tm_min=34, tm_sec=13, tm_wday=1, tm_yday=315, tm_isdst=0), 'published': '2014-11-11T17:34:13Z', 'published_parsed': time.struct_time(tm_year=2014, tm_mon=11, tm_mday=11, tm_hour=17, tm_min=34, tm_sec=13, tm_wday=1, tm_yday=315, tm_isdst=0), 'title': 'Viral Misinformation: The Role of Homophily and Polarization', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Viral Misinformation: The Role of Homophily and Polarization'}, 'summary': ""The spreading of unsubstantiated rumors on online social networks (OSN)\neither unintentionally or intentionally (e.g., for political reasons or even\ntrolling) can have serious consequences such as in the recent case of rumors\nabout Ebola causing disruption to health-care workers. Here we show that\nindicators aimed at quantifying information consumption patterns might provide\nimportant insights about the virality of false claims. In particular, we\naddress the driving forces behind the popularity of contents by analyzing a\nsample of 1.2M Facebook Italian users consuming different (and opposite) types\nof information (science and conspiracy news). We show that users' engagement\nacross different contents correlates with the number of friends having similar\nconsumption patterns (homophily), indicating the area in the social network\nwhere certain types of contents are more likely to spread. Then, we test\ndiffusion patterns on an external sample of $4,709$ intentional satirical false\nclaims showing that neither the presence of hubs (structural properties) nor\nthe most active users (influencers) are prevalent in viral phenomena. Instead,\nwe found out that in an environment where misinformation is pervasive, users'\naggregation around shared beliefs may make the usual exposure to conspiracy\nstories (polarization) a determinant for the virality of false information."", 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': ""The spreading of unsubstantiated rumors on online social networks (OSN)\neither unintentionally or intentionally (e.g., for political reasons or even\ntrolling) can have serious consequences such as in the recent case of rumors\nabout Ebola causing disruption to health-care workers. Here we show that\nindicators aimed at quantifying information consumption patterns might provide\nimportant insights about the virality of false claims. In particular, we\naddress the driving forces behind the popularity of contents by analyzing a\nsample of 1.2M Facebook Italian users consuming different (and opposite) types\nof information (science and conspiracy news). We show that users' engagement\nacross different contents correlates with the number of friends having similar\nconsumption patterns (homophily), indicating the area in the social network\nwhere certain types of contents are more likely to spread. Then, we test\ndiffusion patterns on an external sample of $4,709$ intentional satirical false\nclaims showing that neither the presence of hubs (structural properties) nor\nthe most active users (influencers) are prevalent in viral phenomena. Instead,\nwe found out that in an environment where misinformation is pervasive, users'\naggregation around shared beliefs may make the usual exposure to conspiracy\nstories (polarization) a determinant for the virality of false information.""}, 'authors': [{'name': 'Aris Anagnostopoulos'}, {'name': 'Alessandro Bessi'}, {'name': 'Guido Caldarelli'}, {'name': 'Michela Del Vicario'}, {'name': 'Fabio Petroni'}, {'name': 'Antonio Scala'}, {'name': 'Fabiana Zollo'}, {'name': 'Walter Quattrociocchi'}], 'author_detail': {'name': 'Walter Quattrociocchi'}, 'author': 'Walter Quattrociocchi', 'arxiv_comment': 'Misinformation, Virality, Attention Patterns', 'links': [{'href': 'http://arxiv.org/abs/1411.2893v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1411.2893v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
489,http://arxiv.org/abs/1408.5378v1,2014-08-19 18:00:36+00:00,2014-08-19 18:00:36+00:00,Social Learning in a Human Society: An Experimental Study,"[arxiv.Result.Author('Maziyar Hamdi'), arxiv.Result.Author('Grayden Solman'), arxiv.Result.Author('Alan Kingstone'), arxiv.Result.Author('Vikram Krishnamurthy')]","This paper presents an experimental study to investigate the learning and
decision making behavior of individuals in a human society. Social learning is
used as the mathematical basis for modelling interaction of individuals that
aim to perform a perceptual task interactively. A psychology experiment was
conducted on a group of undergraduate students at the University of British
Columbia to examine whether the decision (action) of one individual affects the
decision of the subsequent individuals. The major experimental observation that
stands out here is that the participants of the experiment (agents) were
affected by decisions of their partners in a relatively large fraction (60%) of
trials. We fit a social learning model that mimics the interactions between
participants of the psychology experiment. Misinformation propagation (also
known as data incest) within the society under study is further investigated in
this paper.",,,,cs.SI,['cs.SI'],"[arxiv.Result.Link('http://arxiv.org/abs/1408.5378v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1408.5378v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1408.5378v1,"{'id': 'http://arxiv.org/abs/1408.5378v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1408.5378v1', 'updated': '2014-08-19T18:00:36Z', 'updated_parsed': time.struct_time(tm_year=2014, tm_mon=8, tm_mday=19, tm_hour=18, tm_min=0, tm_sec=36, tm_wday=1, tm_yday=231, tm_isdst=0), 'published': '2014-08-19T18:00:36Z', 'published_parsed': time.struct_time(tm_year=2014, tm_mon=8, tm_mday=19, tm_hour=18, tm_min=0, tm_sec=36, tm_wday=1, tm_yday=231, tm_isdst=0), 'title': 'Social Learning in a Human Society: An Experimental Study', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Social Learning in a Human Society: An Experimental Study'}, 'summary': 'This paper presents an experimental study to investigate the learning and\ndecision making behavior of individuals in a human society. Social learning is\nused as the mathematical basis for modelling interaction of individuals that\naim to perform a perceptual task interactively. A psychology experiment was\nconducted on a group of undergraduate students at the University of British\nColumbia to examine whether the decision (action) of one individual affects the\ndecision of the subsequent individuals. The major experimental observation that\nstands out here is that the participants of the experiment (agents) were\naffected by decisions of their partners in a relatively large fraction (60%) of\ntrials. We fit a social learning model that mimics the interactions between\nparticipants of the psychology experiment. Misinformation propagation (also\nknown as data incest) within the society under study is further investigated in\nthis paper.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper presents an experimental study to investigate the learning and\ndecision making behavior of individuals in a human society. Social learning is\nused as the mathematical basis for modelling interaction of individuals that\naim to perform a perceptual task interactively. A psychology experiment was\nconducted on a group of undergraduate students at the University of British\nColumbia to examine whether the decision (action) of one individual affects the\ndecision of the subsequent individuals. The major experimental observation that\nstands out here is that the participants of the experiment (agents) were\naffected by decisions of their partners in a relatively large fraction (60%) of\ntrials. We fit a social learning model that mimics the interactions between\nparticipants of the psychology experiment. Misinformation propagation (also\nknown as data incest) within the society under study is further investigated in\nthis paper.'}, 'authors': [{'name': 'Maziyar Hamdi'}, {'name': 'Grayden Solman'}, {'name': 'Alan Kingstone'}, {'name': 'Vikram Krishnamurthy'}], 'author_detail': {'name': 'Vikram Krishnamurthy'}, 'author': 'Vikram Krishnamurthy', 'links': [{'href': 'http://arxiv.org/abs/1408.5378v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1408.5378v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
490,http://arxiv.org/abs/1403.6315v2,2014-04-27 05:42:30+00:00,2014-03-25 11:39:02+00:00,Cost Effective Rumor Containment in Social Networks,"[arxiv.Result.Author('Bhushan Kotnis'), arxiv.Result.Author('Joy Kuri')]","The spread of rumors through social media and online social networks can not
only disrupt the daily lives of citizens but also result in loss of life and
property. A rumor spreads when individuals, who are unable decide the
authenticity of the information, mistake the rumor as genuine information and
pass it on to their acquaintances. We propose a solution where a set of
individuals (based on their degree) in the social network are trained and
provided resources to help them distinguish a rumor from genuine information.
By formulating an optimization problem we calculate the optimum set of
individuals, who must undergo training, and the quality of training that
minimizes the expected training cost and ensures an upper bound on the size of
the rumor outbreak. Our primary contribution is that although the optimization
problem turns out to be non convex, we show that the problem is equivalent to
solving a set of linear programs. This result also allows us to solve the
problem of minimizing the size of rumor outbreak for a given cost budget. The
optimum solution displays an interesting pattern which can be implemented as a
heuristic. These results can prove to be very useful for social planners and
law enforcement agencies for preventing dangerous rumors and misinformation
epidemics.",,,,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Link('http://arxiv.org/abs/1403.6315v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1403.6315v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1403.6315v2,"{'id': 'http://arxiv.org/abs/1403.6315v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1403.6315v2', 'updated': '2014-04-27T05:42:30Z', 'updated_parsed': time.struct_time(tm_year=2014, tm_mon=4, tm_mday=27, tm_hour=5, tm_min=42, tm_sec=30, tm_wday=6, tm_yday=117, tm_isdst=0), 'published': '2014-03-25T11:39:02Z', 'published_parsed': time.struct_time(tm_year=2014, tm_mon=3, tm_mday=25, tm_hour=11, tm_min=39, tm_sec=2, tm_wday=1, tm_yday=84, tm_isdst=0), 'title': 'Cost Effective Rumor Containment in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cost Effective Rumor Containment in Social Networks'}, 'summary': 'The spread of rumors through social media and online social networks can not\nonly disrupt the daily lives of citizens but also result in loss of life and\nproperty. A rumor spreads when individuals, who are unable decide the\nauthenticity of the information, mistake the rumor as genuine information and\npass it on to their acquaintances. We propose a solution where a set of\nindividuals (based on their degree) in the social network are trained and\nprovided resources to help them distinguish a rumor from genuine information.\nBy formulating an optimization problem we calculate the optimum set of\nindividuals, who must undergo training, and the quality of training that\nminimizes the expected training cost and ensures an upper bound on the size of\nthe rumor outbreak. Our primary contribution is that although the optimization\nproblem turns out to be non convex, we show that the problem is equivalent to\nsolving a set of linear programs. This result also allows us to solve the\nproblem of minimizing the size of rumor outbreak for a given cost budget. The\noptimum solution displays an interesting pattern which can be implemented as a\nheuristic. These results can prove to be very useful for social planners and\nlaw enforcement agencies for preventing dangerous rumors and misinformation\nepidemics.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The spread of rumors through social media and online social networks can not\nonly disrupt the daily lives of citizens but also result in loss of life and\nproperty. A rumor spreads when individuals, who are unable decide the\nauthenticity of the information, mistake the rumor as genuine information and\npass it on to their acquaintances. We propose a solution where a set of\nindividuals (based on their degree) in the social network are trained and\nprovided resources to help them distinguish a rumor from genuine information.\nBy formulating an optimization problem we calculate the optimum set of\nindividuals, who must undergo training, and the quality of training that\nminimizes the expected training cost and ensures an upper bound on the size of\nthe rumor outbreak. Our primary contribution is that although the optimization\nproblem turns out to be non convex, we show that the problem is equivalent to\nsolving a set of linear programs. This result also allows us to solve the\nproblem of minimizing the size of rumor outbreak for a given cost budget. The\noptimum solution displays an interesting pattern which can be implemented as a\nheuristic. These results can prove to be very useful for social planners and\nlaw enforcement agencies for preventing dangerous rumors and misinformation\nepidemics.'}, 'authors': [{'name': 'Bhushan Kotnis'}, {'name': 'Joy Kuri'}], 'author_detail': {'name': 'Joy Kuri'}, 'author': 'Joy Kuri', 'links': [{'href': 'http://arxiv.org/abs/1403.6315v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1403.6315v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
491,http://arxiv.org/abs/1310.2665v1,2013-10-10 00:10:46+00:00,2013-10-10 00:10:46+00:00,Clustering Memes in Social Media,"[arxiv.Result.Author('Emilio Ferrara'), arxiv.Result.Author('Mohsen JafariAsbagh'), arxiv.Result.Author('Onur Varol'), arxiv.Result.Author('Vahed Qazvinian'), arxiv.Result.Author('Filippo Menczer'), arxiv.Result.Author('Alessandro Flammini')]","The increasing pervasiveness of social media creates new opportunities to
study human social behavior, while challenging our capability to analyze their
massive data streams. One of the emerging tasks is to distinguish between
different kinds of activities, for example engineered misinformation campaigns
versus spontaneous communication. Such detection problems require a formal
definition of meme, or unit of information that can spread from person to
person through the social network. Once a meme is identified, supervised
learning methods can be applied to classify different types of communication.
The appropriate granularity of a meme, however, is hardly captured from
existing entities such as tags and keywords. Here we present a framework for
the novel task of detecting memes by clustering messages from large streams of
social data. We evaluate various similarity measures that leverage content,
metadata, network features, and their combinations. We also explore the idea of
pre-clustering on the basis of existing entities. A systematic evaluation is
carried out using a manually curated dataset as ground truth. Our analysis
shows that pre-clustering and a combination of heterogeneous features yield the
best trade-off between number of clusters and their quality, demonstrating that
a simple combination based on pairwise maximization of similarity is as
effective as a non-trivial optimization of parameters. Our approach is fully
automatic, unsupervised, and scalable for real-time detection of memes in
streaming data.","Proceedings of the 2013 IEEE/ACM International Conference on Advances
  in Social Networks Analysis and Mining (ASONAM'13), 2013","Advances in social networks analysis and mining (ASONAM), 2013
  IEEE/ACM international conference on (pp. 548-555). IEEE",10.1145/2492517.2492530,cs.SI,"['cs.SI', 'cs.CY', 'physics.data-an', 'physics.soc-ph']","[arxiv.Result.Link('http://dx.doi.org/10.1145/2492517.2492530', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1310.2665v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1310.2665v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1310.2665v1,"{'id': 'http://arxiv.org/abs/1310.2665v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1310.2665v1', 'updated': '2013-10-10T00:10:46Z', 'updated_parsed': time.struct_time(tm_year=2013, tm_mon=10, tm_mday=10, tm_hour=0, tm_min=10, tm_sec=46, tm_wday=3, tm_yday=283, tm_isdst=0), 'published': '2013-10-10T00:10:46Z', 'published_parsed': time.struct_time(tm_year=2013, tm_mon=10, tm_mday=10, tm_hour=0, tm_min=10, tm_sec=46, tm_wday=3, tm_yday=283, tm_isdst=0), 'title': 'Clustering Memes in Social Media', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Clustering Memes in Social Media'}, 'summary': 'The increasing pervasiveness of social media creates new opportunities to\nstudy human social behavior, while challenging our capability to analyze their\nmassive data streams. One of the emerging tasks is to distinguish between\ndifferent kinds of activities, for example engineered misinformation campaigns\nversus spontaneous communication. Such detection problems require a formal\ndefinition of meme, or unit of information that can spread from person to\nperson through the social network. Once a meme is identified, supervised\nlearning methods can be applied to classify different types of communication.\nThe appropriate granularity of a meme, however, is hardly captured from\nexisting entities such as tags and keywords. Here we present a framework for\nthe novel task of detecting memes by clustering messages from large streams of\nsocial data. We evaluate various similarity measures that leverage content,\nmetadata, network features, and their combinations. We also explore the idea of\npre-clustering on the basis of existing entities. A systematic evaluation is\ncarried out using a manually curated dataset as ground truth. Our analysis\nshows that pre-clustering and a combination of heterogeneous features yield the\nbest trade-off between number of clusters and their quality, demonstrating that\na simple combination based on pairwise maximization of similarity is as\neffective as a non-trivial optimization of parameters. Our approach is fully\nautomatic, unsupervised, and scalable for real-time detection of memes in\nstreaming data.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'The increasing pervasiveness of social media creates new opportunities to\nstudy human social behavior, while challenging our capability to analyze their\nmassive data streams. One of the emerging tasks is to distinguish between\ndifferent kinds of activities, for example engineered misinformation campaigns\nversus spontaneous communication. Such detection problems require a formal\ndefinition of meme, or unit of information that can spread from person to\nperson through the social network. Once a meme is identified, supervised\nlearning methods can be applied to classify different types of communication.\nThe appropriate granularity of a meme, however, is hardly captured from\nexisting entities such as tags and keywords. Here we present a framework for\nthe novel task of detecting memes by clustering messages from large streams of\nsocial data. We evaluate various similarity measures that leverage content,\nmetadata, network features, and their combinations. We also explore the idea of\npre-clustering on the basis of existing entities. A systematic evaluation is\ncarried out using a manually curated dataset as ground truth. Our analysis\nshows that pre-clustering and a combination of heterogeneous features yield the\nbest trade-off between number of clusters and their quality, demonstrating that\na simple combination based on pairwise maximization of similarity is as\neffective as a non-trivial optimization of parameters. Our approach is fully\nautomatic, unsupervised, and scalable for real-time detection of memes in\nstreaming data.'}, 'authors': [{'name': 'Emilio Ferrara'}, {'name': 'Mohsen JafariAsbagh'}, {'name': 'Onur Varol'}, {'name': 'Vahed Qazvinian'}, {'name': 'Filippo Menczer'}, {'name': 'Alessandro Flammini'}], 'author_detail': {'name': 'Alessandro Flammini'}, 'author': 'Alessandro Flammini', 'arxiv_doi': '10.1145/2492517.2492530', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/2492517.2492530', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1310.2665v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1310.2665v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': ""Proceedings of the 2013 IEEE/ACM International Conference on Advances\n  in Social Networks Analysis and Mining (ASONAM'13), 2013"", 'arxiv_journal_ref': 'Advances in social networks analysis and mining (ASONAM), 2013\n  IEEE/ACM international conference on (pp. 548-555). IEEE', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
492,http://arxiv.org/abs/1310.1942v1,2013-10-07 20:19:36+00:00,2013-10-07 20:19:36+00:00,"Containing Viral Spread on Sparse Random Graphs: Bounds, Algorithms, and Experiments","[arxiv.Result.Author('Milan Bradonjić'), arxiv.Result.Author('Michael Molloy'), arxiv.Result.Author('Guanhua Yan')]","Viral spread on large graphs has many real-life applications such as malware
propagation in computer networks and rumor (or misinformation) spread in
Twitter-like online social networks. Although viral spread on large graphs has
been intensively analyzed on classical models such as
Susceptible-Infectious-Recovered, there still exits a deficit of effective
methods in practice to contain epidemic spread once it passes a critical
threshold. Against this backdrop, we explore methods of containing viral spread
in large networks with the focus on sparse random networks. The viral
containment strategy is to partition a large network into small components and
then to ensure the sanity of all messages delivered across different
components. With such a defense mechanism in place, an epidemic spread starting
from any node is limited to only those nodes belonging to the same component as
the initial infection node. We establish both lower and upper bounds on the
costs of inspecting inter-component messages. We further propose
heuristic-based approaches to partition large input graphs into small
components. Finally, we study the performance of our proposed algorithms under
different network topologies and different edge weight models.","28 pages, 6 figures",,,math.PR,"['math.PR', 'cs.DM', 'cs.SI', 'math.CO']","[arxiv.Result.Link('http://arxiv.org/abs/1310.1942v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1310.1942v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1310.1942v1,"{'id': 'http://arxiv.org/abs/1310.1942v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1310.1942v1', 'updated': '2013-10-07T20:19:36Z', 'updated_parsed': time.struct_time(tm_year=2013, tm_mon=10, tm_mday=7, tm_hour=20, tm_min=19, tm_sec=36, tm_wday=0, tm_yday=280, tm_isdst=0), 'published': '2013-10-07T20:19:36Z', 'published_parsed': time.struct_time(tm_year=2013, tm_mon=10, tm_mday=7, tm_hour=20, tm_min=19, tm_sec=36, tm_wday=0, tm_yday=280, tm_isdst=0), 'title': 'Containing Viral Spread on Sparse Random Graphs: Bounds, Algorithms, and\n  Experiments', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Containing Viral Spread on Sparse Random Graphs: Bounds, Algorithms, and\n  Experiments'}, 'summary': 'Viral spread on large graphs has many real-life applications such as malware\npropagation in computer networks and rumor (or misinformation) spread in\nTwitter-like online social networks. Although viral spread on large graphs has\nbeen intensively analyzed on classical models such as\nSusceptible-Infectious-Recovered, there still exits a deficit of effective\nmethods in practice to contain epidemic spread once it passes a critical\nthreshold. Against this backdrop, we explore methods of containing viral spread\nin large networks with the focus on sparse random networks. The viral\ncontainment strategy is to partition a large network into small components and\nthen to ensure the sanity of all messages delivered across different\ncomponents. With such a defense mechanism in place, an epidemic spread starting\nfrom any node is limited to only those nodes belonging to the same component as\nthe initial infection node. We establish both lower and upper bounds on the\ncosts of inspecting inter-component messages. We further propose\nheuristic-based approaches to partition large input graphs into small\ncomponents. Finally, we study the performance of our proposed algorithms under\ndifferent network topologies and different edge weight models.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Viral spread on large graphs has many real-life applications such as malware\npropagation in computer networks and rumor (or misinformation) spread in\nTwitter-like online social networks. Although viral spread on large graphs has\nbeen intensively analyzed on classical models such as\nSusceptible-Infectious-Recovered, there still exits a deficit of effective\nmethods in practice to contain epidemic spread once it passes a critical\nthreshold. Against this backdrop, we explore methods of containing viral spread\nin large networks with the focus on sparse random networks. The viral\ncontainment strategy is to partition a large network into small components and\nthen to ensure the sanity of all messages delivered across different\ncomponents. With such a defense mechanism in place, an epidemic spread starting\nfrom any node is limited to only those nodes belonging to the same component as\nthe initial infection node. We establish both lower and upper bounds on the\ncosts of inspecting inter-component messages. We further propose\nheuristic-based approaches to partition large input graphs into small\ncomponents. Finally, we study the performance of our proposed algorithms under\ndifferent network topologies and different edge weight models.'}, 'authors': [{'name': 'Milan Bradonjić'}, {'name': 'Michael Molloy'}, {'name': 'Guanhua Yan'}], 'author_detail': {'name': 'Guanhua Yan'}, 'author': 'Guanhua Yan', 'arxiv_comment': '28 pages, 6 figures', 'links': [{'href': 'http://arxiv.org/abs/1310.1942v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1310.1942v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
493,http://arxiv.org/abs/1307.2176v1,2013-07-08 17:19:02+00:00,2013-07-08 17:19:02+00:00,Cost overruns in Large-Scale Transportation Infrastructure Projects: Explanations and Their Theoretical Embeddedness,"[arxiv.Result.Author('Chantal C. Cantarelli'), arxiv.Result.Author('Bent Flybjerg'), arxiv.Result.Author('Eric J. E. Molin'), arxiv.Result.Author('Bert van Wee')]","Managing large-scale transportation infrastructure projects is difficult due
to frequent misinformation about the costs which results in large cost overruns
that often threaten the overall project viability. This paper investigates the
explanations for cost overruns that are given in the literature. Overall, four
categories of explanations can be distinguished: technical, economic,
psychological, and political. Political explanations have been seen to be the
most dominant explanations for cost overruns. Agency theory is considered the
most interesting for political explanations and an eclectic theory is also
considered possible. Nonpolitical explanations are diverse in character,
therefore a range of different theories (including rational choice theory and
prospect theory), depending on the kind of explanation is considered more
appropriate than one all-embracing theory.",,"European Journal of Transport and Infrastructure Research, vol.
  10, no. 1, March 2010, 5-18",,q-fin.GN,['q-fin.GN'],"[arxiv.Result.Link('http://arxiv.org/abs/1307.2176v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1307.2176v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1307.2176v1,"{'id': 'http://arxiv.org/abs/1307.2176v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1307.2176v1', 'updated': '2013-07-08T17:19:02Z', 'updated_parsed': time.struct_time(tm_year=2013, tm_mon=7, tm_mday=8, tm_hour=17, tm_min=19, tm_sec=2, tm_wday=0, tm_yday=189, tm_isdst=0), 'published': '2013-07-08T17:19:02Z', 'published_parsed': time.struct_time(tm_year=2013, tm_mon=7, tm_mday=8, tm_hour=17, tm_min=19, tm_sec=2, tm_wday=0, tm_yday=189, tm_isdst=0), 'title': 'Cost overruns in Large-Scale Transportation Infrastructure Projects:\n  Explanations and Their Theoretical Embeddedness', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Cost overruns in Large-Scale Transportation Infrastructure Projects:\n  Explanations and Their Theoretical Embeddedness'}, 'summary': 'Managing large-scale transportation infrastructure projects is difficult due\nto frequent misinformation about the costs which results in large cost overruns\nthat often threaten the overall project viability. This paper investigates the\nexplanations for cost overruns that are given in the literature. Overall, four\ncategories of explanations can be distinguished: technical, economic,\npsychological, and political. Political explanations have been seen to be the\nmost dominant explanations for cost overruns. Agency theory is considered the\nmost interesting for political explanations and an eclectic theory is also\nconsidered possible. Nonpolitical explanations are diverse in character,\ntherefore a range of different theories (including rational choice theory and\nprospect theory), depending on the kind of explanation is considered more\nappropriate than one all-embracing theory.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Managing large-scale transportation infrastructure projects is difficult due\nto frequent misinformation about the costs which results in large cost overruns\nthat often threaten the overall project viability. This paper investigates the\nexplanations for cost overruns that are given in the literature. Overall, four\ncategories of explanations can be distinguished: technical, economic,\npsychological, and political. Political explanations have been seen to be the\nmost dominant explanations for cost overruns. Agency theory is considered the\nmost interesting for political explanations and an eclectic theory is also\nconsidered possible. Nonpolitical explanations are diverse in character,\ntherefore a range of different theories (including rational choice theory and\nprospect theory), depending on the kind of explanation is considered more\nappropriate than one all-embracing theory.'}, 'authors': [{'name': 'Chantal C. Cantarelli'}, {'name': 'Bent Flybjerg'}, {'name': 'Eric J. E. Molin'}, {'name': 'Bert van Wee'}], 'author_detail': {'name': 'Bert van Wee'}, 'author': 'Bert van Wee', 'arxiv_journal_ref': 'European Journal of Transport and Infrastructure Research, vol.\n  10, no. 1, March 2010, 5-18', 'links': [{'href': 'http://arxiv.org/abs/1307.2176v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1307.2176v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
494,http://arxiv.org/abs/1304.5719v2,2015-01-05 10:40:27+00:00,2013-04-21 10:58:03+00:00,Synchronous Counting and Computational Algorithm Design,"[arxiv.Result.Author('Danny Dolev'), arxiv.Result.Author('Keijo Heljanko'), arxiv.Result.Author('Matti Järvisalo'), arxiv.Result.Author('Janne H. Korhonen'), arxiv.Result.Author('Christoph Lenzen'), arxiv.Result.Author('Joel Rybicki'), arxiv.Result.Author('Jukka Suomela'), arxiv.Result.Author('Siert Wieringa')]","Consider a complete communication network on $n$ nodes, each of which is a
state machine. In synchronous 2-counting, the nodes receive a common clock
pulse and they have to agree on which pulses are ""odd"" and which are ""even"". We
require that the solution is self-stabilising (reaching the correct operation
from any initial state) and it tolerates $f$ Byzantine failures (nodes that
send arbitrary misinformation). Prior algorithms are expensive to implement in
hardware: they require a source of random bits or a large number of states.
  This work consists of two parts. In the first part, we use computational
techniques (often known as synthesis) to construct very compact deterministic
algorithms for the first non-trivial case of $f = 1$. While no algorithm exists
for $n < 4$, we show that as few as 3 states per node are sufficient for all
values $n \ge 4$. Moreover, the problem cannot be solved with only 2 states per
node for $n = 4$, but there is a 2-state solution for all values $n \ge 6$.
  In the second part, we develop and compare two different approaches for
synthesising synchronous counting algorithms. Both approaches are based on
casting the synthesis problem as a propositional satisfiability (SAT) problem
and employing modern SAT-solvers. The difference lies in how to solve the SAT
problem: either in a direct fashion, or incrementally within a counter-example
guided abstraction refinement loop. Empirical results suggest that the former
technique is more efficient if we want to synthesise time-optimal algorithms,
while the latter technique discovers non-optimal algorithms more quickly.","35 pages, extended and revised version",,10.1016/j.jcss.2015.09.002,cs.DC,"['cs.DC', 'cs.CC', 'cs.DS']","[arxiv.Result.Link('http://dx.doi.org/10.1016/j.jcss.2015.09.002', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1304.5719v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1304.5719v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1304.5719v2,"{'id': 'http://arxiv.org/abs/1304.5719v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1304.5719v2', 'updated': '2015-01-05T10:40:27Z', 'updated_parsed': time.struct_time(tm_year=2015, tm_mon=1, tm_mday=5, tm_hour=10, tm_min=40, tm_sec=27, tm_wday=0, tm_yday=5, tm_isdst=0), 'published': '2013-04-21T10:58:03Z', 'published_parsed': time.struct_time(tm_year=2013, tm_mon=4, tm_mday=21, tm_hour=10, tm_min=58, tm_sec=3, tm_wday=6, tm_yday=111, tm_isdst=0), 'title': 'Synchronous Counting and Computational Algorithm Design', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Synchronous Counting and Computational Algorithm Design'}, 'summary': 'Consider a complete communication network on $n$ nodes, each of which is a\nstate machine. In synchronous 2-counting, the nodes receive a common clock\npulse and they have to agree on which pulses are ""odd"" and which are ""even"". We\nrequire that the solution is self-stabilising (reaching the correct operation\nfrom any initial state) and it tolerates $f$ Byzantine failures (nodes that\nsend arbitrary misinformation). Prior algorithms are expensive to implement in\nhardware: they require a source of random bits or a large number of states.\n  This work consists of two parts. In the first part, we use computational\ntechniques (often known as synthesis) to construct very compact deterministic\nalgorithms for the first non-trivial case of $f = 1$. While no algorithm exists\nfor $n < 4$, we show that as few as 3 states per node are sufficient for all\nvalues $n \\ge 4$. Moreover, the problem cannot be solved with only 2 states per\nnode for $n = 4$, but there is a 2-state solution for all values $n \\ge 6$.\n  In the second part, we develop and compare two different approaches for\nsynthesising synchronous counting algorithms. Both approaches are based on\ncasting the synthesis problem as a propositional satisfiability (SAT) problem\nand employing modern SAT-solvers. The difference lies in how to solve the SAT\nproblem: either in a direct fashion, or incrementally within a counter-example\nguided abstraction refinement loop. Empirical results suggest that the former\ntechnique is more efficient if we want to synthesise time-optimal algorithms,\nwhile the latter technique discovers non-optimal algorithms more quickly.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Consider a complete communication network on $n$ nodes, each of which is a\nstate machine. In synchronous 2-counting, the nodes receive a common clock\npulse and they have to agree on which pulses are ""odd"" and which are ""even"". We\nrequire that the solution is self-stabilising (reaching the correct operation\nfrom any initial state) and it tolerates $f$ Byzantine failures (nodes that\nsend arbitrary misinformation). Prior algorithms are expensive to implement in\nhardware: they require a source of random bits or a large number of states.\n  This work consists of two parts. In the first part, we use computational\ntechniques (often known as synthesis) to construct very compact deterministic\nalgorithms for the first non-trivial case of $f = 1$. While no algorithm exists\nfor $n < 4$, we show that as few as 3 states per node are sufficient for all\nvalues $n \\ge 4$. Moreover, the problem cannot be solved with only 2 states per\nnode for $n = 4$, but there is a 2-state solution for all values $n \\ge 6$.\n  In the second part, we develop and compare two different approaches for\nsynthesising synchronous counting algorithms. Both approaches are based on\ncasting the synthesis problem as a propositional satisfiability (SAT) problem\nand employing modern SAT-solvers. The difference lies in how to solve the SAT\nproblem: either in a direct fashion, or incrementally within a counter-example\nguided abstraction refinement loop. Empirical results suggest that the former\ntechnique is more efficient if we want to synthesise time-optimal algorithms,\nwhile the latter technique discovers non-optimal algorithms more quickly.'}, 'authors': [{'name': 'Danny Dolev'}, {'name': 'Keijo Heljanko'}, {'name': 'Matti Järvisalo'}, {'name': 'Janne H. Korhonen'}, {'name': 'Christoph Lenzen'}, {'name': 'Joel Rybicki'}, {'name': 'Jukka Suomela'}, {'name': 'Siert Wieringa'}], 'author_detail': {'name': 'Siert Wieringa'}, 'author': 'Siert Wieringa', 'arxiv_doi': '10.1016/j.jcss.2015.09.002', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.jcss.2015.09.002', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1304.5719v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1304.5719v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '35 pages, extended and revised version', 'arxiv_primary_category': {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
495,http://arxiv.org/abs/1303.7400v1,2013-03-28 13:04:30+00:00,2013-03-28 13:04:30+00:00,"Policy and Planning for Large Infrastructure Projects: Problems, Causes, Cures",[arxiv.Result.Author('Bent Flyvbjerg')],"This paper argues, first, that a major problem in the planning of large
infrastructure projects is the high level of misinformation about costs and
benefits that decision makers face in deciding whether to build, and the high
risks such misinformation generates. Second, it explores the causes of
misinformation and risk, mainly in the guise of optimism bias and strategic
misrepresentation. Finally, the paper presents a number of measures aimed at
improving planning and decision making for large infrastructure projects,
including changed incentive structures and better planning methods. Thus the
paper is organized as a simple triptych consisting in problems, causes, and
cures.","arXiv admin note: substantial text overlap with arXiv:1303.6571,
  arXiv:1303.6654, arXiv:1303.6571, arXiv:1302.3642",,,q-fin.GN,['q-fin.GN'],"[arxiv.Result.Link('http://arxiv.org/abs/1303.7400v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1303.7400v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1303.7400v1,"{'id': 'http://arxiv.org/abs/1303.7400v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1303.7400v1', 'updated': '2013-03-28T13:04:30Z', 'updated_parsed': time.struct_time(tm_year=2013, tm_mon=3, tm_mday=28, tm_hour=13, tm_min=4, tm_sec=30, tm_wday=3, tm_yday=87, tm_isdst=0), 'published': '2013-03-28T13:04:30Z', 'published_parsed': time.struct_time(tm_year=2013, tm_mon=3, tm_mday=28, tm_hour=13, tm_min=4, tm_sec=30, tm_wday=3, tm_yday=87, tm_isdst=0), 'title': 'Policy and Planning for Large Infrastructure Projects: Problems, Causes,\n  Cures', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Policy and Planning for Large Infrastructure Projects: Problems, Causes,\n  Cures'}, 'summary': 'This paper argues, first, that a major problem in the planning of large\ninfrastructure projects is the high level of misinformation about costs and\nbenefits that decision makers face in deciding whether to build, and the high\nrisks such misinformation generates. Second, it explores the causes of\nmisinformation and risk, mainly in the guise of optimism bias and strategic\nmisrepresentation. Finally, the paper presents a number of measures aimed at\nimproving planning and decision making for large infrastructure projects,\nincluding changed incentive structures and better planning methods. Thus the\npaper is organized as a simple triptych consisting in problems, causes, and\ncures.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper argues, first, that a major problem in the planning of large\ninfrastructure projects is the high level of misinformation about costs and\nbenefits that decision makers face in deciding whether to build, and the high\nrisks such misinformation generates. Second, it explores the causes of\nmisinformation and risk, mainly in the guise of optimism bias and strategic\nmisrepresentation. Finally, the paper presents a number of measures aimed at\nimproving planning and decision making for large infrastructure projects,\nincluding changed incentive structures and better planning methods. Thus the\npaper is organized as a simple triptych consisting in problems, causes, and\ncures.'}, 'authors': [{'name': 'Bent Flyvbjerg'}], 'author_detail': {'name': 'Bent Flyvbjerg'}, 'author': 'Bent Flyvbjerg', 'arxiv_comment': 'arXiv admin note: substantial text overlap with arXiv:1303.6571,\n  arXiv:1303.6654, arXiv:1303.6571, arXiv:1302.3642', 'links': [{'href': 'http://arxiv.org/abs/1303.7400v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1303.7400v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
496,http://arxiv.org/abs/1303.7404v1,2013-03-28 10:29:04+00:00,2013-03-28 10:29:04+00:00,Megaprojects and Risk: An Anatomy of Ambition,"[arxiv.Result.Author('Bent Flyvbjerg'), arxiv.Result.Author('Nils Bruzelius'), arxiv.Result.Author('Werner Rothengatter')]","Back cover text: Megaprojects and Risk provides the first detailed
examination of the phenomenon of megaprojects. It is a fascinating account of
how the promoters of multibillion-dollar megaprojects systematically and
self-servingly misinform parliaments, the public and the media in order to get
projects approved and built. It shows, in unusual depth, how the formula for
approval is an unhealthy cocktail of underestimated costs, overestimated
revenues, undervalued environmental impacts and overvalued economic development
effects. This results in projects that are extremely risky, but where the risk
is concealed from MPs, taxpayers and investors. The authors not only explore
the problems but also suggest practical solutions drawing on theory and hard,
scientific evidence from the several hundred projects in twenty nations that
illustrate the book. Accessibly written, it will be essential reading in its
field for students, scholars, planners, economists, auditors, politicians,
journalists and interested citizens.","Cambridge University Press, 2003",,,q-fin.GN,['q-fin.GN'],"[arxiv.Result.Link('http://arxiv.org/abs/1303.7404v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1303.7404v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1303.7404v1,"{'id': 'http://arxiv.org/abs/1303.7404v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1303.7404v1', 'updated': '2013-03-28T10:29:04Z', 'updated_parsed': time.struct_time(tm_year=2013, tm_mon=3, tm_mday=28, tm_hour=10, tm_min=29, tm_sec=4, tm_wday=3, tm_yday=87, tm_isdst=0), 'published': '2013-03-28T10:29:04Z', 'published_parsed': time.struct_time(tm_year=2013, tm_mon=3, tm_mday=28, tm_hour=10, tm_min=29, tm_sec=4, tm_wday=3, tm_yday=87, tm_isdst=0), 'title': 'Megaprojects and Risk: An Anatomy of Ambition', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Megaprojects and Risk: An Anatomy of Ambition'}, 'summary': 'Back cover text: Megaprojects and Risk provides the first detailed\nexamination of the phenomenon of megaprojects. It is a fascinating account of\nhow the promoters of multibillion-dollar megaprojects systematically and\nself-servingly misinform parliaments, the public and the media in order to get\nprojects approved and built. It shows, in unusual depth, how the formula for\napproval is an unhealthy cocktail of underestimated costs, overestimated\nrevenues, undervalued environmental impacts and overvalued economic development\neffects. This results in projects that are extremely risky, but where the risk\nis concealed from MPs, taxpayers and investors. The authors not only explore\nthe problems but also suggest practical solutions drawing on theory and hard,\nscientific evidence from the several hundred projects in twenty nations that\nillustrate the book. Accessibly written, it will be essential reading in its\nfield for students, scholars, planners, economists, auditors, politicians,\njournalists and interested citizens.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Back cover text: Megaprojects and Risk provides the first detailed\nexamination of the phenomenon of megaprojects. It is a fascinating account of\nhow the promoters of multibillion-dollar megaprojects systematically and\nself-servingly misinform parliaments, the public and the media in order to get\nprojects approved and built. It shows, in unusual depth, how the formula for\napproval is an unhealthy cocktail of underestimated costs, overestimated\nrevenues, undervalued environmental impacts and overvalued economic development\neffects. This results in projects that are extremely risky, but where the risk\nis concealed from MPs, taxpayers and investors. The authors not only explore\nthe problems but also suggest practical solutions drawing on theory and hard,\nscientific evidence from the several hundred projects in twenty nations that\nillustrate the book. Accessibly written, it will be essential reading in its\nfield for students, scholars, planners, economists, auditors, politicians,\njournalists and interested citizens.'}, 'authors': [{'name': 'Bent Flyvbjerg'}, {'name': 'Nils Bruzelius'}, {'name': 'Werner Rothengatter'}], 'author_detail': {'name': 'Werner Rothengatter'}, 'author': 'Werner Rothengatter', 'arxiv_comment': 'Cambridge University Press, 2003', 'links': [{'href': 'http://arxiv.org/abs/1303.7404v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1303.7404v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
497,http://arxiv.org/abs/1212.1002v1,2012-12-05 12:07:05+00:00,2012-12-05 12:07:05+00:00,Stochastic Models of Misinformation Distribution in Online Social Networks,"[arxiv.Result.Author('Konstantin Abramov'), arxiv.Result.Author('Yuri Monakhov')]","This report contains results of an experimental study of the distribution of
misinformation in online social networks (OSNs). We consider the classification
of the topologies of OSNs and analyze the parameters identified in order to
relate the topology of a real network with one of the classes. We propose an
algorithm for conducting a search for the percolation cluster in the social
graph.","4 pages, 1 figure, 1 table",,,cs.SI,"['cs.SI', 'physics.soc-ph', 'H.1.2; J.4']","[arxiv.Result.Link('http://arxiv.org/abs/1212.1002v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1212.1002v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1212.1002v1,"{'id': 'http://arxiv.org/abs/1212.1002v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1212.1002v1', 'updated': '2012-12-05T12:07:05Z', 'updated_parsed': time.struct_time(tm_year=2012, tm_mon=12, tm_mday=5, tm_hour=12, tm_min=7, tm_sec=5, tm_wday=2, tm_yday=340, tm_isdst=0), 'published': '2012-12-05T12:07:05Z', 'published_parsed': time.struct_time(tm_year=2012, tm_mon=12, tm_mday=5, tm_hour=12, tm_min=7, tm_sec=5, tm_wday=2, tm_yday=340, tm_isdst=0), 'title': 'Stochastic Models of Misinformation Distribution in Online Social\n  Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Stochastic Models of Misinformation Distribution in Online Social\n  Networks'}, 'summary': 'This report contains results of an experimental study of the distribution of\nmisinformation in online social networks (OSNs). We consider the classification\nof the topologies of OSNs and analyze the parameters identified in order to\nrelate the topology of a real network with one of the classes. We propose an\nalgorithm for conducting a search for the percolation cluster in the social\ngraph.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This report contains results of an experimental study of the distribution of\nmisinformation in online social networks (OSNs). We consider the classification\nof the topologies of OSNs and analyze the parameters identified in order to\nrelate the topology of a real network with one of the classes. We propose an\nalgorithm for conducting a search for the percolation cluster in the social\ngraph.'}, 'authors': [{'name': 'Konstantin Abramov'}, {'name': 'Yuri Monakhov'}], 'author_detail': {'name': 'Yuri Monakhov'}, 'author': 'Yuri Monakhov', 'arxiv_comment': '4 pages, 1 figure, 1 table', 'links': [{'href': 'http://arxiv.org/abs/1212.1002v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1212.1002v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.1.2; J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
498,http://arxiv.org/abs/1212.0336v1,2012-12-03 09:48:02+00:00,2012-12-03 09:48:02+00:00,Analytical model of misinformation of a social network node,"[arxiv.Result.Author('Yuri Monakhov'), arxiv.Result.Author('Maria Medvednikova'), arxiv.Result.Author('Konstantin Abramov'), arxiv.Result.Author('Natalia Kostina'), arxiv.Result.Author('Roman Malyshev'), arxiv.Result.Author('Makarov Oleg'), arxiv.Result.Author('Irina Semenova')]","This paper presents the research of the influence of cognitive, behavioral,
representational factors on the susceptibility of the participants in social
networks to misinformation, as well as on the activity of the nodes in this
regard. The importance of this research consists of method of blocking the
propaganda. This is very important because when people involuntarily acquire
information some of them experience an undesired change in their social
attitude. Such phenomena typically lead towards the information warfare. A
model was developed during this research for calculating the level of
misinformation of the social network participant (network node) based on the
model of iterative learning process.","3 pages, 1 figure",,,cs.SI,"['cs.SI', 'physics.soc-ph', 'H.1.2; J.4']","[arxiv.Result.Link('http://arxiv.org/abs/1212.0336v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1212.0336v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1212.0336v1,"{'id': 'http://arxiv.org/abs/1212.0336v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1212.0336v1', 'updated': '2012-12-03T09:48:02Z', 'updated_parsed': time.struct_time(tm_year=2012, tm_mon=12, tm_mday=3, tm_hour=9, tm_min=48, tm_sec=2, tm_wday=0, tm_yday=338, tm_isdst=0), 'published': '2012-12-03T09:48:02Z', 'published_parsed': time.struct_time(tm_year=2012, tm_mon=12, tm_mday=3, tm_hour=9, tm_min=48, tm_sec=2, tm_wday=0, tm_yday=338, tm_isdst=0), 'title': 'Analytical model of misinformation of a social network node', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'Analytical model of misinformation of a social network node'}, 'summary': 'This paper presents the research of the influence of cognitive, behavioral,\nrepresentational factors on the susceptibility of the participants in social\nnetworks to misinformation, as well as on the activity of the nodes in this\nregard. The importance of this research consists of method of blocking the\npropaganda. This is very important because when people involuntarily acquire\ninformation some of them experience an undesired change in their social\nattitude. Such phenomena typically lead towards the information warfare. A\nmodel was developed during this research for calculating the level of\nmisinformation of the social network participant (network node) based on the\nmodel of iterative learning process.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This paper presents the research of the influence of cognitive, behavioral,\nrepresentational factors on the susceptibility of the participants in social\nnetworks to misinformation, as well as on the activity of the nodes in this\nregard. The importance of this research consists of method of blocking the\npropaganda. This is very important because when people involuntarily acquire\ninformation some of them experience an undesired change in their social\nattitude. Such phenomena typically lead towards the information warfare. A\nmodel was developed during this research for calculating the level of\nmisinformation of the social network participant (network node) based on the\nmodel of iterative learning process.'}, 'authors': [{'name': 'Yuri Monakhov'}, {'name': 'Maria Medvednikova'}, {'name': 'Konstantin Abramov'}, {'name': 'Natalia Kostina'}, {'name': 'Roman Malyshev'}, {'name': 'Makarov Oleg'}, {'name': 'Irina Semenova'}], 'author_detail': {'name': 'Irina Semenova'}, 'author': 'Irina Semenova', 'arxiv_comment': '3 pages, 1 figure', 'links': [{'href': 'http://arxiv.org/abs/1212.0336v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1212.0336v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.1.2; J.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
499,http://arxiv.org/abs/1211.3175v1,2012-11-14 01:17:59+00:00,2012-11-14 01:17:59+00:00,"""But since the affairs of men rest still uncertain, let's reason with the worst that may befall"": Probability, risk, and the 2009 L'Aquila Earthquake",[arxiv.Result.Author('Steven N. Shore')],"This article is a commentary on the verdict of the ""L'Aquila Six"", the group
of bureaucrats and scientists tried by an Italian court as a result of their
public statements in advance of the quake of 2009 Apr. 6 that left the city in
ruins and cause more than 300 deaths. It was not the worst such catastrophic
event in recent Italian history, but it was one of -- if not the -- worst
failures of risk assessment and preventive action. The six were found guilty
and condemned by a first level of the justice system to substantial prison
terms. The outcry provoked by the verdict in the world press and the
international scientific community has fueled the already fiery debate over
whether the six should have been tried at all. They have been presented as
martyrs to science being treated as scapegoats by a scientifically illiterate
justice system and inflamed local population for not being able to perform the
impossible (predict the event). Petitions of support have been drafted and
signed by thousands of working scientists and technical experts in many fields
excoriating the court and the country for such an outrage against the
scientific community, often accompanied by ominous warnings about the chilling
effect this will have on the availability of expert advice in times of need. My
purpose in this essay is to explain why this view of the events of the trial is
misguided, however well intentioned, and misinformed.","8 pages, no figures (language, english); In press, 2012,
  ScienzaePace, the journal of the Interdisciplinary Center for Peace Studies
  (Centro Interdisciplinare Scienze per la Pace), University of Pisa (ISSN
  2039-1749 http://scienzaepace.unipi.it/)",,,physics.soc-ph,"['physics.soc-ph', 'physics.hist-ph', 'physics.pop-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1211.3175v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1211.3175v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1211.3175v1,"{'id': 'http://arxiv.org/abs/1211.3175v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1211.3175v1', 'updated': '2012-11-14T01:17:59Z', 'updated_parsed': time.struct_time(tm_year=2012, tm_mon=11, tm_mday=14, tm_hour=1, tm_min=17, tm_sec=59, tm_wday=2, tm_yday=319, tm_isdst=0), 'published': '2012-11-14T01:17:59Z', 'published_parsed': time.struct_time(tm_year=2012, tm_mon=11, tm_mday=14, tm_hour=1, tm_min=17, tm_sec=59, tm_wday=2, tm_yday=319, tm_isdst=0), 'title': '""But since the affairs of men rest still uncertain, let\'s reason with\n  the worst that may befall"": Probability, risk, and the 2009 L\'Aquila\n  Earthquake', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': '""But since the affairs of men rest still uncertain, let\'s reason with\n  the worst that may befall"": Probability, risk, and the 2009 L\'Aquila\n  Earthquake'}, 'summary': 'This article is a commentary on the verdict of the ""L\'Aquila Six"", the group\nof bureaucrats and scientists tried by an Italian court as a result of their\npublic statements in advance of the quake of 2009 Apr. 6 that left the city in\nruins and cause more than 300 deaths. It was not the worst such catastrophic\nevent in recent Italian history, but it was one of -- if not the -- worst\nfailures of risk assessment and preventive action. The six were found guilty\nand condemned by a first level of the justice system to substantial prison\nterms. The outcry provoked by the verdict in the world press and the\ninternational scientific community has fueled the already fiery debate over\nwhether the six should have been tried at all. They have been presented as\nmartyrs to science being treated as scapegoats by a scientifically illiterate\njustice system and inflamed local population for not being able to perform the\nimpossible (predict the event). Petitions of support have been drafted and\nsigned by thousands of working scientists and technical experts in many fields\nexcoriating the court and the country for such an outrage against the\nscientific community, often accompanied by ominous warnings about the chilling\neffect this will have on the availability of expert advice in times of need. My\npurpose in this essay is to explain why this view of the events of the trial is\nmisguided, however well intentioned, and misinformed.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=500', 'value': 'This article is a commentary on the verdict of the ""L\'Aquila Six"", the group\nof bureaucrats and scientists tried by an Italian court as a result of their\npublic statements in advance of the quake of 2009 Apr. 6 that left the city in\nruins and cause more than 300 deaths. It was not the worst such catastrophic\nevent in recent Italian history, but it was one of -- if not the -- worst\nfailures of risk assessment and preventive action. The six were found guilty\nand condemned by a first level of the justice system to substantial prison\nterms. The outcry provoked by the verdict in the world press and the\ninternational scientific community has fueled the already fiery debate over\nwhether the six should have been tried at all. They have been presented as\nmartyrs to science being treated as scapegoats by a scientifically illiterate\njustice system and inflamed local population for not being able to perform the\nimpossible (predict the event). Petitions of support have been drafted and\nsigned by thousands of working scientists and technical experts in many fields\nexcoriating the court and the country for such an outrage against the\nscientific community, often accompanied by ominous warnings about the chilling\neffect this will have on the availability of expert advice in times of need. My\npurpose in this essay is to explain why this view of the events of the trial is\nmisguided, however well intentioned, and misinformed.'}, 'authors': [{'name': 'Steven N. Shore'}], 'author_detail': {'name': 'Steven N. Shore'}, 'arxiv_affiliation': 'Dept. of Physics, Univ. of Pisa', 'author': 'Steven N. Shore', 'arxiv_comment': '8 pages, no figures (language, english); In press, 2012,\n  ScienzaePace, the journal of the Interdisciplinary Center for Peace Studies\n  (Centro Interdisciplinare Scienze per la Pace), University of Pisa (ISSN\n  2039-1749 http://scienzaepace.unipi.it/)', 'links': [{'href': 'http://arxiv.org/abs/1211.3175v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1211.3175v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.hist-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
500,http://arxiv.org/abs/1112.3620v2,2011-12-19 18:28:16+00:00,2011-12-15 19:35:01+00:00,Probably a discovery: Bad mathematics means rough scientific communication,"[arxiv.Result.Author(""G. D'Agostini"")]","According to the media, in spring of this year the experiment CDF at Fermilab
has made most likely (""this result has a 99.7 percent chance of being correct"",
Discovery News) a great discovery (""the most significant in physics in half a
century"", NYT). However, since the very beginning, practically all particle
physics experts did not believe that was the case. This is the last of a quite
long series of fake claims based on trivial mistakes in the probabilistic
reasoning. The main purpose of this note is to invite everybody, but especially
journalists and general public, most times innocent victims of misinformation
of this kind, to mistrust claims not explicitly reported in terms of how much
we should believe something, under well stated conditions and assumptions. (A
last minute appendix has been added, with comments on the recent news
concerning the Higgs at LHC.)","21 pages, 2 figures, note based on lectures at the University of
  Perugia, 15-16 April 2011 and at MAPSES School in Lecce, 23-25 November 2011",,,physics.data-an,"['physics.data-an', 'hep-ph', 'math.HO', 'physics.pop-ph', 'physics.soc-ph']","[arxiv.Result.Link('http://arxiv.org/abs/1112.3620v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1112.3620v2', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1112.3620v2,"{'id': 'http://arxiv.org/abs/1112.3620v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1112.3620v2', 'updated': '2011-12-19T18:28:16Z', 'updated_parsed': time.struct_time(tm_year=2011, tm_mon=12, tm_mday=19, tm_hour=18, tm_min=28, tm_sec=16, tm_wday=0, tm_yday=353, tm_isdst=0), 'published': '2011-12-15T19:35:01Z', 'published_parsed': time.struct_time(tm_year=2011, tm_mon=12, tm_mday=15, tm_hour=19, tm_min=35, tm_sec=1, tm_wday=3, tm_yday=349, tm_isdst=0), 'title': 'Probably a discovery: Bad mathematics means rough scientific\n  communication', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Probably a discovery: Bad mathematics means rough scientific\n  communication'}, 'summary': 'According to the media, in spring of this year the experiment CDF at Fermilab\nhas made most likely (""this result has a 99.7 percent chance of being correct"",\nDiscovery News) a great discovery (""the most significant in physics in half a\ncentury"", NYT). However, since the very beginning, practically all particle\nphysics experts did not believe that was the case. This is the last of a quite\nlong series of fake claims based on trivial mistakes in the probabilistic\nreasoning. The main purpose of this note is to invite everybody, but especially\njournalists and general public, most times innocent victims of misinformation\nof this kind, to mistrust claims not explicitly reported in terms of how much\nwe should believe something, under well stated conditions and assumptions. (A\nlast minute appendix has been added, with comments on the recent news\nconcerning the Higgs at LHC.)', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'According to the media, in spring of this year the experiment CDF at Fermilab\nhas made most likely (""this result has a 99.7 percent chance of being correct"",\nDiscovery News) a great discovery (""the most significant in physics in half a\ncentury"", NYT). However, since the very beginning, practically all particle\nphysics experts did not believe that was the case. This is the last of a quite\nlong series of fake claims based on trivial mistakes in the probabilistic\nreasoning. The main purpose of this note is to invite everybody, but especially\njournalists and general public, most times innocent victims of misinformation\nof this kind, to mistrust claims not explicitly reported in terms of how much\nwe should believe something, under well stated conditions and assumptions. (A\nlast minute appendix has been added, with comments on the recent news\nconcerning the Higgs at LHC.)'}, 'authors': [{'name': ""G. D'Agostini""}], 'author_detail': {'name': ""G. D'Agostini""}, 'author': ""G. D'Agostini"", 'arxiv_comment': '21 pages, 2 figures, note based on lectures at the University of\n  Perugia, 15-16 April 2011 and at MAPSES School in Lecce, 23-25 November 2011', 'links': [{'href': 'http://arxiv.org/abs/1112.3620v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1112.3620v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'hep-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.HO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
501,http://arxiv.org/abs/1011.3768v1,2010-11-16 17:46:23+00:00,2010-11-16 17:46:23+00:00,Detecting and Tracking the Spread of Astroturf Memes in Microblog Streams,"[arxiv.Result.Author('Jacob Ratkiewicz'), arxiv.Result.Author('Michael Conover'), arxiv.Result.Author('Mark Meiss'), arxiv.Result.Author('Bruno Gonçalves'), arxiv.Result.Author('Snehal Patil'), arxiv.Result.Author('Alessandro Flammini'), arxiv.Result.Author('Filippo Menczer')]","Online social media are complementing and in some cases replacing
person-to-person social interaction and redefining the diffusion of
information. In particular, microblogs have become crucial grounds on which
public relations, marketing, and political battles are fought. We introduce an
extensible framework that will enable the real-time analysis of meme diffusion
in social media by mining, visualizing, mapping, classifying, and modeling
massive streams of public microblogging events. We describe a Web service that
leverages this framework to track political memes in Twitter and help detect
astroturfing, smear campaigns, and other misinformation in the context of U.S.
political elections. We present some cases of abusive behaviors uncovered by
our service. Finally, we discuss promising preliminary results on the detection
of suspicious memes via supervised learning based on features extracted from
the topology of the diffusion networks, sentiment analysis, and crowdsourced
annotations.",,"Proceedings of the 20th international conference companion on
  World wide web, 249-252 (2011)",10.1145/1963192.1963301,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Link('http://dx.doi.org/10.1145/1963192.1963301', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1011.3768v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1011.3768v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/1011.3768v1,"{'id': 'http://arxiv.org/abs/1011.3768v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/1011.3768v1', 'updated': '2010-11-16T17:46:23Z', 'updated_parsed': time.struct_time(tm_year=2010, tm_mon=11, tm_mday=16, tm_hour=17, tm_min=46, tm_sec=23, tm_wday=1, tm_yday=320, tm_isdst=0), 'published': '2010-11-16T17:46:23Z', 'published_parsed': time.struct_time(tm_year=2010, tm_mon=11, tm_mday=16, tm_hour=17, tm_min=46, tm_sec=23, tm_wday=1, tm_yday=320, tm_isdst=0), 'title': 'Detecting and Tracking the Spread of Astroturf Memes in Microblog\n  Streams', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Detecting and Tracking the Spread of Astroturf Memes in Microblog\n  Streams'}, 'summary': 'Online social media are complementing and in some cases replacing\nperson-to-person social interaction and redefining the diffusion of\ninformation. In particular, microblogs have become crucial grounds on which\npublic relations, marketing, and political battles are fought. We introduce an\nextensible framework that will enable the real-time analysis of meme diffusion\nin social media by mining, visualizing, mapping, classifying, and modeling\nmassive streams of public microblogging events. We describe a Web service that\nleverages this framework to track political memes in Twitter and help detect\nastroturfing, smear campaigns, and other misinformation in the context of U.S.\npolitical elections. We present some cases of abusive behaviors uncovered by\nour service. Finally, we discuss promising preliminary results on the detection\nof suspicious memes via supervised learning based on features extracted from\nthe topology of the diffusion networks, sentiment analysis, and crowdsourced\nannotations.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Online social media are complementing and in some cases replacing\nperson-to-person social interaction and redefining the diffusion of\ninformation. In particular, microblogs have become crucial grounds on which\npublic relations, marketing, and political battles are fought. We introduce an\nextensible framework that will enable the real-time analysis of meme diffusion\nin social media by mining, visualizing, mapping, classifying, and modeling\nmassive streams of public microblogging events. We describe a Web service that\nleverages this framework to track political memes in Twitter and help detect\nastroturfing, smear campaigns, and other misinformation in the context of U.S.\npolitical elections. We present some cases of abusive behaviors uncovered by\nour service. Finally, we discuss promising preliminary results on the detection\nof suspicious memes via supervised learning based on features extracted from\nthe topology of the diffusion networks, sentiment analysis, and crowdsourced\nannotations.'}, 'authors': [{'name': 'Jacob Ratkiewicz'}, {'name': 'Michael Conover'}, {'name': 'Mark Meiss'}, {'name': 'Bruno Gonçalves'}, {'name': 'Snehal Patil'}, {'name': 'Alessandro Flammini'}, {'name': 'Filippo Menczer'}], 'author_detail': {'name': 'Filippo Menczer'}, 'author': 'Filippo Menczer', 'arxiv_doi': '10.1145/1963192.1963301', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/1963192.1963301', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1011.3768v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1011.3768v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_journal_ref': 'Proceedings of the 20th international conference companion on\n  World wide web, 249-252 (2011)', 'arxiv_primary_category': {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
502,http://arxiv.org/abs/0906.5007v1,2009-06-26 20:57:55+00:00,2009-06-26 20:57:55+00:00,Spread of Misinformation in Social Networks,"[arxiv.Result.Author('Daron Acemoglu'), arxiv.Result.Author('Asuman Ozdaglar'), arxiv.Result.Author('Ali ParandehGheibi')]","We provide a model to investigate the tension between information aggregation
and spread of misinformation in large societies (conceptualized as networks of
agents communicating with each other). Each individual holds a belief
represented by a scalar. Individuals meet pairwise and exchange information,
which is modeled as both individuals adopting the average of their pre-meeting
beliefs. When all individuals engage in this type of information exchange, the
society will be able to effectively aggregate the initial information held by
all individuals. There is also the possibility of misinformation, however,
because some of the individuals are ""forceful,"" meaning that they influence the
beliefs of (some) of the other individuals they meet, but do not change their
own opinion. The paper characterizes how the presence of forceful agents
interferes with information aggregation. Under the assumption that even
forceful agents obtain some information (however infrequent) from some others
(and additional weak regularity conditions), we first show that beliefs in this
class of societies converge to a consensus among all individuals. This
consensus value is a random variable, however, and we characterize its
behavior. Our main results quantify the extent of misinformation in the society
by either providing bounds or exact results (in some special cases) on how far
the consensus value can be from the benchmark without forceful agents (where
there is efficient information aggregation). The worst outcomes obtain when
there are several forceful agents and forceful agents themselves update their
beliefs only on the basis of information they obtain from individuals most
likely to have received their own information previously.",Submitted to Games and Economic Behavior,,,cs.IT,"['cs.IT', 'cs.DC', 'math.IT', 'math.PR']","[arxiv.Result.Link('http://arxiv.org/abs/0906.5007v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/0906.5007v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/0906.5007v1,"{'id': 'http://arxiv.org/abs/0906.5007v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/0906.5007v1', 'updated': '2009-06-26T20:57:55Z', 'updated_parsed': time.struct_time(tm_year=2009, tm_mon=6, tm_mday=26, tm_hour=20, tm_min=57, tm_sec=55, tm_wday=4, tm_yday=177, tm_isdst=0), 'published': '2009-06-26T20:57:55Z', 'published_parsed': time.struct_time(tm_year=2009, tm_mon=6, tm_mday=26, tm_hour=20, tm_min=57, tm_sec=55, tm_wday=4, tm_yday=177, tm_isdst=0), 'title': 'Spread of Misinformation in Social Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Spread of Misinformation in Social Networks'}, 'summary': 'We provide a model to investigate the tension between information aggregation\nand spread of misinformation in large societies (conceptualized as networks of\nagents communicating with each other). Each individual holds a belief\nrepresented by a scalar. Individuals meet pairwise and exchange information,\nwhich is modeled as both individuals adopting the average of their pre-meeting\nbeliefs. When all individuals engage in this type of information exchange, the\nsociety will be able to effectively aggregate the initial information held by\nall individuals. There is also the possibility of misinformation, however,\nbecause some of the individuals are ""forceful,"" meaning that they influence the\nbeliefs of (some) of the other individuals they meet, but do not change their\nown opinion. The paper characterizes how the presence of forceful agents\ninterferes with information aggregation. Under the assumption that even\nforceful agents obtain some information (however infrequent) from some others\n(and additional weak regularity conditions), we first show that beliefs in this\nclass of societies converge to a consensus among all individuals. This\nconsensus value is a random variable, however, and we characterize its\nbehavior. Our main results quantify the extent of misinformation in the society\nby either providing bounds or exact results (in some special cases) on how far\nthe consensus value can be from the benchmark without forceful agents (where\nthere is efficient information aggregation). The worst outcomes obtain when\nthere are several forceful agents and forceful agents themselves update their\nbeliefs only on the basis of information they obtain from individuals most\nlikely to have received their own information previously.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'We provide a model to investigate the tension between information aggregation\nand spread of misinformation in large societies (conceptualized as networks of\nagents communicating with each other). Each individual holds a belief\nrepresented by a scalar. Individuals meet pairwise and exchange information,\nwhich is modeled as both individuals adopting the average of their pre-meeting\nbeliefs. When all individuals engage in this type of information exchange, the\nsociety will be able to effectively aggregate the initial information held by\nall individuals. There is also the possibility of misinformation, however,\nbecause some of the individuals are ""forceful,"" meaning that they influence the\nbeliefs of (some) of the other individuals they meet, but do not change their\nown opinion. The paper characterizes how the presence of forceful agents\ninterferes with information aggregation. Under the assumption that even\nforceful agents obtain some information (however infrequent) from some others\n(and additional weak regularity conditions), we first show that beliefs in this\nclass of societies converge to a consensus among all individuals. This\nconsensus value is a random variable, however, and we characterize its\nbehavior. Our main results quantify the extent of misinformation in the society\nby either providing bounds or exact results (in some special cases) on how far\nthe consensus value can be from the benchmark without forceful agents (where\nthere is efficient information aggregation). The worst outcomes obtain when\nthere are several forceful agents and forceful agents themselves update their\nbeliefs only on the basis of information they obtain from individuals most\nlikely to have received their own information previously.'}, 'authors': [{'name': 'Daron Acemoglu'}, {'name': 'Asuman Ozdaglar'}, {'name': 'Ali ParandehGheibi'}], 'author_detail': {'name': 'Ali ParandehGheibi'}, 'author': 'Ali ParandehGheibi', 'arxiv_comment': 'Submitted to Games and Economic Behavior', 'links': [{'href': 'http://arxiv.org/abs/0906.5007v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/0906.5007v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
503,http://arxiv.org/abs/0903.2448v3,2009-03-23 18:42:39+00:00,2009-03-13 18:30:55+00:00,"Positive Logic with Adjoint Modalities: Proof Theory, Semantics and Reasoning about Information","[arxiv.Result.Author('Mehrnoosh Sadrzadeh'), arxiv.Result.Author('Roy Dyckhoff')]","We consider a simple modal logic whose non-modal part has conjunction and
disjunction as connectives and whose modalities come in adjoint pairs, but are
not in general closure operators. Despite absence of negation and implication,
and of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and
S5, such logics are useful, as shown in previous work by Baltag, Coecke and the
first author, for encoding and reasoning about information and misinformation
in multi-agent systems. For such a logic we present an algebraic semantics,
using lattices with agent-indexed families of adjoint pairs of operators, and a
cut-free sequent calculus. The calculus exploits operators on sequents, in the
style of ""nested"" or ""tree-sequent"" calculi; cut-admissibility is shown by
constructive syntactic methods. The applicability of the logic is illustrated
by reasoning about the muddy children puzzle, for which the calculus is
augmented with extra rules to express the facts of the muddy children scenario.","This paper is the full version of the article that is to appear in
  the ENTCS proceedings of the 25th conference on the Mathematical Foundations
  of Programming Semantics (MFPS), April 2009, University of Oxford",,,cs.LO,"['cs.LO', 'cs.MA']","[arxiv.Result.Link('http://arxiv.org/abs/0903.2448v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/0903.2448v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/0903.2448v3,"{'id': 'http://arxiv.org/abs/0903.2448v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/0903.2448v3', 'updated': '2009-03-23T18:42:39Z', 'updated_parsed': time.struct_time(tm_year=2009, tm_mon=3, tm_mday=23, tm_hour=18, tm_min=42, tm_sec=39, tm_wday=0, tm_yday=82, tm_isdst=0), 'published': '2009-03-13T18:30:55Z', 'published_parsed': time.struct_time(tm_year=2009, tm_mon=3, tm_mday=13, tm_hour=18, tm_min=30, tm_sec=55, tm_wday=4, tm_yday=72, tm_isdst=0), 'title': 'Positive Logic with Adjoint Modalities: Proof Theory, Semantics and\n  Reasoning about Information', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Positive Logic with Adjoint Modalities: Proof Theory, Semantics and\n  Reasoning about Information'}, 'summary': 'We consider a simple modal logic whose non-modal part has conjunction and\ndisjunction as connectives and whose modalities come in adjoint pairs, but are\nnot in general closure operators. Despite absence of negation and implication,\nand of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and\nS5, such logics are useful, as shown in previous work by Baltag, Coecke and the\nfirst author, for encoding and reasoning about information and misinformation\nin multi-agent systems. For such a logic we present an algebraic semantics,\nusing lattices with agent-indexed families of adjoint pairs of operators, and a\ncut-free sequent calculus. The calculus exploits operators on sequents, in the\nstyle of ""nested"" or ""tree-sequent"" calculi; cut-admissibility is shown by\nconstructive syntactic methods. The applicability of the logic is illustrated\nby reasoning about the muddy children puzzle, for which the calculus is\naugmented with extra rules to express the facts of the muddy children scenario.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'We consider a simple modal logic whose non-modal part has conjunction and\ndisjunction as connectives and whose modalities come in adjoint pairs, but are\nnot in general closure operators. Despite absence of negation and implication,\nand of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and\nS5, such logics are useful, as shown in previous work by Baltag, Coecke and the\nfirst author, for encoding and reasoning about information and misinformation\nin multi-agent systems. For such a logic we present an algebraic semantics,\nusing lattices with agent-indexed families of adjoint pairs of operators, and a\ncut-free sequent calculus. The calculus exploits operators on sequents, in the\nstyle of ""nested"" or ""tree-sequent"" calculi; cut-admissibility is shown by\nconstructive syntactic methods. The applicability of the logic is illustrated\nby reasoning about the muddy children puzzle, for which the calculus is\naugmented with extra rules to express the facts of the muddy children scenario.'}, 'authors': [{'name': 'Mehrnoosh Sadrzadeh'}, {'name': 'Roy Dyckhoff'}], 'author_detail': {'name': 'Roy Dyckhoff'}, 'author': 'Roy Dyckhoff', 'arxiv_comment': 'This paper is the full version of the article that is to appear in\n  the ENTCS proceedings of the 25th conference on the Mathematical Foundations\n  of Programming Semantics (MFPS), April 2009, University of Oxford', 'links': [{'href': 'http://arxiv.org/abs/0903.2448v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/0903.2448v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_primary_category': {'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
504,http://arxiv.org/abs/0803.4357v1,2008-03-31 00:24:19+00:00,2008-03-31 00:24:19+00:00,Paradoxical popups: Why are they hard to catch?,"[arxiv.Result.Author('Michael K. McBeath'), arxiv.Result.Author('Alan M. Nathan'), arxiv.Result.Author('A. Terry Bahill'), arxiv.Result.Author('David G. Baldwin')]","Even professional baseball players occasionally find it difficult to
gracefully approach seemingly routine pop-ups. This paper describes a set of
towering pop-ups with trajectories that exhibit cusps and loops near the apex.
For a normal fly ball, the horizontal velocity is continuously decreasing due
to drag caused by air resistance. But for pop-ups, the Magnus force (the force
due to the ball spinning in a moving airflow) is larger than the drag force. In
these cases the horizontal velocity decreases in the beginning, like a normal
fly ball, but after the apex, the Magnus force accelerates the horizontal
motion. We refer to this class of pop-ups as paradoxical because they appear to
misinform the typically robust optical control strategies used by fielders and
lead to systematic vacillation in running paths, especially when a trajectory
terminates near the fielder. In short, some of the dancing around when
infielders pursue pop-ups can be well explained as a combination of bizarre
trajectories and misguidance by the normally reliable optical control strategy,
rather than apparent fielder error. Former major league infielders confirm that
our model agrees with their experiences.","28 pages, 10 figures, sumitted to American Journal of Physics",,10.1119/1.2937899,physics.pop-ph,['physics.pop-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1119/1.2937899', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/0803.4357v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/0803.4357v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/0803.4357v1,"{'id': 'http://arxiv.org/abs/0803.4357v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/0803.4357v1', 'updated': '2008-03-31T00:24:19Z', 'updated_parsed': time.struct_time(tm_year=2008, tm_mon=3, tm_mday=31, tm_hour=0, tm_min=24, tm_sec=19, tm_wday=0, tm_yday=91, tm_isdst=0), 'published': '2008-03-31T00:24:19Z', 'published_parsed': time.struct_time(tm_year=2008, tm_mon=3, tm_mday=31, tm_hour=0, tm_min=24, tm_sec=19, tm_wday=0, tm_yday=91, tm_isdst=0), 'title': 'Paradoxical popups: Why are they hard to catch?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Paradoxical popups: Why are they hard to catch?'}, 'summary': 'Even professional baseball players occasionally find it difficult to\ngracefully approach seemingly routine pop-ups. This paper describes a set of\ntowering pop-ups with trajectories that exhibit cusps and loops near the apex.\nFor a normal fly ball, the horizontal velocity is continuously decreasing due\nto drag caused by air resistance. But for pop-ups, the Magnus force (the force\ndue to the ball spinning in a moving airflow) is larger than the drag force. In\nthese cases the horizontal velocity decreases in the beginning, like a normal\nfly ball, but after the apex, the Magnus force accelerates the horizontal\nmotion. We refer to this class of pop-ups as paradoxical because they appear to\nmisinform the typically robust optical control strategies used by fielders and\nlead to systematic vacillation in running paths, especially when a trajectory\nterminates near the fielder. In short, some of the dancing around when\ninfielders pursue pop-ups can be well explained as a combination of bizarre\ntrajectories and misguidance by the normally reliable optical control strategy,\nrather than apparent fielder error. Former major league infielders confirm that\nour model agrees with their experiences.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Even professional baseball players occasionally find it difficult to\ngracefully approach seemingly routine pop-ups. This paper describes a set of\ntowering pop-ups with trajectories that exhibit cusps and loops near the apex.\nFor a normal fly ball, the horizontal velocity is continuously decreasing due\nto drag caused by air resistance. But for pop-ups, the Magnus force (the force\ndue to the ball spinning in a moving airflow) is larger than the drag force. In\nthese cases the horizontal velocity decreases in the beginning, like a normal\nfly ball, but after the apex, the Magnus force accelerates the horizontal\nmotion. We refer to this class of pop-ups as paradoxical because they appear to\nmisinform the typically robust optical control strategies used by fielders and\nlead to systematic vacillation in running paths, especially when a trajectory\nterminates near the fielder. In short, some of the dancing around when\ninfielders pursue pop-ups can be well explained as a combination of bizarre\ntrajectories and misguidance by the normally reliable optical control strategy,\nrather than apparent fielder error. Former major league infielders confirm that\nour model agrees with their experiences.'}, 'authors': [{'name': 'Michael K. McBeath'}, {'name': 'Alan M. Nathan'}, {'name': 'A. Terry Bahill'}, {'name': 'David G. Baldwin'}], 'author_detail': {'name': 'David G. Baldwin'}, 'author': 'David G. Baldwin', 'arxiv_doi': '10.1119/1.2937899', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1119/1.2937899', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/0803.4357v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/0803.4357v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '28 pages, 10 figures, sumitted to American Journal of Physics', 'arxiv_primary_category': {'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.pop-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
505,http://arxiv.org/abs/astro-ph/0702542v3,2009-01-24 18:59:33+00:00,2007-02-20 21:06:10+00:00,Tainted Evidence: Cosmological Model Selection vs. Fitting,"[arxiv.Result.Author('Eric V. Linder'), arxiv.Result.Author('Ramon Miquel')]","Interpretation of cosmological data to determine the number and values of
parameters describing the universe must not rely solely on statistics but
involve physical insight. When statistical techniques such as ""model selection""
or ""integrated survey optimization"" blindly apply Occam's Razor, this can lead
to painful results. We emphasize that the sensitivity to prior probabilities
and to the number of models compared can lead to ""prior selection"" rather than
robust model selection. A concrete example demonstrates that Information
Criteria can in fact misinform over a large region of parameter space.","5 pages, 1 figure; v2 minor rephrasings, clarifications; v3 minor
  changes to match published article under title ""Cosmological Model Selection:
  Statistics and Physics""","Int.J.Mod.Phys.D17:2315,2008",10.1142/S0218271808013881,astro-ph,['astro-ph'],"[arxiv.Result.Link('http://dx.doi.org/10.1142/S0218271808013881', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/astro-ph/0702542v3', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/astro-ph/0702542v3', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/astro-ph/0702542v3,"{'id': 'http://arxiv.org/abs/astro-ph/0702542v3', 'guidislink': True, 'link': 'http://arxiv.org/abs/astro-ph/0702542v3', 'updated': '2009-01-24T18:59:33Z', 'updated_parsed': time.struct_time(tm_year=2009, tm_mon=1, tm_mday=24, tm_hour=18, tm_min=59, tm_sec=33, tm_wday=5, tm_yday=24, tm_isdst=0), 'published': '2007-02-20T21:06:10Z', 'published_parsed': time.struct_time(tm_year=2007, tm_mon=2, tm_mday=20, tm_hour=21, tm_min=6, tm_sec=10, tm_wday=1, tm_yday=51, tm_isdst=0), 'title': 'Tainted Evidence: Cosmological Model Selection vs. Fitting', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Tainted Evidence: Cosmological Model Selection vs. Fitting'}, 'summary': 'Interpretation of cosmological data to determine the number and values of\nparameters describing the universe must not rely solely on statistics but\ninvolve physical insight. When statistical techniques such as ""model selection""\nor ""integrated survey optimization"" blindly apply Occam\'s Razor, this can lead\nto painful results. We emphasize that the sensitivity to prior probabilities\nand to the number of models compared can lead to ""prior selection"" rather than\nrobust model selection. A concrete example demonstrates that Information\nCriteria can in fact misinform over a large region of parameter space.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Interpretation of cosmological data to determine the number and values of\nparameters describing the universe must not rely solely on statistics but\ninvolve physical insight. When statistical techniques such as ""model selection""\nor ""integrated survey optimization"" blindly apply Occam\'s Razor, this can lead\nto painful results. We emphasize that the sensitivity to prior probabilities\nand to the number of models compared can lead to ""prior selection"" rather than\nrobust model selection. A concrete example demonstrates that Information\nCriteria can in fact misinform over a large region of parameter space.'}, 'authors': [{'name': 'Eric V. Linder'}, {'name': 'Ramon Miquel'}], 'author_detail': {'name': 'Ramon Miquel'}, 'author': 'Ramon Miquel', 'arxiv_doi': '10.1142/S0218271808013881', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1142/S0218271808013881', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/astro-ph/0702542v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/astro-ph/0702542v3', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '5 pages, 1 figure; v2 minor rephrasings, clarifications; v3 minor\n  changes to match published article under title ""Cosmological Model Selection:\n  Statistics and Physics""', 'arxiv_journal_ref': 'Int.J.Mod.Phys.D17:2315,2008', 'arxiv_primary_category': {'term': 'astro-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'astro-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
506,http://arxiv.org/abs/physics/0603218v1,2006-03-26 08:07:32+00:00,2006-03-26 08:07:32+00:00,Self-Assembly of Information in Networks,"[arxiv.Result.Author('M. Rosvall'), arxiv.Result.Author('K. Sneppen')]","We model self-assembly of information in networks to investigate necessary
conditions for building a global perception of a system by local communication.
Our approach is to let agents chat in a model system to self-organize distant
communication-pathways. We demonstrate that simple local rules allow agents to
build a perception of the system, that is robust to dynamical changes and
mistakes. We find that messages are most effectively forwarded in the presence
of hubs, while transmission in hub-free networks is more robust against
misinformation and failures.","4 pages and 4 figures, Java simulation available at
  http://cmol.nbi.dk/models/infoflow/infoflow.html","Europhys. Lett., 74, 1109-1115 (2006).",10.1209/epl/i2006-10064-2,physics.soc-ph,"['physics.soc-ph', 'cond-mat.dis-nn']","[arxiv.Result.Link('http://dx.doi.org/10.1209/epl/i2006-10064-2', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/physics/0603218v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/physics/0603218v1', title='pdf', rel='related', content_type=None)]",http://arxiv.org/pdf/physics/0603218v1,"{'id': 'http://arxiv.org/abs/physics/0603218v1', 'guidislink': True, 'link': 'http://arxiv.org/abs/physics/0603218v1', 'updated': '2006-03-26T08:07:32Z', 'updated_parsed': time.struct_time(tm_year=2006, tm_mon=3, tm_mday=26, tm_hour=8, tm_min=7, tm_sec=32, tm_wday=6, tm_yday=85, tm_isdst=0), 'published': '2006-03-26T08:07:32Z', 'published_parsed': time.struct_time(tm_year=2006, tm_mon=3, tm_mday=26, tm_hour=8, tm_min=7, tm_sec=32, tm_wday=6, tm_yday=85, tm_isdst=0), 'title': 'Self-Assembly of Information in Networks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'Self-Assembly of Information in Networks'}, 'summary': 'We model self-assembly of information in networks to investigate necessary\nconditions for building a global perception of a system by local communication.\nOur approach is to let agents chat in a model system to self-organize distant\ncommunication-pathways. We demonstrate that simple local rules allow agents to\nbuild a perception of the system, that is robust to dynamical changes and\nmistakes. We find that messages are most effectively forwarded in the presence\nof hubs, while transmission in hub-free networks is more robust against\nmisinformation and failures.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=abs%3Amisinformation&id_list=&sortBy=submittedDate&sortOrder=descending&start=500&max_results=500', 'value': 'We model self-assembly of information in networks to investigate necessary\nconditions for building a global perception of a system by local communication.\nOur approach is to let agents chat in a model system to self-organize distant\ncommunication-pathways. We demonstrate that simple local rules allow agents to\nbuild a perception of the system, that is robust to dynamical changes and\nmistakes. We find that messages are most effectively forwarded in the presence\nof hubs, while transmission in hub-free networks is more robust against\nmisinformation and failures.'}, 'authors': [{'name': 'M. Rosvall'}, {'name': 'K. Sneppen'}], 'author_detail': {'name': 'K. Sneppen'}, 'author': 'K. Sneppen', 'arxiv_doi': '10.1209/epl/i2006-10064-2', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1209/epl/i2006-10064-2', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/physics/0603218v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/physics/0603218v1', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': '4 pages and 4 figures, Java simulation available at\n  http://cmol.nbi.dk/models/infoflow/infoflow.html', 'arxiv_journal_ref': 'Europhys. Lett., 74, 1109-1115 (2006).', 'arxiv_primary_category': {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.dis-nn', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}",abs:misinformation
